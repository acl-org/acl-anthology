<?xml version='1.0' encoding='UTF-8'?>
<collection id="2023.findings">
  <volume id="eacl" ingest-date="2023-05-03" type="proceedings">
    <meta>
      <booktitle>Findings of the Association for Computational Linguistics: EACL 2023</booktitle>
      <editor><first>Andreas</first><last>Vlachos</last></editor>
      <editor><first>Isabelle</first><last>Augenstein</last></editor>
      <publisher>Association for Computational Linguistics</publisher>
      <address>Dubrovnik, Croatia</address>
      <month>May</month>
      <year>2023</year>
      <url hash="f528210f">2023.findings-eacl</url>
      <venue>findings</venue>
    </meta>
    <frontmatter>
      <url hash="839d7a17">2023.findings-eacl.0</url>
      <bibkey>findings-2023-findings</bibkey>
    </frontmatter>
    <paper id="1">
      <title>Using Punctuation as an Adversarial Attack on Deep Learning-Based <fixed-case>NLP</fixed-case> Systems: An Empirical Study</title>
      <author><first>Brian</first><last>Formento</last><affiliation>Nus</affiliation></author>
      <author><first>Chuan Sheng</first><last>Foo</last><affiliation>Institute for Infocomm Research</affiliation></author>
      <author><first>Luu Anh</first><last>Tuan</last><affiliation>Nanyang Technological University, Singapore</affiliation></author>
      <author><first>See Kiong</first><last>Ng</last><affiliation>National University of Singapore</affiliation></author>
      <pages>1-34</pages>
      <abstract>This work empirically investigates punctuation insertions as adversarial attacks on NLP systems. Data from experiments on three tasks, five datasets, and six models with four attacks show that punctuation insertions, when limited to a few symbols (apostrophes and hyphens), are a superior attack vector compared to character insertions due to 1) a lower after-attack accuracy (<tex-math>A_{aft-atk}</tex-math>) than alphabetical character insertions; 2) higher semantic similarity between the resulting and original texts; and 3) a resulting text that is easier and faster to read as assessed with the Test of Word Reading Efficiency (TOWRE)). The tests also indicate that 4) grammar checking does not mitigate punctuation insertions and 5) punctuation insertions outperform word-level attacks in settings with a limited number of word synonyms and queries to the victim’s model. Our findings indicate that inserting a few punctuation types that result in easy-to-read samples is a general attack mechanism. In light of this threat, we assess the impact of punctuation insertions, potential mitigations, the mitigation’s tradeoffs, punctuation insertion’s worst-case scenarios and summarize our findings in a qualitative casual map, so that developers can design safer, more secure systems.</abstract>
      <url hash="61152bda">2023.findings-eacl.1</url>
      <attachment type="software" hash="a8ea7241">2023.findings-eacl.1.software.zip</attachment>
      <bibkey>formento-etal-2023-using</bibkey>
      <video href="2023.findings-eacl.1.mp4"/>
      <doi>10.18653/v1/2023.findings-eacl.1</doi>
    </paper>
    <paper id="2">
      <title>Self-Supervised Unimodal Label Generation Strategy Using Recalibrated Modality Representations for Multimodal Sentiment Analysis</title>
      <author><first>Yewon</first><last>Hwang</last><affiliation>The Korea Advanced Institute of Science and Technology</affiliation></author>
      <author><first>Jong-Hwan</first><last>Kim</last><affiliation>The Korea Advanced Institute of Science and Technology</affiliation></author>
      <pages>35-46</pages>
      <abstract>While multimodal sentiment analysis (MSA) has gained much attention over the last few years, the main focus of most work on MSA has been limited to constructing multimodal representations that capture interactions between different modalities in a single task. This was largely due to a lack of unimodal annotations in MSA benchmark datasets. However, training a model using only multimodal representations can lead to suboptimal performance due to insufficient learning of each uni-modal representation. In this work, to fully optimize learning representations from multimodal data, we propose SUGRM which jointly trains multimodal and unimodal tasks using recalibrated features. The features are recalibrated such that the model learns to weight the features differently based on the features of other modalities. Further, to leverage unimodal tasks, we auto-generate unimodal annotations via a unimodal label generation module (ULGM). The experiment results on two benchmark datasets demonstrate the efficacy of our framework.</abstract>
      <url hash="25b2427a">2023.findings-eacl.2</url>
      <bibkey>hwang-kim-2023-self</bibkey>
      <video href="2023.findings-eacl.2.mp4"/>
      <doi>10.18653/v1/2023.findings-eacl.2</doi>
    </paper>
    <paper id="3">
      <title>Fighting <fixed-case>FIR</fixed-case>e with <fixed-case>FIRE</fixed-case>: Assessing the Validity of Text-to-Video Retrieval Benchmarks</title>
      <author><first>Pedro</first><last>Rodriguez</last><affiliation>Meta FAIR</affiliation></author>
      <author><first>Mahmoud</first><last>Azab</last><affiliation>Meta Reality Labs</affiliation></author>
      <author><first>Becka</first><last>Silvert</last><affiliation>Facebook</affiliation></author>
      <author><first>Renato</first><last>Sanchez</last><affiliation>Meta</affiliation></author>
      <author><first>Linzy</first><last>Labson</last><affiliation>Meta</affiliation></author>
      <author><first>Hardik</first><last>Shah</last><affiliation>Meta Inc</affiliation></author>
      <author><first>Seungwhan</first><last>Moon</last><affiliation>Meta Reality Labs</affiliation></author>
      <pages>47-68</pages>
      <abstract>Searching troves of videos with textual descriptions is a core multimodal retrieval task. Owing to the lack of a purpose-built dataset for text-to-video retrieval, video captioning datasets have been re-purposed to evaluate models by (1) treating captions as positive matches to their respective videos and (2) assuming all other videos to be negatives. However, this methodology leads to a fundamental flaw during evaluation: since captions are marked as relevant only to their original video, many alternate videos also match the caption, which introduces false-negative caption-video pairs. We show that when these false negatives are corrected, a recent state-of-the-art model gains 25% recall points—a difference that threatens the validity of the benchmark itself. To diagnose and mitigate this issue, we annotate and release 683K additional caption-video pairs. Using these, we recompute effectiveness scores for three models on two standard benchmarks (MSR-VTT and MSVD). We find that (1) the recomputed metrics are up to 25% recall points higher for the best models, (2) these benchmarks are nearing saturation for Recall@10, (3) caption length (generality) is related to the number of positives, and (4) annotation costs can be mitigated through sampling. We recommend retiring these benchmarks in their current form, and we make recommendations for future text-to-video retrieval benchmarks.</abstract>
      <url hash="2ef1b775">2023.findings-eacl.3</url>
      <attachment type="dataset" hash="a5dfb508">2023.findings-eacl.3.dataset.zip</attachment>
      <bibkey>rodriguez-etal-2023-fighting</bibkey>
      <video href="2023.findings-eacl.3.mp4"/>
      <doi>10.18653/v1/2023.findings-eacl.3</doi>
    </paper>
    <paper id="4">
      <title>Improving Numeracy by Input Reframing and Quantitative Pre-Finetuning Task</title>
      <author><first>Chung-Chi</first><last>Chen</last><affiliation>National Institute of Advanced Industrial Science and Technology</affiliation></author>
      <author><first>Hiroya</first><last>Takamura</last><affiliation>The National Institute of Advanced Industrial Science and Technology (AIST)</affiliation></author>
      <author><first>Ichiro</first><last>Kobayashi</last><affiliation>Ochanomizu University</affiliation></author>
      <author><first>Yusuke</first><last>Miyao</last><affiliation>University of Tokyo</affiliation></author>
      <pages>69-77</pages>
      <abstract>Numbers have unique characteristics to words. Teaching models to understand numbers in text is an open-ended research question. Instead of discussing the required calculation skills, this paper focuses on a more fundamental topic: understanding numerals. We point out that innumeracy—the inability to handle basic numeral concepts—exists in most pretrained language models (LMs), and we propose a method to solve this issue by exploring the notation of numbers. Further, we discuss whether changing notation and pre-finetuning along with the comparing-number task can improve performance in three benchmark datasets containing quantitative-related tasks. The results of this study indicate that input reframing and the proposed pre-finetuning task is useful for RoBERTa.</abstract>
      <url hash="501dbfe7">2023.findings-eacl.4</url>
      <bibkey>chen-etal-2023-improving</bibkey>
      <video href="2023.findings-eacl.4.mp4"/>
      <doi>10.18653/v1/2023.findings-eacl.4</doi>
    </paper>
    <paper id="5">
      <title>Visualize Before You Write: Imagination-Guided Open-Ended Text Generation</title>
      <author><first>Wanrong</first><last>Zhu</last><affiliation>University of California, Santa Barbara</affiliation></author>
      <author><first>An</first><last>Yan</last><affiliation>University of California San Diego</affiliation></author>
      <author><first>Yujie</first><last>Lu</last><affiliation>University of California, Santa Barbara</affiliation></author>
      <author><first>Wenda</first><last>Xu</last><affiliation>University of California at Santa Barbara</affiliation></author>
      <author><first>Xin</first><last>Wang</last><affiliation>University of California, Santa Cruz</affiliation></author>
      <author><first>Miguel</first><last>Eckstein</last><affiliation>UC Santa Barbara</affiliation></author>
      <author><first>William Yang</first><last>Wang</last><affiliation>Unversity of California, Santa Barbara</affiliation></author>
      <pages>78-92</pages>
      <abstract>Recent advances in text-to-image synthesis make it possible to visualize machine imaginations for a given context. On the other hand, when generating text, human writers are gifted at creative visualization, which enhances their writings by forming imaginations as blueprints before putting down the stories in words. Inspired by such a cognitive process, we ask the natural question of whether we can endow machines with the same ability to utilize visual information and construct a general picture of the context to guide text generation. In this work, we propose iNLG that uses machine-generated images to guide language models (LM) in open-ended text generation. The experiments and analyses demonstrate the effectiveness of iNLG on open-ended text generation tasks, including text completion, story generation, and concept-to-text generation in both few-shot and full-data scenarios. Both automatic metrics and human evaluations verify that the text snippets generated by our iNLG are coherent and informative while displaying minor degeneration.</abstract>
      <url hash="6a3ced3c">2023.findings-eacl.5</url>
      <bibkey>zhu-etal-2023-visualize</bibkey>
      <video href="2023.findings-eacl.5.mp4"/>
      <doi>10.18653/v1/2023.findings-eacl.5</doi>
    </paper>
    <paper id="6">
      <title><fixed-case>I</fixed-case>magin<fixed-case>E</fixed-case>: An Imagination-Based Automatic Evaluation Metric for Natural Language Generation</title>
      <author><first>Wanrong</first><last>Zhu</last><affiliation>University of California, Santa Barbara</affiliation></author>
      <author><first>Xin</first><last>Wang</last><affiliation>University of California, Santa Cruz</affiliation></author>
      <author><first>An</first><last>Yan</last><affiliation>University of California San Diego</affiliation></author>
      <author><first>Miguel</first><last>Eckstein</last><affiliation>UC Santa Barbara</affiliation></author>
      <author><first>William Yang</first><last>Wang</last><affiliation>Unversity of California, Santa Barbara</affiliation></author>
      <pages>93-105</pages>
      <abstract>Automatic evaluations for natural language generation (NLG) conventionally rely on token-level or embedding-level comparisons with text references. This differs from human language processing, for which visual imagination often improves comprehension. In this work, we propose ImaginE, an imagination-based automatic evaluation metric for natural language generation. With the help of StableDiffusion, a state-of-the-art text-to-image generator, we automatically generate an image as the embodied imagination for the text snippet and compute the imagination similarity using contextual embeddings. Experiments spanning several text generation tasks demonstrate that adding machine-generated images with our ImaginE displays great potential in introducing multi-modal information into NLG evaluation, and improves existing automatic metrics’ correlations with human similarity judgments in both reference-based and reference-free evaluation scenarios.</abstract>
      <url hash="5d7a6296">2023.findings-eacl.6</url>
      <bibkey>zhu-etal-2023-imagine</bibkey>
      <video href="2023.findings-eacl.6.mp4"/>
      <doi>10.18653/v1/2023.findings-eacl.6</doi>
    </paper>
    <paper id="7">
      <title>Entity-Aware Dual Co-Attention Network for Fake News Detection</title>
      <author><first>Sin-han</first><last>Yang</last><affiliation>National Taiwan University</affiliation></author>
      <author><first>Chung-chi</first><last>Chen</last><affiliation>National Institute of Advanced Industrial Science and Technology</affiliation></author>
      <author><first>Hen-Hsen</first><last>Huang</last><affiliation>Institute of Information Science, Academia Sinica</affiliation></author>
      <author><first>Hsin-Hsi</first><last>Chen</last><affiliation>National Taiwan University</affiliation></author>
      <pages>106-113</pages>
      <abstract>Fake news and misinformation spread rapidly on the Internet. How to identify it and how to interpret the identification results have become important issues. In this paper, we propose a Dual Co-Attention Network (Dual-CAN) for fake news detection, which takes news content, social media replies, and external knowledge into consideration. Our experimental results support that the proposed Dual-CAN outperforms current representative models in two benchmark datasets. We further make in-depth discussions by comparing how models work in both datasets with empirical analysis of attention weights.</abstract>
      <url hash="c5399170">2023.findings-eacl.7</url>
      <bibkey>yang-etal-2023-entity</bibkey>
      <video href="2023.findings-eacl.7.mp4"/>
      <doi>10.18653/v1/2023.findings-eacl.7</doi>
    </paper>
    <paper id="8">
      <title><fixed-case>CIKQA</fixed-case>: Learning Commonsense Inference with a Unified Knowledge-in-the-loop <fixed-case>QA</fixed-case> Paradigm</title>
      <author><first>Hongming</first><last>Zhang</last><affiliation>Tencent AI Lab, Bellevue</affiliation></author>
      <author><first>Yintong</first><last>Huo</last><affiliation>Chinese University of Hong Kong</affiliation></author>
      <author><first>Yanai</first><last>Elazar</last><affiliation>Ai2, Uw</affiliation></author>
      <author><first>Yangqiu</first><last>Song</last><affiliation>Hkust</affiliation></author>
      <author><first>Yoav</first><last>Goldberg</last><affiliation>Bar Ilan University</affiliation></author>
      <author><first>Dan</first><last>Roth</last><affiliation>University of Pennsylvania</affiliation></author>
      <pages>114-124</pages>
      <abstract>We propose a new commonsense reasoning benchmark to motivate commonsense reasoning progress from two perspectives: (1) Evaluating whether models can distinguish knowledge quality by predicting if the knowledge is enough to answer the question; (2) Evaluating whether models can develop commonsense inference capabilities that generalize across tasks. We first extract supporting knowledge for each question and ask humans to annotate whether the auto-extracted knowledge is enough to answer the question or not. After that, we convert different tasks into a unified question-answering format to evaluate the models’ generalization capabilities. We name the benchmark Commonsense Inference with Knowledge-in-the-loop Question Answering (\name). Experiments show that with our learning paradigm, models demonstrate encouraging generalization capabilities. At the same time, we also notice that distinguishing knowledge quality remains challenging for current commonsense reasoning models.</abstract>
      <url hash="13d53fc8">2023.findings-eacl.8</url>
      <bibkey>zhang-etal-2023-cikqa</bibkey>
      <video href="2023.findings-eacl.8.mp4"/>
      <doi>10.18653/v1/2023.findings-eacl.8</doi>
    </paper>
    <paper id="9">
      <title>Data-Efficient Methods For Improving Hate Speech Detection</title>
      <author><first>Sumegh</first><last>Roychowdhury</last><affiliation>Indian Institute of Technology , Kharagpur</affiliation></author>
      <author><first>Vikram</first><last>Gupta</last><affiliation>ShareChat, Bangalore</affiliation></author>
      <pages>125-132</pages>
      <url hash="7158b4fa">2023.findings-eacl.9</url>
      <attachment type="dataset" hash="334bf119">2023.findings-eacl.9.dataset.zip</attachment>
      <bibkey>roychowdhury-gupta-2023-data</bibkey>
      <abstract>Scarcity of large-scale datasets, especially for resource-impoverished languages motivates exploration of data-efficient methods for hate speech detection. Hateful intents are expressed explicitly (use of cuss, swear, abusive words) and implicitly (indirect and contextual). In this work, we progress implicit and explicit hate speech detection using an input-level data augmentation technique, task reformulation using entailment and cross-learning across five languages. Our proposed data augmentation technique EasyMix, improves the performance across all english datasets by ~1% and across multilingual datasets by ~1-9%. We also observe substantial gains of ~2-8% by reformulating hate speech detection as entail problem. We further probe the contextual models and observe that higher layers encode implicit hate while lower layers focus on explicit hate, highlighting the importance of token-level understanding for explicit and context-level for implicit hate speech detection. Code and Dataset splits - <url>https://anonymous.4open.science/r/data_efficient_hatedetect/</url></abstract>
      <video href="2023.findings-eacl.9.mp4"/>
      <doi>10.18653/v1/2023.findings-eacl.9</doi>
    </paper>
    <paper id="10">
      <title>Learning the Effects of Physical Actions in a Multi-modal Environment</title>
      <author><first>Gautier</first><last>Dagan</last><affiliation>University of Edinburgh</affiliation></author>
      <author><first>Frank</first><last>Keller</last><affiliation>University of Edinburgh</affiliation></author>
      <author><first>Alex</first><last>Lascarides</last><affiliation>University of Edinburgh</affiliation></author>
      <pages>133-148</pages>
      <abstract>Large Language Models (LLMs) handle physical commonsense information inadequately. As a result of being trained in a disembodied setting, LLMs often fail to predict an action’s outcome in a given environment. However, predicting the effects of an action before it is executed is crucial in planning, where coherent sequences of actions are often needed to achieve a goal. Therefore, we introduce the multi-modal task of predicting the outcomes of actions solely from realistic sensory inputs (images and text). Next, we extend an LLM to model latent representations of objects to better predict action outcomes in an environment. We show that multi-modal models can capture physical commonsense when augmented with visual information. Finally, we evaluate our model’s performance on novel actions and objects and find that combining modalities help models to generalize and learn physical commonsense reasoning better.</abstract>
      <url hash="d5bfc213">2023.findings-eacl.10</url>
      <bibkey>dagan-etal-2023-learning</bibkey>
      <video href="2023.findings-eacl.10.mp4"/>
      <doi>10.18653/v1/2023.findings-eacl.10</doi>
    </paper>
    <paper id="11">
      <title><fixed-case>FVQA</fixed-case> 2.0: Introducing Adversarial Samples into Fact-based Visual Question Answering</title>
      <author><first>Weizhe</first><last>Lin</last><affiliation>University of Cambridge</affiliation></author>
      <author><first>Zhilin</first><last>Wang</last><affiliation>Nvidia</affiliation></author>
      <author id="bill-byrne"><first>Bill</first><last>Byrne</last><affiliation>University of Cambridge</affiliation></author>
      <pages>149-157</pages>
      <abstract>The widely used Fact-based Visual Question Answering (FVQA) dataset contains visually-grounded questions that require information retrieval using common sense knowledge graphs to answer. It has been observed that the original dataset is highly imbalanced and concentrated on a small portion of its associated knowledge graph. We introduce FVQA 2.0 which contains adversarial variants of test questions to address this imbalance. We show that systems trained with the original FVQA train sets can be vulnerable to adversarial samples and we demonstrate an augmentation scheme to reduce this vulnerability without human annotations.</abstract>
      <url hash="23285f32">2023.findings-eacl.11</url>
      <bibkey>lin-etal-2023-fvqa</bibkey>
      <video href="2023.findings-eacl.11.mp4"/>
      <doi>10.18653/v1/2023.findings-eacl.11</doi>
    </paper>
    <paper id="12">
      <title>Revisiting Intermediate Layer Distillation for Compressing Language Models: An Overfitting Perspective</title>
      <author><first>Jongwoo</first><last>Ko</last><affiliation>Kaist</affiliation></author>
      <author><first>Seungjoon</first><last>Park</last><affiliation>Kaist</affiliation></author>
      <author><first>Minchan</first><last>Jeong</last><affiliation>Kaist</affiliation></author>
      <author><first>Sukjin</first><last>Hong</last><affiliation>Kt</affiliation></author>
      <author><first>Euijai</first><last>Ahn</last><affiliation>Kt</affiliation></author>
      <author><first>Du-Seong</first><last>Chang</last><affiliation>Kt</affiliation></author>
      <author><first>Se-Young</first><last>Yun</last><affiliation>Kaist</affiliation></author>
      <pages>158-175</pages>
      <abstract>Knowledge distillation (KD) is a highly promising method for mitigating the computational problems of pre-trained language models (PLMs). Among various KD approaches, Intermediate Layer Distillation (ILD) has been a de facto standard KD method with its performance efficacy in the NLP field. In this paper, we find that existing ILD methods are prone to overfitting to training datasets, although these methods transfer more information than the original KD. Next, we present the simple observations to mitigate the overfitting of ILD: distilling only the last Transformer layer and conducting ILD on supplementary tasks. Based on our two findings, we propose a simple yet effective consistency-regularized ILD (CR-ILD), which prevents the student model from overfitting the training dataset. Substantial experiments on distilling BERT on the GLUE benchmark and several synthetic datasets demonstrate that our proposed ILD method outperforms other KD techniques. Our code is available at <url>https://github.com/jongwooko/CR-ILD</url>.</abstract>
      <url hash="95695ae8">2023.findings-eacl.12</url>
      <bibkey>ko-etal-2023-revisiting</bibkey>
      <video href="2023.findings-eacl.12.mp4"/>
      <doi>10.18653/v1/2023.findings-eacl.12</doi>
    </paper>
    <paper id="13">
      <title>Implicit Temporal Reasoning for Evidence-Based Fact-Checking</title>
      <author><first>Liesbeth</first><last>Allein</last><affiliation>KU Leuven</affiliation></author>
      <author><first>Marlon</first><last>Saelens</last><affiliation>KU Leuven</affiliation></author>
      <author><first>Ruben</first><last>Cartuyvels</last><affiliation>Catholic University of Leuven</affiliation></author>
      <author><first>Marie-Francine</first><last>Moens</last><affiliation>KU Leuven</affiliation></author>
      <pages>176-189</pages>
      <abstract>Leveraging contextual knowledge has become standard practice in automated claim verification, yet the impact of temporal reasoning has been largely overlooked. Our study demonstrates that time positively influences the claim verification process of evidence-based fact-checking. The temporal aspects and relations between claims and evidence are first established through grounding on shared timelines, which are constructed using publication dates and time expressions extracted from their text. Temporal information is then provided to RNN-based and Transformer-based classifiers before or after claim and evidence encoding. Our time-aware fact-checking models surpass base models by up to 9% Micro F1 (64.17%) and 15% Macro F1 (47.43%) on the MultiFC dataset. They also outperform prior methods that explicitly model temporal relations between evidence. Our findings show that the presence of temporal information and the manner in which timelines are constructed greatly influence how fact-checking models determine the relevance and supporting or refuting character of evidence documents.</abstract>
      <url hash="58d18fd4">2023.findings-eacl.13</url>
      <bibkey>allein-etal-2023-implicit</bibkey>
      <video href="2023.findings-eacl.13.mp4"/>
      <doi>10.18653/v1/2023.findings-eacl.13</doi>
    </paper>
    <paper id="14">
      <title>Active <fixed-case>PET</fixed-case>s: Active Data Annotation Prioritisation for Few-Shot Claim Verification with Pattern Exploiting Training</title>
      <author><first>Xia</first><last>Zeng</last><affiliation>Queen Mary University of London</affiliation></author>
      <author><first>Arkaitz</first><last>Zubiaga</last><affiliation>Queen Mary University of London</affiliation></author>
      <pages>190-204</pages>
      <abstract>To mitigate the impact of the scarcity of labelled data on fact-checking systems, we focus on few-shot claim verification. Despite recent work on few-shot classification by proposing advanced language models, there is a dearth of research in data annotation prioritisation that improves the selection of the few shots to be labelled for optimal model performance. We propose Active PETs, a novel weighted approach that utilises an ensemble of Pattern Exploiting Training (PET) models based on various language models, to actively select unlabelled data as candidates for annotation. Using Active PETs for few-shot data selection shows consistent improvement over the baseline methods, on two technical fact-checking datasets and using six different pretrained language models. We show further improvement with Active PETs-o, which further integrates an oversampling strategy. Our approach enables effective selection of instances to be labelled where unlabelled data is abundant but resources for labelling are limited, leading to consistently improved few-shot claim verification performance. Our code is available.</abstract>
      <url hash="27abb948">2023.findings-eacl.14</url>
      <bibkey>zeng-zubiaga-2023-active</bibkey>
      <video href="2023.findings-eacl.14.mp4"/>
      <doi>10.18653/v1/2023.findings-eacl.14</doi>
    </paper>
    <paper id="15">
      <title>Plan-then-Seam: Towards Efficient Table-to-Text Generation</title>
      <author><first>Liang</first><last>Li</last><affiliation>Institute of Information Engineering,Chinese Academy of Sciences</affiliation></author>
      <author><first>Ruiying</first><last>Geng</last><affiliation>Alibaba Group</affiliation></author>
      <author><first>Chengyang</first><last>Fang</last><affiliation>Institute of Information Engineering, Chinese Academy of Sciences; School of Cyber Security, University of Chinese Academy of Sciences</affiliation></author>
      <author><first>Bing</first><last>Li</last><affiliation>Institute of Information Engineering,Chinese Academy of Sciences</affiliation></author>
      <author><first>Can</first><last>Ma</last><affiliation>Institute of Information Engineering, CAS</affiliation></author>
      <author><first>Binhua</first><last>Li</last><affiliation>Alibaba Group</affiliation></author>
      <author><first>Yongbin</first><last>Li</last><affiliation>Alibaba Group</affiliation></author>
      <pages>205-219</pages>
      <abstract>Table-to-text generation aims at automatically generating text to help people conveniently obtain salient information in tables. Recent works explicitly decompose the generation process into content planning and surface generation stages, employing two autoregressive networks for them respectively. However, they are computationally expensive due to the non-parallelizable nature of autoregressive decoding and the redundant parameters of two networks. In this paper, we propose the first totally non-autoregressive table-to-text model (Plan-then-Seam, PTS) that produces its outputs in parallel with one single network.PTS firstly writes and calibrates one plan of the content to be generated with a novel rethinking pointer predictor, and then takes the plan as the context for seaming to decode the description. These two steps share parameters and perform iteratively to capture token inter-dependency while keeping parallel decoding. Experiments on two public benchmarks show that PTS achieves 3.0 5.6 times speedup for inference time, reducing 50% parameters, while maintaining as least comparable performance against strong two-stage table-to-text competitors.</abstract>
      <url hash="95e8369c">2023.findings-eacl.15</url>
      <bibkey>li-etal-2023-plan</bibkey>
      <video href="2023.findings-eacl.15.mp4"/>
      <doi>10.18653/v1/2023.findings-eacl.15</doi>
    </paper>
    <paper id="16">
      <title>A corpus of metaphors as register markers</title>
      <author><first>Markus</first><last>Egg</last><affiliation>Humboldt-Universität zu Berlin</affiliation></author>
      <author><first>Valia</first><last>Kordoni</last><affiliation>Humboldt-Universität zu Berlin</affiliation></author>
      <pages>220-226</pages>
      <abstract>The paper presents our work on corpus annotationfor metaphor in German. Metaphors denoteentities that are similar to their literal referent,e.g., when *Licht* ‘light’ is used in the senseof ‘hope’. We are interested in the relation betweenmetaphor and register, hence, the corpusincludes material from different registers. We focussed on metaphors that can serve asregister markers and can also be reliably indentifiedfor annotation. Our results show hugedifferences between registers in metaphor usage,which we interpret in terms of specificproperties of the registers.</abstract>
      <url hash="c2f7b73f">2023.findings-eacl.16</url>
      <bibkey>egg-kordoni-2023-corpus</bibkey>
      <video href="2023.findings-eacl.16.mp4"/>
      <doi>10.18653/v1/2023.findings-eacl.16</doi>
    </paper>
    <paper id="17">
      <title>Translate First Reorder Later: Leveraging Monotonicity in Semantic Parsing</title>
      <author><first>Francesco</first><last>Cazzaro</last><affiliation>Universitat Politecnica de Catalunya</affiliation></author>
      <author><first>Davide</first><last>Locatelli</last><affiliation>Technical University of Catalonia</affiliation></author>
      <author><first>Ariadna</first><last>Quattoni</last><affiliation>Upc, Dmetrics</affiliation></author>
      <author><first>Xavier</first><last>Carreras</last><affiliation>dMetrics</affiliation></author>
      <pages>227-238</pages>
      <abstract>Prior work in semantic parsing has shown that conventional seq2seq models fail at compositional generalization tasks. This limitation led to a resurgence of methods that model alignments between sentences and their corresponding meaning representations, either implicitly through latent variables or explicitly by taking advantage of alignment annotations. We take the second direction and propose TPol, a two-step approach that first translates input sentences monotonically and then reorders them to obtain the correct output. This is achieved with a modular framework comprising a Translator and a Reorderer component. We test our approach on two popular semantic parsing datasets. Our experiments show that by means of the monotonic translations, TPol can learn reliable lexico-logical patterns from aligned data, significantly improving compositional generalization both over conventional seq2seq models, as well as over other approaches that exploit gold alignments.</abstract>
      <url hash="0fbb59ff">2023.findings-eacl.17</url>
      <bibkey>cazzaro-etal-2023-translate</bibkey>
      <video href="2023.findings-eacl.17.mp4"/>
      <doi>10.18653/v1/2023.findings-eacl.17</doi>
    </paper>
    <paper id="18">
      <title><fixed-case>P</fixed-case>e<fixed-case>P</fixed-case>e: Personalized Post-editing Model utilizing User-generated Post-edits</title>
      <author><first>Jihyeon</first><last>Lee</last><affiliation>Kakaobrain</affiliation></author>
      <author><first>Taehee</first><last>Kim</last><affiliation>Korea Advanced Institute of Science and Technology</affiliation></author>
      <author><first>Yunwon</first><last>Tae</last><affiliation>Vuno</affiliation></author>
      <author><first>Cheonbok</first><last>Park</last><affiliation>NAVER Corp,</affiliation></author>
      <author><first>Jaegul</first><last>Choo</last><affiliation>Kaist</affiliation></author>
      <pages>239-253</pages>
      <abstract>Incorporating personal preference is crucial in advanced machine translation tasks. Despite the recent advancement of machine translation, it remains a demanding task to properly reflect personal style. In this paper, we introduce a personalized automatic post-editing framework to address this challenge, which effectively generates sentences considering distinct personal behaviors. To build this framework, we first collect post-editing data that connotes the user preference from a live machine translation system. Specifically, real-world users enter source sentences for translation and edit the machine-translated outputs according to the user’s preferred style. We then propose a model that combines a discriminator module and user-specific parameters on the APE framework. Experimental results show that the proposed method outperforms other baseline models on four different metrics (i.e., BLEU, TER, YiSi-1, and human evaluation).</abstract>
      <url hash="da05e58d">2023.findings-eacl.18</url>
      <bibkey>lee-etal-2023-pepe</bibkey>
      <video href="2023.findings-eacl.18.mp4"/>
      <doi>10.18653/v1/2023.findings-eacl.18</doi>
    </paper>
    <paper id="19">
      <title>Infusing Context and Knowledge Awareness in Multi-turn Dialog Understanding</title>
      <author><first>Ting-Wei</first><last>Wu</last><affiliation>Georgia Institute of Technology</affiliation></author>
      <author><first>Biing-Hwang</first><last>Juang</last><affiliation>Georgia Institute of Technology</affiliation></author>
      <pages>254-264</pages>
      <abstract>In multi-turn dialog understanding, semantic frames are constructed by detecting intents and slots within each user utterance. However, recent works lack the capability of modeling multi-turn dynamics within a dialog in natural language understanding (NLU), instead leaving them for updating dialog states only. Moreover, humans usually associate relevant background knowledge with the current dialog contexts to better illustrate slot semantics revealed from word connotations, where previous works have explored such possibility mostly in knowledge-grounded response generation. In this paper, we propose to amend the research gap by equipping a BERT-based NLU framework with knowledge and context awareness. We first encode dialog contexts with a unidirectional context-aware transformer encoder and select relevant inter-word knowledge with the current word and previous history based on a knowledge attention mechanism. Experimental results in two complicated multi-turn dialog datasets have demonstrated significant improvements of our proposed framework. Attention visualization also demonstrates how our modules leverage knowledge across the utterance.</abstract>
      <url hash="72f8749b">2023.findings-eacl.19</url>
      <attachment type="software" hash="f4485d93">2023.findings-eacl.19.software.zip</attachment>
      <bibkey>wu-juang-2023-infusing</bibkey>
      <video href="2023.findings-eacl.19.mp4"/>
      <doi>10.18653/v1/2023.findings-eacl.19</doi>
    </paper>
    <paper id="20">
      <title><fixed-case>MC</fixed-case>o<fixed-case>N</fixed-case>a<fixed-case>L</fixed-case>a: A Benchmark for Code Generation from Multiple Natural Languages</title>
      <author><first>Zhiruo</first><last>Wang</last><affiliation>Carnegie Mellon University</affiliation></author>
      <author><first>Grace</first><last>Cuenca</last><affiliation>Princeton University</affiliation></author>
      <author><first>Shuyan</first><last>Zhou</last><affiliation>Carnegie Mellon University</affiliation></author>
      <author><first>Frank F.</first><last>Xu</last><affiliation>Carnegie Mellon University</affiliation></author>
      <author><first>Graham</first><last>Neubig</last><affiliation>Carnegie Mellon University</affiliation></author>
      <pages>265-273</pages>
      <abstract>While there has been a recent burgeoning of applications at the intersection of natural and programming languages, such as code generation and code summarization, these applications are usually English-centric. This creates a barrier for program developers who are not proficient in English. To mitigate this gap in technology development across languages, we propose a multilingual dataset, MCoNaLa, to benchmark code generation from natural language commands extending beyond English. Modeled off of the methodology from the English Code/Natural Language Challenge (CoNaLa) dataset, we annotated a total of 896 NL-Code pairs in three languages: Spanish, Japanese, and Russian. We present a systematic evaluation on MCoNaLa by testing state-of-the-art code generation systems. Although the difficulties vary across three languages, all systems lag significantly behind their English counterparts, revealing the challenges in adapting code generation to new languages.</abstract>
      <url hash="27226a1f">2023.findings-eacl.20</url>
      <bibkey>wang-etal-2023-mconala</bibkey>
      <video href="2023.findings-eacl.20.mp4"/>
      <doi>10.18653/v1/2023.findings-eacl.20</doi>
    </paper>
    <paper id="21">
      <title>Augmenting pre-trained language models with audio feature embedding for argumentation mining in political debates</title>
      <author><first>Rafael</first><last>Mestre</last><affiliation>University of Southampton</affiliation></author>
      <author><first>Stuart E.</first><last>Middleton</last><affiliation>University of Southampton</affiliation></author>
      <author><first>Matt</first><last>Ryan</last><affiliation>University of Southampton</affiliation></author>
      <author><first>Masood</first><last>Gheasi</last><affiliation>University of Southampton</affiliation></author>
      <author><first>Timothy</first><last>Norman</last><affiliation>University of Southampton</affiliation></author>
      <author><first>Jiatong</first><last>Zhu</last><affiliation>University of Southampton</affiliation></author>
      <pages>274-288</pages>
      <abstract>The integration of multimodality in natural language processing (NLP) tasks seeks to exploit the complementary information contained in two or more modalities, such as text, audio and video. This paper investigates the integration of often under-researched audio features with text, using the task of argumentation mining (AM) as a case study. We take a previously reported dataset and present an audio-enhanced version (the Multimodal USElecDeb60To16 dataset). We report the performance of two text models based on BERT and GloVe embeddings, one audio model (based on CNN and Bi-LSTM) and multimodal combinations, on a dataset of 28,850 utterances. The results show that multimodal models do not outperform text-based models when using the full dataset. However, we show that audio features add value in fully supervised scenarios with limited data. We find that when data is scarce (e.g. with 10% of the original dataset) multimodal models yield improved performance, whereas text models based on BERT considerably decrease performance. Finally, we conduct a study with artificially generated voices and an ablation study to investigate the importance of different audio features in the audio models.</abstract>
      <url hash="ef828bd0">2023.findings-eacl.21</url>
      <bibkey>mestre-etal-2023-augmenting</bibkey>
      <video href="2023.findings-eacl.21.mp4"/>
      <doi>10.18653/v1/2023.findings-eacl.21</doi>
    </paper>
    <paper id="22">
      <title>Improving Retrieval Augmented Neural Machine Translation by Controlling Source and Fuzzy-Match Interactions</title>
      <author><first>Cuong</first><last>Hoang</last><affiliation>KaiLua Labs</affiliation></author>
      <author><first>Devendra</first><last>Sachan</last><affiliation>McGill University, MILA - Quebec AI Institute</affiliation></author>
      <author><first>Prashant</first><last>Mathur</last><affiliation>Amazon</affiliation></author>
      <author><first>Brian</first><last>Thompson</last><affiliation>Amazon</affiliation></author>
      <author><first>Marcello</first><last>Federico</last><affiliation>AWS AI Labs</affiliation></author>
      <pages>289-295</pages>
      <abstract>We explore zero-shot adaptation, where a general-domain model has access to customer or domain specific parallel data at inference time, but not during training. We build on the idea of Retrieval Augmented Translation (RAT) where top-k in-domain fuzzy matches are found for the source sentence, and target-language translations of those fuzzy-matched sentences are provided to the translation model at inference time. We propose a novel architecture to control interactions between a source sentence and the top-k fuzzy target-language matches, and compare it to architectures from prior work. We conduct experiments in two language pairs (En-De and En-Fr) by training models on WMT data and testing them with five and seven multi-domain datasets, respectively. Our approach consistently outperforms the alternative architectures, improving BLEU across language pair, domain, and number k of fuzzy matches.</abstract>
      <url hash="ed68f132">2023.findings-eacl.22</url>
      <bibkey>hoang-etal-2023-improving</bibkey>
      <video href="2023.findings-eacl.22.mp4"/>
      <doi>10.18653/v1/2023.findings-eacl.22</doi>
    </paper>
    <paper id="23">
      <title><fixed-case>CALM</fixed-case>-Bench: A Multi-task Benchmark for Evaluating Causality-Aware Language Models</title>
      <author><first>Dhairya</first><last>Dalal</last><affiliation>University of Galway</affiliation></author>
      <author><first>Paul</first><last>Buitelaar</last><affiliation>University of Galway</affiliation></author>
      <author><first>Mihael</first><last>Arcan</last><affiliation>University of Galway</affiliation></author>
      <pages>296-311</pages>
      <abstract>Causal reasoning is a critical component of human cognition and is required across a range of question-answering (QA) tasks (such as abductive reasoning, commonsense QA, and procedural reasoning). Research on causal QA has been underdefined, task-specific, and limited in complexity. Recent advances in foundation language models (such as BERT, ERNIE, and T5) have shown the efficacy of pre-trained models across diverse QA tasks. However, there is limited research exploring the causal reasoning capabilities of those language models and no standard evaluation benchmark. To unify causal QA research, we propose CALM-Bench, a multi-task benchmark for evaluating causality-aware language models (CALM). We present a standardized definition of causal QA tasks and show empirically that causal reasoning can be generalized and transferred across different QA tasks. Additionally, we share a strong multi-task baseline model which outperforms single-task fine-tuned models on the CALM-Bench tasks.</abstract>
      <url hash="061c48e8">2023.findings-eacl.23</url>
      <bibkey>dalal-etal-2023-calm</bibkey>
      <video href="2023.findings-eacl.23.mp4"/>
      <doi>10.18653/v1/2023.findings-eacl.23</doi>
    </paper>
    <paper id="24">
      <title>ez<fixed-case>C</fixed-case>oref: Towards Unifying Annotation Guidelines for Coreference Resolution</title>
      <author><first>Ankita</first><last>Gupta</last><affiliation>University of Massachusetts Amherst</affiliation></author>
      <author><first>Marzena</first><last>Karpinska</last><affiliation>University of Massachusetts Amherst</affiliation></author>
      <author><first>Wenlong</first><last>Zhao</last><affiliation>University of Massachusetts Amherst</affiliation></author>
      <author><first>Kalpesh</first><last>Krishna</last><affiliation>University of Massachusetts Amherst</affiliation></author>
      <author><first>Jack</first><last>Merullo</last><affiliation>Brown University</affiliation></author>
      <author><first>Luke</first><last>Yeh</last><affiliation>University of Massachusetts, Amherst</affiliation></author>
      <author><first>Mohit</first><last>Iyyer</last><affiliation>University of Massachusetts Amherst</affiliation></author>
      <author><first>Brendan</first><last>O’Connor</last><affiliation>University of Massachusetts Amherst</affiliation></author>
      <pages>312-330</pages>
      <abstract>Large-scale, high-quality corpora are critical for advancing research in coreference resolution. However, existing datasets vary in their definition of coreferences and have been collected via complex and lengthy guidelines that are curated for linguistic experts. These concerns have sparked a growing interest among researchers to curate a unified set of guidelines suitable for annotators with various backgrounds. In this work, we develop a crowdsourcing-friendly coreference annotation methodology, ezCoref, consisting of an annotation tool and an interactive tutorial. We use ezCoref to re-annotate 240 passages from seven existing English coreference datasets (spanning fiction, news, and multiple other domains) while teaching annotators only cases that are treated similarly across these datasets. Surprisingly, we find that reasonable quality annotations were already achievable (90% agreement between the crowd and expert annotations) even without extensive training. On carefully analyzing the remaining disagreements, we identify the presence of linguistic cases that our annotators unanimously agree upon but lack unified treatments (e.g., generic pronouns, appositives) in existing datasets. We propose the research community should revisit these phenomena when curating future unified annotation guidelines.</abstract>
      <url hash="7e5348af">2023.findings-eacl.24</url>
      <bibkey>gupta-etal-2023-ezcoref</bibkey>
      <video href="2023.findings-eacl.24.mp4"/>
      <doi>10.18653/v1/2023.findings-eacl.24</doi>
    </paper>
    <paper id="25">
      <title><fixed-case>PREME</fixed-case>: Preference-based Meeting Exploration through an Interactive Questionnaire</title>
      <author><first>Negar</first><last>Arabzadeh</last><affiliation>University of Waterloo</affiliation></author>
      <author><first>Ali</first><last>Ahmadvand</last><affiliation>Emory University</affiliation></author>
      <author><first>Julia</first><last>Kiseleva</last><affiliation>Microsoft Research</affiliation></author>
      <author id="yang-liu-microsoft"><first>Yang</first><last>Liu</last><affiliation>Microsoft Research</affiliation></author>
      <author><first>Ahmed Hassan</first><last>Awadallah</last><affiliation>Microsoft Research</affiliation></author>
      <author><first>Ming</first><last>Zhong</last><affiliation>University of Illinois</affiliation></author>
      <author><first>Milad</first><last>Shokouhi</last><affiliation>Microsoft</affiliation></author>
      <pages>331-342</pages>
      <abstract>The recent increase in the volume of online meetings necessitates automated tools for organizing the material, especially when an attendee has missed the discussion and needs assistance in quickly exploring it. In this work, we propose a novel end-to-end framework for generating interactive questionnaires for preference-based meeting exploration. As a result, users are supplied with a list of suggested questions reflecting their preferences. Since the task is new, we introduce an automatic evaluation strategy by measuring how much the generated questions via questionnaire are answerable to ensure factual correctness and covers the source meeting for the depth of possible exploration.</abstract>
      <url hash="144979c6">2023.findings-eacl.25</url>
      <bibkey>arabzadeh-etal-2023-preme</bibkey>
      <video href="2023.findings-eacl.25.mp4"/>
      <doi>10.18653/v1/2023.findings-eacl.25</doi>
    </paper>
    <paper id="26">
      <title>Sentence Identification with <fixed-case>BOS</fixed-case> and <fixed-case>EOS</fixed-case> Label Combinations</title>
      <author><first>Takuma</first><last>Udagawa</last><affiliation>IBM Research - Tokyo</affiliation></author>
      <author><first>Hiroshi</first><last>Kanayama</last><affiliation>IBM Research - Tokyo</affiliation></author>
      <author><first>Issei</first><last>Yoshida</last><affiliation>IBM Research - Tokyo</affiliation></author>
      <pages>343-358</pages>
      <abstract>The sentence is a fundamental unit in many NLP applications. Sentence segmentation is widely used as the first preprocessing task, where an input text is split into consecutive sentences considering the end of the sentence (EOS) as their boundaries. This task formulation relies on a strong assumption that the input text consists only of sentences, or what we call the sentential units (SUs). However, real-world texts often contain non-sentential units (NSUs) such as metadata, sentence fragments, nonlinguistic markers, etc. which are unreasonable or undesirable to be treated as a part of an SU. To tackle this issue, we formulate a novel task of sentence identification, where the goal is to identify SUs while excluding NSUs in a given text. To conduct sentence identification, we propose a simple yet effective method which combines the beginning of the sentence (BOS) and EOS labels to determine the most probable SUs and NSUs based on dynamic programming. To evaluate this task, we design an automatic, language-independent procedure to convert the Universal Dependencies corpora into sentence identification benchmarks. Finally, our experiments on the sentence identification task demonstrate that our proposed method generally outperforms sentence segmentation baselines which only utilize EOS labels.</abstract>
      <url hash="f8dfa617">2023.findings-eacl.26</url>
      <bibkey>udagawa-etal-2023-sentence</bibkey>
      <video href="2023.findings-eacl.26.mp4"/>
      <doi>10.18653/v1/2023.findings-eacl.26</doi>
    </paper>
    <paper id="27">
      <title>Gauging the Gap Between Human and Machine Text Simplification Through Analytical Evaluation of Simplification Strategies and Errors</title>
      <author><first>Daichi</first><last>Yamaguchi</last><affiliation>Nagoya University</affiliation></author>
      <author><first>Rei</first><last>Miyata</last><affiliation>Nagoya University</affiliation></author>
      <author><first>Sayuka</first><last>Shimada</last><affiliation>Nagoya University</affiliation></author>
      <author><first>Satoshi</first><last>Sato</last><affiliation>Nagoya University</affiliation></author>
      <pages>359-375</pages>
      <abstract>This study presents an analytical evaluation of neural text simplification (TS) systems. Because recent TS models are trained in an end-to-end fashion, it is difficult to grasp their abilities to perform particular simplification operations. For the advancement of TS research and development, we should understand in detail what current TS systems can and cannot perform in comparison with human performance. To that end, we first developed an analytical evaluation framework consisting of fine-grained taxonomies of simplification strategies (at both the surface and content levels) and errors. Using this framework, we annotated TS instances produced by professional human editors and multiple neural TS systems and compared the results. Our analyses concretely and quantitatively revealed a wide gap between humans and systems, specifically indicating that systems tend to perform deletions and local substitutions while excessively omitting important information, and that the systems can hardly perform information addition operations. Based on our analyses, we also provide detailed directions to address these limitations.</abstract>
      <url hash="4e918bac">2023.findings-eacl.27</url>
      <bibkey>yamaguchi-etal-2023-gauging</bibkey>
      <video href="2023.findings-eacl.27.mp4"/>
      <doi>10.18653/v1/2023.findings-eacl.27</doi>
    </paper>
    <paper id="28">
      <title>Bridging the Gap between Pre-Training and Fine-Tuning for Commonsense Generation</title>
      <author><first>Haoran</first><last>Yang</last><affiliation>The Chinese University of Hong Kong</affiliation></author>
      <author><first>Yan</first><last>Wang</last><affiliation>Tencent AI Lab</affiliation></author>
      <author><first>Piji</first><last>Li</last><affiliation>Nanjing University of Aeronautics and Astronautics</affiliation></author>
      <author><first>Wei</first><last>Bi</last><affiliation>Tencent AI Lab</affiliation></author>
      <author><first>Wai</first><last>Lam</last><affiliation>The Chinese University of Hong Kong</affiliation></author>
      <author><first>Chen</first><last>Xu</last><affiliation>Beijing University of Technology</affiliation></author>
      <pages>376-383</pages>
      <abstract>Commonsense generation aims to generate a plausible sentence containing all given unordered concept words. Previous methods focusing on this task usually directly concatenate these words as the input of a pre-trained language model (PLM). However, in PLMs’ pre-training process, the inputs are often corrupted sentences with correct word order. This input distribution discrepancy between pre-training and fine-tuning makes the model difficult to fully utilize the knowledge of PLMs. In this paper, we propose a two-stage framework to alleviate this issue. Firstly, in pre-training stage, we design a new format of input to endow PLMs the ability to deal with masked sentences with incorrect word order. Secondly, during fine-tuning, we insert the special token [MASK] between two consecutive concept words to make the input distribution more similar to the input distribution in pre-training. We conduct extensive experiments and provide thorough analysis to demonstrate the effectiveness of our proposed method.</abstract>
      <url hash="2b0777bb">2023.findings-eacl.28</url>
      <bibkey>yang-etal-2023-bridging</bibkey>
      <video href="2023.findings-eacl.28.mp4"/>
      <doi>10.18653/v1/2023.findings-eacl.28</doi>
    </paper>
    <paper id="29">
      <title><fixed-case>LED</fixed-case>: A Dataset for Life Event Extraction from Dialogs</title>
      <author><first>Yi-Pei</first><last>Chen</last><affiliation>The University of Tokyo</affiliation></author>
      <author><first>An-Zi</first><last>Yen</last><affiliation>National Yang Ming Chiao Tung University</affiliation></author>
      <author><first>Hen-Hsen</first><last>Huang</last><affiliation>Institute of Information Science, Academia Sinica</affiliation></author>
      <author><first>Hideki</first><last>Nakayama</last><affiliation>The University of Tokyo</affiliation></author>
      <author><first>Hsin-Hsi</first><last>Chen</last><affiliation>National Taiwan University</affiliation></author>
      <pages>384-398</pages>
      <abstract>Lifelogging has gained more attention due to its wide applications, such as personalized recommendations or memory assistance. The issues of collecting and extracting personal life events have emerged. People often share their life experiences with others through conversations. However, extracting life events from conversations is rarely explored. In this paper, we present Life Event Dialog, a dataset containing fine-grained life event annotations on conversational data. In addition, we initiate a novel Conversational Life Event Extraction task and differentiate the task from the public event extraction or the life event extraction from other sources like microblogs. We explore three information extraction (IE) frameworks to address the Conversational Life Event Extraction task: OpenIE, relation extraction, and event extraction. A comprehensive empirical analysis of the three baselines is established. The results suggest that the current event extraction model still struggles with extracting life events from human daily conversations. Our proposed Life Event Dialog dataset and in-depth analysis of IE frameworks will facilitate future research on life event extraction from conversations.</abstract>
      <url hash="07471ee1">2023.findings-eacl.29</url>
      <bibkey>chen-etal-2023-led</bibkey>
      <video href="2023.findings-eacl.29.mp4"/>
      <doi>10.18653/v1/2023.findings-eacl.29</doi>
    </paper>
    <paper id="30">
      <title>Reading and Reasoning over Chart Images for Evidence-based Automated Fact-Checking</title>
      <author><first>Mubashara</first><last>Akhtar</last><affiliation>King’s College London</affiliation></author>
      <author><first>Oana</first><last>Cocarascu</last><affiliation>King’s College London</affiliation></author>
      <author><first>Elena</first><last>Simperl</last><affiliation>King’s College London</affiliation></author>
      <pages>399-414</pages>
      <abstract>Evidence data for automated fact-checking (AFC) can be in multiple modalities such as text, tables, images, audio, or video. While there is increasing interest in using images for AFC, previous works mostly focus on detecting manipulated or fake images. We propose a novel task, chart-based fact-checking, and introduce ChartBERT as the first model for AFC against chart evidence. ChartBERT leverages textual, structural and visual information of charts to determine the veracity of textual claims. For evaluation, we create ChartFC, a new dataset of 15,886 charts. We systematically evaluate 75 different vision-language (VL) baselines and show that ChartBERT outperforms VL models, achieving 63.8% accuracy. Our results suggest that the task is complex yet feasible, with many challenges ahead.</abstract>
      <url hash="780dd096">2023.findings-eacl.30</url>
      <bibkey>akhtar-etal-2023-reading</bibkey>
      <video href="2023.findings-eacl.30.mp4"/>
      <doi>10.18653/v1/2023.findings-eacl.30</doi>
    </paper>
    <paper id="31">
      <title>Causal Reasoning of Entities and Events in Procedural Texts</title>
      <author><first>Li</first><last>Zhang</last><affiliation>University of Pennsylvania</affiliation></author>
      <author><first>Hainiu</first><last>Xu</last><affiliation>University of Pennsylvania</affiliation></author>
      <author><first>Yue</first><last>Yang</last><affiliation>University of Pennsylvania</affiliation></author>
      <author><first>Shuyan</first><last>Zhou</last><affiliation>Carnegie Mellon University</affiliation></author>
      <author><first>Weiqiu</first><last>You</last><affiliation>University of Pennsylvania</affiliation></author>
      <author><first>Manni</first><last>Arora</last><affiliation>University of Pennsylvania</affiliation></author>
      <author><first>Chris</first><last>Callison-Burch</last><affiliation>University of Pennsylvania</affiliation></author>
      <pages>415-431</pages>
      <abstract>Entities and events are crucial to natural language reasoning and common in procedural texts. Existing work has focused either exclusively on entity state tracking (e.g., whether a pan is hot) or on event reasoning (e.g., whether one would burn themselves by touching the pan), while these two tasks are often causally related. We propose CREPE, the first benchmark on causal reasoning of event plausibility and entity states. We show that most language models, including GPT-3, perform close to chance at .35 F1, lagging far behind human at .87 F1. We boost model performance to .59 F1 by creatively representing events as programming languages while prompting language models pretrained on code. By injecting the causal relations between entities and events as intermediate reasoning steps in our representation, we further boost the performance to .67 F1. Our findings indicate not only the challenge that CREPE brings for language models, but also the efficacy of code-like prompting combined with chain-of-thought prompting for multihop event reasoning.</abstract>
      <url hash="694d4c8e">2023.findings-eacl.31</url>
      <attachment type="dataset" hash="8546f1bc">2023.findings-eacl.31.dataset.zip</attachment>
      <bibkey>zhang-etal-2023-causal</bibkey>
      <video href="2023.findings-eacl.31.mp4"/>
      <doi>10.18653/v1/2023.findings-eacl.31</doi>
    </paper>
    <paper id="32">
      <title>Few-Shot Structured Policy Learning for Multi-Domain and Multi-Task Dialogues</title>
      <author><first>Thibault</first><last>Cordier</last><affiliation>University of Avignon</affiliation></author>
      <author><first>Tanguy</first><last>Urvoy</last><affiliation>Orange</affiliation></author>
      <author><first>Fabrice</first><last>Lefèvre</last><affiliation>Avignon Univ.</affiliation></author>
      <author><first>Lina M.</first><last>Rojas Barahona</last><affiliation>Orange Innovation Research</affiliation></author>
      <pages>432-441</pages>
      <abstract>Reinforcement learning has been widely adopted to model dialogue managers in task-oriented dialogues. However, the user simulator provided by state-of-the-art dialogue frameworks are only rough approximations of human behaviour. The ability to learn from a small number of human interactions is hence crucial, especially on multi-domain and multi-task environments where the action space is large. We therefore propose to use structured policies to improve sample efficiency when learning on these kinds of environments. We also evaluate the impact of learning from human vs simulated experts. Among the different levels of structure that we tested, the graph neural networks (GNNs) show a remarkable superiority by reaching a success rate above 80% with only 50 dialogues when learning from simulated experts. They also show superiority when learning from human experts, although a performance drop was observed. We therefore suggest to concentrate future research efforts on bridging the gap between human data, simulators and automatic evaluators in dialogue frameworks.</abstract>
      <url hash="24f3c5da">2023.findings-eacl.32</url>
      <bibkey>cordier-etal-2023-shot</bibkey>
      <video href="2023.findings-eacl.32.mp4"/>
      <doi>10.18653/v1/2023.findings-eacl.32</doi>
    </paper>
    <paper id="33">
      <title>Transfer Knowledge from Natural Language to Electrocardiography: Can We Detect Cardiovascular Disease Through Language Models?</title>
      <author><first>Jielin</first><last>Qiu</last><affiliation>Carnegie Mellon University</affiliation></author>
      <author><first>William</first><last>Han</last><affiliation>Carnegie Mellon University</affiliation></author>
      <author><first>Jiacheng</first><last>Zhu</last><affiliation>Carnegie Mellon University</affiliation></author>
      <author><first>Mengdi</first><last>Xu</last><affiliation>Carnegie Mellon University</affiliation></author>
      <author><first>Michael</first><last>Rosenberg</last><affiliation>University of Colorado School of Medicine</affiliation></author>
      <author><first>Emerson</first><last>Liu</last><affiliation>Allegheny Health Network</affiliation></author>
      <author><first>Douglas</first><last>Weber</last><affiliation>Carnegie Mellon University</affiliation></author>
      <author><first>Ding</first><last>Zhao</last><affiliation>Cmu</affiliation></author>
      <pages>442-453</pages>
      <abstract>Recent advancements in Large Language Models (LLMs) have drawn increasing attention since the learned embeddings pretrained on large-scale datasets have shown powerful ability in various downstream applications. However, whether the learned knowledge by LLMs can be transferred to clinical cardiology remains unknown. In this work, we aim to bridge this gap by transferring the knowledge of LLMs to clinical Electrocardiography (ECG). We propose an approach for cardiovascular disease diagnosis and automatic ECG diagnosis report generation. We also introduce an additional loss function by Optimal Transport (OT) to align the distribution between ECG and language embedding. The learned embeddings are evaluated on two downstream tasks: (1) automatic ECG diagnosis report generation, and (2) zero-shot cardiovascular disease detection. Our approach is able to generate high-quality cardiac diagnosis reports and also achieves competitive zero-shot classification performance even compared with supervised baselines, which proves the feasibility of transferring knowledge from LLMs to the cardiac domain.</abstract>
      <url hash="ec188d17">2023.findings-eacl.33</url>
      <bibkey>qiu-etal-2023-transfer</bibkey>
      <video href="2023.findings-eacl.33.mp4"/>
      <doi>10.18653/v1/2023.findings-eacl.33</doi>
    </paper>
    <paper id="34">
      <title>Practical Takes on Federated Learning with Pretrained Language Models</title>
      <author><first>Ankur</first><last>Agarwal</last><affiliation>Huawei Noah’s Ark Lab</affiliation></author>
      <author><first>Mehdi</first><last>Rezagholizadeh</last><affiliation>Noah’s Ark Lab Huawei</affiliation></author>
      <author><first>Prasanna</first><last>Parthasarathi</last><affiliation>Noah’s Ark Lab</affiliation></author>
      <pages>454-471</pages>
      <abstract>Real-world applications of language models entail data privacy constraints when learning from diverse data domains. Federated learning with pretrained language models for language tasks has been gaining attention lately but there are definite confounders that warrants a careful study. Specifically, understanding the limits of federated NLP applications through varying the effects of different aspects (such as data heterogeneity, the trade-off between training time and performance, the effect of different data, and client distributions and sensitivity of the shared model to learning local distributions) is necessary to evaluate whether language models indeed learn to generalize by adapting to the different domains. Towards that, we elaborate different hypotheses over the components in federated NLP architectures and study them in detail with relevant experiments over three tasks: Stanford Sentiment Treebank-2, OntoNotes-5.0 and GigaWord. The experiments with different Transformer inductive biases on the variety of tasks provide a glimpse at the understanding of federated learning at NLP tasks. Specifically, the analysis suggests that regularization due to the ensembling effect may be masquerading as domain adaptation of federated learning in NLP with pre-trained language models.</abstract>
      <url hash="fa46fe0a">2023.findings-eacl.34</url>
      <bibkey>agarwal-etal-2023-practical</bibkey>
      <video href="2023.findings-eacl.34.mp4"/>
      <doi>10.18653/v1/2023.findings-eacl.34</doi>
    </paper>
    <paper id="35">
      <title>Paper Bullets: Modeling Propaganda with the Help of Metaphor</title>
      <author><first>Daniel</first><last>Baleato Rodríguez</last><affiliation>University of Amsterdam</affiliation></author>
      <author><first>Verna</first><last>Dankers</last><affiliation>University of Edinburgh</affiliation></author>
      <author><first>Preslav</first><last>Nakov</last><affiliation>Mohamed bin Zayed University of Artificial Intelligence</affiliation></author>
      <author><first>Ekaterina</first><last>Shutova</last><affiliation>University of Amsterdam</affiliation></author>
      <pages>472-489</pages>
      <abstract>Propaganda aims to persuade an audience by appealing to emotions and using faulty reasoning, with the purpose of promoting a particular point of view. Similarly, metaphor modifies the semantic frame, thus eliciting a response that can be used to tune up or down the emotional volume of the message. Given the close relationship between them, we hypothesize that, when modeling them computationally, it can be beneficial to do so jointly. In particular, we perform multi-task learning with propaganda identification as the main task and metaphor detection as an auxiliary task. To the best of our knowledge, this is the first work that models metaphor and propaganda together. We experiment with two datasets for identifying propaganda techniques in news articles and in memes shared on social media. We find that leveraging metaphor improves model performance, particularly for the two most common propaganda techniques: loaded language and name-calling.</abstract>
      <url hash="011b459d">2023.findings-eacl.35</url>
      <bibkey>baleato-rodriguez-etal-2023-paper</bibkey>
      <video href="2023.findings-eacl.35.mp4"/>
      <doi>10.18653/v1/2023.findings-eacl.35</doi>
    </paper>
    <paper id="36">
      <title>Lexical Semantics with Large Language Models: A Case Study of <fixed-case>E</fixed-case>nglish “break”</title>
      <author><first>Erika</first><last>Petersen</last><affiliation>Stanford University</affiliation></author>
      <author><first>Christopher</first><last>Potts</last><affiliation>Stanford University</affiliation></author>
      <pages>490-511</pages>
      <abstract>Large neural language models (LLMs) can be powerful tools for research in lexical semantics. We illustrate this potential using the English verb “break”, which has numerous senses and appears in a wide range of syntactic frames. We show that LLMs capture known sense distinctions and can be used to identify informative new sense combinations for further analysis. More generally, we argue that LLMs are aligned with lexical semantic theories in providing high-dimensional, contextually modulated representations, but LLMs’ lack of discrete features and dependence on usage-based data offer a genuinely new perspective on traditional problems in lexical semantics.</abstract>
      <url hash="aba3c28b">2023.findings-eacl.36</url>
      <bibkey>petersen-potts-2023-lexical</bibkey>
      <video href="2023.findings-eacl.36.mp4"/>
      <doi>10.18653/v1/2023.findings-eacl.36</doi>
    </paper>
    <paper id="37">
      <title><fixed-case>SWING</fixed-case>: Balancing Coverage and Faithfulness for Dialogue Summarization</title>
      <author><first>Kung-Hsiang</first><last>Huang</last><affiliation>University of Illinois at Urbana-Champaign</affiliation></author>
      <author><first>Siffi</first><last>Singh</last><affiliation>Amazon</affiliation></author>
      <author><first>Xiaofei</first><last>Ma</last><affiliation>Amazon Web Services</affiliation></author>
      <author><first>Wei</first><last>Xiao</last><affiliation>AWS AI, Amazon</affiliation></author>
      <author><first>Feng</first><last>Nan</last><affiliation>Aws Ai</affiliation></author>
      <author><first>Nicholas</first><last>Dingwall</last><affiliation>Amazon AI Labs</affiliation></author>
      <author><first>William Yang</first><last>Wang</last><affiliation>Amazon AWS AI Labs</affiliation></author>
      <author><first>Kathleen</first><last>McKeown</last><affiliation>Columbia University and Amazon (Amazon Scholar)</affiliation></author>
      <pages>512-525</pages>
      <abstract>Missing information is a common issue of dialogue summarization where some information in the reference summaries is not covered in the generated summaries. To address this issue, we propose to utilize natural language inference (NLI) models to improve coverage while avoiding introducing factual inconsistencies. Specifically, we use NLI to compute fine-grained training signals to encourage the model to generate content in the reference summaries that have not been covered, as well as to distinguish between factually consistent and inconsistent generated sentences. Experiments on the DialogSum and SAMSum datasets confirm the effectiveness of the proposed approach in balancing coverage and faithfulness, validated with automatic metrics and human evaluations. Additionally, we compute the correlation between commonly used automatic metrics with human judgments in terms of three different dimensions regarding coverage and factual consistency to provide insight into the most suitable metric for evaluating dialogue summaries.</abstract>
      <url hash="27c9d270">2023.findings-eacl.37</url>
      <bibkey>huang-etal-2023-swing</bibkey>
      <video href="2023.findings-eacl.37.mp4"/>
      <doi>10.18653/v1/2023.findings-eacl.37</doi>
    </paper>
    <paper id="38">
      <title>Language-Aware Multilingual Machine Translation with Self-Supervised Learning</title>
      <author><first>Haoran</first><last>Xu</last><affiliation>Johns Hopkins University</affiliation></author>
      <author><first>Jean</first><last>Maillard</last><affiliation>Meta AI</affiliation></author>
      <author><first>Vedanuj</first><last>Goswami</last><affiliation>Meta AI</affiliation></author>
      <pages>526-539</pages>
      <url hash="8e1b8d0f">2023.findings-eacl.38</url>
      <bibkey>xu-etal-2023-language</bibkey>
      <abstract>Multilingual machine translation (MMT) benefits from cross-lingual transfer but is a challenging multitask optimization problem. This is partly because there is no clear framework to systematically learn language-specific parameters. Self-supervised learning (SSL) approaches that leverage large quantities of monolingual data (where parallel data is unavailable) have shown promise by improving translation performance as complementary tasks to the MMT task. However, jointly optimizing SSL and MMT tasks is even more challenging. In this work, we first investigate how to utilize **intra-distillation** to learn more *language-specific* parameters and then show the importance of these language-specific parameters. Next, we propose a novel but simple SSL task, **concurrent denoising**, that co-trains with the MMT task by concurrently denoising monolingual data on both the encoder and decoder. Finally, we apply **intra-distillation** to this co-training approach. Combining these two approaches significantly improves MMT performance, outperforming three state-of-the-art SSL methods by a large margin, e.g., 11.3% and 3.7% improvement on an 8-language and a 15-language benchmark compared with MASS, respectively.</abstract>
      <doi>10.18653/v1/2023.findings-eacl.38</doi>
    </paper>
    <paper id="39">
      <title>Cloze Quality Estimation for Language Assessment</title>
      <author><first>Zizheng</first><last>Zhang</last><affiliation>Tokyo Metropolitan University</affiliation></author>
      <author><first>Masato</first><last>Mita</last><affiliation>CyberAgent Inc.</affiliation></author>
      <author><first>Mamoru</first><last>Komachi</last><affiliation>Tokyo Metropolitan University</affiliation></author>
      <pages>540-550</pages>
      <abstract>Cloze tests play an essential role in language assessment and help language learners improve their skills. In this paper, we propose a novel task called Cloze Quality Estimation (CQE) — a zero-shot task of evaluating whether a cloze test is of sufficient “high-quality” for language assessment based on two important factors: reliability and validity. We have taken the first step by creating a new dataset named CELA for the CQE task, which includes English cloze tests and corresponding evaluations about their quality annotated by native English speakers, which includes 2,597 and 1,730 instances in aspects of reliability and validity, respectively. We have tested baseline evaluation methods on the dataset, showing that our method could contribute to the CQE task, but the task is still challenging.</abstract>
      <url hash="55cc3bc3">2023.findings-eacl.39</url>
      <bibkey>zhang-etal-2023-cloze</bibkey>
      <video href="2023.findings-eacl.39.mp4"/>
      <doi>10.18653/v1/2023.findings-eacl.39</doi>
    </paper>
    <paper id="40">
      <title>Bag of Tricks for In-Distribution Calibration of Pretrained Transformers</title>
      <author><first>Jaeyoung</first><last>Kim</last><affiliation>VUNO, Inc.</affiliation></author>
      <author><first>Dongbin</first><last>Na</last><affiliation>VUNO Inc.</affiliation></author>
      <author><first>Sungchul</first><last>Choi</last><affiliation>Pukyong National University</affiliation></author>
      <author><first>Sungbin</first><last>Lim</last><affiliation>Unist</affiliation></author>
      <pages>551-563</pages>
      <abstract>While pre-trained language models (PLMs) have become a de-facto standard promoting the accuracy of text classification tasks, recent studies find that PLMs often predict over-confidently. Although calibration methods have been proposed, such as ensemble learning and data augmentation, most of the methods have been verified in computer vision benchmarks rather than in PLM-based text classification tasks. In this paper, we present an empirical study on confidence calibration for PLMs, addressing three categories, including confidence penalty losses, data augmentations, and ensemble methods. We find that the ensemble model overfitted to the training set shows sub-par calibration performance and also observe that PLMs trained with confidence penalty loss have a trade-off between calibration and accuracy. Building on these observations, we propose the Calibrated PLM (CALL), a combination of calibration techniques. The CALL complements shortcomings that may occur when utilizing a calibration method individually and boosts both classification and calibration accuracy. Design choices in CALL’s training procedures are extensively studied, and we provide a detailed analysis of how calibration techniques affect the calibration performance of PLMs.</abstract>
      <url hash="686e61c3">2023.findings-eacl.40</url>
      <bibkey>kim-etal-2023-bag</bibkey>
      <video href="2023.findings-eacl.40.mp4"/>
      <doi>10.18653/v1/2023.findings-eacl.40</doi>
    </paper>
    <paper id="41">
      <title>Fine-Tuning Deteriorates General Textual Out-of-Distribution Detection by Distorting Task-Agnostic Features</title>
      <author><first>Sishuo</first><last>Chen</last><affiliation>Center for Data Science, Peking University</affiliation></author>
      <author><first>Wenkai</first><last>Yang</last><affiliation>Peking University</affiliation></author>
      <author><first>Xiaohan</first><last>Bi</last><affiliation>Peking University</affiliation></author>
      <author><first>Xu</first><last>Sun</last><affiliation>Peking University</affiliation></author>
      <pages>564-579</pages>
      <abstract>Detecting out-of-distribution (OOD) inputs is crucial for the safe deployment of natural language processing (NLP) models. Though existing methods, especially those based on the statistics in the feature space of fine-tuned pre-trained language models (PLMs), are claimed to be effective, their effectiveness on different types of distribution shifts remains underexplored. In this work, we take the first step to comprehensively evaluate the mainstream textual OOD detection methods for detecting semantic and non-semantic shifts. We find that: (1) no existing method behaves well in both settings; (2) fine-tuning PLMs on in-distribution data benefits detecting semantic shifts but severely deteriorates detecting non-semantic shifts, which can be attributed to the distortion of task-agnostic features. To alleviate the issue, we present a simple yet effective general OOD score named GNOME that integrates the confidence scores derived from the task-agnostic and task-specific representations. Experiments show that GNOME works well in both semantic and non-semantic shift scenarios, and further brings significant improvement on two cross-task benchmarks where both kinds of shifts simultaneously take place. Our code is available at <url>https://github.com/lancopku/GNOME</url>.</abstract>
      <url hash="437ea09d">2023.findings-eacl.41</url>
      <bibkey>chen-etal-2023-fine</bibkey>
      <video href="2023.findings-eacl.41.mp4"/>
      <doi>10.18653/v1/2023.findings-eacl.41</doi>
    </paper>
    <paper id="42">
      <title>A Question of Style: A Dataset for Analyzing Formality on Different Levels</title>
      <author><first>Elisabeth</first><last>Eder</last><affiliation>University of Klagenfurt</affiliation></author>
      <author><first>Ulrike</first><last>Krieg-Holz</last><affiliation>University of Klagenfurt</affiliation></author>
      <author><first>Michael</first><last>Wiegand</last><affiliation>Alpen-Adria-Universitaet Klagenfurt</affiliation></author>
      <pages>580-593</pages>
      <abstract>Accounting for different degrees of formality is crucial for producing contextually appropriate language. To assist NLP applications concerned with this problem and formality analysis in general, we present the first dataset of sentences from a wide range of genres assessed on a continuous informal-formal scale via comparative judgments. It is the first corpus with a comprehensive perspective on German sentence-level formality overall. We compare machine learning models for formality scoring, a task we treat as a regression problem, on our dataset. Finally, we investigate the relation between sentence- and document-level formality and evaluate leveraging sentence-based annotations for assessing formality on documents.</abstract>
      <url hash="bdf83b71">2023.findings-eacl.42</url>
      <bibkey>eder-etal-2023-question</bibkey>
      <video href="2023.findings-eacl.42.mp4"/>
      <doi>10.18653/v1/2023.findings-eacl.42</doi>
    </paper>
    <paper id="43">
      <title>Task-specific Compression for Multi-task Language Models using Attribution-based Pruning</title>
      <author><first>Nakyeong</first><last>Yang</last><affiliation>Seoul National University</affiliation></author>
      <author><first>Yunah</first><last>Jang</last><affiliation>Seoul National University</affiliation></author>
      <author><first>Hwanhee</first><last>Lee</last><affiliation>Seoul National University</affiliation></author>
      <author><first>Seohyeong</first><last>Jeong</last><affiliation>42dot</affiliation></author>
      <author><first>Kyomin</first><last>Jung</last><affiliation>Seoul National University</affiliation></author>
      <pages>594-604</pages>
      <abstract>Multi-task language models show outstanding performance for various natural language understanding tasks with only a single model. However, these language models inevitably utilize an unnecessarily large number of model parameters, even when used only for a specific task. In this paper, we propose a novel training-free compression method for multi-task language models using pruning method. Specifically, we use an attribution method to determine which neurons are essential for performing a specific task. We task-specifically prune unimportant neurons and leave only task-specific parameters. Furthermore, we extend our method to be applicable in both low-resource and unsupervised settings. Since our compression method is training-free, it uses little computing resources and does not update the pre-trained parameters of language models, reducing storage space usage. Experimental results on the six widely-used datasets show that our proposed pruning method significantly outperforms baseline pruning methods. In addition, we demonstrate that our method preserves performance even in an unseen domain setting.</abstract>
      <url hash="1c9df74e">2023.findings-eacl.43</url>
      <bibkey>yang-etal-2023-task</bibkey>
      <video href="2023.findings-eacl.43.mp4"/>
      <doi>10.18653/v1/2023.findings-eacl.43</doi>
    </paper>
    <paper id="44">
      <title>Zero-shot Transfer of Article-aware Legal Outcome Classification for <fixed-case>E</fixed-case>uropean Court of Human Rights Cases</title>
      <author><first>Santosh</first><last>T.y.s.s</last><affiliation>Technical University of Munich</affiliation></author>
      <author><first>Oana</first><last>Ichim</last><affiliation>Graduate Institute of International and Development Studies</affiliation></author>
      <author><first>Matthias</first><last>Grabmair</last><affiliation>Technical University of Munich</affiliation></author>
      <pages>605-617</pages>
      <abstract>In this paper, we cast Legal Judgment Prediction on European Court of Human Rights cases into an article-aware classification task, where the case outcome is classified from a combined input of case facts and convention articles. This configuration facilitates the model learning some legal reasoning ability in mapping article text to specific case fact text. It also provides an opportunity to evaluate the model’s ability to generalize to zero-shot settings when asked to classify the case outcome with respect to articles not seen during training. We devise zero-shot experiments and apply domain adaptation methods based on domain discrimination and Wasserstein distance. Our results demonstrate that the article-aware architecture outperforms straightforward fact classification. We also find that domain adaptation methods improve zero-shot transfer performance, with article relatedness and encoder pre-training influencing the effect.</abstract>
      <url hash="0430d11f">2023.findings-eacl.44</url>
      <bibkey>t-y-s-s-etal-2023-zero</bibkey>
      <video href="2023.findings-eacl.44.mp4"/>
      <doi>10.18653/v1/2023.findings-eacl.44</doi>
    </paper>
    <paper id="45">
      <title>Abstractive Document Summarization with Summary-length Prediction</title>
      <author><first>Jingun</first><last>Kwon</last><affiliation>Tokyo Institute of Technology, Naver Corporation</affiliation></author>
      <author><first>Hidetaka</first><last>Kamigaito</last><affiliation>Nara Institute of Science and Technology</affiliation></author>
      <author><first>Manabu</first><last>Okumura</last><affiliation>Tokyo Institute of Technology</affiliation></author>
      <pages>618-624</pages>
      <abstract>Recently, we can obtain a practical abstractive document summarization model by fine-tuning a pre-trained language model (PLM). Since the pre-training for PLMs does not consider summarization-specific information such as the target summary length, there is a gap between the pre-training and fine-tuning for PLMs in summarization tasks. To fill the gap, we propose a method for enabling the model to understand the summarization-specific information by predicting the summary length in the encoder and generating a summary of the predicted length in the decoder in fine-tuning. Experimental results on the WikiHow, NYT, and CNN/DM datasets showed that our methods improve ROUGE scores from BART by generating summaries of appropriate lengths. Further, we observed about 3.0, 1,5, and 3.1 point improvements for ROUGE-1, -2, and -L, respectively, from GSum on the WikiHow dataset. Human evaluation results also showed that our methods improve the informativeness and conciseness of summaries.</abstract>
      <url hash="351039b8">2023.findings-eacl.45</url>
      <attachment type="software" hash="30cadd6d">2023.findings-eacl.45.software.zip</attachment>
      <bibkey>kwon-etal-2023-abstractive</bibkey>
      <video href="2023.findings-eacl.45.mp4"/>
      <doi>10.18653/v1/2023.findings-eacl.45</doi>
    </paper>
    <paper id="46">
      <title>Hierarchical Label Generation for Text Classification</title>
      <author><first>Jingun</first><last>Kwon</last><affiliation>Tokyo Institute of Technology, Naver Corporation</affiliation></author>
      <author><first>Hidetaka</first><last>Kamigaito</last><affiliation>Nara Institute of Science and Technology</affiliation></author>
      <author><first>Young-In</first><last>Song</last><affiliation>Naver</affiliation></author>
      <author><first>Manabu</first><last>Okumura</last><affiliation>Tokyo Institute of Technology</affiliation></author>
      <pages>625-632</pages>
      <abstract/>
      <url hash="2b3aef86">2023.findings-eacl.46</url>
      <bibkey>kwon-etal-2023-hierarchical</bibkey>
      <video href="2023.findings-eacl.46.mp4"/>
      <doi>10.18653/v1/2023.findings-eacl.46</doi>
    </paper>
    <paper id="47">
      <title>Active Learning for Multilingual Semantic Parser</title>
      <author><first>Zhuang</first><last>Li</last><affiliation>Monash University</affiliation></author>
      <author><first>Gholamreza</first><last>Haffari</last><affiliation>Monash University</affiliation></author>
      <pages>633-639</pages>
      <abstract>Current multilingual semantic parsing (MSP) datasets are almost all collected by translating the utterances in the existing datasets from the resource-rich language to the target language. However, manual translation is costly. To reduce the translation effort, this paper proposes the first active learning procedure for MSP (AL-MSP). AL-MSP selects only a subset from the existing datasets to be translated. We also propose a novel selection method that prioritizes the examples diversifying the logical form structures with more lexical choices, and a novel hyperparameter tuning method that needs no extra annotation cost. Our experiments show that AL-MSP significantly reduces translation costs with ideal selection methods. Our selection method with proper hyperparameters yields better parsing performance than the other baselines on two multilingual datasets.</abstract>
      <url hash="451225bf">2023.findings-eacl.47</url>
      <bibkey>li-haffari-2023-active</bibkey>
      <video href="2023.findings-eacl.47.mp4"/>
      <doi>10.18653/v1/2023.findings-eacl.47</doi>
      <revision id="1" href="2023.findings-eacl.47v1" hash="fd2596ec"/>
      <revision id="2" href="2023.findings-eacl.47v2" hash="451225bf" date="2023-09-04">Updated Figure 1.</revision>
    </paper>
    <paper id="48">
      <title>Joint Word and Morpheme Segmentation with <fixed-case>B</fixed-case>ayesian Non-Parametric Models</title>
      <author><first>Shu</first><last>Okabe</last><affiliation>LISN/CNRS, Université Paris-Saclay</affiliation></author>
      <author><first>François</first><last>Yvon</last><affiliation>ISIR CNRS &amp; Sorbonne Université</affiliation></author>
      <pages>640-654</pages>
      <abstract>Language documentation often requires segmenting transcriptions of utterances collected on the field into words and morphemes. While these two tasks are typically performed in succession, we study here Bayesian models for simultaneously segmenting utterances at these two levels. Our aim is twofold: (a) to study the effect of explicitly introducing a hierarchy of units in joint segmentation models; (b) to further assess whether these two levels can be better identified through weak supervision. For this, we first consider a deterministic coupling between independent models; then design and evaluate hierarchical Bayesian models. Experiments with two under-resourced languages (Japhug and Tsez) allow us to better understand the value of various types of weak supervision. In our analysis, we use these results to revisit the distributional hypotheses behind Bayesian segmentation models and evaluate their validity for language documentation data.</abstract>
      <url hash="23335297">2023.findings-eacl.48</url>
      <bibkey>okabe-yvon-2023-joint</bibkey>
      <video href="2023.findings-eacl.48.mp4"/>
      <doi>10.18653/v1/2023.findings-eacl.48</doi>
    </paper>
    <paper id="49">
      <title>Cross-Lingual Transfer of Cognitive Processing Complexity</title>
      <author><first>Charlotte</first><last>Pouw</last><affiliation>University of Amsterdam</affiliation></author>
      <author><first>Nora</first><last>Hollenstein</last><affiliation>University of Copenhagen</affiliation></author>
      <author><first>Lisa</first><last>Beinborn</last><affiliation>Vrije Universiteit Amsterdam</affiliation></author>
      <pages>655-669</pages>
      <abstract>When humans read a text, their eye movements are influenced by the structural complexity of the input sentences. This cognitive phenomenon holds across languages and recent studies indicate that multilingual language models utilize structural similarities between languages to facilitate cross-lingual transfer. We use sentence-level eye-tracking patterns as a cognitive indicator for structural complexity and show that the multilingual model XLM-RoBERTa can successfully predict varied patterns for 13 typologically diverse languages, despite being fine-tuned only on English data. We quantify the sensitivity of the model to structural complexity and distinguish a range of complexity characteristics. Our results indicate that the model develops a meaningful bias towards sentence length but also integrates cross-lingual differences. We conduct a control experiment with randomized word order and find that the model seems to additionally capture more complex structural information.</abstract>
      <url hash="b2c58d40">2023.findings-eacl.49</url>
      <attachment type="software" hash="dfff89be">2023.findings-eacl.49.software.zip</attachment>
      <bibkey>pouw-etal-2023-cross</bibkey>
      <video href="2023.findings-eacl.49.mp4"/>
      <doi>10.18653/v1/2023.findings-eacl.49</doi>
    </paper>
    <paper id="50">
      <title>Does Transliteration Help Multilingual Language Modeling?</title>
      <author><first>Ibraheem Muhammad</first><last>Moosa</last><affiliation>Pennsylvania State University</affiliation></author>
      <author><first>Mahmud Elahi</first><last>Akhter</last><affiliation>North South University</affiliation></author>
      <author><first>Ashfia Binte</first><last>Habib</last><affiliation>North South Univeristy</affiliation></author>
      <pages>670-685</pages>
      <abstract>Script diversity presents a challenge to Multilingual Language Models (MLLM) by reducing lexical overlap among closely related languages. Therefore, transliterating closely related languages that use different writing scripts to a common script may improve the downstream task performance of MLLMs. We empirically measure the effect of transliteration on MLLMs in this context. We specifically focus on the Indic languages, which have the highest script diversity in the world, and we evaluate our models on the IndicGLUE benchmark. We perform the Mann-Whitney U test to rigorously verify whether the effect of transliteration is significant or not. We find that transliteration benefits the low-resource languages without negatively affecting the comparatively high-resource languages. We also measure the cross-lingual representation similarity of the models using centered kernel alignment on parallel sentences from the FLORES-101 dataset. We find that for parallel sentences across different languages, the transliteration-based model learns sentence representations that are more similar.</abstract>
      <url hash="25b6b494">2023.findings-eacl.50</url>
      <bibkey>moosa-etal-2023-transliteration</bibkey>
      <video href="2023.findings-eacl.50.mp4"/>
      <doi>10.18653/v1/2023.findings-eacl.50</doi>
    </paper>
    <paper id="51">
      <title>A Multilingual Dataset of Racial Stereotypes in Social Media Conversational Threads</title>
      <author><first>Tom</first><last>Bourgeade</last><affiliation>IRIT, University of Toulouse</affiliation></author>
      <author><first>Alessandra Teresa</first><last>Cignarella</last><affiliation>Computer Science Department - University of Turin</affiliation></author>
      <author><first>Simona</first><last>Frenda</last><affiliation>Università degli Studi di Torino</affiliation></author>
      <author><first>Mario</first><last>Laurent</last><affiliation>Université Paul Sabatier</affiliation></author>
      <author><first>Wolfgang</first><last>Schmeisser-Nieto</last><affiliation>Universitat de Barcelona</affiliation></author>
      <author><first>Farah</first><last>Benamara</last><affiliation>University of toulouse</affiliation></author>
      <author><first>Cristina</first><last>Bosco</last><affiliation>Dipartimento di Informatica - Università di Torino</affiliation></author>
      <author><first>Véronique</first><last>Moriceau</last><affiliation>IRIT, Université Toulouse 3</affiliation></author>
      <author><first>Viviana</first><last>Patti</last><affiliation>University of Turin, Dipartimento di Informatica</affiliation></author>
      <author><first>Mariona</first><last>Taulé</last><affiliation>University of Barcelona</affiliation></author>
      <pages>686-696</pages>
      <abstract>In this paper, we focus on the topics of misinformation and racial hoaxes from a perspective derived from both social psychology and computational linguistics. In particular, we consider the specific case of anti-immigrant feeling as a first case study for addressing racial stereotypes. We describe the first corpus-based study for multilingual racial stereotype identification in social media conversational threads. Our contributions are: (i) a multilingual corpus of racial hoaxes, (ii) a set of common guidelines for the annotation of racial stereotypes in social media texts, and a multi-layered, fine-grained scheme, psychologically grounded on the work by Fiske, including not only stereotype presence, but also contextuality, implicitness, and forms of discredit, (iii) a multilingual dataset in Italian, Spanish, and French annotated following the aforementioned guidelines, and cross-lingual comparative analyses taking into account racial hoaxes and stereotypes in online discussions. The analysis and results show the usefulness of our methodology and resources, shedding light on how racial hoaxes are spread, and enable the identification of negative stereotypes that reinforce them.</abstract>
      <url hash="7037ea87">2023.findings-eacl.51</url>
      <bibkey>bourgeade-etal-2023-multilingual</bibkey>
      <video href="2023.findings-eacl.51.mp4"/>
      <doi>10.18653/v1/2023.findings-eacl.51</doi>
    </paper>
    <paper id="52">
      <title>Detecting Contextomized Quotes in News Headlines by Contrastive Learning</title>
      <author><first>Seonyeong</first><last>Song</last><affiliation>Soongsil University</affiliation></author>
      <author><first>Hyeonho</first><last>Song</last><affiliation>Kaist</affiliation></author>
      <author><first>Kunwoo</first><last>Park</last><affiliation>Soongsil University</affiliation></author>
      <author><first>Jiyoung</first><last>Han</last><affiliation>Korea Advanced Institute of Science and Technology (KAIST)</affiliation></author>
      <author><first>Meeyoung</first><last>Cha</last><affiliation>Ibs &amp; Kaist</affiliation></author>
      <pages>697-704</pages>
      <abstract>Quotes are critical for establishing credibility in news articles. A direct quote enclosed in quotation marks has a strong visual appeal and is a sign of a reliable citation. Unfortunately, this journalistic practice is not strictly followed, and a quote in the headline is often “contextomized.” Such a quote uses words out of context in a way that alters the speaker’s intention so that there is no semantically matching quote in the body text. We present QuoteCSE, a contrastive learning framework that represents the embedding of news quotes based on domain-driven positive and negative samples to identify such an editorial strategy. The dataset and code are available at <url>https://github.com/ssu-humane/contextomized-quote-contrastive</url>.</abstract>
      <url hash="f02da065">2023.findings-eacl.52</url>
      <bibkey>song-etal-2023-detecting</bibkey>
      <video href="2023.findings-eacl.52.mp4"/>
      <doi>10.18653/v1/2023.findings-eacl.52</doi>
    </paper>
    <paper id="53">
      <title>Zero-Shot On-the-Fly Event Schema Induction</title>
      <author><first>Rotem</first><last>Dror</last><affiliation>University of Pennsylvania</affiliation></author>
      <author><first>Haoyu</first><last>Wang</last><affiliation>University of Pennsylvania</affiliation></author>
      <author><first>Dan</first><last>Roth</last><affiliation>University of Pennsylvania</affiliation></author>
      <pages>705-725</pages>
      <abstract>What are the events involved in a pandemic outbreak? What steps should be taken when planning a wedding? The answers to these questions can be found by collecting many documents on the complex event of interest, extracting relevant information, and analyzing it. We present a new approach in which large language models are utilized to generate source documents that allow predicting, given a high-level event definition, the specific events, arguments, and relations between them to construct a schema that describes the complex event in its entirety. Using our model, complete schemas on any topic can be generated on-the-fly without any manual data collection, i.e., in a zero-shot manner. Moreover, we develop efficient methods to extract pertinent information from texts and demonstrate in a series of experiments that these schemas are considered to be more complete than human-curated ones in the majority of examined scenarios. Finally, we show that this framework is comparable in performance with previous supervised schema induction methods that rely on collecting real texts and even reaching the best score in the prediction task.</abstract>
      <url hash="fa971b33">2023.findings-eacl.53</url>
      <bibkey>dror-etal-2023-zero</bibkey>
      <video href="2023.findings-eacl.53.mp4"/>
      <doi>10.18653/v1/2023.findings-eacl.53</doi>
    </paper>
    <paper id="54">
      <title><fixed-case>B</fixed-case>angla<fixed-case>NLG</fixed-case> and <fixed-case>B</fixed-case>angla<fixed-case>T</fixed-case>5: Benchmarks and Resources for Evaluating Low-Resource Natural Language Generation in <fixed-case>B</fixed-case>angla</title>
      <author><first>Abhik</first><last>Bhattacharjee</last><affiliation>Bangladesh University of Engineering and Technology</affiliation></author>
      <author><first>Tahmid</first><last>Hasan</last><affiliation>Bangladesh University of Engineering and Technology</affiliation></author>
      <author><first>Wasi Uddin</first><last>Ahmad</last><affiliation>AWS AI Labs</affiliation></author>
      <author><first>Rifat</first><last>Shahriyar</last><affiliation>Bangladesh University of Engineering and Technology</affiliation></author>
      <pages>726-735</pages>
      <abstract>This work presents ‘BanglaNLG,’ a comprehensive benchmark for evaluating natural language generation (NLG) models in Bangla, a widely spoken yet low-resource language. We aggregate six challenging conditional text generation tasks under the BanglaNLG benchmark, introducing a new dataset on dialogue generation in the process. Furthermore, using a clean corpus of 27.5 GB of Bangla data, we pretrain ‘BanglaT5’, a sequence-to-sequence Transformer language model for Bangla. BanglaT5 achieves state-of-the-art performance in all of these tasks, outperforming several multilingual models by up to 9% absolute gain and 32% relative gain. We are making the new dialogue dataset and the BanglaT5 model publicly available at <url>https://github.com/csebuetnlp/BanglaNLG</url> in the hope of advancing future research on Bangla NLG.</abstract>
      <url hash="446bdae0">2023.findings-eacl.54</url>
      <bibkey>bhattacharjee-etal-2023-banglanlg</bibkey>
      <video href="2023.findings-eacl.54.mp4"/>
      <doi>10.18653/v1/2023.findings-eacl.54</doi>
    </paper>
    <paper id="55">
      <title>It’s about Time: Rethinking Evaluation on Rumor Detection Benchmarks using Chronological Splits</title>
      <author><first>Yida</first><last>Mu</last><affiliation>The University of Sheffield</affiliation></author>
      <author><first>Kalina</first><last>Bontcheva</last><affiliation>University of Sheffield</affiliation></author>
      <author><first>Nikolaos</first><last>Aletras</last><affiliation>University of Sheffield</affiliation></author>
      <pages>736-743</pages>
      <abstract>New events emerge over time influencing the topics of rumors in social media. Current rumor detection benchmarks use random splits as training, development and test sets which typically results in topical overlaps. Consequently, models trained on random splits may not perform well on rumor classification on previously unseen topics due to the temporal concept drift. In this paper, we provide a re-evaluation of classification models on four popular rumor detection benchmarks considering chronological instead of random splits. Our experimental results show that the use of random splits can significantly overestimate predictive performance across all datasets and models. Therefore, we suggest that rumor detection models should always be evaluated using chronological splits for minimizing topical overlaps.</abstract>
      <url hash="4cf0b62b">2023.findings-eacl.55</url>
      <bibkey>mu-etal-2023-time</bibkey>
      <video href="2023.findings-eacl.55.mp4"/>
      <doi>10.18653/v1/2023.findings-eacl.55</doi>
    </paper>
    <paper id="56">
      <title><fixed-case>MUTANT</fixed-case>: A Multi-sentential Code-mixed <fixed-case>H</fixed-case>inglish Dataset</title>
      <author><first>Rahul</first><last>Gupta</last><affiliation>Indian Institute of Technology Gandhinagar</affiliation></author>
      <author><first>Vivek</first><last>Srivastava</last><affiliation>TCS Research</affiliation></author>
      <author><first>Mayank</first><last>Singh</last><affiliation>IIT Gandhinagar</affiliation></author>
      <pages>744-753</pages>
      <abstract>The multi-sentential long sequence textual data unfolds several interesting research directions pertaining to natural language processing and generation. Though we observe several high-quality long-sequence datasets for English and other monolingual languages, there is no significant effort in building such resources for code-mixed languages such as Hinglish (code-mixing of Hindi-English). In this paper, we propose a novel task of identifying multi-sentential code-mixed text (MCT) from multilingual articles. As a use case, we leverage multilingual articles from two different data sources and build a first-of-its-kind multi-sentential code-mixed Hinglish dataset i.e., MUTANT. We propose a token-level language-aware pipeline and extend the existing metrics measuring the degree of code-mixing to a multi-sentential framework and automatically identify MCT in the multilingual articles. The MUTANT dataset comprises 67k articles with 85k identified Hinglish MCTs. To facilitate future research directions, we will make the dataset and the code publicly available upon publication.</abstract>
      <url hash="aea13fc3">2023.findings-eacl.56</url>
      <bibkey>gupta-etal-2023-mutant</bibkey>
      <video href="2023.findings-eacl.56.mp4"/>
      <doi>10.18653/v1/2023.findings-eacl.56</doi>
    </paper>
    <paper id="57">
      <title>Bridging the Gap between Native Text and Translated Text through Adversarial Learning: A Case Study on Cross-Lingual Event Extraction</title>
      <author><first>Pengfei</first><last>Yu</last><affiliation>Department of Computer Science, University of Illinois at Urbana-Champaign</affiliation></author>
      <author><first>Jonathan</first><last>May</last><affiliation>USC Information Sciences Institute</affiliation></author>
      <author><first>Heng</first><last>Ji</last><affiliation>University of Illinois at Urbana-Champaign and Amazon (Amazon Scholar)</affiliation></author>
      <pages>754-769</pages>
      <abstract>Recent research in cross-lingual learning has found that combining large-scale pretrained multilingual language models with machine translation can yield good performance. We explore this idea for cross-lingual event extraction with a new model architecture that jointly encodes a source language input sentence with its translation to the target language during training, and takes a target language sentence with its translation back to the source language as input during evaluation. However, we observe significant representational gap between the native source language texts during training and the texts translated into source language during evaluation, as well as the texts translated into target language during training and the native target language texts during evaluation. This representational gap undermines the effectiveness of cross-lingual transfer learning for event extraction with machine-translated data. In order to mitigate this problem, we propose an adversarial training framework that encourages the language model to produce more similar representations for the translated text and the native text. To be specific, we train the language model such that its hidden representations are able to fool a jointly trained discriminator that distinguishes translated texts’ representations from native texts’ representations. We conduct experiments on cross-lingual for event extraction across three languages. Results demonstrate that our proposed adversarial training can effectively incorporate machine translation to improve event extraction, while simply adding machine-translated data yields unstable performance due to the representational gap.</abstract>
      <url hash="3ee70b0f">2023.findings-eacl.57</url>
      <bibkey>yu-etal-2023-bridging</bibkey>
      <video href="2023.findings-eacl.57.mp4"/>
      <doi>10.18653/v1/2023.findings-eacl.57</doi>
    </paper>
    <paper id="58">
      <title>Scalable Prompt Generation for Semi-supervised Learning with Language Models</title>
      <author><first>Yuhang</first><last>Zhou</last><affiliation>University of Maryland</affiliation></author>
      <author><first>Suraj</first><last>Maharjan</last><affiliation>Amazon</affiliation></author>
      <author><first>Beiye</first><last>Liu</last><affiliation>Amazon</affiliation></author>
      <pages>770-781</pages>
      <abstract>Prompt-based learning methods in semi-supervised learning (SSL) settings have been shown to be effective on multiple natural language understanding (NLU) datasets and tasks in the literature. However, manually designing multiple prompts and verbalizers requires domain knowledge and human effort, making it difficult and expensive to scale across different datasets. In this paper, we propose two methods to automatically design multiple prompts and integrate automatic verbalizer in SSL settings without sacrificing performance. The first method uses various demonstration examples with learnable continuous prompt tokens to create diverse prompt models. The second method uses a varying number of soft prompt tokens to encourage language models to learn different prompts. For the verbalizer, we use the prototypical verbalizer to replace the manual one. In summary, we obtained the best average accuracy of 71.5% (a relative improvement of 0.99% over even the previous state-of-the-art SSL method with manual prompts and verbalizers) in different few-shot learning settings.</abstract>
      <url hash="d67240cb">2023.findings-eacl.58</url>
      <bibkey>zhou-etal-2023-scalable</bibkey>
      <video href="2023.findings-eacl.58.mp4"/>
      <doi>10.18653/v1/2023.findings-eacl.58</doi>
    </paper>
    <paper id="59">
      <title>Novel Feature Discovery for Task-Oriented Dialog Systems</title>
      <author><first>Vinh Thinh</first><last>Ho</last><affiliation>Amazon Alexa AI</affiliation></author>
      <author><first>Mohamed</first><last>Soliman</last><affiliation>Amazon Alexa AI</affiliation></author>
      <author><first>Abdalghani</first><last>Abujabal</last><affiliation>Amazon Alexa AI</affiliation></author>
      <pages>782-792</pages>
      <abstract>A novel feature represents a cluster of semantically equivalent novel user requests e.g., requests to play a song on a service or read user’s messages. Detecting and supporting novel features is crucial towards wider adoption of dialog systems by end users. Intuitively, features are represented by a combination of intents, slot types and/or their values. For example, while playing a song is a feature represented by a single intent (PlayMusic) only, playing a song on a service is another feature represented by the combination of PlayMusic intent and ServiceName slot type. Prior work on novelty detection limits the scope of features to those represented by novel single intents, leading to (1) giant clusters spanning several user-perceived fine-grained features belonging to the same intent, (2) incoherent interpretation of clusters from users’ perspective (no direct connection to some user-perceived feature), and (3) missing those features spanning several intents. In this work, we introduce feature discovery as opposed to single intent discovery, which aims at discovering novel features spanning a combination of intents and slots, and present a technique for discovering novel features from user utterances. Experiments on two datasets demonstrate the effectiveness of our approach and consistently show its ability to detect novel features.</abstract>
      <url hash="29804f4b">2023.findings-eacl.59</url>
      <bibkey>ho-etal-2023-novel</bibkey>
      <video href="2023.findings-eacl.59.mp4"/>
      <doi>10.18653/v1/2023.findings-eacl.59</doi>
    </paper>
    <paper id="60">
      <title>Context Generation Improves Open Domain Question Answering</title>
      <author><first>Dan</first><last>Su</last><affiliation>The Hong Kong University of Science and Technology</affiliation></author>
      <author><first>Mostofa</first><last>Patwary</last><affiliation>Nvidia</affiliation></author>
      <author><first>Shrimai</first><last>Prabhumoye</last><affiliation>Nvidia</affiliation></author>
      <author><first>Peng</first><last>Xu</last><affiliation>Nvidia</affiliation></author>
      <author><first>Ryan</first><last>Prenger</last><affiliation>Nvidia</affiliation></author>
      <author><first>Mohammad</first><last>Shoeybi</last><affiliation>Nvidia</affiliation></author>
      <author><first>Pascale</first><last>Fung</last><affiliation>Hong Kong University of Science and Technology</affiliation></author>
      <author><first>Anima</first><last>Anandkumar</last><affiliation>California Institute of Technology</affiliation></author>
      <author><first>Bryan</first><last>Catanzaro</last><affiliation>Nvidia</affiliation></author>
      <pages>793-808</pages>
      <abstract>Closed-book question answering (QA) requires a model to directly answer an open-domain question without access to any external knowledge. Prior work on closed-book QA either directly finetunes or prompts a pretrained language model (LM) to leverage the stored knowledge. However, they do not fully exploit the parameterized knowledge. To address this inefficiency, we propose a two-stage, closed-book QA framework which employs a coarse-to-fine approach to extract the relevant knowledge and answer a question. We first generate a related context for a given question by prompting a pretrained LM. We then prompt the same LM to generate an answer using the generated context and the question. Additionally, we marginalize over the generated contexts to improve the accuracies and reduce context uncertainty. Experimental results on three QA benchmarks show that our method significantly outperforms previous closed-book QA methods. For example on TriviaQA, our method improves exact match accuracy from 55.3% to 68.6%, and is on par with open-book QA methods (68.6% vs. 68.0%). Our results show that our new methodology is able to better exploit the stored knowledge in pretrained LMs without adding extra learnable parameters or needing finetuning, and paves the way for hybrid models that integrate pretrained LMs with external knowledge.</abstract>
      <url hash="4feb32fd">2023.findings-eacl.60</url>
      <bibkey>su-etal-2023-context</bibkey>
      <video href="2023.findings-eacl.60.mp4"/>
      <doi>10.18653/v1/2023.findings-eacl.60</doi>
    </paper>
    <paper id="61">
      <title><fixed-case>R</fixed-case>ed<fixed-case>HOT</fixed-case>: A Corpus of Annotated Medical Questions, Experiences, and Claims on Social Media</title>
      <author><first>Somin</first><last>Wadhwa</last><affiliation>Northeastern University</affiliation></author>
      <author><first>Vivek</first><last>Khetan</last><affiliation>Accenture Labs</affiliation></author>
      <author><first>Silvio</first><last>Amir</last><affiliation>Northeastern University</affiliation></author>
      <author><first>Byron</first><last>Wallace</last><affiliation>Northeastern University</affiliation></author>
      <pages>809-827</pages>
      <abstract>We present Reddit Health Online Talk (RedHOT), a corpus of 22,000 richly annotated social media posts from Reddit spanning 24 health conditions. Annotations include demarcations of spans corresponding to medical claims, personal experiences, and questions. We collect additional granular annotations on identified claims. Specifically, we mark snippets that describe patient Populations, Interventions, and Outcomes (PIO elements) within these. Using this corpus, we introduce the task of retrieving trustworthy evidence relevant to a given claim made on social media. We propose a new method to automatically derive (noisy) supervision for this task which we use to train a dense retrieval model; this outperforms baseline models. Manual evaluation of retrieval results performed by medical doctors indicate that while our system performance is promising, there is considerable room for improvement. We release all annotations collected (and scripts to assemble the dataset), and all code necessary to reproduce the results in this paper at: <url>https://sominw.com/redhot</url>.</abstract>
      <url hash="642a6f2e">2023.findings-eacl.61</url>
      <bibkey>wadhwa-etal-2023-redhot</bibkey>
      <video href="2023.findings-eacl.61.mp4"/>
      <doi>10.18653/v1/2023.findings-eacl.61</doi>
    </paper>
    <paper id="62">
      <title>Paparazzi: A Deep Dive into the Capabilities of Language and Vision Models for Grounding Viewpoint Descriptions</title>
      <author><first>Henrik</first><last>Voigt</last><affiliation>Friedrich-Schiller-University</affiliation></author>
      <author><first>Jan</first><last>Hombeck</last><affiliation>University of Jena</affiliation></author>
      <author><first>Monique</first><last>Meuschke</last><affiliation>University of Jena</affiliation></author>
      <author><first>Kai</first><last>Lawonn</last><affiliation>University of Jena</affiliation></author>
      <author><first>Sina</first><last>Zarrieß</last><affiliation>University of Bielefeld</affiliation></author>
      <pages>828-843</pages>
      <abstract>Existing language and vision models achieve impressive performance in image-text understanding. Yet, it is an open question to what extent they can be used for language understanding in 3D environments and whether they implicitly acquire 3D object knowledge, e.g. about different views of an object. In this paper, we investigate whether a state-of-the-art language and vision model, CLIP, is able to ground perspective descriptions of a 3D object and identify canonical views of common objects based on text queries. We present an evaluation framework that uses a circling camera around a 3D object to generate images from different viewpoints and evaluate them in terms of their similarity to natural language descriptions. We find that a pre-trained CLIP model performs poorly on most canonical views and that fine-tuning using hard negative sampling and random contrasting yields good results even under conditions with little available training data.</abstract>
      <url hash="a232eaf5">2023.findings-eacl.62</url>
      <bibkey>voigt-etal-2023-paparazzi</bibkey>
      <video href="2023.findings-eacl.62.mp4"/>
      <doi>10.18653/v1/2023.findings-eacl.62</doi>
    </paper>
    <paper id="63">
      <title><fixed-case>PLACES</fixed-case>: Prompting Language Models for Social Conversation Synthesis</title>
      <author><first>Maximillian</first><last>Chen</last><affiliation>Columbia University</affiliation></author>
      <author><first>Alexandros</first><last>Papangelis</last><affiliation>Amazon Alexa AI</affiliation></author>
      <author><first>Chenyang</first><last>Tao</last><affiliation>Amazon</affiliation></author>
      <author><first>Seokhwan</first><last>Kim</last><affiliation>Amazon Alexa AI</affiliation></author>
      <author><first>Andy</first><last>Rosenbaum</last><affiliation>Amazon</affiliation></author>
      <author id="yang-liu-icsi"><first>Yang</first><last>Liu</last><affiliation>Amazon</affiliation></author>
      <author><first>Zhou</first><last>Yu</last><affiliation>Columbia University</affiliation></author>
      <author><first>Dilek</first><last>Hakkani-Tur</last><affiliation>Amazon Alexa AI</affiliation></author>
      <pages>844-868</pages>
      <abstract>Collecting high quality conversational data can be very expensive for most applications and infeasible for others due to privacy, ethical, or similar concerns. A promising direction to tackle this problem is to generate synthetic dialogues by prompting large language models. In this work, we use a small set of expert-written conversations as in-context examples to synthesize a social conversation dataset using prompting. We perform several thorough evaluations of our synthetic conversations compared to human-collected conversations. This includes various dimensions of conversation quality with human evaluation directly on the synthesized conversations, and interactive human evaluation of chatbots fine-tuned on the synthetically generated dataset. We additionally demonstrate that this prompting approach is generalizable to multi-party conversations, providing potential to create new synthetic data for multi-party tasks. Our synthetic multi-party conversations were rated more favorably across all measured dimensions compared to conversation excerpts sampled from a human-collected multi-party dataset.</abstract>
      <url hash="2de5ef99">2023.findings-eacl.63</url>
      <bibkey>chen-etal-2023-places</bibkey>
      <video href="2023.findings-eacl.63.mp4"/>
      <doi>10.18653/v1/2023.findings-eacl.63</doi>
    </paper>
    <paper id="64">
      <title><fixed-case>F</fixed-case>ed<fixed-case>P</fixed-case>er<fixed-case>C</fixed-case>: Federated Learning for Language Generation with Personal and Context Preference Embeddings</title>
      <author><first>Andrew</first><last>Silva</last><affiliation>Georgia Institute of Technology</affiliation></author>
      <author><first>Pradyumna</first><last>Tambwekar</last><affiliation>Georgia Institute of Technology</affiliation></author>
      <author><first>Matthew</first><last>Gombolay</last><affiliation>Georgia Institute of Technology</affiliation></author>
      <pages>869-882</pages>
      <abstract>Federated learning is a training paradigm that learns from multiple distributed users without aggregating data on a centralized server, promising the ability to deploy machine-learning to a diverse population of users without first collecting large, labeled datasets. As federated learning involves averaging gradient updates across a decentralized population, there is a growing need for personalization of federated learning systems (i.e. conversational agents must personalize to individual users and the context of an interaction).In this work, we propose a new direction for personalization research within federated learning, leveraging both personal embeddings and shared context embeddings.We also present an approach to predict these “preference” embeddings, enabling personalization without backpropagation. Compared to state-of-the-art personalization baselines, our approach achieves a 50% improvement in test-time perplexity using 0.001% of the memory required by baseline approaches, and achieving greater sample- and compute-efficiency.</abstract>
      <url hash="1e5283fc">2023.findings-eacl.64</url>
      <bibkey>silva-etal-2023-fedperc</bibkey>
      <video href="2023.findings-eacl.64.mp4"/>
      <doi>10.18653/v1/2023.findings-eacl.64</doi>
    </paper>
    <paper id="65">
      <title>A Neural <fixed-case>CRF</fixed-case>-based Hierarchical Approach for Linear Text Segmentation</title>
      <author><first>Inderjeet</first><last>Nair</last><affiliation>Adobe Research</affiliation></author>
      <author><first>Aparna</first><last>Garimella</last><affiliation>Adobe Research</affiliation></author>
      <author><first>Balaji Vasan</first><last>Srinivasan</last><affiliation>Adobe Research, India</affiliation></author>
      <author><first>Natwar</first><last>Modani</last><affiliation>Adobe Research, India</affiliation></author>
      <author><first>Niyati</first><last>Chhaya</last><affiliation>Adobe Research</affiliation></author>
      <author><first>Srikrishna</first><last>Karanam</last><affiliation>Adobe Research</affiliation></author>
      <author><first>Sumit</first><last>Shekhar</last><affiliation>Adobe Systems</affiliation></author>
      <pages>883-893</pages>
      <abstract>We consider the problem of segmenting unformatted text and transcripts linearly based on their topical structure. While prior approaches explicitly train to predict segment boundaries, our proposed approach solves this task by inferring the hierarchical segmentation structure associated with the input text fragment. Given the lack of a large annotated dataset for this task, we propose a data curation strategy and create a corpus of over 700K Wikipedia articles with their hierarchical structures. We then propose the first supervised approach to generating hierarchical segmentation structures based on these annotations. Our method, in particular, is based on a neural conditional random field (CRF), which explicitly models the statistical dependency between a node and its constituent child nodes. We introduce a new data augmentation scheme as part of our model training strategy, which involves sampling a variety of node aggregations, permutations, and removals, all of which help capture fine-grained and coarse topical shifts in the data and improve model performance. Extensive experiments show that our model outperforms or achieves competitive performance when compared to previous state-of-the-art algorithms in the following settings: rich-resource, cross-domain transferability, few-shot supervision, and segmentation when topic label annotations are provided.</abstract>
      <url hash="34687b17">2023.findings-eacl.65</url>
      <bibkey>nair-etal-2023-neural</bibkey>
      <video href="2023.findings-eacl.65.mp4"/>
      <doi>10.18653/v1/2023.findings-eacl.65</doi>
    </paper>
    <paper id="66">
      <title><fixed-case>M</fixed-case>ulti<fixed-case>F</fixed-case>in: A Dataset for Multilingual Financial <fixed-case>NLP</fixed-case></title>
      <author><first>Rasmus</first><last>Jørgensen</last><affiliation>University of Copenhagen, UCPH</affiliation></author>
      <author><first>Oliver</first><last>Brandt</last><affiliation>Independent researcher</affiliation></author>
      <author><first>Mareike</first><last>Hartmann</last><affiliation>Saarland University</affiliation></author>
      <author><first>Xiang</first><last>Dai</last><affiliation>CSIRO Data61</affiliation></author>
      <author><first>Christian</first><last>Igel</last><affiliation>University of Copenhagen</affiliation></author>
      <author><first>Desmond</first><last>Elliott</last><affiliation>University of Copenhagen</affiliation></author>
      <pages>894-909</pages>
      <abstract>Financial information is generated and distributed across the world, resulting in a vast amount of domain-specific multilingual data. Multilingual models adapted to the financial domain would ease deployment when an organization needs to work with multiple languages on a regular basis. For the development and evaluation of such models, there is a need for multilingual financial language processing datasets. We describe MultiFin – a publicly available financial dataset consisting of real-world article headlines covering 15 languages across different writing systems and language families. The dataset consists of hierarchical label structure providing two classification tasks: multi-label and multi-class. We develop our annotation schema based on a real-world application and annotate our dataset using both ‘label by native-speaker’ and ‘translate-then-label’ approaches. The evaluation of several popular multilingual models, e.g., mBERT, XLM-R, and mT5, show that although decent accuracy can be achieved in high-resource languages, there is substantial room for improvement in low-resource languages.</abstract>
      <url hash="a16a2890">2023.findings-eacl.66</url>
      <bibkey>jorgensen-etal-2023-multifin</bibkey>
      <video href="2023.findings-eacl.66.mp4"/>
      <doi>10.18653/v1/2023.findings-eacl.66</doi>
    </paper>
    <paper id="67">
      <title><fixed-case>MLASK</fixed-case>: Multimodal Summarization of Video-based News Articles</title>
      <author><first>Mateusz</first><last>Krubiński</last><affiliation>Charles University</affiliation></author>
      <author><first>Pavel</first><last>Pecina</last><affiliation>Charles University</affiliation></author>
      <pages>910-924</pages>
      <abstract>In recent years, the pattern of news consumption has been changing. The most popular multimedia news formats are now multimodal - the reader is often presented not only with a textual article but also with a short, vivid video. To draw the attention of the reader, such video-based articles are usually presented as a short textual summary paired with an image thumbnail. In this paper, we introduce MLASK (MultimodaL Article Summarization Kit) - a new dataset of video-based news articles paired with a textual summary and a cover picture, all obtained by automatically crawling several news websites. We demonstrate how the proposed dataset can be used to model the task of multimodal summarization by training a Transformer-based neural model. We also examine the effects of pre-training when the usage of generative pre-trained language models helps to improve the model performance, but (additional) pre-training on the simpler task of text summarization yields even better results. Our experiments suggest that the benefits of pre-training and using additional modalities in the input are not orthogonal.</abstract>
      <url hash="7fb171fd">2023.findings-eacl.67</url>
      <bibkey>krubinski-pecina-2023-mlask</bibkey>
      <video href="2023.findings-eacl.67.mp4"/>
      <doi>10.18653/v1/2023.findings-eacl.67</doi>
    </paper>
    <paper id="68">
      <title>Going beyond research datasets: Novel intent discovery in the industry setting</title>
      <author><first>Aleksandra</first><last>Chrabrowa</last><affiliation>Allegro Machine Learning Research</affiliation></author>
      <author><first>Tsimur</first><last>Hadeliya</last><affiliation>Allegro Sp. z o.o.</affiliation></author>
      <author><first>Dariusz</first><last>Kajtoch</last><affiliation>Allegro sp. z o.o.</affiliation></author>
      <author><first>Robert</first><last>Mroczkowski</last><affiliation>Allegro SP. Z O.O.</affiliation></author>
      <author><first>Piotr</first><last>Rybak</last><affiliation>Institute of Computer Science, Polish Academy of Sciences</affiliation></author>
      <pages>925-941</pages>
      <abstract>Novel intent discovery automates the process of grouping similar messages (questions) to identify previously unknown intents. However, current research focuses on publicly available datasets which have only the question field and significantly differ from real-life datasets. This paper proposes methods to improve the intent discovery pipeline deployed in a large e-commerce platform. We show the benefit of pre-training language models on in-domain data: both self-supervised and with weak supervision. We also devise the best method to utilize the conversational structure (i.e., question and answer) of real-life datasets during fine-tuning for clustering tasks, which we call Conv. All our methods combined to fully utilize real-life datasets give up to 33pp performance boost over state-of-the-art Constrained Deep Adaptive Clustering (CDAC) model for question only. By comparison CDAC model for the question data only gives only up to 13pp performance boost over the naive baseline.</abstract>
      <url hash="c1dcfdec">2023.findings-eacl.68</url>
      <bibkey>chrabrowa-etal-2023-going</bibkey>
      <video href="2023.findings-eacl.68.mp4"/>
      <doi>10.18653/v1/2023.findings-eacl.68</doi>
    </paper>
    <paper id="69">
      <title><fixed-case>DATS</fixed-case>core: Evaluating Translation with Data Augmented Translations</title>
      <author><first>Moussa</first><last>Kamal Eddine</last><affiliation>École polytechnique</affiliation></author>
      <author><first>Guokan</first><last>Shang</last><affiliation>Linagora</affiliation></author>
      <author><first>Michalis</first><last>Vazirgiannis</last><affiliation>Ecole Polytechnique</affiliation></author>
      <pages>942-952</pages>
      <abstract>The rapid development of large pretrained language models has revolutionized not only the field of Natural Language Generation (NLG) but also its evaluation. Inspired by the recent work of BARTScore: a metric leveraging the BART language model to evaluate the quality of generated text from various aspects, we introduce DATScore. DATScore uses data augmentation techniques to improve the evaluation of machine translation. Our main finding is that introducing data augmented translations of the source and reference texts is greatly helpful in evaluating the quality of the generated translation. We also propose two novel score averaging and term weighting strategies to improve the original score computing process of BARTScore. Experimental results on WMT show that DATScore correlates better with human meta-evaluations than the other recent state-of-the-art metrics, especially for low-resource languages. Ablation studies demonstrate the value added by our new scoring strategies. Moreover, we report in our extended experiments the performance of DATScore on 3 NLG tasks other than translation.</abstract>
      <url hash="89833e58">2023.findings-eacl.69</url>
      <bibkey>kamal-eddine-etal-2023-datscore</bibkey>
      <video href="2023.findings-eacl.69.mp4"/>
      <doi>10.18653/v1/2023.findings-eacl.69</doi>
    </paper>
    <paper id="70">
      <title>How do decoding algorithms distribute information in dialogue responses?</title>
      <author><first>Saranya</first><last>Venkatraman</last><affiliation>The Pennsylvania State University</affiliation></author>
      <author><first>He</first><last>He</last><affiliation>New York University</affiliation></author>
      <author><first>David</first><last>Reitter</last><affiliation>Google Research</affiliation></author>
      <pages>953-962</pages>
      <abstract>Humans tend to follow the Uniform Information Density (UID) principle by distributing information evenly in utterances. We study if decoding algorithms implicitly follow this UID principle, and under what conditions adherence to UID might be desirable for dialogue generation. We generate responses using different decoding algorithms with GPT-2 on the Persona-Chat dataset and collect human judgments on their quality using Amazon Mechanical Turk. We find that (i) surprisingly, model-generated responses follow the UID principle to a greater extent than human responses, and (ii) decoding algorithms that promote UID do not generate higher-quality responses. Instead, when we control for surprisal, non-uniformity of information density correlates with the quality of responses with very low/high surprisal. Our findings indicate that encouraging non-uniform responses is a potential solution to the “likelihood trap” problem (quality degradation in very high-likelihood text). Our dataset containing multiple candidate responses per dialog history along with human-annotated quality ratings is available at: <url>https://huggingface.co/datasets/saranya132/dialog_uid_gpt2</url>.</abstract>
      <url hash="495c58f4">2023.findings-eacl.70</url>
      <bibkey>venkatraman-etal-2023-decoding</bibkey>
      <video href="2023.findings-eacl.70.mp4"/>
      <doi>10.18653/v1/2023.findings-eacl.70</doi>
    </paper>
    <paper id="71">
      <title>Benchmarking Long-tail Generalization with Likelihood Splits</title>
      <author><first>Ameya</first><last>Godbole</last><affiliation>University of Southern California</affiliation></author>
      <author><first>Robin</first><last>Jia</last><affiliation>University of Southern California</affiliation></author>
      <pages>963-983</pages>
      <abstract>In order to reliably process natural language, NLP systems must generalize to the long tail of rare utterances. We propose a method to create challenging benchmarks that require generalizing to the tail of the distribution by re-splitting existing datasets. We create ‘Likelihood Splits’ where examples that are assigned lower likelihood by a pre-trained language model (LM) are placed in the test set, and more likely examples are in the training set. This simple approach can be customized to construct meaningful train-test splits for a wide range of tasks. Likelihood Splits surface more challenges than random splits: relative error rates of state-of-the-art models increase by 59% for semantic parsing on Spider, 93% for natural language inference on SNLI, and 33% for yes/no question answering on BoolQ, on our splits compared with the corresponding random splits. Moreover, Likelihood Splits create fairer benchmarks than adversarial filtering; when the LM used to create the splits is also employed as the task model, our splits do not unfairly penalize the LM.</abstract>
      <url hash="c3e991da">2023.findings-eacl.71</url>
      <bibkey>godbole-jia-2023-benchmarking</bibkey>
      <video href="2023.findings-eacl.71.mp4"/>
      <doi>10.18653/v1/2023.findings-eacl.71</doi>
    </paper>
    <paper id="72">
      <title>Exploring Enhanced Code-Switched Noising for Pretraining in Neural Machine Translation</title>
      <author><first>Vivek</first><last>Iyer</last><affiliation>The University of Edinburgh</affiliation></author>
      <author><first>Arturo</first><last>Oncevay</last><affiliation>The University of Edinburgh</affiliation></author>
      <author><first>Alexandra</first><last>Birch</last><affiliation>University of Edinburgh</affiliation></author>
      <pages>984-998</pages>
      <abstract>Multilingual pretraining approaches in Neural Machine Translation (NMT) have shown that training models to denoise synthetic code-switched data can yield impressive performance gains — owing to better multilingual semantic representations and transfer learning. However, they generated the synthetic code-switched data using non-contextual, one-to-one word translations obtained from lexicons - which can lead to significant noise in a variety of cases, including the poor handling of polysemes and multi-word expressions, violation of linguistic agreement and inability to scale to agglutinative languages. To overcome these limitations, we propose an approach called Contextual Code-Switching (CCS), where contextual, many-to-many word translations are generated using a ‘base’ NMT model. We conduct experiments on 3 different language families - Romance, Uralic, and Indo-Aryan - and show significant improvements (by up to 5.5 spBLEU points) over the previous lexicon-based SOTA approaches. We also observe that small CCS models can perform comparably or better than massive models like mBART50 and mRASP2, depending on the size of data provided. We empirically analyse several key factors responsible for these - including context, many-to-many substitutions, code-switching language count etc. - and prove that they all contribute to enhanced pretraining of multilingual NMT models.</abstract>
      <url hash="f593d081">2023.findings-eacl.72</url>
      <attachment type="software" hash="d4ce2bc3">2023.findings-eacl.72.software.zip</attachment>
      <bibkey>iyer-etal-2023-exploring</bibkey>
      <video href="2023.findings-eacl.72.mp4"/>
      <doi>10.18653/v1/2023.findings-eacl.72</doi>
    </paper>
    <paper id="73">
      <title><fixed-case>XQA</fixed-case>-<fixed-case>DST</fixed-case>: Multi-Domain and Multi-Lingual Dialogue State Tracking</title>
      <author><first>Han</first><last>Zhou</last><affiliation>University of Cambridge</affiliation></author>
      <author><first>Ignacio</first><last>Iacobacci</last><affiliation>Huawei Noah’s Ark Lab</affiliation></author>
      <author><first>Pasquale</first><last>Minervini</last><affiliation>Ucl</affiliation></author>
      <pages>999-1009</pages>
      <abstract>Dialogue State Tracking (DST), a crucial component of task-oriented dialogue (ToD) systems, keeps track of all important information pertaining to dialogue history: filling slots with the most probable values throughout the conversation. Existing methods generally rely on a predefined set of values and struggle to generalise to previously unseen slots in new domains. To overcome these challenges, we propose a domain-agnostic extractive question answering (QA) approach with shared weights across domains. To disentangle the complex domain information in ToDs, we train our DST with a novel domain filtering strategy by excluding out-of-domain question samples. With an independent classifier that predicts the presence of multiple domains given the context, our model tackles DST by extracting spans in active domains. Empirical results demonstrate that our model can efficiently leverage domain-agnostic QA datasets by two-stage fine-tuning while being both domain-scalable and open vocabulary in DST. It shows strong transferability by achieving zero-shot domain-adaptation results on MultiWOZ 2.1 with an average JGA of 36.7%. It further achieves cross-lingual transfer with state-of-the-art zero-shot results, 66.2% JGA from English to German and 75.7% JGA from English to Italian on WOZ 2.0.</abstract>
      <url hash="8d094ece">2023.findings-eacl.73</url>
      <bibkey>zhou-etal-2023-xqa</bibkey>
      <video href="2023.findings-eacl.73.mp4"/>
      <doi>10.18653/v1/2023.findings-eacl.73</doi>
    </paper>
    <paper id="74">
      <title>Improving Prediction Backward-Compatiblility in <fixed-case>NLP</fixed-case> Model Upgrade with Gated Fusion</title>
      <author><first>Yi-An</first><last>Lai</last><affiliation>Amazon</affiliation></author>
      <author><first>Elman</first><last>Mansimov</last><affiliation>Amazon Web Services</affiliation></author>
      <author><first>Yuqing</first><last>Xie</last><affiliation>The University of Waterloo</affiliation></author>
      <author><first>Yi</first><last>Zhang</last><affiliation>Amazon AI</affiliation></author>
      <pages>1010-1022</pages>
      <abstract>When upgrading neural models to a newer version, new errors that were not encountered in the legacy version can be introduced, known as regression errors. This inconsistent behavior during model upgrade often outweighs the benefits of accuracy gain and hinders the adoption of new models. To mitigate regression errors from model upgrade, distillation and ensemble have proven to be viable solutions without significant compromise in performance. Despite the progress, these approaches attained an incremental reduction in regression which is still far from achieving backward-compatible model upgrade. In this work, we propose a novel method, Gated Fusion, that promotes backward compatibility via learning to mix predictions between old and new models. Empirical results on two distinct model upgrade scenarios show that our method reduces the number of regression errors by 62% on average, outperforming the strongest baseline by an average of 25%.</abstract>
      <url hash="70552620">2023.findings-eacl.74</url>
      <bibkey>lai-etal-2023-improving</bibkey>
      <video href="2023.findings-eacl.74.mp4"/>
      <doi>10.18653/v1/2023.findings-eacl.74</doi>
    </paper>
    <paper id="75">
      <title><fixed-case>A</fixed-case>mbi<fixed-case>C</fixed-case>oref: Evaluating Human and Model Sensitivity to Ambiguous Coreference</title>
      <author><first>Yuewei</first><last>Yuan</last><affiliation>University of Pennsylvania</affiliation></author>
      <author><first>Chaitanya</first><last>Malaviya</last><affiliation>University of Pennsylvania</affiliation></author>
      <author><first>Mark</first><last>Yatskar</last><affiliation>University of Pennsylvania</affiliation></author>
      <pages>1023-1030</pages>
      <abstract>Given a sentence “Abby told Brittney that she upset Courtney”, one would struggle to understand who “she” refers to, and ask for clarification. However, if the word “upset” were replaced with “hugged”, “she” unambiguously refers to Abby. We study if modern coreference resolution models are sensitive to such pronominal ambiguity. To this end, we construct AmbiCoref, a diagnostic corpus of minimal sentence pairs with ambiguous and unambiguous referents. Our examples generalize psycholinguistic studies of human perception of ambiguity around particular arrangements of verbs and their arguments. Analysis shows that (1) humans are less sure of referents in ambiguous AmbiCoref examples than unambiguous ones, and (2) most coreference models show little difference in output between ambiguous and unambiguous pairs. We release AmbiCoref as a diagnostic corpus for testing whether models treat ambiguity similarly to humans.</abstract>
      <url hash="e613a4bd">2023.findings-eacl.75</url>
      <bibkey>yuan-etal-2023-ambicoref</bibkey>
      <video href="2023.findings-eacl.75.mp4"/>
      <doi>10.18653/v1/2023.findings-eacl.75</doi>
    </paper>
    <paper id="76">
      <title>Improving Unsupervised Out-of-domain detection through Pseudo Labeling and Learning</title>
      <author><first>Byounghan</first><last>Lee</last><affiliation>Department of Artificial Intelligence, Ajou university</affiliation></author>
      <author><first>Jaesik</first><last>Kim</last><affiliation>Department of Bioengineering, University of Pennsylvania</affiliation></author>
      <author><first>Junekyu</first><last>Park</last><affiliation>Superb AI</affiliation></author>
      <author><first>Kyung-Ah</first><last>Sohn</last><affiliation>Ajou University</affiliation></author>
      <pages>1031-1041</pages>
      <abstract>Unsupervised out-of-domain (OOD) detection is a task aimed at discriminating whether given samples are from the in-domain or not, without the categorical labels of in-domain instances. Unlike supervised OOD, as there are no labels for training a classifier, previous works on unsupervised OOD detection adopted the one-class classification (OCC) approach, assuming that the training samples come from a single domain. However, in-domain instances in many real world applications can have a heterogeneous distribution (i.e., across multiple domains or multiple classes). In this case, OCC methods have difficulty in reflecting the categorical information of the domain properly. To tackle this issue, we propose a two-stage framework that leverages the latent categorical information to improve representation learning for textual OOD detection. In the first stage, we train a transformer-based sentence encoder for pseudo labeling by contrastive loss and cluster loss. The second stage is pseudo label learning in which the model is re-trained with pseudo-labels obtained in the first stage. The empirical results on the three datasets show that our two-stage framework significantly outperforms baseline models in more challenging scenarios.</abstract>
      <url hash="ac84f823">2023.findings-eacl.76</url>
      <bibkey>lee-etal-2023-improving</bibkey>
      <video href="2023.findings-eacl.76.mp4"/>
      <doi>10.18653/v1/2023.findings-eacl.76</doi>
    </paper>
    <paper id="77">
      <title>How Many Data Samples is an Additional Instruction Worth?</title>
      <author><first>Ravsehaj Singh</first><last>Puri</last><affiliation>Arizona State University</affiliation></author>
      <author><first>Swaroop</first><last>Mishra</last><affiliation>Arizona State University</affiliation></author>
      <author><first>Mihir</first><last>Parmar</last><affiliation>Arizona State University</affiliation></author>
      <author><first>Chitta</first><last>Baral</last><affiliation>Arizona State University</affiliation></author>
      <pages>1042-1057</pages>
      <abstract>Recently introduced instruction-paradigm empowers non-expert users to leverage NLP resources by defining a new task in natural language. Instruction-tuned models have significantly outperformed multitask learning models (without instruction); however they are far from state-of-the-art task-specific models. Conventional approaches to improve model performance via creating datasets with large number of task instances or architectural changes in the model may not be feasible for non-expert users. However, they can write alternate instructions to represent an instruction task. Is Instruction-augmentation helpful? We augment a subset of tasks in the expanded version of NATURAL INSTRUCTIONS with additional instructions and find that it significantly improves model performance (up to 35%), especially in the low-data regime. Our results indicate that an additional instruction can be equivalent to ~200 data samples on average across tasks.</abstract>
      <url hash="c88278a7">2023.findings-eacl.77</url>
      <bibkey>puri-etal-2023-many</bibkey>
      <video href="2023.findings-eacl.77.mp4"/>
      <doi>10.18653/v1/2023.findings-eacl.77</doi>
    </paper>
    <paper id="78">
      <title>[<fixed-case>MASK</fixed-case>] Insertion: a robust method for anti-adversarial attacks</title>
      <author><first>Xinrong</first><last>Hu</last><affiliation>Wuhan Textile University</affiliation></author>
      <author><first>Ce</first><last>Xu</last><affiliation>Wuhan Textile University</affiliation></author>
      <author><first>Junlong</first><last>Ma</last><affiliation>Wuhan Textile University</affiliation></author>
      <author><first>Zijian</first><last>Huang</last><affiliation>Wuhan Textile University</affiliation></author>
      <author><first>Jie</first><last>Yang</last><affiliation>University of Wollongong</affiliation></author>
      <author><first>Yi</first><last>Guo</last><affiliation>Western Sydney University</affiliation></author>
      <author><first>Johan</first><last>Barthelemy</last><affiliation>Nvidia</affiliation></author>
      <pages>1058-1070</pages>
      <abstract>Adversarial attack aims to perturb input sequences and mislead a trained model for false predictions. To enhance the model robustness, defensing methods are accordingly employed by either data augmentation (involving adversarial samples) or model enhancement (modifying the training loss and/or model architecture). In contrast to previous work, this paper revisits the masked language modeling (MLM) and presents a simple yet efficient algorithm against adversarial attacks, termed [MASK] insertion for defensing (MI4D). Specifically, MI4D simply inserts [MASK] tokens to input sequences during training and inference, maximizing the intersection of the new convex hull (MI4D creates) with the original one (the clean input forms). As neither additional adversarial samples nor the model modification is required, MI4D is as computationally efficient as traditional fine-tuning. Comprehensive experiments have been conducted using three benchmark datasets and four attacking methods. MI4D yields a significant improvement (on average) of the accuracy between 3.2 and 11.1 absolute points when compared with six state-of-the-art defensing baselines.</abstract>
      <url hash="b5372da2">2023.findings-eacl.78</url>
      <bibkey>hu-etal-2023-mask</bibkey>
      <video href="2023.findings-eacl.78.mp4"/>
      <doi>10.18653/v1/2023.findings-eacl.78</doi>
    </paper>
    <paper id="79">
      <title><fixed-case>V</fixed-case>i<fixed-case>D</fixed-case>e<fixed-case>BERT</fixed-case>a: A powerful pre-trained language model for <fixed-case>V</fixed-case>ietnamese</title>
      <author><first>Cong Dao</first><last>Tran</last><affiliation>FPT Software AI Center</affiliation></author>
      <author><first>Nhut Huy</first><last>Pham</last><affiliation>FPT Software AI Center</affiliation></author>
      <author><first>Anh Tuan</first><last>Nguyen</last><affiliation>Microsoft</affiliation></author>
      <author><first>Truong Son</first><last>Hy</last><affiliation>University of California San Diego</affiliation></author>
      <author><first>Tu</first><last>Vu</last><affiliation>University of Massachusetts Amherst</affiliation></author>
      <pages>1071-1078</pages>
      <abstract>This paper presents ViDeBERTa, a new pre-trained monolingual language model for Vietnamese, with three versions - ViDeBERTa_xsmall, ViDeBERTa_base, and ViDeBERTa_large, which are pre-trained on a large-scale corpus of high-quality and diverse Vietnamese texts using DeBERTa architecture. Although many successful pre-trained language models based on Transformer have been widely proposed for the English language, there are still few pre-trained models for Vietnamese, a low-resource language, that perform good results on downstream tasks, especially Question answering. We fine-tune and evaluate our model on three important natural language downstream tasks, Part-of-speech tagging, Named-entity recognition, and Question answering. The empirical results demonstrate that ViDeBERTa with far fewer parameters surpasses the previous state-of-the-art models on multiple Vietnamese-specific natural language understanding tasks. Notably, ViDeBERTa_base with 86M parameters, which is only about 23% of PhoBERT_large with 370M parameters, still performs the same or better results than the previous state-of-the-art model. Our ViDeBERTa models are available at: <url>https://github.com/HySonLab/ViDeBERTa</url>.</abstract>
      <url hash="8cf0f7f1">2023.findings-eacl.79</url>
      <bibkey>tran-etal-2023-videberta</bibkey>
      <video href="2023.findings-eacl.79.mp4"/>
      <doi>10.18653/v1/2023.findings-eacl.79</doi>
    </paper>
    <paper id="80">
      <title><fixed-case>N</fixed-case>ap<fixed-case>SS</fixed-case>: Paragraph-level Medical Text Simplification via Narrative Prompting and Sentence-matching Summarization</title>
      <author><first>Junru</first><last>Lu</last><affiliation>University of Warwick</affiliation></author>
      <author><first>Jiazheng</first><last>Li</last><affiliation>King’s College London</affiliation></author>
      <author><first>Byron</first><last>Wallace</last><affiliation>Northeastern University</affiliation></author>
      <author><first>Yulan</first><last>He</last><affiliation>King’s College London</affiliation></author>
      <author><first>Gabriele</first><last>Pergola</last><affiliation>University of Warwick</affiliation></author>
      <pages>1079-1091</pages>
      <abstract>Accessing medical literature is difficult for laypeople as the content is written for specialists and contains medical jargon. Automated text simplification methods offer a potential means to address this issue. In this work, we propose a summarize-then-simplify two-stage strategy, which we call NapSS, identifying the relevant content to simplify while ensuring that the original narrative flow is preserved. In this approach, we first generate reference summaries via sentence matching between the original and the simplified abstracts. These summaries are then used to train an extractive summarizer, learning the most relevant content to be simplified. Then, to ensure the narrative consistency of the simplified text, we synthesize auxiliary narrative prompts combining key phrases derived from the syntactical analyses of the original text. Our model achieves results significantly better than the seq2seq baseline on an English medical corpus, yielding 3% 4% absolute improvements in terms of lexical similarity, and providing a further 1.1% improvement of SARI score when combined with the baseline. We also highlight shortcomings of existing evaluation methods, and introduce new metrics that take into account both lexical and high-level semantic similarity. A human evaluation conducted on a random sample of the test set further establishes the effectiveness of the proposed approach. Codes and models are released here: <url>https://github.com/LuJunru/NapSS</url>.</abstract>
      <url hash="8f0ddbee">2023.findings-eacl.80</url>
      <bibkey>lu-etal-2023-napss</bibkey>
      <video href="2023.findings-eacl.80.mp4"/>
      <doi>10.18653/v1/2023.findings-eacl.80</doi>
    </paper>
    <paper id="81">
      <title>Long-tailed Extreme Multi-label Text Classification by the Retrieval of Generated Pseudo Label Descriptions</title>
      <author><first>Ruohong</first><last>Zhang</last><affiliation>Carnegie Mellon University</affiliation></author>
      <author><first>Yau-Shian</first><last>Wang</last><affiliation>Amazon</affiliation></author>
      <author><first>Yiming</first><last>Yang</last><affiliation>Carnegie Mellon University</affiliation></author>
      <author><first>Donghan</first><last>Yu</last><affiliation>Carnegine Mellon University</affiliation></author>
      <author><first>Tom</first><last>Vu</last><affiliation>Flexport</affiliation></author>
      <author><first>Likun</first><last>Lei</last><affiliation>Flexport</affiliation></author>
      <pages>1092-1106</pages>
      <abstract>Extreme Multi-label Text Classification (XMTC) has been a tough challenge in machine learning research and applications due to the sheer sizes of the label spaces and the severe data scarcity problem associated with the long tail of rare labels in highly skewed distributions. This paper addresses the challenge of tail label prediction by leveraging the power of dense neural retrieval model in mapping input documents (as queries) to relevant label descriptions. To further enhance the quality of label descriptions, we propose to generate pseudo label descriptions from a trained bag-of-words (BoW) classifier, which demonstrates better classification performance under severe scarce data conditions. The proposed approach achieves the state-of-the-art (SOTA) performance of overall label prediction on XMTC benchmark datasets and especially outperforms the SOTA models in the tail label prediction. We also provide a theoretical analysis for relating the BoW and neural models w.r.t. performance lower bound.</abstract>
      <url hash="e13dccf9">2023.findings-eacl.81</url>
      <bibkey>zhang-etal-2023-long</bibkey>
      <video href="2023.findings-eacl.81.mp4"/>
      <doi>10.18653/v1/2023.findings-eacl.81</doi>
    </paper>
    <paper id="82">
      <title>Unsupervised Keyphrase Extraction via Interpretable Neural Networks</title>
      <author><first>Rishabh</first><last>Joshi</last><affiliation>Google</affiliation></author>
      <author><first>Vidhisha</first><last>Balachandran</last><affiliation>Carnegie Mellon University</affiliation></author>
      <author><first>Emily</first><last>Saldanha</last><affiliation>Pacific Northwest National Laboratory</affiliation></author>
      <author><first>Maria</first><last>Glenski</last><affiliation>Pacific Northwest National Laboratory</affiliation></author>
      <author><first>Svitlana</first><last>Volkova</last><affiliation>Aptima Inc.</affiliation></author>
      <author><first>Yulia</first><last>Tsvetkov</last><affiliation>University of Washington</affiliation></author>
      <pages>1107-1119</pages>
      <abstract>Keyphrase extraction aims at automatically extracting a list of “important” phrases representing the key concepts in a document. Prior approaches for unsupervised keyphrase extraction resorted to heuristic notions of phrase importance via embedding clustering or graph centrality, requiring extensive domain expertise. Our work presents a simple alternative approach which defines keyphrases as document phrases that are salient for predicting the topic of the document. To this end, we propose INSPECT—an approach that uses self-explaining models for identifying influential keyphrases in a document by measuring the predictive impact of input phrases on the downstream task of the document topic classification. We show that this novel method not only alleviates the need for ad-hoc heuristics but also achieves state-of-the-art results in unsupervised keyphrase extraction in four datasets across two domains: scientific publications and news articles.</abstract>
      <url hash="2ec19953">2023.findings-eacl.82</url>
      <bibkey>joshi-etal-2023-unsupervised</bibkey>
      <video href="2023.findings-eacl.82.mp4"/>
      <doi>10.18653/v1/2023.findings-eacl.82</doi>
    </paper>
    <paper id="83">
      <title>Large Language Models are few(1)-shot Table Reasoners</title>
      <author><first>Wenhu</first><last>Chen</last><affiliation>University of Waterloo &amp; Google Research</affiliation></author>
      <pages>1120-1130</pages>
      <url hash="e86974fb">2023.findings-eacl.83</url>
      <bibkey>chen-2023-large</bibkey>
      <abstract>Recent literature has shown that large language models (LLMs) are generally excellent few-shot reasoners to solve text reasoning tasks. However, the capability of LLMs on table reasoning tasks is yet to be explored. In this paper, we aim at understanding how well LLMs can perform table-related tasks with few-shot in-context learning. Specifically, we evaluated LLMs on popular table QA and fact verification datasets like WikiTableQuestion, FetaQA, TabFact, and FEVEROUS and found that LLMs are competent at complex reasoning over table structures, though these models are not pre-trained on any table corpus. When combined with ‘chain of thoughts’ prompting, LLMs can achieve very strong performance with only a 1-shot demonstration, even on par with some SoTA models. We show that LLMs are even more competent at generating comprehensive long-form answers on FetaQA than tuned T5-large. We further manually studied the reasoning chains elicited from LLMs and found that these reasoning chains are highly consistent with the underlying semantic form. We believe that LLMs can serve as a simple yet generic baseline for future research. The code and data are released in <url>https://github.com/wenhuchen/TableCoT</url>.</abstract>
      <video href="2023.findings-eacl.83.mp4"/>
      <doi>10.18653/v1/2023.findings-eacl.83</doi>
    </paper>
    <paper id="84">
      <title>Realistic Citation Count Prediction Task for Newly Published Papers</title>
      <author><first>Jun</first><last>Hirako</last><affiliation>Nagoya University</affiliation></author>
      <author><first>Ryohei</first><last>Sasano</last><affiliation>Nagoya University</affiliation></author>
      <author><first>Koichi</first><last>Takeda</last><affiliation>Nagoya University</affiliation></author>
      <pages>1131-1141</pages>
      <abstract>Citation count prediction is the task of predicting the future citation counts of academic papers, which is particularly useful for estimating the future impacts of an ever-growing number of academic papers. Although there have been many studies on citation count prediction, they are not applicable to predicting the citation counts of newly published papers, because they assume the availability of future citation counts for papers that have not had enough time pass since publication. In this paper, we first identify problems in the settings of existing studies and introduce a realistic citation count prediction task that strictly uses information available at the time of a target paper’s publication. For realistic citation count prediction, we then propose two methods to leverage the citation counts of papers shortly after publication. Through experiments using papers collected from arXiv and bioRxiv, we demonstrate that our methods considerably improve the performance of citation count prediction for newly published papers in a realistic setting.</abstract>
      <url hash="7c867f32">2023.findings-eacl.84</url>
      <bibkey>hirako-etal-2023-realistic</bibkey>
      <video href="2023.findings-eacl.84.mp4"/>
      <doi>10.18653/v1/2023.findings-eacl.84</doi>
    </paper>
    <paper id="85">
      <title>“Why do <fixed-case>I</fixed-case> feel offended?” - <fixed-case>K</fixed-case>orean Dataset for Offensive Language Identification</title>
      <author><first>San-Hee</first><last>Park</last><affiliation>Korea University</affiliation></author>
      <author><first>Kang-Min</first><last>Kim</last><affiliation>The Catholic University of Korea</affiliation></author>
      <author><first>O-Joun</first><last>Lee</last><affiliation>The Catholic University of Korea</affiliation></author>
      <author><first>Youjin</first><last>Kang</last><affiliation>Korea University</affiliation></author>
      <author><first>Jaewon</first><last>Lee</last><affiliation>Department of Transdisciplinary Studies, Seoul National University</affiliation></author>
      <author><first>Su-Min</first><last>Lee</last><affiliation>The Catholic University of Korea</affiliation></author>
      <author><first>SangKeun</first><last>Lee</last><affiliation>Korea University</affiliation></author>
      <pages>1142-1153</pages>
      <abstract>Warning: This paper contains some offensive expressions. Offensive content is an unavoidable issue on social media. Most existing offensive language identification methods rely on the compilation of labeled datasets. However, existing methods rarely consider low-resource languages that have relatively less data available for training (e.g., Korean). To address these issues, we construct a novel KOrean Dataset for Offensive Language Identification (KODOLI). KODOLI comprises more fine-grained offensiveness categories (i.e., not offensive, likely offensive, and offensive) than existing ones. A likely offensive language refers to texts with implicit offensiveness or abusive language without offensive intentions. In addition, we propose two auxiliary tasks to help identify offensive languages: abusive language detection and sentiment analysis. We provide experimental results for baselines on KODOLI and observe that language models suffer from identifying “LIKELY” offensive statements. Quantitative results and qualitative analysis demonstrate that jointly learning offensive language, abusive language and sentiment information improves the performance of offensive language identification.</abstract>
      <url hash="19d300ea">2023.findings-eacl.85</url>
      <attachment type="dataset" hash="cc484a68">2023.findings-eacl.85.dataset.zip</attachment>
      <bibkey>park-etal-2023-feel</bibkey>
      <video href="2023.findings-eacl.85.mp4"/>
      <doi>10.18653/v1/2023.findings-eacl.85</doi>
    </paper>
    <paper id="86">
      <title>Empirical Investigation of Neural Symbolic Reasoning Strategies</title>
      <author><first>Yoichi</first><last>Aoki</last><affiliation>Tohoku University</affiliation></author>
      <author><first>Keito</first><last>Kudo</last><affiliation>Tohoku University</affiliation></author>
      <author><first>Tatsuki</first><last>Kuribayashi</last><affiliation>Tohoku University / Langsmith Inc.</affiliation></author>
      <author><first>Ana</first><last>Brassard</last><affiliation>RIKEN AIP / Tohoku University</affiliation></author>
      <author><first>Masashi</first><last>Yoshikawa</last><affiliation>Tohoku University</affiliation></author>
      <author><first>Keisuke</first><last>Sakaguchi</last><affiliation>Tohoku University</affiliation></author>
      <author><first>Kentaro</first><last>Inui</last><affiliation>Tohoku University / Riken</affiliation></author>
      <pages>1154-1162</pages>
      <abstract>Neural reasoning accuracy improves when generating intermediate reasoning steps. However, the source of this improvement is yet unclear. Here, we investigate and factorize the benefit of generating intermediate steps for symbolic reasoning. Specifically, we decompose the reasoning strategy w.r.t. step granularity and chaining strategy. With a purely symbolic numerical reasoning dataset (e.g., A=1, B=3, C=A+3, C?), we found that the choice of reasoning strategies significantly affects the performance, with the gap becoming even larger as the extrapolation length becomes longer. Surprisingly, we also found that certain configurations lead to nearly perfect performance, even in the case of length extrapolation. Our results indicate the importance of further exploring effective strategies for neural reasoning models.</abstract>
      <url hash="89f5ff67">2023.findings-eacl.86</url>
      <attachment type="software" hash="f143974b">2023.findings-eacl.86.software.zip</attachment>
      <bibkey>aoki-etal-2023-empirical</bibkey>
      <video href="2023.findings-eacl.86.mp4"/>
      <doi>10.18653/v1/2023.findings-eacl.86</doi>
    </paper>
    <paper id="87">
      <title>Analyzing the Effectiveness of the Underlying Reasoning Tasks in Multi-hop Question Answering</title>
      <author><first>Xanh</first><last>Ho</last><affiliation>National Institute of Informatics</affiliation></author>
      <author><first>Anh-Khoa</first><last>Duong Nguyen</last><affiliation>N/a</affiliation></author>
      <author><first>Saku</first><last>Sugawara</last><affiliation>National Institute of Informatics</affiliation></author>
      <author><first>Akiko</first><last>Aizawa</last><affiliation>National Institute of Informatics</affiliation></author>
      <pages>1163-1180</pages>
      <abstract>To explain the predicted answers and evaluate the reasoning abilities of models, several studies have utilized underlying reasoning (UR) tasks in multi-hop question answering (QA) datasets. However, it remains an open question as to how effective UR tasks are for the QA task when training models on both tasks in an end-to-end manner. In this study, we address this question by analyzing the effectiveness of UR tasks (including both sentence-level and entity-level tasks) in three aspects: (1) QA performance, (2) reasoning shortcuts, and (3) robustness. While the previous models have not been explicitly trained on an entity-level reasoning prediction task, we build a multi-task model that performs three tasks together: sentence-level supporting facts prediction, entity-level reasoning prediction, and answer prediction. Experimental results on 2WikiMultiHopQA and HotpotQA-small datasets reveal that (1) UR tasks can improve QA performance. Using four debiased datasets that are newly created, we demonstrate that (2) UR tasks are helpful in preventing reasoning shortcuts in the multi-hop QA task. However, we find that (3) UR tasks do not contribute to improving the robustness of the model on adversarial questions, such as sub-questions and inverted questions. We encourage future studies to investigate the effectiveness of entity-level reasoning in the form of natural language questions (e.g., sub-question forms).</abstract>
      <url hash="df42e10e">2023.findings-eacl.87</url>
      <bibkey>ho-etal-2023-analyzing</bibkey>
      <video href="2023.findings-eacl.87.mp4"/>
      <doi>10.18653/v1/2023.findings-eacl.87</doi>
    </paper>
    <paper id="88">
      <title><fixed-case>P</fixed-case>ub<fixed-case>M</fixed-case>ed<fixed-case>CLIP</fixed-case>: How Much Does <fixed-case>CLIP</fixed-case> Benefit Visual Question Answering in the Medical Domain?</title>
      <author><first>Sedigheh</first><last>Eslami</last><affiliation>Hasso Plattner Institute</affiliation></author>
      <author><first>Christoph</first><last>Meinel</last><affiliation>Hasso Plattner Institute</affiliation></author>
      <author><first>Gerard</first><last>de Melo</last><affiliation>Hasso Plattner Institute, University of Potsdam</affiliation></author>
      <pages>1181-1193</pages>
      <abstract>Contrastive Language–Image Pre-training (CLIP) has shown remarkable success in learning with cross-modal supervision from extensive amounts of image–text pairs collected online. Thus far, the effectiveness of CLIP has been investigated primarily in general-domain multimodal problems. In this work, we evaluate the effectiveness of CLIP for the task of Medical Visual Question Answering (MedVQA). We present PubMedCLIP, a fine-tuned version of CLIP for the medical domain based on PubMed articles. Our experiments conducted on two MedVQA benchmark datasets illustrate that PubMedCLIP achieves superior results improving the overall accuracy up to 3% in comparison to the state-of-the-art Model-Agnostic Meta-Learning (MAML) networks pre-trained only on visual data. The PubMedCLIP model with different back-ends, the source code for pre-training them and reproducing our MedVQA pipeline is publicly available at <url>https://github.com/sarahESL/PubMedCLIP</url>.</abstract>
      <url hash="f7e9525d">2023.findings-eacl.88</url>
      <bibkey>eslami-etal-2023-pubmedclip</bibkey>
      <video href="2023.findings-eacl.88.mp4"/>
      <doi>10.18653/v1/2023.findings-eacl.88</doi>
    </paper>
    <paper id="89">
      <title>Multilingual <fixed-case>BERT</fixed-case> has an accent: Evaluating <fixed-case>E</fixed-case>nglish influences on fluency in multilingual models</title>
      <author><first>Isabel</first><last>Papadimitriou</last><affiliation>Stanford University</affiliation></author>
      <author><first>Kezia</first><last>Lopez</last><affiliation>Stanford University</affiliation></author>
      <author><first>Dan</first><last>Jurafsky</last><affiliation>Stanford University</affiliation></author>
      <pages>1194-1200</pages>
      <abstract>While multilingual language models can improve NLP performance on low-resource languages by leveraging higher-resource languages, they also reduce average performance on all languages (the ‘curse of multilinguality’). Here we show another problem with multilingual models: grammatical structures in higher-resource languages bleed into lower-resource languages, a phenomenon we call grammatical structure bias. We show this bias via a novel method for comparing the fluency of multilingual models to the fluency of monolingual Spanish and Greek models: testing their preference for two carefully-chosen variable grammatical structures (optional pronoun-drop in Spanish and optional Subject-Verb ordering in Greek). We find that multilingual BERT is biased toward the English-like setting (explicit pronouns and Subject-Verb-Object ordering) as compared to our monolingual control language model. With our case studies, we hope to bring to light the fine-grained ways in which multilingual models can be biased, and encourage more linguistically-aware fluency evaluation.</abstract>
      <url hash="4ce513fd">2023.findings-eacl.89</url>
      <bibkey>papadimitriou-etal-2023-multilingual</bibkey>
      <video href="2023.findings-eacl.89.mp4"/>
      <doi>10.18653/v1/2023.findings-eacl.89</doi>
    </paper>
    <paper id="90">
      <title>Reassessing Evaluation Practices in Visual Question Answering: A Case Study on Out-of-Distribution Generalization</title>
      <author><first>Aishwarya</first><last>Agrawal</last><affiliation>University of Montreal, Mila, DeepMind</affiliation></author>
      <author><first>Ivana</first><last>Kajic</last><affiliation>DeepMind</affiliation></author>
      <author><first>Emanuele</first><last>Bugliarello</last><affiliation>University of Copenhagen</affiliation></author>
      <author><first>Elnaz</first><last>Davoodi</last><affiliation>DeepMind</affiliation></author>
      <author><first>Anita</first><last>Gergely</last><affiliation>DeepMind</affiliation></author>
      <author><first>Phil</first><last>Blunsom</last><affiliation>University of Oxford</affiliation></author>
      <author><first>Aida</first><last>Nematzadeh</last><affiliation>DeepMind</affiliation></author>
      <pages>1201-1226</pages>
      <abstract>Vision-and-language (V&amp;L) models pretrained on large-scale multimodal data have demonstrated strong performance on various tasks such as image captioning and visual question answering (VQA). The quality of such models is commonly assessed by measuring their performance on unseen data that typically comes from the same distribution as the training data. However, when evaluated under out-of-distribution (out-of-dataset) settings for VQA, we observe that these models exhibit poor generalization. We comprehensively evaluate two pretrained V&amp;L models under different settings (i.e. classification and open-ended text generation) by conducting cross-dataset evaluations. We find that these models tend to learn to solve the benchmark, rather than learning the high-level skills required by the VQA task. We also find that in most cases generative models are less susceptible to shifts in data distribution compared to discriminative ones, and that multimodal pretraining is generally helpful for OOD generalization. Finally, we revisit assumptions underlying the use of automatic VQA evaluation metrics, and empirically show that their stringent nature repeatedly penalizes models for correct responses.</abstract>
      <url hash="77d51b13">2023.findings-eacl.90</url>
      <bibkey>agrawal-etal-2023-reassessing</bibkey>
      <video href="2023.findings-eacl.90.mp4"/>
      <doi>10.18653/v1/2023.findings-eacl.90</doi>
    </paper>
    <paper id="91">
      <title>Our kind of people? Detecting populist references in political debates</title>
      <author><first>Christopher</first><last>Klamm</last><affiliation>University of Mannheim</affiliation></author>
      <author><first>Ines</first><last>Rehbein</last><affiliation>University of Mannheim</affiliation></author>
      <author><first>Simone Paolo</first><last>Ponzetto</last><affiliation>University of Mannheim</affiliation></author>
      <pages>1227-1243</pages>
      <abstract>This paper investigates the identification of populist rhetoric in text and presents a novel cross-lingual dataset for this task. Our work is based on the definition of populism as a “communication style of political actors that refers to the people” but also includes anti-elitism as another core feature of populism. Accordingly, we annotate references to The People and The Elite in German and English parliamentary debates with a hierarchical scheme. The paper describes our dataset and annotation procedure and reports inter-annotator agreement for this task. Next, we compare and evaluate different transformer-based model architectures on a German dataset and report results for zero-shot learning on a smaller English dataset. We then show that semi-supervised tri-training can improve results in the cross-lingual setting. Our dataset can be used to investigate how political actors talk about The Elite and The People and to study how populist rhetoric is used as a strategic device.</abstract>
      <url hash="6abc8df2">2023.findings-eacl.91</url>
      <attachment type="dataset" hash="938ba72f">2023.findings-eacl.91.dataset.zip</attachment>
      <bibkey>klamm-etal-2023-kind</bibkey>
      <video href="2023.findings-eacl.91.mp4"/>
      <doi>10.18653/v1/2023.findings-eacl.91</doi>
    </paper>
    <paper id="92">
      <title><fixed-case>S</fixed-case>har<fixed-case>PT</fixed-case>: Shared Latent Space Prompt Tuning</title>
      <author><first>Bo</first><last>Pang</last><affiliation>Salesforce Research</affiliation></author>
      <author><first>Semih</first><last>Yavuz</last><affiliation>Salesforce Research</affiliation></author>
      <author><first>Caiming</first><last>Xiong</last><affiliation>Salesforce</affiliation></author>
      <author><first>Yingbo</first><last>Zhou</last><affiliation>Salesforce Research</affiliation></author>
      <pages>1244-1250</pages>
      <abstract>Prompt tuning is an efficient method for adapting large language models, and Soft Prompt Transfer (SPoT) further narrows the gap between prompt tuning and full model tuning by transferring prompts learned from source tasks to target tasks. It is nevertheless difficult and expensive to identify the source task that provides optimal prompts. In this work, we propose to learn a shared latent space which captures a set of basis skills from a mixture of source tasks. Given an instance, its embedding queries the latent space, yielding a basis skill vector. This vector generates soft prompts, via a lightweight prompt generator, which modulates a frozen model. The latent space and prompt transformation are learned end-to-end by training on source tasks. Transfer learning from source tasks to a target task simply amounts to finetuning the prompt generator, accounting for roughly 0.3% parameters of the frozen backbone model, while the shared latent space is also frozen in finetuning. Our approach outperforms prior soft prompt methods by a significant margin on a variety of tasks such as NLI, sentence completion, QA, conference resolution, word sense disambiguation. We also find, on various model scales, our method achieves competitive performance compared to finetuning the full model.</abstract>
      <url hash="e601eb41">2023.findings-eacl.92</url>
      <bibkey>pang-etal-2023-sharpt</bibkey>
      <doi>10.18653/v1/2023.findings-eacl.92</doi>
    </paper>
    <paper id="93">
      <title>Mini But Mighty: Efficient Multilingual Pretraining with Linguistically-Informed Data Selection</title>
      <author><first>Tolulope</first><last>Ogunremi</last><affiliation>Stanford University</affiliation></author>
      <author><first>Dan</first><last>Jurafsky</last><affiliation>Stanford University</affiliation></author>
      <author><first>Christopher</first><last>Manning</last><affiliation>Stanford University</affiliation></author>
      <pages>1251-1266</pages>
      <abstract>With the prominence of large pretrained language models, low-resource languages are rarely modelled monolingually and become victims of the “curse of multilinguality” in massively multilingual models. Recently, AfriBERTa showed that training transformer models from scratch on 1GB of data from many unrelated African languages outperforms massively multilingual models on downstream NLP tasks. Here we extend this direction, focusing on the use of related languages. We propose that training on smaller amounts of data but from related languages could match the performance of models trained on large, unrelated data. We test our hypothesis on the Niger-Congo family and its Bantu and Volta-Niger sub-families, pretraining models with data solely from Niger-Congo languages and finetuning on 4 downstream tasks: NER, part-of-speech tagging, sentiment analysis and text classification. We find that models trained on genetically related languages achieve equal performance on downstream tasks in low-resource languages despite using less training data. We recommend selecting training data based on language-relatedness when pretraining language models for low-resource languages.</abstract>
      <url hash="1229afc0">2023.findings-eacl.93</url>
      <bibkey>ogunremi-etal-2023-mini</bibkey>
      <video href="2023.findings-eacl.93.mp4"/>
      <doi>10.18653/v1/2023.findings-eacl.93</doi>
    </paper>
    <paper id="94">
      <title>Long Document Summarization with Top-down and Bottom-up Inference</title>
      <author><first>Bo</first><last>Pang</last><affiliation>Salesforce Research</affiliation></author>
      <author><first>Erik</first><last>Nijkamp</last><affiliation>Ucla</affiliation></author>
      <author><first>Wojciech</first><last>Kryscinski</last><affiliation>Salesforce Research</affiliation></author>
      <author><first>Silvio</first><last>Savarese</last><affiliation>Salesforce Research</affiliation></author>
      <author><first>Yingbo</first><last>Zhou</last><affiliation>Salesforce Research</affiliation></author>
      <author><first>Caiming</first><last>Xiong</last><affiliation>Salesforce</affiliation></author>
      <pages>1267-1284</pages>
      <abstract>Text summarization aims to condense long documents and retain key information. Critical to the success of a summarization model is the faithful inference of latent representations of words or tokens in the source documents. Most recent models infer the latent representations with a transformer encoder, which is purely bottom-up and thus does not capture long-distance context well. Also, self-attention-based models face the challenge of quadratic complexity with respect to sequence length. We propose a method to improve summarization models on these two aspects. Our method assumes a hierarchical latent structure of a document where the top-level captures the long range dependency at a coarser time scale and the bottom token level preserves the details. Critically, our method enables token representations to be updated in both a bottom-up and top-down manner. In the bottom-up pass, token representations are inferred with local self-attention to leverage its efficiency. Top-down correction is then applied to allow tokens to capture global context. We demonstrate the effectiveness on a diverse set of summarization datasets, including narrative, conversational, scientific documents and news. Our model achieves state-of-the-art performance on a wide range of long document summarization benchmarks, compared to recent efficient transformers. We show that our model can summarize an entire book and achieve competitive performance using 0.27% parameters and much less training data, compared to a recent GPT-3-based model. These results indicate the general applicability and benefits of the framework.</abstract>
      <url hash="a103e5fa">2023.findings-eacl.94</url>
      <bibkey>pang-etal-2023-long</bibkey>
      <doi>10.18653/v1/2023.findings-eacl.94</doi>
    </paper>
    <paper id="95">
      <title>Open Information Extraction with Entity Focused Constraints</title>
      <author><first>Prajna</first><last>Upadhyay</last><affiliation>Inria Saclay</affiliation></author>
      <author><first>Oana</first><last>Balalau</last><affiliation>Inria and Ecole Polytechnique</affiliation></author>
      <author><first>Ioana</first><last>Manolescu</last><affiliation>Inria and Ecole Polytechnique</affiliation></author>
      <pages>1285-1296</pages>
      <abstract>Open Information Extraction (OIE) is the task of extracting tuples of the form (subject, predicate, object), without any knowledge of the type and lexical form of the predicate, the subject, or the object. In this work, we focus on improving OIE quality by exploiting domain knowledge about the subject and object. More precisely, knowing that the subjects and objects in sentences are oftentimes named entities, we explore how to inject constraints in the extraction through constrained inference and constraint-aware training. Our work leverages the state-of-the-art OpenIE6 platform, which we adapt to our setting. Through a carefully constructed training dataset and constrained training, we obtain a 29.17% F1-score improvement in the CaRB metric and a 24.37% F1-score improvement in the WIRe57 metric. Our technique has important applications – one of them is investigative journalism, where automatically extracting conflict-of-interest between scientists and funding organizations helps understand the type of relations companies engage with the scientists.</abstract>
      <url hash="785c5846">2023.findings-eacl.95</url>
      <bibkey>upadhyay-etal-2023-open</bibkey>
      <video href="2023.findings-eacl.95.mp4"/>
      <doi>10.18653/v1/2023.findings-eacl.95</doi>
    </paper>
    <paper id="96">
      <title><fixed-case>H</fixed-case>ierarchical3<fixed-case>D</fixed-case> Adapters for Long Video-to-text Summarization</title>
      <author><first>Pinelopi</first><last>Papalampidi</last><affiliation>DeepMind</affiliation></author>
      <author><first>Mirella</first><last>Lapata</last><affiliation>School of Informatics, University of Edinburgh</affiliation></author>
      <pages>1297-1320</pages>
      <abstract>In this paper, we focus on video-to-text summarization and investigate how to best utilize multimodal information for summarizing long inputs (e.g., an hour-long TV show) into long outputs (e.g., a multi-sentence summary). We extend SummScreen (Chen et al., 2022), a dialogue summarization dataset consisting of transcripts of TV episodes with reference summaries, and create a multimodal variant by collecting corresponding full-length videos. We incorporate multimodal information into a pre-trained textual summarizer efficiently using adapter modules augmented with a hierarchical structure while tuning only 3.8% of model parameters. Our experiments demonstrate that multimodal information offers superior performance over more memory-heavy and fully fine-tuned textual summarization methods.</abstract>
      <url hash="9c7bdf10">2023.findings-eacl.96</url>
      <bibkey>papalampidi-lapata-2023-hierarchical3d</bibkey>
      <video href="2023.findings-eacl.96.mp4"/>
      <doi>10.18653/v1/2023.findings-eacl.96</doi>
    </paper>
    <paper id="97">
      <title>An Intra-Class Relation Guided Approach for Code Comment Generation</title>
      <author><first>Zhenni</first><last>Wang</last><affiliation>Peking University</affiliation></author>
      <author><first>Xiaohan</first><last>Yu</last><affiliation>Peking University</affiliation></author>
      <author><first>Yansong</first><last>Feng</last><affiliation>Peking University</affiliation></author>
      <author><first>Dongyan</first><last>Zhao</last><affiliation>Pku.edu.cn</affiliation></author>
      <pages>1321-1333</pages>
      <abstract>Code comments are critical for maintaining and comprehending software programs, but they are often missing, mismatched, or outdated in practice. Code comment generation task aims to automatically produce descriptive comments for code snippets. Recently, methods based on the neural encoder-decoder architecture have achieved impressive performance. These methods assume that all the information required to generate comments is encoded in the target function itself, yet in most realistic situations, it is hard to understand a function in isolation from the surrounding context. Furthermore, the global context may contain redundant information that should not be introduced. To address the above issues, we present a novel graph-based learning framework to capture various relations among functions in a class file. Our approach is based on a common real-world scenario in which only a few functions in the source file have human-written comments. Guided by intra-class function relations, our model incorporates contextual information extracted from both the source code and available comments to generate missing comments. We conduct experiments on a Java dataset collected from real-world projects. Experimental results show that the proposed method outperforms competitive baseline models on all automatic and human evaluation metrics.</abstract>
      <url hash="06c6c90d">2023.findings-eacl.97</url>
      <bibkey>wang-etal-2023-intra</bibkey>
      <video href="2023.findings-eacl.97.mp4"/>
      <doi>10.18653/v1/2023.findings-eacl.97</doi>
    </paper>
    <paper id="98">
      <title>Spelling convention sensitivity in neural language models</title>
      <author><first>Elizabeth</first><last>Nielsen</last><affiliation>University of Edinburgh</affiliation></author>
      <author><first>Christo</first><last>Kirov</last><affiliation>Google</affiliation></author>
      <author><first>Brian</first><last>Roark</last><affiliation>Google Inc.</affiliation></author>
      <pages>1334-1346</pages>
      <abstract>We examine whether large neural language models, trained on very large collections of varied English text, learn the potentially long-distance dependency of British versus American spelling conventions, i.e., whether spelling is consistently one or the other within model-generated strings. In contrast to long-distance dependencies in non-surface underlying structure (e.g., syntax), spelling consistency is easier to measure both in LMs and the text corpora used to train them, which can provide additional insight into certain observed model behaviors. Using a set of probe words unique to either British or American English, we first establish that training corpora exhibit substantial (though not total) consistency. A large T5 language model does appear to internalize this consistency, though only with respect to observed lexical items (not nonce words with British/American spelling patterns). We further experiment with correcting for biases in the training data by fine-tuning T5 on synthetic data that has been debiased, and find that finetuned T5 remains only somewhat sensitive to spelling consistency. Further experiments show GPT2 to be similarly limited.</abstract>
      <url hash="3310ebab">2023.findings-eacl.98</url>
      <bibkey>nielsen-etal-2023-spelling</bibkey>
      <video href="2023.findings-eacl.98.mp4"/>
      <doi>10.18653/v1/2023.findings-eacl.98</doi>
    </paper>
    <paper id="99">
      <title>Modelling Language Acquisition through Syntactico-Semantic Pattern Finding</title>
      <author><first>Jonas</first><last>Doumen</last><affiliation>KU Leuven, imec research group itec</affiliation></author>
      <author><first>Katrien</first><last>Beuls</last><affiliation>Faculté d’informatique, University of Namur</affiliation></author>
      <author><first>Paul</first><last>Van Eecke</last><affiliation>Artificial Intelligence Lab - Vrije Universiteit Brussel</affiliation></author>
      <pages>1347-1357</pages>
      <abstract>Usage-based theories of language acquisition have extensively documented the processes by which children acquire language through communicative interaction. Notably, Tomasello (2003) distinguishes two main cognitive capacities that underlie human language acquisition: intention reading and pattern finding. Intention reading is the process by which children try to continuously reconstruct the intended meaning of their interlocutors. Pattern finding refers to the process that allows them to distil linguistic schemata from multiple communicative interactions. Even though the fields of cognitive science and psycholinguistics have studied these processes in depth, no faithful computational operationalisations of these mechanisms through which children learn language exist to date. The research on which we report in this paper aims to fill part of this void by introducing a computational operationalisation of syntactico-semantic pattern finding. Concretely, we present a methodology for learning grammars based on similarities and differences in the form and meaning of linguistic observations alone. Our methodology is able to learn compositional lexical and item-based constructions of variable extent and degree of abstraction, along with a network of emergent syntactic categories. We evaluate our methodology on the CLEVR benchmark dataset and show that the methodology allows for fast, incremental and effective learning. The constructions and categorial network that result from the learning process are fully transparent and bidirectional, facilitating both language comprehension and production. Theoretically, our model provides computational evidence for the learnability of usage-based constructionist theories of language acquisition. Practically, the techniques that we present facilitate the learning of computationally tractable, usage-based construction grammars, which are applicable for natural language understanding and production tasks.</abstract>
      <url hash="21563627">2023.findings-eacl.99</url>
      <attachment type="dataset" hash="ad38bf7a">2023.findings-eacl.99.dataset.zip</attachment>
      <bibkey>doumen-etal-2023-modelling</bibkey>
      <video href="2023.findings-eacl.99.mp4"/>
      <doi>10.18653/v1/2023.findings-eacl.99</doi>
    </paper>
    <paper id="100">
      <title>Benchmark Data and Evaluation Framework for Intent Discovery Around <fixed-case>COVID</fixed-case>-19 Vaccine Hesitancy</title>
      <author><first>Shai</first><last>Gretz</last><affiliation>IBM Research</affiliation></author>
      <author><first>Assaf</first><last>Toledo</last><affiliation>IBM Research</affiliation></author>
      <author><first>Roni</first><last>Friedman</last><affiliation>IBM Research</affiliation></author>
      <author><first>Dan</first><last>Lahav</last><affiliation>IBM Research</affiliation></author>
      <author><first>Rose</first><last>Weeks</last><affiliation>Johns Hopkins Bloomberg School of Public Health</affiliation></author>
      <author><first>Naor</first><last>Bar-Zeev</last><affiliation>Johns Hopkins University</affiliation></author>
      <author><first>João</first><last>Sedoc</last><affiliation>New York University</affiliation></author>
      <author><first>Pooja</first><last>Sangha</last><affiliation>Johns Hopkins University</affiliation></author>
      <author><first>Yoav</first><last>Katz</last><affiliation>IBM Research AI</affiliation></author>
      <author><first>Noam</first><last>Slonim</last><affiliation>IBM Research</affiliation></author>
      <pages>1358-1370</pages>
      <abstract>The COVID-19 pandemic has made a huge global impact and cost millions of lives. As COVID-19 vaccines were rolled out, they were quickly met with widespread hesitancy. To address the concerns of hesitant people, we launched VIRA, a public dialogue system aimed at addressing questions and concerns surrounding the COVID-19 vaccines. Here, we release VIRADialogs, a dataset of over 8k dialogues conducted by actual users with VIRA, providing a unique real-world conversational dataset. In light of rapid changes in users’ intents, due to updates in guidelines or in response to new information, we highlight the important task of intent discovery in this use-case. We introduce a novel automatic evaluation framework for intent discovery, leveraging the existing intent classifier of VIRA. We use this framework to report baseline intent discovery results over VIRADialogs, that highlight the difficulty of this task.</abstract>
      <url hash="c7ed9889">2023.findings-eacl.100</url>
      <bibkey>gretz-etal-2023-benchmark</bibkey>
      <video href="2023.findings-eacl.100.mp4"/>
      <doi>10.18653/v1/2023.findings-eacl.100</doi>
    </paper>
    <paper id="101">
      <title>Learning Disentangled Representations for Natural Language Definitions</title>
      <author><first>Danilo</first><last>Silva De Carvalho</last><affiliation>University of Manchester</affiliation></author>
      <author><first>Giangiacomo</first><last>Mercatali</last><affiliation>University of Manchester</affiliation></author>
      <author><first>Yingji</first><last>Zhang</last><affiliation>The University of Manchester</affiliation></author>
      <author><first>André</first><last>Freitas</last><affiliation>University of Manchester</affiliation></author>
      <pages>1371-1384</pages>
      <abstract>Disentangling the encodings of neural models is a fundamental aspect for improving interpretability, semantic control and downstream task performance in Natural Language Processing. Currently, most disentanglement methods are unsupervised or rely on synthetic datasets with known generative factors. We argue that recurrent syntactic and semantic regularities in textual data can be used to provide the models with both structural biases and generative factors. We leverage the semantic structures present in a representative and semantically dense category of sentence types, definitional sentences, for training a Variational Autoencoder to learn disentangled representations. Our experimental results show that the proposed model outperforms unsupervised baselines on several qualitative and quantitative benchmarks for disentanglement, and it also improves the results in the downstream task of definition modeling.</abstract>
      <url hash="04379dee">2023.findings-eacl.101</url>
      <bibkey>silva-de-carvalho-etal-2023-learning</bibkey>
      <video href="2023.findings-eacl.101.mp4"/>
      <doi>10.18653/v1/2023.findings-eacl.101</doi>
    </paper>
    <paper id="102">
      <title>Distinguishability Calibration to In-Context Learning</title>
      <author><first>Hongjing</first><last>Li</last><affiliation>Computer Science Department, the University of Warwick</affiliation></author>
      <author><first>Hanqi</first><last>Yan</last><affiliation>Computer Science Department, University of Warwick</affiliation></author>
      <author><first>Yanran</first><last>Li</last><affiliation>The Hong Kong Polytechnic University</affiliation></author>
      <author><first>Li</first><last>Qian</last><affiliation>XiaomiAI</affiliation></author>
      <author><first>Yulan</first><last>He</last><affiliation>King’s College London</affiliation></author>
      <author><first>Lin</first><last>Gui</last><affiliation>King’s College London</affiliation></author>
      <pages>1385-1397</pages>
      <abstract>Recent years have witnessed increasing interests in prompt-based learning in which models can be trained on only a few annotated instances, making them suitable in low-resource settings. It is even challenging in fine-grained classification as the pre-trained language models tend to generate similar output embedding which makes it difficult to discriminate for the prompt-based classifier. In this work, we alleviate this information diffusion issue by proposing a calibration method based on a transformation which rotates the embedding feature into a new metric space where we adapt the ratio of each dimension to a uniform distribution to guarantee the distinguishability of learned embeddings. Furthermore, we take the advantage of hyperbolic embedding to capture the relation between dimensions by a coarse-fine metric learning strategy to enhance interpretability. Extensive experiments on the three datasets under various settings demonstrate the effectiveness of our approach.</abstract>
      <url hash="f217d318">2023.findings-eacl.102</url>
      <bibkey>li-etal-2023-distinguishability</bibkey>
      <video href="2023.findings-eacl.102.mp4"/>
      <doi>10.18653/v1/2023.findings-eacl.102</doi>
    </paper>
    <paper id="103">
      <title>Investigating anatomical bias in clinical machine learning algorithms</title>
      <author><first>Jannik</first><last>Pedersen</last><affiliation>University of Southern Denmark</affiliation></author>
      <author><first>Martin</first><last>Laursen</last><affiliation>University of Southern Denmark</affiliation></author>
      <author><first>Pernille</first><last>Vinholt</last><affiliation>Odense University Hospital</affiliation></author>
      <author><first>Anne</first><last>Alnor</last><affiliation>Odense University Hospital</affiliation></author>
      <author><first>Thiusius</first><last>Savarimuthu</last><affiliation>University of Southern Denmark</affiliation></author>
      <pages>1398-1410</pages>
      <abstract>Clinical machine learning algorithms have shown promising results and could potentially be implemented in clinical practice to provide diagnosis support and improve patient treatment. Barriers for realisation of the algorithms’ full potential include bias which is systematic and unfair discrimination against certain individuals in favor of others. The objective of this work is to measure anatomical bias in clinical text algorithms. We define anatomical bias as unfair algorithmic outcomes against patients with medical conditions in specific anatomical locations. We measure the degree of anatomical bias across two machine learning models and two Danish clinical text classification tasks, and find that clinical text algorithms are highly prone to anatomical bias. We argue that datasets for creating clinical text algorithms should be curated carefully to isolate the effect of anatomical location in order to avoid bias against patient subgroups.</abstract>
      <url hash="ae014a97">2023.findings-eacl.103</url>
      <attachment type="dataset" hash="f4aaa562">2023.findings-eacl.103.dataset.zip</attachment>
      <bibkey>pedersen-etal-2023-investigating</bibkey>
      <video href="2023.findings-eacl.103.mp4"/>
      <doi>10.18653/v1/2023.findings-eacl.103</doi>
    </paper>
    <paper id="104">
      <title>Topic Ontologies for Arguments</title>
      <author><first>Yamen</first><last>Ajjour</last><affiliation>Leipzig University, Bauhaus-Universität Weimar</affiliation></author>
      <author><first>Johannes</first><last>Kiesel</last><affiliation>Bauhaus-Universität Weimar</affiliation></author>
      <author><first>Benno</first><last>Stein</last><affiliation>Bauhaus-Universität Weimar</affiliation></author>
      <author><first>Martin</first><last>Potthast</last><affiliation>Leipzig University</affiliation></author>
      <pages>1411-1427</pages>
      <abstract>Many computational argumentation tasks, such as stance classification, are topic-dependent: The effectiveness of approaches to these tasks depends largely on whether they are trained with arguments on the same topics as those on which they are tested. The key question is: What are these training topics? To answer this question, we take the first step of mapping the argumentation landscape with The Argument Ontology (TAO). TAO draws on three authoritative sources for argument topics: the World Economic Forum, Wikipedia’s list of controversial topics, and Debatepedia. By comparing the topics in our ontology with those in 59 argument corpora, we perform the first comprehensive assessment of their topic coverage. While TAO already covers most of the corpus topics, the corpus topics barely cover all the topics in TAO. This points to a new goal for corpus construction to achieve a broad topic coverage and thus better generalizability of computational argumentation approaches.</abstract>
      <url hash="f71acfa9">2023.findings-eacl.104</url>
      <bibkey>ajjour-etal-2023-topic</bibkey>
      <video href="2023.findings-eacl.104.mp4"/>
      <doi>10.18653/v1/2023.findings-eacl.104</doi>
    </paper>
    <paper id="105">
      <title>Longtonotes: <fixed-case>O</fixed-case>nto<fixed-case>N</fixed-case>otes with Longer Coreference Chains</title>
      <author><first>Kumar</first><last>Shridhar</last><affiliation>ETH Zürich</affiliation></author>
      <author><first>Nicholas</first><last>Monath</last><affiliation>Google</affiliation></author>
      <author><first>Raghuveer</first><last>Thirukovalluru</last><affiliation>University of Massachusetts Amherst</affiliation></author>
      <author><first>Alessandro</first><last>Stolfo</last><affiliation>ETH Zurich</affiliation></author>
      <author><first>Manzil</first><last>Zaheer</last><affiliation>Google Inc</affiliation></author>
      <author><first>Andrew</first><last>McCallum</last><affiliation>UMass Amherst</affiliation></author>
      <author><first>Mrinmaya</first><last>Sachan</last><affiliation>ETH Zurich</affiliation></author>
      <pages>1428-1442</pages>
      <abstract>Ontonotes has served as the most important benchmark for coreference resolution. However, for ease of annotation, several long documents in Ontonotes were split into smaller parts. In this work, we build a corpus of coreference-annotated documents of significantly longer length than what is currently available. We do so by providing an accurate, manually-curated, merging of annotations from documents that were split into multiple parts in the original Ontonotes annotation process. The resulting corpus, which we call LongtoNotes contains documents in multiple genres of the English language with varying lengths, the longest of which are up to 8x the length of documents in Ontonotes, and 2x those in Litbank.We evaluate state-of-the-art neural coreference systems on this new corpus, analyze the relationships between model architectures/hyperparameters and document length on performance and efficiency of the models, and demonstrate areas of improvement in long-document coreference modelling revealed by our new corpus.</abstract>
      <url hash="5a212498">2023.findings-eacl.105</url>
      <bibkey>shridhar-etal-2023-longtonotes</bibkey>
      <doi>10.18653/v1/2023.findings-eacl.105</doi>
    </paper>
    <paper id="106">
      <title>More Robust Schema-Guided Dialogue State Tracking via Tree-Based Paraphrase Ranking</title>
      <author><first>Alexandru</first><last>Coca</last><affiliation>University Cambridge</affiliation></author>
      <author><first>Bo-Hsiang</first><last>Tseng</last><affiliation>Apple</affiliation></author>
      <author><first>Weizhe</first><last>Lin</last><affiliation>University of Cambridge</affiliation></author>
      <author id="bill-byrne"><first>Bill</first><last>Byrne</last><affiliation>University of Cambridge</affiliation></author>
      <pages>1443-1454</pages>
      <abstract>The schema-guided paradigm overcomes scalability issues inherent in building task-oriented dialogue (TOD) agents with static ontologies. Rather than operating on dialogue context alone, agents have access to hierarchical schemas containing task-relevant natural language descriptions. Fine-tuned language models excel at schema-guided dialogue state tracking (DST) but are sensitive to the writing style of the schemas. We explore methods for improving the robustness of DST models. We propose a framework for generating synthetic schemas which uses tree-based ranking to jointly optimise lexical diversity and semantic faithfulness. The robust generalisation of strong baselines is improved when augmenting their training data with prompts generated by our framework, as demonstrated by marked improvements in average Joint Goal Accuracy (JGA) and schema sensitivity (SS) on the SGD-X benchmark.</abstract>
      <url hash="0103498c">2023.findings-eacl.106</url>
      <bibkey>coca-etal-2023-robust</bibkey>
      <video href="2023.findings-eacl.106.mp4"/>
      <doi>10.18653/v1/2023.findings-eacl.106</doi>
    </paper>
    <paper id="107">
      <title>Language Model Decoding as Likelihood–Utility Alignment</title>
      <author><first>Martin</first><last>Josifoski</last><affiliation>Ecole Polytechnique Federale de Lausane</affiliation></author>
      <author><first>Maxime</first><last>Peyrard</last><affiliation>Epfl</affiliation></author>
      <author><first>Frano</first><last>Rajič</last><affiliation>Swiss Federal Institute of Technology Lausanne</affiliation></author>
      <author><first>Jiheng</first><last>Wei</last><affiliation>PSL University</affiliation></author>
      <author><first>Debjit</first><last>Paul</last><affiliation>Epfl</affiliation></author>
      <author><first>Valentin</first><last>Hartmann</last><affiliation>Epfl</affiliation></author>
      <author><first>Barun</first><last>Patra</last><affiliation>Microsoft</affiliation></author>
      <author><first>Vishrav</first><last>Chaudhary</last><affiliation>Microsoft</affiliation></author>
      <author><first>Emre</first><last>Kiciman</last><affiliation>Microsoft Research</affiliation></author>
      <author><first>Boi</first><last>Faltings</last><affiliation>Epfl</affiliation></author>
      <pages>1455-1470</pages>
      <abstract>A critical component of a successful language generation pipeline is the decoding algorithm. However, the general principles that should guide the choice of a decoding algorithm remain unclear. Previous works only compare decoding algorithms in narrow scenarios, and their findings do not generalize across tasks. We argue that the misalignment between the model’s likelihood and the task-specific notion of utility is the key factor in understanding the effectiveness of decoding algorithms. To structure the discussion, we introduce a taxonomy of misalignment mitigation strategies (MMSs), providing a unifying view of decoding as a tool for alignment. The MMS taxonomy groups decoding algorithms based on their implicit assumptions about likelihood–utility misalignment, yielding general statements about their applicability across tasks. Specifically, by analyzing the correlation between the likelihood and the utility of predictions across a diverse set of tasks, we provide empirical evidence supporting the proposed taxonomy and a set of principles to structure reasoning when choosing a decoding algorithm. Crucially, our analysis is the first to relate likelihood-based decoding algorithms with algorithms that rely on external information, such as value-guided methods and prompting, and covers the most diverse set of tasks to date. Code, data, and models are available at <url>https://github.com/epfl-dlab/understanding-decoding</url>.</abstract>
      <url hash="95e9a5ad">2023.findings-eacl.107</url>
      <bibkey>josifoski-etal-2023-language</bibkey>
      <video href="2023.findings-eacl.107.mp4"/>
      <doi>10.18653/v1/2023.findings-eacl.107</doi>
    </paper>
    <paper id="108">
      <title>Lightweight Spatial Modeling for Combinatorial Information Extraction From Documents</title>
      <author><first>Yanfei</first><last>Dong</last><affiliation>National University of Singapore</affiliation></author>
      <author><first>Lambert</first><last>Deng</last><affiliation>PayPal</affiliation></author>
      <author><first>Jiazheng</first><last>Zhang</last><affiliation>PayPal</affiliation></author>
      <author><first>Xiaodong</first><last>Yu</last><affiliation>PayPal</affiliation></author>
      <author><first>Ting</first><last>Lin</last><affiliation>Nanyang Technology University</affiliation></author>
      <author><first>Francesco</first><last>Gelli</last><affiliation>PayPal</affiliation></author>
      <author><first>Soujanya</first><last>Poria</last><affiliation>Singapore University of Technology and Design</affiliation></author>
      <author><first>Wee Sun</first><last>Lee</last><affiliation>National University of Singapore</affiliation></author>
      <pages>1471-1484</pages>
      <abstract>Documents that consist of diverse templates and exhibit complex spatial structures pose a challenge for document entity classification. We propose KNN-Former, which incorporates a new kind of spatial bias in attention calculation based on the K-nearest-neighbor (KNN) graph of document entities. We limit entities’ attention only to their local radius defined by the KNN graph. We also use combinatorial matching to address the one-to-one mapping property that exists in many documents, where one field has only one corresponding entity. Moreover, our method is highly parameter-efficient compared to existing approaches in terms of the number of trainable parameters. Despite this, experiments across various datasets show our method outperforms baselines in most entity types. Many real-world documents exhibit combinatorial properties which can be leveraged as inductive biases to improve extraction accuracy, but existing datasets do not cover these documents. To facilitate future research into these types of documents, we release a new ID document dataset that covers diverse templates and languages. We also release enhanced annotations for an existing dataset.</abstract>
      <url hash="82906c0d">2023.findings-eacl.108</url>
      <bibkey>dong-etal-2023-lightweight</bibkey>
      <video href="2023.findings-eacl.108.mp4"/>
      <doi>10.18653/v1/2023.findings-eacl.108</doi>
    </paper>
    <paper id="109">
      <title>On the Generalization Ability of Retrieval-Enhanced Transformers</title>
      <author><first>Tobias</first><last>Norlund</last><affiliation>Chalmers University of Technology / Recorded Future</affiliation></author>
      <author><first>Ehsan</first><last>Doostmohammadi</last><affiliation>Linköping University</affiliation></author>
      <author><first>Richard</first><last>Johansson</last><affiliation>University of Gothenburg</affiliation></author>
      <author><first>Marco</first><last>Kuhlmann</last><affiliation>Linköping University</affiliation></author>
      <pages>1485-1493</pages>
      <abstract>Recent work on the Retrieval-Enhanced Transformer (RETRO) model has shown impressive results: off-loading memory from trainable weights to a retrieval database can significantly improve language modeling and match the performance of non-retrieval models that are an order of magnitude larger in size. It has been suggested that at least some of this performance gain is due to non-trivial generalization based on both model weights and retrieval. In this paper, we try to better understand the relative contributions of these two components. We find that the performance gains from retrieval to a very large extent originate from overlapping tokens between the database and the test data, suggesting less of non-trivial generalization than previously assumed. More generally, our results point to the challenges of evaluating the generalization of retrieval-augmented language models such as RETRO, as even limited token overlap may significantly decrease test-time loss. We release our code and model at <url>https://github.com/TobiasNorlund/retro</url></abstract>
      <url hash="e06e0ed2">2023.findings-eacl.109</url>
      <bibkey>norlund-etal-2023-generalization</bibkey>
      <video href="2023.findings-eacl.109.mp4"/>
      <doi>10.18653/v1/2023.findings-eacl.109</doi>
    </paper>
    <paper id="110">
      <title>Assessing Monotonicity Reasoning in <fixed-case>D</fixed-case>utch through Natural Language Inference</title>
      <author><first>Gijs</first><last>Wijnholds</last><affiliation>Utrecht University</affiliation></author>
      <pages>1494-1500</pages>
      <abstract>In this paper we investigate monotonicity reasoning in Dutch, through a novel Natural Language Inference dataset. Monotonicity reasoning shows to be highly challenging for Transformer-based language models in English and here, we corroborate those findings using a parallel Dutch dataset, obtained by translating the Monotonicity Entailment Dataset of Yanaka et al. (2019). After fine-tuning two Dutch language models BERTje and RobBERT on the Dutch NLI dataset SICK-NL, we find that performance severely drops on the monotonicity reasoning dataset, indicating poor generalization capacity of the models. We provide a detailed analysis of the test results by means of the linguistic annotations in the dataset. We find that models struggle with downward entailing contexts, and argue that this is due to a poor understanding of negation. Additionally, we find that the choice of monotonicity context affects model performance on conjunction and disjunction. We hope that this new resource paves the way for further research in generalization of neural reasoning models in Dutch, and contributes to the development of better language technology for Natural Language Inference, specifically for Dutch.</abstract>
      <url hash="2c136d22">2023.findings-eacl.110</url>
      <attachment type="dataset" hash="73d0c51b">2023.findings-eacl.110.dataset.zip</attachment>
      <bibkey>wijnholds-2023-assessing</bibkey>
      <video href="2023.findings-eacl.110.mp4"/>
      <doi>10.18653/v1/2023.findings-eacl.110</doi>
    </paper>
    <paper id="111">
      <title>Noisy Parallel Data Alignment</title>
      <author><first>Ruoyu</first><last>Xie</last><affiliation>George Mason University</affiliation></author>
      <author><first>Antonios</first><last>Anastasopoulos</last><affiliation>George Mason University</affiliation></author>
      <pages>1501-1513</pages>
      <abstract>An ongoing challenge in current natural language processing is how its major advancements tend to disproportionately favor resource-rich languages, leaving a significant number of under-resourced languages behind. Due to the lack of resources required to train and evaluate models, most modern language technologies are either nonexistent or unreliable to process endangered, local, and non-standardized languages. Optical character recognition (OCR) is often used to convert endangered language documents into machine-readable data. However, such OCR output is typically noisy, and most word alignment models are not built to work under such noisy conditions. In this work, we study the existing word-level alignment models under noisy settings and aim to make them more robust to noisy data. Our noise simulation and structural biasing method, tested on multiple language pairs, manages to reduce the alignment error rate on a state-of-the-art neural-based alignment model up to 59.6%.</abstract>
      <url hash="a63ceef5">2023.findings-eacl.111</url>
      <bibkey>xie-anastasopoulos-2023-noisy</bibkey>
      <video href="2023.findings-eacl.111.mp4"/>
      <doi>10.18653/v1/2023.findings-eacl.111</doi>
    </paper>
    <paper id="112">
      <title>Enhancing Dialogue Generation with Conversational Concept Flows</title>
      <author><first>Siheng</first><last>Li</last><affiliation>Tsinghua Shenzhen International Graduate School, Tsinghua University</affiliation></author>
      <author><first>Wangjie</first><last>Jiang</last><affiliation>Tsinghua Shenzhen International Graduate School</affiliation></author>
      <author><first>Pengda</first><last>Si</last><affiliation>Tsinghua Shenzhen International Graduate School</affiliation></author>
      <author><first>Cheng</first><last>Yang</last><affiliation>Tsinghua Shenzhen International Graduate School</affiliation></author>
      <author><first>Qiu</first><last>Yao</last><affiliation>Tencent Inc, Beijing, China</affiliation></author>
      <author><first>Jinchao</first><last>Zhang</last><affiliation>Tencent Inc, Beijing, China</affiliation></author>
      <author><first>Jie</first><last>Zhou</last><affiliation>Tencent Inc, Beijing, China</affiliation></author>
      <author><first>Yujiu</first><last>Yang</last><affiliation>Tsinghua.edu.cn</affiliation></author>
      <pages>1514-1525</pages>
      <abstract>Human conversations contain natural and reasonable topic shifts, reflected as the concept flows across utterances. Previous researches prove that explicitly modeling concept flows with a large commonsense knowledge graph effectively improves response quality. However, we argue that there exists a gap between the knowledge graph and the conversation. The knowledge graph has limited commonsense knowledge and ignores the characteristics of natural conversations. Thus, many concepts and relations in conversations are not included. To bridge this gap, we propose to enhance dialogue generation with conversational concept flows. Specifically, we extract abundant concepts and relations from natural conversations and build a new conversation-aware knowledge graph. In addition, we design a novel relation-aware graph encoder to capture the concept flows guided by the knowledge graph. Experimental results on the large-scale Reddit conversation dataset indicate that our method performs better than strong baselines, andfurther analysis verifies the effectiveness of each component. All our code and data will be publicly available after acceptance.</abstract>
      <url hash="ba1de98b">2023.findings-eacl.112</url>
      <attachment type="software" hash="78809694">2023.findings-eacl.112.software.zip</attachment>
      <bibkey>li-etal-2023-enhancing</bibkey>
      <video href="2023.findings-eacl.112.mp4"/>
      <doi>10.18653/v1/2023.findings-eacl.112</doi>
    </paper>
    <paper id="113">
      <title><fixed-case>SMHD</fixed-case>-<fixed-case>GER</fixed-case>: A Large-Scale Benchmark Dataset for Automatic Mental Health Detection from Social Media in <fixed-case>G</fixed-case>erman</title>
      <author><first>Sourabh</first><last>Zanwar</last><affiliation>RWTH Aachen University</affiliation></author>
      <author><first>Daniel</first><last>Wiechmann</last><affiliation>Institute for Logic Language and Computation</affiliation></author>
      <author><first>Yu</first><last>Qiao</last><affiliation>RWTH-Achen</affiliation></author>
      <author><first>Elma</first><last>Kerz</last><affiliation>RWTH Aachen University</affiliation></author>
      <pages>1526-1541</pages>
      <abstract>Mental health problems are a challenge to our modern society, and their prevalence is predicted to increase worldwide. Recently, a surge of research has demonstrated the potential of automated detection of mental health conditions (MHC) through social media posts, with the ultimate goal of enabling early intervention and monitoring population-level health outcomes in real-time. Progress in this area of research is highly dependent on the availability of high-quality datasets and benchmark corpora. However, the publicly available datasets for understanding and modelling MHC are largely confined to the English language. In this paper, we introduce SMHD-GER (Self-Reported Mental Health Diagnoses for German), a large-scale, carefully constructed dataset for MHC detection built on high-precision patterns and the approach proposed for English. We provide benchmark models for this dataset to facilitate further research and conduct extensive experiments. These models leverage engineered (psycho-)linguistic features as well as BERT-German. We also examine nuanced patterns of linguistic markers characteristics of specific MHC.</abstract>
      <url hash="9f1a2a2c">2023.findings-eacl.113</url>
      <bibkey>zanwar-etal-2023-smhd</bibkey>
      <video href="2023.findings-eacl.113.mp4"/>
      <doi>10.18653/v1/2023.findings-eacl.113</doi>
    </paper>
    <paper id="114">
      <title>Exploring Data Augmentation for Code Generation Tasks</title>
      <author><first>Pinzhen</first><last>Chen</last><affiliation>University of Edinburgh</affiliation></author>
      <author><first>Gerasimos</first><last>Lampouras</last><affiliation>Huawei Noah’s Ark Lab</affiliation></author>
      <pages>1542-1550</pages>
      <abstract>Advances in natural language processing, such as transfer learning from pre-trained language models, have impacted how models are trained for programming language tasks too. Previous research primarily explored code pre-training and expanded it through multi-modality and multi-tasking, yet the data for downstream tasks remain modest in size. Focusing on data utilization for downstream tasks, we propose and adapt augmentation methods that yield consistent improvements in code translation and summarization by up to 6.9% and 7.5% respectively. Further analysis suggests that our methods work orthogonally and show benefits in output code style and numeric consistency. We also discuss test data imperfections.</abstract>
      <url hash="1fae719e">2023.findings-eacl.114</url>
      <bibkey>chen-lampouras-2023-exploring</bibkey>
      <video href="2023.findings-eacl.114.mp4"/>
      <doi>10.18653/v1/2023.findings-eacl.114</doi>
    </paper>
    <paper id="115">
      <title>Stabilized In-Context Learning with Pre-trained Language Models for Few Shot Dialogue State Tracking</title>
      <author><first>Derek</first><last>Chen</last><affiliation>Columbia University</affiliation></author>
      <author><first>Kun</first><last>Qian</last><affiliation>Columbia University</affiliation></author>
      <author><first>Zhou</first><last>Yu</last><affiliation>Columbia University</affiliation></author>
      <pages>1551-1564</pages>
      <abstract>Prompt-based methods with large pre-trained language models (PLMs) have shown impressive unaided performance across many NLP tasks. These models improve even further with the addition of a few labeled in-context exemplars to guide output generation. However, for more complex tasks such as dialogue state tracking (DST), designing prompts that reliably convey the desired intent is nontrivial, leading to unstable results. Furthermore, building in-context exemplars for dialogue tasks is difficult because conversational contexts are long while model input lengths are relatively short. To overcome these issues we first adapt a meta-learning scheme to the dialogue domain which stabilizes the ability of the model to perform well under various prompts. We additionally design a novel training method to improve upon vanilla retrieval mechanisms to find ideal in-context examples. Finally, we introduce a saliency model to limit dialogue text length, allowing us to include more exemplars per query. In effect, we are able to achieve highly competitive results for few-shot DST on MultiWOZ.</abstract>
      <url hash="f2a86463">2023.findings-eacl.115</url>
      <bibkey>chen-etal-2023-stabilized</bibkey>
      <video href="2023.findings-eacl.115.mp4"/>
      <doi>10.18653/v1/2023.findings-eacl.115</doi>
    </paper>
    <paper id="116">
      <title>Can Demographic Factors Improve Text Classification? Revisiting Demographic Adaptation in the Age of Transformers</title>
      <author><first>Chia-Chien</first><last>Hung</last><affiliation>University of Mannheim</affiliation></author>
      <author><first>Anne</first><last>Lauscher</last><affiliation>University of Hamburg</affiliation></author>
      <author><first>Dirk</first><last>Hovy</last><affiliation>Bocconi University</affiliation></author>
      <author><first>Simone Paolo</first><last>Ponzetto</last><affiliation>University of Mannheim</affiliation></author>
      <author><first>Goran</first><last>Glavaš</last><affiliation>University of Würzburg</affiliation></author>
      <pages>1565-1580</pages>
      <abstract>Demographic factors (e.g., gender or age) shape our language. Previous work showed that incorporating demographic factors can consistently improve performance for various NLP tasks with traditional NLP models. In this work, we investigate whether these previous findings still hold with state-of-the-art pretrained Transformer-based language models (PLMs). We use three common specialization methods proven effective for incorporating external knowledge into pretrained Transformers (e.g., domain-specific or geographic knowledge). We adapt the language representations for the demographic dimensions of gender and age, using continuous language modeling and dynamic multi-task learning for adaptation, where we couple language modeling objectives with the prediction of demographic classes. Our results, when employing a multilingual PLM, show substantial gains in task performance across four languages (English, German, French, and Danish), which is consistent with the results of previous work. However, controlling for confounding factors – primarily domain and language proficiency of Transformer-based PLMs – shows that downstream performance gains from our demographic adaptation do not actually stem from demographic knowledge. Our results indicate that demographic specialization of PLMs, while holding promise for positive societal impact, still represents an unsolved problem for (modern) NLP.</abstract>
      <url hash="4516c4d1">2023.findings-eacl.116</url>
      <bibkey>hung-etal-2023-demographic</bibkey>
      <video href="2023.findings-eacl.116.mp4"/>
      <doi>10.18653/v1/2023.findings-eacl.116</doi>
    </paper>
    <paper id="117">
      <title><fixed-case>JBL</fixed-case>i<fixed-case>MP</fixed-case>: <fixed-case>J</fixed-case>apanese Benchmark of Linguistic Minimal Pairs</title>
      <author><first>Taiga</first><last>Someya</last><affiliation>The University of Tokyo</affiliation></author>
      <author><first>Yohei</first><last>Oseki</last><affiliation>University of Tokyo</affiliation></author>
      <pages>1581-1594</pages>
      <abstract>In this paper, we introduce JBLiMP (Japanese Benchmark of Linguistic Minimal Pairs), a novel dataset for targeted syntactic evaluations of language models in Japanese. JBLiMP consists of 331 minimal pairs, which are created based on acceptability judgments extracted from journal articles in theoretical linguistics. These minimal pairs are grouped into 11 categories, each covering a different linguistic phenomenon. JBLiMP is unique in that it successfully combines two important features independently observed in existing datasets: (i) coverage of complex linguistic phenomena (cf. CoLA) and (ii) presentation of sentences as minimal pairs (cf. BLiMP). In addition, JBLiMP is the first dataset for targeted syntactic evaluations of language models in Japanese, thus allowing the comparison of syntactic knowledge of language models across different languages. We then evaluate the syntactic knowledge of several language models on JBLiMP: GPT-2, LSTM, and n-gram language models. The results demonstrated that all the architectures achieved comparable overall accuracies around 75%. Error analyses by linguistic phenomenon further revealed that these language models successfully captured local dependencies like nominal structures, but not long-distance dependencies such as verbal agreement and binding.</abstract>
      <url hash="f2dd9340">2023.findings-eacl.117</url>
      <bibkey>someya-oseki-2023-jblimp</bibkey>
      <video href="2023.findings-eacl.117.mp4"/>
      <doi>10.18653/v1/2023.findings-eacl.117</doi>
    </paper>
    <paper id="118">
      <title><fixed-case>SMATCH</fixed-case>++: Standardized and Extended Evaluation of Semantic Graphs</title>
      <author><first>Juri</first><last>Opitz</last><affiliation>Heidelberg University</affiliation></author>
      <pages>1595-1607</pages>
      <abstract>The Smatch metric is a popular method for evaluating graph distances, as is necessary, for instance, to assess the performance of semantic graph parsing systems. However, we observe some issues in the metric that jeopardize meaningful evaluation. E.g., opaque pre-processing choices can affect results, and current graph-alignment solvers do not provide us with upper-bounds. Without upper-bounds, however, fair evaluation is not guaranteed. Furthermore, adaptions of Smatch for extended tasks (e.g., fine-grained semantic similarity) are spread out, and lack a unifying framework. For better inspection, we divide the metric into three modules: pre-processing, alignment, and scoring. Examining each module, we specify its goals and diagnose potential issues, for which we discuss and test mitigation strategies. For pre-processing, we show how to fully conform to annotation guidelines that allow structurally deviating but valid graphs. For safer and enhanced alignment, we show the feasibility of optimal alignment in a standard evaluation setup, and develop a lossless graph compression method that shrinks the search space and significantly increases efficiency. For improved scoring, we propose standardized and extended metric calculation of fine-grained sub-graph meaning aspects. Our code is available at <url>https://github.com/flipz357/smatchpp</url></abstract>
      <url hash="250c3657">2023.findings-eacl.118</url>
      <bibkey>opitz-2023-smatch</bibkey>
      <video href="2023.findings-eacl.118.mp4"/>
      <doi>10.18653/v1/2023.findings-eacl.118</doi>
    </paper>
    <paper id="119">
      <title>An Extended Sequence Tagging Vocabulary for Grammatical Error Correction</title>
      <author><first>Stuart</first><last>Mesham</last><affiliation>University of Cambridge</affiliation></author>
      <author><first>Christopher</first><last>Bryant</last><affiliation>University of Cambridge</affiliation></author>
      <author><first>Marek</first><last>Rei</last><affiliation>Imperial College London</affiliation></author>
      <author><first>Zheng</first><last>Yuan</last><affiliation>King’s College London</affiliation></author>
      <pages>1608-1619</pages>
      <abstract>We extend a current sequence-tagging approach to Grammatical Error Correction (GEC) by introducing specialised tags for spelling correction and morphological inflection using the SymSpell and LemmInflect algorithms. Our approach improves generalisation: the proposed new tagset allows a smaller number of tags to correct a larger range of errors. Our results show a performance improvement both overall and in the targeted error categories. We further show that ensembles trained with our new tagset outperform those trained with the baseline tagset on the public BEA benchmark.</abstract>
      <url hash="5bba87a0">2023.findings-eacl.119</url>
      <attachment type="software" hash="6046b7c7">2023.findings-eacl.119.software.zip</attachment>
      <bibkey>mesham-etal-2023-extended</bibkey>
      <video href="2023.findings-eacl.119.mp4"/>
      <doi>10.18653/v1/2023.findings-eacl.119</doi>
    </paper>
    <paper id="120">
      <title>Cheating to Identify Hard Problems for Neural Machine Translation</title>
      <author><first>Proyag</first><last>Pal</last><affiliation>University of Edinburgh</affiliation></author>
      <author><first>Kenneth</first><last>Heafield</last><affiliation>University of Edinburgh</affiliation></author>
      <pages>1620-1631</pages>
      <abstract>We identify hard problems for neural machine translation models by analyzing progressively higher-scoring translations generated by letting models cheat to various degrees. If a system cheats and still gets something wrong, that suggests it is a hard problem. We experiment with two forms of cheating: providing the model a compressed representation of the target as an additional input, and fine-tuning on the test set. Contrary to popular belief, we find that the most frequent tokens are not necessarily the most accurately translated due to these often being function words and punctuation that can be used more flexibly in translation, or content words which can easily be paraphrased. We systematically analyze system outputs to identify categories of tokens which are particularly hard for the model to translate, and find that this includes certain types of named entities, subordinating conjunctions, and unknown and foreign words. We also encounter a phenomenon where words, often names, which were not infrequent in the training data are still repeatedly mistranslated by the models — we dub this the Fleetwood Mac problem.</abstract>
      <url hash="7c468a9e">2023.findings-eacl.120</url>
      <bibkey>pal-heafield-2023-cheating</bibkey>
      <video href="2023.findings-eacl.120.mp4"/>
      <doi>10.18653/v1/2023.findings-eacl.120</doi>
    </paper>
    <paper id="121">
      <title>Model-Agnostic Bias Measurement in Link Prediction</title>
      <author><first>Lena</first><last>Schwertmann</last><affiliation>Hasso Plattner Institute, University of Potsdam</affiliation></author>
      <author><first>Manoj Prabhakar</first><last>Kannan Ravi</last><affiliation>LexisNexis</affiliation></author>
      <author><first>Gerard</first><last>de Melo</last><affiliation>Hasso Plattner Institute, University of Potsdam</affiliation></author>
      <pages>1632-1648</pages>
      <abstract>Link prediction models based on factual knowledge graphs are commonly used in applications such as search and question answering. However, work investigating social bias in these models has been limited. Previous work focused on knowledge graph embeddings, so more recent classes of models achieving superior results by fine-tuning Transformers have not yet been investigated. We therefore present a model-agnostic approach for bias measurement leveraging fairness metrics to compare bias in knowledge graph embedding-based predictions (KG only) with models that use pre-trained, Transformer-based language models (KG+LM). We further create a dataset to measure gender bias in occupation predictions and assess whether the KG+LM models are more or less biased than KG only models. We find that gender bias tends to be higher for the KG+LM models and analyze potential connections to the accuracy of the models and the data bias inherent in our dataset. Finally, we discuss the limitations and ethical considerations of our work. The repository containing the source code and the data set is publicly available at <url>https://github.com/lena-schwert/comparing-bias-in-KG-models</url>.</abstract>
      <url hash="ff8d262c">2023.findings-eacl.121</url>
      <bibkey>schwertmann-etal-2023-model</bibkey>
      <video href="2023.findings-eacl.121.mp4"/>
      <doi>10.18653/v1/2023.findings-eacl.121</doi>
    </paper>
    <paper id="122">
      <title>Divergence-Based Domain Transferability for Zero-Shot Classification</title>
      <author><first>Alexander</first><last>Pugantsov</last><affiliation>University of Glasgow</affiliation></author>
      <author><first>Richard</first><last>McCreadie</last><affiliation>University of Glasgow</affiliation></author>
      <pages>1649-1654</pages>
      <abstract>Transferring learned patterns from pretrained neural language models has been shown to significantly improve effectiveness across a variety of language-based tasks, meanwhile further tuning on intermediate tasks has been demonstrated to provide additional performance benefits, provided the intermediate task is sufficiently related to the target task. However, how to identify related tasks is an open problem, and brute-force searching effective task combinations is prohibitively expensive. Hence, the question arises, are we able to improve the effectiveness and efficiency of tasks with no training examples through selective fine-tuning? In this paper, we explore statistical measures that approximate the divergence between domain representations as a means to estimate whether tuning using one task pair will exhibit performance benefits over tuning another. This estimation can then be used to reduce the number of task pairs that need to be tested by eliminating pairs that are unlikely to provide benefits. Through experimentation over 58 tasks and over 6,600 task pair combinations, we demonstrate that statistical measures can distinguish effective task pairs, and the resulting estimates can reduce end-to-end runtime by up to 40%.</abstract>
      <url hash="ed1f36bf">2023.findings-eacl.122</url>
      <bibkey>pugantsov-mccreadie-2023-divergence</bibkey>
      <video href="2023.findings-eacl.122.mp4"/>
      <doi>10.18653/v1/2023.findings-eacl.122</doi>
    </paper>
    <paper id="123">
      <title><fixed-case>EDU</fixed-case>-level Extractive Summarization with Varying Summary Lengths</title>
      <author><first>Yuping</first><last>Wu</last><affiliation>University of Manchester</affiliation></author>
      <author><first>Ching-Hsun</first><last>Tseng</last><affiliation>the University of Manchester</affiliation></author>
      <author><first>Jiayu</first><last>Shang</last><affiliation>University of Manchester</affiliation></author>
      <author><first>Shengzhong</first><last>Mao</last><affiliation>University of Manchester</affiliation></author>
      <author><first>Goran</first><last>Nenadic</last><affiliation>University of Manchester</affiliation></author>
      <author><first>Xiao-Jun</first><last>Zeng</last><affiliation>University of Manchester</affiliation></author>
      <pages>1655-1667</pages>
      <abstract>Extractive models usually formulate text summarization as extracting fixed top-k salient sentences from the document as a summary. Few works exploited extracting finer-grained Elementary Discourse Unit (EDU) with little analysis and justification for the extractive unit selection. Further, the selection strategy of the fixed top-k salient sentences fits the summarization need poorly, as the number of salient sentences in different documents varies and therefore a common or best k does not exist in reality. To fill these gaps, this paper first conducts the comparison analysis of oracle summaries based on EDUs and sentences, which provides evidence from both theoretical and experimental perspectives to justify and quantify that EDUs make summaries with higher automatic evaluation scores than sentences. Then, considering this merit of EDUs, this paper further proposes an EDU-level extractive model with Varying summary Lengths (EDU-VL) and develops the corresponding learning algorithm. EDU-VL learns to encode and predict probabilities of EDUs in the document, generate multiple candidate summaries with varying lengths based on various k values, and encode and score candidate summaries, in an end-to-end training manner. Finally, EDU-VL is experimented on single and multi-document benchmark datasets and shows improved performances on ROUGE scores in comparison with state-of-the-art extractive models, and further human evaluation suggests that EDU-constituent summaries maintain good grammaticality and readability.</abstract>
      <url hash="ed168e9f">2023.findings-eacl.123</url>
      <attachment type="software" hash="182f1ce9">2023.findings-eacl.123.software.zip</attachment>
      <bibkey>wu-etal-2023-edu</bibkey>
      <video href="2023.findings-eacl.123.mp4"/>
      <doi>10.18653/v1/2023.findings-eacl.123</doi>
    </paper>
    <paper id="124">
      <title>“Chère maison” or “maison chère”? Transformer-based prediction of adjective placement in <fixed-case>F</fixed-case>rench</title>
      <author><first>Eleni</first><last>Metheniti</last><affiliation>CLLE-CNRS and IRIT-CNRS</affiliation></author>
      <author><first>Tim</first><last>Van de Cruys</last><affiliation>University of Leuven</affiliation></author>
      <author><first>Wissam</first><last>Kerkri</last><affiliation>Clle</affiliation></author>
      <author><first>Juliette</first><last>Thuilier</last><affiliation>Université Toulouse Jean Jaurès &amp; CLLE-ERSS</affiliation></author>
      <author><first>Nabil</first><last>Hathout</last><affiliation>CLLE, CNRS &amp; Universite de Toulouse</affiliation></author>
      <pages>1668-1683</pages>
      <abstract>In French, the placement of the adjective within a noun phrase is subject to variation: it can appear either before or after the noun. We conduct experiments to assess whether transformer-based language models are able to learn the adjective position in noun phrases in French –a position which depends on several linguistic factors. Prior findings have shown that transformer models are insensitive to permutated word order, but in this work, we show that finetuned models are successful at learning and selecting the correct position of the adjective. However, this success can be attributed to the process of finetuning rather than the linguistic knowledge acquired during pretraining, as evidenced by the low accuracy of experiments of classification that make use of pretrained embeddings. Comparing the finetuned models to the choices of native speakers (with a questionnaire), we notice that the models favor context and global syntactic roles, and are weaker with complex structures and fixed expressions.</abstract>
      <url hash="56bcd1df">2023.findings-eacl.124</url>
      <bibkey>metheniti-etal-2023-chere</bibkey>
      <video href="2023.findings-eacl.124.mp4"/>
      <doi>10.18653/v1/2023.findings-eacl.124</doi>
    </paper>
    <paper id="125">
      <title>On the Role of Reviewer Expertise in Temporal Review Helpfulness Prediction</title>
      <author><first>Mir Tafseer</first><last>Nayeem</last><affiliation>University of Alberta</affiliation></author>
      <author><first>Davood</first><last>Rafiei</last><affiliation>University of Alberta</affiliation></author>
      <pages>1684-1692</pages>
      <abstract>Helpful reviews have been essential for the success of e-commerce services, as they help customers make quick purchase decisions and benefit the merchants in their sales. While many reviews are informative, others provide little value and may contain spam, excessive appraisal, or unexpected biases. With the large volume of reviews and their uneven quality, the problem of detecting helpful reviews has drawn much attention lately. Existing methods for identifying helpful reviews primarily focus on review text and ignore the two key factors of (1) who post the reviews and (2) when the reviews are posted. Moreover, the helpfulness votes suffer from scarcity for less popular products and recently submitted (a.k.a., cold-start) reviews. To address these challenges, we introduce a dataset and develop a model that integrates the reviewer’s expertise, derived from the past review history of the reviewers, and the temporal dynamics of the reviews to automatically assess review helpfulness. We conduct experiments on our dataset to demonstrate the effectiveness of incorporating these factors and report improved results compared to several well-established baselines.</abstract>
      <url hash="06bfaff6">2023.findings-eacl.125</url>
      <bibkey>nayeem-rafiei-2023-role</bibkey>
      <video href="2023.findings-eacl.125.mp4"/>
      <doi>10.18653/v1/2023.findings-eacl.125</doi>
    </paper>
    <paper id="126">
      <title>Towards a Unified Model for Generating Answers and Explanations in Visual Question Answering</title>
      <author><first>Chenxi</first><last>Whitehouse</last><affiliation>City, University of London</affiliation></author>
      <author><first>Tillman</first><last>Weyde</last><affiliation>City, University of London</affiliation></author>
      <author><first>Pranava</first><last>Madhyastha</last><affiliation>City, University of London</affiliation></author>
      <pages>1693-1705</pages>
      <abstract>The field of visual question answering (VQA) has recently seen a surge in research focused on providing explanations for predicted answers. However, current systems mostly rely on separate models to predict answers and generate explanations, leading to less grounded and frequently inconsistent results. To address this, we propose a multitask learning approach towards a Unified Model for Answer and Explanation generation (UMAE). Our approach involves the addition of artificial prompt tokens to training data and fine-tuning a multimodal encoder-decoder model on a variety of VQA-related tasks. In our experiments, UMAE models surpass the prior state-of-the-art answer accuracy on A-OKVQA by 10 15%, show competitive results on OK-VQA, achieve new state-of-the-art explanation scores on A-OKVQA and VCR, and demonstrate promising out-of-domain performance on VQA-X.</abstract>
      <url hash="72fc7a80">2023.findings-eacl.126</url>
      <bibkey>whitehouse-etal-2023-towards</bibkey>
      <video href="2023.findings-eacl.126.mp4"/>
      <doi>10.18653/v1/2023.findings-eacl.126</doi>
    </paper>
    <paper id="127">
      <title>Machine Translation between Spoken Languages and Signed Languages Represented in <fixed-case>S</fixed-case>ign<fixed-case>W</fixed-case>riting</title>
      <author><first>Zifan</first><last>Jiang</last><affiliation>University of Zurich</affiliation></author>
      <author><first>Amit</first><last>Moryossef</last><affiliation>Bar-Ilan university, University of Zurich</affiliation></author>
      <author><first>Mathias</first><last>Müller</last><affiliation>University of Zurich</affiliation></author>
      <author><first>Sarah</first><last>Ebling</last><affiliation>University of Zurich</affiliation></author>
      <pages>1706-1724</pages>
      <abstract>This paper presents work on novel machine translation (MT) systems between spoken and signed languages, where signed languages are represented in SignWriting, a sign language writing system. Our work seeks to address the lack of out-of-the-box support for signed languages in current MT systems and is based on the SignBank dataset, which contains pairs of spoken language text and SignWriting content. We introduce novel methods to parse, factorize, decode, and evaluate SignWriting, leveraging ideas from neural factored MT. In a bilingual setup—translating from American Sign Language to (American) English—our method achieves over 30 BLEU, while in two multilingual setups—translating in both directions between spoken languages and signed languages—we achieve over 20 BLEU. We find that common MT techniques used to improve spoken language translation similarly affect the performance of sign language translation. These findings validate our use of an intermediate text representation for signed languages to include them in natural language processing research.</abstract>
      <url hash="44d816fe">2023.findings-eacl.127</url>
      <bibkey>jiang-etal-2023-machine</bibkey>
      <video href="2023.findings-eacl.127.mp4"/>
      <doi>10.18653/v1/2023.findings-eacl.127</doi>
    </paper>
    <paper id="128">
      <title>A Multi-dimensional Evaluation of Tokenizer-free Multilingual Pretrained Models</title>
      <author><first>Jimin</first><last>Sun</last><affiliation>Carnegie Mellon University</affiliation></author>
      <author><first>Patrick</first><last>Fernandes</last><affiliation>Carnegie Mellon University, Instituto de Telecomunicações</affiliation></author>
      <author><first>Xinyi</first><last>Wang</last><affiliation>Google</affiliation></author>
      <author><first>Graham</first><last>Neubig</last><affiliation>Carnegie Mellon University</affiliation></author>
      <pages>1725-1735</pages>
      <abstract>Recent works on tokenizer-free multilingual pretrained models show promising results in improving cross-lingual transfer and reducing engineering overhead compared to subword-based alternatives. However, previous work mainly focuses on reporting accuracy on a limited set of tasks and data settings, placing less emphasis on other important factors when tuning and deploying the models in practice, such as memory usage, inference speed, and finetuning data efficiency. We attempt to fill this gap by performing a comprehensive empirical comparison of multilingual tokenizer-free and subword-based models considering the various dimensions. Surprisingly, we find that subword-based models might still be the most practical choice in many settings, achieving better performance for lower inference latency and memory usage. Based on these results, we encourage future work in tokenizer-free methods to consider these factors when designing and evaluating new models.</abstract>
      <url hash="fa25f392">2023.findings-eacl.128</url>
      <bibkey>sun-etal-2023-multi</bibkey>
      <video href="2023.findings-eacl.128.mp4"/>
      <doi>10.18653/v1/2023.findings-eacl.128</doi>
    </paper>
    <paper id="129">
      <title>Neural Ranking with Weak Supervision for Open-Domain Question Answering : A Survey</title>
      <author><first>Xiaoyu</first><last>Shen</last><affiliation>Amazon</affiliation></author>
      <author><first>Svitlana</first><last>Vakulenko</last><affiliation>Amazon</affiliation></author>
      <author><first>Marco</first><last>del Tredici</last><affiliation>Amazon</affiliation></author>
      <author><first>Gianni</first><last>Barlacchi</last><affiliation>Amazon Alexa</affiliation></author>
      <author id="bill-byrne"><first>Bill</first><last>Byrne</last><affiliation>University of Cambridge</affiliation></author>
      <author><first>Adria</first><last>de Gispert</last><affiliation>Amazon</affiliation></author>
      <pages>1736-1750</pages>
      <abstract>Neural ranking (NR) has become a key component for open-domain question-answering in order to access external knowledge. However, training a good NR model requires substantial amounts of relevance annotations, which is very costly to scale. To address this, a growing body of research works have been proposed to reduce the annotation cost by training the NR model with weak supervision (WS) instead. These works differ in what resources they require and employ a diverse set of WS signals to train the model. Understanding such differences is crucial for choosing the right WS technique. To facilitate this understanding, we provide a structured overview of standard WS signals used for training a NR model. Based on their required resources, we divide them into three main categories: (1) only documents are needed; (2) documents and questions are needed; and (3) documents and question-answer pairs are needed. For every WS signal, we review its general idea and choices. Promising directions are outlined for future research.</abstract>
      <url hash="6740f9e9">2023.findings-eacl.129</url>
      <bibkey>shen-etal-2023-neural</bibkey>
      <video href="2023.findings-eacl.129.mp4"/>
      <doi>10.18653/v1/2023.findings-eacl.129</doi>
    </paper>
    <paper id="130">
      <title>Double Retrieval and Ranking for Accurate Question Answering</title>
      <author><first>Zeyu</first><last>Zhang</last><affiliation>School of Information, the University of Arizona</affiliation></author>
      <author><first>Thuy</first><last>Vu</last><affiliation>Amazon</affiliation></author>
      <author><first>Alessandro</first><last>Moschitti</last><affiliation>Amazon</affiliation></author>
      <pages>1751-1762</pages>
      <abstract>Recent work has shown that an answer verification step introduced in Transformer-based answer selection models can significantly improve the state of the art in Question Answering. This step is performed by aggregating the embeddings of top <tex-math>k</tex-math> answer candidates to support the verification of a target answer. Although the approach is intuitive and sound, it still shows two limitations: (i) the supporting candidates are ranked only according to the relevancy with the question and not with the answer, and (ii) the support provided by the other answer candidates is suboptimal as these are retrieved independently of the target answer. In this paper, we address both drawbacks by proposing (i) a double reranking model, which, for each target answer, selects the best support; and (ii) a second neural retrieval stage designed to encode question and answer pair as the query, which finds more specific verification information. The results on well-known datasets for Answer Sentence Selection show significant improvement over the state of the art.</abstract>
      <url hash="53c44d09">2023.findings-eacl.130</url>
      <bibkey>zhang-etal-2023-double</bibkey>
      <video href="2023.findings-eacl.130.mp4"/>
      <doi>10.18653/v1/2023.findings-eacl.130</doi>
    </paper>
    <paper id="131">
      <title>Evaluating the Diversity, Equity, and Inclusion of <fixed-case>NLP</fixed-case> Technology: A Case Study for <fixed-case>I</fixed-case>ndian Languages</title>
      <author><first>Simran</first><last>Khanuja</last><affiliation>Carnegie Mellon University</affiliation></author>
      <author><first>Sebastian</first><last>Ruder</last><affiliation>Google</affiliation></author>
      <author><first>Partha</first><last>Talukdar</last><affiliation>Google Research and IISc</affiliation></author>
      <pages>1763-1777</pages>
      <abstract>In order for NLP technology to be widely applicable, fair, and useful, it needs to serve a diverse set of speakers across the world’s languages, be equitable, i.e., not unduly biased towards any particular language, and be inclusive of all users, particularly in low-resource settings where compute constraints are common. In this paper, we propose an evaluation paradigm that assesses NLP technologies across all three dimensions. While diversity and inclusion have received attention in recent literature, equity is currently unexplored. We propose to address this gap using the Gini coefficient, a well-established metric used for estimating societal wealth inequality. Using our paradigm, we highlight the distressed state of current technologies for Indian (IN) languages (a linguistically large and diverse set, with a varied speaker population), across all three dimensions. To improve upon these metrics, we demonstrate the importance of region-specific choices in model building and dataset creation, and more importantly, propose a novel, generalisable approach to optimal resource allocation during fine-tuning. Finally, we discuss steps to mitigate these biases and encourage the community to employ multi-faceted evaluation when building linguistically diverse and equitable technologies.</abstract>
      <url hash="5b4910ba">2023.findings-eacl.131</url>
      <bibkey>khanuja-etal-2023-evaluating</bibkey>
      <video href="2023.findings-eacl.131.mp4"/>
      <doi>10.18653/v1/2023.findings-eacl.131</doi>
    </paper>
    <paper id="132">
      <title>Joint Reasoning on Hybrid-knowledge sources for Task-Oriented Dialog</title>
      <author><first>Mayank</first><last>Mishra</last><affiliation>IBM Research</affiliation></author>
      <author><first>Danish</first><last>Contractor</last><affiliation>IBM Research IBM Research</affiliation></author>
      <author><first>Dinesh</first><last>Raghu</last><affiliation>IBM Research</affiliation></author>
      <pages>1778-1787</pages>
      <abstract>Traditional systems designed for task oriented dialog utilize knowledge present only in structured knowledge sources to generate responses. However, relevant information required to generate responses may also reside in unstructured sources, such as documents. Recent state of the art models such as HyKnow (Gao et al., 2021b) and SEKNOW (Gao et al., 2021a) aimed at overcoming these challenges make limiting assumptions about the knowledge sources. For instance, these systems assume that certain types of information, such as a phone number, is always present in a structured knowledge base (KB) while information about aspects such as entrance ticket prices, would always be available in documents. In this paper, we create a modified version of the MutliWOZ-based dataset prepared by (Gao et al., 2021a) to demonstrate how current methods have significant degradation in performance when strict assumptions about the source of information are removed. Then, in line with recent work exploiting pre-trained language models, we fine-tune a BART (Lewiset al., 2020) based model using prompts (Brown et al., 2020; Sun et al., 2021) for the tasks of querying knowledge sources, as well as, for response generation, without makingassumptions about the information present in each knowledge source. Through a series of experiments, we demonstrate that our model is robust to perturbations to knowledge modality (source of information), and that it can fuse information from structured as well as unstructured knowledge to generate responses.</abstract>
      <url hash="527851d8">2023.findings-eacl.132</url>
      <bibkey>mishra-etal-2023-joint</bibkey>
      <video href="2023.findings-eacl.132.mp4"/>
      <doi>10.18653/v1/2023.findings-eacl.132</doi>
    </paper>
    <paper id="133">
      <title>Revisiting Offline Compression: Going Beyond Factorization-based Methods for Transformer Language Models</title>
      <author><first>Mohammadreza</first><last>Banaei</last><affiliation>Epfl</affiliation></author>
      <author><first>Klaudia</first><last>Bałazy</last><affiliation>Jagiellonian University</affiliation></author>
      <author><first>Artur</first><last>Kasymov</last><affiliation>Jagiellonian University</affiliation></author>
      <author><first>Rémi</first><last>Lebret</last><affiliation>Epfl</affiliation></author>
      <author><first>Jacek</first><last>Tabor</last><affiliation>Jagiellonian University</affiliation></author>
      <author><first>Karl</first><last>Aberer</last><affiliation>Epfl</affiliation></author>
      <pages>1788-1805</pages>
      <abstract>Recent transformer language models achieve outstanding results in many natural language processing (NLP) tasks. However, their enormous size often makes them impractical on memory-constrained devices, requiring practitioners to compress them to smaller networks. In this paper, we explore offline compression methods, meaning computationally-cheap approaches that do not require further fine-tuning of the compressed model. We challenge the classical matrix factorization methods by proposing a novel, better-performing autoencoder-based framework. We perform a comprehensive ablation study of our approach, examining its different aspects over a diverse set of evaluation settings. Moreover, we show that enabling collaboration between modules across layers by compressing certain modules together positively impacts the final model performance. Experiments on various NLP tasks demonstrate that our approach significantly outperforms commonly used factorization-based offline compression methods.</abstract>
      <url hash="1d926a91">2023.findings-eacl.133</url>
      <bibkey>banaei-etal-2023-revisiting</bibkey>
      <video href="2023.findings-eacl.133.mp4"/>
      <doi>10.18653/v1/2023.findings-eacl.133</doi>
    </paper>
    <paper id="134">
      <title><fixed-case>P</fixed-case>ri<fixed-case>M</fixed-case>e<fixed-case>SRL</fixed-case>-Eval: A Practical Quality Metric for Semantic Role Labeling Systems Evaluation</title>
      <author><first>Ishan</first><last>Jindal</last><affiliation>IBM Research</affiliation></author>
      <author><first>Alexandre</first><last>Rademaker</last><affiliation>IBM Research and EMAp/FGV</affiliation></author>
      <author><first>Khoi-Nguyen</first><last>Tran</last><affiliation>Ibm</affiliation></author>
      <author><first>Huaiyu</first><last>Zhu</last><affiliation>IBM Research - Almaden</affiliation></author>
      <author><first>Hiroshi</first><last>Kanayama</last><affiliation>IBM Research - Tokyo</affiliation></author>
      <author><first>Marina</first><last>Danilevsky</last><affiliation>IBM Research</affiliation></author>
      <author><first>Yunyao</first><last>Li</last><affiliation>Apple</affiliation></author>
      <pages>1806-1818</pages>
      <abstract>Semantic role labeling (SRL) identifies the predicate-argument structure in a sentence. This task is usually accomplished in four steps: predicate identification, predicate sense disambiguation, argument identification, and argument classification. Errors introduced at one step propagate to later steps. Unfortunately, the existing SRL evaluation scripts do not consider the full effect of this error propagation aspect. They either evaluate arguments independent of predicate sense (CoNLL09) or do not evaluate predicate sense at all (CoNLL05), yielding an inaccurate SRL model performance on the argument classification task. In this paper, we address key practical issues with existing evaluation scripts and propose a more strict SRL evaluation metric PriMeSRL. We observe that by employing PriMeSRL, the quality evaluation of all SoTA SRL models drops significantly, and their relative rankings also change. We also show that PriMeSRLsuccessfully penalizes actual failures in SoTA SRL models.</abstract>
      <url hash="ea374953">2023.findings-eacl.134</url>
      <attachment type="software" hash="e7bf8e40">2023.findings-eacl.134.software.zip</attachment>
      <bibkey>jindal-etal-2023-primesrl</bibkey>
      <video href="2023.findings-eacl.134.mp4"/>
      <doi>10.18653/v1/2023.findings-eacl.134</doi>
    </paper>
    <paper id="135">
      <title>Prompt-based Learning for Text Readability Assessment</title>
      <author><first>Bruce W.</first><last>Lee</last><affiliation>University of Pennsylvania</affiliation></author>
      <author><first>Jason</first><last>Lee</last><affiliation>Lxper Ai</affiliation></author>
      <pages>1819-1824</pages>
      <abstract>We propose the novel adaptation of a pre-trained seq2seq model for readability assessment. We prove that a seq2seq model - T5 or BART - can be adapted to discern which text is more difficult from two given texts (pairwise). As an exploratory study to prompt-learn a neural network for text readability in a text-to-text manner, we report useful tips for future work in seq2seq training and ranking-based approach to readability assessment. Specifically, we test nine input-output formats/prefixes and show that they can significantly influence the final model performance. Also, we argue that the combination of text-to-text training and pairwise ranking setup 1) enables leveraging multiple parallel text simplification data for teaching readability and 2) trains a neural model for the general concept of readability (therefore, better cross-domain generalization). At last, we report a 99.6% pairwise classification accuracy on Newsela and a 98.7% for OneStopEnglish, through a joint training approach. Our code is available at github.com/brucewlee/prompt-learning-readability.</abstract>
      <url hash="50323060">2023.findings-eacl.135</url>
      <bibkey>lee-lee-2023-prompt</bibkey>
      <video href="2023.findings-eacl.135.mp4"/>
      <doi>10.18653/v1/2023.findings-eacl.135</doi>
    </paper>
    <paper id="136">
      <title>Best Practices in the Creation and Use of Emotion Lexicons</title>
      <author><first>Saif</first><last>Mohammad</last><affiliation>Nrc</affiliation></author>
      <pages>1825-1836</pages>
      <abstract>Words play a central role in how we express ourselves. Lexicons of word–emotion associations are widely used in research and real-world applications for sentiment analysis, tracking emotions associated with products and policies, studying health disorders, tracking emotional arcs of stories, and so on. However, inappropriate and incorrect use of these lexicons can lead to not just sub-optimal results, but also inferences that are directly harmful to people. This paper brings together ideas from Affective Computing and AI Ethics to present, some of the practical and ethical considerations involved in the creation and use of emotion lexicons – best practices. The goal is to provide a comprehensive set of relevant considerations, so that readers (especially those new to work with emotions) can find relevant information in one place. We hope this work will facilitate more thoughtfulness when one is deciding on what emotions to work on, how to create an emotion lexicon, how to use an emotion lexicon, how to draw meaningful inferences, and how to judge success.</abstract>
      <url hash="d5a03e51">2023.findings-eacl.136</url>
      <bibkey>mohammad-2023-best</bibkey>
      <video href="2023.findings-eacl.136.mp4"/>
      <doi>10.18653/v1/2023.findings-eacl.136</doi>
    </paper>
    <paper id="137">
      <title>The Role of Semantic Parsing in Understanding Procedural Text</title>
      <author><first>Hossein</first><last>Rajaby Faghihi</last><affiliation>Michigan State University</affiliation></author>
      <author><first>Parisa</first><last>Kordjamshidi</last><affiliation>Michigan State University</affiliation></author>
      <author><first>Choh Man</first><last>Teng</last><affiliation>Institute for Human and Machine Cognition</affiliation></author>
      <author><first>James</first><last>Allen</last><affiliation>University of Rochester</affiliation></author>
      <pages>1837-1849</pages>
      <abstract>In this paper, we investigate whether symbolic semantic representations, extracted from deep semantic parsers, can help reasoning over the states of involved entities in a procedural text. We consider a deep semantic parser (TRIPS) and semantic role labeling as two sources of semantic parsing knowledge. First, we propose PROPOLIS, a symbolic parsing-based procedural reasoning framework. Second, we integrate semantic parsing information into state-of-the-art neural models to conduct procedural reasoning. Our experiments indicate that explicitly incorporating such semantic knowledge improves procedural understanding. This paper presents new metrics for evaluating procedural reasoning tasks that clarify the challenges and identify differences among neural, symbolic, and integrated models.</abstract>
      <url hash="c5d442f0">2023.findings-eacl.137</url>
      <bibkey>rajaby-faghihi-etal-2023-role</bibkey>
      <video href="2023.findings-eacl.137.mp4"/>
      <doi>10.18653/v1/2023.findings-eacl.137</doi>
    </paper>
    <paper id="138">
      <title>Named Entity Recognition in a Very Homogenous Domain</title>
      <author><first>Oshin</first><last>Agarwal</last><affiliation>University of Pennsylvania</affiliation></author>
      <author><first>Ani</first><last>Nenkova</last><affiliation>Adobe Research</affiliation></author>
      <pages>1850-1855</pages>
      <abstract>Machine Learning models have lower accuracy when tested on out-of-domain data. Developing models that perform well on several domains or can be quickly adapted to a new domain is an important research area. Domain, however, is a vague term, that can refer to any aspect of data such as language, genre, source and structure. We consider a very homogeneous source of data, specifically sentences from news articles from the same newspaper in English, and collect a dataset of such “in-domain” sentences annotated with named entities. We find that even in such a homogeneous domain, the performance of named entity recognition models varies significantly across news topics. Selection of diverse data, as we demonstrate, is crucial even in a seemingly homogeneous domain.</abstract>
      <url hash="ed8f4b60">2023.findings-eacl.138</url>
      <bibkey>agarwal-nenkova-2023-named</bibkey>
      <video href="2023.findings-eacl.138.mp4"/>
      <doi>10.18653/v1/2023.findings-eacl.138</doi>
    </paper>
    <paper id="139">
      <title>Crawling The Internal Knowledge-Base of Language Models</title>
      <author><first>Roi</first><last>Cohen</last><affiliation>Tel Aviv University</affiliation></author>
      <author><first>Mor</first><last>Geva</last><affiliation>Google</affiliation></author>
      <author><first>Jonathan</first><last>Berant</last><affiliation>Tel Aviv University and AI2</affiliation></author>
      <author><first>Amir</first><last>Globerson</last><affiliation>Tel Aviv University, Google</affiliation></author>
      <pages>1856-1869</pages>
      <abstract>Language models are trained on large volumes of text, and as a result their parameters might contain a significant body of factual knowledge. Any downstream task performed by these models implicitly builds on these facts, and thus it is highly desirable to have means for representing this body of knowledge in an interpretable way. However, there is currently no mechanism for such a representation. Here, we propose to address this goal by extracting a knowledge-graph of facts from a given language model. We describe a procedure for “crawling” the internal knowledge-base of a language model. Specifically, given a seed entity, we expand a knowledge-graph around it. The crawling procedure is decomposed into sub-tasks, realized through specially designed prompts that control for both precision (i.e., that no wrong facts are generated) and recall (i.e., the number of facts generated). We evaluate our approach on graphs crawled starting from dozens of seed entities, and show it yields high precision graphs (82-92%), while emitting a reasonable number of facts per entity.</abstract>
      <url hash="1f54aae5">2023.findings-eacl.139</url>
      <bibkey>cohen-etal-2023-crawling</bibkey>
      <video href="2023.findings-eacl.139.mp4"/>
      <doi>10.18653/v1/2023.findings-eacl.139</doi>
    </paper>
    <paper id="140">
      <title>Intent Identification and Entity Extraction for Healthcare Queries in <fixed-case>I</fixed-case>ndic Languages</title>
      <author><first>Ankan</first><last>Mullick</last><affiliation>Indian Institute of Technology, Kharagpur</affiliation></author>
      <author><first>Ishani</first><last>Mondal</last><affiliation>Microsoft</affiliation></author>
      <author><first>Sourjyadip</first><last>Ray</last><affiliation>Indian Institute of Technology, Kharagpur</affiliation></author>
      <author><first>Raghav</first><last>R</last><affiliation>Cmu</affiliation></author>
      <author><first>G</first><last>Chaitanya</last><affiliation>IIT Kharagpur</affiliation></author>
      <author><first>Pawan</first><last>Goyal</last><affiliation>IIT Kharagpur</affiliation></author>
      <pages>1870-1881</pages>
      <abstract>Scarcity of data and technological limitations for resource-poor languages in developing countries like India poses a threat to the development of sophisticated NLU systems for healthcare. To assess the current status of various state-of-the-art language models in healthcare, this paper studies the problem by initially proposing two different Healthcare datasets, Indian Healthcare Query Intent-WebMD and 1mg (IHQID-WebMD and IHQID-1mg) and one real world Indian hospital query data in English and multiple Indic languages (Hindi, Bengali, Tamil, Telugu, Marathi and Gujarati) which are annotated with the query intents as well as entities. Our aim is to detect query intents and corresponding entities. We perform extensive experiments on a set of models which in various realistic settings and explore two scenarios based on the access to English data only (less costly) and access to target language data (more expensive). We analyze context specific practical relevancy through empirical analysis. The results, expressed in terms of overall F-score show that our approach is practically useful to identify intents and entities.</abstract>
      <url hash="d72f9391">2023.findings-eacl.140</url>
      <bibkey>mullick-etal-2023-intent</bibkey>
      <video href="2023.findings-eacl.140.mp4"/>
      <doi>10.18653/v1/2023.findings-eacl.140</doi>
    </paper>
    <paper id="141">
      <title>Text-Derived Knowledge Helps Vision: A Simple Cross-modal Distillation for Video-based Action Anticipation</title>
      <author><first>Sayontan</first><last>Ghosh</last><affiliation>Stony Brook University</affiliation></author>
      <author><first>Tanvi</first><last>Aggarwal</last><affiliation>Stony Brook University</affiliation></author>
      <author><first>Minh</first><last>Hoai</last><affiliation>Stony Brook University</affiliation></author>
      <author><first>Niranjan</first><last>Balasubramanian</last><affiliation>Stony Brook University</affiliation></author>
      <pages>1882-1897</pages>
      <abstract>Anticipating future actions in a video is useful for many autonomous and assistive technologies. Prior action anticipation work mostly treat this as a vision modality problem, where the models learn the task information primarily from the video features in the action anticipation datasets. However, knowledge about action sequences can also be obtained from external textual data. In this work, we show how knowledge in pretrained language models can be adapted and distilled into vision based action anticipation models. We show that a simple distillation technique can achieve effective knowledge transfer and provide consistent gains on a strong vision model (Anticipative Vision Transformer) for two action anticipation datasets (3.5% relative gain on EGTEA-GAZE+ and 7.2% relative gain on EPIC-KITCHEN 55), giving a new state-of-the-art result.</abstract>
      <url hash="93239279">2023.findings-eacl.141</url>
      <bibkey>ghosh-etal-2023-text</bibkey>
      <video href="2023.findings-eacl.141.mp4"/>
      <doi>10.18653/v1/2023.findings-eacl.141</doi>
    </paper>
    <paper id="142">
      <title>Simple Yet Effective Synthetic Dataset Construction for Unsupervised Opinion Summarization</title>
      <author><first>Ming</first><last>Shen</last><affiliation>Arizona State University</affiliation></author>
      <author><first>Jie</first><last>Ma</last><affiliation>AWS AI Lab</affiliation></author>
      <author><first>Shuai</first><last>Wang</last><affiliation>Amazon AI</affiliation></author>
      <author><first>Yogarshi</first><last>Vyas</last><affiliation>AWS AI Labs</affiliation></author>
      <author><first>Kalpit</first><last>Dixit</last><affiliation>Amazon</affiliation></author>
      <author><first>Miguel</first><last>Ballesteros</last><affiliation>Amazon</affiliation></author>
      <author><first>Yassine</first><last>Benajiba</last><affiliation>AWS AI Labs</affiliation></author>
      <pages>1898-1911</pages>
      <abstract>Opinion summarization provides an important solution for summarizing opinions expressed among a large number of reviews. However, generating aspect-specific and general summaries is challenging due to the lack of annotated data. In this work, we propose two simple yet effective unsupervised approaches to generate both aspect-specific and general opinion summaries by training on synthetic datasets constructed with aspect-related review contents. Our first approach, Seed Words Based Leave-One-Out (SW-LOO), identifies aspect-related portions of reviews simply by exact-matching aspect seed words and outperforms existing methods by 3.4 ROUGE-L points on Space and 0.5 ROUGE-1 point on Oposum+ for aspect-specific opinion summarization. Our second approach, Natural Language Inference Based Leave-One-Out (NLI-LOO) identifies aspect-related sentences utilizing an NLI model in a more general setting without using seed words and outperforms existing approaches by 1.2 ROUGE-L points on Space for aspect-specific opinion summarization and remains competitive on other metrics.</abstract>
      <url hash="710841d3">2023.findings-eacl.142</url>
      <bibkey>shen-etal-2023-simple</bibkey>
      <video href="2023.findings-eacl.142.mp4"/>
      <doi>10.18653/v1/2023.findings-eacl.142</doi>
    </paper>
    <paper id="143">
      <title>Towards Fine-tuning Pre-trained Language Models with Integer Forward and Backward Propagation</title>
      <author><first>Mohammadreza</first><last>Tayaranian Hosseini</last><affiliation>Huawei Technologies Canada</affiliation></author>
      <author><first>Alireza</first><last>Ghaffari</last><affiliation>Huawei Noah’s Ark Lab</affiliation></author>
      <author><first>Marzieh S.</first><last>Tahaei</last><affiliation>Huawei Noah’s Ark Lab</affiliation></author>
      <author><first>Mehdi</first><last>Rezagholizadeh</last><affiliation>Noah’s Ark Lab Huawei</affiliation></author>
      <author><first>Masoud</first><last>Asgharian</last><affiliation>McGill Universirty</affiliation></author>
      <author><first>Vahid</first><last>Partovi Nia</last><affiliation>Huawei Noah’s Ark Lab</affiliation></author>
      <pages>1912-1921</pages>
      <abstract>The large number of parameters of some prominent language models, such as BERT, makes their fine-tuning on downstream tasks computationally intensive and energy hungry. Previously researchers were focused on lower bit-width integer data types for the forward propagation of language models to save memory and computation. As for the backward propagation, however, only 16-bit floating-point data type has been used for the fine-tuning of BERT.In this work, we use integer arithmetic for both forward and back propagation in the fine-tuning of BERT.We study the effects of varying the integer bit-width on the model’s metric performance. Our integer fine-tuning uses integer arithmetic to perform forward propagation and gradient computation of linear, layer-norm, and embedding layers of BERT.We fine-tune BERT using our integer training method on SQuAD v1.1 and SQuAD v2., and GLUE benchmark. We demonstrate that metric performance of fine-tuning 16-bit integer BERT matches both 16-bit and 32-bit floating-point baselines. Furthermore, using the faster and more memory efficient 8-bit integer data type, integer fine-tuning of BERT loses an average of 3.1 points compared to the FP32 baseline.</abstract>
      <url hash="72105025">2023.findings-eacl.143</url>
      <bibkey>tayaranian-hosseini-etal-2023-towards</bibkey>
      <video href="2023.findings-eacl.143.mp4"/>
      <doi>10.18653/v1/2023.findings-eacl.143</doi>
    </paper>
    <paper id="144">
      <title>Data Augmentation for Radiology Report Simplification</title>
      <author><first>Ziyu</first><last>Yang</last><affiliation>Temple University</affiliation></author>
      <author><first>Santhosh</first><last>Cherian</last><affiliation>Temple University Hospital</affiliation></author>
      <author><first>Slobodan</first><last>Vucetic</last><affiliation>Temple University</affiliation></author>
      <pages>1922-1932</pages>
      <abstract>This work considers the development of a text simplification model to help patients better understand their radiology reports. This paper proposes a data augmentation approach to address the data scarcity issue caused by the high cost of manual simplification. It prompts a large foundational pre-trained language model to generate simplifications of unlabeled radiology sentences. In addition, it uses paraphrasing of labeled radiology sentences. Experimental results show that the proposed data augmentation approach enables the training of a significantly more accurate simplification model than the baselines.</abstract>
      <url hash="1f70841a">2023.findings-eacl.144</url>
      <attachment type="dataset" hash="70c758d7">2023.findings-eacl.144.dataset.zip</attachment>
      <bibkey>yang-etal-2023-data</bibkey>
      <video href="2023.findings-eacl.144.mp4"/>
      <doi>10.18653/v1/2023.findings-eacl.144</doi>
    </paper>
    <paper id="145">
      <title>Embedding Recycling for Language Models</title>
      <author><first>Jon</first><last>Saad-Falcon</last><affiliation>Stanford University</affiliation></author>
      <author><first>Amanpreet</first><last>Singh</last><affiliation>Allen Institute for Artificial Intelligence</affiliation></author>
      <author><first>Luca</first><last>Soldaini</last><affiliation>Allen Institute for AI</affiliation></author>
      <author><first>Mike</first><last>D’Arcy</last><affiliation>Northwestern University</affiliation></author>
      <author><first>Arman</first><last>Cohan</last><affiliation>Allen Institute for AI</affiliation></author>
      <author><first>Doug</first><last>Downey</last><affiliation>Allen Institute for AI, Northwestern University</affiliation></author>
      <pages>1933-1953</pages>
      <abstract>Real-world applications of neural language models often involve running many different models over the same corpus. The high computational cost of these runs has led to interest in techniques that can reuse the contextualized embeddings produced in previous runs to speed training and inference of future ones. We refer to this approach as embedding recycling (ER). While multiple ER techniques have been proposed, their practical effectiveness is still unknown because existing evaluations consider very few models and do not adequately account for overhead costs. We perform an extensive evaluation of ER across eight different models (17 to 900 million parameters) and fourteen tasks in English. We show how a simple ER technique that caches activations from an intermediate layer of a pretrained model, and learns task-specific adapters on the later layers, is broadly effective. For the best-performing baseline in our experiments (DeBERTa-v2 XL), adding a precomputed cache results in a 90% speedup during training and 87-91% speedup for inference, with negligible impact on accuracy. Our analysis reveals important areas of future work.</abstract>
      <url hash="5ca919c9">2023.findings-eacl.145</url>
      <bibkey>saad-falcon-etal-2023-embedding</bibkey>
      <video href="2023.findings-eacl.145.mp4"/>
      <doi>10.18653/v1/2023.findings-eacl.145</doi>
    </paper>
    <paper id="146">
      <title>Trained on 100 million words and still in shape: <fixed-case>BERT</fixed-case> meets <fixed-case>B</fixed-case>ritish <fixed-case>N</fixed-case>ational <fixed-case>C</fixed-case>orpus</title>
      <author><first>David</first><last>Samuel</last><affiliation>University of Oslo, Language Technology Group</affiliation></author>
      <author><first>Andrey</first><last>Kutuzov</last><affiliation>University of Oslo</affiliation></author>
      <author><first>Lilja</first><last>Øvrelid</last><affiliation>Dept of Informatics, University of Oslo</affiliation></author>
      <author><first>Erik</first><last>Velldal</last><affiliation>University of Oslo</affiliation></author>
      <pages>1954-1974</pages>
      <abstract>While modern masked language models (LMs) are trained on ever larger corpora, we here explore the effects of down-scaling training to a modestly-sized but representative, well-balanced, and publicly available English text source – the British National Corpus. We show that pre-training on this carefully curated corpus can reach better performance than the original BERT model. We argue that this type of corpora has great potential as a language modeling benchmark. To showcase this potential, we present fair, reproducible and data-efficient comparative studies of LMs, in which we evaluate several training objectives and model architectures and replicate previous empirical results in a systematic way. We propose an optimized LM architecture called LTG-BERT.</abstract>
      <url hash="6ce1ab43">2023.findings-eacl.146</url>
      <bibkey>samuel-etal-2023-trained</bibkey>
      <video href="2023.findings-eacl.146.mp4"/>
      <doi>10.18653/v1/2023.findings-eacl.146</doi>
    </paper>
    <paper id="147">
      <title>Generating Synthetic Speech from <fixed-case>S</fixed-case>poken<fixed-case>V</fixed-case>ocab for Speech Translation</title>
      <author><first>Jinming</first><last>Zhao</last><affiliation>Dept of Data Science and AI, Faculty of IT, Monash University</affiliation></author>
      <author><first>Gholamreza</first><last>Haffari</last><affiliation>Monash University</affiliation></author>
      <author><first>Ehsan</first><last>Shareghi</last><affiliation>Monash University</affiliation></author>
      <pages>1975-1981</pages>
      <abstract>Training end-to-end speech translation (ST) systems requires sufficiently large-scale data, which is unavailable for most language pairs and domains. One practical solution to the data scarcity issue is to convert text-based machine translation (MT) data to ST data via text-to-speech (TTS) systems. Yet, using TTS systems can be tedious and slow. In this work, we propose SpokenVocab, a simple, scalable and effective data augmentation technique to convert MT data to ST data on-the-fly. The idea is to retrieve and stitch audio snippets, corresponding to words in an MT sentence, from a spoken vocabulary bank. Our experiments on multiple language pairs show that stitched speech helps to improve translation quality by an average of 1.83 BLEU score, while performing equally well as TTS-generated speech in improving translation quality. We also showcase how SpokenVocab can be applied in code-switching ST for which often no TTS systems exit.</abstract>
      <url hash="f319dd4c">2023.findings-eacl.147</url>
      <bibkey>zhao-etal-2023-generating</bibkey>
      <video href="2023.findings-eacl.147.mp4"/>
      <doi>10.18653/v1/2023.findings-eacl.147</doi>
    </paper>
    <paper id="148">
      <title>Bounding the Capabilities of Large Language Models in Open Text Generation with Prompt Constraints</title>
      <author><first>Albert</first><last>Lu</last><affiliation>Georgia Institute of Technology</affiliation></author>
      <author><first>Hongxin</first><last>Zhang</last><affiliation>Shanghai Jiao Tong University</affiliation></author>
      <author><first>Yanzhe</first><last>Zhang</last><affiliation>Georgia Institute of Technology</affiliation></author>
      <author><first>Xuezhi</first><last>Wang</last><affiliation>Google</affiliation></author>
      <author><first>Diyi</first><last>Yang</last><affiliation>Stanford University</affiliation></author>
      <pages>1982-2008</pages>
      <abstract>The limits of open-ended generative models are unclear, yet increasingly important. What causes them to succeed and what causes them to fail? In this paper, we take a prompt-centric approach to analyzing and bounding the abilities of open-ended generative models. We present a generic methodology of analysis with two challenging prompt constraint types: structural and stylistic. These constraint types are categorized into a set of well-defined constraints that are analyzable by a single prompt. We then systematically create a diverse set of simple, natural, and useful prompts to robustly analyze each individual constraint. Using the GPT-3 text-davinci-002 model as a case study, we generate outputs from our collection of prompts and analyze the model’s generative failures. We also show the generalizability of our proposed method on other large models like BLOOM and OPT. Our results and our in-context mitigation strategies reveal open challenges for future research.</abstract>
      <url hash="6f809fd3">2023.findings-eacl.148</url>
      <bibkey>lu-etal-2023-bounding</bibkey>
      <video href="2023.findings-eacl.148.mp4"/>
      <doi>10.18653/v1/2023.findings-eacl.148</doi>
    </paper>
    <paper id="149">
      <title>Learning to Retrieve Engaging Follow-Up Queries</title>
      <author><first>Christopher</first><last>Richardson</last><affiliation>Georgia Institute of Technology</affiliation></author>
      <author><first>Sudipta</first><last>Kar</last><affiliation>Amazon Alexa AI</affiliation></author>
      <author><first>Anjishnu</first><last>Kumar</last><affiliation>Amazon Alexa</affiliation></author>
      <author><first>Anand</first><last>Ramachandran</last><affiliation>Amazon</affiliation></author>
      <author><first>Zeynab</first><last>Raeesy</last><affiliation>Amazon</affiliation></author>
      <author><first>Omar</first><last>Khan</last><affiliation>Amazon</affiliation></author>
      <author><first>Abhinav</first><last>Sethy</last><affiliation>Amazon</affiliation></author>
      <pages>2009-2016</pages>
      <abstract>Open domain conversational agents can answer a broad range of targeted queries. However, the sequential nature of interaction with these systems makes knowledge exploration a lengthy task which burdens the user with asking a chain of well phrased questions. In this paper, we present a retrieval based system and associated dataset for predicting the next questions that the user might have. Such a system can proactively assist users in knowledge exploration leading to a more engaging dialog. The retrieval system is trained on a dataset called the Follow-up Query Bank (FQ-Bank). FQ-Bank contains ~14K multi-turn information-seeking conversations with a valid follow-up question and a set of invalid candidates. The invalid candidates are generated to simulate various syntactic and semantic confounders such as paraphrases, partial entity match, irrelevant entity, and ASR errors. We use confounder specific techniques to simulate these negative examples on the OR-QuAC dataset. Then, we train ranking models on FQ-Bank and present results comparing supervised and unsupervised approaches. The results suggest that we can retrieve the valid follow-ups by ranking them in higher positions compared to confounders, but further knowledge grounding can improve ranking performance.FQ-Bank is publicly available at <url>https://github.com/amazon-science/fq-bank</url>.</abstract>
      <url hash="45df0353">2023.findings-eacl.149</url>
      <bibkey>richardson-etal-2023-learning</bibkey>
      <video href="2023.findings-eacl.149.mp4"/>
      <doi>10.18653/v1/2023.findings-eacl.149</doi>
    </paper>
    <paper id="150">
      <title>Selective-<fixed-case>LAMA</fixed-case>: Selective Prediction for Confidence-Aware Evaluation of Language Models</title>
      <author><first>Hiyori</first><last>Yoshikawa</last><affiliation>Fujitsu Limited</affiliation></author>
      <author><first>Naoaki</first><last>Okazaki</last><affiliation>Tokyo Institute of Technology</affiliation></author>
      <pages>2017-2028</pages>
      <abstract>Recent studies have suggested that neural language models learn and store a large amount of facts and commonsense knowledge from training data. The ability of language models to restore such knowledge is often evaluated via zero-shot cloze-style QA tasks. However, such evaluations rely only on prediction accuracy without punishing the systems for their mistakes, e.g., simply guessing or hallucinating likely answers. Selective prediction is a more informative evaluation framework that takes the confidence of predictions into account. Under the selective prediction setting, a model is evaluated not only by the number of correct predictions, but also by the ability to filter out dubious predictions by estimating the confidence of individual predictions. Such confidence-aware evaluation is crucial for determining whether to trust zero-shot predictions of language models. In this paper, we apply the selective prediction setting to an existing benchmark, LAMA probe, and conduct extensive experiments with recent neural language models and different confidence functions. We empirically show that our Selective-LAMA evaluation is more robust to the effect of simple guesses than the conventional accuracy-based evaluation. Our evaluation reveals the importance of the choice of confidence functions by showing that simply relying on token probabilities is not always the best choice. Further analysis shows that various confidence functions exhibit different preferences over predicted tokens for a given context.</abstract>
      <url hash="270b8411">2023.findings-eacl.150</url>
      <attachment type="software" hash="ef302ab8">2023.findings-eacl.150.software.zip</attachment>
      <bibkey>yoshikawa-okazaki-2023-selective</bibkey>
      <video href="2023.findings-eacl.150.mp4"/>
      <doi>10.18653/v1/2023.findings-eacl.150</doi>
    </paper>
    <paper id="151">
      <title>Multi-View Source Ablation for Faithful Summarization</title>
      <author><first>Shuyang</first><last>Cao</last><affiliation>Univerisity of Michigan</affiliation></author>
      <author><first>Liang</first><last>Ma</last><affiliation>Dataminr</affiliation></author>
      <author><first>Di</first><last>Lu</last><affiliation>Dataminr</affiliation></author>
      <author><first>Robert L</first><last>Logan IV</last><affiliation>Dataminr</affiliation></author>
      <author><first>Joel</first><last>Tetreault</last><affiliation>Dataminr</affiliation></author>
      <author><first>Alejandro</first><last>Jaimes</last><affiliation>Dataminr</affiliation></author>
      <pages>2029-2047</pages>
      <abstract>In this paper, we present MuFaSSa (Multi-view Faithfulness Scoring via Source Ablation), a metric for evaluating faithfulness of abstractive summaries, and for guiding training of more faithful summarizers. For evaluation, MuFaSSa employs different strategies (e.g., masking entity mentions) to first remove information from the source document to form multiple ablated views. Then, the faithfulness level of each token in a generated summary is measured by the difference between the token generation probabilities when given the original document and the ablated document as inputs to trained summarizers. For training, MuFaSSa uses a novel word truncation objective that drops unfaithful tokens located by MuFaSSa in both the decoder input and output. Alignments with human-annotated faithfulness labels on AggreFact show that MuFaSSa is comparable to or better than existing metrics built on classifiers or QA models pre-trained on other tasks. In experiments on summarization with XSum and CNN/DailyMail, models trained with word truncation using MuFaSSa outperform competitive methods according to both automatic faithfulness metrics and human assessments.</abstract>
      <url hash="77e28880">2023.findings-eacl.151</url>
      <bibkey>cao-etal-2023-multi</bibkey>
      <video href="2023.findings-eacl.151.mp4"/>
      <doi>10.18653/v1/2023.findings-eacl.151</doi>
    </paper>
    <paper id="152">
      <title>Mining Effective Features Using Quantum Entropy for Humor Recognition</title>
      <author id="yang-liu-tianjin"><first>Yang</first><last>Liu</last><affiliation>College of Intelligence and Computing, Tianjin University, Tianjin, China</affiliation></author>
      <author><first>Yuexian</first><last>Hou</last><affiliation>College of Intelligence and Computing, Tianjin University, Tianjin, China</affiliation></author>
      <pages>2048-2053</pages>
      <abstract>Humor recognition has been extensively studied with different methods in the past years. However, existing studies on humor recognition do not understand the mechanisms that generate humor. In this paper, inspired by the incongruity theory, any joke can be divided into two components (the setup and the punchline). Both components have multiple possible semantics, and there is an incongruous relationship between them. We use density matrices to represent the semantic uncertainty of the setup and the punchline, respectively, and design QE-Uncertainty and QE-Incongruity with the help of quantum entropy as features for humor recognition. The experimental results on the SemEval2021 Task 7 dataset show that the proposed features are more effective than the baselines for recognizing humorous and non-humorous texts.</abstract>
      <url hash="40e55e09">2023.findings-eacl.152</url>
      <attachment type="dataset" hash="e117da59">2023.findings-eacl.152.dataset.rar</attachment>
      <bibkey>liu-hou-2023-mining</bibkey>
      <video href="2023.findings-eacl.152.mp4"/>
      <doi>10.18653/v1/2023.findings-eacl.152</doi>
    </paper>
    <paper id="153">
      <title><fixed-case>A</fixed-case>dapter<fixed-case>S</fixed-case>oup: Weight Averaging to Improve Generalization of Pretrained Language Models</title>
      <author><first>Alexandra</first><last>Chronopoulou</last><affiliation>LMU Munich</affiliation></author>
      <author><first>Matthew</first><last>Peters</last><affiliation>Allen Institute for Artificial Intelligence</affiliation></author>
      <author><first>Alexander</first><last>Fraser</last><affiliation>Ludwig-Maximilians-Universität München</affiliation></author>
      <author><first>Jesse</first><last>Dodge</last><affiliation>Allen Institute for AI</affiliation></author>
      <pages>2054-2063</pages>
      <abstract>Pretrained language models (PLMs) are trained on massive corpora, but often need to specialize to specific domains. A parameter-efficient adaptation method suggests training an adapter for each domain on the task of language modeling. This leads to good in-domain scores but can be impractical for domain- or resource-restricted settings. A solution is to use a related-domain adapter for the novel domain at test time. In this paper, we introduce AdapterSoup, an approach that performs weight-space averaging of adapters trained on different domains. Our approach is embarrassingly parallel: first, we train a set of domain-specific adapters; then, for each novel domain, we determine which adapters should be averaged at test time. We present extensive experiments showing that AdapterSoup consistently improves performance to new domains without extra training. We also explore weight averaging of adapters trained on the same domain with different hyper-parameters, and show that it preserves the performance of a PLM on new domains while obtaining strong in-domain results. We explore various approaches for choosing which adapters to combine, such as text clustering and semantic similarity. We find that using clustering leads to the most competitive results on novel domains.</abstract>
      <url hash="4e92467b">2023.findings-eacl.153</url>
      <bibkey>chronopoulou-etal-2023-adaptersoup</bibkey>
      <video href="2023.findings-eacl.153.mp4"/>
      <doi>10.18653/v1/2023.findings-eacl.153</doi>
    </paper>
    <paper id="154">
      <title>Towards End-to-End Open Conversational Machine Reading</title>
      <author><first>Sizhe</first><last>Zhou</last><affiliation>Shanghai Jiao Tong University</affiliation></author>
      <author><first>Siru</first><last>Ouyang</last><affiliation>University of Illinois Urbana-Champaign</affiliation></author>
      <author><first>Zhuosheng</first><last>Zhang</last><affiliation>Shanghai Jiao Tong University</affiliation></author>
      <author><first>Hai</first><last>Zhao</last><affiliation>Shanghai Jiao Tong University</affiliation></author>
      <pages>2064-2076</pages>
      <abstract>In open-retrieval conversational machine reading (OR-CMR) task, machines are required to do multi-turn question answering given dialogue history and a textual knowledge base. Existing works generally utilize two independent modules to approach this problem’s two successive sub-tasks: first with a hard-label decision making and second with a question generation aided by various entailment reasoning methods. Such usual cascaded modeling is vulnerable to error propagation and prevents the two sub-tasks from being consistently optimized. In this work, we instead model OR-CMR as a unified text-to-text task in a fully end-to-end style. Experiments on the ShARC and OR-ShARC dataset show the effectiveness of our proposed end-to-end framework on both sub-tasks by a large margin, achieving new state-of-the-art results. Further ablation studies support that our framework can generalize to different backbone models.</abstract>
      <url hash="74f2a5b6">2023.findings-eacl.154</url>
      <bibkey>zhou-etal-2023-towards</bibkey>
      <video href="2023.findings-eacl.154.mp4"/>
      <doi>10.18653/v1/2023.findings-eacl.154</doi>
    </paper>
    <paper id="155">
      <title>Generative Knowledge Selection for Knowledge-Grounded Dialogues</title>
      <author><first>Weiwei</first><last>Sun</last><affiliation>Shandong University</affiliation></author>
      <author><first>Pengjie</first><last>Ren</last><affiliation>Shandong University</affiliation></author>
      <author><first>Zhaochun</first><last>Ren</last><affiliation>Shandong University</affiliation></author>
      <pages>2077-2088</pages>
      <abstract>Knowledge selection is the key in knowledge-grounded dialogues (KGD), which aims to select an appropriate knowledge snippet to be used in the utterance based on dialogue history. Previous studies mainly employ the classification approach to classify each candidate snippet as “relevant” or “irrelevant” independently. However, such approaches neglect the interactions between snippets, leading to difficulties in inferring the meaning of snippets. Moreover, they lack modeling of the discourse structure of dialogue-knowledge interactions. We propose a simple yet effective generative approach for knowledge selection, called GenKS. GenKS learns to select snippets by generating their identifiers with a sequence-to-sequence model. GenKS therefore captures intra-knowledge interaction inherently through attention mechanisms. Meanwhile, we devise a hyperlink mechanism to model the dialogue-knowledge interactions explicitly. We conduct experiments on three benchmark datasets, and verify GenKS achieves the best results on both knowledge selection and response generation.</abstract>
      <url hash="93a1f155">2023.findings-eacl.155</url>
      <bibkey>sun-etal-2023-generative</bibkey>
      <video href="2023.findings-eacl.155.mp4"/>
      <doi>10.18653/v1/2023.findings-eacl.155</doi>
    </paper>
    <paper id="156">
      <title>Evaluating the Tradeoff Between Abstractiveness and Factuality in Abstractive Summarization</title>
      <author><first>Markus</first><last>Dreyer</last><affiliation>Amazon.com</affiliation></author>
      <author><first>Mengwen</first><last>Liu</last><affiliation>Amazon</affiliation></author>
      <author><first>Feng</first><last>Nan</last><affiliation>Aws Ai</affiliation></author>
      <author><first>Sandeep</first><last>Atluri</last><affiliation>Amazon</affiliation></author>
      <author><first>Sujith</first><last>Ravi</last><affiliation>SliceX AI</affiliation></author>
      <pages>2089-2105</pages>
      <abstract>Neural models for abstractive summarization tend to generate output that is fluent and well-formed but lacks semantic faithfulness, or factuality, with respect to the input documents. In this paper, we analyze the tradeoff between abstractiveness and factuality of generated summaries across multiple datasets and models, using extensive human evaluations of factuality. In our analysis, we visualize the rates of change in factuality as we gradually increase abstractiveness using a decoding constraint, and we observe that, while increased abstractiveness generally leads to a drop in factuality, the rate of factuality decay depends on factors such as the data that the system was trained on. We introduce two datasets with human factuality judgements; one containing 10.2k generated summaries with systematically varied degrees of abstractiveness; the other containing 4.2k summaries from five different summarization models. We propose new factuality metrics that adjust for the degree of abstractiveness, and we use them to compare the abstractiveness-adjusted factuality of previous summarization works, providing baselines for future work.</abstract>
      <url hash="be27149d">2023.findings-eacl.156</url>
      <bibkey>dreyer-etal-2023-evaluating</bibkey>
      <video href="2023.findings-eacl.156.mp4"/>
      <doi>10.18653/v1/2023.findings-eacl.156</doi>
    </paper>
    <paper id="157">
      <title>Fairness in Language Models Beyond <fixed-case>E</fixed-case>nglish: Gaps and Challenges</title>
      <author><first>Krithika</first><last>Ramesh</last><affiliation>Microsoft Research India</affiliation></author>
      <author><first>Sunayana</first><last>Sitaram</last><affiliation>Microsoft Research India</affiliation></author>
      <author><first>Monojit</first><last>Choudhury</last><affiliation>Microsoft</affiliation></author>
      <pages>2106-2119</pages>
      <abstract>With language models becoming increasingly ubiquitous, it has become essential to address their inequitable treatment of diverse demographic groups and factors. Most research on evaluating and mitigating fairness harms has been concentrated on English, while multilingual models and non-English languages have received comparatively little attention. In this paper, we survey different aspects of fairness in languages beyond English and multilingual contexts. This paper presents a survey of fairness in multilingual and non-English contexts, highlighting the shortcomings of current research and the difficulties faced by methods designed for English. We contend that the multitude of diverse cultures and languages across the world makes it infeasible to achieve comprehensive coverage in terms of constructing fairness datasets. Thus, the measurement and mitigation of biases must evolve beyond the current dataset-driven practices that are narrowly focused on specific dimensions and types of biases and, therefore, impossible to scale across languages and cultures.</abstract>
      <url hash="2844454f">2023.findings-eacl.157</url>
      <bibkey>ramesh-etal-2023-fairness</bibkey>
      <video href="2023.findings-eacl.157.mp4"/>
      <doi>10.18653/v1/2023.findings-eacl.157</doi>
    </paper>
    <paper id="158">
      <title>Global-Local Modeling with Prompt-Based Knowledge Enhancement for Emotion Inference in Conversation</title>
      <author><first>Renxi</first><last>Wang</last><affiliation>Northeastern University, China</affiliation></author>
      <author><first>Shi</first><last>Feng</last><affiliation>Northeastern University, China</affiliation></author>
      <pages>2120-2127</pages>
      <abstract>The ability to recognize emotions in conversations is necessary and important for the online chatbot to do tasks such as empathetic response generation and emotional support. Present researches mainly focus on recognizing emotions through a speaker’s utterance, while research on emotion inference predicts emotions of addressees through previous utterances. Because of the lack of the addressee’s utterance, emotion inference is more challenging than emotion recognition. In this paper, we propose a global-local modeling method based on recurrent neural networks (RNN) and pre-trained language models (PLM) to do emotion inference, which utilizes the sequence modeling ability of RNNs and abundant knowledge from PLMs. Moreover, we take the whole dialogue history as input of PLM to generate knowledge by in-context learning. Experimental results show that our model with knoledge enhancement achieves state-of-the-art performance on all three datasets.</abstract>
      <url hash="13b20ab3">2023.findings-eacl.158</url>
      <attachment type="dataset" hash="b7ae075f">2023.findings-eacl.158.dataset.zip</attachment>
      <bibkey>wang-feng-2023-global</bibkey>
      <video href="2023.findings-eacl.158.mp4"/>
      <doi>10.18653/v1/2023.findings-eacl.158</doi>
    </paper>
    <paper id="159">
      <title>Headline Token-based Discriminative Learning for Subheading Generation in News Article</title>
      <author><first>Joonwon</first><last>Jang</last><affiliation>Sejong University</affiliation></author>
      <author><first>Misuk</first><last>Kim</last><affiliation>Sejong University</affiliation></author>
      <pages>2128-2135</pages>
      <abstract>The news subheading summarizes an article’s contents in several sentences to support the headline limited to solely conveying the main contents. So, it is necessary to generate compelling news subheadings in consideration of the structural characteristics of the news. In this paper, we propose a subheading generation model using topical headline information. We introduce a discriminative learning method that utilizes the prediction result of masked headline tokens. Experiments show that the proposed model is effective and outperforms the comparative models on three news datasets written in two languages. We also show that our model performs robustly on a small dataset and various masking ratios. Qualitative analysis and human evaluations also show that the overall quality of generated subheadings improved over the comparative models.</abstract>
      <url hash="1e09fa7d">2023.findings-eacl.159</url>
      <attachment type="dataset" hash="ef34f709">2023.findings-eacl.159.dataset.zip</attachment>
      <bibkey>jang-kim-2023-headline</bibkey>
      <video href="2023.findings-eacl.159.mp4"/>
      <doi>10.18653/v1/2023.findings-eacl.159</doi>
    </paper>
    <paper id="160">
      <title>Decipherment as Regression: Solving Historical Substitution Ciphers by Learning Symbol Recurrence Relations</title>
      <author><first>Nishant</first><last>Kambhatla</last><affiliation>Simon Fraser University</affiliation></author>
      <author><first>Logan</first><last>Born</last><affiliation>Simon Fraser University</affiliation></author>
      <author><first>Anoop</first><last>Sarkar</last><affiliation>Simon Fraser University</affiliation></author>
      <pages>2136-2152</pages>
      <abstract>Solving substitution ciphers involves mapping sequences of cipher symbols to fluent text in a target language. This has conventionally been formulated as a search problem, to find the decipherment key using a character-level language model to constrain the search space. This work instead frames decipherment as a sequence prediction task, using a Transformer-based causal language model to learn recurrences between characters in a ciphertext. We introduce a novel technique for transcribing arbitrary substitution ciphers into a common recurrence encoding. By leveraging this technique, we (i) create a large synthetic dataset of homophonic ciphers using random keys, and (ii) train a decipherment model that predicts the plaintext sequence given a recurrence-encoded ciphertext. Our method achieves strong results on synthetic 1:1 and homophonic ciphers, and cracks several real historic homophonic ciphers. Our analysis shows that the model learns recurrence relations between cipher symbols and recovers decipherment keys in its self-attention.</abstract>
      <url hash="74cb7b46">2023.findings-eacl.160</url>
      <bibkey>kambhatla-etal-2023-decipherment</bibkey>
      <video href="2023.findings-eacl.160.mp4"/>
      <doi>10.18653/v1/2023.findings-eacl.160</doi>
    </paper>
    <paper id="161">
      <title>A Survey on Recent Advances in Keyphrase Extraction from Pre-trained Language Models</title>
      <author><first>Mingyang</first><last>Song</last><affiliation>Beijing Jiaotong University</affiliation></author>
      <author><first>Yi</first><last>Feng</last><affiliation>BeiJing JiaoTong University</affiliation></author>
      <author><first>Liping</first><last>Jing</last><affiliation>Beijing Jiaotong Univesity</affiliation></author>
      <pages>2153-2164</pages>
      <abstract>Keyphrase Extraction (KE) is a critical component in Natural Language Processing (NLP) systems for selecting a set of phrases from the document that could summarize the important information discussed in the document. Typically, a keyphrase extraction system can significantly accelerate the speed of information retrieval and help people get first-hand information from a long document quickly and accurately. Specifically, keyphrases are capable of providing semantic metadata characterizing documents and producing an overview of the content of a document. In this paper, we introduce keyphrase extraction, present a review of the recent studies based on pre-trained language models, offer interesting insights on the different approaches, highlight open issues, and give a comparative experimental study of popular supervised as well as unsupervised techniques on several datasets. To encourage more instantiations, we release the related files mentioned in this paper.</abstract>
      <url hash="79dec4d8">2023.findings-eacl.161</url>
      <bibkey>song-etal-2023-survey</bibkey>
      <video href="2023.findings-eacl.161.mp4"/>
      <doi>10.18653/v1/2023.findings-eacl.161</doi>
    </paper>
    <paper id="162">
      <title>Prompting for explanations improves Adversarial <fixed-case>NLI</fixed-case>. Is this true? {Yes} it is {true} because {it weakens superficial cues}</title>
      <author><first>Pride</first><last>Kavumba</last><affiliation>Tohoku University / RIKEN AIP</affiliation></author>
      <author><first>Ana</first><last>Brassard</last><affiliation>RIKEN AIP / Tohoku University</affiliation></author>
      <author><first>Benjamin</first><last>Heinzerling</last><affiliation>RIKEN AIP &amp; Tohoku University</affiliation></author>
      <author><first>Kentaro</first><last>Inui</last><affiliation>Tohoku University / Riken</affiliation></author>
      <pages>2165-2180</pages>
      <abstract>Explanation prompts ask language models to not only assign a particular label to a giveninput, such as true, entailment, or contradiction in the case of natural language inference but also to generate a free-text explanation that supports this label. For example: “This is label because explanation.” While this type of prompt was originally introduced with the aim of improving model interpretability, we showhere that explanation prompts also improve robustness to adversarial perturbations in naturallanguage inference benchmarks. Compared to prompting for labels only, explanation prompting consistently yields stronger performance on adversarial benchmarks, outperforming the state of the art on Adversarial Natural Language Inference, Counterfactually-Augmented Natural Language Inference, and SNLI-Hard datasets. We argue that the increase in robustness is due to the fact that prompting for explanations weakens superficial cues. Specifically, single tokens that are highly predictive of the correct answer in the label-only setting become uninformative when the model also has to generate explanations.</abstract>
      <url hash="aa869a9e">2023.findings-eacl.162</url>
      <bibkey>kavumba-etal-2023-prompting</bibkey>
      <video href="2023.findings-eacl.162.mp4"/>
      <doi>10.18653/v1/2023.findings-eacl.162</doi>
    </paper>
    <paper id="163">
      <title><fixed-case>J</fixed-case>ob<fixed-case>XMLC</fixed-case>: <fixed-case>EX</fixed-case>treme Multi-Label Classification of Job Skills with Graph Neural Networks</title>
      <author><first>Nidhi</first><last>Goyal</last><affiliation>Iiit</affiliation></author>
      <author><first>Jushaan</first><last>Kalra</last><affiliation>PreCog</affiliation></author>
      <author><first>Charu</first><last>Sharma</last><affiliation>International Institute of Information Technology Hyderabad</affiliation></author>
      <author><first>Raghava</first><last>Mutharaju</last><affiliation>IIIT-Delhi</affiliation></author>
      <author><first>Niharika</first><last>Sachdeva</last><affiliation>Infoedge</affiliation></author>
      <author><first>Ponnurangam</first><last>Kumaraguru</last><affiliation>IIIT Hyderabad</affiliation></author>
      <pages>2181-2191</pages>
      <abstract>Writing a good job description is an important step in the online recruitment process to hire the best candidates. Most recruiters forget to include some relevant skills in the job description. These missing skills affect the performance of recruitment tasks such as job suggestions, job search, candidate recommendations, etc. Existing approaches are limited to contextual modelling, do not exploit inter-relational structures like job-job and job-skill relationships, and are not scalable. In this paper, we exploit these structural relationships using a graph-based approach. We propose a novel skill prediction framework called JobXMLC, which uses graph neural networks with skill attention to predict missing skills using job descriptions. JobXMLC enables joint learning over a job-skill graph consisting of 22.8K entities (jobs and skills) and 650K relationships. We experiment with real-world recruitment datasets to evaluate our proposed approach. We train JobXMLC on 20,298 job descriptions and 2,548 skills within 30 minutes on a single GPU machine. JobXMLC outperforms the state-of-the-art approaches by 6% in precision and 3% in recall. JobXMLC is 18X faster for training task and up to 634X faster in skill prediction on benchmark datasets enabling JobXMLC to scale up on larger datasets.</abstract>
      <url hash="67881392">2023.findings-eacl.163</url>
      <bibkey>goyal-etal-2023-jobxmlc</bibkey>
      <doi>10.18653/v1/2023.findings-eacl.163</doi>
    </paper>
    <paper id="164">
      <title><fixed-case>V</fixed-case>i<fixed-case>LPA</fixed-case>ct: A Benchmark for Compositional Generalization on Multimodal Human Activities</title>
      <author><first>Terry Yue</first><last>Zhuo</last><affiliation>CSIRO’s Data61 and Monash University</affiliation></author>
      <author><first>Yaqing</first><last>Liao</last><affiliation>University of Electronic Science and Technology of China</affiliation></author>
      <author><first>Yuecheng</first><last>Lei</last><affiliation>University of Electronic Science and Technology of China</affiliation></author>
      <author><first>Lizhen</first><last>Qu</last><affiliation>Monash University</affiliation></author>
      <author><first>Gerard</first><last>de Melo</last><affiliation>HPI/University of Potsdam</affiliation></author>
      <author><first>Xiaojun</first><last>Chang</last><affiliation>University of Technology Sydney</affiliation></author>
      <author><first>Yazhou</first><last>Ren</last><affiliation>University of Electronic Science and Technology of China</affiliation></author>
      <author><first>Zenglin</first><last>Xu</last><affiliation>Harbin Institute of Technology</affiliation></author>
      <pages>2192-2207</pages>
      <abstract>We introduce <tex-math>\texttt{ViLPAct}</tex-math>, a novel vision-language benchmark for human activity planning. It is designed for a task where embodied AI agents can reason and forecast future actions of humans based on video clips about their initial activities and intents in text. The dataset consists of 2.9k videos from <tex-math>\texttt{Charades}</tex-math> extended with intents via crowdsourcing, a multi-choice question test set, and four strong baselines. One of the baselines implements a neurosymbolic approach based on a multi-modal knowledge base (MKB), while the other ones are deep generative models adapted from recent state-of-the-art (SOTA) methods. According to our extensive experiments, the key challenges are compositional generalization and effective use of information from both modalities.</abstract>
      <url hash="b613eda2">2023.findings-eacl.164</url>
      <bibkey>zhuo-etal-2023-vilpact</bibkey>
      <video href="2023.findings-eacl.164.mp4"/>
      <doi>10.18653/v1/2023.findings-eacl.164</doi>
    </paper>
    <paper id="165">
      <title>Grammatical Error Correction through Round-Trip Machine Translation</title>
      <author><first>Yova</first><last>Kementchedjhieva</last><affiliation>University of Copenhagen</affiliation></author>
      <author><first>Anders</first><last>Søgaard</last><affiliation>University of Copenhagen</affiliation></author>
      <pages>2208-2215</pages>
      <abstract>Machine translation (MT) operates on the premise of an interlingua which abstracts away from surface form while preserving meaning. A decade ago the idea of using round-trip MT to guide grammatical error correction was proposed as a way to abstract away from potential errors in surface forms (Madnani et al., 2012). At the time, it did not pan out due to the low quality of MT systems of the day. Today much stronger MT systems are available so we re-evaluate this idea across five languages and models of various sizes. We find that for extra large models input augmentation through round-trip MT has little to no effect. For more ‘workable’ model sizes, however, it yields consistent improvements, sometimes bringing the performance of a <i>base</i> or <i>large</i> model up to that of a <i>large</i> or <i>xl</i> model, respectively. The round-trip translation comes at a computational cost though, so one would have to determine whether to opt for a larger model or for input augmentation on a case-by-case basis.</abstract>
      <url hash="2d237fc0">2023.findings-eacl.165</url>
      <bibkey>kementchedjhieva-sogaard-2023-grammatical</bibkey>
      <video href="2023.findings-eacl.165.mp4"/>
      <doi>10.18653/v1/2023.findings-eacl.165</doi>
    </paper>
    <paper id="166">
      <title>Does Masked Language Model Pre-training with Artificial Data Improve Low-resource Neural Machine Translation?</title>
      <author><first>Hiroto</first><last>Tamura</last><affiliation>Tokyo Metropolitan University</affiliation></author>
      <author><first>Tosho</first><last>Hirasawa</last><affiliation>Tokyo Metropolitan University</affiliation></author>
      <author><first>Hwichan</first><last>Kim</last><affiliation>Tokyo Metropolitan University</affiliation></author>
      <author><first>Mamoru</first><last>Komachi</last><affiliation>Tokyo Metropolitan University</affiliation></author>
      <pages>2216-2225</pages>
      <abstract>Pre-training masked language models (MLMs) with artificial data has been proven beneficial for several natural language processing tasks such as natural language understanding and summarization; however, it has been less explored for neural machine translation (NMT).A previous study revealed the benefit of transfer learning for NMT in a limited setup, which differs from MLM.In this study, we prepared two kinds of artificial data and compared the translation performance of NMT when pre-trained with MLM.In addition to the random sequences, we created artificial data mimicking token frequency information from the real world. Our results showed that pre-training the models with artificial data by MLM improves translation performance in low-resource situations. Additionally, we found that pre-training on artificial data created considering token frequency information facilitates improved performance.</abstract>
      <url hash="43771cb6">2023.findings-eacl.166</url>
      <bibkey>tamura-etal-2023-masked</bibkey>
      <video href="2023.findings-eacl.166.mp4"/>
      <doi>10.18653/v1/2023.findings-eacl.166</doi>
    </paper>
    <paper id="167">
      <title>Performance and Risk Trade-offs for Multi-word Text Prediction at Scale</title>
      <author><first>Aniket</first><last>Vashishtha</last><affiliation>Microsoft Research India</affiliation></author>
      <author><first>S Sai</first><last>Prasad</last><affiliation>Microsoft</affiliation></author>
      <author><first>Payal</first><last>Bajaj</last><affiliation>Microsoft</affiliation></author>
      <author><first>Vishrav</first><last>Chaudhary</last><affiliation>Microsoft</affiliation></author>
      <author><first>Kate</first><last>Cook</last><affiliation>Microsoft</affiliation></author>
      <author><first>Sandipan</first><last>Dandapat</last><affiliation>Microsoft India</affiliation></author>
      <author><first>Sunayana</first><last>Sitaram</last><affiliation>Microsoft Research India</affiliation></author>
      <author><first>Monojit</first><last>Choudhury</last><affiliation>Microsoft</affiliation></author>
      <pages>2226-2242</pages>
      <abstract>Large Language Models such as GPT-3 are well-suited for text prediction tasks, which can help and delight users during text composition. LLMs are known to generate ethically inappropriate predictions even for seemingly innocuous contexts. Toxicity detection followed by filtering is a common strategy for mitigating the harm from such predictions. However, as we shall argue in this paper, in the context of text prediction, it is not sufficient to detect and filter toxic content. One also needs to ensure factual correctness and group-level fairness of the predictions; failing to do so can make the system ineffective and nonsensical at best, and unfair and detrimental to the users at worst. We discuss the gaps and challenges of toxicity detection approaches - from blocklist-based approaches to sophisticated state-of-the-art neural classifiers - by evaluating them on the text prediction task for English against a manually crafted CheckList of harms targeted at different groups and different levels of severity.</abstract>
      <url hash="f7d08d89">2023.findings-eacl.167</url>
      <bibkey>vashishtha-etal-2023-performance</bibkey>
      <video href="2023.findings-eacl.167.mp4"/>
      <doi>10.18653/v1/2023.findings-eacl.167</doi>
    </paper>
    <paper id="168">
      <title>Searching for Better Database Queries in the Outputs of Semantic Parsers</title>
      <author><first>Anton</first><last>Osokin</last><affiliation>HSE University, Yandex</affiliation></author>
      <author><first>Irina</first><last>Saparina</last><affiliation>HSE University, Yandex</affiliation></author>
      <author><first>Ramil</first><last>Yarullin</last><affiliation>HSE University, Yandex</affiliation></author>
      <pages>2243-2256</pages>
      <abstract>The task of generating a database query from a question in natural language suffers from ambiguity and insufficiently precise description of the goal. The problem is amplified when the system needs to generalize to databases unseen at training. In this paper, we consider the case when, at the test time, the system has access to an external criterion that evaluates the generated queries. The criterion can vary from checking that a query executes without errors to verifying the query on a set of tests. In this setting, we augment neural autoregressive models with a search algorithm that looks for a query satisfying the criterion. We apply our approach to the state-of-the-art semantic parsers and report that it allows us to find many queries passing all the tests on different datasets.</abstract>
      <url hash="cb389ec2">2023.findings-eacl.168</url>
      <bibkey>osokin-etal-2023-searching</bibkey>
      <doi>10.18653/v1/2023.findings-eacl.168</doi>
    </paper>
    <paper id="169">
      <title>Style-Aware Contrastive Learning for Multi-Style Image Captioning</title>
      <author><first>Yucheng</first><last>Zhou</last><affiliation>University of Technology Sydney</affiliation></author>
      <author><first>Guodong</first><last>Long</last><affiliation>University of Technology Sydney</affiliation></author>
      <pages>2257-2267</pages>
      <abstract>Existing multi-style image captioning methods show promising results in generating a caption with accurate visual content and desired linguistic style. However, existing methods overlook the relationship between linguistic style and visual content. To overcome this drawback, we propose style-aware contrastive learning for multi-style image captioning. First, we present a style-aware visual encoder with contrastive learning to mine potential visual content relevant to style. Moreover, we propose a style-aware triplet contrast objective to distinguish whether the image, style and caption matched. To provide positive and negative samples for contrastive learning, we present three retrieval schemes: object-based retrieval, RoI-based retrieval and triplet-based retrieval, and design a dynamic trade-off function to calculate retrieval scores. Experimental results demonstrate that our approach achieves state-of-the-art performance. In addition, we conduct an extensive analysis to verify the effectiveness of our method.</abstract>
      <url hash="388e6ec8">2023.findings-eacl.169</url>
      <bibkey>zhou-long-2023-style</bibkey>
      <video href="2023.findings-eacl.169.mp4"/>
      <doi>10.18653/v1/2023.findings-eacl.169</doi>
    </paper>
    <paper id="170">
      <title>Strategize Before Teaching: A Conversational Tutoring System with Pedagogy Self-Distillation</title>
      <author><first>Lingzhi</first><last>Wang</last><affiliation>The Chinese University of Hong Kong</affiliation></author>
      <author><first>Mrinmaya</first><last>Sachan</last><affiliation>ETH Zurich</affiliation></author>
      <author><first>Xingshan</first><last>Zeng</last><affiliation>Huawei Noah’s Ark Lab</affiliation></author>
      <author><first>Kam-Fai</first><last>Wong</last><affiliation>Department of Systems Engineering and Engineering Management, The Chinese University of Hong Kong, Hong Kong</affiliation></author>
      <pages>2268-2274</pages>
      <abstract>Conversational tutoring systems (CTSs) aim to help students master educational material with natural language interaction in the form of a dialog. CTSs have become a key pillar in educational data mining research. A key challenge in CTSs is to engage the student in the conversation while exposing them to a diverse set of teaching strategies, akin to a human teacher, thereby, helping them learn in the process. Different from previous work that generates responses given the strategies as input, we propose to jointly predict teaching strategies and generate tutor responses accordingly, which fits a more realistic application scenario. We benchmark several competitive models on three dialog tutoring datasets and propose a unified framework that combines teaching response generation and pedagogical strategy prediction, where a self-distillation mechanism is adopted to guide the teaching strategy learning and facilitate tutor response generation. Our experiments and analyses shed light on how teaching strategies affect dialog tutoring.</abstract>
      <url hash="3f366ebe">2023.findings-eacl.170</url>
      <bibkey>wang-etal-2023-strategize</bibkey>
      <video href="2023.findings-eacl.170.mp4"/>
      <doi>10.18653/v1/2023.findings-eacl.170</doi>
    </paper>
    <paper id="171">
      <title><fixed-case>ICA</fixed-case>-Proto: Iterative Cross Alignment Prototypical Network for Incremental Few-Shot Relation Classification</title>
      <author><first>Wangjie</first><last>Jiang</last><affiliation>Tsinghua University</affiliation></author>
      <author><first>Zhihao</first><last>Ye</last><affiliation>Tencent Jarvis</affiliation></author>
      <author><first>Bang</first><last>Liu</last><affiliation>University of Montreal</affiliation></author>
      <author><first>Ruihui</first><last>Zhao</last><affiliation>Bytedance</affiliation></author>
      <author><first>Jianguang</first><last>Zheng</last><affiliation>Tencent Jarvis</affiliation></author>
      <author><first>Mengyao</first><last>Li</last><affiliation>Hunan University</affiliation></author>
      <author><first>Zhiyong</first><last>Li</last><affiliation>Hunan University</affiliation></author>
      <author><first>Yujiu</first><last>Yang</last><affiliation>Tsinghua.edu.cn</affiliation></author>
      <author><first>Yefeng</first><last>Zheng</last><affiliation>Tencent</affiliation></author>
      <pages>2275-2284</pages>
      <abstract>In the task of incremental few-shot relation classification, model performance is always limited by the incompatibility between the base feature embedding space and the novel feature embedding space. To tackle the issue, we propose a novel model named ICA-Proto: Iterative Cross Alignment prototypical network. Specifically, we incorporate the query representation into the encoding of novel prototypes and utilize the query-aware prototypes to update the query representation at the same time. Further, we implement the above process iteratively to achieve more interaction. In addition, a novel prototype quadruplet loss is designed to regulate the spatial distributions of embedding space, so as to make it easier for the relation classification. Experimental results on two benchmark datasets demonstrate that ICA-Proto significantly outperforms the state-of-the-art baseline model.</abstract>
      <url hash="c05e2333">2023.findings-eacl.171</url>
      <bibkey>jiang-etal-2023-ica</bibkey>
      <video href="2023.findings-eacl.171.mp4"/>
      <doi>10.18653/v1/2023.findings-eacl.171</doi>
    </paper>
    <paper id="172">
      <title>A Large-Scale Multilingual Study of Visual Constraints on Linguistic Selection of Descriptions</title>
      <author><first>Uri</first><last>Berger</last><affiliation>The Hebrew University of Jerusalem, University of Melbourne</affiliation></author>
      <author><first>Lea</first><last>Frermann</last><affiliation>Melbourne University</affiliation></author>
      <author><first>Gabriel</first><last>Stanovsky</last><affiliation>The Hebrew University of Jerusalem</affiliation></author>
      <author><first>Omri</first><last>Abend</last><affiliation>The Hebrew University of Jerusalem</affiliation></author>
      <pages>2285-2299</pages>
      <abstract>We present a large, multilingual study into how vision constrains linguistic choice, covering four languages and five linguistic properties, such as verb transitivity or use of numerals. We propose a novel method that leverages existing corpora of images with captions written by native speakers, and apply it to nine corpora, comprising 600k images and 3M captions. We study the relation between visual input and linguistic choices by training classifiers to predict the probability of expressing a property from raw images, and find evidence supporting the claim that linguistic properties are constrained by visual context across languages. We complement this investigation with a corpus study, taking the test case of numerals. Specifically, we use existing annotations (number or type of objects) to investigate the effect of different visual conditions on the use of numeral expressions in captions, and show that similar patterns emerge across languages. Our methods and findings both confirm and extend existing research in the cognitive literature. We additionally discuss possible applications for language generation.</abstract>
      <url hash="a44d9367">2023.findings-eacl.172</url>
      <bibkey>berger-etal-2023-large</bibkey>
      <video href="2023.findings-eacl.172.mp4"/>
      <doi>10.18653/v1/2023.findings-eacl.172</doi>
    </paper>
    <paper id="173">
      <title>How Much Syntactic Supervision is “Good Enough”?</title>
      <author><first>Hiroshi</first><last>Noji</last><affiliation>LeapMind Inc.</affiliation></author>
      <author><first>Yohei</first><last>Oseki</last><affiliation>University of Tokyo</affiliation></author>
      <pages>2300-2305</pages>
      <abstract>In this paper, we explore how much syntactic supervision is “good enough” to make language models (LMs) more human-like. Specifically, we propose the new method called syntactic ablation, where syntactic LMs, namely Recurrent Neural Network Grammars (RNNGs), are gradually ablated from full syntactic supervision to zero syntactic supervision (≈ unidirectional LSTM) by preserving NP, VP, PP, SBAR nonterminal symbols and the combinations thereof. The 17 ablated grammars are then evaluated via targeted syntactic evaluation on the SyntaxGym benchmark. The results of our syntactic ablation demonstrated that (i) the RNNG with zero syntactic supervision underperformed the RNNGs with some syntactic supervision, (ii) the RNNG with full syntactic supervision underperformed the RNNGs with less syntactic supervision, and (iii) the RNNG with mild syntactic supervision achieved the best performance comparable to the state-of-the-art GPT-2-XL. Those results may suggest that the “good enough” approach to language processing seems to make LMs more human-like.</abstract>
      <url hash="619e82af">2023.findings-eacl.173</url>
      <bibkey>noji-oseki-2023-much</bibkey>
      <video href="2023.findings-eacl.173.mp4"/>
      <doi>10.18653/v1/2023.findings-eacl.173</doi>
    </paper>
    <paper id="174">
      <title>Are the Best Multilingual Document Embeddings simply Based on Sentence Embeddings?</title>
      <author><first>Sonal</first><last>Sannigrahi</last><affiliation>Saarland University</affiliation></author>
      <author><first>Josef</first><last>van Genabith</last><affiliation>Dfki</affiliation></author>
      <author><first>Cristina</first><last>España-Bonet</last><affiliation>DFKI GmbH</affiliation></author>
      <pages>2306-2316</pages>
      <abstract>Dense vector representations for textual data are crucial in modern NLP. Word embeddings and sentence embeddings estimated from raw texts are key in achieving state-of-the-art resultsin various tasks requiring semantic understanding. However, obtaining embeddings at the document level is challenging due to computational requirements and lack of appropriate data. Instead, most approaches fall back on computing document embeddings based on sentence representations. Although there exist architectures and models to encode documents fully, they are in general limited to English and few other high-resourced languages. In this work, we provide a systematic comparison of methods to produce document-level representations from sentences based on LASER, LaBSE, and Sentence BERT pre-trained multilingual models. We compare input token number truncation, sentence averaging as well as some simple windowing and in some cases new augmented and learnable approaches, on 3 multi- and cross-lingual tasks in 8 languages belonging to 3 different language families. Our task-based extrinsic evaluations show that, independently of the language, a clever combination of sentence embeddings is usually better than encoding the full document as a single unit, even when this is possible. We demonstrate that while a simple sentence average results in a strong baseline for classification tasks, more complex combinations are necessary for semantic tasks</abstract>
      <url hash="2557a6b9">2023.findings-eacl.174</url>
      <bibkey>sannigrahi-etal-2023-best</bibkey>
      <video href="2023.findings-eacl.174.mp4"/>
      <doi>10.18653/v1/2023.findings-eacl.174</doi>
    </paper>
    <paper id="175">
      <title>Improving User Controlled Table-To-Text Generation Robustness</title>
      <author><first>Hanxu</first><last>Hu</last><affiliation>University of Edinburgh</affiliation></author>
      <author><first>Yunqing</first><last>Liu</last><affiliation>The Hong Kong Polytechnic University</affiliation></author>
      <author><first>Zhongyi</first><last>Yu</last><affiliation>University of Edinburgh</affiliation></author>
      <author><first>Laura</first><last>Perez-Beltrachini</last><affiliation>School of Informatics, University of Edinburgh</affiliation></author>
      <pages>2317-2324</pages>
      <abstract>In this work we study user controlled table-to-text generation where users explore the content in a table by selecting cells and reading a natural language description thereof automatically produce by a natural language generator. Such generation models usually learn from carefully selected cell combinations (clean cell selections); however, in practice users may select unexpected, redundant, or incoherent cell combinations (noisy cell selections). In experiments, we find that models perform well on test sets coming from the same distribution as the train data but their performance drops when evaluated on realistic noisy user inputs. We propose a fine-tuning regime with additional user-simulated noisy cell selections. Models fine-tuned with the proposed regime gain 4.85 BLEU points on user noisy test cases and 1.4 on clean test cases; and achieve comparable state-of-the-art performance on the ToTTo dataset.</abstract>
      <url hash="da9235d1">2023.findings-eacl.175</url>
      <bibkey>hu-etal-2023-improving</bibkey>
      <video href="2023.findings-eacl.175.mp4"/>
      <doi>10.18653/v1/2023.findings-eacl.175</doi>
    </paper>
    <paper id="176">
      <title>Better Pre-Training by Reducing Representation Confusion</title>
      <author><first>Haojie</first><last>Zhang</last><affiliation>Peking University</affiliation></author>
      <author><first>Mingfei</first><last>Liang</last><affiliation>WeChat Search Application Department, Tencent, China</affiliation></author>
      <author><first>Ruobing</first><last>Xie</last><affiliation>WeChat, Tencent</affiliation></author>
      <author><first>Zhenlong</first><last>Sun</last><affiliation>WeChat Search Application Department, Tencent, China</affiliation></author>
      <author><first>Bo</first><last>Zhang</last><affiliation>WeChat Search Application Department, Tencent, China</affiliation></author>
      <author><first>Leyu</first><last>Lin</last><affiliation>WeChat Search Application Department, Tencent, China</affiliation></author>
      <pages>2325-2336</pages>
      <url hash="26b7cc31">2023.findings-eacl.176</url>
      <bibkey>zhang-etal-2023-better</bibkey>
      <abstract>In this work, we revisit the Transformer-based pre-trained language models and identify two different types of information confusion in position encoding and model representations, respectively. Firstly, we show that in the relative position encoding, the joint modeling about relative distances and directions brings confusion between two heterogeneous information. It may make the model unable to capture the associative semantics of the same distance and the opposite directions, which in turn affects the performance of downstream tasks. Secondly, we notice the BERT with Mask Language Modeling (MLM) pre-training objective outputs similar token representations (last hidden states of different tokens) and head representations (attention weightsof different heads), which may make the diversity of information expressed by different tokens and heads limited. Motivated by the above investigation, we propose two novel techniques to improve pre-trained language models: Decoupled Directional Relative Position (DDRP) encoding and MTH pre-training objective. DDRP decouples the relative distance features and the directional features in classical relative position encoding. MTH applies two novel auxiliary regularizers besides MLM to enlarge the dissimilarities between (a) last hidden states of different tokens, and (b) attention weights of different heads. These designs allow the model to capture different categories of information more clearly, as a way to alleviate information confusion in representation learning for better optimization. Extensive experiments and ablation studies on GLUE benchmark demonstrate the effectiveness of our proposed methods.</abstract>
      <video href="2023.findings-eacl.176.mp4"/>
      <doi>10.18653/v1/2023.findings-eacl.176</doi>
    </paper>
    <paper id="177">
      <title><fixed-case>MAF</fixed-case>i<fixed-case>D</fixed-case>: Moving Average Equipped Fusion-in-Decoder for Question Answering over Tabular and Textual Data</title>
      <author><first>Sung-Min</first><last>Lee</last><affiliation>Jeonbuk National University</affiliation></author>
      <author><first>Eunhwan</first><last>Park</last><affiliation>Jeonbuk National University</affiliation></author>
      <author><first>Daeryong</first><last>Seo</last><affiliation>Naver</affiliation></author>
      <author><first>Donghyeon</first><last>Jeon</last><affiliation>NAVER Search</affiliation></author>
      <author><first>Inho</first><last>Kang</last><affiliation>Naver Search</affiliation></author>
      <author><first>Seung-Hoon</first><last>Na</last><affiliation>Jeonbuk National University</affiliation></author>
      <pages>2337-2344</pages>
      <url hash="e2a9eb0d">2023.findings-eacl.177</url>
      <bibkey>lee-etal-2023-mafid</bibkey>
      <abstract>Transformer-based models for question answering (QA) over tables and texts confront a “long” hybrid sequence over tabular and textual elements, causing long-range reasoning problems. To handle long-range reasoning, we extensively employ a fusion-in-decoder (FiD) and exponential moving average (EMA), proposing a Moving Average Equipped Fusion-in-Decoder (<b>MAFiD</b>). With FiD as the backbone architecture, MAFiD combines various levels of reasoning: <i>independent encoding</i> of homogeneous data and <i>single-row</i> and <i>multi-row heterogeneous reasoning</i>, using a <i>gated cross attention layer</i> to effectively aggregate the three types of representations resulting from various reasonings. Experimental results on HybridQA indicate that MAFiD achieves state-of-the-art performance by increasing exact matching (EM) and F1 by 1.1 and 1.7, respectively, on the blind test set.</abstract>
      <video href="2023.findings-eacl.177.mp4"/>
      <doi>10.18653/v1/2023.findings-eacl.177</doi>
    </paper>
    <paper id="178">
      <title>Transformer-based Models for Long-Form Document Matching: Challenges and Empirical Analysis</title>
      <author><first>Akshita</first><last>Jha</last><affiliation>Virginia Tech</affiliation></author>
      <author><first>Adithya</first><last>Samavedhi</last><affiliation>Virginia Tech</affiliation></author>
      <author><first>Vineeth</first><last>Rakesh</last><affiliation>InterDigital</affiliation></author>
      <author><first>Jaideep</first><last>Chandrashekar</last><affiliation>InterDigital</affiliation></author>
      <author><first>Chandan</first><last>Reddy</last><affiliation>Virginia Tech</affiliation></author>
      <pages>2345-2355</pages>
      <abstract>Recent advances in the area of long document matching have primarily focused on using transformer-based models for long document encoding and matching. There are two primary challenges associated with these models. Firstly, the performance gain provided by transformer-based models comes at a steep cost – both in terms of the required training time and the resource (memory and energy) consumption. The second major limitation is their inability to handle more than a pre-defined input token length at a time. In this work, we empirically demonstrate the effectiveness of simple neural models (such as feed-forward networks, and CNNs) and simple embeddings (like GloVe, and Paragraph Vector) over transformer-based models on the task of document matching. We show that simple models outperform the more complex BERT-based models while taking significantly less training time, energy, and memory. The simple models are also more robust to variations in document length and text perturbations.</abstract>
      <url hash="69add9e2">2023.findings-eacl.178</url>
      <bibkey>jha-etal-2023-transformer</bibkey>
      <video href="2023.findings-eacl.178.mp4"/>
      <doi>10.18653/v1/2023.findings-eacl.178</doi>
    </paper>
    <paper id="179">
      <title>Simple and Effective Multi-Token Completion from Masked Language Models</title>
      <author><first>Oren</first><last>Kalinsky</last><affiliation>Amazon</affiliation></author>
      <author><first>Guy</first><last>Kushilevitz</last><affiliation>Amazon</affiliation></author>
      <author><first>Alexander</first><last>Libov</last><affiliation>Amazon</affiliation></author>
      <author><first>Yoav</first><last>Goldberg</last><affiliation>Bar Ilan University</affiliation></author>
      <pages>2356-2369</pages>
      <abstract>Pre-trained neural masked language models are often used for predicting a replacement token for a given sequence position, in a cloze-like task. However, this usage is restricted to predicting a single token, from a relatively small pre-trained vocabulary. Recent Sequence2Sequence pre-trained LMs like T5 do allow predicting multi-token completions, but are more expensive to train and run. We show that pre-trained masked language models can be adapted to produce multi-token completions, with only a modest addition to their parameter count. We propose two simple adaptation approaches, trading parameter counts for accuracy. The first method generates multi-token completions from a conditioned RNN. It has a very low parameter count and achieves competitive results. The second method is even simpler: it adds items corresponding to multi-token units to the output prediction matrix. While being higher in parameter count than the RNN method, it also surpasses current state-of-the-art multi-token completion models, including T5-3B, while being significantly more parameter efficient. We demonstrate that our approach is flexible to different vocabularies and domains and can effectively leverage existing pre-trained models available in different domains. Finally, a human evaluation further validates our results and shows that our solution regularly provides valid completions, as well as reasonable correctness for factual-sentence completions.</abstract>
      <url hash="3a938f13">2023.findings-eacl.179</url>
      <bibkey>kalinsky-etal-2023-simple</bibkey>
      <video href="2023.findings-eacl.179.mp4"/>
      <doi>10.18653/v1/2023.findings-eacl.179</doi>
    </paper>
    <paper id="180">
      <title>A Survey on Dynamic Neural Networks for Natural Language Processing</title>
      <author><first>Canwen</first><last>Xu</last><affiliation>UC San Diego</affiliation></author>
      <author><first>Julian</first><last>McAuley</last><affiliation>Ucsd</affiliation></author>
      <pages>2370-2381</pages>
      <abstract>Effectively scaling large Transformer models is a main driver of recent advances in natural language processing. Dynamic neural networks, as an emerging research direction, are capable of scaling up neural networks with sub-linear increases in computation and time by dynamically adjusting their computational path based on the input. Dynamic neural networks could be a promising solution to the growing parameter numbers of pretrained language models, allowing both model pretraining with trillions of parameters and faster inference on mobile devices. In this survey, we summarize the progress of three types of dynamic neural networks in NLP: skimming, mixture of experts, and early exit. We also highlight current challenges in dynamic neural networks and directions for future research.</abstract>
      <url hash="6dfdc695">2023.findings-eacl.180</url>
      <bibkey>xu-mcauley-2023-survey</bibkey>
      <doi>10.18653/v1/2023.findings-eacl.180</doi>
    </paper>
    <paper id="181">
      <title>Transformers with Learnable Activation Functions</title>
      <author><first>Haishuo</first><last>Fang</last><affiliation>UKP Lab, TU Darmstadt</affiliation></author>
      <author><first>Ji-Ung</first><last>Lee</last><affiliation>UKP, TU Darmstadt</affiliation></author>
      <author><first>Nafise Sadat</first><last>Moosavi</last><affiliation>Department of Computer Science, The University of Sheffield</affiliation></author>
      <author><first>Iryna</first><last>Gurevych</last><affiliation>UKP Lab, Technische Universität Darmstadt</affiliation></author>
      <pages>2382-2398</pages>
      <abstract>Activation functions can have a significant impact on reducing the topological complexity of input data and therefore, improving a model’s performance. However, the choice of activation functions is seldom discussed or explored in Transformer-based language models. As a common practice, commonly used activation functions like Gaussian Error Linear Unit (GELU) are chosen beforehand and then remain fixed from pre-training to fine-tuning. In this paper, we investigate the impact of activation functions on Transformer-based models by utilizing rational activation functions (RAFs). In contrast to fixed activation functions (FAF), RAFs are capable of learning the optimal activation functions from data. Our experiments show that the RAF-based Transformer model (RAFT) achieves a better performance than its FAF-based counterpart (). For instance, we find that RAFT outperforms on the GLUE benchmark by 5.71 points when using only 100 training examples and by 2.05 points on SQuAD with all available data. Analyzing the shapes of the learned RAFs further unveils that they vary across different layers and different tasks; opening a promising way to better analyze and understand large, pre-trained language models.</abstract>
      <url hash="f7420647">2023.findings-eacl.181</url>
      <bibkey>fang-etal-2023-transformers</bibkey>
      <video href="2023.findings-eacl.181.mp4"/>
      <doi>10.18653/v1/2023.findings-eacl.181</doi>
    </paper>
    <paper id="182">
      <title>The Solvability of Interpretability Evaluation Metrics</title>
      <author><first>Yilun</first><last>Zhou</last><affiliation>Mit</affiliation></author>
      <author><first>Julie</first><last>Shah</last><affiliation>Mit</affiliation></author>
      <pages>2399-2415</pages>
      <abstract>Feature attribution methods are popular for explaining neural network predictions, and they are often evaluated on metrics such as comprehensiveness and sufficiency. In this paper, we highlight an intriguing property of these metrics: their solvability. Concretely, we can define the problem of optimizing an explanation for a metric, which can be solved by beam search. This observation leads to the obvious yet unaddressed question: why do we use explainers (e.g., LIME) not based on solving the target metric, if the metric value represents explanation quality? We present a series of investigations showing strong performance of this beam search explainer and discuss its broader implication: a definition-evaluation duality of interpretability concepts. We implement the explainer and release the Python solvex package for models of text, image and tabular domains.</abstract>
      <url hash="87aa8ccd">2023.findings-eacl.182</url>
      <bibkey>zhou-shah-2023-solvability</bibkey>
      <doi>10.18653/v1/2023.findings-eacl.182</doi>
    </paper>
    <paper id="183">
      <title>Reliable Gradient-free and Likelihood-free Prompt Tuning</title>
      <author><first>Maohao</first><last>Shen</last><affiliation>Massachusetts Institute of Technology</affiliation></author>
      <author><first>Soumya</first><last>Ghosh</last><affiliation>IBM Research</affiliation></author>
      <author><first>Prasanna</first><last>Sattigeri</last><affiliation>IBM Research</affiliation></author>
      <author><first>Subhro</first><last>Das</last><affiliation>MIT-IBM Watson AI Lab</affiliation></author>
      <author><first>Yuheng</first><last>Bu</last><affiliation>University of Florida</affiliation></author>
      <author><first>Gregory</first><last>Wornell</last><affiliation>Massachusetts Institute of Technology</affiliation></author>
      <pages>2416-2429</pages>
      <abstract>Due to privacy or commercial constraints, large pre-trained language models (PLMs) are often offered as black-box APIs. Fine-tuning such models to downstream tasks is challenging because one can neither access the model’s internal representations nor propagate gradients through it. This paper addresses these challenges by developing techniques for adapting PLMs with only API access. Building on recent work on soft prompt tuning, we develop methods to tune the soft prompts without requiring gradient computation. Further, we develop extensions that in addition to not requiring gradients also do not need to access any internal representation of the PLM beyond the input embeddings. Moreover, instead of learning a single prompt, our methods learn a distribution over prompts allowing us to quantify predictive uncertainty. Ours is the first work to consider uncertainty in prompts when only having API access to the PLM. Finally, through extensive experiments, we carefully vet the proposed methods and find them competitive with (and sometimes even improving on) gradient-based approaches with full access to the PLM.</abstract>
      <url hash="0bfa1f77">2023.findings-eacl.183</url>
      <bibkey>shen-etal-2023-reliable</bibkey>
      <video href="2023.findings-eacl.183.mp4"/>
      <doi>10.18653/v1/2023.findings-eacl.183</doi>
    </paper>
    <paper id="184">
      <title>Combining Psychological Theory with Language Models for Suicide Risk Detection</title>
      <author><first>Daniel</first><last>Izmaylov</last><affiliation>Ben-Gurion University of the Negev</affiliation></author>
      <author><first>Avi</first><last>Segal</last><affiliation>Ben-Gurion University of the Negev</affiliation></author>
      <author><first>Kobi</first><last>Gal</last><affiliation>Ben-Gurion University of the Negev</affiliation></author>
      <author><first>Meytal</first><last>Grimland</last><affiliation>Ruppin Academic Center</affiliation></author>
      <author><first>Yossi</first><last>Levi-Belz</last><affiliation>Ruppin Academic Center</affiliation></author>
      <pages>2430-2438</pages>
      <abstract>With the increased awareness of situations of mental crisis and their societal impact, online services providing emergency support are becoming commonplace in many countries. Computational models, trained on discussions between help-seekers and providers, can support suicide prevention by identifying at-risk individuals. However, the lack of domain-specific models, especially in low-resource languages, poses a significant challenge for the automatic detection of suicide risk. We propose a model that combines pre-trained language models (PLM) with a fixed set of manually crafted (and clinically approved) set of suicidal cues, followed by a two-stage fine-tuning process. Our model achieves 0.91 ROC-AUC and an F2-score of 0.55, significantly outperforming an array of strong baselines even early on in the conversation, which is critical for real-time detection in the field. Moreover, the model performs well across genders and age groups.</abstract>
      <url hash="dc766402">2023.findings-eacl.184</url>
      <bibkey>izmaylov-etal-2023-combining</bibkey>
      <video href="2023.findings-eacl.184.mp4"/>
      <doi>10.18653/v1/2023.findings-eacl.184</doi>
    </paper>
    <paper id="185">
      <title>Cross-Lingual Question Answering over Knowledge Base as Reading Comprehension</title>
      <author><first>Chen</first><last>Zhang</last><affiliation>Peking University</affiliation></author>
      <author><first>Yuxuan</first><last>Lai</last><affiliation>Peking University</affiliation></author>
      <author><first>Yansong</first><last>Feng</last><affiliation>Peking University</affiliation></author>
      <author><first>Xingyu</first><last>Shen</last><affiliation>Peking University</affiliation></author>
      <author><first>Haowei</first><last>Du</last><affiliation>Peking University</affiliation></author>
      <author><first>Dongyan</first><last>Zhao</last><affiliation>Pku.edu.cn</affiliation></author>
      <pages>2439-2452</pages>
      <abstract>Although many large-scale knowledge bases (KBs) claim to contain multilingual information, their support for many non-English languages is often incomplete. This incompleteness gives birth to the task of cross-lingual question answering over knowledge base (xKBQA), which aims to answer questions in languages different from that of the provided KB. One of the major challenges facing xKBQA is the high cost of data annotation, leading to limited resources available for further exploration. Another challenge is mapping KB schemas and natural language expressions in the questions under cross-lingual settings. In this paper, we propose a novel approach for xKBQA in a reading comprehension paradigm. We convert KB subgraphs into passages to narrow the gap between KB schemas and questions, which enables our model to benefit from recent advances in multilingual pre-trained language models (MPLMs) and cross-lingual machine reading comprehension (xMRC). Specifically, we use MPLMs, with considerable knowledge of cross-lingual mappings, for cross-lingual reading comprehension. Existing high-quality xMRC datasets can be further utilized to finetune our model, greatly alleviating the data scarcity issue in xKBQA. Extensive experiments on two xKBQA datasets in 12 languages show that our approach outperforms various baselines and achieves strong few-shot and zero-shot performance. Our dataset and code are released for further research.</abstract>
      <url hash="bb2bf885">2023.findings-eacl.185</url>
      <bibkey>zhang-etal-2023-cross</bibkey>
      <video href="2023.findings-eacl.185.mp4"/>
      <doi>10.18653/v1/2023.findings-eacl.185</doi>
    </paper>
    <paper id="186">
      <title>Delving Deeper into Cross-lingual Visual Question Answering</title>
      <author><first>Chen</first><last>Liu</last><affiliation>Technische Universitat Darmstadt</affiliation></author>
      <author><first>Jonas</first><last>Pfeiffer</last><affiliation>Google</affiliation></author>
      <author><first>Anna</first><last>Korhonen</last><affiliation>University of Cambridge</affiliation></author>
      <author><first>Ivan</first><last>Vulić</last><affiliation>University of Cambridge</affiliation></author>
      <author><first>Iryna</first><last>Gurevych</last><affiliation>UKP Lab, Technische Universität Darmstadt</affiliation></author>
      <pages>2453-2468</pages>
      <abstract>Visual question answering (VQA) is one of the crucial vision-and-language tasks. Yet, existing VQA research has mostly focused on the English language, due to a lack of suitable evaluation resources. Previous work on cross-lingual VQA has reported poor zero-shot transfer performance of current multilingual multimodal Transformers with large gaps to monolingual performance, without any deeper analysis. In this work, we delve deeper into the different aspects of cross-lingual VQA, aiming to understand the impact of 1) modeling methods and choices, including architecture, inductive bias, fine-tuning; 2) learning biases: including question types and modality biases in cross-lingual setups. The key results of our analysis are: 1. We show that simple modifications to the standard training setup can substantially reduce the transfer gap to monolingual English performance, yielding +10 accuracy points over existing methods. 2. We analyze cross-lingual VQA across different question types of varying complexity for different multilingual multimodal Transformers, and identify question types that are the most difficult to improve on. 3. We provide an analysis of modality biases present in training data and models, revealing why zero-shot performance gaps remain for certain question types and languages.</abstract>
      <url hash="1b3f39b1">2023.findings-eacl.186</url>
      <bibkey>liu-etal-2023-delving</bibkey>
      <video href="2023.findings-eacl.186.mp4"/>
      <doi>10.18653/v1/2023.findings-eacl.186</doi>
    </paper>
    <paper id="187">
      <title>Bridging Argument Quality and Deliberative Quality Annotations with Adapters</title>
      <author><first>Neele</first><last>Falk</last><affiliation>University of Stuttgart</affiliation></author>
      <author><first>Gabriella</first><last>Lapesa</last><affiliation>Universität Stuttgart, Institut für Maschinelle Sprachverarbeitung</affiliation></author>
      <pages>2469-2488</pages>
      <abstract>Assessing the quality of an argument is a complex, highly subjective task, influenced by heterogeneous factors (e.g., prior beliefs of the annotators, topic, domain, and application), and crucial for its impact in downstream tasks (e.g., argument retrieval or generation). Both the Argument Mining and the Social Science community have devoted plenty of attention to it, resulting in a wide variety of argument quality dimensions and a large number of annotated resources. This work aims at a better understanding of how the different aspects of argument quality relate to each other from a practical point of view. We employ adapter-fusion (Pfeiffer et al., 2021) as a multi-task learning framework which a) can improve the prediction of individual quality dimensions by injecting knowledge about related dimensions b) is efficient and modular and c) can serve as an analysis tool to investigate relations between different dimensions. We conduct experiments on 6 datasets and 20 quality dimensions. We find that the majority of the dimensions can be learned as a weighted combination of other quality aspects, and that for 8 dimensions adapter fusion improves quality prediction. Last, we show the benefits of this approach by improving the performance in an extrinsic, out-of-domain task: prediction of moderator interventions in a deliberative forum.</abstract>
      <url hash="11a1075a">2023.findings-eacl.187</url>
      <bibkey>falk-lapesa-2023-bridging</bibkey>
      <video href="2023.findings-eacl.187.mp4"/>
      <doi>10.18653/v1/2023.findings-eacl.187</doi>
    </paper>
    <paper id="188">
      <title>Interventional Probing in High Dimensions: An <fixed-case>NLI</fixed-case> Case Study</title>
      <author><first>Julia</first><last>Rozanova</last><affiliation>University of Manchester</affiliation></author>
      <author><first>Marco</first><last>Valentino</last><affiliation>Idiap Research Institute</affiliation></author>
      <author><first>Lucas</first><last>Cordeiro</last><affiliation>University of Manchester</affiliation></author>
      <author><first>André</first><last>Freitas</last><affiliation>University of Manchester</affiliation></author>
      <pages>2489-2500</pages>
      <abstract>Probing strategies have been shown to detectthe presence of various linguistic features inlarge language models; in particular, seman-tic features intermediate to the “natural logic”fragment of the Natural Language Inferencetask (NLI). In the case of natural logic, the rela-tion between the intermediate features and theentailment label is explicitly known: as such,this provides a ripe setting for interventionalstudies on the NLI models’ representations, al-lowing for stronger causal conjectures and adeeper critical analysis of interventional prob-ing methods. In this work, we carry out newand existing representation-level interventionsto investigate the effect of these semantic fea-tures on NLI classification: we perform am-nesic probing (which removes features as di-rected by learned linear probes) and introducethe mnestic probing variation (which forgetsall dimensions except the probe-selected ones).Furthermore, we delve into the limitations ofthese methods and outline some pitfalls havebeen obscuring the effectivity of interventionalprobing studies.</abstract>
      <url hash="9ee97fe8">2023.findings-eacl.188</url>
      <bibkey>rozanova-etal-2023-interventional</bibkey>
      <doi>10.18653/v1/2023.findings-eacl.188</doi>
    </paper>
    <paper id="189">
      <title>Program Synthesis for Complex <fixed-case>QA</fixed-case> on Charts via Probabilistic Grammar Based Filtered Iterative Back-Translation</title>
      <author><first>Shabbirhussain</first><last>Bhaisaheb</last><affiliation>TCS Research</affiliation></author>
      <author><first>Shubham</first><last>Paliwal</last><affiliation>TCS Research</affiliation></author>
      <author><first>Rajaswa</first><last>Patil</last><affiliation>TCS Research</affiliation></author>
      <author><first>Manasi</first><last>Patwardhan</last><affiliation>TCS Research</affiliation></author>
      <author><first>Lovekesh</first><last>Vig</last><affiliation>TCS Research</affiliation></author>
      <author><first>Gautam</first><last>Shroff</last><affiliation>TCS Research</affiliation></author>
      <pages>2501-2515</pages>
      <abstract>Answering complex reasoning questions from chart images is a challenging problem requiring a combination of natural language understanding, fine-grained perception, and analytical reasoning. Current chart-based Question Answering (QA) approaches largely address structural, visual or simple data retrieval-type questions with fixed-vocabulary answers and perform poorly on reasoning queries. We focus on answering realistic, complex, reasoning-based questions where the answer needs to be computed and not selected from a fixed set of choices. Our approach employs a neural semantic parser to transform Natural Language (NL) questions into SQL programs and execute them on a standardized schema populated from the extracted chart contents. In the absence of program annotations, i.e., in a weak supervision setting, we obtain initial SQL predictions from a pre-trained CodeT5 semantic parser and employ Filtered Iterative Back-Translation (FIBT) for iteratively augmenting our NL-SQL training set. The forward (neural semantic parser) and backward (language model) models are initially trained with an external NL-SQL dataset. We iteratively move towards the NL query distribution by generating NL questions from the synthesized SQL programs using a Probabilistic Context-Free Grammar (PCFG) where the production rule probabilities are induced to be inversely proportional to the probabilities in the training data. We filter out the generated NL queries with mismatched structures and compositions. Our FIBT approach achieves State-of-the-Art (SOTA) results on reasoning-based queries in the PlotQA dataset yielding a test accuracy of 60.44%, superseding the previous baselines by a large margin.</abstract>
      <url hash="8b35f87d">2023.findings-eacl.189</url>
      <bibkey>bhaisaheb-etal-2023-program</bibkey>
      <doi>10.18653/v1/2023.findings-eacl.189</doi>
    </paper>
    <paper id="190">
      <title>Exploiting Language Characteristics for Legal Domain-Specific Language Model Pretraining</title>
      <author><first>Inderjeet</first><last>Nair</last><affiliation>Adobe Research</affiliation></author>
      <author><first>Natwar</first><last>Modani</last><affiliation>Adobe Research, India</affiliation></author>
      <pages>2516-2526</pages>
      <abstract>Pretraining large language models has resulted in tremendous performance improvement for many natural language processing (NLP) tasks. While for non-domain specific tasks, such models can be used directly, a common strategy to achieve better performance for specific domains involves pretraining these language models over domain specific data using objectives like Masked Language Modelling (MLM), Autoregressive Language Modelling, etc. While such pretraining addresses the change in vocabulary and style of language for the domain, it is otherwise a domain agnostic approach. In this work, we investigate the effect of incorporating pretraining objectives that explicitly tries to exploit the domain specific language characteristics in addition to such MLM based pretraining. Particularly, we examine two distinct characteristics associated with the legal domain and propose pretraining objectives modelling these characteristics. The proposed objectives target improvement of token-level feature representation, as well as aim to incorporate sentence level semantics. We demonstrate superiority in the performance of the models pretrained using our objectives against those trained using domain-agnostic objectives over several legal downstream tasks.</abstract>
      <url hash="4d266a5d">2023.findings-eacl.190</url>
      <bibkey>nair-modani-2023-exploiting</bibkey>
      <video href="2023.findings-eacl.190.mp4"/>
      <doi>10.18653/v1/2023.findings-eacl.190</doi>
    </paper>
    <paper id="191">
      <title>Global Constraints with Prompting for Zero-Shot Event Argument Classification</title>
      <author><first>Zizheng</first><last>Lin</last><affiliation>The Hong Kong University of Science and Technology</affiliation></author>
      <author><first>Hongming</first><last>Zhang</last><affiliation>Tencent AI Lab, Bellevue</affiliation></author>
      <author><first>Yangqiu</first><last>Song</last><affiliation>Hkust</affiliation></author>
      <pages>2527-2538</pages>
      <abstract>Determining the role of event arguments is a crucial subtask of event extraction. Most previous supervised models leverage costly annotations, which is not practical for open-domain applications. In this work, we propose to use global constraints with prompting to effectively tackles event argument classification without any annotation and task-specific training. Specifically, given an event and its associated passage, the model first creates several new passages by prefix prompts and cloze prompts, where prefix prompts indicate event type and trigger span, and cloze prompts connect each candidate role with the target argument span. Then, a pre-trained language model scores the new passages, making the initial prediction. Our novel prompt templates can easily adapt to all events and argument types without manual effort. Next, the model regularizes the prediction by global constraints exploiting cross-task, cross-argument, and cross-event relations. Extensive experiments demonstrate our model’s effectiveness: it outperforms the best zero-shot baselines by 12.5% and 10.9% F1 on ACE and ERE with given argument spans and by 4.3% and 3.3% F1, respectively, without given argument spans. We have made our code publicly available.</abstract>
      <url hash="7bde8964">2023.findings-eacl.191</url>
      <bibkey>lin-etal-2023-global</bibkey>
      <video href="2023.findings-eacl.191.mp4"/>
      <doi>10.18653/v1/2023.findings-eacl.191</doi>
    </paper>
    <paper id="192">
      <title>Distillation of encoder-decoder transformers for sequence labelling</title>
      <author><first>Marco</first><last>Farina</last><affiliation>Bloomberg L.P.</affiliation></author>
      <author><first>Duccio</first><last>Pappadopulo</last><affiliation>Bloomberg LP</affiliation></author>
      <author><first>Anant</first><last>Gupta</last><affiliation>Bloomberg.net</affiliation></author>
      <author><first>Leslie</first><last>Huang</last><affiliation>Bloomberg LP</affiliation></author>
      <author><first>Ozan</first><last>Irsoy</last><affiliation>Bloomberg</affiliation></author>
      <author><first>Thamar</first><last>Solorio</last><affiliation>University of Houston</affiliation></author>
      <pages>2539-2549</pages>
      <abstract>Driven by encouraging results on a wide range of tasks, the field of NLP is experiencing an accelerated race to develop bigger language models. This race for bigger models has also underscored the need to continue the pursuit of practical distillation approaches that can leverage the knowledge acquired by these big models in a compute-efficient manner. Having this goal in mind, we build on recent work to propose a hallucination-free framework for sequence tagging that is especially suited for distillation. We show empirical results of new state-of-the-art performance across multiple sequence labelling datasets and validate the usefulness of this framework for distilling a large model in a few-shot learning scenario.</abstract>
      <url hash="5e93decc">2023.findings-eacl.192</url>
      <bibkey>farina-etal-2023-distillation</bibkey>
      <video href="2023.findings-eacl.192.mp4"/>
      <doi>10.18653/v1/2023.findings-eacl.192</doi>
    </paper>
    <paper id="193">
      <title>Predicting Desirable Revisions of Evidence and Reasoning in Argumentative Writing</title>
      <author><first>Tazin</first><last>Afrin</last><affiliation>Educational Testing Service</affiliation></author>
      <author><first>Diane</first><last>Litman</last><affiliation>University of Pittsburgh</affiliation></author>
      <pages>2550-2561</pages>
      <abstract>We develop models to classify desirable evidence and desirable reasoning revisions in student argumentative writing. We explore two ways to improve classifier performance – using the essay context of the revision, and using the feedback students received before the revision. We perform both intrinsic and extrinsic evaluation for each of our models and report a qualitative analysis. Our results show that while a model using feedback information improves over a baseline model, models utilizing context - either alone or with feedback - are the most successful in identifying desirable revisions.</abstract>
      <url hash="7662042c">2023.findings-eacl.193</url>
      <bibkey>afrin-litman-2023-predicting</bibkey>
      <video href="2023.findings-eacl.193.mp4"/>
      <doi>10.18653/v1/2023.findings-eacl.193</doi>
    </paper>
    <paper id="194">
      <title>Discourse Structure Extraction from Pre-Trained and Fine-Tuned Language Models in Dialogues</title>
      <author><first>Chuyuan</first><last>Li</last><affiliation>Loria</affiliation></author>
      <author><first>Patrick</first><last>Huber</last><affiliation>University of British Columbia</affiliation></author>
      <author><first>Wen</first><last>Xiao</last><affiliation>University of British Columbia</affiliation></author>
      <author><first>Maxime</first><last>Amblard</last><affiliation>Université de Lorraine</affiliation></author>
      <author><first>Chloe</first><last>Braud</last><affiliation>Irit - Cnrs - Aniti</affiliation></author>
      <author><first>Giuseppe</first><last>Carenini</last><affiliation>University Of British Columbia</affiliation></author>
      <pages>2562-2579</pages>
      <abstract>Discourse processing suffers from data sparsity, especially for dialogues. As a result, we explore approaches to infer latent discourse structures for dialogues, based on attention matrices from Pre-trained Language Models (PLMs). We investigate multiple auxiliary tasks for fine-tuning and show that the dialogue-tailored Sentence Ordering task performs best. To locate and exploit discourse information in PLMs, we propose an unsupervised and a semi-supervised method. Our proposals thereby achieve encouraging results on the STAC corpus, with F1 scores of 57.2 and 59.3 for the unsupervised and semi-supervised methods, respectively. When restricted to projective trees, our scores improved to 63.3 and 68.1.</abstract>
      <url hash="389d2b00">2023.findings-eacl.194</url>
      <bibkey>li-etal-2023-discourse</bibkey>
      <video href="2023.findings-eacl.194.mp4"/>
      <doi>10.18653/v1/2023.findings-eacl.194</doi>
    </paper>
    <paper id="195">
      <title>Relation Extraction with Weighted Contrastive Pre-training on Distant Supervision</title>
      <author><first>Zhen</first><last>Wan</last><affiliation>Kyoto University</affiliation></author>
      <author><first>Fei</first><last>Cheng</last><affiliation>Kyoto University</affiliation></author>
      <author><first>Qianying</first><last>Liu</last><affiliation>Kyoto University</affiliation></author>
      <author><first>Zhuoyuan</first><last>Mao</last><affiliation>Kyoto University</affiliation></author>
      <author><first>Haiyue</first><last>Song</last><affiliation>Kyoto University</affiliation></author>
      <author><first>Sadao</first><last>Kurohashi</last><affiliation>Kyoto University</affiliation></author>
      <pages>2580-2585</pages>
      <abstract>Contrastive pre-training on distant supervision has shown remarkable effectiveness in improving supervised relation extraction tasks. However, the existing methods ignore the intrinsic noise of distant supervision during the pre-training stage. In this paper, we propose a weighted contrastive learning method by leveraging the supervised data to estimate the reliability of pre-training instances and explicitly reduce the effect of noise. Experimental results on three supervised datasets demonstrate the advantages of our proposed weighted contrastive learning approach compared to two state-of-the-art non-weighted baselines. Our code and models are available at: <url>https://github.com/YukinoWan/WCL</url>.</abstract>
      <url hash="c5645035">2023.findings-eacl.195</url>
      <bibkey>wan-etal-2023-relation</bibkey>
      <video href="2023.findings-eacl.195.mp4"/>
      <doi>10.18653/v1/2023.findings-eacl.195</doi>
    </paper>
    <paper id="196">
      <title><fixed-case>CK</fixed-case>-Transformer: Commonsense Knowledge Enhanced Transformers for Referring Expression Comprehension</title>
      <author><first>Zhi</first><last>Zhang</last><affiliation>University of Amsterdam</affiliation></author>
      <author><first>Helen</first><last>Yannakoudakis</last><affiliation>King’s College London, University of Cambridge</affiliation></author>
      <author><first>Xiantong</first><last>Zhen</last><affiliation>United Imaging Healthcare</affiliation></author>
      <author><first>Ekaterina</first><last>Shutova</last><affiliation>University of Amsterdam</affiliation></author>
      <pages>2586-2596</pages>
      <abstract>The task of multimodal referring expression comprehension (REC), aiming at localizing an image region described by a natural language expression, has recently received increasing attention within the research comminity. In this paper, we specifically focus on referring expression comprehension with commonsense knowledge (KB-Ref), a task which typically requires reasoning beyond spatial, visual or semantic information. We propose a novel framework for Commonsense Knowledge Enhanced Transformers (CK-Transformer) which effectively integrates commonsense knowledge into the representations of objects in an image, facilitating identification of the target objects referred to by the expressions. We conduct extensive experiments on several benchmarks for the task of KB-Ref. Our results show that the proposed CK-Transformer achieves a new state of the art, with an absolute improvement of 3.14% accuracy over the existing state of the art.</abstract>
      <url hash="fa01abcc">2023.findings-eacl.196</url>
      <bibkey>zhang-etal-2023-ck</bibkey>
      <video href="2023.findings-eacl.196.mp4"/>
      <doi>10.18653/v1/2023.findings-eacl.196</doi>
    </paper>
    <paper id="197">
      <title>Curricular Next Conversation Prediction Pretraining for Transcript Segmentation</title>
      <author><first>Anvesh Rao</first><last>Vijjini</last><affiliation>UNC Chapel Hill</affiliation></author>
      <author><first>Hanieh</first><last>Deilamsalehy</last><affiliation>Adobe Research</affiliation></author>
      <author><first>Franck</first><last>Dernoncourt</last><affiliation>Adobe Research</affiliation></author>
      <author><first>Snigdha</first><last>Chaturvedi</last><affiliation>University of North Carolina, Chapel Hill</affiliation></author>
      <pages>2597-2607</pages>
      <abstract>Transcript segmentation is the task of dividing a single continuous transcript into multiple segments. While document segmentation is a popular task, transcript segmentation has significant challenges due to the relatively noisy and sporadic nature of data. We propose pretraining strategies to address these challenges. The strategies are based on “Next Conversation Prediction” (NCP) with the underlying idea of pretraining a model to identify consecutive conversations. We further introduce “Advanced NCP” to make the pretraining task more relevant to the downstream task of segmentation break prediction while being significantly easier. Finally we introduce a curriculum to Advanced NCP (Curricular NCP) based on the similarity between pretraining and downstream task samples. Curricular NCP applied to a state-of-the-art model for text segmentation outperforms prior results. We also show that our pretraining strategies make the model robust to speech recognition errors commonly found in automatically generated transcripts.</abstract>
      <url hash="8166576d">2023.findings-eacl.197</url>
      <bibkey>vijjini-etal-2023-curricular</bibkey>
      <video href="2023.findings-eacl.197.mp4"/>
      <doi>10.18653/v1/2023.findings-eacl.197</doi>
    </paper>
  </volume>
  <volume id="acl" ingest-date="2023-07-09" type="proceedings">
    <meta>
      <booktitle>Findings of the Association for Computational Linguistics: ACL 2023</booktitle>
      <editor><first>Anna</first><last>Rogers</last></editor>
      <editor><first>Jordan</first><last>Boyd-Graber</last></editor>
      <editor><first>Naoaki</first><last>Okazaki</last></editor>
      <publisher>Association for Computational Linguistics</publisher>
      <address>Toronto, Canada</address>
      <month>July</month>
      <year>2023</year>
      <venue>findings</venue>
    </meta>
    <frontmatter>
      <url hash="6754525f">2023.findings-acl.0</url>
      <bibkey>findings-2023-findings-association</bibkey>
    </frontmatter>
    <paper id="1">
      <title>Investigating Glyph-Phonetic Information for <fixed-case>C</fixed-case>hinese Spell Checking: What Works and What’s Next?</title>
      <author><first>Xiaotian</first><last>Zhang</last><affiliation>Fudan University</affiliation></author>
      <author><first>Yanjun</first><last>Zheng</last><affiliation>Fudan University</affiliation></author>
      <author><first>Hang</first><last>Yan</last><affiliation>Fudan University</affiliation></author>
      <author><first>Xipeng</first><last>Qiu</last><affiliation>Fudan University</affiliation></author>
      <pages>1-13</pages>
      <abstract>While pre-trained Chinese language models have demonstrated impressive performance on a wide range of NLP tasks, the Chinese Spell Checking (CSC) task remains a challenge. Previous research has explored using information such as glyphs and phonetics to improve the ability of CSC models to distinguish misspelled characters, with good results at the accuracy level on public datasets. However, the generalization ability of these CSC models has not been well understood: it is unclear whether they incorporate glyph-phonetic information and, if so, whether this information is fully utilized. In this paper, we aim to better understand the role of glyph-phonetic information in the CSC task and suggest directions for improvement. Additionally, we propose a new, more challenging, and practical setting for testing the generalizability of CSC models. All code is made publicly available.</abstract>
      <url hash="1449ab52">2023.findings-acl.1</url>
      <bibkey>zhang-etal-2023-investigating</bibkey>
      <doi>10.18653/v1/2023.findings-acl.1</doi>
    </paper>
    <paper id="2">
      <title>A Self-Supervised Integration Method of Pretrained Language Models and Word Definitions</title>
      <author><first>Hwiyeol</first><last>Jo</last><affiliation>Search US, Naver</affiliation></author>
      <pages>14-26</pages>
      <abstract>We investigate the representation of pretrained language models and humans, using the idea of word definition modeling–how well a word is represented by its definition, and vice versa. Our analysis shows that a word representation in pretrained language models does not successfully map its human-written definition and its usage in example sentences. We then present a simple method DefBERT that integrates pretrained models with word semantics in dictionaries. We show its benefits on newly-proposed tasks of definition ranking and definition sense disambiguation. Furthermore, we present the results on standard word similarity tasks and short text classification tasks where models are required to encode semantics with only a few words. The results demonstrate the effectiveness of integrating word definitions and pretrained language models.</abstract>
      <url hash="d95448cf">2023.findings-acl.2</url>
      <bibkey>jo-2023-self</bibkey>
      <doi>10.18653/v1/2023.findings-acl.2</doi>
    </paper>
    <paper id="3">
      <title>Conformal Nucleus Sampling</title>
      <author><first>Shauli</first><last>Ravfogel</last><affiliation>Bar Ilan University</affiliation></author>
      <author><first>Yoav</first><last>Goldberg</last><affiliation>Bar Ilan University</affiliation></author>
      <author><first>Jacob</first><last>Goldberger</last><affiliation>Bar-Ilan University</affiliation></author>
      <pages>27-34</pages>
      <abstract>Language models generate text based on successively sampling the next word. A decoding procedure based on nucleus (top-<tex-math>p</tex-math>) sampling chooses from the smallest possible set of words whose cumulative probability exceeds the probability <tex-math>p</tex-math>. In this work, we assess whether a top-<tex-math>p</tex-math> set is indeed aligned with its probabilistic meaning in various linguistic contexts.We employ conformal prediction, a calibration procedure that focuses on the construction of minimal prediction sets according to a desired confidence level, to calibrate the parameter <tex-math>p</tex-math> as a function of the entropy of the next word distribution. We find that OPT models are overconfident, and that calibration shows a moderate inverse scaling with model size.</abstract>
      <url hash="36489086">2023.findings-acl.3</url>
      <bibkey>ravfogel-etal-2023-conformal</bibkey>
      <doi>10.18653/v1/2023.findings-acl.3</doi>
    </paper>
    <paper id="4">
      <title><fixed-case>D</fixed-case>isco<fixed-case>P</fixed-case>rompt: Path Prediction Prompt Tuning for Implicit Discourse Relation Recognition</title>
      <author><first>Chunkit</first><last>Chan</last><affiliation>Department of CSE, Hong Kong University of Science and Technology, Hong Kong, China</affiliation></author>
      <author><first>Xin</first><last>Liu</last><affiliation>Hong Kong University of Science and Technology</affiliation></author>
      <author><first>Jiayang</first><last>Cheng</last><affiliation>HKUST</affiliation></author>
      <author><first>Zihan</first><last>Li</last><affiliation>Department of CSE, Hong Kong University of Science and Technology, Hong Kong, China</affiliation></author>
      <author><first>Yangqiu</first><last>Song</last><affiliation>HKUST</affiliation></author>
      <author><first>Ginny</first><last>Wong</last><affiliation>NVIDIA AI Technology Center</affiliation></author>
      <author><first>Simon</first><last>See</last><affiliation>nvidia</affiliation></author>
      <pages>35-57</pages>
      <abstract>Implicit Discourse Relation Recognition (IDRR) is a sophisticated and challenging task to recognize the discourse relations between the arguments with the absence of discourse connectives. The sense labels for each discourse relation follow a hierarchical classification scheme in the annotation process (Prasad et al., 2008), forming a hierarchy structure. Most existing works do not well incorporate the hierarchy structure but focus on the syntax features and the prior knowledge of connectives in the manner of pure text classification. We argue that it is more effective to predict the paths inside the hierarchical tree (e.g., “Comparison -&gt; Contrast -&gt; however”) rather than flat labels (e.g., Contrast) or connectives (e.g., however). We propose a prompt-based path prediction method to utilize the interactive information and intrinsic senses among the hierarchy in IDRR. This is the first work that injects such structure information into pre-trained language models via prompt tuning, and the performance of our solution shows significant and consistent improvement against competitive baselines.</abstract>
      <url hash="7b57d276">2023.findings-acl.4</url>
      <bibkey>chan-etal-2023-discoprompt</bibkey>
      <doi>10.18653/v1/2023.findings-acl.4</doi>
    </paper>
    <paper id="5">
      <title>Modularized Zero-shot <fixed-case>VQA</fixed-case> with Pre-trained Models</title>
      <author><first>Rui</first><last>Cao</last><affiliation>Singapore Management University</affiliation></author>
      <author><first>Jing</first><last>Jiang</last><affiliation>Singapore Management University</affiliation></author>
      <pages>58-76</pages>
      <abstract>Large-scale pre-trained models (PTMs) show great zero-shot capabilities. In this paper, we study how to leverage them for zero-shot visual question answering (VQA).Our approach is motivated by a few observations. First, VQA questions often require multiple steps of reasoning, which is still a capability that most PTMs lack. Second, different steps in VQA reasoning chains require different skills such as object detection and relational reasoning, but a single PTM may not possess all these skills. Third, recent work on zero-shot VQA does not explicitly consider multi-step reasoning chains, which makes them less interpretable compared with a decomposition-based approach. We propose a modularized zero-shot network that explicitly decomposes questions into sub reasoning steps and is highly interpretable. We convert sub reasoning tasks to acceptable objectives of PTMs and assign tasks to proper PTMs without any adaptation. Our experiments on two VQA benchmarks under the zero-shot setting demonstrate the effectiveness of our method and better interpretability compared with several baselines.</abstract>
      <url hash="0e5c9b65">2023.findings-acl.5</url>
      <bibkey>cao-jiang-2023-modularized</bibkey>
      <doi>10.18653/v1/2023.findings-acl.5</doi>
    </paper>
    <paper id="6">
      <title><fixed-case>T</fixed-case>imeline<fixed-case>QA</fixed-case>: A Benchmark for Question Answering over Timelines</title>
      <author><first>Wang-Chiew</first><last>Tan</last><affiliation>Meta</affiliation></author>
      <author><first>Jane</first><last>Dwivedi-Yu</last><affiliation>Meta AI</affiliation></author>
      <author><first>Yuliang</first><last>Li</last><affiliation>Meta</affiliation></author>
      <author><first>Lambert</first><last>Mathias</last><affiliation>Meta</affiliation></author>
      <author><first>Marzieh</first><last>Saeidi</last><affiliation>Shiftlab AI</affiliation></author>
      <author><first>Jing Nathan</first><last>Yan</last><affiliation>Cornell University</affiliation></author>
      <author><first>Alon</first><last>Halevy</last><affiliation>Meta AI</affiliation></author>
      <pages>77-91</pages>
      <abstract>Lifelogs are descriptions of experiences that a person had during their life. Lifelogs are created by fusing data from the multitude of digital services, such as online photos, maps, shopping and content streaming services. Question answering over lifelogs can offer personal assistants a critical resource when they try to provide advice in context. However, obtaining answers to questions over lifelogs is beyond the current state of the art of question answering techniques for a variety of reasons, the most pronounced of which is that lifelogs combine free text with some degree of structure such as temporal and geographical information. We create and publicly release TimelineQA, a benchmark for accelerating progress on querying lifelogs. TimelineQA generates lifelogs of imaginary people. The episodes in the lifelog range from major life episodes such as high school graduation to those that occur on a daily basis such as going for a run. We describe a set of experiments on TimelineQA with several state-of-the-art QA models. Our experiments reveal that for atomic queries, an extractive QA system significantly out-performs a state-of-the-art retrieval-augmented QA system. For multi-hop queries involving aggregates, we show that the best result is obtained with a state-of-the-art table QA technique, assuming the ground truth set of episodes for deriving the answer is available.</abstract>
      <url hash="813d0d55">2023.findings-acl.6</url>
      <bibkey>tan-etal-2023-timelineqa</bibkey>
      <doi>10.18653/v1/2023.findings-acl.6</doi>
    </paper>
    <paper id="7">
      <title>Abstractive Text Summarization Using the <fixed-case>BRIO</fixed-case> Training Paradigm</title>
      <author><first>Khang</first><last>Lam</last><affiliation>Can Tho University</affiliation></author>
      <author><first>Thieu</first><last>Doan</last><affiliation>Can Tho University</affiliation></author>
      <author><first>Khang</first><last>Pham</last><affiliation>Duy Tan University</affiliation></author>
      <author><first>Jugal</first><last>Kalita</last><affiliation>University of Colorado</affiliation></author>
      <pages>92-99</pages>
      <abstract>Summary sentences produced by abstractive summarization models may be coherent and comprehensive, but they lack control and rely heavily on reference summaries. The BRIO training paradigm assumes a non-deterministic distribution to reduce the model’s dependence on reference summaries, and improve model performance during inference. This paper presents a straightforward but effective technique to improve abstractive summaries by fine-tuning pre-trained language models, and training them with the BRIO paradigm. We build a text summarization dataset for Vietnamese, called VieSum. We perform experiments with abstractive summarization models trained with the BRIO paradigm on the CNNDM and the VieSum datasets. The results show that the models, trained on basic hardware, outperform all existing abstractive summarization models, especially for Vietnamese.</abstract>
      <url hash="ffed3bbb">2023.findings-acl.7</url>
      <bibkey>lam-etal-2023-abstractive</bibkey>
      <doi>10.18653/v1/2023.findings-acl.7</doi>
    </paper>
    <paper id="8">
      <title>Modeling the <fixed-case>Q</fixed-case>-Diversity in a Min-max Play Game for Robust Optimization</title>
      <author><first>Ting</first><last>Wu</last><affiliation>Fudan University</affiliation></author>
      <author><first>Rui</first><last>Zheng</last><affiliation>Fudan University</affiliation></author>
      <author><first>Tao</first><last>Gui</last><affiliation>fudan university</affiliation></author>
      <author><first>Qi</first><last>Zhang</last><affiliation>Fudan University</affiliation></author>
      <author><first>Xuanjing</first><last>Huang</last><affiliation>Fudan University</affiliation></author>
      <pages>100-113</pages>
      <abstract>Models trained with empirical risk minimization (ERM) are revealed to easily rely on spurious correlations, resulting in poor generalization. Group distributionally robust optimization (group DRO) can alleviate this problem by minimizing the worst-case loss over pre-defined groups. While promising, in practice factors like expensive annotations and privacy preclude the availability of group labels. More crucially, when taking a closer look at the failure modes of out-of-distribution generalization, the typical procedure of reweighting in group DRO loses efficiency. Hinged on the limitations, in this work, we reformulate the group DRO framework by proposing Q-Diversity. Characterized by an interactive training mode, Q-Diversity relaxes the group identification from annotation into direct parameterization. Furthermore, a novel mixing strategy across groups is presented to diversify the under-represented groups. In a series of experiments on both synthetic and real-world text classification tasks, results demonstrate that Q-Diversity can consistently improve worst-case accuracy under different distributional shifts, outperforming state-of-the-art alternatives.</abstract>
      <url hash="7d02f983">2023.findings-acl.8</url>
      <bibkey>wu-etal-2023-modeling</bibkey>
      <doi>10.18653/v1/2023.findings-acl.8</doi>
    </paper>
    <paper id="9">
      <title>Pre-training Language Model as a Multi-perspective Course Learner</title>
      <author><first>Beiduo</first><last>Chen</last><affiliation>University of Science and Technology of China</affiliation></author>
      <author><first>Shaohan</first><last>Huang</last><affiliation>Microsoft Research Asia</affiliation></author>
      <author><first>Zihan</first><last>Zhang</last><affiliation>Microsoft</affiliation></author>
      <author><first>Wu</first><last>Guo</last><affiliation>university of science and technology of china</affiliation></author>
      <author><first>Zhenhua</first><last>Ling</last><affiliation>University of Science and Technology of China</affiliation></author>
      <author><first>Haizhen</first><last>Huang</last><affiliation>Microsoft</affiliation></author>
      <author><first>Furu</first><last>Wei</last><affiliation>Microsoft Research</affiliation></author>
      <author><first>Weiwei</first><last>Deng</last><affiliation>Microsoft</affiliation></author>
      <author><first>Qi</first><last>Zhang</last><affiliation>Microsoft</affiliation></author>
      <pages>114-128</pages>
      <abstract>ELECTRA, the generator-discriminator pre-training framework, has achieved impressive semantic construction capability among various downstream tasks. Despite the convincing performance, ELECTRA still faces the challenges of monotonous training and deficient interaction. Generator with only masked language modeling (MLM) leads to biased learning and label imbalance for discriminator, decreasing learning efficiency; no explicit feedback loop from discriminator to generator results in the chasm between these two components, underutilizing the course learning. In this study, a multi-perspective course learning (MCL) method is proposed to fetch a many degrees and visual angles for sample-efficient pre-training, and to fully leverage the relationship between generator and discriminator. Concretely, three self-supervision courses are designed to alleviate inherent flaws of MLM and balance the label in a multi-perspective way. Besides, two self-correction courses are proposed to bridge the chasm between the two encoders by creating a “correction notebook” for secondary-supervision. Moreover, a course soups trial is conducted to solve the “tug-of-war” dynamics problem of MCL, evolving a stronger pre-trained model. Experimental results show that our method significantly improves ELECTRA’s average performance by 2.8% and 3.2% absolute points respectively on GLUE and SQuAD 2.0 benchmarks, and overshadows recent advanced ELECTRA-style models under the same settings. The pre-trained MCL model is available at <url>https://huggingface.co/McmanusChen/MCL-base</url>.</abstract>
      <url hash="4806ca5e">2023.findings-acl.9</url>
      <bibkey>chen-etal-2023-pre</bibkey>
      <doi>10.18653/v1/2023.findings-acl.9</doi>
    </paper>
    <paper id="10">
      <title>Layerwise universal adversarial attack on <fixed-case>NLP</fixed-case> models</title>
      <author><first>Olga</first><last>Tsymboi</last><affiliation>Sber AI Lab, Moscow Institute of Physics and Technology</affiliation></author>
      <author><first>Danil</first><last>Malaev</last><affiliation>Sber AI Lab</affiliation></author>
      <author><first>Andrei</first><last>Petrovskii</last><affiliation>Sber AI Lab</affiliation></author>
      <author><first>Ivan</first><last>Oseledets</last><affiliation>Skolkovo Institute of Science and Technology</affiliation></author>
      <pages>129-143</pages>
      <abstract>In this work, we examine the vulnerability of language models to universal adversarial triggers (UATs). We propose a new white-box approach to the construction of layerwise UATs (LUATs), which searches the triggers by perturbing hidden layers of a network. On the example of three transformer models and three datasets from the GLUE benchmark, we demonstrate that our method provides better transferability in a model-to-model setting with an average gain of 9.3% in the fooling rate over the baseline. Moreover, we investigate triggers transferability in the task-to-task setting. Using small subsets from the datasets similar to the target tasks for choosing a perturbed layer, we show that LUATs are more efficient than vanilla UATs by 7.1% in the fooling rate.</abstract>
      <url hash="e195db81">2023.findings-acl.10</url>
      <bibkey>tsymboi-etal-2023-layerwise</bibkey>
      <doi>10.18653/v1/2023.findings-acl.10</doi>
    </paper>
    <paper id="11">
      <title>Scene-robust Natural Language Video Localization via Learning Domain-invariant Representations</title>
      <author><first>Zehan</first><last>Wang</last><affiliation>zhejiang university</affiliation></author>
      <author><first>Yang</first><last>Zhao</last><affiliation>Zhejiang University</affiliation></author>
      <author><first>Haifeng</first><last>Huang</last><affiliation>Zhejiang University</affiliation></author>
      <author><first>Yan</first><last>Xia</last><affiliation>Zhejiang University</affiliation></author>
      <author><first>Zhou</first><last>Zhao</last><affiliation>zhejiang university</affiliation></author>
      <pages>144-160</pages>
      <abstract>Natural language video localization(NLVL) task involves the semantic matching of a text query with a moment from an untrimmed video. Previous methods primarily focus on improving performance with the assumption of independently identical data distribution while ignoring the out-of-distribution data. Therefore, these approaches often fail when handling the videos and queries in novel scenes, which is inevitable in real-world scenarios. In this paper, we, for the first time, formulate the scene-robust NLVL problem and propose a novel generalizable NLVL framework utilizing data in multiple available scenes to learn a robust model. Specifically, our model learns a group of generalizable domain-invariant representations by alignment and decomposition. First, we propose a comprehensive intra- and inter-sample distance metric for complex multi-modal feature space, and an asymmetric multi-modal alignment loss for different information densities of text and vision. Further, to alleviate the conflict between domain-invariant features for generalization and domain-specific information for reasoning, we introduce domain-specific and domain-agnostic predictors to decompose and refine the learned features by dynamically adjusting the weights of samples. Based on the original video tags, we conduct extensive experiments on three NLVL datasets with different-grained scene shifts to show the effectiveness of our proposed methods.</abstract>
      <url hash="d5027ebe">2023.findings-acl.11</url>
      <bibkey>wang-etal-2023-scene</bibkey>
      <doi>10.18653/v1/2023.findings-acl.11</doi>
    </paper>
    <paper id="12">
      <title>Exploiting Pseudo Image Captions for Multimodal Summarization</title>
      <author><first>Chaoya</first><last>Jiang</last><affiliation>Peking University</affiliation></author>
      <author><first>Rui</first><last>Xie</last><affiliation>Peking University</affiliation></author>
      <author><first>Wei</first><last>Ye</last><affiliation>Peking University</affiliation></author>
      <author><first>Jinan</first><last>Sun</last><affiliation>Peking University</affiliation></author>
      <author><first>Shikun</first><last>Zhang</last><affiliation>Peking University</affiliation></author>
      <pages>161-175</pages>
      <abstract>Multimodal summarization with multimodal output (MSMO) faces a challenging semantic gap between visual and textual modalities due to the lack of reference images for training. Our pilot investigation indicates that image captions, which naturally connect texts and images, can significantly benefit MSMO. However, exposure of image captions during training is inconsistent with MSMO’s task settings, where prior cross-modal alignment information is excluded to guarantee the generalization of cross-modal semantic modeling. To this end, we propose a novel coarse-to-fine image-text alignment mechanism to identify the most relevant sentence of each image in a document, resembling the role of image captions in capturing visual knowledge and bridging the cross-modal semantic gap. Equipped with this alignment mechanism, our method easily yet impressively sets up state-of-the-art performances on all intermodality and intramodality metrics (e.g., more than 10% relative improvement on image recommendation precision). Further experiments reveal the correlation between image captions and text summaries, and prove that the pseudo image captions we generated are even better than the original ones in terms of promoting multimodal summarization.</abstract>
      <url hash="1cc1c1ef">2023.findings-acl.12</url>
      <bibkey>jiang-etal-2023-exploiting</bibkey>
      <doi>10.18653/v1/2023.findings-acl.12</doi>
    </paper>
    <paper id="13">
      <title>Cross-Lingual Transfer with Target Language-Ready Task Adapters</title>
      <author><first>Marinela</first><last>Parovic</last><affiliation>University of Cambridge</affiliation></author>
      <author><first>Alan</first><last>Ansell</last><affiliation>University of Cambridge</affiliation></author>
      <author><first>Ivan</first><last>Vulić</last><affiliation>University of Cambridge</affiliation></author>
      <author><first>Anna</first><last>Korhonen</last><affiliation>University of Cambridge</affiliation></author>
      <pages>176-193</pages>
      <abstract>Adapters have emerged as a modular and parameter-efficient approach to (zero-shot) cross-lingual transfer. The established MAD-X framework employs separate language and task adapters which can be arbitrarily combined to perform the transfer of any task to any target language. Subsequently, BAD-X, an extension of the MAD-X framework, achieves improved transfer at the cost of MAD-X’s modularity by creating ‘bilingual’ adapters specific to the source-target language pair. In this work, we aim to take the best of both worlds by (i) fine-tuning *task* adapters adapted to the target language(s) (so-called *‘target language-ready’ (TLR)* adapters) to maintain high transfer performance, but (ii) without sacrificing the highly modular design of MAD-X. The main idea of ‘target language-ready’ adapters is to resolve the training-vs-inference discrepancy of MAD-X: the task adapter ‘sees’ the target language adapter for the very first time during inference, and thus might not be fully compatible with it. We address this mismatch by exposing the task adapter to the target language adapter during training, and empirically validate several variants of the idea: in the simplest form, we alternate between using the source and target language adapters during task adapter training, which can be generalized to cycling over any set of language adapters. We evaluate different TLR-based transfer configurations with varying degrees of generality across a suite of standard cross-lingual benchmarks, and find that the most general (and thus most modular) configuration consistently outperforms MAD-X and BAD-X on most tasks and languages.</abstract>
      <url hash="5bdf4065">2023.findings-acl.13</url>
      <bibkey>parovic-etal-2023-cross</bibkey>
      <doi>10.18653/v1/2023.findings-acl.13</doi>
    </paper>
    <paper id="14">
      <title><fixed-case>D</fixed-case>yna<fixed-case>M</fixed-case>i<fixed-case>TE</fixed-case>: Discovering Explosive Topic Evolutions with User Guidance</title>
      <author><first>Nishant</first><last>Balepur</last><affiliation>University of Illinois at Urbana-Champaign</affiliation></author>
      <author><first>Shivam</first><last>Agarwal</last><affiliation>University of Illinois at Urbana Champaign</affiliation></author>
      <author><first>Karthik</first><last>Venkat Ramanan</last><affiliation>University of Illinois Urbana-Champaign</affiliation></author>
      <author><first>Susik</first><last>Yoon</last><affiliation>University of Illinois at Urbana-Champaign</affiliation></author>
      <author><first>Diyi</first><last>Yang</last><affiliation>Stanford University</affiliation></author>
      <author><first>Jiawei</first><last>Han</last><affiliation>UIUC</affiliation></author>
      <pages>194-217</pages>
      <abstract>Dynamic topic models (DTMs) analyze text streams to capture the evolution of topics. Despite their popularity, existing DTMs are either fully supervised, requiring expensive human annotations, or fully unsupervised, producing topic evolutions that often do not cater to a user’s needs. Further, the topic evolutions produced by DTMs tend to contain generic terms that are not indicative of their designated time steps. To address these issues, we propose the task of discriminative dynamic topic discovery. This task aims to discover topic evolutions from temporal corpora that distinctly align with a set of user-provided category names and uniquely capture topics at each time step. We solve this task by developing DynaMiTE, a framework that ensembles semantic similarity, category indicative, and time indicative scores to produce informative topic evolutions. Through experiments on three diverse datasets, including the use of a newly-designed human evaluation experiment, we demonstrate that DynaMiTE is a practical and efficient framework for helping users discover high-quality topic evolutions suited to their interests.</abstract>
      <url hash="212dc802">2023.findings-acl.14</url>
      <bibkey>balepur-etal-2023-dynamite</bibkey>
      <doi>10.18653/v1/2023.findings-acl.14</doi>
    </paper>
    <paper id="15">
      <title>Boost Transformer-based Language Models with <fixed-case>GPU</fixed-case>-Friendly Sparsity and Quantization</title>
      <author><first>Chong</first><last>Yu</last><affiliation>Fudan University, NVIDIA</affiliation></author>
      <author><first>Tao</first><last>Chen</last><affiliation>Fudan University</affiliation></author>
      <author><first>Zhongxue</first><last>Gan</last><affiliation>Fudan University</affiliation></author>
      <pages>218-235</pages>
      <abstract>Along with the performance improvement in NLP domain, the sizes of transformer-based language models (TLM) are also dramatically increased. Some prior works intend to compress TLM models into more compact forms, but do not fully consider the hardware characters may not support the efficient execution for these forms, leading to the deployment of TLM on hardware with noticeable acceleration is still challenging. This paper thoroughly designs a compression scheme named GPUSQ-TLM to maximally utilize the GPU-friendly 2:4 fine-grained structured sparsity and quantization characters. Especially, a dense TLM model is first pruned to meet the GPU’s acceleration constraint of sparse patterns with FP16 type, then it is further quantized into a fixed-point one by quantization-aware training, to provide an extra speedup for integer tensors on GPU. A mixed-strategy knowledge distillation of labels, logits and feature maps is used for best accuracy compensation during pruning and quantization process. Experiment results show GPUSQ-TLM scheme achieves state-of-the-art compression on TLM model of various encoder and decoder blocks with negligible accuracy degradation on SQuAD, GLUE, CNN-DM &amp; XSum and WikiText benchmarking tasks. Moreover, GPUSQ-TLM can boost actual deployment performance by up to 4.08-4.25x latency and 6.18-6.79x throughput on A100 GPU.</abstract>
      <url hash="7fde7186">2023.findings-acl.15</url>
      <bibkey>yu-etal-2023-boost</bibkey>
      <doi>10.18653/v1/2023.findings-acl.15</doi>
    </paper>
    <paper id="16">
      <title><fixed-case>RMSS</fixed-case>inger: Realistic-Music-Score based Singing Voice Synthesis</title>
      <author><first>Jinzheng</first><last>He</last><affiliation>Zhejiang University</affiliation></author>
      <author><first>Jinglin</first><last>Liu</last><affiliation>ByteDance</affiliation></author>
      <author><first>Zhenhui</first><last>Ye</last><affiliation>Zhejiang University</affiliation></author>
      <author><first>Rongjie</first><last>Huang</last><affiliation>Zhejiang University</affiliation></author>
      <author><first>Chenye</first><last>Cui</last><affiliation>Zhejiang University</affiliation></author>
      <author><first>Huadai</first><last>Liu</last><affiliation>Zhejiang University</affiliation></author>
      <author><first>Zhou</first><last>Zhao</last><affiliation>zhejiang university</affiliation></author>
      <pages>236-248</pages>
      <abstract>We are interested in a challenging task, Realistic-Music-Score based Singing Voice Synthesis (RMS-SVS). RMS-SVS aims to generate high-quality singing voices given realistic music scores with different note types (grace, slur, rest, etc.). Though significant progress has been achieved, recent singing voice synthesis (SVS) methods are limited to fine-grained music scores, which require a complicated data collection pipeline with time-consuming manual annotation to align music notes with phonemes. % Furthermore, existing approaches cannot synthesize rhythmic singing voices given realistic music scores due to the domain gap between fine-grained music scores and realistic music scores. Furthermore, these manual annotation destroys the regularity of note durations in music scores, making fine-grained music scores inconvenient for composing. To tackle these challenges, we propose RMSSinger, the first RMS-SVS method, which takes realistic music scores as input, eliminating most of the tedious manual annotation and avoiding the aforementioned inconvenience. Note that music scores are based on words rather than phonemes, in RMSSinger, we introduce word-level modeling to avoid the time-consuming phoneme duration annotation and the complicated phoneme-level mel-note alignment. Furthermore, we propose the first diffusion-based pitch modeling method, which ameliorates the naturalness of existing pitch-modeling methods. To achieve these, we collect a new dataset containing realistic music scores and singing voices according to these realistic music scores from professional singers. Extensive experiments on the dataset demonstrate the effectiveness of our methods. Audio samples are available at <url>https://rmssinger.github.io/</url>.</abstract>
      <url hash="380da6ce">2023.findings-acl.16</url>
      <bibkey>he-etal-2023-rmssinger</bibkey>
      <doi>10.18653/v1/2023.findings-acl.16</doi>
    </paper>
    <paper id="17">
      <title>Zero-Shot Prompting for Implicit Intent Prediction and Recommendation with Commonsense Reasoning</title>
      <author><first>Hui-Chi</first><last>Kuo</last><affiliation>National Taiwan University</affiliation></author>
      <author><first>Yun-Nung</first><last>Chen</last><affiliation>National Taiwan University</affiliation></author>
      <pages>249-258</pages>
      <abstract>The current generation of intelligent assistants require explicit user requests to perform tasks or services, often leading to lengthy and complex conversations. In contrast, human assistants can infer multiple implicit intents from utterances via their commonsense knowledge, thereby simplifying interactions. To bridge this gap, this paper proposes a framework for multi-domain dialogue systems. This framework automatically infers implicit intents from user utterances, and prompts a large pre-trained language model to suggest suitable task-oriented bots. By leveraging commonsense knowledge, our framework recommends associated bots in a zero-shot manner, enhancing interaction efficiency and effectiveness. This approach substantially reduces interaction complexity, seamlessly integrates various domains and tasks, and represents a significant step towards creating more human-like intelligent assistants that can reason about implicit intents, offering a superior user experience.</abstract>
      <url hash="5323b4c8">2023.findings-acl.17</url>
      <bibkey>kuo-chen-2023-zero</bibkey>
      <doi>10.18653/v1/2023.findings-acl.17</doi>
    </paper>
    <paper id="18">
      <title><fixed-case>MTGP</fixed-case>: Multi-turn Target-oriented Dialogue Guided by Generative Global Path with Flexible Turns</title>
      <author><first>Anqi</first><last>Liu</last><affiliation>TianJin University</affiliation></author>
      <author><first>Bo</first><last>Wang</last><affiliation>Tianjin University</affiliation></author>
      <author><first>Yue</first><last>Tan</last><affiliation>Tianjin University</affiliation></author>
      <author><first>Dongming</first><last>Zhao</last><affiliation>Artificial Intelligence Laboratory of China Mobile Communications Group Tianjin Co., Ltd</affiliation></author>
      <author><first>Kun</first><last>Huang</last><affiliation>China Mobile</affiliation></author>
      <author><first>Ruifang</first><last>He</last><affiliation>Tianjin University</affiliation></author>
      <author><first>Yuexian</first><last>Hou</last><affiliation>Tianjin University</affiliation></author>
      <pages>259-271</pages>
      <abstract>Target-oriented dialogue guides the dialogue to a target quickly and smoothly. The latest approaches focus on global planning, which plans toward the target before the conversation instead of adopting a greedy strategy during the conversation. However, the global plan in existing works is fixed to certain turns by generating paths with certain nodes, which limits the optimization of turns and coherence of the target-oriented process. Toward flexible global planning, we propose to generate a global path as a natural language sentence instead of a sequence of nodes. With this path, the dialog is guided to the target with flexible turns of dialog. For model training, we also extract targetoriented dialogues from the chit-chat corpus with a knowledge graph. We conduct experiments on three datasets and simulate scenarios with and without user participation. The results show that our method has fewer turns, more coherent semantics, and a higher success rate in reaching the target than baselines.</abstract>
      <url hash="4feba1dc">2023.findings-acl.18</url>
      <bibkey>liu-etal-2023-mtgp</bibkey>
      <doi>10.18653/v1/2023.findings-acl.18</doi>
    </paper>
    <paper id="19">
      <title>The Larger they are, the Harder they Fail: Language Models do not Recognize Identifier Swaps in Python</title>
      <author><first>Antonio Valerio</first><last>Miceli Barone</last><affiliation>The University of Edinburgh</affiliation></author>
      <author><first>Fazl</first><last>Barez</last><affiliation>The University of Edinburgh</affiliation></author>
      <author><first>Shay B.</first><last>Cohen</last><affiliation>University of Edinburgh</affiliation></author>
      <author><first>Ioannis</first><last>Konstas</last><affiliation>Heriot-Watt University</affiliation></author>
      <pages>272-292</pages>
      <abstract>Large Language Models (LLMs) have successfully been applied to code generation tasks, raising the question of how well these models understand programming. Typical programming languages have invariances and equivariances in their semantics that human programmers intuitively understand and exploit, such as the (near) invariance to the renaming of identifiers. We show that LLMs not only fail to properly generate correct Python code when default function names are swapped, but some of them even become more confident in their incorrect predictions as the model size increases, an instance of the recently discovered phenomenon of Inverse Scaling, which runs contrary to the commonly observed trend of increasing prediction quality with increasing model size. Our findings indicate that, despite their astonishing typical-case performance, LLMs still lack a deep, abstract understanding of the content they manipulate, making them unsuitable for tasks that statistically deviate from their training data, and that mere scaling is not enough to achieve such capability.</abstract>
      <url hash="8ac00732">2023.findings-acl.19</url>
      <bibkey>miceli-barone-etal-2023-larger</bibkey>
      <doi>10.18653/v1/2023.findings-acl.19</doi>
    </paper>
    <paper id="20">
      <title>Class Lifelong Learning for Intent Detection via Structure Consolidation Networks</title>
      <author><first>Qingbin</first><last>Liu</last><affiliation>Tencent</affiliation></author>
      <author><first>Yanchao</first><last>Hao</last><affiliation>Tencent</affiliation></author>
      <author><first>Xiaolong</first><last>Liu</last><affiliation>Tencent</affiliation></author>
      <author id="bo-li"><first>Bo</first><last>Li</last><affiliation>Tencent</affiliation></author>
      <author><first>Dianbo</first><last>Sui</last><affiliation>Institute of Automation, Chinese Academy of Sciences</affiliation></author>
      <author><first>Shizhu</first><last>He</last><affiliation>Institute of Automation, Chinese Academy of Sciences</affiliation></author>
      <author><first>Kang</first><last>Liu</last><affiliation>Institute of Automation, Chinese Academy of Sciences</affiliation></author>
      <author><first>Jun</first><last>Zhao</last><affiliation>Chinese Academy of Sciences</affiliation></author>
      <author><first>Xi</first><last>Chen</last><affiliation>tencent</affiliation></author>
      <author><first>Ningyu</first><last>Zhang</last><affiliation>Zhejiang University</affiliation></author>
      <author><first>Jiaoyan</first><last>Chen</last><affiliation>The University of Manchester</affiliation></author>
      <pages>293-306</pages>
      <abstract>Intent detection, which estimates diverse intents behind user utterances, is an essential component of task-oriented dialogue systems. Previous intent detection models are usually trained offline, which can only handle predefined intent classes. In the real world, new intents may keep challenging deployed models. For example, with the prevalence of the COVID-19 pandemic, users may pose various issues related to the pandemic to conversational systems, which brings many new intents. A general intent detection model should be intelligent enough to continually learn new data and recognize new arriving intent classes. Therefore, this work explores Class Lifelong Learning for Intent Detection (CLL-ID), where the model continually learns new intent classes from new data while avoiding catastrophic performance degradation on old data. To this end, we propose a novel lifelong learning method, called Structure Consolidation Networks (SCN), which consists of structure-based retrospection and contrastive knowledge distillation to handle the problems of expression diversity and class imbalance in the CLL-ID task. In addition to formulating the new task, we construct 3 benchmarks based on 8 intent detection datasets. Experimental results demonstrate the effectiveness of SCN, which significantly outperforms previous lifelong learning methods on the three benchmarks.</abstract>
      <url hash="396694ad">2023.findings-acl.20</url>
      <bibkey>liu-etal-2023-class</bibkey>
      <doi>10.18653/v1/2023.findings-acl.20</doi>
    </paper>
    <paper id="21">
      <title>On Evaluating and Mitigating Gender Biases in Multilingual Settings</title>
      <author><first>Aniket</first><last>Vashishtha</last><affiliation>Microsoft Research India</affiliation></author>
      <author><first>Kabir</first><last>Ahuja</last><affiliation>Microsoft Research</affiliation></author>
      <author><first>Sunayana</first><last>Sitaram</last><affiliation>Microsoft Research India</affiliation></author>
      <pages>307-318</pages>
      <abstract>While understanding and removing gender biases in language models has been a long-standing problem in Natural Language Processing, prior research work has primarily been limited to English. In this work, we investigate some of the challenges with evaluating and mitigating biases in multilingual settings which stem from a lack of existing benchmarks and resources for bias evaluation beyond English especially for non-western context. In this paper, we first create a benchmark for evaluating gender biases in pre-trained masked language models by extending DisCo to different Indian languages using human annotations. We extend various debiasing methods to work beyond English and evaluate their effectiveness for SOTA massively multilingual models on our proposed metric. Overall, our work highlights the challenges that arise while studying social biases in multilingual settings and provides resources as well as mitigation techniques to take a step toward scaling to more languages.</abstract>
      <url hash="447dc081">2023.findings-acl.21</url>
      <bibkey>vashishtha-etal-2023-evaluating</bibkey>
      <doi>10.18653/v1/2023.findings-acl.21</doi>
    </paper>
    <paper id="22">
      <title>Rethinking Round-Trip Translation for Machine Translation Evaluation</title>
      <author><first>Terry Yue</first><last>Zhuo</last><affiliation>CSIRO’s Data61 and Monash University</affiliation></author>
      <author><first>Qiongkai</first><last>Xu</last><affiliation>The University of Melbourne</affiliation></author>
      <author><first>Xuanli</first><last>He</last><affiliation>University College London</affiliation></author>
      <author><first>Trevor</first><last>Cohn</last><affiliation>University of Melbourne</affiliation></author>
      <pages>319-337</pages>
      <abstract>Automatic evaluation methods for translation often require model training, and thus the availability of parallel corpora limits their applicability to low-resource settings. Round-trip translation is a potential workaround, which can reframe bilingual evaluation into a much simpler monolingual task. Early results from the era of statistical machine translation (SMT) raised fundamental concerns about the utility of this approach, based on poor correlation with human translation quality judgments. In this paper, we revisit this technique with modern neural translation (NMT) and show that round-trip translation does allow for accurate automatic evaluation without the need for reference translations. These opposite findings can be explained through the copy mechanism in SMT that is absent in NMT. We demonstrate that round-trip translation benefits multiple machine translation evaluation tasks: i) predicting forward translation scores; ii) improving the performance of a quality estimation model; and iii) identifying adversarial competitors in shared tasks via cross-system verification.</abstract>
      <url hash="2f44d0e5">2023.findings-acl.22</url>
      <bibkey>zhuo-etal-2023-rethinking</bibkey>
      <doi>10.18653/v1/2023.findings-acl.22</doi>
    </paper>
    <paper id="23">
      <title><tex-math>G^3R</tex-math>: A Graph-Guided Generate-and-Rerank Framework for Complex and Cross-domain Text-to-<fixed-case>SQL</fixed-case> Generation</title>
      <author><first>Yanzheng</first><last>Xiang</last><affiliation>Southeast University</affiliation></author>
      <author><first>Qian-Wen</first><last>Zhang</last><affiliation>Tencent</affiliation></author>
      <author><first>Xu</first><last>Zhang</last><affiliation>Southeast University</affiliation></author>
      <author><first>Zejie</first><last>Liu</last><affiliation>Southeast University</affiliation></author>
      <author><first>Yunbo</first><last>Cao</last><affiliation>Tencent Corporation</affiliation></author>
      <author><first>Deyu</first><last>Zhou</last><affiliation>Southeast University</affiliation></author>
      <pages>338-352</pages>
      <abstract>We present a framework called G3R for complex and cross-domain Text-to-SQL generation. G3R aims to address two limitations of current approaches: (1) The structure of the abstract syntax tree (AST) is not fully explored during the decoding process which is crucial for complex SQL generation; (2) Domain knowledge is not incorporated to enhance their ability to generalise to unseen domains. G3R consists of a graph-guided SQL generator and a knowledge-enhanced re-ranking mechanism. Firstly, during the decoding process, An AST-Grammar bipartite graph is constructed for both the AST and corresponding grammar rules of the generated partial SQL query. The graph-guided SQL generator captures its structural information and fuses heterogeneous information to predict the action sequence which can construct the AST for the corresponding SQL query uniquely. Then, in the inference stage, a knowledge-enhanced re-ranking mechanism is proposed to introduce domain knowledge to re-rank candidate SQL queries from the beam output and choose the final answer. The SQL ranker is based on pre-trained language models (PLM) and contrastive learning with hybrid prompt tuning is incorporated to stimulate the knowledge of PLMs and make it more discriminative. The proposed approach achieves state-of-the-art results on the Spider and Spider-DK benchmarks, which are challenging complex and cross-domain benchmarks for Text-to-SQL semantic analysis.</abstract>
      <url hash="35f1a036">2023.findings-acl.23</url>
      <bibkey>xiang-etal-2023-g</bibkey>
      <doi>10.18653/v1/2023.findings-acl.23</doi>
    </paper>
    <paper id="24">
      <title>A Unified Knowledge Graph Augmentation Service for Boosting Domain-specific <fixed-case>NLP</fixed-case> Tasks</title>
      <author><first>Ruiqing</first><last>Ding</last><affiliation>Peking University</affiliation></author>
      <author><first>Xiao</first><last>Han</last><affiliation>Shanghai University of Finance and Economics</affiliation></author>
      <author><first>Leye</first><last>Wang</last><affiliation>Peking University</affiliation></author>
      <pages>353-369</pages>
      <abstract>By focusing the pre-training process on domain-specific corpora, some domain-specific pre-trained language models (PLMs) have achieved state-of-the-art results. However, it is under-investigated to design a unified paradigm to inject domain knowledge in the PLM fine-tuning stage. We propose KnowledgeDA, a unified domain language model development service to enhance the task-specific training procedure with domain knowledge graphs. Given domain-specific task texts input, KnowledgeDA can automatically generate a domain-specific language model following three steps: (i) localize domain knowledge entities in texts via an embedding-similarity approach; (ii) generate augmented samples by retrieving replaceable domain entity pairs from two views of both knowledge graph and training data; (iii) select high-quality augmented samples for fine-tuning via confidence-based assessment. We implement a prototype of KnowledgeDA to learn language models for two domains, healthcare and software development. Experiments on domain-specific text classification and QA tasks verify the effectiveness and generalizability of KnowledgeDA.</abstract>
      <url hash="c2d8ee9c">2023.findings-acl.24</url>
      <bibkey>ding-etal-2023-unified</bibkey>
      <doi>10.18653/v1/2023.findings-acl.24</doi>
    </paper>
    <paper id="25">
      <title>Dialogue Planning via Brownian Bridge Stochastic Process for Goal-directed Proactive Dialogue</title>
      <author><first>Jian</first><last>Wang</last><affiliation>The Hong Kong Polytechnic University</affiliation></author>
      <author><first>Dongding</first><last>Lin</last><affiliation>The Hong Kong Polytechnic University</affiliation></author>
      <author><first>Wenjie</first><last>Li</last><affiliation>The Hong Kong Polytechnic University</affiliation></author>
      <pages>370-387</pages>
      <abstract>Goal-directed dialogue systems aim to proactively reach a pre-determined target through multi-turn conversations. The key to achieving this task lies in planning dialogue paths that smoothly and coherently direct conversations towards the target. However, this is a challenging and under-explored task. In this work, we propose a coherent dialogue planning approach that uses a stochastic process to model the temporal dynamics of dialogue paths. We define a latent space that captures the coherence of goal-directed behavior using a Brownian bridge process, which allows us to incorporate user feedback flexibly in dialogue planning. Based on the derived latent trajectories, we generate dialogue paths explicitly using pre-trained language models. We finally employ these paths as natural language prompts to guide dialogue generation. Our experiments show that our approach generates more coherent utterances and achieves the goal with a higher success rate.</abstract>
      <url hash="35ce3539">2023.findings-acl.25</url>
      <bibkey>wang-etal-2023-dialogue</bibkey>
      <doi>10.18653/v1/2023.findings-acl.25</doi>
    </paper>
    <paper id="26">
      <title>A Match Made in Heaven: A Multi-task Framework for Hyperbole and Metaphor Detection</title>
      <author><first>Naveen</first><last>Badathala</last><affiliation>Indian Institute of Technology Bombay</affiliation></author>
      <author><first>Abisek</first><last>Rajakumar Kalarani</last><affiliation>Indian Institute of Technology Bombay</affiliation></author>
      <author><first>Tejpalsingh</first><last>Siledar</last><affiliation>Indian Institute of Technology, Bombay</affiliation></author>
      <author><first>Pushpak</first><last>Bhattacharyya</last><affiliation>Indian Institute of Technology Bombay and Patna</affiliation></author>
      <pages>388-401</pages>
      <abstract>Hyperbole and metaphor are common in day-to-day communication (e.g., “I am in deep trouble”: how does trouble have depth?), which makes their detection important, especially in a conversational AI setting. Existing approaches to automatically detect metaphor and hyperbole have studied these language phenomena independently, but their relationship has hardly, if ever, been explored computationally. In this paper, we propose a multi-task deep learning framework to detect hyperbole and metaphor simultaneously. We hypothesize that metaphors help in hyperbole detection, and vice-versa. To test this hypothesis, we annotate two hyperbole datasets- HYPO and HYPO-L- with metaphor labels. Simultaneously, we annotate two metaphor datasets- TroFi and LCC- with hyperbole labels. Experiments using these datasets give an improvement of the state of the art of hyperbole detection by 12%. Additionally, our multi-task learning (MTL) approach shows an improvement of up to 17% over single-task learning (STL) for both hyperbole and metaphor detection, supporting our hypothesis. To the best of our knowledge, ours is the first demonstration of computational leveraging of linguistic intimacy between metaphor and hyperbole, leading to showing the superiority of MTL over STL for hyperbole and metaphor detection.</abstract>
      <url hash="bb6513d6">2023.findings-acl.26</url>
      <bibkey>badathala-etal-2023-match</bibkey>
      <doi>10.18653/v1/2023.findings-acl.26</doi>
    </paper>
    <paper id="27">
      <title>Prompt Tuning for Unified Multimodal Pretrained Models</title>
      <author><first>Hao</first><last>Yang</last><affiliation>Alibaba Group</affiliation></author>
      <author><first>Junyang</first><last>Lin</last><affiliation>Alibaba Group</affiliation></author>
      <author><first>An</first><last>Yang</last><affiliation>Alibaba Group</affiliation></author>
      <author><first>Peng</first><last>Wang</last><affiliation>Alibaba Group</affiliation></author>
      <author><first>Chang</first><last>Zhou</last><affiliation>Alibaba Group</affiliation></author>
      <pages>402-416</pages>
      <abstract>Prompt tuning has become a new paradigm for model tuning and it has demonstrated success in natural language pretraining and even vision pretraining. The parameter-efficient prompt tuning methods that optimize soft embeddings while keeping the pretrained model frozen demonstrate advantages in low computation costs and almost lossless performance. In this work, we explore the transfer of prompt tuning to multimodal pretrained models. Specifically, we implement prompt tuning to a unified sequence-to-sequence pretrained model by adding a sequence of learnable embeddings to each layer and finetuning the pretrained model on downstream task with only the learnable embeddings being optimized. Experimental results on a series of multimodal understanding and generation tasks demonstrate that our method OFA-PT can achieve comparable performance with finetuning across a series of multimodal generation and understanding tasks. Additionally, it significantly outperforms the unified multimodal pretrained model with other parameter-efficient tuning methods, e.g., Adapter, BitFit. etc. Besides, in comparison with finetuned models, the prompt-tuned models demonstrate improved robustness against adversarial attacks. We further figure out that experimental factors, including prompt length, prompt depth, and reparameteratization, have great impacts on the model performance, and thus we empirically provide a recommendation for the setups of prompt tuning.</abstract>
      <url hash="6d6915e5">2023.findings-acl.27</url>
      <bibkey>yang-etal-2023-prompt</bibkey>
      <doi>10.18653/v1/2023.findings-acl.27</doi>
    </paper>
    <paper id="28">
      <title>Learning Joint Structural and Temporal Contextualized Knowledge Embeddings for Temporal Knowledge Graph Completion</title>
      <author><first>Yifu</first><last>Gao</last><affiliation>National University of Defense Technology</affiliation></author>
      <author><first>Yongquan</first><last>He</last><affiliation>Meituan</affiliation></author>
      <author><first>Zhigang</first><last>Kan</last><affiliation>National University of Defense Technology</affiliation></author>
      <author><first>Yi</first><last>Han</last><affiliation>College of Meteorology and Oceanography, National University of Defense Technology</affiliation></author>
      <author><first>Linbo</first><last>Qiao</last><affiliation>National University of Defense Technology</affiliation></author>
      <author><first>Dongsheng</first><last>Li</last><affiliation>National University of Defense Technology</affiliation></author>
      <pages>417-430</pages>
      <abstract>Temporal knowledge graph completion that predicts missing links for incomplete temporal knowledge graphs (TKG) is gaining increasing attention. Most existing works have achieved good results by incorporating time information into static knowledge graph embedding methods. However, they ignore the contextual nature of the TKG structure, i.e., query-specific subgraph contains both structural and temporal neighboring facts. This paper presents the SToKE, a novel method that employs the pre-trained language model (PLM) to learn joint Structural and Temporal Contextualized Knowledge Embeddings.Specifically, we first construct an event evolution tree (EET) for each query to enable PLMs to handle the TKG, which can be seen as a structured event sequence recording query-relevant structural and temporal contexts. We then propose a novel temporal embedding and structural matrix to learn the time information and structural dependencies of facts in EET.Finally, we formulate TKG completion as a mask prediction problem by masking the missing entity of the query to fine-tune pre-trained language models. Experimental results on three widely used datasets show the superiority of our model.</abstract>
      <url hash="59e7aafe">2023.findings-acl.28</url>
      <bibkey>gao-etal-2023-learning</bibkey>
      <doi>10.18653/v1/2023.findings-acl.28</doi>
    </paper>
    <paper id="29">
      <title>A Systematic Study and Comprehensive Evaluation of <fixed-case>C</fixed-case>hat<fixed-case>GPT</fixed-case> on Benchmark Datasets</title>
      <author><first>Md Tahmid Rahman</first><last>Laskar</last><affiliation>Dialpad Inc</affiliation></author>
      <author><first>M Saiful</first><last>Bari</last><affiliation>Nanyang Technological University</affiliation></author>
      <author><first>Mizanur</first><last>Rahman</last><affiliation>York University</affiliation></author>
      <author><first>Md Amran Hossen</first><last>Bhuiyan</last><affiliation>York University</affiliation></author>
      <author><first>Shafiq</first><last>Joty</last><affiliation>Nanyang Technological University; Salesforce AI Research</affiliation></author>
      <author><first>Jimmy</first><last>Huang</last><affiliation>School of Information Technology, York University</affiliation></author>
      <pages>431-469</pages>
      <abstract>The development of large language models (LLMs) such as ChatGPT has brought a lot of attention recently. However, their evaluation in the benchmark academic datasets remains under-explored due to the difficulty of evaluating the generative outputs produced by this model against the ground truth. In this paper, we aim to present a thorough evaluation of ChatGPT’s performance on diverse academic datasets, covering tasks like question-answering, text summarization, code generation, commonsense reasoning, mathematical problem-solving, machine translation, bias detection, and ethical considerations. Specifically, we evaluate ChatGPT across 140 tasks and analyze 255K responses it generates in these datasets. This makes our work the largest evaluation of ChatGPT in NLP benchmarks. In short, our study aims to validate the strengths and weaknesses of ChatGPT in various tasks and provide insights for future research using LLMs. We also report a new emergent ability to follow multi-query instructions that we mostly found in ChatGPT and other instruction-tuned models. Our extensive evaluation shows that even though ChatGPT is capable of performing a wide variety of tasks, and may obtain impressive performance in several benchmark datasets, it is still far from achieving the ability to reliably solve many challenging tasks. By providing a thorough assessment of ChatGPT’s performance across diverse NLP tasks, this paper sets the stage for a targeted deployment of ChatGPT-like LLMs in real-world applications.</abstract>
      <url hash="20c05d96">2023.findings-acl.29</url>
      <bibkey>laskar-etal-2023-systematic</bibkey>
      <doi>10.18653/v1/2023.findings-acl.29</doi>
    </paper>
    <paper id="30">
      <title>Generating Deep Questions with Commonsense Reasoning Ability from the Text by Disentangled Adversarial Inference</title>
      <author><first>Jianxing</first><last>Yu</last><affiliation>Sun Yat-sen University</affiliation></author>
      <author><first>Shiqi</first><last>Wang</last><affiliation>Sun Yat-sen University</affiliation></author>
      <author><first>Libin</first><last>Zheng</last><affiliation>Sun Yat-sen University</affiliation></author>
      <author><first>Qinliang</first><last>Su</last><affiliation>Sun Yat-sen University</affiliation></author>
      <author><first>Wei</first><last>Liu</last><affiliation>Sun Yat-sen University</affiliation></author>
      <author><first>Baoquan</first><last>Zhao</last><affiliation>Sun Yat-sen University</affiliation></author>
      <author><first>Jian</first><last>Yin</last><affiliation>Sun Yat-Sen University</affiliation></author>
      <pages>470-486</pages>
      <abstract>This paper proposes a new task of commonsense question generation, which aims to yield deep-level and to-the-point questions from the text. Their answers need to reason over disjoint relevant contexts and external commonsense knowledge, such as encyclopedic facts and causality. The knowledge may not be explicitly mentioned in the text but is used by most humans for problem-shooting. Such complex reasoning with hidden contexts involves deep semantic understanding. Thus, this task has great application value, such as making high-quality quizzes in advanced exams. Due to the lack of modeling complexity, existing methods may produce shallow questions that can be answered by simple word matching. To address these challenges, we propose a new QG model by simultaneously considering asking contents, expressive ways, and answering complexity. We first retrieve text-related commonsense context. Then we disentangle the key factors that control questions in terms of reasoning content and verbalized way. Independence priors and constraints are imposed to facilitate disentanglement. We further develop a discriminator to promote the deep results by considering their answering complexity. Through adversarial inference, we learn the latent factors from data. By sampling the expressive factor from the data distributions, diverse questions can be yielded. Evaluations of two typical data sets show the effectiveness of our approach.</abstract>
      <url hash="f0b6d023">2023.findings-acl.30</url>
      <bibkey>yu-etal-2023-generating-deep</bibkey>
      <doi>10.18653/v1/2023.findings-acl.30</doi>
    </paper>
    <paper id="31">
      <title><fixed-case>TADA</fixed-case>: Efficient Task-Agnostic Domain Adaptation for Transformers</title>
      <author><first>Chia-Chien</first><last>Hung</last><affiliation>University of Mannheim</affiliation></author>
      <author><first>Lukas</first><last>Lange</last><affiliation>Bosch Center for Artificial Intelligence</affiliation></author>
      <author><first>Jannik</first><last>Strötgen</last><affiliation>Bosch Center for Artificial Intelligence</affiliation></author>
      <pages>487-503</pages>
      <abstract>Intermediate training of pre-trained transformer-based language models on domain-specific data leads to substantial gains for downstream tasks. To increase efficiency and prevent catastrophic forgetting alleviated from full domain-adaptive pre-training, approaches such as adapters have been developed. However, these require additional parameters for each layer, and are criticized for their limited expressiveness. In this work, we introduce TADA, a novel task-agnostic domain adaptation method which is modular, parameter-efficient, and thus, data-efficient. Within TADA, we retrain the embeddings to learn domain-aware input representations and tokenizers for the transformer encoder, while freezing all other parameters of the model. Then, task-specific fine-tuning is performed. We further conduct experiments with meta-embeddings and newly introduced meta-tokenizers, resulting in one model per task in multi-domain use cases. Our broad evaluation in 4 downstream tasks for 14 domains across single- and multi-domain setups and high- and low-resource scenarios reveals that TADA is an effective and efficient alternative to full domain-adaptive pre-training and adapters for domain adaptation, while not introducing additional parameters or complex training steps.</abstract>
      <url hash="c9206f06">2023.findings-acl.31</url>
      <bibkey>hung-etal-2023-tada</bibkey>
      <doi>10.18653/v1/2023.findings-acl.31</doi>
    </paper>
    <paper id="32">
      <title>Robust Natural Language Understanding with Residual Attention Debiasing</title>
      <author><first>Fei</first><last>Wang</last><affiliation>University of Southern California</affiliation></author>
      <author><first>James Y.</first><last>Huang</last><affiliation>University of Southern California</affiliation></author>
      <author><first>Tianyi</first><last>Yan</last><affiliation>University of Southern California</affiliation></author>
      <author><first>Wenxuan</first><last>Zhou</last><affiliation>University of Southern California</affiliation></author>
      <author><first>Muhao</first><last>Chen</last><affiliation>USC</affiliation></author>
      <pages>504-519</pages>
      <abstract>Natural language understanding (NLU) models often suffer from unintended dataset biases. Among bias mitigation methods, ensemble-based debiasing methods, especially product-of-experts (PoE), have stood out for their impressive empirical success. However, previous ensemble-based debiasing methods typically apply debiasing on top-level logits without directly addressing biased attention patterns. Attention serves as the main media of feature interaction and aggregation in PLMs and plays a crucial role in providing robust prediction. In this paper, we propose REsidual Attention Debiasing (READ), an end-to-end debiasing method that mitigates unintended biases from attention. Experiments on three NLU benchmarks show that READ significantly improves the OOD performance of BERT-based models, including +12.9% accuracy on HANS, +11.0% accuracy on FEVER-Symmetric, and +2.7% F1 on PAWS. Detailed analyses demonstrate the crucial role of unbiased attention in robust NLU models and that READ effectively mitigates biases in attention.</abstract>
      <url hash="1c619b87">2023.findings-acl.32</url>
      <bibkey>wang-etal-2023-robust</bibkey>
      <doi>10.18653/v1/2023.findings-acl.32</doi>
    </paper>
    <paper id="33">
      <title><fixed-case>M</fixed-case>o<fixed-case>NET</fixed-case>: Tackle State Momentum via Noise-Enhanced Training for Dialogue State Tracking</title>
      <author><first>Haoning</first><last>Zhang</last><affiliation>The Chinese University of Hong Kong, Shenzhen</affiliation></author>
      <author><first>Junwei</first><last>Bao</last><affiliation>JD AI Research</affiliation></author>
      <author><first>Haipeng</first><last>Sun</last><affiliation>JD</affiliation></author>
      <author><first>Youzheng</first><last>Wu</last><affiliation>JD AI Research</affiliation></author>
      <author><first>Wenye</first><last>Li</last><affiliation>The Chinese University of Hong Kong, Shenzhen</affiliation></author>
      <author><first>Shuguang</first><last>Cui</last><affiliation>The Chinese University of Hong Kong, Shenzhen</affiliation></author>
      <author><first>Xiaodong</first><last>He</last><affiliation>JD AI Research</affiliation></author>
      <pages>520-534</pages>
      <abstract>Dialogue state tracking (DST) aims to convert the dialogue history into dialogue states which consist of slot-value pairs. As condensed structural information memorizes all history information, the dialogue state in the previous turn is typically adopted as the input for predicting the current state by DST models. However, these models tend to keep the predicted slot values unchanged, which is defined as state momentum in this paper. Specifically, the models struggle to update slot values that need to be changed and correct wrongly predicted slot values in the previous turn. To this end, we propose MoNET to tackle state momentum via noise-enhanced training. First, the previous state of each turn in the training data is noised via replacing some of its slot values. Then, the noised previous state is used as the input to learn to predict the current state, improving the model’s ability to update and correct slot values. Furthermore, a contrastive contextmatching framework is designed to narrow the representation distance between a state and itscorresponding noised variant, which reduces the impact of noised state and makes the model better understand the dialogue history. Experimental results on MultiWOZ datasets show that MoNET outperforms previous DST methods. Ablations and analysis verify the effectiveness of MoNET in alleviating state momentum issues and improving the anti-noise ability.</abstract>
      <url hash="8f5fcec4">2023.findings-acl.33</url>
      <bibkey>zhang-etal-2023-monet</bibkey>
      <doi>10.18653/v1/2023.findings-acl.33</doi>
    </paper>
    <paper id="34">
      <title><fixed-case>PAL</fixed-case>: Persona-Augmented Emotional Support Conversation Generation</title>
      <author><first>Jiale</first><last>Cheng</last><affiliation>Tsinghua University</affiliation></author>
      <author><first>Sahand</first><last>Sabour</last><affiliation>Tsinghua University</affiliation></author>
      <author><first>Hao</first><last>Sun</last><affiliation>Tsinghua University</affiliation></author>
      <author><first>Zhuang</first><last>Chen</last><affiliation>Department of Computer Science and Technology, Tsinghua University, China</affiliation></author>
      <author><first>Minlie</first><last>Huang</last><affiliation>Tsinghua University</affiliation></author>
      <pages>535-554</pages>
      <abstract>Due to the lack of human resources for mental health support, there is an increasing demand for employing conversational agents for support. Recent work has demonstrated the effectiveness of dialogue models in providing emotional support. As previous studies have demonstrated that seekers’ persona is an important factor for effective support, we investigate whether there are benefits to modeling such information in dialogue models for support. In this paper, our empirical analysis verifies that persona has an important impact on emotional support. Therefore, we propose a framework for dynamically inferring and modeling seekers’ persona. We first train a model for inferring the seeker’s persona from the conversation history. Accordingly, we propose PAL, a model that leverages persona information and, in conjunction with our strategy-based controllable generation method, provides personalized emotional support. Automatic and manual evaluations demonstrate that PAL achieves state-of-the-art results, outperforming the baselines on the studied benchmark. Our code and data are publicly available at <url>https://github.com/chengjl19/PAL</url>.</abstract>
      <url hash="5c75b407">2023.findings-acl.34</url>
      <bibkey>cheng-etal-2023-pal</bibkey>
      <doi>10.18653/v1/2023.findings-acl.34</doi>
    </paper>
    <paper id="35">
      <title>Farewell to Aimless Large-scale Pretraining: Influential Subset Selection for Language Model</title>
      <author><first>Xiao</first><last>Wang</last><affiliation>Fudan University</affiliation></author>
      <author><first>Weikang</first><last>Zhou</last><affiliation>Fudan University</affiliation></author>
      <author><first>Qi</first><last>Zhang</last><affiliation>Fudan University</affiliation></author>
      <author><first>Jie</first><last>Zhou</last><affiliation>Fudan University</affiliation></author>
      <author><first>SongYang</first><last>Gao</last><affiliation>Fudan University</affiliation></author>
      <author><first>Junzhe</first><last>Wang</last><affiliation>Fudan University</affiliation></author>
      <author><first>Menghan</first><last>Zhang</last><affiliation>Institute of Modern Languages and Linguistics, Fudan University</affiliation></author>
      <author><first>Xiang</first><last>Gao</last><affiliation>DataGrand Inc.</affiliation></author>
      <author><first>Yun Wen</first><last>Chen</last><affiliation>DataGrand Inc.</affiliation></author>
      <author><first>Tao</first><last>Gui</last><affiliation>fudan university</affiliation></author>
      <pages>555-568</pages>
      <abstract>Pretrained language models have achieved remarkable success in various natural language processing tasks. However, pretraining has recently shifted toward larger models and larger data, which has resulted in significant computational and energy costs. In this paper, we propose Influence Subset Selection (ISS) for language model, which explicitly utilizes end-task knowledge to select a tiny subset of the pretraining corpus. Specifically, the ISS selects the samples that will provide the most positive influence on the performance of the end task. Furthermore, we design a gradient matching-based influence estimation method, which can drastically reduce the computation time of influence. With only 0.45% of the data and a three-orders-of-magnitude lower computational cost, ISS outperformed pretrained models (e.g., RoBERTa) on eight datasets covering four domains.</abstract>
      <url hash="c4b84a19">2023.findings-acl.35</url>
      <bibkey>wang-etal-2023-farewell</bibkey>
      <doi>10.18653/v1/2023.findings-acl.35</doi>
    </paper>
    <paper id="36">
      <title>Exclusive Supermask Subnetwork Training for Continual Learning</title>
      <author><first>Prateek</first><last>Yadav</last><affiliation>University of North Carolina - Chapel Hill</affiliation></author>
      <author><first>Mohit</first><last>Bansal</last><affiliation>University of North Carolina at Chapel Hill</affiliation></author>
      <pages>569-587</pages>
      <abstract>Continual Learning (CL) methods focus on accumulating knowledge over time while avoiding catastrophic forgetting. Recently, Wortsman et al. (2020) proposed a CL method, SupSup, which uses a randomly initialized, fixed base network (model) and finds a supermask for each new task that selectively keeps or removes each weight to produce a subnetwork. They prevent forgetting as the network weights are not being updated. Although there is no forgetting, the performance of SupSup is sub-optimal because fixed weights restrict its representational power. Furthermore, there is no accumulation or transfer of knowledge inside the model when new tasks are learned. Hence, we propose ExSSNeT (Exclusive Supermask SubNetwork Training), that performs exclusive and non-overlapping subnetwork weight training. This avoids conflicting updates to the shared weights by subsequent tasks to improve performance while still preventing forgetting. Furthermore, we propose a novel KNN-based Knowledge Transfer (KKT) module that utilizes previously acquired knowledge to learn new tasks better and faster. We demonstrate that ExSSNeT outperforms strong previous methods on both NLP and Vision domains while preventing forgetting. Moreover, ExSSNeT is particularly advantageous for sparse masks that activate 2-10% of the model parameters, resulting in an average improvement of 8.3% over SupSup. Furthermore, ExSSNeT scales to a large number of tasks (100).</abstract>
      <url hash="38b40912">2023.findings-acl.36</url>
      <bibkey>yadav-bansal-2023-exclusive</bibkey>
      <doi>10.18653/v1/2023.findings-acl.36</doi>
    </paper>
    <paper id="37">
      <title>Transferring General Multimodal Pretrained Models to Text Recognition</title>
      <author><first>Junyang</first><last>Lin</last><affiliation>Alibaba Group</affiliation></author>
      <author><first>Xuancheng</first><last>Ren</last><affiliation>DAMO Academy, Alibaba Group</affiliation></author>
      <author><first>Yichang</first><last>Zhang</last><affiliation>Alibaba group</affiliation></author>
      <author><first>Gao</first><last>Liu</last><affiliation>Alibaba</affiliation></author>
      <author><first>Peng</first><last>Wang</last><affiliation>Alibaba Group</affiliation></author>
      <author><first>An</first><last>Yang</last><affiliation>Alibaba Group</affiliation></author>
      <author><first>Chang</first><last>Zhou</last><affiliation>Alibaba Group</affiliation></author>
      <pages>588-597</pages>
      <abstract>This paper proposes a new method, OFA-OCR, to transfer multimodal pretrained models to text recognition. Specifically, we recast text recognition as image captioning and directly transfer a unified vision-language pretrained model to the end task. Without pretraining on large-scale annotated or synthetic text recognition data, OFA-OCR outperforms the baselines and achieves state-of-the-art performance in the Chinese text recognition benchmark. Additionally, we construct an OCR pipeline with OFA-OCR, and we demonstrate that it can achieve competitive performance with the product-level API.</abstract>
      <url hash="f06f3a49">2023.findings-acl.37</url>
      <bibkey>lin-etal-2023-transferring</bibkey>
      <doi>10.18653/v1/2023.findings-acl.37</doi>
    </paper>
    <paper id="38">
      <title>A Formal Perspective on Byte-Pair Encoding</title>
      <author><first>Vilém</first><last>Zouhar</last><affiliation>ETH Zurich, Charles University</affiliation></author>
      <author><first>Clara</first><last>Meister</last><affiliation>ETH Zurich</affiliation></author>
      <author><first>Juan</first><last>Gastaldi</last><affiliation>ETH Zurich</affiliation></author>
      <author><first>Li</first><last>Du</last><affiliation>Johns Hopkins University</affiliation></author>
      <author><first>Tim</first><last>Vieira</last><affiliation>Johns Hopkins University</affiliation></author>
      <author><first>Mrinmaya</first><last>Sachan</last><affiliation>ETH Zurich</affiliation></author>
      <author><first>Ryan</first><last>Cotterell</last><affiliation>ETH Zürich</affiliation></author>
      <pages>598-614</pages>
      <abstract>Byte-Pair Encoding (BPE) is a popular algorithm used for tokenizing data in NLP, despite being devised initially as a compression method.BPE appears to be a greedy algorithm at face value, but the underlying optimization problem that BPE seeks to solve has not yet been laid down. We formalize BPE as a combinatorial optimization problem. Via submodular functions, we prove that the iterative greedy version is a 1/sigma*(1-e(-sigma))-approximation of an optimal merge sequence, where sigma is the total backward curvature with respect to the optimal merge sequence. Empirically the lower bound of the approximation is approx0.37.We provide a faster implementation of BPE which improves the runtime complexity from O(NM) to O(N log M), where N is the sequence length and M is the merge count. Finally, we optimize the brute-force algorithm for optimal BPE using memoization.</abstract>
      <url hash="40ed62e8">2023.findings-acl.38</url>
      <bibkey>zouhar-etal-2023-formal</bibkey>
      <doi>10.18653/v1/2023.findings-acl.38</doi>
    </paper>
    <paper id="39">
      <title>Automatic Named Entity Obfuscation in Speech</title>
      <author><first>Judita</first><last>Preiss</last><affiliation>University of Sheffield</affiliation></author>
      <pages>615-622</pages>
      <abstract>Sharing data containing personal information often requires its anonymization, even when consent for sharing was obtained from the data originator. While approaches exist for automated anonymization of text, the area is not as thoroughly explored in speech. This work focuses on identifying, replacing and inserting replacement named entities synthesized using voice cloning into original audio thereby retaining prosodic information while reducing the likelihood of deanonymization. The approach employs a novel named entity recognition (NER) system built directly on speech by training HuBERT (Hsu et al, 2021) using the English speech NER dataset (Yadav et al, 2020). Name substitutes are found using a masked language model and are synthesized using text to speech voice cloning (Eren and team, 2021), upon which the substitute named entities are re-inserted into the original text. The approach is prototyped on a sample of the LibriSpeech corpus (Panyatov et al, 2015) with each step evaluated individually.</abstract>
      <url hash="0cf95584">2023.findings-acl.39</url>
      <bibkey>preiss-2023-automatic</bibkey>
      <doi>10.18653/v1/2023.findings-acl.39</doi>
    </paper>
    <paper id="40">
      <title>Recursion of Thought: A Divide-and-Conquer Approach to Multi-Context Reasoning with Language Models</title>
      <author><first>Soochan</first><last>Lee</last><affiliation>Seoul National University</affiliation></author>
      <author><first>Gunhee</first><last>Kim</last><affiliation>Seoul National University</affiliation></author>
      <pages>623-658</pages>
      <abstract>Generating intermediate steps, or Chain of Thought (CoT), is an effective way to significantly improve language models’ (LM) multi-step reasoning capability. However, the CoT lengths can grow rapidly with the problem complexity, easily exceeding the maximum context size. Instead of increasing the context limit, which has already been heavily investigated, we explore an orthogonal direction: making LMs divide a problem into multiple contexts. We propose a new inference framework, called Recursion of Thought (RoT), which introduces several special tokens that the models can output to trigger context-related operations. Extensive experiments with multiple architectures including GPT-3 show that RoT dramatically improves LMs’ inference capability to solve problems, whose solution consists of hundreds of thousands of tokens.</abstract>
      <url hash="17da3114">2023.findings-acl.40</url>
      <bibkey>lee-kim-2023-recursion</bibkey>
      <doi>10.18653/v1/2023.findings-acl.40</doi>
    </paper>
    <paper id="41">
      <title><fixed-case>U</fixed-case>ni<fixed-case>S</fixed-case>-<fixed-case>MMC</fixed-case>: Multimodal Classification via Unimodality-supervised Multimodal Contrastive Learning</title>
      <author><first>Heqing</first><last>Zou</last><affiliation>Nanyang Technological University</affiliation></author>
      <author><first>Meng</first><last>Shen</last><affiliation>Nanyang Technological University</affiliation></author>
      <author><first>Chen</first><last>Chen</last><affiliation>Nanyang Technological University</affiliation></author>
      <author><first>Yuchen</first><last>Hu</last><affiliation>Nanyang Technological University</affiliation></author>
      <author><first>Deepu</first><last>Rajan</last><affiliation>Nanyang Technological University</affiliation></author>
      <author><first>Eng Siong</first><last>Chng</last><affiliation>Nanyang Technological University</affiliation></author>
      <pages>659-672</pages>
      <abstract>Multimodal learning aims to imitate human beings to acquire complementary information from multiple modalities for various downstream tasks. However, traditional aggregation-based multimodal fusion methods ignore the inter-modality relationship, treat each modality equally, suffer sensor noise, and thus reduce multimodal learning performance. In this work, we propose a novel multimodal contrastive method to explore more reliable multimodal representations under the weak supervision of unimodal predicting. Specifically, we first capture task-related unimodal representations and the unimodal predictions from the introduced unimodal predicting task. Then the unimodal representations are aligned with the more effective one by the designed multimodal contrastive method under the supervision of the unimodal predictions. Experimental results with fused features on two image-text classification benchmarks UPMC-Food-101 and N24News show that our proposed Unimodality-Supervised MultiModal Contrastive UniS-MMC learning method outperforms current state-of-the-art multimodal methods. The detailed ablation study and analysis further demonstrate the advantage of our proposed method.</abstract>
      <url hash="bde42e4e">2023.findings-acl.41</url>
      <bibkey>zou-etal-2023-unis</bibkey>
      <doi>10.18653/v1/2023.findings-acl.41</doi>
    </paper>
    <paper id="42">
      <title>Robustness-Aware Word Embedding Improves Certified Robustness to Adversarial Word Substitutions</title>
      <author><first>Yibin</first><last>Wang</last><affiliation>Huazhong University of Science and Technology</affiliation></author>
      <author><first>Yichen</first><last>Yang</last><affiliation>Huazhong University of Science and Technology</affiliation></author>
      <author><first>Di</first><last>He</last><affiliation>Peking University</affiliation></author>
      <author><first>Kun</first><last>He</last><affiliation>Huazhong University of Science and Technology</affiliation></author>
      <pages>673-687</pages>
      <abstract>Natural Language Processing (NLP) models have gained great success on clean texts, but they are known to be vulnerable to adversarial examples typically crafted by synonym substitutions. In this paper, we target to solve this problem and find that word embedding is important to the certified robustness of NLP models. Given the findings, we propose the Embedding Interval Bound Constraint (EIBC) triplet loss to train robustness-aware word embeddings for better certified robustness. We optimize the EIBC triplet loss to reduce distances between synonyms in the embedding space, which is theoretically proven to make the verification boundary tighter. Meanwhile, we enlarge distances among non-synonyms, maintaining the semantic representation of word embeddings. Our method is conceptually simple and componentized. It can be easily combined with IBP training and improves the certified robust accuracy from 76.73% to 84.78% on the IMDB dataset. Experiments demonstrate that our method outperforms various state-of-the-art certified defense baselines and generalizes well to unseen substitutions. The code is available at <url>https://github.com/JHL-HUST/EIBC-IBP/</url>.</abstract>
      <url hash="e6b7f08c">2023.findings-acl.42</url>
      <bibkey>wang-etal-2023-robustness</bibkey>
      <doi>10.18653/v1/2023.findings-acl.42</doi>
    </paper>
    <paper id="43">
      <title>Exploring the Compositional Generalization in Context Dependent Text-to-<fixed-case>SQL</fixed-case> Parsing</title>
      <author><first>Aiwei</first><last>Liu</last><affiliation>School of Software, Tsinghua University</affiliation></author>
      <author><first>Wei</first><last>Liu</last><affiliation>School of Software, Tsinghua University</affiliation></author>
      <author><first>Xuming</first><last>Hu</last><affiliation>School of Software, Tsinghua University</affiliation></author>
      <author><first>Shuang</first><last>Li</last><affiliation>School of Software, Tsinghua University</affiliation></author>
      <author><first>Fukun</first><last>Ma</last><affiliation>School of Software,Tsinghua University</affiliation></author>
      <author><first>Yawen</first><last>Yang</last><affiliation>School of Software, Tsinghua University</affiliation></author>
      <author><first>Lijie</first><last>Wen</last><affiliation>School of Software, Tsinghua University</affiliation></author>
      <pages>688-700</pages>
      <abstract>In the context-dependent Text-to-SQL task, the generated SQL statements are refined iteratively based on the user input utterance from each interaction. The input text from each interaction can be viewed as component modifications to the previous SQL statements, which could be further extracted as the modification patterns. Since these modification patterns could also be combined with other SQL statements, the models are supposed to have the compositional generalization to these novel combinations. This work is the first exploration of compositional generalization in context-dependent Text-to-SQL scenarios. To facilitate related studies, we constructed two challenging benchmarks named CoSQL-CG and SParC-CG by recombining the modification patterns and existing SQL statements. The following experiments show that almost all current models struggle on our proposed benchmarks. Furthermore, we found that better aligning the previous SQL statements with the input utterance could give models better combinatorial generalization ability. Based on these observations, we propose a method name p-align to improve the combinatorial generalization of Text-to-SQL models. Further experiments validate the effectiveness of our model.</abstract>
      <url hash="53894db2">2023.findings-acl.43</url>
      <bibkey>liu-etal-2023-exploring</bibkey>
      <doi>10.18653/v1/2023.findings-acl.43</doi>
    </paper>
    <paper id="44">
      <title>Towards Generative Event Factuality Prediction</title>
      <author><first>John</first><last>Murzaku</last><affiliation>Stony Brook University</affiliation></author>
      <author><first>Tyler</first><last>Osborne</last><affiliation>Boston College</affiliation></author>
      <author><first>Amittai</first><last>Aviram</last><affiliation>Boston College</affiliation></author>
      <author><first>Owen</first><last>Rambow</last><affiliation>Stony Brook University</affiliation></author>
      <pages>701-715</pages>
      <abstract>We present a novel end-to-end generative task and system for predicting event factuality holders, targets, and their associated factuality values. We perform the first experiments using all sources and targets of factuality statements from the FactBank corpus. We perform multi-task learning with other tasks and event-factuality corpora to improve on the FactBank source and target task. We argue that careful domain specific target text output format in generative systems is important and verify this with multiple experiments on target text output structure. We redo previous state-of-the-art author-only event factuality experiments and also offer insights towards a generative paradigm for the author-only event factuality prediction task.</abstract>
      <url hash="28b07017">2023.findings-acl.44</url>
      <bibkey>murzaku-etal-2023-towards</bibkey>
      <doi>10.18653/v1/2023.findings-acl.44</doi>
    </paper>
    <paper id="45">
      <title>Can Language Models Be Specific? How?</title>
      <author><first>Jie</first><last>Huang</last><affiliation>University of Illinois at Urbana-Champaign</affiliation></author>
      <author><first>Kevin Chen-Chuan</first><last>Chang</last><affiliation>University of Illinois at Urbana-Champaign</affiliation></author>
      <author><first>Jinjun</first><last>Xiong</last><affiliation>University at Buffalo</affiliation></author>
      <author><first>Wen-mei</first><last>Hwu</last><affiliation>University of Illinois at Urbana-Champaign</affiliation></author>
      <pages>716-727</pages>
      <abstract>“He is a person”, “Paris is located on the earth”. Both statements are correct but meaningless - due to lack of specificity. In this paper, we propose to measure how specific the language of pre-trained language models (PLMs) is. To achieve this, we introduce a novel approach to build a benchmark for specificity testing by forming masked token prediction tasks with prompts. For instance, given “Toronto is located in [MASK].”, we want to test whether a more specific answer will be better filled in by PLMs, e.g., Ontario instead of Canada. From our evaluations, we show that existing PLMs have only a slight preference for more specific answers. We identify underlying factors affecting the specificity and design two prompt-based methods to improve the specificity. Results show that the specificity of the models can be improved by the proposed methods without additional training. We hope this work can bring to awareness the notion of specificity of language models and encourage the research community to further explore this important but understudied problem.</abstract>
      <url hash="f3609448">2023.findings-acl.45</url>
      <bibkey>huang-etal-2023-language</bibkey>
      <doi>10.18653/v1/2023.findings-acl.45</doi>
    </paper>
    <paper id="46">
      <title>The Web Can Be Your Oyster for Improving Language Models</title>
      <author><first>Junyi</first><last>Li</last><affiliation>Gaoling School of Artificial Intelligence, Renmin University of China</affiliation></author>
      <author><first>Tianyi</first><last>Tang</last><affiliation>Renmin University of China</affiliation></author>
      <author><first>Wayne Xin</first><last>Zhao</last><affiliation>RUC</affiliation></author>
      <author><first>Jingyuan</first><last>Wang</last><affiliation>Beihang University</affiliation></author>
      <author><first>Jian-Yun</first><last>Nie</last><affiliation>University of Montreal</affiliation></author>
      <author><first>Ji-Rong</first><last>Wen</last><affiliation>Renmin University of China</affiliation></author>
      <pages>728-746</pages>
      <abstract>Pretrained language models (PLMs) encode a large amount of world knowledge. However, as such knowledge is frozen at the time of model training, the models become static and limited by the training data at that time. In order to further improve the capacity of PLMs for knowledge-intensive tasks, we consider augmenting PLMs with the large-scale web using search engine. Unlike previous augmentation sources (e.g., Wikipedia data dump), the web provides broader, more comprehensive and constantly updated information. In this paper, we present a web-augmented PLM – UniWeb, which is trained over 16 knowledge-intensive tasks in a unified text-to-text format. Instead of simply using the retrieved contents from web, our approach has made two major improvements. Firstly, we propose an adaptive search engine assisted learning method that can self-evaluate the confidence level of PLM’s predictions, and adaptively determine when to refer to the web for more data, which can avoid useless or noisy augmentation from web. Secondly, we design a pretraining task, i.e., continual knowledge learning, based on salient spans prediction, to reduce the discrepancy between the encoded and retrieved knowledge. Experiments on a wide range of knowledge-intensive tasks show that our model significantly outperforms previous retrieval-augmented methods.</abstract>
      <url hash="f88dcc9d">2023.findings-acl.46</url>
      <bibkey>li-etal-2023-web</bibkey>
      <doi>10.18653/v1/2023.findings-acl.46</doi>
    </paper>
    <paper id="47">
      <title>Enhancing Few-shot Cross-lingual Transfer with Target Language Peculiar Examples</title>
      <author><first>Hwichan</first><last>Kim</last><affiliation>Tokyo Metropolitan University</affiliation></author>
      <author><first>Mamoru</first><last>Komachi</last><affiliation>Hitotsubashi University</affiliation></author>
      <pages>747-767</pages>
      <abstract>Few-shot cross-lingual transfer, fine-tuning Multilingual Masked Language Model (MMLM) with source language labeled data and a small amount of target language labeled data, provides excellent performance in the target language. However, if no labeled data in the target language are available, they need to be created through human annotations. In this study, we devise a metric to select annotation candidates from an unlabeled data pool that efficiently enhance accuracy for few-shot cross-lingual transfer. It is known that training a model with hard examples is important to improve the model’s performance. Therefore, we first identify examples that MMLM cannot solve in a zero-shot cross-lingual transfer setting and demonstrate that it is hard to predict peculiar examples in the target language, i.e., the examples distant from the source language examples in cross-lingual semantic space of the MMLM.We then choose high peculiarity examples as annotation candidates and perform few-shot cross-lingual transfer. In comprehensive experiments with 20 languages and 6 tasks, we demonstrate that the high peculiarity examples improve the target language accuracy compared to other candidate selection methods proposed in previous studies.</abstract>
      <url hash="77765b6b">2023.findings-acl.47</url>
      <bibkey>kim-komachi-2023-enhancing</bibkey>
      <doi>10.18653/v1/2023.findings-acl.47</doi>
    </paper>
    <paper id="48">
      <title>Overcoming Catastrophic Forgetting in Massively Multilingual Continual Learning</title>
      <author><first>Genta</first><last>Winata</last><affiliation>Bloomberg</affiliation></author>
      <author><first>Lingjue</first><last>Xie</last><affiliation>Bloomberg</affiliation></author>
      <author><first>Karthik</first><last>Radhakrishnan</last><affiliation>Bloomberg LP</affiliation></author>
      <author><first>Shijie</first><last>Wu</last><affiliation>Bloomberg L.P.</affiliation></author>
      <author><first>Xisen</first><last>Jin</last><affiliation>University of Southern California</affiliation></author>
      <author><first>Pengxiang</first><last>Cheng</last><affiliation>Bloomberg LP</affiliation></author>
      <author><first>Mayank</first><last>Kulkarni</last><affiliation>Amazon</affiliation></author>
      <author><first>Daniel</first><last>Preotiuc-Pietro</last><affiliation>Bloomberg</affiliation></author>
      <pages>768-777</pages>
      <abstract>Real-life multilingual systems should be able to efficiently incorporate new languages as data distributions fed to the system evolve and shift over time. To do this, systems need to handle the issue of catastrophic forgetting, where the model performance drops for languages or tasks seen further in its past. In this paper, we study catastrophic forgetting, as well as methods to minimize this, in a massively multilingual continual learning framework involving up to 51 languages and covering both classification and sequence labeling tasks. We present LR ADJUST, a learning rate scheduling method that is simple, yet effective in preserving new information without strongly overwriting past knowledge. Furthermore, we show that this method is effective across multiple continual learning approaches. Finally, we provide further insights into the dynamics of catastrophic forgetting in this massively multilingual setup.</abstract>
      <url hash="09d803b0">2023.findings-acl.48</url>
      <bibkey>winata-etal-2023-overcoming</bibkey>
      <doi>10.18653/v1/2023.findings-acl.48</doi>
    </paper>
    <paper id="49">
      <title><fixed-case>U</fixed-case>ni<fixed-case>F</fixed-case>ine: A Unified and Fine-grained Approach for Zero-shot Vision-Language Understanding</title>
      <author><first>Rui</first><last>Sun</last><affiliation>Columbia University</affiliation></author>
      <author><first>Zhecan</first><last>Wang</last><affiliation>columbia university</affiliation></author>
      <author><first>Haoxuan</first><last>You</last><affiliation>Columbia University</affiliation></author>
      <author><first>Noel</first><last>Codella</last><affiliation>Microsoft</affiliation></author>
      <author><first>Kai-Wei</first><last>Chang</last><affiliation>UCLA</affiliation></author>
      <author><first>Shih-Fu</first><last>Chang</last><affiliation>Columbia University</affiliation></author>
      <pages>778-793</pages>
      <abstract>Vision-language tasks, such as VQA, SNLI-VE, and VCR are challenging because they require the model’s reasoning ability to understand the semantics of the visual world and natural language. Supervised methods working for vision-language tasks have been well-studied. However, solving these tasks in a zero-shot setting is less explored. Since Contrastive Language-Image Pre-training (CLIP) has shown remarkable zero-shot performance on image-text matching, previous works utilized its strong zero-shot ability by converting vision-language tasks into an image-text matching problem, and they mainly consider global-level matching (e.g., the whole image or sentence). However, we find visual and textual fine-grained information, e.g., keywords in the sentence and objects in the image, can be fairly informative for semantics understanding. Inspired by this, we propose a unified framework to take advantage of the fine-grained information for zero-shot vision-language learning, covering multiple tasks such as VQA, SNLI-VE, and VCR. Our experiments show that our framework outperforms former zero-shot methods on VQA and achieves substantial improvement on SNLI-VE and VCR. Furthermore, our ablation studies confirm the effectiveness and generalizability of our proposed method.</abstract>
      <url hash="0431c4d6">2023.findings-acl.49</url>
      <bibkey>sun-etal-2023-unifine</bibkey>
      <doi>10.18653/v1/2023.findings-acl.49</doi>
    </paper>
    <paper id="50">
      <title>Aligning Instruction Tasks Unlocks Large Language Models as Zero-Shot Relation Extractors</title>
      <author><first>Kai</first><last>Zhang</last><affiliation>The Ohio State University</affiliation></author>
      <author><first>Bernal</first><last>Jimenez Gutierrez</last><affiliation>The Ohio State University</affiliation></author>
      <author><first>Yu</first><last>Su</last><affiliation>The Ohio State University</affiliation></author>
      <pages>794-812</pages>
      <abstract>Recent work has shown that fine-tuning large language models (LLMs) on large-scale instruction-following datasets substantially improves their performance on a wide range of NLP tasks, especially in the zero-shot setting. However, even advanced instruction-tuned LLMs still fail to outperform small LMs on relation extraction (RE), a fundamental information extraction task. We hypothesize that instruction-tuning has been unable to elicit strong RE capabilities in LLMs due to RE’s low incidence in instruction-tuning datasets, making up less than 1% of all tasks (Wang et al. 2022). To address this limitation, we propose QA4RE, a framework that aligns RE with question answering (QA), a predominant task in instruction-tuning datasets. Comprehensive zero-shot RE experiments over four datasets with two series of instruction-tuned LLMs (six LLMs in total) demonstrate that our QA4RE framework consistently improves LLM performance, strongly verifying our hypothesis and enabling LLMs to outperform strong zero-shot baselines by a large margin. Additionally, we provide thorough experiments and discussions to show the robustness, few-shot effectiveness, and strong transferability of our QA4RE framework. This work illustrates a promising way of adapting LLMs to challenging and underrepresented tasks by aligning these tasks with more common instruction-tuning tasks like QA.</abstract>
      <url hash="c704f80d">2023.findings-acl.50</url>
      <bibkey>zhang-etal-2023-aligning</bibkey>
      <doi>10.18653/v1/2023.findings-acl.50</doi>
    </paper>
    <paper id="51">
      <title><fixed-case>TADA</fixed-case> : Task Agnostic Dialect Adapters for <fixed-case>E</fixed-case>nglish</title>
      <author><first>William</first><last>Held</last><affiliation>Georgia Tech</affiliation></author>
      <author><first>Caleb</first><last>Ziems</last><affiliation>Georgia Institute of Technology</affiliation></author>
      <author><first>Diyi</first><last>Yang</last><affiliation>Stanford University</affiliation></author>
      <pages>813-824</pages>
      <abstract>Large Language Models, the dominant starting point for Natural Language Processing (NLP) applications, fail at a higher rate for speakers of English dialects other than Standard American English (SAE). Prior work addresses this using task specific data or synthetic data augmentation, both of which require intervention for each dialect and task pair. This poses a scalability issue that prevents the broad adoption of robust dialectal English NLP. We introduce a simple yet effective method for task-agnostic dialect adaptation by aligning non-SAE dialects using adapters and composing them with task-specific adapters from SAE. Task-Agnostic Dialect Adapters (TADA) improve dialectal robustness on 4 dialectal variants of the GLUE benchmark without task-specific supervision.</abstract>
      <url hash="b32d12e3">2023.findings-acl.51</url>
      <bibkey>held-etal-2023-tada</bibkey>
      <doi>10.18653/v1/2023.findings-acl.51</doi>
    </paper>
    <paper id="52">
      <title>Generative Zero-Shot Prompt Learning for Cross-Domain Slot Filling with Inverse Prompting</title>
      <author><first>Xuefeng</first><last>Li</last><affiliation>Beijing University of Posts and Telecommunications</affiliation></author>
      <author><first>Liwen</first><last>Wang</last><affiliation>Beijing University of Posts and Telecommunications</affiliation></author>
      <author><first>Guanting</first><last>Dong</last><affiliation>Beijing University of Posts and Telecommunications</affiliation></author>
      <author><first>Keqing</first><last>He</last><affiliation>Beijing University of Posts and Telecommunications</affiliation></author>
      <author><first>Jinzheng</first><last>Zhao</last><affiliation>University of Surrey</affiliation></author>
      <author><first>Hao</first><last>Lei</last><affiliation>Beijing University of Posts and Telecommunications</affiliation></author>
      <author><first>Jiachi</first><last>Liu</last><affiliation>Beijing University of Posts and Telecommunications</affiliation></author>
      <author><first>Weiran</first><last>Xu</last><affiliation>Beijing University of Posts and Telecommunications</affiliation></author>
      <pages>825-834</pages>
      <abstract>Zero-shot cross-domain slot filling aims to transfer knowledge from the labeled source domain to the unlabeled target domain. Existing models either encode slot descriptions and examples or design handcrafted question templates using heuristic rules, suffering from poor generalization capability or robustness. In this paper, we propose a generative zero-shot prompt learning framework for cross-domain slot filling, both improving generalization and robustness than previous work. Besides, we introduce a novel inverse prompting strategy to distinguish different slot types to avoid the multiple prediction problem, and an efficient prompt tuning strategy to boost higher performance only training fewer prompt parameters. Experiments and analysis demonstrate the effectiveness of our proposed framework, especially huge improvements (+13.44% F1) on the unseen slots.</abstract>
      <url hash="3ef4ace2">2023.findings-acl.52</url>
      <bibkey>li-etal-2023-generative</bibkey>
      <doi>10.18653/v1/2023.findings-acl.52</doi>
    </paper>
    <paper id="53">
      <title>Re-appraising the Schema Linking for Text-to-<fixed-case>SQL</fixed-case></title>
      <author><first>Yujian</first><last>Gan</last><affiliation>Queen Mary University of London</affiliation></author>
      <author><first>Xinyun</first><last>Chen</last><affiliation>Google LLC</affiliation></author>
      <author><first>Matthew</first><last>Purver</last><affiliation>Queen Mary University of London</affiliation></author>
      <pages>835-852</pages>
      <abstract>Most text-to-SQL models, even though based on the same grammar decoder, generate the SQL structure first and then fill in the SQL slots with the correct schema items. This second step depends on schema linking: aligning the entity references in the question with the schema columns or tables. This is generally approached via Exact Match based Schema Linking (EMSL) within a neural network-based schema linking module. EMSL has become standard in text-to-SQL: many state-of-the-art models employ EMSL, with performance dropping significantly when the EMSL component is removed. In this work, however, we show that EMSL reduces robustness, rendering models vulnerable to synonym substitution and typos. Instead of relying on EMSL to make up for deficiencies in question-schema encoding, we show that using a pre-trained language model as an encoder can improve performance without using EMSL, giving a more robust model. We also study the design choice of the schema linking module, finding that a suitable design benefits performance and interoperability. Finally, based on the above study of schema linking, we introduce the grammar linking to help model align grammar references in the question with the SQL keywords.</abstract>
      <url hash="7f0d9cbe">2023.findings-acl.53</url>
      <bibkey>gan-etal-2023-appraising</bibkey>
      <doi>10.18653/v1/2023.findings-acl.53</doi>
    </paper>
    <paper id="54">
      <title>Echoes from Alexandria: A Large Resource for Multilingual Book Summarization</title>
      <author><first>Alessandro</first><last>Scirè</last><affiliation>Babelscape and Sapienza University of Rome</affiliation></author>
      <author><first>Simone</first><last>Conia</last><affiliation>Sapienza University of Rome</affiliation></author>
      <author><first>Simone</first><last>Ciciliano</last><affiliation>Free University of Bozen, La Sapienza University of Rome</affiliation></author>
      <author><first>Roberto</first><last>Navigli</last><affiliation>Sapienza University of Rome</affiliation></author>
      <pages>853-867</pages>
      <abstract>In recent years, research in text summarization has mainly focused on the news domain, where texts are typically short and have strong layout features. The task of full-book summarization presents additional challenges which are hard to tackle with current resources, due to their limited size and availability in English only. To overcome these limitations, we present “Echoes from Alexandria”, or in shortened form, “Echoes”, a large resource for multilingual book summarization. Echoes featuresthree novel datasets: i) Echo-Wiki, for multilingual book summarization, ii) Echo-XSum, for extremely-compressive multilingual book summarization, and iii) Echo-FairySum, for extractive book summarization. To the best of our knowledge, Echoes – with its thousands of books and summaries – is the largest resource, and the first to be multilingual, featuring 5 languages and 25 language pairs. In addition to Echoes, we also introduce a new extractive-then-abstractive baseline, and, supported by our experimental results and manual analysis of the summaries generated, we argue that this baseline is more suitable for book summarization than purely-abstractive approaches. We release our resource and software at <url>https://github.com/Babelscape/echoes-from-alexandria</url> in the hope of fostering innovative research in multilingual booksummarization.</abstract>
      <url hash="1ce2c798">2023.findings-acl.54</url>
      <bibkey>scire-etal-2023-echoes</bibkey>
      <doi>10.18653/v1/2023.findings-acl.54</doi>
    </paper>
    <paper id="55">
      <title>When Gradient Descent Meets Derivative-Free Optimization: A Match Made in Black-Box Scenario</title>
      <author><first>Chengcheng</first><last>Han</last><affiliation>East China Normal University</affiliation></author>
      <author><first>Liqing</first><last>Cui</last><affiliation>East China Normal University</affiliation></author>
      <author><first>Renyu</first><last>Zhu</last><affiliation>East China Normal University</affiliation></author>
      <author><first>Jianing</first><last>Wang</last><affiliation>East China Normal University</affiliation></author>
      <author><first>Nuo</first><last>Chen</last><affiliation>East China Normal University</affiliation></author>
      <author><first>Qiushi</first><last>Sun</last><affiliation>National University of Singapore</affiliation></author>
      <author><first>Xiang</first><last>Li</last><affiliation>East China Normal University</affiliation></author>
      <author><first>Ming</first><last>Gao</last><affiliation>East China Normal University</affiliation></author>
      <pages>868-880</pages>
      <abstract>Large pre-trained language models (PLMs) have garnered significant attention for their versatility and potential for solving a wide spectrum of natural language processing (NLP) tasks. However, the cost of running these PLMs may be prohibitive. Furthermore, PLMs may not be open-sourced due to commercial considerations and potential risks of misuse, such as GPT-3. The parameters and gradients of PLMs are unavailable in this scenario. To solve the issue, black-box tuning has been proposed, which utilizes derivative-free optimization (DFO), instead of gradient descent, for training task-specific continuous prompts. However, these gradient-free methods still exhibit a significant gap compared to gradient-based methods. In this paper, we introduce gradient descent into black-box tuning scenario through knowledge distillation. Furthermore, we propose a novel method GDFO, which integrates gradient descent and derivative-free optimization to optimize task-specific continuous prompts in a harmonized manner. Experimental results show that GDFO can achieve significant performance gains over previous state-of-the-art methods.</abstract>
      <url hash="40017b15">2023.findings-acl.55</url>
      <bibkey>han-etal-2023-gradient</bibkey>
      <doi>10.18653/v1/2023.findings-acl.55</doi>
    </paper>
    <paper id="56">
      <title>Align-then-Enhance: Multilingual Entailment Graph Enhancement with Soft Predicate Alignment</title>
      <author><first>Yuting</first><last>Wu</last><affiliation>Beijing Jiaotong University</affiliation></author>
      <author><first>Yutong</first><last>Hu</last><affiliation>Peking University</affiliation></author>
      <author><first>Yansong</first><last>Feng</last><affiliation>Peking University</affiliation></author>
      <author><first>Tianyi</first><last>Li</last><affiliation>University of Edinburgh</affiliation></author>
      <author><first>Mark</first><last>Steedman</last><affiliation>University of Edinburgh</affiliation></author>
      <author><first>Dongyan</first><last>Zhao</last><affiliation>pku.edu.cn</affiliation></author>
      <pages>881-894</pages>
      <abstract>Entailment graphs (EGs) with predicates as nodes and entailment relations as edges are typically incomplete, while EGs in different languages are often complementary to each other. In this paper, we propose a new task, multilingual entailment graph enhancement, which aims to utilize the entailment information from one EG to enhance another EG in a different language. The ultimate goal is to obtain an enhanced EG containing richer and more accurate entailment information. We present an align-then-enhance framework (ATE) to achieve accurate multilingual entailment graph enhancement, which first exploits a cross-graph guided interaction mechanism to automatically discover potential equivalent predicates between different EGs and then constructs more accurate enhanced entailment graphs based on soft predicate alignments. Extensive experiments show that ATE achieves better and more robust predicate alignment results between different EGs, and the enhanced entailment graphs generated by ATE outperform the original graphs for entailment detection.</abstract>
      <url hash="baf328e6">2023.findings-acl.56</url>
      <bibkey>wu-etal-2023-align</bibkey>
      <doi>10.18653/v1/2023.findings-acl.56</doi>
    </paper>
    <paper id="57">
      <title>Few-shot Classification with Hypersphere Modeling of Prototypes</title>
      <author><first>Ning</first><last>Ding</last><affiliation>Tsinghua University</affiliation></author>
      <author><first>Yulin</first><last>Chen</last><affiliation>Tsinghua University</affiliation></author>
      <author><first>Ganqu</first><last>Cui</last><affiliation>Tsinghua University</affiliation></author>
      <author><first>Xiaobin</first><last>Wang</last><affiliation>Alibaba Group</affiliation></author>
      <author><first>Haitao</first><last>Zheng</last><affiliation>Tsinghua Shenzhen International School, Tsinghua University.</affiliation></author>
      <author><first>Zhiyuan</first><last>Liu</last><affiliation>Tsinghua University</affiliation></author>
      <author><first>Pengjun</first><last>Xie</last><affiliation>Alibaba Group</affiliation></author>
      <pages>895-917</pages>
      <abstract>Metric-based meta-learning is one of the de facto standards in few-shot learning. It composes of representation learning and metrics calculation designs. Previous works construct class representations in different ways, varying from mean output embedding to covariance and distributions. However, using embeddings in space lacks expressivity and cannot capture class information robustly, while statistical complex modeling poses difficulty to metric designs. In this work, we use tensor fields (“areas”) to model classes from the geometrical perspective for few-shot learning. We present a simple and effective method, dubbed as hypersphere prototypes (HyperProto), where class information is represented by hyperspheres with dynamic sizes with two sets of learnable parameters: the hypersphere’s center and the radius. Extending from points to areas, hyperspheres are much more expressive than embeddings. Moreover, it is more convenient to perform metric-based classification with hypersphere prototypes than statistical modeling, as we only need to calculate the distance from a data point to the surface of the hypersphere. Following this idea, we also develop two variants of prototypes under other measurements. Extensive experiments and analysis on few-shot NLP tasks and comparison with 20+ competitive baselines demonstrate the effectiveness of our approach.</abstract>
      <url hash="322d3396">2023.findings-acl.57</url>
      <bibkey>ding-etal-2023-shot</bibkey>
      <doi>10.18653/v1/2023.findings-acl.57</doi>
    </paper>
    <paper id="58">
      <title>Structured Mean-Field Variational Inference for Higher-Order Span-Based Semantic Role Labeling</title>
      <author><first>Wei</first><last>Liu</last><affiliation>ShanghaiTech University</affiliation></author>
      <author><first>Songlin</first><last>Yang</last><affiliation>ShanghaiTech University</affiliation></author>
      <author><first>Kewei</first><last>Tu</last><affiliation>ShanghaiTech University</affiliation></author>
      <pages>918-931</pages>
      <abstract>In this work, we enhance higher-order graph-based approaches for span-based semantic role labeling (SRL) by means of structured modeling. To decrease the complexity of higher-order modeling, we decompose the edge from predicate word to argument span into three different edges, predicate-to-head (P2H), predicate-to-tail (P2T), and head-to-tail (H2T), where head/tail means the first/last word of the semantic argument span. As such, we use a CRF-based higher-order dependency parser and leverage Mean-Field Variational Inference (MFVI) for higher-order inference. Moreover, since semantic arguments of predicates are often constituents within a constituency parse tree, we can leverage such nice structural property by defining a TreeCRF distribution over all H2T edges, using the idea of partial marginalization to define structural training loss. We further leverage structured MFVI to enhance inference. We experiment on span-based SRL benchmarks, showing the effectiveness of both higher-order and structured modeling and the combination thereof. In addition, we show superior performance of structured MFVI against vanilla MFVI.</abstract>
      <url hash="cc271478">2023.findings-acl.58</url>
      <bibkey>liu-etal-2023-structured</bibkey>
      <doi>10.18653/v1/2023.findings-acl.58</doi>
    </paper>
    <paper id="59">
      <title><fixed-case>AQE</fixed-case>: Argument Quadruplet Extraction via a Quad-Tagging Augmented Generative Approach</title>
      <author><first>Jia</first><last>Guo</last><affiliation>National University of Singapore</affiliation></author>
      <author><first>Liying</first><last>Cheng</last><affiliation>Alibaba</affiliation></author>
      <author><first>Wenxuan</first><last>Zhang</last><affiliation>DAMO Academy, Alibaba Group</affiliation></author>
      <author><first>Stanley</first><last>Kok</last><affiliation>National University of Singapore</affiliation></author>
      <author><first>Xin</first><last>Li</last><affiliation>Alibaba Group</affiliation></author>
      <author><first>Lidong</first><last>Bing</last><affiliation>Alibaba DAMO Academy</affiliation></author>
      <pages>932-946</pages>
      <abstract>Argument mining involves multiple sub-tasks that automatically identify argumentative elements, such as claim detection, evidence extraction, stance classification, etc. However, each subtask alone is insufficient for a thorough understanding of the argumentative structure and reasoning process. To learn a complete view of an argument essay and capture the interdependence among argumentative components, we need to know what opinions people hold (i.e., claims), why those opinions are valid (i.e., supporting evidence), which source the evidence comes from (i.e., evidence type), and how those claims react to the debating topic (i.e., stance). In this work, we for the first time propose a challenging argument quadruplet extraction task (AQE), which can provide an all-in-one extraction of four argumentative components, i.e., claims, evidence, evidence types, and stances. To support this task, we construct a large-scale and challenging dataset. However, there is no existing method that can solve the argument quadruplet extraction. To fill this gap, we propose a novel quad-tagging augmented generative approach, which leverages a quadruplet tagging module to augment the training of the generative framework. The experimental results on our dataset demonstrate the empirical superiority of our proposed approach over several strong baselines.</abstract>
      <url hash="1b72be57">2023.findings-acl.59</url>
      <bibkey>guo-etal-2023-aqe</bibkey>
      <doi>10.18653/v1/2023.findings-acl.59</doi>
    </paper>
    <paper id="60">
      <title>The Dangers of trusting Stochastic Parrots: Faithfulness and Trust in Open-domain Conversational Question Answering</title>
      <author><first>Sabrina</first><last>Chiesurin</last><affiliation>Alana AI</affiliation></author>
      <author><first>Dimitris</first><last>Dimakopoulos</last><affiliation>Alana AI</affiliation></author>
      <author><first>Marco Antonio</first><last>Sobrevilla Cabezudo</last><affiliation>University of São Paulo</affiliation></author>
      <author><first>Arash</first><last>Eshghi</last><affiliation>Heriot-Watt University</affiliation></author>
      <author><first>Ioannis</first><last>Papaioannou</last><affiliation>Alana AI</affiliation></author>
      <author><first>Verena</first><last>Rieser</last><affiliation>Heriot-Watt University</affiliation></author>
      <author><first>Ioannis</first><last>Konstas</last><affiliation>Heriot-Watt University</affiliation></author>
      <pages>947-959</pages>
      <abstract>Large language models are known to produce output which sounds fluent and convincing, but is also often wrong, e.g. “unfaithful” with respect to a rationale as retrieved from a knowledge base. In this paper, we show that task-based systems which exhibit certain advanced linguistic dialog behaviors, such as lexical alignment (repeating what the user said), are in fact preferred and trusted more, whereas other phenomena, such as pronouns and ellipsis are dis-preferred. We use open-domain question answering systems as our test-bed for task based dialog generation and compare several open- and closed-book models. Our results highlight the danger of systems that appear to be trustworthy by parroting user input while providing an unfaithful response.</abstract>
      <url hash="103f6ca8">2023.findings-acl.60</url>
      <bibkey>chiesurin-etal-2023-dangers</bibkey>
      <doi>10.18653/v1/2023.findings-acl.60</doi>
    </paper>
    <paper id="61">
      <title>Discrete Prompt Optimization via Constrained Generation for Zero-shot Re-ranker</title>
      <author><first>Sukmin</first><last>Cho</last><affiliation>Korea Advanced Institute of Science and Technology</affiliation></author>
      <author><first>Soyeong</first><last>Jeong</last><affiliation>Korea Advanced Institute of Science and Technology</affiliation></author>
      <author><first>Jeong yeon</first><last>Seo</last><affiliation>KAIST</affiliation></author>
      <author><first>Jong</first><last>Park</last><affiliation>KAIST</affiliation></author>
      <pages>960-971</pages>
      <abstract>Re-rankers, which order retrieved documents with respect to the relevance score on the given query, have gained attention for the information retrieval (IR) task. Rather than fine-tuning the pre-trained language model (PLM), the large-scale language model (LLM) is utilized as a zero-shot re-ranker with excellent results. While LLM is highly dependent on the prompts, the impact and the optimization of the prompts for the zero-shot re-ranker are not explored yet. Along with highlighting the impact of optimization on the zero-shot re-ranker, we propose a novel discrete prompt optimization method, Constrained Prompt generation (Co-Prompt), with the metric estimating the optimum for re-ranking. Co-Prompt guides the generated texts from PLM toward optimal prompts based on the metric without parameter update. The experimental results demonstrate that Co-Prompt leads to outstanding re-ranking performance against the baselines. Also, Co-Prompt generates more interpretable prompts for humans against other prompt optimization methods.</abstract>
      <url hash="a3da31f9">2023.findings-acl.61</url>
      <bibkey>cho-etal-2023-discrete</bibkey>
      <doi>10.18653/v1/2023.findings-acl.61</doi>
    </paper>
    <paper id="62">
      <title>Triggering Multi-Hop Reasoning for Question Answering in Language Models using Soft Prompts and Random Walks</title>
      <author><first>Kanishka</first><last>Misra</last><affiliation>Purdue University</affiliation></author>
      <author><first>Cicero</first><last>Nogueira dos Santos</last><affiliation>Google Research</affiliation></author>
      <author><first>Siamak</first><last>Shakeri</last><affiliation>Google.com</affiliation></author>
      <pages>972-985</pages>
      <abstract>Despite readily memorizing world knowledge about entities, pre-trained language models (LMs) struggle to compose together two or more facts to perform multi-hop reasoning in question-answering tasks. In this work, we propose techniques that improve upon this limitation by relying on random-walks over structured knowledge graphs. Specifically, we use soft-prompts to guide LMs to chain together their encoded knowledge by learning to map multi-hop questions to random-walk paths that lead to the answer. Applying our methods on two T5 LMs shows substantial improvements over standard tuning approaches in answering questions that require multi-hop reasoning.</abstract>
      <url hash="bde76e6e">2023.findings-acl.62</url>
      <bibkey>misra-etal-2023-triggering</bibkey>
      <doi>10.18653/v1/2023.findings-acl.62</doi>
    </paper>
    <paper id="63">
      <title>Multimedia Generative Script Learning for Task Planning</title>
      <author><first>Qingyun</first><last>Wang</last><affiliation>University of Illinois at Urbana-Champaign</affiliation></author>
      <author><first>Manling</first><last>Li</last><affiliation>UIUC</affiliation></author>
      <author><first>Hou Pong</first><last>Chan</last><affiliation>University of Macau</affiliation></author>
      <author><first>Lifu</first><last>Huang</last><affiliation>Virginia Tech</affiliation></author>
      <author><first>Julia</first><last>Hockenmaier</last><affiliation>University of Illinois Urbana-Champaign</affiliation></author>
      <author><first>Girish</first><last>Chowdhary</last><affiliation>University of Illinois at Urbana Champaign</affiliation></author>
      <author><first>Heng</first><last>Ji</last><affiliation>University of Illinois at Urbana-Champaign and Amazon (Amazon Scholar)</affiliation></author>
      <pages>986-1008</pages>
      <abstract>Goal-oriented generative script learning aims to generate subsequent steps to reach a particular goal, which is an essential task to assist robots or humans in performing stereotypical activities. An important aspect of this process is the ability to capture historical states visually, which provides detailed information that is not covered by text and will guide subsequent steps. Therefore, we propose a new task, Multimedia Generative Script Learning, to generate subsequent steps by tracking historical states in both text and vision modalities, as well as presenting the first benchmark containing 5,652 tasks and 79,089 multimedia steps. This task is challenging in three aspects: the multimedia challenge of capturing the visual states in images, the induction challenge of performing unseen tasks, and the diversity challenge of covering different information in individual steps. We propose to encode visual state changes through a selective multimedia encoder to address the multimedia challenge, transfer knowledge from previously observed tasks using a retrieval-augmented decoder to overcome the induction challenge, and further present distinct information at each step by optimizing a diversity-oriented contrastive learning objective. We define metrics to evaluate both generation and inductive quality. Experiment results demonstrate that our approach significantly outperforms strong baselines.</abstract>
      <url hash="29188530">2023.findings-acl.63</url>
      <bibkey>wang-etal-2023-multimedia</bibkey>
      <revision id="1" href="2023.findings-acl.63v1" hash="b7dc11ef"/>
      <revision id="2" href="2023.findings-acl.63v2" hash="29188530" date="2023-07-29">Hyperlinks correction.</revision>
      <doi>10.18653/v1/2023.findings-acl.63</doi>
    </paper>
    <paper id="64">
      <title>Label Agnostic Pre-training for Zero-shot Text Classification</title>
      <author><first>Christopher</first><last>Clarke</last><affiliation>University of Michigan</affiliation></author>
      <author><first>Yuzhao</first><last>Heng</last><affiliation>University of Michigan at Ann Arbor</affiliation></author>
      <author><first>Yiping</first><last>Kang</last><affiliation>University of Michigan</affiliation></author>
      <author><first>Krisztian</first><last>Flautner</last><affiliation>ARM</affiliation></author>
      <author><first>Lingjia</first><last>Tang</last><affiliation>Clinc, Inc / University of Michigan</affiliation></author>
      <author><first>Jason</first><last>Mars</last><affiliation>University of Michigan</affiliation></author>
      <pages>1009-1021</pages>
      <abstract>Conventional approaches to text classification typically assume the existence of a fixed set of predefined labels to which a given text can be classified. However, in real-world applications, there exists an infinite label space for describing a given text. In addition, depending on the aspect (sentiment, topic, etc.) and domain of the text (finance, legal, etc.), the interpretation of the label can vary greatly. This makes the task of text classification, particularly in the zero-shot scenario, extremely challenging. In this paper, we investigate the task of zero-shot text classification with the aim of improving the ability of pre-trained language models (PLMs) to generalize to both seen and unseen data across varying aspects and domains. To solve this we introduce two new simple yet effective pre-training strategies, Implicit and Explicit pre-training. These methods inject aspect-level understanding into the model at train time with the goal of conditioning the model to build task-level understanding. To evaluate this, we construct and release UTCD, a new benchmark dataset for evaluating text classification in zero-shot settings. Experimental results on UTCD show that our approach achieves improved zero-shot generalization on a suite of challenging datasets across an array of zero-shot formalizations.</abstract>
      <url hash="26e33c20">2023.findings-acl.64</url>
      <bibkey>clarke-etal-2023-label</bibkey>
      <doi>10.18653/v1/2023.findings-acl.64</doi>
    </paper>
    <paper id="65">
      <title>Click: Controllable Text Generation with Sequence Likelihood Contrastive Learning</title>
      <author><first>Chujie</first><last>Zheng</last><affiliation>Tsinghua University</affiliation></author>
      <author><first>Pei</first><last>Ke</last><affiliation>Tsinghua University</affiliation></author>
      <author><first>Zheng</first><last>Zhang</last><affiliation>Tsinghua University</affiliation></author>
      <author><first>Minlie</first><last>Huang</last><affiliation>Tsinghua University</affiliation></author>
      <pages>1022-1040</pages>
      <abstract>It has always been an important yet challenging problem to control language models to avoid generating texts with undesirable attributes, such as toxic language and unnatural repetition. We introduce Leo for controllable text generation, which needs no modification to the model architecture and facilitates out-of-the-box use of trained models. It employs a contrastive loss on sequence likelihood, which fundamentally decreases the generation probability of negative samples (i.e., generations with undesirable attributes). It also adopts a novel likelihood ranking-based strategy to construct contrastive samples from model generations. On the tasks of language detoxification, sentiment steering, and repetition reduction, we show that Leo outperforms strong baselines of controllable text generation and demonstrate the superiority of Leo’s sample construction strategy.</abstract>
      <url hash="f6c00d0e">2023.findings-acl.65</url>
      <bibkey>zheng-etal-2023-click</bibkey>
      <doi>10.18653/v1/2023.findings-acl.65</doi>
    </paper>
    <paper id="66">
      <title>Improving Embedding-based Unsupervised Keyphrase Extraction by Incorporating Structural Information</title>
      <author><first>Mingyang</first><last>Song</last><affiliation>Beijing Jiaotong University</affiliation></author>
      <author><first>Huafeng</first><last>Liu</last><affiliation>Beijing Jiaotong University</affiliation></author>
      <author><first>Yi</first><last>Feng</last><affiliation>BeiJing JiaoTong University</affiliation></author>
      <author><first>Liping</first><last>Jing</last><affiliation>Beijing Jiaotong Univesity</affiliation></author>
      <pages>1041-1048</pages>
      <abstract>Keyphrase extraction aims to extract a set of phrases with the central idea of the source document. In a structured document, there are certain locations (e.g., the title or the first sentence) where a keyphrase is most likely to appear. However, when extracting keyphrases from the document, most existing embedding-based unsupervised keyphrase extraction models ignore the indicative role of the highlights in certain locations, leading to wrong keyphrases extraction. In this paper, we propose a new Highlight-Guided Unsupervised Keyphrase Extraction model (HGUKE) to address the above issue. Specifically, HGUKE first models the phrase-document relevance via the highlights of the documents. Next, HGUKE calculates the cross-phrase relevance between all candidate phrases. Finally, HGUKE aggregates the above two relevance as the importance score of each candidate phrase to rank and extract keyphrases. The experimental results on three benchmarks demonstrate that HGUKE outperforms the state-of-the-art unsupervised keyphrase extraction baselines.</abstract>
      <url hash="05263e00">2023.findings-acl.66</url>
      <bibkey>song-etal-2023-improving</bibkey>
      <doi>10.18653/v1/2023.findings-acl.66</doi>
    </paper>
    <paper id="67">
      <title>Towards Reasoning in Large Language Models: A Survey</title>
      <author><first>Jie</first><last>Huang</last><affiliation>University of Illinois at Urbana-Champaign</affiliation></author>
      <author><first>Kevin Chen-Chuan</first><last>Chang</last><affiliation>University of Illinois at Urbana-Champaign</affiliation></author>
      <pages>1049-1065</pages>
      <abstract>Reasoning is a fundamental aspect of human intelligence that plays a crucial role in activities such as problem solving, decision making, and critical thinking. In recent years, large language models (LLMs) have made significant progress in natural language processing, and there is observation that these models may exhibit reasoning abilities when they are sufficiently large. However, it is not yet clear to what extent LLMs are capable of reasoning. This paper provides a comprehensive overview of the current state of knowledge on reasoning in LLMs, including techniques for improving and eliciting reasoning in these models, methods and benchmarks for evaluating reasoning abilities, findings and implications of previous research in this field, and suggestions on future directions. Our aim is to provide a detailed and up-to-date review of this topic and stimulate meaningful discussion and future work.</abstract>
      <url hash="93b31452">2023.findings-acl.67</url>
      <bibkey>huang-chang-2023-towards</bibkey>
      <doi>10.18653/v1/2023.findings-acl.67</doi>
    </paper>
    <paper id="68">
      <title>Transitioning from benchmarks to a real-world case of information-seeking in Scientific Publications</title>
      <author><first>Chyrine</first><last>Tahri</last><affiliation>Sorbonne Université, Inserm, LIMICS</affiliation></author>
      <author><first>Aurore</first><last>Bochnakian</last><affiliation>Erdyn</affiliation></author>
      <author><first>Patrick</first><last>Haouat</last><affiliation>Erdyn</affiliation></author>
      <author><first>Xavier</first><last>Tannier</last><affiliation>Sorbonne Université, Inserm, LIMICS</affiliation></author>
      <pages>1066-1076</pages>
      <abstract>Although recent years have been marked by incredible advances in the whole development process of NLP systems, there are still blind spots in characterizing what is still hampering real-world adoption of models in knowledge-intensive settings. In this paper, we illustrate through a real-world zero-shot text search case for information seeking in scientific papers, the masked phenomena that the current process of measuring performance might not reflect, even when benchmarks are, in appearance, faithfully representative of the task at hand. In addition to experimenting with TREC-COVID and NFCorpus, we provide an industrial, expert-carried/annotated, case of studying vitamin B’s impact on health. We thus discuss the misalignment between solely focusing on single-metric performance as a criterion for model choice and relevancy as a subjective measure for meeting a user’s need.</abstract>
      <url hash="e0d0a100">2023.findings-acl.68</url>
      <bibkey>tahri-etal-2023-transitioning</bibkey>
      <doi>10.18653/v1/2023.findings-acl.68</doi>
    </paper>
    <paper id="69">
      <title><fixed-case>CLIPT</fixed-case>ext: A New Paradigm for Zero-shot Text Classification</title>
      <author><first>Libo</first><last>Qin</last><affiliation>Harbin Institute of Technology</affiliation></author>
      <author><first>Weiyun</first><last>Wang</last><affiliation>China</affiliation></author>
      <author><first>Qiguang</first><last>Chen</last><affiliation>Harbin Institute of Technology</affiliation></author>
      <author><first>Wanxiang</first><last>Che</last><affiliation>Harbin Institute of Technology</affiliation></author>
      <pages>1077-1088</pages>
      <abstract>While CLIP models are useful for zero-shot vision-and-language (VL) tasks or computer vision tasks, little attention has been paid to the application of CLIP for language tasks. Intuitively, CLIP model have a rich representation pre-trained with natural language supervision, in which we argue that it is useful for language tasks. Hence, this work bridge this gap by investigating a CLIP model for zero-shot text classification. Specifically, we introduce CLIPText, a novel paradigm for zero-shot text classification, which reformulates zero-shot text classification into a text-image matching problem that CLIP can be applied to. In addition, we further incorporate prompt into CLIPText (Prompt-CLIPText) to better derive knowledge from CLIP. Experimental results on seven publicly available zero-shot text classification datasets show that both CLIPText and Prompt-CLIPText attain promising performance. Besides, extensive analysis further verifies that knowledge from CLIP can benefit zero-shot text classification task. We hope this work can attract more breakthroughs on applying VL pre-trained models for language tasks.</abstract>
      <url hash="f4abb034">2023.findings-acl.69</url>
      <bibkey>qin-etal-2023-cliptext</bibkey>
      <doi>10.18653/v1/2023.findings-acl.69</doi>
    </paper>
    <paper id="70">
      <title>Rethinking Dictionaries and Glyphs for <fixed-case>C</fixed-case>hinese Language Pre-training</title>
      <author><first>Yuxuan</first><last>Wang</last><affiliation>Peking University</affiliation></author>
      <author><first>Jack</first><last>Wang</last><affiliation>Beijing Institution for General Artificial Intelligence</affiliation></author>
      <author><first>Dongyan</first><last>Zhao</last><affiliation>pku.edu.cn</affiliation></author>
      <author><first>Zilong</first><last>Zheng</last><affiliation>Beijing Institute for General Artificial Intelligence</affiliation></author>
      <pages>1089-1101</pages>
      <abstract>We introduce CDBert, a new learning paradigm that enhances the semantics understanding ability of the Chinese PLMs with dictionary knowledge and structure of Chinese characters. We name the two core modules of CDBert as Shuowen and Jiezi, where Shuowen refers to the process of retrieving the most appropriate meaning from Chinese dictionaries and Jiezi refers to the process of enhancing characters’ glyph representations with structure understanding. To facilitate dictionary understanding, we propose three pre-training tasks, i.e.„ Masked Entry Modeling, Contrastive Learning for Synonym and Antonym, and Example Learning. We evaluate our method on both modern Chinese understanding benchmark CLUE and ancient Chinese benchmark CCLUE. Moreover, we propose a new polysemy discrimination task PolyMRC based on the collected dictionary of ancient Chinese. Our paradigm demonstrates consistent improvements on previous Chinese PLMs across all tasks. Moreover, our approach yields significant boosting on few-shot setting of ancient Chinese understanding.</abstract>
      <url hash="dc512fb3">2023.findings-acl.70</url>
      <bibkey>wang-etal-2023-rethinking</bibkey>
      <doi>10.18653/v1/2023.findings-acl.70</doi>
    </paper>
    <paper id="71">
      <title>One Embedder, Any Task: Instruction-Finetuned Text Embeddings</title>
      <author><first>Hongjin</first><last>Su</last><affiliation>The University of Hong Kong</affiliation></author>
      <author><first>Weijia</first><last>Shi</last><affiliation>uw.edu</affiliation></author>
      <author><first>Jungo</first><last>Kasai</last><affiliation>University of Washington</affiliation></author>
      <author><first>Yizhong</first><last>Wang</last><affiliation>University of Washington</affiliation></author>
      <author><first>Yushi</first><last>Hu</last><affiliation>University of Washington</affiliation></author>
      <author><first>Mari</first><last>Ostendorf</last><affiliation>University of Washington</affiliation></author>
      <author><first>Wen-tau</first><last>Yih</last><affiliation>Meta AI - FAIR</affiliation></author>
      <author><first>Noah A.</first><last>Smith</last><affiliation>University of Washington</affiliation></author>
      <author><first>Luke</first><last>Zettlemoyer</last><affiliation>University of Washington; Meta</affiliation></author>
      <author><first>Tao</first><last>Yu</last><affiliation>University of Hong Kong</affiliation></author>
      <pages>1102-1121</pages>
      <abstract>We introduce INSTRUCTOR, a new method for computing text embeddings given task instructions: every text input is embedded together with instructions explaining the use case (e.g., task and domain descriptions). Unlike encoders from prior work that are more specialized, INSTRUCTOR is a single embedder that can generate text embeddings tailored to different downstream tasks and domains, without any further training. We first annotate instructions for 330 diverse tasks and train INSTRUCTOR on this multitask mixture with a contrastive loss. We evaluate INSTRUCTOR on 70 embedding evaluation tasks (66 of which are unseen during training), ranging from classification and information retrieval to semantic textual similarity and text generation evaluation. INSTRUCTOR, while having an order of magnitude fewer parameters than the previous best model, achieves state-of-the-art performance, with an average improvement of 3.4% compared to the previous best results on the 70 diverse datasets. Our analysis suggests that INSTRUCTOR is robust to changes in instructions, and that instruction finetuning mitigates the challenge of training a single model on diverse datasets. Our model, code, and data are available at <url>https://instructor-embedding.github.io</url>.</abstract>
      <url hash="de019bdb">2023.findings-acl.71</url>
      <bibkey>su-etal-2023-one</bibkey>
      <doi>10.18653/v1/2023.findings-acl.71</doi>
    </paper>
    <paper id="72">
      <title>Towards Speech Dialogue Translation Mediating Speakers of Different Languages</title>
      <author><first>Shuichiro</first><last>Shimizu</last><affiliation>Kyoto University</affiliation></author>
      <author><first>Chenhui</first><last>Chu</last><affiliation>Kyoto University</affiliation></author>
      <author><first>Sheng</first><last>Li</last><affiliation>National Institute of Information and Communications Technology (NICT), Advanced Speech Technology Laboratory</affiliation></author>
      <author><first>Sadao</first><last>Kurohashi</last><affiliation>Kyoto University</affiliation></author>
      <pages>1122-1134</pages>
      <abstract>We present a new task, speech dialogue translation mediating speakers of different languages. We construct the SpeechBSD dataset for the task and conduct baseline experiments. Furthermore, we consider context to be an important aspect that needs to be addressed in this task and propose two ways of utilizing context, namely monolingual context and bilingual context. We conduct cascaded speech translation experiments using Whisper and mBART, and show that bilingual context performs better in our settings.</abstract>
      <url hash="57d780fd">2023.findings-acl.72</url>
      <bibkey>shimizu-etal-2023-towards</bibkey>
      <doi>10.18653/v1/2023.findings-acl.72</doi>
    </paper>
    <paper id="73">
      <title>Adaptation Approaches for Nearest Neighbor Language Models</title>
      <author><first>Rishabh</first><last>Bhardwaj</last><affiliation>Singapore University of Technology and Design</affiliation></author>
      <author><first>George</first><last>Polovets</last><affiliation>Amazon AWS AI</affiliation></author>
      <author><first>Monica</first><last>Sunkara</last><affiliation>Amazon</affiliation></author>
      <pages>1135-1146</pages>
      <abstract>Semi-parametric Nearest Neighbor Language Models (kNN-LMs) have produced impressive gains over purely parametric LMs, by leveraging large-scale neighborhood retrieval over external memory datastores. However, there has been little investigation into adapting such models for new domains. This work attempts to fill that gap and suggests the following approaches for adapting kNN-LMs — 1) adapting the underlying LM (using Adapters), 2) expanding neighborhood retrieval over an additional adaptation datastore, and 3) adapting the weights (scores) of retrieved neighbors using a learned Rescorer module. We study each adaptation strategy separately, as well as the combined performance improvement through ablation experiments and an extensive set of evaluations run over seven adaptation domains. Our combined adaptation approach consistently outperforms purely parametric adaptation and zero-shot (kNN-LM) baselines that construct datastores from the adaptation data. On average, we see perplexity improvements of 17.1% and 16% for these respective baselines, across domains.</abstract>
      <url hash="2910d9f4">2023.findings-acl.73</url>
      <bibkey>bhardwaj-etal-2023-adaptation</bibkey>
      <doi>10.18653/v1/2023.findings-acl.73</doi>
    </paper>
    <paper id="74">
      <title>Language Models for <fixed-case>G</fixed-case>erman Text Simplification: Overcoming Parallel Data Scarcity through Style-specific Pre-training</title>
      <author><first>Miriam</first><last>Anschütz</last><affiliation>Technical University of Munich</affiliation></author>
      <author><first>Joshua</first><last>Oehms</last><affiliation>Technical University of Munich</affiliation></author>
      <author><first>Thomas</first><last>Wimmer</last><affiliation>Technical University of Munich</affiliation></author>
      <author><first>Bartłomiej</first><last>Jezierski</last><affiliation>Technical University of Munich</affiliation></author>
      <author><first>Georg</first><last>Groh</last><affiliation>TUM</affiliation></author>
      <pages>1147-1158</pages>
      <abstract>Automatic text simplification systems help to reduce textual information barriers on the internet. However, for languages other than English, only few parallel data to train these systems exists. We propose a two-step approach to overcome this data scarcity issue. First, we fine-tuned language models on a corpus of German Easy Language, a specific style of German. Then, we used these models as decoders in a sequence-to-sequence simplification task. We show that the language models adapt to the style characteristics of Easy Language and output more accessible texts. Moreover, with the style-specific pre-training, we reduced the number of trainable parameters in text simplification models. Hence, less parallel data is sufficient for training. Our results indicate that pre-training on unaligned data can reduce the required parallel data while improving the performance on downstream tasks.</abstract>
      <url hash="ba41a5f6">2023.findings-acl.74</url>
      <bibkey>anschutz-etal-2023-language</bibkey>
      <doi>10.18653/v1/2023.findings-acl.74</doi>
    </paper>
    <paper id="75">
      <title>Client-Customized Adaptation for Parameter-Efficient Federated Learning</title>
      <author><first>Yeachan</first><last>Kim</last><affiliation>Korea University</affiliation></author>
      <author><first>Junho</first><last>Kim</last><affiliation>Korea University</affiliation></author>
      <author><first>Wing-Lam</first><last>Mok</last><affiliation>Korea University</affiliation></author>
      <author><first>Jun-Hyung</first><last>Park</last><affiliation>Korea University</affiliation></author>
      <author><first>SangKeun</first><last>Lee</last><affiliation>Korea University</affiliation></author>
      <pages>1159-1172</pages>
      <abstract>Despite the versatility of pre-trained language models (PLMs) across domains, their large memory footprints pose significant challenges in federated learning (FL), where the training model has to be distributed between a server and clients. One potential solution to bypass such constraints might be the use of parameter-efficient fine-tuning (PEFT) in the context of FL. However, we have observed that typical PEFT tends to severely suffer from heterogeneity among clients in FL scenarios, resulting in unstable and slow convergence. In this paper, we propose Client-Customized Adaptation (C2A), a novel hypernetwork-based FL framework that generates client-specific adapters by conditioning the client information. With the effectiveness of the hypernetworks in generating customized weights through learning to adopt the different characteristics of inputs, C2A can maximize the utility of shared model parameters while minimizing the divergence caused by client heterogeneity. To verify the efficacy of C2A, we perform extensive evaluations on FL scenarios involving heterogeneity in label and language distributions. Comprehensive evaluation results clearly support the superiority of C2A in terms of both efficiency and effectiveness in FL scenarios.</abstract>
      <url hash="4b01bb35">2023.findings-acl.75</url>
      <bibkey>kim-etal-2023-client</bibkey>
      <doi>10.18653/v1/2023.findings-acl.75</doi>
    </paper>
    <paper id="76">
      <title><fixed-case>F</fixed-case>olk<fixed-case>S</fixed-case>cope: Intention Knowledge Graph Construction for <fixed-case>E</fixed-case>-commerce Commonsense Discovery</title>
      <author><first>Changlong</first><last>Yu</last><affiliation>HKUST</affiliation></author>
      <author><first>Weiqi</first><last>Wang</last><affiliation>Hong Kong University of Science and Technology</affiliation></author>
      <author><first>Xin</first><last>Liu</last><affiliation>Hong Kong University of Science and Technology</affiliation></author>
      <author><first>Jiaxin</first><last>Bai</last><affiliation>Hong Kong University of Science and Technology</affiliation></author>
      <author><first>Yangqiu</first><last>Song</last><affiliation>HKUST</affiliation></author>
      <author><first>Zheng</first><last>Li</last><affiliation>Amazon</affiliation></author>
      <author><first>Yifan</first><last>Gao</last><affiliation>Amazon</affiliation></author>
      <author><first>Tianyu</first><last>Cao</last><affiliation>amazon.com</affiliation></author>
      <author><first>Bing</first><last>Yin</last><affiliation>Amazon.com</affiliation></author>
      <pages>1173-1191</pages>
      <abstract>Understanding users’ intentions in e-commerce platforms requires commonsense knowledge. In this paper, we present FolkScope, an intention knowledge graph construction framework, to reveal the structure of humans’ minds about purchasing items. As commonsense knowledge is usually ineffable and not expressed explicitly, it is challenging to perform information extraction. Thus, we propose a new approach that leverages the generation power of large language models (LLMs) and human-in-the-loop annotation to semi-automatically construct the knowledge graph. LLMs first generate intention assertions via e-commerce specific prompts to explain shopping behaviors, where the intention can be an open reason or a predicate falling into one of 18 categories aligning with ConceptNet, e.g., IsA, MadeOf, UsedFor, etc. Then we annotate plausibility and typicality labels of sampled intentions as training data in order to populate human judgments to all automatic generations. Last, to structurize the assertions, we propose pattern mining and conceptualization to form more condensed and abstract knowledge. Extensive evaluations and study demonstrate that our constructed knowledge graph can well model e-commerce knowledge and have many potential applications.</abstract>
      <url hash="6f5fe0da">2023.findings-acl.76</url>
      <bibkey>yu-etal-2023-folkscope</bibkey>
      <doi>10.18653/v1/2023.findings-acl.76</doi>
    </paper>
    <paper id="77">
      <title><fixed-case>I</fixed-case> am <fixed-case>P</fixed-case>sy<fixed-case>AM</fixed-case>: Modeling Happiness with Cognitive Appraisal Dimensions</title>
      <author><first>Xuan</first><last>Liu</last><affiliation>University of California, Berkeley</affiliation></author>
      <author><first>Kokil</first><last>Jaidka</last><affiliation>National University of Singapore</affiliation></author>
      <pages>1192-1210</pages>
      <abstract>This paper proposes and evaluates PsyAM (<url>https://anonymous.4open.science/r/BERT-PsyAM-10B9</url>), a framework that incorporates adaptor modules in a sequential multi-task learning setup to generate high-dimensional feature representations of hedonic well-being (momentary happiness) in terms of its psychological underpinnings. PsyAM models emotion in text through its cognitive antecedents through auxiliary models that achieve multi-task learning through novel feature fusion methods. We show that BERT-PsyAM has cross-task validity and cross-domain generalizability through experiments with emotion-related tasks – on new emotion tasks and new datasets, as well as against traditional methods and BERT baselines. We further probe the robustness of BERT-PsyAM through feature ablation studies, as well as discuss the qualitative inferences we can draw regarding the effectiveness of the framework for representing emotional states. We close with a discussion of a future agenda of psychology-inspired neural network architectures.</abstract>
      <url hash="f1c5cbb6">2023.findings-acl.77</url>
      <bibkey>liu-jaidka-2023-psyam</bibkey>
      <doi>10.18653/v1/2023.findings-acl.77</doi>
    </paper>
    <paper id="78">
      <title>Value type: the bridge to a better <fixed-case>DST</fixed-case> model</title>
      <author><first>Gao</first><last>Qixiang</last><affiliation>Beijing University of Posts and Telecommunications</affiliation></author>
      <author><first>Mingyang</first><last>Sun</last><affiliation>Beijing University of Posts and Telecommunications</affiliation></author>
      <author><first>Yutao</first><last>Mou</last><affiliation>Beijing University of Posts and Telecommunications</affiliation></author>
      <author><first>Chen</first><last>Zeng</last><affiliation>Beijing University of Posts and Telecommunications</affiliation></author>
      <author><first>Weiran</first><last>Xu</last><affiliation>Beijing University of Posts and Telecommunications</affiliation></author>
      <pages>1211-1219</pages>
      <abstract>Value type of the slots can provide lots of useful information for DST tasks. However, it has been ignored in most previous works. In this paper, we propose a new framework for DST task based on these value types. Firstly, we extract the type of token from each turn. Specifically, we divide the slots in the dataset into 9 categories according to the type of slot value, and then train a Ner model to extract the corresponding type-entity from each turn of conversation according to the token. Secondly, we improve the attention mode which is integrated into value type information between the slot and the conversation history to help each slot pay more attention to the turns that contain the same value type. Meanwhile, we introduce a sampling strategy to integrate these types into the attention formula, which decrease the error of Ner model. Finally, we conduct a comprehensive experiment on two multi-domain task-oriented conversation datasets, MultiWOZ 2.1 and MultiWOZ 2.4. The ablation experimental results show that our method is effective on both datasets, which verify the necessity of considering the type of slot value.</abstract>
      <url hash="f540ed12">2023.findings-acl.78</url>
      <bibkey>qixiang-etal-2023-value</bibkey>
      <doi>10.18653/v1/2023.findings-acl.78</doi>
    </paper>
    <paper id="79">
      <title>Hypothetical Training for Robust Machine Reading Comprehension of Tabular Context</title>
      <author><first>Moxin</first><last>Li</last><affiliation>National University of Singapore</affiliation></author>
      <author><first>Wenjie</first><last>Wang</last><affiliation>National University of Singapore</affiliation></author>
      <author><first>Fuli</first><last>Feng</last><affiliation>University of Science and Technology of China</affiliation></author>
      <author><first>Hanwang</first><last>Zhang</last><affiliation>Nanyang Technological University</affiliation></author>
      <author><first>Qifan</first><last>Wang</last><affiliation>Meta AI</affiliation></author>
      <author><first>Tat-Seng</first><last>Chua</last><affiliation>National University of Singapore</affiliation></author>
      <pages>1220-1236</pages>
      <abstract>Machine Reading Comprehension (MRC) models easily learn spurious correlations from complex contexts such as tabular data. Counterfactual training—using the factual and counterfactual data by augmentation—has become a promising solution. However, it is costly to construct faithful counterfactual examples because it is tricky to maintain the consistency and dependency of the tabular data. In this paper, we take a more efficient fashion to ask <b>hypothetical questions</b> like <i>“in which year would the net profit be larger if the revenue in 2019 were $38,298?”</i>, whose effects on the answers are equivalent to those expensive counterfactual tables. We propose a hypothetical training framework that uses paired examples with different hypothetical questions to supervise the direction of model gradient towards the counterfactual answer change. The superior generalization results on tabular MRC datasets, including a newly constructed stress test and MultiHiertt, validate our effectiveness.</abstract>
      <url hash="d8b6bce9">2023.findings-acl.79</url>
      <bibkey>li-etal-2023-hypothetical</bibkey>
      <doi>10.18653/v1/2023.findings-acl.79</doi>
    </paper>
    <paper id="80">
      <title><fixed-case>B</fixed-case>angla<fixed-case>B</fixed-case>ook: A Large-scale <fixed-case>B</fixed-case>angla Dataset for Sentiment Analysis from Book Reviews</title>
      <author><first>Mohsinul</first><last>Kabir</last><affiliation>Islamic University of Technology</affiliation></author>
      <author><first>Obayed</first><last>Bin Mahfuz</last><affiliation>Islamic University of Technology</affiliation></author>
      <author><first>Syed Rifat</first><last>Raiyan</last><affiliation>Islamic University of Technology</affiliation></author>
      <author><first>Hasan</first><last>Mahmud</last><affiliation>Associate Professor</affiliation></author>
      <author><first>Md Kamrul</first><last>Hasan</last><affiliation>Islamic University of Technology</affiliation></author>
      <pages>1237-1247</pages>
      <abstract>The analysis of consumer sentiment, as expressed through reviews, can provide a wealth of insight regarding the quality of a product. While the study of sentiment analysis has been widely explored in many popular languages, relatively less attention has been given to the Bangla language, mostly due to a lack of relevant data and cross-domain adaptability. To address this limitation, we present BanglaBook, a large-scale dataset of Bangla book reviews consisting of 158,065 samples classified into three broad categories: positive, negative, and neutral. We provide a detailed statistical analysis of the dataset and employ a range of machine learning models to establish baselines including SVM, LSTM, and Bangla-BERT. Our findings demonstrate a substantial performance advantage of pre-trained models over models that rely on manually crafted features, emphasizing the necessity for additional training resources in this domain. Additionally, we conduct an in-depth error analysis by examining sentiment unigrams, which may provide insight into common classification errors in under-resourced languages like Bangla. Our codes and data are publicly available at <url>https://github.com/mohsinulkabir14/BanglaBook</url>.</abstract>
      <url hash="ef20a78a">2023.findings-acl.80</url>
      <bibkey>kabir-etal-2023-banglabook</bibkey>
      <doi>10.18653/v1/2023.findings-acl.80</doi>
    </paper>
    <paper id="81">
      <title>Risks and <fixed-case>NLP</fixed-case> Design: A Case Study on Procedural Document <fixed-case>QA</fixed-case></title>
      <author><first>Nikita</first><last>Haduong</last><affiliation>University of Washington</affiliation></author>
      <author><first>Alice</first><last>Gao</last><affiliation>University of Washington</affiliation></author>
      <author><first>Noah A.</first><last>Smith</last><affiliation>University of Washington</affiliation></author>
      <pages>1248-1269</pages>
      <abstract>As NLP systems are increasingly deployed at scale, concerns about their potential negative impacts have attracted the attention of the research community, yet discussions of risk have mostly been at an abstract level and focused on generic AI or NLP applications. We argue that clearer assessments of risks and harms to users—and concrete strategies to mitigate them—will be possible when we specialize the analysis to more concrete applications and their plausible users. As an illustration, this paper is grounded in cooking recipe procedural document question answering (ProcDocQA), where there are well-defined risks to users such as injuries or allergic reactions. Our case study shows that an existing language model, applied in “zero-shot” mode, quantitatively answers real-world questions about recipes as well or better than the humans who have answered the questions on the web. Using a novel questionnaire informed by theoretical work on AI risk, we conduct a risk-oriented error analysis that could then inform the design of a future system to be deployed with lower risk of harm and better performance.</abstract>
      <url hash="b9807d1c">2023.findings-acl.81</url>
      <bibkey>haduong-etal-2023-risks</bibkey>
      <doi>10.18653/v1/2023.findings-acl.81</doi>
    </paper>
    <paper id="82">
      <title>The Diminishing Returns of Masked Language Models to Science</title>
      <author><first>Zhi</first><last>Hong</last><affiliation>University of Chicago</affiliation></author>
      <author><first>Aswathy</first><last>Ajith</last><affiliation>University of Chicago</affiliation></author>
      <author><first>James</first><last>Pauloski</last><affiliation>University of Chicago</affiliation></author>
      <author><first>Eamon</first><last>Duede</last><affiliation>University of Chicago</affiliation></author>
      <author><first>Kyle</first><last>Chard</last><affiliation>UChicago</affiliation></author>
      <author><first>Ian</first><last>Foster</last><affiliation>University of Chicago</affiliation></author>
      <pages>1270-1283</pages>
      <abstract>Transformer-based masked language models such as BERT, trained on general corpora, have shown impressive performance on downstream tasks. It has also been demonstrated that the downstream task performance of such models can be improved by pretraining larger models for longer on more data. In this work, we empirically evaluate the extent to which these results extend to tasks in science. We use 14 domain-specific transformer-based models (including ScholarBERT, a new 770Mparameter science-focused masked language model pretrained on up to 225B tokens) to evaluate the impact of training data, model size, pretraining and finetuning time on 12 downstream scientific tasks. Interestingly, we find that increasing model size, training data, or compute time does not always lead to significant improvements (i.e., &gt;1% F1), if any, in scientific information extraction tasks. We offer possible explanations for this surprising result.</abstract>
      <url hash="8a6d3596">2023.findings-acl.82</url>
      <bibkey>hong-etal-2023-diminishing</bibkey>
      <doi>10.18653/v1/2023.findings-acl.82</doi>
    </paper>
    <paper id="83">
      <title>Causal Matching with Text Embeddings: A Case Study in Estimating the Causal Effects of Peer Review Policies</title>
      <author><first>Raymond</first><last>Zhang</last><affiliation>Stanford University</affiliation></author>
      <author><first>Neha Nayak</first><last>Kennard</last><affiliation>University of Massachusetts Amherst</affiliation></author>
      <author><first>Daniel</first><last>Smith</last><affiliation>Stanford University</affiliation></author>
      <author><first>Daniel</first><last>McFarland</last><affiliation>Stanford University</affiliation></author>
      <author><first>Andrew</first><last>McCallum</last><affiliation>UMass Amherst</affiliation></author>
      <author><first>Katherine</first><last>Keith</last><affiliation>Williams College</affiliation></author>
      <pages>1284-1297</pages>
      <abstract>A promising approach to estimate the causal effects of peer review policies is to analyze data from publication venues that shift policies from single-blind to double-blind from one year to the next. However, in these settings the content of the manuscript is a confounding variable—each year has a different distribution of scientific content which may naturally affect the distribution of reviewer scores. To address this textual confounding, we extend variable ratio nearest neighbor matching to incorporate text embeddings. We compare this matching method to a widely-used causal method of stratified propensity score matching and a baseline of randomly selected matches. For our case study of the ICLR conference shifting from single- to double-blind review from 2017 to 2018, we find human judges prefer manuscript matches from our method in 70% of cases. While the unadjusted estimate of the average causal effect of reviewers’ scores is -0.25, our method shifts the estimate to -0.17, a slightly smaller difference between the outcomes of single- and double-blind policies. We hope this case study enables exploration of additional text-based causal estimation methods and domains in the future.</abstract>
      <url hash="b98e6317">2023.findings-acl.83</url>
      <bibkey>zhang-etal-2023-causal-matching</bibkey>
      <doi>10.18653/v1/2023.findings-acl.83</doi>
    </paper>
    <paper id="84">
      <title>Learning to Generalize for Cross-domain <fixed-case>QA</fixed-case></title>
      <author><first>Yingjie</first><last>Niu</last><affiliation>University College Dublin</affiliation></author>
      <author><first>Linyi</first><last>Yang</last><affiliation>Westlake University</affiliation></author>
      <author><first>Ruihai</first><last>Dong</last><affiliation>Insight Centre for Data Analytics, University College Dublin</affiliation></author>
      <author><first>Yue</first><last>Zhang</last><affiliation>Westlake University</affiliation></author>
      <pages>1298-1313</pages>
      <abstract>There have been growing concerns regarding the out-of-domain generalization ability of natural language processing (NLP) models, particularly in question-answering (QA) tasks. Current synthesized data augmentation methods for QA are hampered by increased training costs. To address this issue, we propose a novel approach that combines prompting methods and linear probing with fine-tuning strategy, which does not entail additional cost. Our method has been theoretically and empirically shown to be effective in enhancing the generalization ability of both generative and discriminative models. Our approach outperforms state-of-the-art baselines, with an average increase in F1 score of 4.5%-7.9%. Furthermore, our method can be easily integrated into any pre-trained models and offers a promising solution to the under-explored cross-domain QA task.</abstract>
      <url hash="88c1399f">2023.findings-acl.84</url>
      <bibkey>niu-etal-2023-learning</bibkey>
      <doi>10.18653/v1/2023.findings-acl.84</doi>
    </paper>
    <paper id="85">
      <title>Enhanced Chart Understanding via Visual Language Pre-training on Plot Table Pairs</title>
      <author><first>Mingyang</first><last>Zhou</last><affiliation>Post Doctoral Research Scientist at Columbia University</affiliation></author>
      <author><first>Yi</first><last>Fung</last><affiliation>University of Illinois at Urbana Champaign</affiliation></author>
      <author><first>Long</first><last>Chen</last><affiliation>Hong Kong University of Science and Technology</affiliation></author>
      <author><first>Christopher</first><last>Thomas</last><affiliation>Columbia University</affiliation></author>
      <author><first>Heng</first><last>Ji</last><affiliation>University of Illinois at Urbana-Champaign and Amazon (Amazon Scholar)</affiliation></author>
      <author><first>Shih-Fu</first><last>Chang</last><affiliation>Columbia University</affiliation></author>
      <pages>1314-1326</pages>
      <abstract>Building cross-model intelligence that can understand charts and communicate the salient information hidden behind them is an appealing challenge in the vision and language (V+L) community. The capability to uncover the underlined table data of chart figures is a critical key to automatic chart understanding. We introduce ChartT5, a V+L model that learns how to interpret table information from chart images via cross-modal pre-training on plot table pairs. Specifically, we propose two novel pre-training objectives: Masked Header Prediction (MHP) and Masked Value Prediction (MVP) to facilitate the model with different skills to interpret the table information. We have conducted extensive experiments on chart question answering and chart summarization to verify the effectiveness of the proposed pre-training strategies. In particular, on the ChartQA benchmark, our ChartT5 outperforms the state-of-the-art non-pretraining methods by over 8% performance gains.</abstract>
      <url hash="c9e290d0">2023.findings-acl.85</url>
      <bibkey>zhou-etal-2023-enhanced</bibkey>
      <doi>10.18653/v1/2023.findings-acl.85</doi>
    </paper>
    <paper id="86">
      <title>Importance of Synthesizing High-quality Data for Text-to-<fixed-case>SQL</fixed-case> Parsing</title>
      <author><first>Yiqun</first><last>Hu</last><affiliation>AWS AI Labs</affiliation></author>
      <author><first>Yiyun</first><last>Zhao</last><affiliation>University of Arizona/JPMorgan Chase &amp; Co.</affiliation></author>
      <author><first>Jiarong</first><last>Jiang</last><affiliation>AWS</affiliation></author>
      <author><first>Wuwei</first><last>Lan</last><affiliation>Amazon Web Services</affiliation></author>
      <author><first>Henghui</first><last>Zhu</last><affiliation>Amazon</affiliation></author>
      <author><first>Anuj</first><last>Chauhan</last><affiliation>AWS AI</affiliation></author>
      <author><first>Alexander Hanbo</first><last>Li</last><affiliation>AWS AI Labs</affiliation></author>
      <author><first>Lin</first><last>Pan</last><affiliation>Amazon</affiliation></author>
      <author><first>Jun</first><last>Wang</last><affiliation>Amazon AWS</affiliation></author>
      <author><first>Chung-Wei</first><last>Hang</last><affiliation>AWS AI Labs</affiliation></author>
      <author><first>Sheng</first><last>Zhang</last><affiliation>Amazon</affiliation></author>
      <author><first>Jiang</first><last>Guo</last><affiliation>AWS AI Labs</affiliation></author>
      <author><first>Mingwen</first><last>Dong</last><affiliation>Amazon</affiliation></author>
      <author><first>Joseph</first><last>Lilien</last><affiliation>AWS AI Labs</affiliation></author>
      <author><first>Patrick</first><last>Ng</last><affiliation>Amazon.com</affiliation></author>
      <author><first>Zhiguo</first><last>Wang</last><affiliation>AWS AI Labs</affiliation></author>
      <author><first>Vittorio</first><last>Castelli</last><affiliation>AWS AI Labs</affiliation></author>
      <author><first>Bing</first><last>Xiang</last><affiliation>Amazon</affiliation></author>
      <pages>1327-1343</pages>
      <abstract>There has been increasing interest in synthesizing data to improve downstream text-to-SQL tasks. In this paper, we examined the existing synthesized datasets and discovered that state-of-the-art text-to-SQL algorithms did not further improve on popular benchmarks when trained with augmented synthetic data. We observed three shortcomings: illogical synthetic SQL queries from independent column sampling, arbitrary table joins, and language gaps between the synthesized SQL and natural language question (NLQ) pair. To address these issues, we propose a novel synthesis framework that imposes strong typing constraints, incorporates key relationships from schema, and conducts schema-distance-weighted column sampling. We also adopt an intermediate representation (IR) for the SQL-to-text task to further improve the quality of the generated NLQ. When existing powerful text-to-SQL parsers are pretrained on our high-quality synthesized data, these models have significant accuracy boosts and achieve new state-of-the-art performance on Spider. We also demonstrate the effectiveness of our techniques with ablation studies</abstract>
      <url hash="d2ac4292">2023.findings-acl.86</url>
      <bibkey>hu-etal-2023-importance</bibkey>
      <doi>10.18653/v1/2023.findings-acl.86</doi>
    </paper>
    <paper id="87">
      <title>Exploring Schema Generalizability of Text-to-<fixed-case>SQL</fixed-case></title>
      <author><first>Jieyu</first><last>Li</last><affiliation>Shanghai Jiao Tong University</affiliation></author>
      <author><first>Lu</first><last>Chen</last><affiliation>Shanghai Jiao Tong University</affiliation></author>
      <author><first>Ruisheng</first><last>Cao</last><affiliation>Shanghai Jiao Tong University</affiliation></author>
      <author><first>Su</first><last>Zhu</last><affiliation>AISpeech Co., Ltd</affiliation></author>
      <author><first>Hongshen</first><last>Xu</last><affiliation>Shanghai Jiao Tong University</affiliation></author>
      <author><first>Zhi</first><last>Chen</last><affiliation>Shanghai Jiao Tong University</affiliation></author>
      <author><first>Hanchong</first><last>Zhang</last><affiliation>Shanghai Jiao Tong University</affiliation></author>
      <author><first>Kai</first><last>Yu</last><affiliation>Shanghai Jiao Tong University</affiliation></author>
      <pages>1344-1360</pages>
      <abstract>Exploring the generalizability of a text-to-SQL parser is essential for a system to automatically adapt the real-world databases. Previous investigation works mostly focus on lexical diversity, including the influence of the synonym and perturbations in both natural language questions and databases. However, the structural variability of database schema (DS), as a widely seen real-world scenario, is yet underexplored. Specifically, confronted with the same input question, the target SQL may be represented in different ways when the DS comes to a different structure. In this work, we provide in-depth discussions about the schema generalizability challenge of text-to-SQL tasks. We observe that current datasets are too templated to study schema generalization. To collect suitable test data, we propose a framework to generate novel text-to-SQL data via automatic and synchronous (DS, SQL) pair altering. When evaluating state-of-the-art text-to-SQL models on the synthetic samples, performance is significantly degraded, which demonstrates the limitation of current research regarding schema generalization.</abstract>
      <url hash="1ace13f2">2023.findings-acl.87</url>
      <bibkey>li-etal-2023-exploring</bibkey>
      <doi>10.18653/v1/2023.findings-acl.87</doi>
    </paper>
    <paper id="88">
      <title>Enhancing Cross-lingual Natural Language Inference by Soft Prompting with Multilingual Verbalizer</title>
      <author><first>Shuang</first><last>Li</last><affiliation>School of Software, Tsinghua University</affiliation></author>
      <author><first>Xuming</first><last>Hu</last><affiliation>School of Software, Tsinghua University</affiliation></author>
      <author><first>Aiwei</first><last>Liu</last><affiliation>School of Software, Tsinghua University</affiliation></author>
      <author><first>Yawen</first><last>Yang</last><affiliation>School of Software, Tsinghua University</affiliation></author>
      <author><first>Fukun</first><last>Ma</last><affiliation>School of Software,Tsinghua University</affiliation></author>
      <author><first>Philip S.</first><last>Yu</last><affiliation>University of Illinois at Chicago</affiliation></author>
      <author><first>Lijie</first><last>Wen</last><affiliation>School of Software, Tsinghua University</affiliation></author>
      <pages>1361-1374</pages>
      <abstract>Cross-lingual natural language inference is a fundamental problem in cross-lingual language understanding. Many recent works have used prompt learning to address the lack of annotated parallel corpora in XNLI.However, these methods adopt discrete prompting by simply translating the templates to the target language and need external expert knowledge to design the templates. Besides, discrete prompts of human-designed template words are not trainable vectors and can not be migrated to target languages in the inference stage flexibly. In this paper, we propose a novel Soft prompt learning framework with the Multilingual Verbalizer (SoftMV) for XNLI. SoftMV first constructs cloze-style question with soft prompts for the input sample. Then we leverage bilingual dictionaries to generate an augmented multilingual question for the original question. SoftMV adopts a multilingual verbalizer to align the representations of original and augmented multilingual questions into a unified semantic space with consistency regularization. Experimental results on XNLI demonstrate that SoftMV can achieve state-of-the-art performance and significantly outperform the previous methods under the few-shot and full-shot cross-lingual transfer settings.</abstract>
      <url hash="f6a6f5a6">2023.findings-acl.88</url>
      <bibkey>li-etal-2023-enhancing-cross</bibkey>
      <doi>10.18653/v1/2023.findings-acl.88</doi>
    </paper>
    <paper id="89">
      <title>A Confidence-based Partial Label Learning Model for Crowd-Annotated Named Entity Recognition</title>
      <author><first>Limao</first><last>Xiong</last><affiliation>Fudan University</affiliation></author>
      <author><first>Jie</first><last>Zhou</last><affiliation>Fudan University</affiliation></author>
      <author><first>Qunxi</first><last>Zhu</last><affiliation>Fudan University</affiliation></author>
      <author><first>Xiao</first><last>Wang</last><affiliation>Fudan University</affiliation></author>
      <author><first>Yuanbin</first><last>Wu</last><affiliation>East China Normal University</affiliation></author>
      <author><first>Qi</first><last>Zhang</last><affiliation>Fudan University</affiliation></author>
      <author><first>Tao</first><last>Gui</last><affiliation>fudan university</affiliation></author>
      <author><first>Xuanjing</first><last>Huang</last><affiliation>Fudan University</affiliation></author>
      <author><first>Jin</first><last>Ma</last><affiliation>ustc</affiliation></author>
      <author><first>Ying</first><last>Shan</last><affiliation>Tencent</affiliation></author>
      <pages>1375-1386</pages>
      <abstract>Existing models for named entity recognition (NER) are mainly based on large-scale labeled datasets, which always obtain using crowdsourcing. However, it is hard to obtain a unified and correct label via majority voting from multiple annotators for NER due to the large labeling space and complexity of this task. To address this problem, we aim to utilize the original multi-annotator labels directly. Particularly, we propose a CONfidence-based partial Label Learning (CONLL) method to integrate the prior confidence (given by annotators) and posterior confidences (learned by models) for crowd-annotated NER. This model learns a token- and content-dependent confidence via an Expectation–Maximization (EM) algorithm by minimizing empirical risk. The true posterior estimator and confidence estimator perform iteratively to update the true posterior and confidence respectively. We conduct extensive experimental results on both real-world and synthetic datasets, which show that our model can improve performance effectively compared with strong baselines.</abstract>
      <url hash="1d2596da">2023.findings-acl.89</url>
      <bibkey>xiong-etal-2023-confidence</bibkey>
      <doi>10.18653/v1/2023.findings-acl.89</doi>
    </paper>
    <paper id="90">
      <title>Towards Zero-Shot Persona Dialogue Generation with In-Context Learning</title>
      <author><first>Xinchao</first><last>Xu</last><affiliation>Baidu</affiliation></author>
      <author><first>Zeyang</first><last>Lei</last><affiliation>Baidu Inc.</affiliation></author>
      <author><first>Wenquan</first><last>Wu</last><affiliation>Baidu</affiliation></author>
      <author><first>Zheng-Yu</first><last>Niu</last><affiliation>Baidu Inc.</affiliation></author>
      <author><first>Hua</first><last>Wu</last><affiliation>Baidu</affiliation></author>
      <author><first>Haifeng</first><last>Wang</last><affiliation>Baidu</affiliation></author>
      <pages>1387-1398</pages>
      <abstract>Much work has been done to improve persona consistency by finetuning a pretrained dialogue model on high-quality human-annoated persona datasets. However, these methods still face the challenges of high cost and poor scalability. To this end, we propose a simple-yet-effective approach to significantly improve zero-shot persona consistency via in-context learning. Specifically, we first pre-train a persona-augmented dialogue generation model and then utilize in-context prompting mechanism to realize zero-shot persona customization. Experimental results demonstrate that our method can dramatically improve persona consistency without compromising coherence and informativeness in zero-shot settings.</abstract>
      <url hash="072d0037">2023.findings-acl.90</url>
      <bibkey>xu-etal-2023-towards-zero</bibkey>
      <doi>10.18653/v1/2023.findings-acl.90</doi>
    </paper>
    <paper id="91">
      <title>Grammar-based Decoding for Improved Compositional Generalization in Semantic Parsing</title>
      <author><first>Jing</first><last>Zheng</last><affiliation>Ant Group</affiliation></author>
      <author><first>Jyh-Herng</first><last>Chow</last><affiliation>Ant Group</affiliation></author>
      <author><first>Zhongnan</first><last>Shen</last><affiliation>Ant Technologies, US, inc</affiliation></author>
      <author><first>Peng</first><last>Xu</last><affiliation>Ant Group</affiliation></author>
      <pages>1399-1418</pages>
      <abstract>Sequence-to-sequence (seq2seq) models have achieved great success in semantic parsing tasks, but they tend to struggle on out-of-distribution (OOD) data. Despite recent progress, robust semantic parsing on large-scale tasks with combined challenges from both compositional generalization and natural language variations remains an unsolved problem. To promote research in this area, this work presents CUDON, a large-scale dialogue dataset in Chinese language, particularly designed for evaluating compositional generalization of semantic parsing. The dataset contains about ten thousand multi-turn complex queries, and provides multiple splits with different degrees of train-test distribution divergence. We have investigated improving compositional generalization with grammar-based decodering on this dataset. With specially designed grammars leveraging program schema, we are able to substantially improve accuracy of seq2seq semantic parsers on OOD splits: A LSTM-based parser using a Context-free Grammar (CFG) achieves over 25% higher accuracy than a standard seq2seq baseline; a parser using Tree-Substitution Grammar (TSG) improves parsing speed five to seven times over the CFG parser with only a small accuracy loss. The grammar-based LSTM parsers also outperforms BART- and T5-based seq2seq parsers on the OOD splits, despite having less than one tenth of parameters and no pretraining. We also verified our approach on the SMCalflow-CS dataset, particularly, on the zero-shot learning task.</abstract>
      <url hash="bcb55f75">2023.findings-acl.91</url>
      <bibkey>zheng-etal-2023-grammar</bibkey>
      <doi>10.18653/v1/2023.findings-acl.91</doi>
    </paper>
    <paper id="92">
      <title>Exploiting Rich Textual User-Product Context for Improving Personalized Sentiment Analysis</title>
      <author><first>Chenyang</first><last>Lyu</last><affiliation>Dublin City University</affiliation></author>
      <author><first>Linyi</first><last>Yang</last><affiliation>Westlake University</affiliation></author>
      <author><first>Yue</first><last>Zhang</last><affiliation>Westlake University</affiliation></author>
      <author><first>Yvette</first><last>Graham</last><affiliation>ADAPT, Trinity College Dublin</affiliation></author>
      <author><first>Jennifer</first><last>Foster</last><affiliation>Dublin City University</affiliation></author>
      <pages>1419-1429</pages>
      <abstract>User and product information associated with a review is useful for sentiment polarity prediction. Typical approaches incorporating such information focus on modeling users and products as implicitly learned representation vectors. Most do not exploit the potential of historical reviews, or those that currently do require unnecessary modifications to model architectureor do not make full use of user/product associations. The contribution of this work is twofold: i) a method to explicitly employ historical reviews belonging to the same user/product in initializing representations, and ii) efficient incorporation of textual associations between users and products via a user-product cross-context module. Experiments on the IMDb, Yelp-2013 and Yelp-2014 English benchmarks with BERT, SpanBERT and Longformer pretrained language models show that our approach substantially outperforms previous state-of-the-art.</abstract>
      <url hash="a30f5a1f">2023.findings-acl.92</url>
      <bibkey>lyu-etal-2023-exploiting</bibkey>
      <doi>10.18653/v1/2023.findings-acl.92</doi>
    </paper>
    <paper id="93">
      <title>Efficient Out-of-Domain Detection for Sequence to Sequence Models</title>
      <author><first>Artem</first><last>Vazhentsev</last><affiliation>AIRI, Skoltech</affiliation></author>
      <author><first>Akim</first><last>Tsvigun</last><affiliation>AIRI / Semrush / HSE</affiliation></author>
      <author><first>Roman</first><last>Vashurin</last><affiliation>Skolkovo Institute of Science and Technology</affiliation></author>
      <author><first>Sergey</first><last>Petrakov</last><affiliation>Skolkovo institute of science and technology</affiliation></author>
      <author><first>Daniil</first><last>Vasilev</last><affiliation>HSE</affiliation></author>
      <author><first>Maxim</first><last>Panov</last><affiliation>Technology Innovation Institute</affiliation></author>
      <author><first>Alexander</first><last>Panchenko</last><affiliation>Skolkovo Institue of Science and Technology</affiliation></author>
      <author><first>Artem</first><last>Shelmanov</last><affiliation>Mohamed bin Zayed University of Artificial Intelligence: MBZUAI</affiliation></author>
      <pages>1430-1454</pages>
      <abstract>Sequence-to-sequence (seq2seq) models based on the Transformer architecture have become a ubiquitous tool applicable not only to classical text generation tasks such as machine translation and summarization but also to any other task where an answer can be represented in a form of a finite text fragment (e.g., question answering). However, when deploying a model in practice, we need not only high performance but also an ability to determine cases where the model is not applicable. Uncertainty estimation (UE) techniques provide a tool for identifying out-of-domain (OOD) input where the model is susceptible to errors. State-of-the-art UE methods for seq2seq models rely on computationally heavyweight and impractical deep ensembles. In this work, we perform an empirical investigation of various novel UE methods for large pre-trained seq2seq models T5 and BART on three tasks: machine translation, text summarization, and question answering. We apply computationally lightweight density-based UE methods to seq2seq models and show that they often outperform heavyweight deep ensembles on the task of OOD detection.</abstract>
      <url hash="9ca13af4">2023.findings-acl.93</url>
      <bibkey>vazhentsev-etal-2023-efficient</bibkey>
      <doi>10.18653/v1/2023.findings-acl.93</doi>
    </paper>
    <paper id="94">
      <title>Emotion Cause Extraction on Social Media without Human Annotation</title>
      <author><first>Debin</first><last>Xiao</last><affiliation>Nanjing University of Science and Technology</affiliation></author>
      <author><first>Rui</first><last>Xia</last><affiliation>Nanjing University of Science and Technology</affiliation></author>
      <author><first>Jianfei</first><last>Yu</last><affiliation>Nanjing University of Science and Technology</affiliation></author>
      <pages>1455-1468</pages>
      <abstract>In social media, there is a vast amount of information pertaining to people’s emotions and the corresponding causes. The emotion cause extraction (ECE) from social media data is an important research area that has not been thoroughly explored due to the lack of fine-grained annotations. Early studies referred to either unsupervised rule-based methods or supervised machine learning methods using a number of manually annotated data in specific domains. However, the former suffers from limitations in extraction performance, while the latter is constrained by the availability of fine-grained annotations and struggles to generalize to diverse domains. To address these issues, this paper proposes a new ECE framework on Chinese social media that achieves high extraction performance and generalizability without relying on human annotation. Specifically, we design a more dedicated rule-based system based on constituency parsing tree to discover causal patterns in social media. This system enables us to acquire large amounts of fine-grained annotated data. Next, we train a neural model on the rule-annotated dataset with a specific training strategy to further improve the model’s generalizability. Extensive experiments demonstrate the superiority of our approach over other methods in unsupervised and weakly-supervised settings.</abstract>
      <url hash="36ef462d">2023.findings-acl.94</url>
      <bibkey>xiao-etal-2023-emotion</bibkey>
      <doi>10.18653/v1/2023.findings-acl.94</doi>
    </paper>
    <paper id="95">
      <title>Pseudo Outlier Exposure for Out-of-Distribution Detection using Pretrained Transformers</title>
      <author><first>Jaeyoung</first><last>Kim</last><affiliation>VUNO, Inc.</affiliation></author>
      <author><first>Kyuheon</first><last>Jung</last><affiliation>Pukyong National University</affiliation></author>
      <author><first>Dongbin</first><last>Na</last><affiliation>VUNO Inc.</affiliation></author>
      <author><first>Sion</first><last>Jang</last><affiliation>TEAMLAB</affiliation></author>
      <author><first>Eunbin</first><last>Park</last><affiliation>Pukyong National University</affiliation></author>
      <author><first>Sungchul</first><last>Choi</last><affiliation>Pukyong National University</affiliation></author>
      <pages>1469-1482</pages>
      <abstract>For real-world language applications, detecting an out-of-distribution (OOD) sample is helpful to alert users or reject such unreliable samples. However, modern over-parameterized language models often produce overconfident predictions for both in-distribution (ID) and OOD samples. In particular, language models suffer from OOD samples with a similar semantic representation to ID samples since these OOD samples lie near the ID manifold.A rejection network can be trained with ID and diverse outlier samples to detect test OOD samples, but explicitly collecting auxiliary OOD datasets brings an additional burden for data collection. In this paper, we propose a simple but effective method called Pseudo Outlier Exposure (POE) that constructs a surrogate OOD dataset by sequentially masking tokens related to ID classes. The surrogate OOD sample introduced by POE shows a similar representation to ID data, which is most effective in training a rejection network. Our method does not require any external OOD data and can be easily implemented within off-the-shelf Transformers.A comprehensive comparison with state-of-the-art algorithms demonstrates POE’s competitiveness on several text classification benchmarks.</abstract>
      <url hash="b18dfbb0">2023.findings-acl.95</url>
      <bibkey>kim-etal-2023-pseudo</bibkey>
      <doi>10.18653/v1/2023.findings-acl.95</doi>
    </paper>
    <paper id="96">
      <title>Adversarial Multi-task Learning for End-to-end Metaphor Detection</title>
      <author><first>Shenglong</first><last>Zhang</last><affiliation>Tsinghua University</affiliation></author>
      <author><first>Ying</first><last>Liu</last><affiliation>Department of Chinese language and literature,Tsinghua University</affiliation></author>
      <pages>1483-1497</pages>
      <abstract>Metaphor detection (MD) suffers from limited training data. In this paper, we started with a linguistic rule called Metaphor Identification Procedure and then proposed a novel multi-task learning framework to transfer knowledge in basic sense discrimination (BSD) to MD. BSD is constructed from word sense disambiguation (WSD), which has copious amounts of data. We leverage adversarial training to align the data distributions of MD and BSD in the same feature space, so task-invariant representations can be learned. To capture fine-grained alignment patterns, we utilize the multi-mode structures of MD and BSD. Our method is totally end-to-end and can mitigate the data scarcity problem in MD. Competitive results are reported on four public datasets. Our code and datasets are available.</abstract>
      <url hash="bdc28f98">2023.findings-acl.96</url>
      <bibkey>zhang-liu-2023-adversarial</bibkey>
      <doi>10.18653/v1/2023.findings-acl.96</doi>
    </paper>
    <paper id="97">
      <title><fixed-case>SERENGETI</fixed-case>: Massively Multilingual Language Models for <fixed-case>A</fixed-case>frica</title>
      <author><first>Ife</first><last>Adebara</last><affiliation>University of British Columbia</affiliation></author>
      <author><first>AbdelRahim</first><last>Elmadany</last><affiliation>Natural Language Processing Lab, University of British Columbia (UBC)</affiliation></author>
      <author><first>Muhammad</first><last>Abdul-Mageed</last><affiliation>The University of British Columbia</affiliation></author>
      <author><first>Alcides</first><last>Alcoba Inciarte</last><affiliation>The University of British Columbia</affiliation></author>
      <pages>1498-1537</pages>
      <abstract>Multilingual pretrained language models (mPLMs) acquire valuable, generalizable linguistic information during pretraining and have advanced the state of the art on task-specific finetuning. To date, only ~31 out of ~2,000 African languages are covered in existing language models. We ameliorate this limitation by developing SERENGETI, a set of massively multilingual language model that covers 517 African languages and language varieties. We evaluate our novel models on eight natural language understanding tasks across 20 datasets, comparing to 4 mPLMs that cover 4-23 African languages. SERENGETI outperforms other models on 11 datasets across the eights tasks, achieving 82.27 average F_1. We also perform analyses of errors from our models, which allows us to investigate the influence of language genealogy and linguistic similarity when the models are applied under zero-shot settings. We will publicly release our models for research. Anonymous link</abstract>
      <url hash="4586bc6a">2023.findings-acl.97</url>
      <bibkey>adebara-etal-2023-serengeti</bibkey>
      <doi>10.18653/v1/2023.findings-acl.97</doi>
    </paper>
    <paper id="98">
      <title>Prompt- and Trait Relation-aware Cross-prompt Essay Trait Scoring</title>
      <author><first>Heejin</first><last>Do</last><affiliation>Pohang University of Science and Technology</affiliation></author>
      <author><first>Yunsu</first><last>Kim</last><affiliation>POSTECH</affiliation></author>
      <author><first>Gary Geunbae</first><last>Lee</last><affiliation>Pohang University of Science and Technology (POSTECH)</affiliation></author>
      <pages>1538-1551</pages>
      <abstract>Automated essay scoring (AES) aims to score essays written for a given prompt, which defines the writing topic. Most existing AES systems assume to grade essays of the same prompt as used in training and assign only a holistic score. However, such settings conflict with real-education situations; pre-graded essays for a particular prompt are lacking, and detailed trait scores of sub-rubrics are required. Thus, predicting various trait scores of unseen-prompt essays (called cross-prompt essay trait scoring) is a remaining challenge of AES. In this paper, we propose a robust model: prompt- and trait relation-aware cross-prompt essay trait scorer. We encode prompt-aware essay representation by essay-prompt attention and utilizing the topic-coherence feature extracted by the topic-modeling mechanism without access to labeled data; therefore, our model considers the prompt adherence of an essay, even in a cross-prompt setting. To facilitate multi-trait scoring, we design trait-similarity loss that encapsulates the correlations of traits. Experiments prove the efficacy of our model, showing state-of-the-art results for all prompts and traits. Significant improvements in low-resource-prompt and inferior traits further indicate our model’s strength.</abstract>
      <url hash="fda94d32">2023.findings-acl.98</url>
      <bibkey>do-etal-2023-prompt</bibkey>
      <doi>10.18653/v1/2023.findings-acl.98</doi>
    </paper>
    <paper id="99">
      <title><fixed-case>A</fixed-case>ug<fixed-case>ESC</fixed-case>: Dialogue Augmentation with Large Language Models for Emotional Support Conversation</title>
      <author><first>Chujie</first><last>Zheng</last><affiliation>Tsinghua University</affiliation></author>
      <author><first>Sahand</first><last>Sabour</last><affiliation>Tsinghua University</affiliation></author>
      <author><first>Jiaxin</first><last>Wen</last><affiliation>Tsinghua University</affiliation></author>
      <author><first>Zheng</first><last>Zhang</last><affiliation>Tsinghua University</affiliation></author>
      <author><first>Minlie</first><last>Huang</last><affiliation>Tsinghua University</affiliation></author>
      <pages>1552-1568</pages>
      <abstract>Crowdsourced dialogue corpora are usually limited in scale and topic coverage due to the expensive cost of data curation. This would hinder the generalization of downstream dialogue models to open-domain topics. In this work, we leverage large language models for dialogue augmentation in the task of emotional support conversation (ESC). By treating dialogue augmentation as a dialogue completion task, we prompt a fine-tuned language model to complete full dialogues from available dialogue posts of various topics, which are then postprocessed based on heuristics. Applying this approach, we construct AugESC, an augmented dataset for the ESC task, which largely extends the scale and topic coverage of the crowdsourced ESConv corpus. Through comprehensive human evaluation, we demonstrate that our approach is superior to strong baselines of dialogue augmentation and that AugESC has comparable dialogue quality to the crowdsourced corpus. We also conduct human interactive evaluation and prove that post-training on AugESC improves downstream dialogue models’ generalization ability to open-domain topics. These results suggest the utility of AugESC and highlight the potential of large language models in improving data-scarce dialogue generation tasks.</abstract>
      <url hash="69fec7a7">2023.findings-acl.99</url>
      <bibkey>zheng-etal-2023-augesc</bibkey>
      <doi>10.18653/v1/2023.findings-acl.99</doi>
    </paper>
    <paper id="100">
      <title><tex-math>2*n</tex-math> is better than <tex-math>n^2</tex-math>: Decomposing Event Coreference Resolution into Two Tractable Problems</title>
      <author><first>Shafiuddin Rehan</first><last>Ahmed</last><affiliation>University of Colorado Boulder</affiliation></author>
      <author><first>Abhijnan</first><last>Nath</last><affiliation>Colorado State University</affiliation></author>
      <author><first>James H.</first><last>Martin</last><affiliation>University of Colorado Boulder</affiliation></author>
      <author><first>Nikhil</first><last>Krishnaswamy</last><affiliation>Colorado State University</affiliation></author>
      <pages>1569-1583</pages>
      <abstract>Event Coreference Resolution (ECR) is the task of linking mentions of the same event either within or across documents. Most mention pairs are not coreferent, yet many that are coreferent can be identified through simple techniques such as lemma matching of the event triggers or the sentences in which they appear. Existing methods for training coreference systems sample from a largely skewed distribution, making it difficult for the algorithm to learn coreference beyond surface matching. Additionally, these methods are intractable because of the quadratic operations needed. To address these challenges, we break the problem of ECR into two parts: a) a heuristic to efficiently filter out a large number of non-coreferent pairs, and b) a training approach on a balanced set of coreferent and non-coreferent mention pairs. By following this approach, we show that we get comparable results to the state of the art on two popular ECR datasets while significantly reducing compute requirements. We also analyze the mention pairs that are “hard” to accurately classify as coreferent or non-coreferentcode repo: <tex-math>\mathtt{github.com/ahmeshaf/lemma\_ce\_coref}</tex-math>.</abstract>
      <url hash="320a6e84">2023.findings-acl.100</url>
      <bibkey>ahmed-etal-2023-2</bibkey>
      <revision id="1" href="2023.findings-acl.100v1" hash="a6fb5982"/>
      <revision id="2" href="2023.findings-acl.100v2" hash="320a6e84" date="2023-07-30">Figure legend fix.</revision>
      <doi>10.18653/v1/2023.findings-acl.100</doi>
    </paper>
    <paper id="101">
      <title><fixed-case>SCCS</fixed-case>: Semantics-Consistent Cross-domain Summarization via Optimal Transport Alignment</title>
      <author><first>Jielin</first><last>Qiu</last><affiliation>Carnegie Mellon University</affiliation></author>
      <author><first>Jiacheng</first><last>Zhu</last><affiliation>Carnegie Mellon University</affiliation></author>
      <author><first>Mengdi</first><last>Xu</last><affiliation>Carnegie Mellon University</affiliation></author>
      <author><first>Franck</first><last>Dernoncourt</last><affiliation>Adobe Research</affiliation></author>
      <author><first>Trung</first><last>Bui</last><affiliation>Adobe Research</affiliation></author>
      <author><first>Zhaowen</first><last>Wang</last><affiliation>Adobe Inc.</affiliation></author>
      <author id="bo-li"><first>Bo</first><last>Li</last><affiliation>University of Illinois at Urbana-Champaign</affiliation></author>
      <author><first>Ding</first><last>Zhao</last><affiliation>CMU</affiliation></author>
      <author><first>Hailin</first><last>Jin</last><affiliation>Adobe Research</affiliation></author>
      <pages>1584-1601</pages>
      <abstract>Multimedia summarization with multimodal output (MSMO) is a recently explored application in language grounding. It plays an essential role in real-world applications, i.e., automatically generating cover images and titles for news articles or providing introductions to online videos. However, existing methods extract features from the whole video and article and use fusion methods to select the representative one, thus usually ignoring the critical structure and varying semantics with video/document. In this work, we propose a Semantics-Consistent Cross-domain Summarization (SCCS) model based on optimal transport alignment with visual and textual segmentation. Our method first decomposes both videos and articles into segments in order to capture the structural semantics, and then follows a cross-domain alignment objective with optimal transport distance, which leverages multimodal interaction to match and select the visual and textual summary. We evaluated our method on three MSMO datasets, and achieved performance improvement by 8% &amp; 6% of textual and 6.6% &amp;5.7% of video summarization, respectively, which demonstrated the effectiveness of our method in producing high-quality multimodal summaries.</abstract>
      <url hash="9dc1d0cf">2023.findings-acl.101</url>
      <bibkey>qiu-etal-2023-sccs</bibkey>
      <doi>10.18653/v1/2023.findings-acl.101</doi>
    </paper>
    <paper id="102">
      <title>General-to-Specific Transfer Labeling for Domain Adaptable Keyphrase Generation</title>
      <author><first>Rui</first><last>Meng</last><affiliation>Salesforce Research</affiliation></author>
      <author><first>Tong</first><last>Wang</last><affiliation>Microsoft Research</affiliation></author>
      <author><first>Xingdi</first><last>Yuan</last><affiliation>Microsoft Research</affiliation></author>
      <author><first>Yingbo</first><last>Zhou</last><affiliation>Salesforce Research</affiliation></author>
      <author><first>Daqing</first><last>He</last><affiliation>University of Pittsburgh</affiliation></author>
      <pages>1602-1618</pages>
      <abstract>Training keyphrase generation (KPG) models require a large amount of annotated data, which can be prohibitively expensive and often limited to specific domains. In this study, we first demonstrate that large distribution shifts among different domains severely hinder the transferability of KPG models. We then propose a three-stage pipeline, which gradually guides KPG models’ learning focus from general syntactical features to domain-related semantics, in a data-efficient manner. With domain-general phrase pre-training, we pre-train Sequence-to-Sequence models with generic phrase annotations that are widely available on the web, which enables the models to generate phrases in a wide range of domains. The resulting model is then applied in the Transfer Labeling stage to produce domain-specific pseudo keyphrases, which help adapt models to a new domain. Finally, we fine-tune the model with limited data with true labels to fully adapt it to the target domain. Our experiment results show that the proposed process can produce good quality keyphrases in new domains and achieve consistent improvements after adaptation with limited in-domain annotated data. All code and datasets are available at <url>https://github.com/memray/OpenNMT-kpg-release</url>.</abstract>
      <url hash="3e1ec75d">2023.findings-acl.102</url>
      <bibkey>meng-etal-2023-general</bibkey>
      <doi>10.18653/v1/2023.findings-acl.102</doi>
    </paper>
    <paper id="103">
      <title><fixed-case>E</fixed-case>-<fixed-case>NER</fixed-case>: Evidential Deep Learning for Trustworthy Named Entity Recognition</title>
      <author><first>Zhen</first><last>Zhang</last><affiliation>Nankai University</affiliation></author>
      <author><first>Mengting</first><last>Hu</last><affiliation>Nankai University</affiliation></author>
      <author><first>Shiwan</first><last>Zhao</last><affiliation>Independent Researcher</affiliation></author>
      <author><first>Minlie</first><last>Huang</last><affiliation>Tsinghua University</affiliation></author>
      <author><first>Haotian</first><last>Wang</last><affiliation>Nankai University</affiliation></author>
      <author><first>Lemao</first><last>Liu</last><affiliation>Tencent AI Lab</affiliation></author>
      <author><first>Zhirui</first><last>Zhang</last><affiliation>Tencent AI Lab</affiliation></author>
      <author><first>Zhe</first><last>Liu</last><affiliation>University of Luxembourg</affiliation></author>
      <author><first>Bingzhe</first><last>Wu</last><affiliation>Tencent AI Lab</affiliation></author>
      <pages>1619-1634</pages>
      <abstract>Most named entity recognition (NER) systems focus on improving model performance, ignoring the need to quantify model uncertainty, which is critical to the reliability of NER systems in open environments. Evidential deep learning (EDL) has recently been proposed as a promising solution to explicitly model predictive uncertainty for classification tasks. However, directly applying EDL to NER applications faces two challenges, i.e., the problems of sparse entities and OOV/OOD entities in NER tasks. To address these challenges, we propose a trustworthy NER framework named E-NER by introducing two uncertainty-guided loss terms to the conventional EDL, along with a series of uncertainty-guided training strategies. Experiments show that E-NER can be applied to multiple NER paradigms to obtain accurate uncertainty estimation. Furthermore, compared to state-of-the-art baselines, the proposed method achieves a better OOV/OOD detection performance and better generalization ability on OOV entities.</abstract>
      <url hash="8b90c0c1">2023.findings-acl.103</url>
      <bibkey>zhang-etal-2023-e</bibkey>
      <doi>10.18653/v1/2023.findings-acl.103</doi>
    </paper>
    <paper id="104">
      <title><fixed-case>LMC</fixed-case>ap: Few-shot Multilingual Image Captioning by Retrieval Augmented Language Model Prompting</title>
      <author><first>Rita</first><last>Ramos</last><affiliation>Instituto Superior Tecnico, University of Lisbon</affiliation></author>
      <author><first>Bruno</first><last>Martins</last><affiliation>IST and INESC-ID</affiliation></author>
      <author><first>Desmond</first><last>Elliott</last><affiliation>University of Copenhagen</affiliation></author>
      <pages>1635-1651</pages>
      <abstract>Multilingual image captioning has recently been tackled by training with large-scale machine translated data, which is an expensive, noisy, and time-consuming process. Without requiring any multilingual caption data, we propose LMCap, an image-blind few-shot multilingual captioning model that works by prompting a language model with retrieved captions. Specifically, instead of following the standard encoder-decoder paradigm, given an image, LMCap first retrieves the captions of similar images using a multilingual CLIP encoder. These captions are then combined into a prompt for an XGLM decoder, in order to generate captions in the desired language. In other words, the generation model does not directly process the image, instead it processes retrieved captions. Experiments on the XM3600 dataset of geographically diverse images show that our model is competitive with fully-supervised multilingual captioning models, without requiring any supervised training on any captioning data.</abstract>
      <url hash="04d10200">2023.findings-acl.104</url>
      <bibkey>ramos-etal-2023-lmcap</bibkey>
      <doi>10.18653/v1/2023.findings-acl.104</doi>
    </paper>
    <paper id="105">
      <title>Boosting Text Augmentation via Hybrid Instance Filtering Framework</title>
      <author><first>Heng</first><last>Yang</last><affiliation>Faculty of Environment, Science and Economy, University of Exeter</affiliation></author>
      <author><first>Ke</first><last>Li</last><affiliation>University of Exeter</affiliation></author>
      <pages>1652-1669</pages>
      <abstract>Text augmentation is an effective technique for addressing the problem of insufficient data in natural language processing. However, existing text augmentation methods tend to focus on few-shot scenarios and usually perform poorly on large public datasets. Our research indicates that existing augmentation methods often generate instances with shifted feature spaces, which leads to a drop in performance on the augmented data (for example, EDA generally loses approximately 2% in aspect-based sentiment classification). To address this problem, we propose a hybrid instance-filtering framework (BoostAug) based on pre-trained language models that can maintain a similar feature space with natural datasets. BoostAug is transferable to existing text augmentation methods (such as synonym substitution and back translation) and significantly improves the augmentation performance by 2-3% in classification accuracy. Our experimental results on three classification tasks and nine public datasets show that BoostAug addresses the performance drop problem and outperforms state-of-the-art text augmentation methods. Additionally, we release the code to help improve existing augmentation methods on large datasets.</abstract>
      <url hash="db28d46a">2023.findings-acl.105</url>
      <bibkey>yang-li-2023-boosting</bibkey>
      <doi>10.18653/v1/2023.findings-acl.105</doi>
    </paper>
    <paper id="106">
      <title>Gradient-Boosted Decision Tree for Listwise Context Model in Multimodal Review Helpfulness Prediction</title>
      <author><first>Thong</first><last>Nguyen</last><affiliation>National University of Singapore</affiliation></author>
      <author><first>Xiaobao</first><last>Wu</last><affiliation>Nanyang Technological University</affiliation></author>
      <author><first>Xinshuai</first><last>Dong</last><affiliation>Carnegie Mellon University</affiliation></author>
      <author><first>Cong-Duy</first><last>Nguyen</last><affiliation>Nanyang Technological University</affiliation></author>
      <author><first>Zhen</first><last>Hai</last><affiliation>Data Analytics Department, Institute for Infocomm Research (I2R), A*STAR, Singapore</affiliation></author>
      <author><first>Lidong</first><last>Bing</last><affiliation>Alibaba DAMO Academy</affiliation></author>
      <author><first>Anh Tuan</first><last>Luu</last><affiliation>Nanyang Technological University, Singapore</affiliation></author>
      <pages>1670-1696</pages>
      <abstract>Multimodal Review Helpfulness Prediction (MRHP) aims to rank product reviews based on predicted helpfulness scores and has been widely applied in e-commerce via presenting customers with useful reviews. Previous studies commonly employ fully-connected neural networks (FCNNs) as the final score predictor and pairwise loss as the training objective. However, FCNNs have been shown to perform inefficient splitting for review features, making the model difficult to clearly differentiate helpful from unhelpful reviews. Furthermore, pairwise objective, which works on review pairs, may not completely capture the MRHP goal to produce the ranking for the entire review list, and possibly induces low generalization during testing. To address these issues, we propose a listwise attention network that clearly captures the MRHP ranking context and a listwise optimization objective that enhances model generalization. We further propose gradient-boosted decision tree as the score predictor to efficaciously partition product reviews’ representations. Extensive experiments demonstrate that our method achieves state-of-the-art results and polished generalization performance on two large-scale MRHP benchmark datasets.</abstract>
      <url hash="7f62b029">2023.findings-acl.106</url>
      <bibkey>nguyen-etal-2023-gradient</bibkey>
      <doi>10.18653/v1/2023.findings-acl.106</doi>
    </paper>
    <paper id="107">
      <title>Extract and Attend: Improving Entity Translation in Neural Machine Translation</title>
      <author><first>Zixin</first><last>Zeng</last><affiliation>Peking University</affiliation></author>
      <author><first>Rui</first><last>Wang</last><affiliation>Microsoft</affiliation></author>
      <author><first>Yichong</first><last>Leng</last><affiliation>University of Science and Technology of China</affiliation></author>
      <author><first>Junliang</first><last>Guo</last><affiliation>Microsoft Research</affiliation></author>
      <author><first>Shufang</first><last>Xie</last><affiliation>Microsoft</affiliation></author>
      <author><first>Xu</first><last>Tan</last><affiliation>Microsoft Research Asia</affiliation></author>
      <author><first>Tao</first><last>Qin</last><affiliation>Microsoft Research Asia</affiliation></author>
      <author><first>Tie-Yan</first><last>Liu</last><affiliation>Microsoft Research Asia</affiliation></author>
      <pages>1697-1710</pages>
      <abstract>While Neural Machine Translation (NMT) has achieved great progress in recent years, it still suffers from inaccurate translation of entities (e.g., person/organization name, location), due to the lack of entity training instances. When we humans encounter an unknown entity during translation, we usually first look up in a dictionary and then organize the entity translation together with the translations of other parts to form a smooth target sentence. Inspired by this translation process, we propose an Extract-and-Attend approach to enhance entity translation in NMT, where the translation candidates of source entities are first extracted from a dictionary and then attended to by the NMT model to generate the target sentence. Specifically, the translation candidates are extracted by first detecting the entities in a source sentence and then translating the entities through looking up in a dictionary. Then, the extracted candidates are added as a prefix of the decoder input to be attended to by the decoder when generating the target sentence through self-attention. Experiments conducted on En-Zh and En-Ru demonstrate that the proposed method is effective on improving both the translation accuracy of entities and the overall translation quality, with up to 35% reduction on entity error rate and 0.85 gain on BLEU and 13.8 gain on COMET.</abstract>
      <url hash="8b420ebe">2023.findings-acl.107</url>
      <bibkey>zeng-etal-2023-extract</bibkey>
      <doi>10.18653/v1/2023.findings-acl.107</doi>
    </paper>
    <paper id="108">
      <title>Real-World Compositional Generalization with Disentangled Sequence-to-Sequence Learning</title>
      <author><first>Hao</first><last>Zheng</last><affiliation>The University of Edinburgh</affiliation></author>
      <author><first>Mirella</first><last>Lapata</last><affiliation>School of Informatics, University of Edinburgh</affiliation></author>
      <pages>1711-1725</pages>
      <abstract>Compositional generalization is a basic mechanism in human language learning, which current neural networks struggle with. A recently proposed Disentangled sequence-to-sequence model (Dangle) shows promising generalization capability by learning specialized encodings for each decoding step. We introduce two key modifications to this model which encourage more disentangled representations and improve its compute and memory efficiency, allowing us to tackle compositional generalization in a more realistic setting. Specifically, instead of adaptively re-encoding source keys and values at each time step, we disentangle their representations and only re-encode keys periodically, at some interval. Our new architecture leads to better generalization performance across existing tasks and datasets, and a new machine translation benchmark which we create by detecting naturally occurring compositional patterns in relation to a training set. We show this methodology better emulates real-world requirements than artificial challenges.</abstract>
      <url hash="c1f70713">2023.findings-acl.108</url>
      <bibkey>zheng-lapata-2023-real</bibkey>
      <doi>10.18653/v1/2023.findings-acl.108</doi>
    </paper>
    <paper id="109">
      <title>Cross-lingual <fixed-case>AMR</fixed-case> Aligner: Paying Attention to Cross-Attention</title>
      <author><first>Abelardo Carlos</first><last>Martínez Lorenzo</last><affiliation>Sapienza University</affiliation></author>
      <author><first>Pere Lluís</first><last>Huguet Cabot</last><affiliation>Sapienza University of Rome</affiliation></author>
      <author><first>Roberto</first><last>Navigli</last><affiliation>Sapienza University of Rome</affiliation></author>
      <pages>1726-1742</pages>
      <abstract>This paper introduces a novel aligner for Abstract Meaning Representation (AMR) graphs that can scale cross-lingually, and is thus capable of aligning units and spans in sentences of different languages. Our approach leverages modern Transformer-based parsers, which inherently encode alignment information in their cross-attention weights, allowing us to extract this information during parsing. This eliminates the need for English-specific rules or the Expectation Maximization (EM) algorithm that have been used in previous approaches. In addition, we propose a guided supervised method using alignment to further enhance the performance of our aligner. We achieve state-of-the-art results in the benchmarks for AMR alignment and demonstrate our aligner’s ability to obtain them across multiple languages. Our code will be available at [<url>https://www.github.com/babelscape/AMR-alignment</url>](<url>https://www.github.com/babelscape/AMR-alignment</url>).</abstract>
      <url hash="0c5e707b">2023.findings-acl.109</url>
      <bibkey>martinez-lorenzo-etal-2023-cross</bibkey>
      <doi>10.18653/v1/2023.findings-acl.109</doi>
    </paper>
    <paper id="110">
      <title>Zero-Shot Text Classification via Self-Supervised Tuning</title>
      <author><first>Chaoqun</first><last>Liu</last><affiliation>Nanyang Technological University, Singapore; Alibaba DAMO Academy</affiliation></author>
      <author><first>Wenxuan</first><last>Zhang</last><affiliation>DAMO Academy, Alibaba Group</affiliation></author>
      <author><first>Guizhen</first><last>Chen</last><affiliation>Nanyang Technological University at Singapore, Alibaba DAMO Academy</affiliation></author>
      <author><first>Xiaobao</first><last>Wu</last><affiliation>Nanyang Technological University</affiliation></author>
      <author><first>Anh Tuan</first><last>Luu</last><affiliation>Nanyang Technological University, Singapore</affiliation></author>
      <author><first>Chip Hong</first><last>Chang</last><affiliation>Nanyang Technological University</affiliation></author>
      <author><first>Lidong</first><last>Bing</last><affiliation>Alibaba DAMO Academy</affiliation></author>
      <pages>1743-1761</pages>
      <abstract>Existing solutions to zero-shot text classification either conduct prompting with pre-trained language models, which is sensitive to the choices of templates, or rely on large-scale annotated data of relevant tasks for meta-tuning. In this work, we propose a new paradigm based on self-supervised learning to solve zero-shot text classification tasks by tuning the language models with unlabeled data, called self-supervised tuning. By exploring the inherent structure of free texts, we propose a new learning objective called first sentence prediction to bridge the gap between unlabeled data and text classification tasks. After tuning the model to learn to predict the first sentence in a paragraph based on the rest, the model is able to conduct zero-shot inference on unseen tasks such as topic classification and sentiment analysis. Experimental results show that our model outperforms the state-of-the-art baselines on 7 out of 10 tasks. Moreover, the analysis reveals that our model is less sensitive to the prompt design. Our code and pre-trained models are publicly available at <url>https://github.com/DAMO-NLP-SG/SSTuning</url>.</abstract>
      <url hash="e5eb2104">2023.findings-acl.110</url>
      <bibkey>liu-etal-2023-zero</bibkey>
      <doi>10.18653/v1/2023.findings-acl.110</doi>
    </paper>
    <paper id="111">
      <title>Logical Transformers: Infusing Logical Structures into Pre-Trained Language Models</title>
      <author><first>Borui</first><last>Wang</last><affiliation>Yale University</affiliation></author>
      <author><first>Qiuyuan</first><last>Huang</last><affiliation>Microsoft Research, Redmond</affiliation></author>
      <author><first>Budhaditya</first><last>Deb</last><affiliation>Microsoft Corporation</affiliation></author>
      <author><first>Aaron</first><last>Halfaker</last><affiliation>Microsoft</affiliation></author>
      <author><first>Liqun</first><last>Shao</last><affiliation>Microsoft</affiliation></author>
      <author><first>Daniel</first><last>McDuff</last><affiliation>Google</affiliation></author>
      <author><first>Ahmed Hassan</first><last>Awadallah</last><affiliation>Microsoft Research</affiliation></author>
      <author><first>Dragomir</first><last>Radev</last><affiliation>Yale University</affiliation></author>
      <author><first>Jianfeng</first><last>Gao</last><affiliation>Microsoft Research, Redmond</affiliation></author>
      <pages>1762-1773</pages>
      <abstract>Natural language contains rich logical structures and logical information, and correctly detecting and accurately understanding these logical structures and information underlying natural language texts is very crucial for NLP models’ performance on many important NLU and NLG tasks. Existing pre-trained language models based on the transformer architecture mostly adopt a classical design for constructing their input embeddings that ignores the logical structures underlying natural language texts, thus limiting their ability to better capture and encode key logical information in the input sequences. To overcome such limitations, in this paper we first propose a novel approach to construct logic-aware input embeddings for transformer language models through a combination of logic detection, logic mapping and hierarchical logical projections, and then develop a corresponding new modeling paradigm that can upgrade existing transformer language models into logical transformers to boost their performance on different NLU and NLG tasks. Our empirical experiments on four important and challenging NLU and NLG tasks demonstrate that our proposed logical transformer language models can achieve superior performance over their baseline transformer models through a deeper understanding of the logical structures of texts.</abstract>
      <url hash="9e949077">2023.findings-acl.111</url>
      <bibkey>wang-etal-2023-logical</bibkey>
      <doi>10.18653/v1/2023.findings-acl.111</doi>
    </paper>
    <paper id="112">
      <title>Large Language Models with Controllable Working Memory</title>
      <author><first>Daliang</first><last>Li</last><affiliation>Google Research</affiliation></author>
      <author><first>Ankit Singh</first><last>Rawat</last><affiliation>Google Research</affiliation></author>
      <author><first>Manzil</first><last>Zaheer</last><affiliation>Google Inc</affiliation></author>
      <author><first>Xin</first><last>Wang</last><affiliation>Google Inc</affiliation></author>
      <author><first>Michal</first><last>Lukasik</last><affiliation>Google Research</affiliation></author>
      <author><first>Andreas</first><last>Veit</last><affiliation>Google</affiliation></author>
      <author><first>Felix</first><last>Yu</last><affiliation>Google</affiliation></author>
      <author><first>Sanjiv</first><last>Kumar</last><affiliation>Google Research</affiliation></author>
      <pages>1774-1793</pages>
      <abstract>Large language models (LLMs) have led to a series of breakthroughs in natural language processing (NLP), partly owing to the massive amounts of world knowledge they memorize during pretraining. While many downstream applications provide the model with an informational context to aid its underlying task, how the model’s world knowledge interacts with the factual information presented in the context remains under explored. As a desirable behavior, an LLM should give precedence to the context whenever it contains task-relevant information that conflicts with the model’s memorized knowledge. This enables model predictions to be grounded in the context, which then facilitates updating specific model predictions without frequently retraining the model. By contrast, when the context is irrelevant to the task, the model should ignore it and fall back on its internal knowledge. In this paper, we undertake a first joint study of the aforementioned two properties, namely controllability and robustness, in the context of LLMs. We demonstrate that state-of-the-art T5 and PaLM models (both pretrained and finetuned) could exhibit low controllability and robustness that does not improve with increasing the model size. As a solution, we propose a simple yet effective method – knowledge aware finetuning (KAFT) – to strengthen both controllability and robustness by injecting counterfactual and irrelevant contexts to standard supervised datasets. Our comprehensive evaluation showcases the utility of KAFT across model architectures and sizes.</abstract>
      <url hash="2d3e8d2b">2023.findings-acl.112</url>
      <bibkey>li-etal-2023-large</bibkey>
      <doi>10.18653/v1/2023.findings-acl.112</doi>
    </paper>
    <paper id="113">
      <title>A Unified Evaluation Framework for Novelty Detection and Accommodation in <fixed-case>NLP</fixed-case> with an Instantiation in Authorship Attribution</title>
      <author><first>Neeraj</first><last>Varshney</last><affiliation>Arizona State University</affiliation></author>
      <author><first>Himanshu</first><last>Gupta</last><affiliation>Arizona State University</affiliation></author>
      <author><first>Eric</first><last>Robertson</last><affiliation>PAR Government</affiliation></author>
      <author><first>Bing</first><last>Liu</last><affiliation>University of Illinois at Chicago</affiliation></author>
      <author><first>Chitta</first><last>Baral</last><affiliation>Arizona State University</affiliation></author>
      <pages>1794-1818</pages>
      <abstract>State-of-the-art natural language processing models have been shown to achieve remarkable performance in ‘closed-world’ settings where all the labels in the evaluation set are known at training time. However, in real-world settings, ‘novel’ instances that do not belong to any known class are often observed. This renders the ability to deal with novelties crucial. To initiate a systematic research in this important area of ‘dealing with novelties’, we introduce NoveltyTask, a multi-stage task to evaluate a system’s performance on pipelined novelty ‘detection’ and ‘accommodation’ tasks. We provide mathematical formulation of NoveltyTask and instantiate it with the authorship attribution task that pertains to identifying the correct author of a given text. We use amazon reviews corpus and compile a large dataset (consisting of 250k instances across 200 authors/labels) for NoveltyTask. We conduct comprehensive experiments and explore several baseline methods for the task. Our results show that the methods achieve considerably low performance making the task challenging and leaving sufficient room for improvement. Finally, we believe our work will encourage research in this underexplored area of dealing with novelties, an important step en route to developing robust systems.</abstract>
      <url hash="717bf4d5">2023.findings-acl.113</url>
      <bibkey>varshney-etal-2023-unified</bibkey>
      <doi>10.18653/v1/2023.findings-acl.113</doi>
    </paper>
    <paper id="114">
      <title><fixed-case>CDA</fixed-case>: A Contrastive Data Augmentation Method for <fixed-case>A</fixed-case>lzheimer’s Disease Detection</title>
      <author><first>Junwen</first><last>Duan</last><affiliation>Central South University</affiliation></author>
      <author><first>Fangyuan</first><last>Wei</last><affiliation>Central South University</affiliation></author>
      <author><first>Jin</first><last>Liu</last><affiliation>Central South University</affiliation></author>
      <author><first>Hongdong</first><last>Li</last><affiliation>Central South University</affiliation></author>
      <author><first>Tianming</first><last>Liu</last><affiliation>University of Georgia</affiliation></author>
      <author><first>Jianxin</first><last>Wang</last><affiliation>Central South University</affiliation></author>
      <pages>1819-1826</pages>
      <abstract>Alzheimer’s Disease (AD) is a neurodegenerative disorder that significantly impacts a patient’s ability to communicate and organize language. Traditional methods for detecting AD, such as physical screening or neurological testing, can be challenging and time-consuming. Recent research has explored the use of deep learning techniques to distinguish AD patients from non-AD patients by analysing the spontaneous speech. These models, however, are limited by the availability of data. To address this, we propose a novel contrastive data augmentation method, which simulates the cognitive impairment of a patient by randomly deleting a proportion of text from the transcript to create negative samples. The corrupted samples are expected to be in worse conditions than the original by a margin. Experimental results on the benchmark ADReSS Challenge dataset demonstrate that our model achieves the best performance among language-based models.</abstract>
      <url hash="8edf960d">2023.findings-acl.114</url>
      <bibkey>duan-etal-2023-cda</bibkey>
      <doi>10.18653/v1/2023.findings-acl.114</doi>
    </paper>
    <paper id="115">
      <title>Disentangling Aspect and Stance via a <fixed-case>S</fixed-case>iamese Autoencoder for Aspect Clustering of Vaccination Opinions</title>
      <author><first>Lixing</first><last>Zhu</last><affiliation>Department of Computer Science, University of Warwick</affiliation></author>
      <author><first>Runcong</first><last>Zhao</last><affiliation>University of Warwick</affiliation></author>
      <author><first>Gabriele</first><last>Pergola</last><affiliation>University of Warwick</affiliation></author>
      <author><first>Yulan</first><last>He</last><affiliation>King’s College London</affiliation></author>
      <pages>1827-1842</pages>
      <abstract>Mining public opinions about vaccines from social media has been increasingly relevant to analyse trends in public debates and to provide quick insights to policy-makers. However, the application of existing models has been hindered by the wide variety of users’ attitudes and the new aspects continuously arising in the public debate. Existing approaches, frequently framed via well-known tasks, such as aspect classification or text span detection, make direct usage of the supervision information constraining the models to predefined aspect classes, while still not distinguishing those aspects from users’ stances. As a result, this has significantly hindered the dynamic integration of new aspects. We thus propose a model, namely Disentangled Opinion Clustering (DOC), for vaccination opinion mining from social media. DOC is able to disentangle users’ stances from opinions via a disentangling attention mechanism and a Swapping-Autoencoder, and is designed to process unseen aspect categories via a clustering approach, leveraging clustering-friendly representations induced by out-of-the-box Sentence-BERT encodings and disentangling mechanisms. We conduct a thorough experimental assessment demonstrating the benefit of the disentangling mechanisms and cluster-based approach on both the quality of aspect clusters and the generalization across new aspect categories, outperforming existing methodologies on aspect-based opinion mining.</abstract>
      <url hash="cb8824ad">2023.findings-acl.115</url>
      <bibkey>zhu-etal-2023-disentangling</bibkey>
      <doi>10.18653/v1/2023.findings-acl.115</doi>
    </paper>
    <paper id="116">
      <title>Temporal Relation Classification using <fixed-case>B</fixed-case>oolean Question Answering</title>
      <author><first>Omer</first><last>Cohen</last><affiliation>Reichman University</affiliation></author>
      <author><first>Kfir</first><last>Bar</last><affiliation>College of Management Academic Studies</affiliation></author>
      <pages>1843-1852</pages>
      <abstract>Classifying temporal relations between a pair of events is crucial to natural language understanding and a well-known natural language processing task. Given a document and two event mentions, the task is aimed at finding which one started first. We propose an efficient approach for temporal relation classification (TRC) using a boolean question answering (QA) model which we fine-tune on questions that we carefully design based on the TRC annotation guidelines, thereby mimicking the way human annotators approach the task. Our new QA-based TRC model outperforms previous state-of-the-art results by 2.4%.</abstract>
      <url hash="f54005c7">2023.findings-acl.116</url>
      <bibkey>cohen-bar-2023-temporal</bibkey>
      <doi>10.18653/v1/2023.findings-acl.116</doi>
    </paper>
    <paper id="117">
      <title>Are Synonym Substitution Attacks Really Synonym Substitution Attacks?</title>
      <author><first>Cheng-Han</first><last>Chiang</last><affiliation>National Taiwan University</affiliation></author>
      <author><first>Hung-yi</first><last>Lee</last><affiliation>National Taiwan University (NTU)</affiliation></author>
      <pages>1853-1878</pages>
      <abstract>In this paper, we explore the following question: Are synonym substitution attacks really synonym substitution attacks (SSAs)?We approach this question by examining how SSAs replace words in the original sentence and show that there are still unresolved obstacles that make current SSAs generate invalid adversarial samples. We reveal that four widely used word substitution methods generate a large fraction of invalid substitution words that are ungrammatical or do not preserve the original sentence’s semantics. Next, we show that the semantic and grammatical constraints used in SSAs for detecting invalid word replacements are highly insufficient in detecting invalid adversarial samples.</abstract>
      <url hash="a2046bdb">2023.findings-acl.117</url>
      <bibkey>chiang-lee-2023-synonym</bibkey>
      <doi>10.18653/v1/2023.findings-acl.117</doi>
    </paper>
    <paper id="118">
      <title><fixed-case>D</fixed-case>iv<fixed-case>HSK</fixed-case>: Diverse Headline Generation using Self-Attention based Keyword Selection</title>
      <author><first>Venkatesh</first><last>E</last><affiliation>IIT Hyderabad</affiliation></author>
      <author><first>Kaushal</first><last>Maurya</last><affiliation>IIT Hyderabad</affiliation></author>
      <author><first>Deepak</first><last>Kumar</last><affiliation>SRIB</affiliation></author>
      <author><first>Maunendra Sankar</first><last>Desarkar</last><affiliation>IIT Hyderabad</affiliation></author>
      <pages>1879-1891</pages>
      <abstract>Diverse headline generation is an NLP task where given a news article, the goal is to generate multiple headlines that are true to the content of the article but are different among themselves. This task aims to exhibit and exploit semantically similar one-to-many relationships between a source news article and multiple target headlines. Toward this, we propose a novel model called DIVHSK. It has two components:KEYSELECT for selecting the important keywords, and SEQGEN, for finally generating the multiple diverse headlines. In KEYSELECT, we cluster the self-attention heads of the last layer of the pre-trained encoder and select the most-attentive theme and general keywords from the source article. Then, cluster-specific keyword sets guide the SEQGEN, a pre-trained encoder-decoder model, to generate diverse yet semantically similar headlines. The proposed model consistently outperformed existing literature and our strong baselines and emerged as a state-of-the-art model. We have also created a high-quality multi-reference headline dataset from news articles.</abstract>
      <url hash="97a036f6">2023.findings-acl.118</url>
      <bibkey>e-etal-2023-divhsk</bibkey>
      <doi>10.18653/v1/2023.findings-acl.118</doi>
    </paper>
    <paper id="119">
      <title>Similarity-Based Content Scoring - A more Classroom-Suitable Alternative to Instance-Based Scoring?</title>
      <author><first>Marie</first><last>Bexte</last><affiliation>FernUniversität in Hagen</affiliation></author>
      <author><first>Andrea</first><last>Horbach</last><affiliation>Universität Hildesheim</affiliation></author>
      <author><first>Torsten</first><last>Zesch</last><affiliation>Computational Linguistics, FernUniversität in Hagen</affiliation></author>
      <pages>1892-1903</pages>
      <abstract>Automatically scoring student answers is an important task that is usually solved using instance-based supervised learning. Recently, similarity-based scoring has been proposed as an alternative approach yielding similar perfor- mance. It has hypothetical advantages such as a lower need for annotated training data and better zero-shot performance, both of which are properties that would be highly beneficial when applying content scoring in a realistic classroom setting. In this paper we take a closer look at these alleged advantages by comparing different instance-based and similarity-based methods on multiple data sets in a number of learning curve experiments. We find that both the demand on data and cross-prompt performance is similar, thus not confirming the former two suggested advantages. The by default more straightforward possibility to give feedback based on a similarity-based approach may thus tip the scales in favor of it, although future work is needed to explore this advantage in practice.</abstract>
      <url hash="98fb2e06">2023.findings-acl.119</url>
      <bibkey>bexte-etal-2023-similarity</bibkey>
      <doi>10.18653/v1/2023.findings-acl.119</doi>
    </paper>
    <paper id="120">
      <title>Pragmatic Inference with a <fixed-case>CLIP</fixed-case> Listener for Contrastive Captioning</title>
      <author><first>Jiefu</first><last>Ou</last><affiliation>Language Technologies Institute - Carnegie Mellon University</affiliation></author>
      <author><first>Benno</first><last>Krojer</last><affiliation>Mila - Quebec AI Institute / McGill University</affiliation></author>
      <author><first>Daniel</first><last>Fried</last><affiliation>Carnegie Mellon University</affiliation></author>
      <pages>1904-1917</pages>
      <abstract>We propose a simple yet effective and robust method for contrastive captioning: generating discriminative captions that distinguish target images from very similar alternative distractor images. Our approach is built on a pragmatic inference procedure that formulates captioning as a reference game between a speaker, which produces possible captions describing the target, and a listener, which selects the target given the caption. Unlike previous methods that derive both speaker and listener distributions from a single captioning model, we leverage an off-the-shelf CLIP model to parameterize the listener. Compared with captioner-only pragmatic models, our method benefits from rich vision-language alignment representations from CLIP when reasoning over distractors. Like previous methods for discriminative captioning, our method uses a hyperparameter to control the tradeoff between the informativity (how likely captions are to allow a human listener to discriminate the target image) and the fluency of the captions. However, we find that our method is substantially more robust to the value of this hyperparameter than past methods, which allows us to automatically optimize the captions for informativity — outperforming past methods for discriminative captioning by 11% to 15% accuracy in human evaluations.</abstract>
      <url hash="209c99e9">2023.findings-acl.120</url>
      <bibkey>ou-etal-2023-pragmatic</bibkey>
      <doi>10.18653/v1/2023.findings-acl.120</doi>
    </paper>
    <paper id="121">
      <title>A Statistical Exploration of Text Partition Into Constituents: The Case of the Priestly Source in the Books of Genesis and Exodus</title>
      <author><first>Gideon</first><last>Yoffe</last><affiliation>Hebrew University of Jerusalem</affiliation></author>
      <author><first>Axel</first><last>Bühler</last><affiliation>University of Geneva</affiliation></author>
      <author><first>Nachum</first><last>Dershowitz</last><affiliation>Tel Aviv University</affiliation></author>
      <author><first>Thomas</first><last>Romer</last><affiliation>College de France</affiliation></author>
      <author><first>Eli</first><last>Piasetzky</last><affiliation>Tel Aviv University</affiliation></author>
      <author><first>Israel</first><last>Finkelstein</last><affiliation>University of Haifa</affiliation></author>
      <author><first>Barak</first><last>Sober</last><affiliation>The Hebrew University of Jerusalem</affiliation></author>
      <pages>1918-1940</pages>
      <abstract>We present a pipeline for a statistical stylometric exploration of a hypothesized partition of a text. Given a parameterization of the text, our pipeline: (1) detects literary features yielding the optimal overlap between the hypothesized and unsupervised partitions, (2) performs a hypothesis-testing analysis to quantify the statistical significance of the optimal overlap, while conserving implicit correlations between units of text that are more likely to be grouped, and (3) extracts and quantifies the importance of features most responsible for the classification, estimates their statistical stability and cluster-wise abundance. We apply our pipeline to the first two books in the Bible, where one stylistic component stands out in the eyes of biblical scholars, namely, the Priestly component. We identify and explore statistically significant stylistic differences between the Priestly and non-Priestly components.</abstract>
      <url hash="477bf32f">2023.findings-acl.121</url>
      <bibkey>yoffe-etal-2023-statistical</bibkey>
      <doi>10.18653/v1/2023.findings-acl.121</doi>
    </paper>
    <paper id="122">
      <title>A Language-First Approach for Procedure Planning</title>
      <author><first>Jiateng</first><last>Liu</last><affiliation>Zhejiang University</affiliation></author>
      <author><first>Sha</first><last>Li</last><affiliation>University of Illinois Urbana-Champaign</affiliation></author>
      <author><first>Zhenhailong</first><last>Wang</last><affiliation>University of Illinois at Urbana-Champaign</affiliation></author>
      <author><first>Manling</first><last>Li</last><affiliation>UIUC</affiliation></author>
      <author><first>Heng</first><last>Ji</last><affiliation>University of Illinois at Urbana-Champaign and Amazon (Amazon Scholar)</affiliation></author>
      <pages>1941-1954</pages>
      <abstract>Procedure planning, or the ability to predict a series of steps that can achieve a given goal conditioned on the current observation, is critical for building intelligent embodied agents that can assist users in everyday tasks. Encouraged by the recent success of language models (LMs) for zero-shot and few-shot planning, we hypothesize that LMs may be equipped with stronger priors for planning compared to their visual counterparts. To this end, we propose a language-first procedure planning framework with a modularized design: we first align the current and goal observations with corresponding steps and then use a pre-trained LM to predict the intermediate steps. Under this framework, we find that using an image captioning model for alignment can already match state-of-the-art performance and by designing a double retrieval model conditioned over current and goal observations jointly, we can achieve large improvements (19.2%-98.9% relatively higher success rate than state-of-the-art) on both COIN and CrossTask benchmarks. Our work verifies the planning ability of LMs and demonstrates how LMs can serve as a powerful “reasoning engine” even when the input is provided in another modality.</abstract>
      <url hash="fcb78127">2023.findings-acl.122</url>
      <bibkey>liu-etal-2023-language</bibkey>
      <doi>10.18653/v1/2023.findings-acl.122</doi>
    </paper>
    <paper id="123">
      <title>An Empirical Analysis of Leveraging Knowledge for Low-Resource Task-Oriented Semantic Parsing</title>
      <author><first>Mayank</first><last>Kulkarni</last><affiliation>Amazon</affiliation></author>
      <author><first>Aoxiao</first><last>Zhong</last><affiliation>Havard University</affiliation></author>
      <author><first>Nicolas</first><last>Guenon des mesnards</last><affiliation>Amazon</affiliation></author>
      <author><first>Sahar</first><last>Movaghati</last><affiliation>Amazon</affiliation></author>
      <author><first>Mukund</first><last>Sridhar</last><affiliation>Google</affiliation></author>
      <author><first>He</first><last>Xie</last><affiliation>Amazon Alexa AI</affiliation></author>
      <author><first>Jianhua</first><last>Lu</last><affiliation>Amazon</affiliation></author>
      <pages>1955-1969</pages>
      <abstract>Task-oriented semantic parsing has drawn a lot of interest from the NLP community, and especially the voice assistant industry as it enables representing the meaning of user requests with arbitrarily nested semantics, including multiple intents and compound entities. SOTA models are large seq2seq transformers and require hundreds of thousands of annotated examples to be trained. However annotating such data to bootstrap new domains or languages is expensive and error-prone, especially for requests made of nested semantics. In addition large models easily break the tight latency constraints imposed in a user-facing production environment. As part of this work we explore leveraging external knowledge to improve model accuracy in low-resource and low-compute settings. We demonstrate that using knowledge-enhanced encoders inside seq2seq models does not result in performance gains by itself, but jointly learning to uncover entities in addition to the parse generation is a simple yet effective way of improving performance across the board. We show this is especially true in the low-compute scarce-data setting and for entity-rich domains, with relative gains up to 74.48% on the TOPv2 dataset.</abstract>
      <url hash="4fade366">2023.findings-acl.123</url>
      <bibkey>kulkarni-etal-2023-empirical</bibkey>
      <doi>10.18653/v1/2023.findings-acl.123</doi>
    </paper>
    <paper id="124">
      <title><fixed-case>T</fixed-case>emp<fixed-case>LM</fixed-case>: Distilling Language Models into Template-Based Generators</title>
      <author><first>Tianyi</first><last>Zhang</last><affiliation>Stanford University</affiliation></author>
      <author><first>Mina</first><last>Lee</last><affiliation>Stanford University</affiliation></author>
      <author><first>Xiang Lisa</first><last>Li</last><affiliation>Stanford University</affiliation></author>
      <author><first>Ende</first><last>Shen</last><affiliation>Stanford University</affiliation></author>
      <author><first>Tatsunori</first><last>Hashimoto</last><affiliation>Stanford</affiliation></author>
      <pages>1970-1994</pages>
      <abstract>While pretrained language models (PLMs) have greatly improved text generation, they have also been known to produce unfaithful or inappropriate content. In contrast, classic template-based systems provide strong guarantees of faithfulness at the cost of fluency. We propose TempLM, which achieves the best of both worlds by distilling a PLM into a template-based generator. On the E2E and SynthBio data-to-text datasets, we show that TempLM is more faithful than the original PLM and is more fluent than prior template systems. Notably, on an out-of-domain evaluation, TempLM reduces a finetuned BART model’s unfaithfulness rate from 83% to 0%. In a human study, we find that TempLM’s templates substantially improve upon human-written ones in BERTScore.</abstract>
      <url hash="982592d6">2023.findings-acl.124</url>
      <bibkey>zhang-etal-2023-templm</bibkey>
      <doi>10.18653/v1/2023.findings-acl.124</doi>
    </paper>
    <paper id="125">
      <title>Incorporating Graph Information in Transformer-based <fixed-case>AMR</fixed-case> Parsing</title>
      <author><first>Pavlo</first><last>Vasylenko</last><affiliation>Sapienza University of Rome</affiliation></author>
      <author><first>Pere Lluís</first><last>Huguet Cabot</last><affiliation>Sapienza University of Rome</affiliation></author>
      <author><first>Abelardo Carlos</first><last>Martínez Lorenzo</last><affiliation>Sapienza University</affiliation></author>
      <author><first>Roberto</first><last>Navigli</last><affiliation>Sapienza University of Rome</affiliation></author>
      <pages>1995-2011</pages>
      <abstract>Abstract Meaning Representation (AMR) is a Semantic Parsing formalism that aims at providing a semantic graph abstraction representing a given text. Current approaches are based on autoregressive language models such as BART or T5, fine-tuned through Teacher Forcing to obtain a linearized version of the AMR graph from a sentence. In this paper, we present LeakDistill, a model and method that explores a modification to the Transformer architecture, using structural adapters to explicitly incorporate graph information into the learned representations and improve AMR parsing performance. Our experiments show how, by employing word-to-node alignment to embed graph structural information into the encoder at training time, we can obtain state-of-the-art AMR parsing through self-knowledge distillation, even without the use of additional data. We release the code at [<url>http://www.github.com/sapienzanlp/LeakDistill</url>](<url>http://www.github.com/sapienzanlp/LeakDistill</url>).</abstract>
      <url hash="f02b08cb">2023.findings-acl.125</url>
      <bibkey>vasylenko-etal-2023-incorporating</bibkey>
      <doi>10.18653/v1/2023.findings-acl.125</doi>
    </paper>
    <paper id="126">
      <title>Rethinking the Word-level Quality Estimation for Machine Translation from Human Judgement</title>
      <author><first>Zhen</first><last>Yang</last><affiliation>tencent.com</affiliation></author>
      <author><first>Fandong</first><last>Meng</last><affiliation>WeChat AI, Tencent</affiliation></author>
      <author><first>Yuanmeng</first><last>Yan</last><affiliation>Beijing University of Posts and Telecommunications</affiliation></author>
      <author><first>Jie</first><last>Zhou</last><affiliation>Tencent Inc.</affiliation></author>
      <pages>2012-2025</pages>
      <abstract>Word-level Quality Estimation (QE) of Machine Translation (MT) aims to detect potential translation errors in the translated sentence without reference. Typically, conventional works on word-level QE are usually designed to predict the quality of translated words in terms of the post-editing effort, where the word labels in the dataset, i.e., OK or BAD, are automatically generated by comparing words between MT sentences and the post-edited sentences through a Translation Error Rate (TER) toolkit. While the post-editing effort can be used to measure the translation quality to some extent, we find it usually conflicts with human judgment on whether the word is well or poorly translated. To investigate this conflict, we first create a golden benchmark dataset, namely <i>HJQE</i> (Human Judgement on Quality Estimation), where the source and MT sentences are identical to the original TER-based dataset and the expert translators directly annotate the poorly translated words on their judgments. Based on our analysis, we further propose two tag-correcting strategies which can make the TER-based artificial QE corpus closer to <i>HJQE</i>. We conduct substantial experiments based on the publicly available WMT En-De and En-Zh corpora. The results not only show our proposed dataset is more consistent with human judgment but also confirm the effectiveness of the proposed tag-correcting strategies.For reviewers, the corpora and codes can be found in the attached files.</abstract>
      <url hash="43023e8d">2023.findings-acl.126</url>
      <bibkey>yang-etal-2023-rethinking</bibkey>
      <doi>10.18653/v1/2023.findings-acl.126</doi>
    </paper>
    <paper id="127">
      <title><fixed-case>PV</fixed-case>2<fixed-case>TEA</fixed-case>: Patching Visual Modality to Textual-Established Information Extraction</title>
      <author><first>Hejie</first><last>Cui</last><affiliation>Emory University</affiliation></author>
      <author><first>Rongmei</first><last>Lin</last><affiliation>Amazon</affiliation></author>
      <author><first>Nasser</first><last>Zalmout</last><affiliation>Amazon</affiliation></author>
      <author><first>Chenwei</first><last>Zhang</last><affiliation>Amazon</affiliation></author>
      <author><first>Jingbo</first><last>Shang</last><affiliation>University of California, San Diego</affiliation></author>
      <author><first>Carl</first><last>Yang</last><affiliation>Emory University</affiliation></author>
      <author><first>Xian</first><last>Li</last><affiliation>Amazon</affiliation></author>
      <pages>2026-2041</pages>
      <abstract>Information extraction, e.g., attribute value extraction, has been extensively studied and formulated based only on text. However, many attributes can benefit from image-based extraction, like color, shape, pattern, among others. The visual modality has long been underutilized, mainly due to multimodal annotation difficulty. In this paper, we aim to patch the visual modality to the textual-established attribute in- formation extractor. The cross-modality integration faces several unique challenges: (C1) images and textual descriptions are loosely paired intra-sample and inter-samples; (C2) images usually contain rich backgrounds that can mislead the prediction; (C3) weakly supervised labels from textual-established ex- tractors are biased for multimodal training. We present PV2TEA, an encoder-decoder architecture equipped with three bias reduction schemes: (S1) Augmented label-smoothed contrast to improve the cross-modality alignment for loosely-paired image and text; (S2) Attention-pruning that adaptively distinguishes the visual foreground; (S3) Two-level neighborhood regularization that mitigates the label textual bias via reliability estimation. Empirical results on real-world e-Commerce datasets1 demonstrate up to 11.74% absolute (20.97% relatively) F1 increase over unimodal baselines.</abstract>
      <url hash="f1e7a25b">2023.findings-acl.127</url>
      <bibkey>cui-etal-2023-pv2tea</bibkey>
      <doi>10.18653/v1/2023.findings-acl.127</doi>
    </paper>
    <paper id="128">
      <title>Structural Contrastive Pretraining for Cross-Lingual Comprehension</title>
      <author><first>Nuo</first><last>Chen</last><affiliation>School of ECE, Peking Univesity</affiliation></author>
      <author><first>Linjun</first><last>Shou</last><affiliation>Microsoft STCA</affiliation></author>
      <author><first>Tengtao</first><last>Song</last><affiliation>Peking University</affiliation></author>
      <author><first>Ming</first><last>Gong</last><affiliation>STCA Search &amp; Distribution Group, Microsoft (China)</affiliation></author>
      <author><first>Jian</first><last>Pei</last><affiliation>Simon Fraser University</affiliation></author>
      <author><first>Jianhui</first><last>Chang</last><affiliation>Peking University</affiliation></author>
      <author><first>Daxin</first><last>Jiang</last><affiliation>STCA, Microsoft</affiliation></author>
      <author><first>Jia</first><last>Li</last><affiliation>Hong Kong University of Science and Technology</affiliation></author>
      <pages>2042-2057</pages>
      <abstract>To present, multilingual language models trained using various pre-training tasks like mask language modeling (MLM) have yielded encouraging results on a wide range of downstream tasks. Despite the promising performances, structural knowledge in cross-lingual corpus is less explored in current works, leading to the semantic misalignment. In this paper, we propose a new pre-training task named Structural Contrast Pretraining (SCP) to align the structural words in a parallel sentence, enhancing the models’ ability to comprehend cross-lingual representations. Concretely, each structural word in source and target languages is regarded as a positive pair in SCP. Since contrastive learning compares positive and negative pairs, an increase in the frequency of negative pairings could enhance the performance of the resulting model. Therefore, we further propose Cross-lingual Momentum Contrast (CL-MoCo) to increase the number of negative pairs by maintaining a large size of the queue. CL-MoCo extends the original Moco approach into cross-lingual training and jointly optimizes the source-to-target language and target-to-source language representations, resulting in a more suitable encoder for cross-lingual transfer. We conduct extensive experiments to validate the proposed approach on three cross-lingual tasks across five datasets such as MLQA, WikiAnn, etc, and results prove the effectiveness of our method.</abstract>
      <url hash="275ab580">2023.findings-acl.128</url>
      <bibkey>chen-etal-2023-structural</bibkey>
      <doi>10.18653/v1/2023.findings-acl.128</doi>
    </paper>
    <paper id="129">
      <title>Reducing Sensitivity on Speaker Names for Text Generation from Dialogues</title>
      <author><first>Qi</first><last>Jia</last><affiliation>Shanghai Jiao Tong University</affiliation></author>
      <author><first>Haifeng</first><last>Tang</last><affiliation>China Merchants Bank Credit Card Center</affiliation></author>
      <author><first>Kenny</first><last>Zhu</last><affiliation>Shanghai Jiao Tong University</affiliation></author>
      <pages>2058-2073</pages>
      <abstract>Changing speaker names consistently throughout a dialogue should not affect its meaning and corresponding outputs for text generation from dialogues. However, pre-trained language models, serving as the backbone for dialogue-processing tasks, have shown to be sensitive to nuances. This may result in unfairness in real-world applications. No comprehensive analysis of this problem has been done in the past. In this work, we propose to quantitatively measure a model’s sensitivity on speaker names, and comprehensively evaluate a number of known methods for reducing speaker name sensitivity, including a novel approach of our own. Extensive experiments on multiple datasets provide a benchmark for this problem and show the favorable performance of our approach in sensitivity reduction and quality of generation.</abstract>
      <url hash="a60658bb">2023.findings-acl.129</url>
      <bibkey>jia-etal-2023-reducing</bibkey>
      <doi>10.18653/v1/2023.findings-acl.129</doi>
    </paper>
    <paper id="130">
      <title>Topic and Style-aware Transformer for Multimodal Emotion Recognition</title>
      <author><first>Shuwen</first><last>Qiu</last><affiliation>University of California, Los Angeles</affiliation></author>
      <author><first>Nitesh</first><last>Sekhar</last><affiliation>Amazon</affiliation></author>
      <author><first>Prateek</first><last>Singhal</last><affiliation>Amazon</affiliation></author>
      <pages>2074-2082</pages>
      <abstract>Understanding emotion expressions in multimodal signals is key for machines to have a better understanding of human communication. While language, visual and acoustic modalities can provide clues from different perspectives, the visual modality is shown to make minimal contribution to the performance in the emotion recognition field due to its high dimensionality. Therefore, we first leverage the strong multimodality backbone VATT to project the visual signal to the common space with language and acoustic signals. Also, we propose content-oriented features Topic and Speaking style on top of it to approach the subjectivity issues. Experiments conducted on the benchmark dataset MOSEI show our model can outperform SOTA results and effectively incorporate visual signals and handle subjectivity issues by serving as content “normalization”.</abstract>
      <url hash="cf8f5d27">2023.findings-acl.130</url>
      <bibkey>qiu-etal-2023-topic</bibkey>
      <doi>10.18653/v1/2023.findings-acl.130</doi>
    </paper>
    <paper id="131">
      <title>Exploiting <fixed-case>A</fixed-case>bstract <fixed-case>M</fixed-case>eaning <fixed-case>R</fixed-case>epresentation for Open-Domain Question Answering</title>
      <author><first>Cunxiang</first><last>Wang</last><affiliation>Westlake University &amp; Zhejiang University</affiliation></author>
      <author><first>Zhikun</first><last>Xu</last><affiliation>Fudan University</affiliation></author>
      <author><first>Qipeng</first><last>Guo</last><affiliation>Amazon Shanghai AI Lab</affiliation></author>
      <author><first>Xiangkun</first><last>Hu</last><affiliation>Amazon</affiliation></author>
      <author><first>Xuefeng</first><last>Bai</last><affiliation>Zhejiang University;Westlake University</affiliation></author>
      <author><first>Zheng</first><last>Zhang</last><affiliation>NYU Shanghai</affiliation></author>
      <author><first>Yue</first><last>Zhang</last><affiliation>Westlake University</affiliation></author>
      <pages>2083-2096</pages>
      <abstract>The Open-Domain Question Answering (ODQA) task involves retrieving and subsequently generating answers from fine-grained relevant passages within a database. Current systems leverage Pretrained Language Models (PLMs) to model the relationship between questions and passages. However, the diversity in surface form expressions can hinder the model’s ability to capture accurate correlations, especially within complex contexts. Therefore, we utilize Abstract Meaning Representation (AMR) graphs to assist the model in understanding complex semantic information. We introduce a method known as Graph-as-Token (GST) to incorporate AMRs into PLMs. Results from Natural Questions (NQ) and TriviaQA (TQ) demonstrate that our GST method can significantly improve performance, resulting in up to 2.44/3.17 Exact Match score improvements on NQ/TQ respectively. Furthermore, our method enhances robustness and outperforms alternative Graph Neural Network (GNN) methods for integrating AMRs. To the best of our knowledge, we are the first to employ semantic graphs in ODQA.</abstract>
      <url hash="8016ea4b">2023.findings-acl.131</url>
      <bibkey>wang-etal-2023-exploiting</bibkey>
      <doi>10.18653/v1/2023.findings-acl.131</doi>
    </paper>
    <paper id="132">
      <title>Nonparametric Masked Language Modeling</title>
      <author><first>Sewon</first><last>Min</last><affiliation>University of Washington</affiliation></author>
      <author><first>Weijia</first><last>Shi</last><affiliation>uw.edu</affiliation></author>
      <author><first>Mike</first><last>Lewis</last><affiliation>Facebook AI Research</affiliation></author>
      <author><first>Xilun</first><last>Chen</last><affiliation>Meta AI</affiliation></author>
      <author><first>Wen-tau</first><last>Yih</last><affiliation>Meta AI - FAIR</affiliation></author>
      <author><first>Hannaneh</first><last>Hajishirzi</last><affiliation>University of Washington</affiliation></author>
      <author><first>Luke</first><last>Zettlemoyer</last><affiliation>University of Washington; Meta</affiliation></author>
      <pages>2097-2118</pages>
      <abstract>Existing language models (LMs) predict tokens with a softmax over a finite vocabulary, which can make it difficult to predict rare tokens or phrases. We introduce NPM, the first nonparametric masked language model that replaces this softmax with a nonparametric distribution over every phrase in a reference corpus. NPM fills in the [MASK] solely from retrieving a token from a text corpus. We show that NPM can be efficiently trained with a contrastive objective and an in-batch approximation to full corpus retrieval. Zero-shot evaluation on 16 tasks including classification, fact probing and question answering demonstrates that NPM outperforms significantly larger parametric models, either with or without a retrieve-and-generate approach. It is particularly better at dealing with rare patterns (word senses or facts) and predicting rare or nearly unseen words (e.g., non-Latin script). We release the model and code at github.com/facebookresearch/NPM.</abstract>
      <url hash="b4cf15eb">2023.findings-acl.132</url>
      <bibkey>min-etal-2023-nonparametric</bibkey>
      <doi>10.18653/v1/2023.findings-acl.132</doi>
    </paper>
    <paper id="133">
      <title>Pay More Attention to Relation Exploration for Knowledge Base Question Answering</title>
      <author><first>Yong</first><last>Cao</last><affiliation>Huazhong University of Science and Technology</affiliation></author>
      <author><first>Xianzhi</first><last>Li</last><affiliation>Huazhong University of Science and Technology</affiliation></author>
      <author><first>Huiwen</first><last>Liu</last><affiliation>xiaomi ai lab</affiliation></author>
      <author><first>Wen</first><last>Dai</last><affiliation>Xiaomi AI Lab, Xiaomi Inc.</affiliation></author>
      <author><first>Shuai</first><last>Chen</last><affiliation>xiaomi</affiliation></author>
      <author><first>Bin</first><last>Wang</last><affiliation>Xiaomi AI Lab</affiliation></author>
      <author><first>Min</first><last>Chen</last><affiliation>South China University of Technology</affiliation></author>
      <author><first>Daniel</first><last>Hershcovich</last><affiliation>University of Copenhagen</affiliation></author>
      <pages>2119-2136</pages>
      <abstract>Knowledge base question answering (KBQA) is a challenging task that aims to retrieve correct answers from large-scale knowledge bases. Existing attempts primarily focus on entity representation and final answer reasoning, which results in limited supervision for this task. Moreover, the relations, which empirically determine the reasoning path selection, are not fully considered in recent advancements. In this study, we propose a novel framework, RE-KBQA, that utilizes relations in the knowledge base to enhance entity representation and introduce additional supervision. We explore guidance from relations in three aspects, including (1) distinguishing similar entities by employing a variational graph auto-encoder to learn relation importance; (2) exploring extra supervision by predicting relation distributions as soft labels with a multi-task scheme; (3) designing a relation-guided re-ranking algorithm for post-processing. Experimental results on two benchmark datasets demonstrate the effectiveness and superiority of our framework, improving the F1 score by 5.8% from 40.5 to 46.3 on CWQ and 5.7% from 62.8 to 68.5 on WebQSP, better or on par with state-of-the-art methods.</abstract>
      <url hash="557bd1b2">2023.findings-acl.133</url>
      <bibkey>cao-etal-2023-pay</bibkey>
      <doi>10.18653/v1/2023.findings-acl.133</doi>
    </paper>
    <paper id="134">
      <title>Speaking Multiple Languages Affects the Moral Bias of Language Models</title>
      <author><first>Katharina</first><last>Haemmerl</last><affiliation>Center for Information and Language Processing, LMU</affiliation></author>
      <author><first>Bjoern</first><last>Deiseroth</last><affiliation>TU Darmstadt, Aleph Alpha</affiliation></author>
      <author><first>Patrick</first><last>Schramowski</last><affiliation>TU Darmstadt</affiliation></author>
      <author><first>Jindřich</first><last>Libovický</last><affiliation>Charles Univeristy</affiliation></author>
      <author><first>Constantin</first><last>Rothkopf</last><affiliation>Technical University of darmstadt</affiliation></author>
      <author><first>Alexander</first><last>Fraser</last><affiliation>Ludwig-Maximilians-Universität München</affiliation></author>
      <author><first>Kristian</first><last>Kersting</last><affiliation>TU Darmstadt</affiliation></author>
      <pages>2137-2156</pages>
      <abstract>Pre-trained multilingual language models (PMLMs) are commonly used when dealing with data from multiple languages and cross-lingual transfer. However, PMLMs are trained on varying amounts of data for each language. In practice this means their performance is often much better on English than many other languages. We explore to what extent this also applies to moral norms. Do the models capture moral norms from English and impose them on other languages? Do the models exhibit random and thus potentially harmful beliefs in certain languages? Both these issues could negatively impact cross-lingual transfer and potentially lead to harmful outcomes. In this paper, we (1) apply the MORALDIRECTION framework to multilingual models, comparing results in German, Czech, Arabic, Chinese, and English, (2) analyse model behaviour on filtered parallel subtitles corpora, and (3) apply the models to a Moral Foundations Questionnaire, comparing with human responses from different countries. Our experiments demonstrate that, indeed, PMLMs encode differing moral biases, but these do not necessarily correspond to cultural differences or commonalities in human opinions. We release our code and models.</abstract>
      <url hash="dffd6e72">2023.findings-acl.134</url>
      <bibkey>haemmerl-etal-2023-speaking</bibkey>
      <doi>10.18653/v1/2023.findings-acl.134</doi>
    </paper>
    <paper id="135">
      <title>Retrieving Relevant Context to Align Representations for Cross-lingual Event Detection</title>
      <author><first>Chien</first><last>Nguyen</last><affiliation>VinAI Research, Vietnam</affiliation></author>
      <author><first>Linh</first><last>Ngo</last><affiliation>Hanoi University of Science and Technology</affiliation></author>
      <author><first>Thien</first><last>Nguyen</last><affiliation>University of Oregon</affiliation></author>
      <pages>2157-2170</pages>
      <abstract>We study the problem of cross-lingual transfer learning for event detection (ED) where models trained on a source language are expected to perform well on data for a new target language. Among a few recent works for this problem, the main approaches involve representation matching (e.g., adversarial training) that aims to eliminate language-specific features from the representations to achieve the language-invariant representations. However, due to the mix of language-specific features with event-discriminative context, representation matching methods might also remove important features for event prediction, thus hindering the performance for ED. To address this issue, we introduce a novel approach for cross-lingual ED where representations are augmented with additional context (i.e., not eliminating) to bridge the gap between languages while enriching the contextual information to facilitate ED. At the core of our method involves a retrieval model that retrieves relevant sentences in the target language for an input sentence to compute augmentation representations. Experiments on three languages demonstrate the state-of-the-art performance of our model for cross-lingual ED.</abstract>
      <url hash="2c61c7f6">2023.findings-acl.135</url>
      <bibkey>nguyen-etal-2023-retrieving</bibkey>
      <doi>10.18653/v1/2023.findings-acl.135</doi>
    </paper>
    <paper id="136">
      <title><fixed-case>N</fixed-case>orm<fixed-case>N</fixed-case>et: Normalize Noun Phrases for More Robust <fixed-case>NLP</fixed-case></title>
      <author><first>Minlong</first><last>Peng</last><affiliation>Baidu Inc.</affiliation></author>
      <author><first>Mingming</first><last>Sun</last><affiliation>Baidu Research</affiliation></author>
      <pages>2171-2183</pages>
      <abstract>A critical limitation of deep NLP models is their over-fitting over spurious features. Previous work has proposed several approaches to debunk such features and reduce their impact on the learned models. In this work, a normalization strategy is proposed to eliminate the false features caused by the textual surfaces of noun phrases. The motivation for this strategy is that noun phrases often play the role of slots in textual expressions and their exact forms are often not that important for performing the final task. As an intuitive example, consider the expression ”<tex-math>x \text{ like eating } y</tex-math>". There are a huge number of suitable instantiations for <tex-math>x</tex-math> and <tex-math>y</tex-math> in the locale. However, humans can already infer the sentiment polarity of <tex-math>x</tex-math> toward <tex-math>y</tex-math> without knowing their exact forms.Based on this intuition, we introduce NormNet, a pretrained language model based network, to implement the normalization strategy. NormNet learns to replace as many noun phrases in the input sentence as possible with pre-defined base forms. The output of NormNet is then fed as input to a prompt-based learning model to perform label prediction. To evaluate the effectiveness of our strategy, we conducted experimental studies on several tasks, including aspect sentiment classification (ASC), semantic text similarity (STS), and natural language inference (NLI). The experimental results confirm the effectiveness of our strategy.</abstract>
      <url hash="2d43407a">2023.findings-acl.136</url>
      <bibkey>peng-sun-2023-normnet</bibkey>
      <doi>10.18653/v1/2023.findings-acl.136</doi>
    </paper>
    <paper id="137">
      <title>Cross Encoding as Augmentation: Towards Effective Educational Text Classification</title>
      <author><first>Hyun Seung</first><last>Lee</last><affiliation>Riiid</affiliation></author>
      <author><first>Seungtaek</first><last>Choi</last><affiliation>Riiid</affiliation></author>
      <author><first>Yunsung</first><last>Lee</last><affiliation>Riiid</affiliation></author>
      <author><first>Hyeongdon</first><last>Moon</last><affiliation>None</affiliation></author>
      <author><first>Shinhyeok</first><last>Oh</last><affiliation>Riiid</affiliation></author>
      <author><first>Myeongho</first><last>Jeong</last><affiliation>Riiid</affiliation></author>
      <author><first>Hyojun</first><last>Go</last><affiliation>Riiid</affiliation></author>
      <author><first>Christian</first><last>Wallraven</last><affiliation>Korea University</affiliation></author>
      <pages>2184-2195</pages>
      <abstract>Text classification in education, usually called auto-tagging, is the automated process of assigning relevant tags to educational content, such as questions and textbooks. However, auto-tagging suffers from a data scarcity problem, which stems from two major challenges: 1) it possesses a large tag space and 2) it is multi-label. Though a retrieval approach is reportedly good at low-resource scenarios, there have been fewer efforts to directly address the data scarcity problem. To mitigate these issues, here we propose a novel retrieval approach CEAA that provides effective learning in educational text classification. Our main contributions are as follows: 1) we leverage transfer learning from question-answering datasets, and 2) we propose a simple but effective data augmentation method introducing cross-encoder style texts to a bi-encoder architecture for more efficient inference. An extensive set of experiments shows that our proposed method is effective in multi-label scenarios and low-resource tags compared to state-of-the-art models.</abstract>
      <url hash="3c48d481">2023.findings-acl.137</url>
      <bibkey>lee-etal-2023-cross</bibkey>
      <doi>10.18653/v1/2023.findings-acl.137</doi>
    </paper>
    <paper id="138">
      <title>Adversarial Robustness of Prompt-based Few-Shot Learning for Natural Language Understanding</title>
      <author><first>Venkata Prabhakara Sarath</first><last>Nookala</last><affiliation>Georgia Institute of Technology</affiliation></author>
      <author><first>Gaurav</first><last>Verma</last><affiliation>Georgia Institute of Technology</affiliation></author>
      <author><first>Subhabrata</first><last>Mukherjee</last><affiliation>Microsoft Research</affiliation></author>
      <author><first>Srijan</first><last>Kumar</last><affiliation>Georgia Institute of Technology</affiliation></author>
      <pages>2196-2208</pages>
      <abstract>State-of-the-art few-shot learning (FSL) methods leverage prompt-based fine-tuning to obtain remarkable results for natural language understanding (NLU) tasks. While much of the prior FSL methods focus on improving downstream task performance, there is a limited understanding of the adversarial robustness of such methods. In this work, we conduct an extensive study of several state-of-the-art FSL methods to assess their robustness to adversarial perturbations. To better understand the impact of various factors towards robustness (or the lack of it), we evaluate prompt-based FSL methods against fully fine-tuned models for aspects such as the use of unlabeled data, multiple prompts, number of few-shot examples, model size and type. Our results on six GLUE tasks indicate that compared to fully fine-tuned models, vanilla FSL methods lead to a notable relative drop in task performance (i.e., are less robust) in the face of adversarial perturbations. However, using (i) unlabeled data for prompt-based FSL and (ii) multiple prompts flip the trend – the few-shot learning approaches demonstrate a lesser drop in task performance than fully fine-tuned models. We further demonstrate that increasing the number of few-shot examples and model size lead to increased adversarial robustness of vanilla FSL methods. Broadly, our work sheds light on the adversarial robustness evaluation of prompt-based FSL methods for NLU tasks.</abstract>
      <url hash="9c807b85">2023.findings-acl.138</url>
      <bibkey>nookala-etal-2023-adversarial</bibkey>
      <doi>10.18653/v1/2023.findings-acl.138</doi>
    </paper>
    <paper id="139">
      <title>This prompt is measuring &lt;mask&gt;: evaluating bias evaluation in language models</title>
      <author><first>Seraphina</first><last>Goldfarb-Tarrant</last><affiliation>University of Edinburgh</affiliation></author>
      <author><first>Eddie</first><last>Ungless</last><affiliation>University of Edinburgh</affiliation></author>
      <author><first>Esma</first><last>Balkir</last><affiliation>National Research Council Canada</affiliation></author>
      <author><first>Su Lin</first><last>Blodgett</last><affiliation>Microsoft Research</affiliation></author>
      <pages>2209-2225</pages>
      <abstract>Bias research in NLP seeks to analyse models for social biases, thus helping NLP practitioners uncover, measure, and mitigate social harms. We analyse the body of work that uses prompts and templates to assess bias in language models. We draw on a measurement modelling framework to create a taxonomy of attributes that capture what a bias test aims to measure and how that measurement is carried out. By applying this taxonomy to 90 bias tests, we illustrate qualitatively and quantitatively that core aspects of bias test conceptualisations and operationalisations are frequently unstated or ambiguous, carry implicit assumptions, or be mismatched. Our analysis illuminates the scope of possible bias types the field is able to measure, and reveals types that are as yet under-researched. We offer guidance to enable the community to explore a wider section of the possible bias space, and to better close the gap between desired outcomes and experimental design, both for bias and for evaluating language models more broadly.</abstract>
      <url hash="5ba80350">2023.findings-acl.139</url>
      <bibkey>goldfarb-tarrant-etal-2023-prompt</bibkey>
      <doi>10.18653/v1/2023.findings-acl.139</doi>
    </paper>
    <paper id="140">
      <title>Towards Open Environment Intent Prediction</title>
      <author><first>Yunhua</first><last>Zhou</last><affiliation>Fudan University</affiliation></author>
      <author><first>Jiawei</first><last>Hong</last><affiliation>Fudan University</affiliation></author>
      <author><first>Xipeng</first><last>Qiu</last><affiliation>Fudan University</affiliation></author>
      <pages>2226-2240</pages>
      <abstract>Out-of-Domain (OOD) Intent Classification and New Intent Discovering are two basic and critical tasks in the Task-Oriented Dialogue System, which are typically treated two independent tasks. Classification focuses on identifying intents beyond the predefined set of the dialog system, but it will not further differentiate detected OOD intents in fine granularity. Discovering focuses on how to cluster unlabeled samples according to their semantic representation, which relies heavily on prior knowledge and can not provide label information for the formed clusters. To be closer to the real user-facing scenarios, we introduce a task paradigm to extend Classification with Discovering referred as Open Environment Intent Prediction, which is to make a further fine-grained discovery of OOD based on OOD Intent Classification. Using various widely-used generative models as an archetype, we propose a general scheme for Open Environment Intent Prediction. In a nutshell, we first perform intent detection to identify the In-domain (IND) samples and then generate labels for those identified as OOD. With these generated labels, we can discover new general intents and provide label information for them. We develop a suite of benchmarks on the existing intent datasets and present a simple yet effective implementation. Extensive experiments demonstrate that our method establishes substantial improvement compared to the baselines.</abstract>
      <url hash="057f978b">2023.findings-acl.140</url>
      <bibkey>zhou-etal-2023-towards-open</bibkey>
      <doi>10.18653/v1/2023.findings-acl.140</doi>
    </paper>
    <paper id="141">
      <title>Teamwork Is Not Always Good: An Empirical Study of Classifier Drift in Class-incremental Information Extraction</title>
      <author><first>Minqian</first><last>Liu</last><affiliation>Virginia Tech</affiliation></author>
      <author><first>Lifu</first><last>Huang</last><affiliation>Virginia Tech</affiliation></author>
      <pages>2241-2257</pages>
      <abstract>Class-incremental learning (CIL) aims to develop a learning system that can continually learn new classes from a data stream without forgetting previously learned classes. When learning classes incrementally, the classifier must be constantly updated to incorporate new classes, and the drift in decision boundary may lead to severe forgetting. This fundamental challenge, however, has not yet been studied extensively, especially in the setting where no samples from old classes are stored for rehearsal. In this paper, we take a closer look at how the drift in the classifier leads to forgetting, and accordingly, design four simple yet (super-) effective solutions to alleviate the classifier drift: an Individual Classifiers with Frozen Feature Extractor (ICE) framework where we individually train a classifier for each learning session, and its three variants ICE-PL, ICE-O, and ICE-PL&amp;O which further take the logits of previously learned classes from old sessions or a constant logit of an Other class as constraint to the learning of new classifiers. Extensive experiments and analysis on 6 class-incremental information extraction tasks demonstrate that our solutions, especially ICE-O, consistently show significant improvement over the previous state-of-the-art approaches with up to 44.7% absolute F-score gain, providing a strong baseline and insights for future research on class-incremental learning.</abstract>
      <url hash="d5a4bbbb">2023.findings-acl.141</url>
      <bibkey>liu-huang-2023-teamwork</bibkey>
      <doi>10.18653/v1/2023.findings-acl.141</doi>
    </paper>
    <paper id="142">
      <title><fixed-case>C</fixed-case>-<fixed-case>XNLI</fixed-case>: <fixed-case>C</fixed-case>roatian Extension of <fixed-case>XNLI</fixed-case> Dataset</title>
      <author><first>Leo</first><last>Obadić</last><affiliation>RealNetworks</affiliation></author>
      <author><first>Andrej</first><last>Jertec</last><affiliation>RealNetworks</affiliation></author>
      <author><first>Marko</first><last>Rajnović</last><affiliation>RealNetworks</affiliation></author>
      <author><first>Branimir</first><last>Dropuljić</last><affiliation>RealNetworks</affiliation></author>
      <pages>2258-2267</pages>
      <abstract>Comprehensive multilingual evaluations have been encouraged by emerging cross-lingual benchmarks and constrained by existing parallel datasets. To partially mitigate this limitation, we extended the Cross-lingual Natural Language Inference (XNLI) corpus with Croatian. The development and test sets were translated by a professional translator, and we show that Croatian is consistent with other XNLI dubs. The train set is translated using Facebook’s 1.2B parameter m2m_100 model. We thoroughly analyze the Croatian train set and compare its quality with the existing machine-translated German set. The comparison is based on 2000 manually scored sentences per language using a variant of the Direct Assessment (DA) score commonly used at the Conference on Machine Translation (WMT). Our findings reveal that a less-resourced language like Croatian is still lacking in translation quality of longer sentences compared to German. However, both sets have a substantial amount of poor quality translations, which should be considered in translation-based training or evaluation setups.</abstract>
      <url hash="1803c80d">2023.findings-acl.142</url>
      <bibkey>obadic-etal-2023-c</bibkey>
      <doi>10.18653/v1/2023.findings-acl.142</doi>
    </paper>
    <paper id="143">
      <title><fixed-case>AVATAR</fixed-case>: A Parallel Corpus for <fixed-case>J</fixed-case>ava-Python Program Translation</title>
      <author><first>Wasi Uddin</first><last>Ahmad</last><affiliation>AWS AI Labs</affiliation></author>
      <author><first>Md Golam Rahman</first><last>Tushar</last><affiliation>Individual Contributor</affiliation></author>
      <author><first>Saikat</first><last>Chakraborty</last><affiliation>Microsoft Research</affiliation></author>
      <author><first>Kai-Wei</first><last>Chang</last><affiliation>UCLA</affiliation></author>
      <pages>2268-2281</pages>
      <abstract>Program translation refers to migrating source code from one programming language to another. It has tremendous practical value in software development, as porting software across languages is time-consuming and costly. Automating program translation is of paramount importance in software migration, and recently researchers explored unsupervised approaches due to the unavailability of parallel corpora. However, the availability of pre-trained language models for programming languages enables supervised fine-tuning with a small number of labeled examples. Therefore, we present AVATAR, a collection of 9,515 programming problems and their solutions written in two popular languages, Java and Python. AVATAR is collected from competitive programming sites, online platforms, and open-source repositories. Furthermore, AVATAR includes unit tests for 250 examples to facilitate functional correctness evaluation. We benchmark several pre-trained language models fine-tuned on AVATAR. Experiment results show that the models lack in generating functionally accurate code.</abstract>
      <url hash="03d189f5">2023.findings-acl.143</url>
      <bibkey>ahmad-etal-2023-avatar</bibkey>
      <doi>10.18653/v1/2023.findings-acl.143</doi>
    </paper>
    <paper id="144">
      <title>On Dataset Transferability in Active Learning for Transformers</title>
      <author><first>Fran</first><last>Jelenić</last><affiliation>University of Zagreb</affiliation></author>
      <author><first>Josip</first><last>Jukić</last><affiliation>University of Zagreb, Faculty of Electrical Engineering and Computing</affiliation></author>
      <author><first>Nina</first><last>Drobac</last><affiliation>University of Zagreb</affiliation></author>
      <author><first>Jan</first><last>Snajder</last><affiliation>University of Zagreb, Faculty of Electrical Engineering and Computing, Unska 3, 10000 Zagreb</affiliation></author>
      <pages>2282-2295</pages>
      <abstract>Active learning (AL) aims to reduce labeling costs by querying the examples most beneficial for model learning. While the effectiveness of AL for fine-tuning transformer-based pre-trained language models (PLMs) has been demonstrated, it is less clear to what extent the AL gains obtained with one model transfer to others. We consider the problem of transferability of actively acquired datasets in text classification and investigate whether AL gains persist when a dataset built using AL coupled with a specific PLM is used to train a different PLM. We link the AL dataset transferability to the similarity of instances queried by the different PLMs and show that AL methods with similar acquisition sequences produce highly transferable datasets regardless of the models used. Additionally, we show that the similarity of acquisition sequences is influenced more by the choice of the AL method than the choice of the model.</abstract>
      <url hash="639b3429">2023.findings-acl.144</url>
      <bibkey>jelenic-etal-2023-dataset</bibkey>
      <doi>10.18653/v1/2023.findings-acl.144</doi>
    </paper>
    <paper id="145">
      <title>Structured Persuasive Writing Support in Legal Education: A Model and Tool for <fixed-case>G</fixed-case>erman Legal Case Solutions</title>
      <author><first>Florian</first><last>Weber</last><affiliation>University of Kassel</affiliation></author>
      <author><first>Thiemo</first><last>Wambsganss</last><affiliation>Swiss Federal Institute of Technology in Lausanne (EPFL)</affiliation></author>
      <author><first>Seyed Parsa</first><last>Neshaei</last><affiliation>Sharif University of Technology</affiliation></author>
      <author><first>Matthias</first><last>Soellner</last><affiliation>University of Kassel</affiliation></author>
      <pages>2296-2313</pages>
      <abstract>We present an annotation approach for capturing structured components and arguments inlegal case solutions of German students. Based on the appraisal style, which dictates the structured way of persuasive writing in German law, we propose an annotation scheme with annotation guidelines that identify structured writing in legal case solutions. We conducted an annotation study with two annotators and annotated legal case solutions to capture the structures of a persuasive legal text. Based on our dataset, we trained three transformer-based models to show that the annotated components can be successfully predicted, e.g. to provide users with writing assistance for legal texts. We evaluated a writing support system in which our models were integrated in an online experiment with law students and found positive learning success and users’ perceptions. Finally, we present our freely available corpus of 413 law student case studies to support the development of intelligent writing support systems.</abstract>
      <url hash="d262f0cf">2023.findings-acl.145</url>
      <bibkey>weber-etal-2023-structured</bibkey>
      <doi>10.18653/v1/2023.findings-acl.145</doi>
    </paper>
    <paper id="146">
      <title>Characterizing the Impacts of Instances on Robustness</title>
      <author><first>Rui</first><last>Zheng</last><affiliation>Fudan University</affiliation></author>
      <author><first>Zhiheng</first><last>Xi</last><affiliation>Fudan University</affiliation></author>
      <author><first>Qin</first><last>Liu</last><affiliation>University of Southern California</affiliation></author>
      <author><first>Wenbin</first><last>Lai</last><affiliation>Fudan University</affiliation></author>
      <author><first>Tao</first><last>Gui</last><affiliation>fudan university</affiliation></author>
      <author><first>Qi</first><last>Zhang</last><affiliation>Fudan University</affiliation></author>
      <author><first>Xuanjing</first><last>Huang</last><affiliation>Fudan University</affiliation></author>
      <author><first>Jin</first><last>Ma</last><affiliation>ustc</affiliation></author>
      <author><first>Ying</first><last>Shan</last><affiliation>Tencent</affiliation></author>
      <author><first>Weifeng</first><last>Ge</last><affiliation>Fudan University</affiliation></author>
      <pages>2314-2332</pages>
      <abstract>Building robust deep neural networks (DNNs) against adversarial attacks is an important but challenging task. Previous defense approaches mainly focus on developing new model structures or training algorithms, but they do little to tap the potential of training instances, especially instances with robust patterns carring innate robustness. In this paper, we show that robust and non-robust instances in the training dataset, though are both important for test performance, have contrary impacts on robustness, which makes it possible to build a highly robust model by leveraging the training dataset in a more effective way. We propose a new method that can distinguish between robust instances from non-robust ones according to the model’s sensitivity to perturbations on individual instances during training. Surprisingly, we find that the model under standard training easily overfits the robust instances by relying on their simple patterns before the model completely learns their robust features. Finally, we propose a new mitigation algorithm to further release the potential of robust instances. Experimental results show that proper use of robust instances in the original dataset is a new line to achieve highly robust models.</abstract>
      <url hash="281b6629">2023.findings-acl.146</url>
      <bibkey>zheng-etal-2023-characterizing</bibkey>
      <doi>10.18653/v1/2023.findings-acl.146</doi>
    </paper>
    <paper id="147">
      <title>Generate then Select: Open-ended Visual Question Answering Guided by World Knowledge</title>
      <author><first>Xingyu</first><last>Fu</last><affiliation>Upenn</affiliation></author>
      <author><first>Sheng</first><last>Zhang</last><affiliation>Amazon</affiliation></author>
      <author><first>Gukyeong</first><last>Kwon</last><affiliation>AWS</affiliation></author>
      <author><first>Pramuditha</first><last>Perera</last><affiliation>AWS AI Labs</affiliation></author>
      <author><first>Henghui</first><last>Zhu</last><affiliation>Amazon</affiliation></author>
      <author><first>Yuhao</first><last>Zhang</last><affiliation>Amazon AWS AI</affiliation></author>
      <author><first>Alexander Hanbo</first><last>Li</last><affiliation>AWS AI Labs</affiliation></author>
      <author><first>William Yang</first><last>Wang</last><affiliation>Amazon AWS AI Labs</affiliation></author>
      <author><first>Zhiguo</first><last>Wang</last><affiliation>AWS AI Labs</affiliation></author>
      <author><first>Vittorio</first><last>Castelli</last><affiliation>AWS AI Labs</affiliation></author>
      <author><first>Patrick</first><last>Ng</last><affiliation>Amazon.com</affiliation></author>
      <author><first>Dan</first><last>Roth</last><affiliation>University of Pennsylvania</affiliation></author>
      <author><first>Bing</first><last>Xiang</last><affiliation>Amazon</affiliation></author>
      <pages>2333-2346</pages>
      <abstract>The open-ended Visual Question Answering (VQA) task requires AI models to jointly reason over visual and natural language inputs using world knowledge. Recently, pre-trained Language Models (PLM) such as GPT-3 have been applied to the task and shown to be powerful world knowledge sources. However, these methods suffer from low knowledge coverage caused by PLM bias – the tendency to generate certain tokens over other tokens regardless of prompt changes, and high dependency on the PLM quality – only models using GPT-3 can achieve the best result. To address the aforementioned challenges, we propose RASO: a new VQA pipeline that deploys a generate-then-select strategy guided by world knowledge for the first time. Rather than following the de facto standard to train a multi-modal model that directly generates the VQA answer, {pasted macro ‘MODEL’}name first adopts PLM to generate all the possible answers, and then trains a lightweight answer selection model for the correct answer. As proved in our analysis, RASO expands the knowledge coverage from in-domain training data by a large margin. We provide extensive experimentation and show the effectiveness of our pipeline by advancing the state-of-the-art by 4.1% on OK-VQA, without additional computation cost.</abstract>
      <url hash="ad4c650b">2023.findings-acl.147</url>
      <bibkey>fu-etal-2023-generate</bibkey>
      <doi>10.18653/v1/2023.findings-acl.147</doi>
    </paper>
    <paper id="148">
      <title>Hence, Socrates is mortal: A Benchmark for Natural Language Syllogistic Reasoning</title>
      <author><first>Yongkang</first><last>Wu</last><affiliation>Huawei</affiliation></author>
      <author><first>Meng</first><last>Han</last><affiliation>Huawei</affiliation></author>
      <author><first>Yutao</first><last>Zhu</last><affiliation>University of Montreal</affiliation></author>
      <author><first>Lei</first><last>Li</last><affiliation>Huawei</affiliation></author>
      <author><first>Xinyu</first><last>Zhang</last><affiliation>Huawei Technologies Co., Ltd</affiliation></author>
      <author><first>Ruofei</first><last>Lai</last><affiliation>Huawei</affiliation></author>
      <author><first>Xiaoguang</first><last>Li</last><affiliation>Huawei Noah’s Ark Lab</affiliation></author>
      <author><first>Yuanhang</first><last>Ren</last><affiliation>University of Electronic Science and Technology of China</affiliation></author>
      <author><first>Zhicheng</first><last>Dou</last><affiliation>Renmin University of China</affiliation></author>
      <author><first>Zhao</first><last>Cao</last><affiliation>Huawei</affiliation></author>
      <pages>2347-2367</pages>
      <abstract>Syllogistic reasoning, a typical form of deductive reasoning, is a critical capability widely required in natural language understanding tasks, such as text entailment and question answering. To better facilitate research on syllogistic reasoning, we develop a benchmark called SylloBase that differs from existing syllogistic datasets in three aspects: (1) Covering a complete taxonomy of syllogism reasoning patterns; (2) Containing both automatically and manually constructed samples; and (3) Involving both the generation and understanding tasks. We automatically construct 50k template-based syllogism samples by mining syllogism patterns from Wikidata and ConceptNet. To improve our dataset’s naturalness and challenge, we apply GPT-3 to paraphrase the template-based data and further manually rewrite 1,000 samples as the test set. State-of-the-art pre-trained language models can achieve the best generation ROUGE-L of 38.72 by T5 and the best multi-choice accuracy of 72.77% by RoBERTa on SylloBase, which indicates the great challenge of learning diverse syllogistic reasoning types on SylloBase. Our datasets are released at <url>https://github.com/casually-PYlearner/SYLLOBASE</url>.</abstract>
      <url hash="c43ce73b">2023.findings-acl.148</url>
      <bibkey>wu-etal-2023-hence</bibkey>
      <doi>10.18653/v1/2023.findings-acl.148</doi>
    </paper>
    <paper id="149">
      <title>Categorial grammar induction from raw data</title>
      <author><first>Christian</first><last>Clark</last><affiliation>The Ohio State University</affiliation></author>
      <author><first>William</first><last>Schuler</last><affiliation>The Ohio State University</affiliation></author>
      <pages>2368-2379</pages>
      <abstract>Grammar induction, the task of learning a set of grammatical rules from raw or minimally labeled text data, can provide clues about what kinds of syntactic structures are learnable without prior knowledge. Recent work (e.g., Kim et al., 2019; Zhu et al., 2020; Jin et al., 2021a) has achieved advances in unsupervised induction of probabilistic context-free grammars (PCFGs). However, categorial grammar induction has received less recent attention, despite allowing inducers to support a larger set of syntactic categories—due to restrictions on how categories can combine—and providing a transparent interface with compositional semantics, opening up possibilities for models that jointly learn form and meaning. Motivated by this, we propose a new model for inducing a basic (Ajdukiewicz, 1935; Bar-Hillel, 1953) categorial grammar. In contrast to earlier categorial grammar induction systems (e.g., Bisk and Hockenmaier, 2012), our model learns from raw data without any part-of-speech information. Experiments on child-directed speech show that our model attains a recall-homogeneity of 0.33 on average, which dramatically increases to 0.59 when a bias toward forward function application is added to the model.</abstract>
      <url hash="5260a978">2023.findings-acl.149</url>
      <bibkey>clark-schuler-2023-categorial</bibkey>
      <doi>10.18653/v1/2023.findings-acl.149</doi>
    </paper>
    <paper id="150">
      <title>Attribute Controlled Dialogue Prompting</title>
      <author><first>Runcheng</first><last>Liu</last><affiliation>University of Waterloo</affiliation></author>
      <author><first>Ahmad</first><last>Rashid</last><affiliation>University of Waterloo; Huawei Noah’s Ark Lab</affiliation></author>
      <author><first>Ivan</first><last>Kobyzev</last><affiliation>Huawei Noah’s Ark Lab</affiliation></author>
      <author><first>Mehdi</first><last>Rezagholizadeh</last><affiliation>Noah’s Ark Lab Huawei</affiliation></author>
      <author><first>Pascal</first><last>Poupart</last><affiliation>University of Waterloo &amp; Vector Institute</affiliation></author>
      <pages>2380-2389</pages>
      <abstract>Prompt-tuning has become an increasingly popular parameter-efficient method for adapting large pretrained language models to downstream tasks. However, both discrete prompting and continuous prompting assume fixed prompts for all data samples within a task, neglecting the fact that inputs vary greatly in some tasks such as open-domain dialogue generation. In this paper, we present a novel, instance-specific prompt-tuning algorithm for dialogue generation. Specifically, we generate prompts based on instance-level control code, rather than the conversation history, to explore their impact on controlled dialogue generation. Experiments on popular open-domain dialogue datasets, evaluated on both automated metrics and human evaluation, demonstrate that our method is superior to prompting baselines and comparable to fine-tuning with only 5%-6% of total parameters.</abstract>
      <url hash="3876fa69">2023.findings-acl.150</url>
      <bibkey>liu-etal-2023-attribute</bibkey>
      <doi>10.18653/v1/2023.findings-acl.150</doi>
    </paper>
    <paper id="151">
      <title>Open-World Factually Consistent Question Generation</title>
      <author><first>Himanshu</first><last>Maheshwari</last><affiliation>Adobe Research</affiliation></author>
      <author><first>Sumit</first><last>Shekhar</last><affiliation>Adobe Systems</affiliation></author>
      <author><first>Apoorv</first><last>Saxena</last><affiliation>Indian Institute of Science, Bangalore</affiliation></author>
      <author><first>Niyati</first><last>Chhaya</last><affiliation>Adobe Research</affiliation></author>
      <pages>2390-2404</pages>
      <abstract>Question generation methods based on pre-trained language models often suffer from factual inconsistencies and incorrect entities and are not answerable from the input paragraph. Domain shift – where the test data is from a different domain than the training data - further exacerbates the problem of hallucination. This is a critical issue for any natural language application doing question generation. In this work, we propose an effective data processing technique based on de-lexicalization for consistent question generation across domains. Unlike existing approaches for remedying hallucination, the proposed approach does not filter training data and is generic across question-generation models. Experimental results across six benchmark datasets show that our model is robust to domain shift and produces entity-level factually consistent questions without significant impact on traditional metrics.</abstract>
      <url hash="217fb90f">2023.findings-acl.151</url>
      <bibkey>maheshwari-etal-2023-open</bibkey>
      <doi>10.18653/v1/2023.findings-acl.151</doi>
    </paper>
    <paper id="152">
      <title>Contrastive Learning of Sociopragmatic Meaning in Social Media</title>
      <author><first>Chiyu</first><last>Zhang</last><affiliation>The University of British Columbia</affiliation></author>
      <author><first>Muhammad</first><last>Abdul-Mageed</last><affiliation>The University of British Columbia</affiliation></author>
      <author><first>Ganesh</first><last>Jawahar</last><affiliation>The University of British Columbia</affiliation></author>
      <pages>2405-2439</pages>
      <abstract>Recent progress in representation and contrastive learning in NLP has not widely considered the class of sociopragmatic meaning (i.e., meaning in interaction within different language communities). To bridge this gap, we propose a novel framework for learning task-agnostic representations transferable to a wide range of sociopragmatic tasks (e.g., emotion, hate speech, humor, sarcasm). Our framework outperforms other contrastive learning frameworks for both in-domain and out-of-domain data, across both the general and few-shot settings. For example, compared to two popular pre-trained language models, our model obtains an improvement of 11.66 average F1 on 16 datasets when fine-tuned on only 20 training samples per dataset. We also show that our framework improves uniformity and preserves the semantic structure of representations. Our code is available at: <url>https://github.com/UBC-NLP/infodcl</url></abstract>
      <url hash="c0e0212a">2023.findings-acl.152</url>
      <bibkey>zhang-etal-2023-contrastive</bibkey>
      <doi>10.18653/v1/2023.findings-acl.152</doi>
    </paper>
    <paper id="153">
      <title>Noisy Positive-Unlabeled Learning with Self-Training for Speculative Knowledge Graph Reasoning</title>
      <author><first>Ruijie</first><last>Wang</last><affiliation>University of Illinois at Urbana-Champaion</affiliation></author>
      <author><first>Baoyu</first><last>Li</last><affiliation>University of Illinois Urbana-Champaign</affiliation></author>
      <author><first>Yichen</first><last>Lu</last><affiliation>University of Illinois Urbana Champaign</affiliation></author>
      <author><first>Dachun</first><last>Sun</last><affiliation>University of Illinois at Urbana-Champaign</affiliation></author>
      <author><first>Jinning</first><last>Li</last><affiliation>University of Illinois at Urbana-Champaign</affiliation></author>
      <author><first>Yuchen</first><last>Yan</last><affiliation>University of Illinois at Urbana-Champaign</affiliation></author>
      <author><first>Shengzhong</first><last>Liu</last><affiliation>University of Illinois at Urbana-Champaign</affiliation></author>
      <author><first>Hanghang</first><last>Tong</last><affiliation>UIUC</affiliation></author>
      <author><first>Tarek</first><last>Abdelzaher</last><affiliation>University of Illinois at Urbana Champaign</affiliation></author>
      <pages>2440-2457</pages>
      <abstract>This paper studies speculative reasoning task on real-world knowledge graphs (KG) that contain both false negative issue (i.e., potential true facts being excluded) and false positive issue (i.e., unreliable or outdated facts being included). State-of-the-art methods fall short in the speculative reasoning ability, as they assume the correctness of a fact is solely determined by its presence in KG, making them vulnerable to false negative/positive issues. The new reasoning task is formulated as a noisy Positive-Unlabeled learning problem. We propose a variational framework, namely nPUGraph, that jointly estimates the correctness of both collected and uncollected facts (which we call label posterior) and updates model parameters during training. The label posterior estimation facilitates speculative reasoning from two perspectives. First, it improves the robustness of a label posterior-aware graph encoder against false positive links. Second, it identifies missing facts to provide high-quality grounds of reasoning. They are unified in a simple yet effective self-training procedure. Empirically, extensive experiments on three benchmark KG and one Twitter dataset with various degrees of false negative/positive cases demonstrate the effectiveness of nPUGraph.</abstract>
      <url hash="446d7c9f">2023.findings-acl.153</url>
      <bibkey>wang-etal-2023-noisy</bibkey>
      <doi>10.18653/v1/2023.findings-acl.153</doi>
    </paper>
    <paper id="154">
      <title><fixed-case>ACROSS</fixed-case>: An Alignment-based Framework for Low-Resource Many-to-One Cross-Lingual Summarization</title>
      <author><first>Peiyao</first><last>Li</last><affiliation>Nankai University</affiliation></author>
      <author><first>Zhengkun</first><last>Zhang</last><affiliation>Nankai University</affiliation></author>
      <author><first>Jun</first><last>Wang</last><affiliation>Ludong University</affiliation></author>
      <author><first>Liang</first><last>Li</last><affiliation>Nayuan Technology Co., Ltd.</affiliation></author>
      <author><first>Adam</first><last>Jatowt</last><affiliation>University of Innsbruck</affiliation></author>
      <author><first>Zhenglu</first><last>Yang</last><affiliation>Nankai University</affiliation></author>
      <pages>2458-2472</pages>
      <abstract>This research addresses the challenges of Cross-Lingual Summarization (CLS) in low-resource scenarios and over imbalanced multilingual data. Existing CLS studies mostly resort to pipeline frameworks or multi-task methods in bilingual settings. However, they ignore the data imbalance in multilingual scenarios and do not utilize the high-resource monolingual summarization data. In this paper, we propose the Aligned CROSs-lingual Summarization (ACROSS) model to tackle these issues. Our framework aligns low-resource cross-lingual data with high-resource monolingual data via contrastive and consistency loss, which help enrich low-resource information for high-quality summaries. In addition, we introduce a data augmentation method that can select informative monolingual sentences, which facilitates a deep exploration of high-resource information and introduce new information for low-resource languages. Experiments on the CrossSum dataset show that ACROSS outperforms baseline models and obtains consistently dominant performance on 45 language pairs.</abstract>
      <url hash="367fa163">2023.findings-acl.154</url>
      <bibkey>li-etal-2023-across</bibkey>
      <doi>10.18653/v1/2023.findings-acl.154</doi>
    </paper>
    <paper id="155">
      <title><fixed-case>RF</fixed-case>i<fixed-case>D</fixed-case>: Towards Rational Fusion-in-Decoder for Open-Domain Question Answering</title>
      <author><first>Cunxiang</first><last>Wang</last><affiliation>Westlake University &amp; Zhejiang University</affiliation></author>
      <author><first>Haofei</first><last>Yu</last><affiliation>Carnegie Mellon University</affiliation></author>
      <author><first>Yue</first><last>Zhang</last><affiliation>Westlake University</affiliation></author>
      <pages>2473-2481</pages>
      <abstract>Open-Domain Question Answering (ODQA) systems necessitate a reader model capable of generating answers by simultaneously referring to multiple passages. Although representative models like Fusion-in-Decoder (FiD) have been proposed to address this challenge, these systems can inadvertently rely on spurious features instead of genuine causal relationships between the question and the passages to generate answers. To counter this problem, we introduce the Rational Fusion-in-Decoder (RFiD) model. Our model leverages the encoders of FiD to differentiate between causal relationships and spurious features, subsequently guiding the decoder to generate answers informed by this discernment. Experimental results on two ODQA datasets, Natural Questions (NQ) and TriviaQA (TQ), demonstrate that our model surpasses previous methods, achieving improvements of up to 1.5 and 0.7 in Exact Match scores on NQ, and exhibits an enhanced ability to identify causal relationships.</abstract>
      <url hash="aadf1bc6">2023.findings-acl.155</url>
      <bibkey>wang-etal-2023-rfid</bibkey>
      <doi>10.18653/v1/2023.findings-acl.155</doi>
    </paper>
    <paper id="156">
      <title>Unsupervised Keyphrase Extraction by Learning Neural Keyphrase Set Function</title>
      <author><first>Mingyang</first><last>Song</last><affiliation>Beijing Jiaotong University</affiliation></author>
      <author><first>Haiyun</first><last>Jiang</last><affiliation>Tencent AI Lab</affiliation></author>
      <author><first>Lemao</first><last>Liu</last><affiliation>Tencent AI Lab</affiliation></author>
      <author><first>Shuming</first><last>Shi</last><affiliation>Tencent AI Lab</affiliation></author>
      <author><first>Liping</first><last>Jing</last><affiliation>Beijing Jiaotong Univesity</affiliation></author>
      <pages>2482-2494</pages>
      <abstract>We create a <i>paradigm shift</i> concerning building unsupervised keyphrase extraction systems in this paper. Instead of modeling the relevance between an individual candidate phrase and the document as in the commonly used framework, we formulate the unsupervised keyphrase extraction task as a document-set matching problem from <i>a set-wise perspective</i>, in which the document and the candidate set are globally matched in the semantic space to particularly take into account the interactions among all candidate phrases. Since it is intractable to exactly extract the keyphrase set by the matching function during the inference, we propose an approximate approach, which obtains the candidate subsets via a set extractor agent learned by reinforcement learning. Exhaustive experimental results demonstrate the effectiveness of our model, which outperforms the recent state-of-the-art unsupervised keyphrase extraction baselines by a large margin.</abstract>
      <url hash="9b14fe30">2023.findings-acl.156</url>
      <bibkey>song-etal-2023-unsupervised</bibkey>
      <doi>10.18653/v1/2023.findings-acl.156</doi>
    </paper>
    <paper id="157">
      <title>Diffusion Theory as a Scalpel: Detecting and Purifying Poisonous Dimensions in Pre-trained Language Models Caused by Backdoor or Bias</title>
      <author><first>Zhiyuan</first><last>Zhang</last><affiliation>Peking University</affiliation></author>
      <author><first>Deli</first><last>Chen</last><affiliation>Tencent Inc.</affiliation></author>
      <author><first>Hao</first><last>Zhou</last><affiliation>Pattern Recognition Center, WeChat, Tencent</affiliation></author>
      <author><first>Fandong</first><last>Meng</last><affiliation>WeChat AI, Tencent</affiliation></author>
      <author><first>Jie</first><last>Zhou</last><affiliation>Tencent Inc.</affiliation></author>
      <author><first>Xu</first><last>Sun</last><affiliation>Peking University</affiliation></author>
      <pages>2495-2517</pages>
      <abstract>Pre-trained Language Models (PLMs) may be poisonous with backdoors or bias injected by the suspicious attacker during the fine-tuning process. A core challenge of purifying potentially poisonous PLMs is precisely finding poisonous dimensions. To settle this issue, we propose the Fine-purifying approach, which utilizes the diffusion theory to study the dynamic process of fine-tuning for finding potentially poisonous dimensions. According to the relationship between parameter drifts and Hessians of different dimensions, we can detect poisonous dimensions with abnormal dynamics, purify them by resetting them to clean pre-trained weights, and then fine-tune the purified weights on a small clean dataset. To the best of our knowledge, we are the first to study the dynamics guided by the diffusion theory for safety or defense purposes. Experimental results validate the effectiveness of Fine-purifying even with a small clean dataset.</abstract>
      <url hash="da8e4e8d">2023.findings-acl.157</url>
      <bibkey>zhang-etal-2023-diffusion</bibkey>
      <doi>10.18653/v1/2023.findings-acl.157</doi>
    </paper>
    <paper id="158">
      <title>Retrieving Multimodal Prompts for Generative Visual Question Answering</title>
      <author><first>Timothy</first><last>Ossowski</last><affiliation>University of Wisconsin Madison</affiliation></author>
      <author><first>Junjie</first><last>Hu</last><affiliation>University of Wisconsin-Madison</affiliation></author>
      <pages>2518-2535</pages>
      <abstract>Recent years have witnessed impressive results of pre-trained vision-language models on knowledge-intensive tasks such as visual question answering (VQA). Despite the recent advances in VQA, existing methods mainly adopt a discriminative formulation that predicts answers within a pre-defined label set, leading to easy overfitting on low-resource domains (e.g., medicine) and poor generalization under domain shift to another dataset. To tackle this limitation, we propose a novel generative model enhanced by multimodal prompt retrieval (MPR) that integrates retrieved prompts and multimodal features to generate answers in free text. Our generative model enables rapid zero-shot dataset adaptation to unseen data distributions and open-set answer labels across datasets. Our experiments on medical VQA tasks show that MPR outperforms its non-retrieval counterpart by up to 30% accuracy points in a few-shot domain adaptation setting.</abstract>
      <url hash="f0119bfa">2023.findings-acl.158</url>
      <bibkey>ossowski-hu-2023-retrieving</bibkey>
      <doi>10.18653/v1/2023.findings-acl.158</doi>
    </paper>
    <paper id="159">
      <title><fixed-case>I</fixed-case>nfo<fixed-case>S</fixed-case>ync: Information Synchronization across Multilingual Semi-structured Tables</title>
      <author><first>Siddharth</first><last>Khincha</last><affiliation>Indian Institute of Technology Guwahati</affiliation></author>
      <author><first>Chelsi</first><last>Jain</last><affiliation>College of Technology and Engineering, MPUAT</affiliation></author>
      <author><first>Vivek</first><last>Gupta</last><affiliation>School of Computing, University of Utah</affiliation></author>
      <author><first>Tushar</first><last>Kataria</last><affiliation>University of Utah</affiliation></author>
      <author><first>Shuo</first><last>Zhang</last><affiliation>Bloomberg</affiliation></author>
      <pages>2536-2559</pages>
      <abstract>Information Synchronization of semi-structured data across languages is challenging. For example, Wikipedia tables in one language need to be synchronized with others. To address this problem, we introduce a new dataset InfoSync and a two-step method for tabular synchronization. InfoSync contains 100K entity-centric tables (Wikipedia Infoboxes) across 14 languages, of which a subset (~3.5K pairs) are manually annotated. The proposed method includes 1) Information Alignment to map rows and 2) Information Update for updating missing/outdated information for aligned tables across multilingual tables. When evaluated on InfoSync, information alignment achieves an F1 score of 87.91 (en &lt;-&gt; non-en). To evaluate information updation, we perform human-assisted Wikipedia edits on Infoboxes for 532 table pairs. Our approach obtains an acceptance rate of 77.28% on Wikipedia, showing the effectiveness of the proposed method.</abstract>
      <url hash="387f46a1">2023.findings-acl.159</url>
      <bibkey>khincha-etal-2023-infosync</bibkey>
      <doi>10.18653/v1/2023.findings-acl.159</doi>
    </paper>
    <paper id="160">
      <title><fixed-case>T</fixed-case>2<fixed-case>IAT</fixed-case>: Measuring Valence and Stereotypical Biases in Text-to-Image Generation</title>
      <author><first>Jialu</first><last>Wang</last><affiliation>University of California, Santa Cruz</affiliation></author>
      <author><first>Xinyue</first><last>Liu</last><affiliation>UC Santa Cruz</affiliation></author>
      <author><first>Zonglin</first><last>Di</last><affiliation>UCSC</affiliation></author>
      <author id="yang-liu"><first>Yang</first><last>Liu</last><affiliation>UC Santa Cruz</affiliation></author>
      <author><first>Xin</first><last>Wang</last><affiliation>University of California, Santa Cruz</affiliation></author>
      <pages>2560-2574</pages>
      <abstract>*Warning: This paper contains several contents that may be toxic, harmful, or offensive.*In the last few years, text-to-image generative models have gained remarkable success in generating images with unprecedented quality accompanied by a breakthrough of inference speed. Despite their rapid progress, human biases that manifest in the training examples, particularly with regard to common stereotypical biases, like gender and skin tone, still have been found in these generative models. In this work, we seek to measure more complex human biases exist in the task of text-to-image generations. Inspired by the well-known Implicit Association Test (IAT) from social psychology, we propose a novel Text-to-Image Association Test (T2IAT) framework that quantifies the implicit stereotypes between concepts and valence, and those in the images. We replicate the previously documented bias tests on generative models, including morally neutral tests on flowers and insects as well as demographic stereotypical tests on diverse social attributes. The results of these experiments demonstrate the presence of complex stereotypical behaviors in image generations.</abstract>
      <url hash="9797c16c">2023.findings-acl.160</url>
      <bibkey>wang-etal-2023-t2iat</bibkey>
      <doi>10.18653/v1/2023.findings-acl.160</doi>
    </paper>
    <paper id="161">
      <title>An Investigation of Evaluation Methods in Automatic Medical Note Generation</title>
      <author><first>Asma</first><last>Ben Abacha</last><affiliation>Microsoft</affiliation></author>
      <author><first>Wen-wai</first><last>Yim</last><affiliation>Microsoft</affiliation></author>
      <author><first>George</first><last>Michalopoulos</last><affiliation>Microsoft</affiliation></author>
      <author><first>Thomas</first><last>Lin</last><affiliation>Microsoft</affiliation></author>
      <pages>2575-2588</pages>
      <abstract>Recent studies on automatic note generation have shown that doctors can save significant amounts of time when using automatic clinical note generation (Knoll et al., 2022). Summarization models have been used for this task to generate clinical notes as summaries of doctor-patient conversations (Krishna et al., 2021; Cai et al., 2022). However, assessing which model would best serve clinicians in their daily practice is still a challenging task due to the large set of possible correct summaries, and the potential limitations of automatic evaluation metrics. In this paper we study evaluation methods and metrics for the automatic generation of clinical notes from medical conversation. In particular, we propose new task-specific metrics and we compare them to SOTA evaluation metrics in text summarization and generation, including: (i) knowledge-graph embedding-based metrics, (ii) customized model-based metrics with domain-specific weights, (iii) domain-adapted/fine-tuned metrics, and (iv) ensemble metrics. To study the correlation between the automatic metrics and manual judgments, we evaluate automatic notes/summaries by comparing the system and reference facts and computing the factual correctness, and the hallucination and omission rates for critical medical facts. This study relied on seven datasets manually annotated by domain experts. Our experiments show that automatic evaluation metrics can have substantially different behaviors on different types of clinical notes datasets. However, the results highlight one stable subset of metrics as the most correlated with human judgments with a relevant aggregation of different evaluation criteria.</abstract>
      <url hash="42b9afad">2023.findings-acl.161</url>
      <bibkey>ben-abacha-etal-2023-investigation</bibkey>
      <doi>10.18653/v1/2023.findings-acl.161</doi>
    </paper>
    <paper id="162">
      <title>Rethinking Translation Memory Augmented Neural Machine Translation</title>
      <author><first>Hongkun</first><last>Hao</last><affiliation>Shanghai Jiao Tong University</affiliation></author>
      <author><first>Guoping</first><last>Huang</last><affiliation>Tencent AI Lab</affiliation></author>
      <author><first>Lemao</first><last>Liu</last><affiliation>Tencent AI Lab</affiliation></author>
      <author><first>Zhirui</first><last>Zhang</last><affiliation>Tencent AI Lab</affiliation></author>
      <author><first>Shuming</first><last>Shi</last><affiliation>Tencent AI Lab</affiliation></author>
      <author><first>Rui</first><last>Wang</last><affiliation>Shanghai Jiao Tong University</affiliation></author>
      <pages>2589-2605</pages>
      <abstract>This paper rethinks translation memory augmented neural machine translation (TM-augmented NMT) from two perspectives, i.e., a probabilistic view of retrieval and the variance-bias decomposition principle. The finding demonstrates that TM-augmented NMT is good at the ability of fitting data (i.e., lower bias) but is more sensitive to the fluctuations in the training data (i.e., higher variance), which provides an explanation to a recently reported contradictory phenomenon on the same translation task: TM-augmented NMT substantially advances NMT without TM under the high resource scenario whereas it fails under the low resource scenario. Then this paper proposes a simple yet effective TM-augmented NMT model to promote the variance and address the contradictory phenomenon. Extensive experiments show that the proposed TM-augmented NMT achieves consistent gains over both conventional NMT and existing TM-augmented NMT under two variance-preferable (low resource and plug-and-play) scenarios as well as the high resource scenario.</abstract>
      <url hash="d8c31cf4">2023.findings-acl.162</url>
      <bibkey>hao-etal-2023-rethinking</bibkey>
      <doi>10.18653/v1/2023.findings-acl.162</doi>
    </paper>
    <paper id="163">
      <title>Controlling Styles in Neural Machine Translation with Activation Prompt</title>
      <author><first>Yifan</first><last>Wang</last><affiliation>Fudan University</affiliation></author>
      <author><first>Zewei</first><last>Sun</last><affiliation>ByteDance</affiliation></author>
      <author><first>Shanbo</first><last>Cheng</last><affiliation>Bytedance AI Lab</affiliation></author>
      <author><first>Weiguo</first><last>Zheng</last><affiliation>Fudan University</affiliation></author>
      <author><first>Mingxuan</first><last>Wang</last><affiliation>Bytedance AI Lab</affiliation></author>
      <pages>2606-2620</pages>
      <abstract>Controlling styles in neural machine translation (NMT) has attracted wide attention, as it is crucial for enhancing user experience. Earlier studies on this topic typically concentrate on regulating the level of formality and achieve some progress in this area. However, they still encounter two major challenges. The first is the difficulty in style evaluation. The style comprises various aspects such as lexis, syntax, and others that provide abundant information. Nevertheless, only formality has been thoroughly investigated. The second challenge involves excessive dependence on incremental adjustments, particularly when new styles are necessary. To address both challenges, this paper presents a new benchmark and approach. A multiway stylized machine translation (MSMT) benchmark is introduced, incorporating diverse categories of styles across four linguistic domains. Then, we propose a method named style activation prompt (StyleAP) by retrieving prompts from stylized monolingual corpus, which does not require extra fine-tuning. Experiments show that StyleAP could effectively control the style of translation and achieve remarkable performance.</abstract>
      <url hash="25d45d29">2023.findings-acl.163</url>
      <bibkey>wang-etal-2023-controlling</bibkey>
      <doi>10.18653/v1/2023.findings-acl.163</doi>
    </paper>
    <paper id="164">
      <title>Focusing, Bridging and Prompting for Few-shot Nested Named Entity Recognition</title>
      <author><first>Yuanyuan</first><last>Xu</last><affiliation>Southeast University</affiliation></author>
      <author><first>Zeng</first><last>Yang</last><affiliation>Southeast University</affiliation></author>
      <author><first>Linhai</first><last>Zhang</last><affiliation>Southeast University</affiliation></author>
      <author><first>Deyu</first><last>Zhou</last><affiliation>Southeast University</affiliation></author>
      <author><first>Tiandeng</first><last>Wu</last><affiliation>Huawei Technologies Co., Ltd.</affiliation></author>
      <author><first>Rong</first><last>Zhou</last><affiliation>Huawei Technologies Co., Ltd.</affiliation></author>
      <pages>2621-2637</pages>
      <abstract>Few-shot named entity recognition (NER), identifying named entities with a small number of labeled data, has attracted much attention. Frequently, entities are nested within each other. However, most of the existing work on few-shot NER addresses flat entities instead of nested entities. To tackle nested NER in a few-shot setting, it is crucial to utilize the limited labeled data to mine unique features of nested entities, such as the relationship between inner and outer entities and contextual position information. Therefore, in this work, we propose a novel method based on focusing, bridging and prompting for few-shot nested NER without using source domain data. Both focusing and bridging components provide accurate candidate spans for the prompting component. The prompting component leverages the unique features of nested entities to classify spans based on soft prompts and contrastive learning. Experimental results show that the proposed approach achieves state-of-the-art performance consistently on the four benchmark datasets (ACE2004, ACE2005, GENIA and KBP2017) and outperforms several competing baseline models on F1-score by 9.33% on ACE2004, 6.17% on ACE2005, 9.40% on GENIA and 5.12% on KBP2017 on the 5-shot setting.</abstract>
      <url hash="9f0d4553">2023.findings-acl.164</url>
      <bibkey>xu-etal-2023-focusing</bibkey>
      <doi>10.18653/v1/2023.findings-acl.164</doi>
    </paper>
    <paper id="165">
      <title>Together We Make Sense–Learning Meta-Sense Embeddings</title>
      <author><first>Haochen</first><last>Luo</last><affiliation>University of Oxford</affiliation></author>
      <author><first>Yi</first><last>Zhou</last><affiliation>Cardiff University</affiliation></author>
      <author><first>Danushka</first><last>Bollegala</last><affiliation>University of Liverpool/Amazon</affiliation></author>
      <pages>2638-2651</pages>
      <abstract>Sense embedding learning methods learn multiple vectors for a given ambiguous word, corresponding to its different word senses. For this purpose, different methods have been proposed in prior work on sense embedding learning that use different sense inventories, sense-tagged corpora and learning methods. However, not all existing sense embeddings cover all senses of ambiguous words equally well due to the discrepancies in their training resources. To address this problem, we propose the first-ever meta-sense embedding method – Neighbour Preserving Meta-Sense Embeddings, which learns meta-sense embeddings by combining multiple independently trained source sense embeddings such that the sense neighbourhoods computed from the source embeddings are preserved in the meta-embedding space. Our proposed method can combine source sense embeddings that cover different sets of word senses. Experimental results on Word Sense Disambiguation (WSD) and Word-in-Context (WiC) tasks show that the proposed meta-sense embedding method consistently outperforms several competitive baselines. An anonymised version of the source code implementation for our proposed method is submitted to reviewing system. Both source code and the learnt meta-sense embeddings will be publicly released upon paper acceptance.</abstract>
      <url hash="aeaa0813">2023.findings-acl.165</url>
      <bibkey>luo-etal-2023-together</bibkey>
      <doi>10.18653/v1/2023.findings-acl.165</doi>
    </paper>
    <paper id="166">
      <title>Multimodal Prompt Learning for Product Title Generation with Extremely Limited Labels</title>
      <author><first>Bang</first><last>Yang</last><affiliation>Peking University; Peng Cheng Laboratory</affiliation></author>
      <author><first>Fenglin</first><last>Liu</last><affiliation>University of Oxford</affiliation></author>
      <author><first>Zheng</first><last>Li</last><affiliation>Amazon</affiliation></author>
      <author><first>Qingyu</first><last>Yin</last><affiliation>Amazon</affiliation></author>
      <author><first>Chenyu</first><last>You</last><affiliation>Yale University</affiliation></author>
      <author><first>Bing</first><last>Yin</last><affiliation>Amazon.com</affiliation></author>
      <author><first>Yuexian</first><last>Zou</last><affiliation>Peking University</affiliation></author>
      <pages>2652-2665</pages>
      <abstract>Generating an informative and attractive title for the product is a crucial task for e-commerce. Most existing works follow the standard multimodal natural language generation approaches, e.g., image captioning, and employ the large scale of human-labelled datasets to train desirable models. However, for novel products, especially in a different domain, there are few existing labelled data. In this paper, we propose a prompt-based approach, i.e., the Multimodal Prompt Learning framework, to accurately and efficiently generate titles for novel products with limited labels. We observe that the core challenges of novel product title generation are the understanding of novel product characteristics and the generation of titles in a novel writing style. To this end, we build a set of multimodal prompts from different modalities to preserve the corresponding characteristics and writing styles of novel products. As a result, with extremely limited labels for training, the proposed method can retrieve the multimodal prompts to generate desirable titles for novel products. The experiments and analyses are conducted on five novel product categories under both the in-domain and out-of-domain experimental settings. The results show that, with only 1% of downstream labelled data for training, our proposed approach achieves the best few-shot results and even achieves competitive results with fully-supervised methods trained on 100% of training data; With the full labelled data for training, our method achieves state-of-the-art results.</abstract>
      <url hash="45f9fe55">2023.findings-acl.166</url>
      <bibkey>yang-etal-2023-multimodal</bibkey>
      <doi>10.18653/v1/2023.findings-acl.166</doi>
    </paper>
    <paper id="167">
      <title>Large Language Models are Built-in Autoregressive Search Engines</title>
      <author><first>Noah</first><last>Ziems</last><affiliation>University of Notre Dame</affiliation></author>
      <author><first>Wenhao</first><last>Yu</last><affiliation>University of Notre Dame</affiliation></author>
      <author><first>Zhihan</first><last>Zhang</last><affiliation>University of Notre Dame</affiliation></author>
      <author><first>Meng</first><last>Jiang</last><affiliation>University of Notre Dame</affiliation></author>
      <pages>2666-2678</pages>
      <abstract>Document retrieval is a key stage of standard Web search engines. Existing dual-encoder dense retrievers obtain representations for questions and documents independently, allowing for only shallow interactions between them. To overcome this limitation, recent autoregressive search engines replace the dual-encoder architecture by directly generating identifiers for relevant documents in the candidate pool. However, the training cost of such autoregressive search engines rises sharply as the number of candidate documents increases. In this paper, we find that large language models (LLMs) can follow human instructions to directly generate URLs for document retrieval. Surprisingly, when providing a few Query-URL pairs as in-context demonstrations, LLMs can generate Web URLs where nearly 90% of the corresponding documents contain correct answers to open-domain questions. In this way, LLMs can be thought of as built-in search engines, since they have not been explicitly trained to map questions to document identifiers. Experiments demonstrate that our method can consistently achieve better retrieval performance than existing retrieval approaches by a significant margin on three open-domain question answering benchmarks, under both zero and few-shot settings. The code for this work can be found at <url>https://github.com/Ziems/llm-url</url>.</abstract>
      <url hash="da999833">2023.findings-acl.167</url>
      <bibkey>ziems-etal-2023-large</bibkey>
      <doi>10.18653/v1/2023.findings-acl.167</doi>
    </paper>
    <paper id="168">
      <title>Beyond Triplet: Leveraging the Most Data for Multimodal Machine Translation</title>
      <author><first>Yaoming</first><last>Zhu</last><affiliation>ByteDance AI lab</affiliation></author>
      <author><first>Zewei</first><last>Sun</last><affiliation>ByteDance</affiliation></author>
      <author><first>Shanbo</first><last>Cheng</last><affiliation>Bytedance AI Lab</affiliation></author>
      <author><first>Luyang</first><last>Huang</last><affiliation>Bytedance</affiliation></author>
      <author><first>Liwei</first><last>Wu</last><affiliation>Bytedance AI Lab</affiliation></author>
      <author><first>Mingxuan</first><last>Wang</last><affiliation>Bytedance AI Lab</affiliation></author>
      <pages>2679-2697</pages>
      <abstract>Multimodal machine translation (MMT) aims to improve translation quality by incorporating information from other modalities, such as vision. Previous MMT systems focus on better access and use of visual information and tend to validate their methods on image-related datasets. However, these studies face two challenges. First, they can only utilize a limited amount of data that is composed of bilingual texts and images (referred to as “triple data”), which is scarce. Second, current benchmarks for MMT are restricted and do not correspond to realistic scenarios. Therefore, this paper correspondingly establishes new methods and a new dataset for MMT. We propose a novel framework for MMT that addresses these challenges by utilizing large-scale non-triple data, such as monolingual image-text and parallel text-only data. Additionally, we construct a new e-commercial multimodal translation dataset, named EMMT, of which the test set is specifically designed to include ambiguous words that require visual context for accurate translation. Experiments show that our method is well-suited for real-world scenarios and can significantly improve translation performance with more non-triple data. In addition, our model also rivals or surpasses various SOTA models in conventional multimodal translation benchmarks.</abstract>
      <url hash="4a6fc0fe">2023.findings-acl.168</url>
      <bibkey>zhu-etal-2023-beyond</bibkey>
      <doi>10.18653/v1/2023.findings-acl.168</doi>
    </paper>
    <paper id="169">
      <title>From chocolate bunny to chocolate crocodile: Do Language Models Understand Noun Compounds?</title>
      <author><first>Albert</first><last>Coil</last><affiliation>University of British Columbia</affiliation></author>
      <author><first>Vered</first><last>Shwartz</last><affiliation>University of British Columbia</affiliation></author>
      <pages>2698-2710</pages>
      <abstract>Noun compound interpretation is the task of expressing a noun compound (e.g. chocolate bunny) in a free-text paraphrase that makes the relationship between the constituent nouns explicit (e.g. bunny-shaped chocolate). We propose modifications to the data and evaluation setup of the standard task (Hendrickx et al., 2013), and show that GPT-3 solves it almost perfectly. We then investigate the task of noun compound conceptualization, i.e. paraphrasing a novel or rare noun compound. E.g., chocolate crocodile is a crocodile-shaped chocolate. This task requires creativity, commonsense, and the ability to generalize knowledge about similar concepts. While GPT-3’s performance is not perfect, it is better than that of humans—likely thanks to its access to vast amounts of knowledge, and because conceptual processing is effortful for people (Connell and Lynott, 2012). Finally, we estimate the extent to which GPT-3 is reasoning about the world vs. parroting its training data. We find that the outputs from GPT-3 often have significant overlap with a large web corpus, but that the parroting strategy is less beneficial for novel noun compounds.</abstract>
      <url hash="396c2aa8">2023.findings-acl.169</url>
      <bibkey>coil-shwartz-2023-chocolate</bibkey>
      <doi>10.18653/v1/2023.findings-acl.169</doi>
    </paper>
    <paper id="170">
      <title>Measuring Intersectional Biases in Historical Documents</title>
      <author><first>Nadav</first><last>Borenstein</last><affiliation>Department of Computer Science, University of Copenhagen</affiliation></author>
      <author><first>Karolina</first><last>Stanczak</last><affiliation>University of Copenhagen</affiliation></author>
      <author><first>Thea</first><last>Rolskov</last><affiliation>Aarhus University</affiliation></author>
      <author><first>Natacha</first><last>Klein Käfer</last><affiliation>Centre for Privacy Studies</affiliation></author>
      <author><first>Natália</first><last>da Silva Perez</last><affiliation>University of Copenhagen</affiliation></author>
      <author><first>Isabelle</first><last>Augenstein</last><affiliation>Department of Computer Science, University of Copenhagen</affiliation></author>
      <pages>2711-2730</pages>
      <abstract>Data-driven analyses of biases in historical texts can help illuminate the origin and development of biases prevailing in modern society. However, digitised historical documents pose a challenge for NLP practitioners as these corpora suffer from errors introduced by optical character recognition (OCR) and are written in an archaic language. In this paper, we investigate the continuities and transformations of bias in historical newspapers published in the Caribbean during the colonial era (18th to 19th centuries). Our analyses are performed along the axes of gender, race, and their intersection. We examine these biases by conducting a temporal study in which we measure the development of lexical associations using distributional semantics models and word embeddings. Further, we evaluate the effectiveness of techniques designed to process OCR-generated data and assess their stability when trained on and applied to the noisy historical newspapers. We find that there is a trade-off between the stability of the word embeddings and their compatibility with the historical dataset. We provide evidence that gender and racial biases are interdependent, and their intersection triggers distinct effects. These findings align with the theory of intersectionality, which stresses that biases affecting people with multiple marginalised identities compound to more than the sum of their constituents.</abstract>
      <url hash="73458fd1">2023.findings-acl.170</url>
      <bibkey>borenstein-etal-2023-measuring</bibkey>
      <doi>10.18653/v1/2023.findings-acl.170</doi>
    </paper>
    <paper id="171">
      <title>Incomplete Utterance Rewriting by A Two-Phase Locate-and-Fill Regime</title>
      <author><first>Zitong</first><last>Li</last><affiliation>Shanghai Jiao Tong University</affiliation></author>
      <author><first>Jiawei</first><last>Li</last><affiliation>Shanghai Jiao Tong University</affiliation></author>
      <author><first>Haifeng</first><last>Tang</last><affiliation>China Merchants Bank Credit Card Center</affiliation></author>
      <author><first>Kenny</first><last>Zhu</last><affiliation>Shanghai Jiao Tong University</affiliation></author>
      <author><first>Ruolan</first><last>Yang</last><affiliation>University of California San Diego</affiliation></author>
      <pages>2731-2745</pages>
      <abstract>Rewriting incomplete and ambiguous utterances can improve dialogue models’ understanding of the context and help them generate better results. However, the existing end-to-end models will have the problem of too large search space, resulting in poor quality of rewriting results. We propose a 2-phase rewriting framework which first predicts the empty slots in the utterance that need to be completed, and then generate the part to be filled into each positions. Our framework is simple to implement, fast to run, and achieves the state-of-the-art results on several public rewriting datasets.</abstract>
      <url hash="875dd760">2023.findings-acl.171</url>
      <bibkey>li-etal-2023-incomplete</bibkey>
      <doi>10.18653/v1/2023.findings-acl.171</doi>
    </paper>
    <paper id="172">
      <title>Exploring Variation of Results from Different Experimental Conditions</title>
      <author><first>Maja</first><last>Popović</last><affiliation>ADAPT, Dublin City University</affiliation></author>
      <author><first>Mohammad</first><last>Arvan</last><affiliation>University of Illinois at Chicago</affiliation></author>
      <author><first>Natalie</first><last>Parde</last><affiliation>University of Illinois at Chicago</affiliation></author>
      <author><first>Anya</first><last>Belz</last><affiliation>ADAPT Research Centre, Dublin City University</affiliation></author>
      <pages>2746-2757</pages>
      <abstract>It might reasonably be expected that running multiple experiments for the same task using the same data and model would yield very similar results. Recent research has, however, shown this not to be the case for many NLP experiments. In this paper, we report extensive coordinated work by two NLP groups to run the training and testing pipeline for three neural text simplification models under varying experimental conditions, including different random seeds, run-time environments, and dependency versions, yielding a large number of results for each of the three models using the same data and train/dev/test set splits. From one perspective, these results can be interpreted as shedding light on the reproducibility of evaluation results for the three NTS models, and we present an in-depth analysis of the variation observed for different combinations of experimental conditions. From another perspective, the results raise the question of whether the averaged score should be considered the ‘true’ result for each model.</abstract>
      <url hash="1f22cc52">2023.findings-acl.172</url>
      <bibkey>popovic-etal-2023-exploring</bibkey>
      <doi>10.18653/v1/2023.findings-acl.172</doi>
    </paper>
    <paper id="173">
      <title>Playing the Part of the Sharp Bully: Generating Adversarial Examples for Implicit Hate Speech Detection</title>
      <author><first>Nicolas</first><last>Ocampo</last><affiliation>Université Côte d’Azur</affiliation></author>
      <author><first>Elena</first><last>Cabrio</last><affiliation>Université Côte d’Azur, Inria, CNRS, I3S</affiliation></author>
      <author><first>Serena</first><last>Villata</last><affiliation>Université Côte d’Azur, CNRS, Inria, I3S</affiliation></author>
      <pages>2758-2772</pages>
      <abstract>Research on abusive content detection on social media has primarily focused on explicit forms of hate speech (HS), that are often identifiable by recognizing hateful words and expressions. Messages containing linguistically subtle and implicit forms of hate speech still constitute an open challenge for automatic hate speech detection. In this paper, we propose a new framework for generating adversarial implicit HS short-text messages using Auto-regressive Language Models. Moreover, we propose a strategy to group the generated implicit messages in complexity levels (EASY, MEDIUM, and HARD categories) characterizing how challenging these messages are for supervised classifiers. Finally, relying on (Dinan et al., 2019; Vidgen et al., 2021), we propose a “build it, break it, fix it”, training scheme using HARD messages showing how iteratively retraining on HARD messages substantially leverages SOTA models’ performances on implicit HS benchmarks.</abstract>
      <url hash="d8a17e96">2023.findings-acl.173</url>
      <bibkey>ocampo-etal-2023-playing</bibkey>
      <doi>10.18653/v1/2023.findings-acl.173</doi>
    </paper>
    <paper id="174">
      <title><fixed-case>X</fixed-case>-<fixed-case>R</fixed-case>i<fixed-case>SAWOZ</fixed-case>: High-Quality End-to-End Multilingual Dialogue Datasets and Few-shot Agents</title>
      <author><first>Mehrad</first><last>Moradshahi</last><affiliation>Stanford University</affiliation></author>
      <author><first>Tianhao</first><last>Shen</last><affiliation>Tianjin University</affiliation></author>
      <author><first>Kalika</first><last>Bali</last><affiliation>Microsoft Research Labs</affiliation></author>
      <author><first>Monojit</first><last>Choudhury</last><affiliation>Microsoft</affiliation></author>
      <author><first>Gael</first><last>de Chalendar</last><affiliation>CEA LIST</affiliation></author>
      <author><first>Anmol</first><last>Goel</last><affiliation>IIIT Hyderabad</affiliation></author>
      <author><first>Sungkyun</first><last>Kim</last><affiliation>Hanyang University</affiliation></author>
      <author><first>Prashant</first><last>Kodali</last><affiliation>IIIT Hyderabad</affiliation></author>
      <author><first>Ponnurangam</first><last>Kumaraguru</last><affiliation>IIIT Hyderabad</affiliation></author>
      <author><first>Nasredine</first><last>Semmar</last><affiliation>CEA LIST</affiliation></author>
      <author><first>Sina</first><last>Semnani</last><affiliation>Stanford University</affiliation></author>
      <author><first>Jiwon</first><last>Seo</last><affiliation>Hanyang University</affiliation></author>
      <author><first>Vivek</first><last>Seshadri</last><affiliation>Microsoft Research India / Karya Inc</affiliation></author>
      <author><first>Manish</first><last>Shrivastava</last><affiliation>International Institute of Information Technology Hyderabad</affiliation></author>
      <author><first>Michael</first><last>Sun</last><affiliation>Stanford University</affiliation></author>
      <author><first>Aditya</first><last>Yadavalli</last><affiliation>Karya Inc</affiliation></author>
      <author><first>Chaobin</first><last>You</last><affiliation>Tianjin University</affiliation></author>
      <author><first>Deyi</first><last>Xiong</last><affiliation>Tianjin University</affiliation></author>
      <author><first>Monica</first><last>Lam</last><affiliation>Stanford University</affiliation></author>
      <pages>2773-2794</pages>
      <abstract>Task-oriented dialogue research has mainly focused on a few popular languages like English and Chinese, due to the high dataset creation cost for a new language. To reduce the cost, we apply manual editing to automatically translated data. We create a new multilingual benchmark, X-RiSAWOZ, by translating the Chinese RiSAWOZ to 4 languages: English, French, Hindi, Korean; and a code-mixed English-Hindi language.X-RiSAWOZ has more than 18,000 human-verified dialogue utterances for each language, and unlike most multilingual prior work, is an end-to-end dataset for building fully-functioning agents. The many difficulties we encountered in creating X-RiSAWOZ led us to develop a toolset to accelerate the post-editing of a new language dataset after translation. This toolset improves machine translation with a hybrid entity alignment technique that combines neural with dictionary-based methods, along with many automated and semi-automated validation checks. We establish strong baselines for X-RiSAWOZ by training dialogue agents in the zero- and few-shot settings where limited gold data is available in the target language. Our results suggest that our translation and post-editing methodology and toolset can be used to create new high-quality multilingual dialogue agents cost-effectively. Our dataset, code, and toolkit are released open-source.</abstract>
      <url hash="a7a25afd">2023.findings-acl.174</url>
      <bibkey>moradshahi-etal-2023-x</bibkey>
      <doi>10.18653/v1/2023.findings-acl.174</doi>
    </paper>
    <paper id="175">
      <title>Subword Segmental Machine Translation: Unifying Segmentation and Target Sentence Generation</title>
      <author><first>Francois</first><last>Meyer</last><affiliation>University of Cape Town</affiliation></author>
      <author><first>Jan</first><last>Buys</last><affiliation>University of Cape Town</affiliation></author>
      <pages>2795-2809</pages>
      <abstract>Subword segmenters like BPE operate as a preprocessing step in neural machine translation and other (conditional) language models. They are applied to datasets before training, so translation or text generation quality relies on the quality of segmentations. We propose a departure from this paradigm, called subword segmental machine translation (SSMT). SSMT unifies subword segmentation and MT in a single trainable model. It learns to segment target sentence words while jointly learning to generate target sentences. To use SSMT during inference we propose dynamic decoding, a text generation algorithm that adapts segmentations as it generates translations. Experiments across 6 translation directions show that SSMT improves chrF scores for morphologically rich agglutinative languages. Gains are strongest in the very low-resource scenario. SSMT also learns subwords that are closer to morphemes compared to baselines and proves more robust on a test set constructed for evaluating morphological compositional generalisation.</abstract>
      <url hash="ee801ae3">2023.findings-acl.175</url>
      <bibkey>meyer-buys-2023-subword</bibkey>
      <doi>10.18653/v1/2023.findings-acl.175</doi>
    </paper>
    <paper id="176">
      <title>Measuring and Mitigating Local Instability in Deep Neural Networks</title>
      <author><first>Arghya</first><last>Datta</last><affiliation>Amazon.com Services LLC</affiliation></author>
      <author><first>Subhrangshu</first><last>Nandi</last><affiliation>Amazon</affiliation></author>
      <author><first>Jingcheng</first><last>Xu</last><affiliation>University of Wisconsin - Madison</affiliation></author>
      <author><first>Greg</first><last>Ver Steeg</last><affiliation>University of California Riverside</affiliation></author>
      <author><first>He</first><last>Xie</last><affiliation>Amazon Alexa AI</affiliation></author>
      <author><first>Anoop</first><last>Kumar</last><affiliation>Amazon</affiliation></author>
      <author><first>Aram</first><last>Galstyan</last><affiliation>USC Information Sciences Institute</affiliation></author>
      <pages>2810-2823</pages>
      <abstract>Deep Neural Networks (DNNs) are becoming integral components of real world services relied upon by millions of users. Unfortunately, architects of these systems can find it difficult to ensure reliable performance as irrelevant details like random initialization can unexpectedly change the outputs of a trained system with potentially disastrous consequences. We formulate the model stability problem by studying how the predictions of a model change, even when it is retrained on the same data, as a consequence of stochasticity in the training process. For Natural Language Understanding (NLU) tasks, we find instability in predictions for a significant fraction of queries. We formulate principled metrics, like per-sample “label entropy” across training runs or within a single training run, to quantify this phenomenon. Intriguingly, we find that unstable predictions do not appear at random, but rather appear to be clustered in data-specific ways. We study data-agnostic regularization methods to improve stability and propose new data-centric methods that exploit our local stability estimates. We find that our localized data-specific mitigation strategy dramatically outperforms data-agnostic methods, and comes within 90% of the gold standard, achieved by ensembling, at a fraction of the computational cost.</abstract>
      <url hash="82c0d18d">2023.findings-acl.176</url>
      <bibkey>datta-etal-2023-measuring</bibkey>
      <doi>10.18653/v1/2023.findings-acl.176</doi>
    </paper>
    <paper id="177">
      <title>What Knowledge Is Needed? Towards Explainable Memory for k<fixed-case>NN</fixed-case>-<fixed-case>MT</fixed-case> Domain Adaptation</title>
      <author><first>Wenhao</first><last>Zhu</last><affiliation>National Key Laboratory for Novel Software Technology, Nanjing University</affiliation></author>
      <author><first>Shujian</first><last>Huang</last><affiliation>National Key Laboratory for Novel Software Technology, Nanjing University</affiliation></author>
      <author><first>Yunzhe</first><last>Lv</last><affiliation>Nanjing University</affiliation></author>
      <author><first>Xin</first><last>Zheng</last><affiliation>National Key Laboratory for Novel Software Technology, Nanjing University</affiliation></author>
      <author><first>Jiajun</first><last>Chen</last><affiliation>Nanjing University</affiliation></author>
      <pages>2824-2836</pages>
      <abstract>kNN-MT presents a new paradigm for domain adaptation by building an external datastore, which usually saves all target language token occurrences in the parallel corpus. As a result, the constructed datastore is usually large and possibly redundant. In this paper, we investigate the interpretability issue of this approach: what knowledge does the NMT model need? We propose the notion of local correctness (LAC) as a new angle, which describes the potential translation correctness for a single entry and for a given neighborhood. Empirical study shows that our investigation successfully finds the conditions where the NMT model could easily fail and need related knowledge. Experiments on six diverse target domains and two language-pairs show that pruning according to local correctness brings a light and more explainable memory for kNN-MT domain adaptation.</abstract>
      <url hash="e0af3709">2023.findings-acl.177</url>
      <bibkey>zhu-etal-2023-knowledge</bibkey>
      <doi>10.18653/v1/2023.findings-acl.177</doi>
    </paper>
    <paper id="178">
      <title>Measuring Your <fixed-case>ASTE</fixed-case> Models in The Wild: A Diversified Multi-domain Dataset For Aspect Sentiment Triplet Extraction</title>
      <author><first>Ting</first><last>Xu</last><affiliation>Nanjing University</affiliation></author>
      <author><first>Huiyun</first><last>Yang</last><affiliation>ByteDance</affiliation></author>
      <author><first>Zhen</first><last>Wu</last><affiliation>Nanjing University</affiliation></author>
      <author><first>Jiaze</first><last>Chen</last><affiliation>Bytedance AI Lab</affiliation></author>
      <author><first>Fei</first><last>Zhao</last><affiliation>Nanjing University</affiliation></author>
      <author><first>Xinyu</first><last>Dai</last><affiliation>National Key Laboratory for Novel Software Technology, Nanjing University</affiliation></author>
      <pages>2837-2853</pages>
      <abstract>Aspect Sentiment Triplet Extraction (ASTE) is widely used in various applications. However, existing ASTE datasets are limited in their ability to represent real-world scenarios, hindering the advancement of research in this area. In this paper, we introduce a new dataset, named DMASTE, which is manually annotated to better fit real-world scenarios by providing more diverse and realistic reviews for the task. The dataset includes various lengths, diverse expressions, more aspect types, and more domains than existing datasets. We conduct extensive experiments on DMASTE in multiple settings to evaluate previous ASTE approaches. Empirical results demonstrate that DMASTE is a more challenging ASTE dataset. Further analyses of in-domain and cross-domain settings provide some promising directions for future research.</abstract>
      <url hash="5896ed5d">2023.findings-acl.178</url>
      <bibkey>xu-etal-2023-measuring</bibkey>
      <doi>10.18653/v1/2023.findings-acl.178</doi>
    </paper>
    <paper id="179">
      <title>Grounding the Lexical Substitution Task in Entailment</title>
      <author><first>Talgat</first><last>Omarov</last><affiliation>University of Alberta</affiliation></author>
      <author><first>Grzegorz</first><last>Kondrak</last><affiliation>University of Alberta</affiliation></author>
      <pages>2854-2869</pages>
      <abstract>Existing definitions of lexical substitutes are often vague or inconsistent with the gold annotations. We propose a new definition which is grounded in the relation of entailment; namely, that the sentence that results from the substitution should be in the relation of mutual entailment with the original sentence. We argue that the new definition is well-founded and supported by previous work on lexical entailment. We empirically validate our definition by verifying that it covers the majority of gold substitutes in existing datasets. Based on this definition, we create a new dataset from existing semantic resources. Finally, we propose a novel context augmentation method motivated by the definition, which relates the substitutes to the sense of the target word by incorporating glosses and synonyms directly into the context. Experimental results demonstrate that our augmentation approach improves the performance of lexical substitution systems on the existing benchmarks.</abstract>
      <url hash="ec3f8300">2023.findings-acl.179</url>
      <bibkey>omarov-kondrak-2023-grounding</bibkey>
      <doi>10.18653/v1/2023.findings-acl.179</doi>
    </paper>
    <paper id="180">
      <title>Operator Selection and Ordering in a Pipeline Approach to Efficiency Optimizations for Transformers</title>
      <author><first>Ji</first><last>Xin</last><affiliation>University of Waterloo</affiliation></author>
      <author><first>Raphael</first><last>Tang</last><affiliation>Comcast</affiliation></author>
      <author><first>Zhiying</first><last>Jiang</last><affiliation>University of Waterloo</affiliation></author>
      <author><first>Yaoliang</first><last>Yu</last><affiliation>University of Waterloo</affiliation></author>
      <author><first>Jimmy</first><last>Lin</last><affiliation>University of Waterloo</affiliation></author>
      <pages>2870-2882</pages>
      <abstract>There exists a wide variety of efficiency methods for natural language processing (NLP) tasks, such as pruning, distillation, dynamic inference, quantization, etc. From a different perspective, we can consider an efficiency method as an operator applied on a model. Naturally, we may construct a pipeline of operators, i.e., to apply multiple efficiency methods on the model sequentially. In this paper, we study the plausibility of this idea, and more importantly, the commutativity and cumulativeness of efficiency operators. We make two interesting observations from our experiments: (1) The operators are commutative—the order of efficiency methods within the pipeline has little impact on the final results; (2) The operators are also cumulative—the final results of combining several efficiency methods can be estimated by combining the results of individual methods. These observations deepen our understanding of efficiency operators and provide useful guidelines for building them in real-world applications.</abstract>
      <url hash="b6724fe9">2023.findings-acl.180</url>
      <bibkey>xin-etal-2023-operator</bibkey>
      <doi>10.18653/v1/2023.findings-acl.180</doi>
    </paper>
    <paper id="181">
      <title><fixed-case>A</fixed-case>ra<fixed-case>MUS</fixed-case>: Pushing the Limits of Data and Model Scale for <fixed-case>A</fixed-case>rabic Natural Language Processing</title>
      <author><first>Asaad</first><last>Alghamdi</last><affiliation>TONOMUS</affiliation></author>
      <author><first>Xinyu</first><last>Duan</last><affiliation>Huawei</affiliation></author>
      <author><first>Wei</first><last>Jiang</last><affiliation>Huawei Cloud</affiliation></author>
      <author><first>Zhenhai</first><last>Wang</last><affiliation>Huawei Cloud</affiliation></author>
      <author><first>Yimeng</first><last>Wu</last><affiliation>Huawei Noah’s Ark Lab</affiliation></author>
      <author><first>Qingrong</first><last>Xia</last><affiliation>Huawei Cloud</affiliation></author>
      <author><first>Zhefeng</first><last>Wang</last><affiliation>Huawei Cloud</affiliation></author>
      <author><first>Yi</first><last>Zheng</last><affiliation>Huawei Cloud</affiliation></author>
      <author><first>Mehdi</first><last>Rezagholizadeh</last><affiliation>Noah’s Ark Lab Huawei</affiliation></author>
      <author><first>Baoxing</first><last>Huai</last><affiliation>Huawei Technologies</affiliation></author>
      <author><first>Peilun</first><last>Cheng</last><affiliation>TONOMUS</affiliation></author>
      <author><first>Abbas</first><last>Ghaddar</last><affiliation>Huawei Noah’s Ark Lab, Montreal Research Center</affiliation></author>
      <pages>2883-2894</pages>
      <abstract>Developing monolingual large Pre-trained Language Models (PLMs) is shown to be very successful in handling different tasks in Natural Language Processing (NLP). In this work, we present AraMUS, the largest Arabic PLM with 11B parameters trained on 529GB of high-quality Arabic textual data. AraMUS achieves state-of-the-art performances on a diverse set of Arabic classification and generative tasks. Moreover, AraMUS shows impressive few-shot learning abilities compared with the best existing Arabic PLMs.</abstract>
      <url hash="9cd0e18e">2023.findings-acl.181</url>
      <bibkey>alghamdi-etal-2023-aramus</bibkey>
      <doi>10.18653/v1/2023.findings-acl.181</doi>
    </paper>
    <paper id="182">
      <title>Leveraging Explicit Procedural Instructions for Data-Efficient Action Prediction</title>
      <author><first>Julia</first><last>White</last><affiliation>Stanford University</affiliation></author>
      <author><first>Arushi</first><last>Raghuvanshi</last><affiliation>Infinitus</affiliation></author>
      <author><first>Yada</first><last>Pruksachatkun</last><affiliation>Alexa AI</affiliation></author>
      <pages>2895-2904</pages>
      <abstract>Task-oriented dialogues often require agents to enact complex, multi-step procedures in order to meet user requests. While large language models have found success automating these dialogues in constrained environments, their widespread deployment is limited by the substantial quantities of task-specific data required for training. The following paper presents a data-efficient solution to constructing dialogue systems, leveraging explicit instructions derived from agent guidelines, such as company policies or customer service manuals. Our proposed Knowledge-Augmented Dialogue System (KADS) combines a large language model with a knowledge retrieval module that pulls documents outlining relevant procedures from a predefined set of policies, given a user-agent interaction. To train this system, we introduce a semi-supervised pre-training scheme that employs dialogue-document matching and action-oriented masked language modeling with partial parameter freezing. We evaluate the effectiveness of our approach on prominent task-oriented dialogue datasets, Action-Based Conversations Dataset and Schema-Guided Dialogue, for two dialogue tasks: action state tracking and workflow discovery. Our results demonstrate that procedural knowledge augmentation improves accuracy predicting in- and out-of-distribution actions while preserving high performance in settings with low or sparse data.</abstract>
      <url hash="7b425d91">2023.findings-acl.182</url>
      <bibkey>white-etal-2023-leveraging</bibkey>
      <doi>10.18653/v1/2023.findings-acl.182</doi>
    </paper>
    <paper id="183">
      <title>Quantifying Train-Evaluation Overlap with Nearest Neighbors</title>
      <author><first>Gauri</first><last>Kambhatla</last><affiliation>The University of Texas at Austin</affiliation></author>
      <author><first>Thuy</first><last>Nguyen</last><affiliation>University of Texas at Austin</affiliation></author>
      <author><first>Eunsol</first><last>Choi</last><affiliation>The University of Texas at Austin</affiliation></author>
      <pages>2905-2920</pages>
      <abstract>Characterizing benchmark datasets is crucial to interpreting model performance. In this work, we study train-evaluation overlap as a measure of an individual dataset’s adequacy to evaluate model generalization over a wide range of datasets. We quantify the overlap with a simple novel metric based on a nearest neighbors approach between the training and evaluation sets. We identify nearest training examples for each evaluation example by mapping instances with generic and task-specific embedding methods. Our study on eleven classification and extractive QA tasks reveals a wide range of train-evaluation overlap, and we show that the data collection method of the dataset and the difficulty of the task may play a role in the amount of overlap. Lastly, we use our nearest neighbor analysis to identify challenging or potentially mislabeled examples. Our analysis quantifies train-evaluation overlap, providing insights for constructing datasets to study generalization.</abstract>
      <url hash="034901bf">2023.findings-acl.183</url>
      <bibkey>kambhatla-etal-2023-quantifying</bibkey>
      <doi>10.18653/v1/2023.findings-acl.183</doi>
    </paper>
    <paper id="184">
      <title>Unsupervised Mapping of Arguments of Deverbal Nouns to Their Corresponding Verbal Labels</title>
      <author><first>Aviv</first><last>Weinstein</last><affiliation>Bar Ilan University</affiliation></author>
      <author><first>Yoav</first><last>Goldberg</last><affiliation>Bar Ilan University</affiliation></author>
      <pages>2921-2935</pages>
      <abstract>Deverbal nouns are nominal forms of verbs commonly used in written English texts to describe events or actions, as well as their arguments. However, many NLP systems, and in particular pattern-based ones, neglect to handle such nominalized constructions. The solutions that do exist for handling arguments of nominalized constructions are based on semantic annotation and require semantic ontologies, making their applications restricted to a small set of nouns. We propose to adopt instead a more syntactic approach, which maps the arguments of deverbal nouns to the universal-dependency relations of the corresponding verbal construction. We present an unsupervised mechanism—based on contextualized word representations—which allows to enrich universal-dependency trees with dependency arcs denoting arguments of deverbal nouns, using the same labels as the corresponding verbal cases. By sharing the same label set as in the verbal case, patterns that were developed for verbs can be applied without modification but with high accuracy also to the nominal constructions.</abstract>
      <url hash="c3d025df">2023.findings-acl.184</url>
      <bibkey>weinstein-goldberg-2023-unsupervised</bibkey>
      <doi>10.18653/v1/2023.findings-acl.184</doi>
    </paper>
    <paper id="185">
      <title>The Decades Progress on Code-Switching Research in <fixed-case>NLP</fixed-case>: A Systematic Survey on Trends and Challenges</title>
      <author><first>Genta</first><last>Winata</last><affiliation>Bloomberg</affiliation></author>
      <author><first>Alham Fikri</first><last>Aji</last><affiliation>MBZUAI</affiliation></author>
      <author><first>Zheng Xin</first><last>Yong</last><affiliation>Brown University</affiliation></author>
      <author><first>Thamar</first><last>Solorio</last><affiliation>University of Houston</affiliation></author>
      <pages>2936-2978</pages>
      <abstract>Code-Switching, a common phenomenon in written text and conversation, has been studied over decades by the natural language processing (NLP) research community. Initially, code-switching is intensively explored by leveraging linguistic theories and, currently, more machine-learning oriented approaches to develop models. We introduce a comprehensive systematic survey on code-switching research in natural language processing to understand the progress of the past decades and conceptualize the challenges and tasks on the code-switching topic. Finally, we summarize the trends and findings and conclude with a discussion for future direction and open questions for further investigation.</abstract>
      <url hash="64e1bba7">2023.findings-acl.185</url>
      <bibkey>winata-etal-2023-decades</bibkey>
      <doi>10.18653/v1/2023.findings-acl.185</doi>
    </paper>
    <paper id="186">
      <title>Learning to Predict Persona Information for Dialogue Personalization without Explicit Persona Description</title>
      <author><first>Wangchunshu</first><last>Zhou</last><affiliation>ETH Zurich</affiliation></author>
      <author><first>Qifei</first><last>Li</last><affiliation>Microsoft Research Asia</affiliation></author>
      <author><first>Chenle</first><last>Li</last><affiliation>Beihang University</affiliation></author>
      <pages>2979-2991</pages>
      <abstract>Personalizing dialogue agents is important for dialogue systems to generate more specific,consistent, and engaging responses. However, most current dialogue personalization approaches rely on explicit persona descriptions during inference, which severely restricts its application. In this paper, we propose a novel approach that learns to predict persona information based on the dialogue history to personalize the dialogue agent without relying on any explicit persona descriptions during inference. Experimental results on the PersonaChat dataset show that the proposed method can improve the consistency of generated responses when conditioning on the predicted profile of the dialogue agent (i.e. “self persona”), and improve the engagingness of the generated responses when conditioning on the predicted persona of the dialogue partner (i.e. “their persona”). We also find that a trained persona prediction model can be successfully transferred to other datasets and help generate more relevant responses.</abstract>
      <url hash="f69d0132">2023.findings-acl.186</url>
      <bibkey>zhou-etal-2023-learning</bibkey>
      <doi>10.18653/v1/2023.findings-acl.186</doi>
    </paper>
    <paper id="187">
      <title>Automated Refugee Case Analysis: A <fixed-case>NLP</fixed-case> Pipeline for Supporting Legal Practitioners</title>
      <author><first>Claire</first><last>Barale</last><affiliation>The University of Edinburgh</affiliation></author>
      <author><first>Michael</first><last>Rovatsos</last><affiliation>The University of Edinburgh</affiliation></author>
      <author><first>Nehal</first><last>Bhuta</last><affiliation>University of Edinburgh</affiliation></author>
      <pages>2992-3005</pages>
      <abstract>In this paper, we introduce an end-to-end pipeline for retrieving, processing, and extracting targeted information from legal cases. We investigate an under-studied legal domain with a case study on refugee law Canada. Searching case law for past similar cases is a key part of legal work for both lawyers and judges, the potential end-users of our prototype. While traditional named-entity recognition labels such as dates are meaningful information in law, we propose to extend existing models and retrieve a total of 19 categories of items from refugee cases. After creating a novel data set of cases, we perform information extraction based on state-of-the-art neural named-entity recognition (NER). We test different architectures including two transformer models, using contextual and non-contextual embeddings, and compare general purpose versus domain-specific pre-training. The results demonstrate that models pre-trained on legal data perform best despite their smaller size, suggesting that domain-matching had a larger effect than network architecture. We achieve a F1- score superior to 90% on five of the targeted categories and superior to 80% on an additional 4 categories.</abstract>
      <url hash="f0969c4e">2023.findings-acl.187</url>
      <bibkey>barale-etal-2023-automated</bibkey>
      <doi>10.18653/v1/2023.findings-acl.187</doi>
    </paper>
    <paper id="188">
      <title>Recurrent Attention Networks for Long-text Modeling</title>
      <author><first>Xianming</first><last>Li</last><affiliation>Ant Group</affiliation></author>
      <author><first>Zongxi</first><last>Li</last><affiliation>Hong Kong Metropolitan University</affiliation></author>
      <author><first>Xiaotian</first><last>Luo</last><affiliation>Ant Group</affiliation></author>
      <author><first>Haoran</first><last>Xie</last><affiliation>Lingnan University</affiliation></author>
      <author><first>Xing</first><last>Lee</last><affiliation>AntGroup</affiliation></author>
      <author><first>Yingbin</first><last>Zhao</last><affiliation>Ant Group</affiliation></author>
      <author><first>Fu Lee</first><last>Wang</last><affiliation>Hong Kong Metropolitan University</affiliation></author>
      <author><first>Qing</first><last>Li</last><affiliation>the Hong Kong Polytechnic University</affiliation></author>
      <pages>3006-3019</pages>
      <abstract>Self-attention-based models have achieved remarkable progress in short-text mining. However, the quadratic computational complexities restrict their application in long text processing. Prior works have adopted the chunking strategy to divide long documents into chunks and stack a self-attention backbone with the recurrent structure to extract semantic representation. Such an approach disables parallelization of the attention mechanism, significantly increasing the training cost and raising hardware requirements. Revisiting the self-attention mechanism and the recurrent structure, this paper proposes a novel long-document encoding model, Recurrent Attention Network (RAN), to enable the recurrent operation of self-attention. Combining the advantages from both sides, the well-designed RAN is capable of extracting global semantics in both token-level and document-level representations, making it inherently compatible with both sequential and classification tasks, respectively. Furthermore, RAN is computationally scalable as it supports parallelization on long document processing. Extensive experiments demonstrate the long-text encoding ability of the proposed RAN model on both classification and sequential tasks, showing its potential for a wide range of applications.</abstract>
      <url hash="9fca95ed">2023.findings-acl.188</url>
      <bibkey>li-etal-2023-recurrent</bibkey>
      <doi>10.18653/v1/2023.findings-acl.188</doi>
    </paper>
    <paper id="189">
      <title>Exploring the Relationship between Alignment and Cross-lingual Transfer in Multilingual Transformers</title>
      <author><first>Felix</first><last>Gaschi</last><affiliation>LORIA</affiliation></author>
      <author><first>Patricio</first><last>Cerda</last><affiliation>Posos</affiliation></author>
      <author><first>Parisa</first><last>Rastin</last><affiliation>University of Lorraine</affiliation></author>
      <author><first>Yannick</first><last>Toussaint</last><affiliation>LORIA, Université de Lorraine</affiliation></author>
      <pages>3020-3042</pages>
      <abstract>Without any explicit cross-lingual training data, multilingual language models can achieve cross-lingual transfer. One common way to improve this transfer is to perform realignment steps before fine-tuning, i.e., to train the model to build similar representations for pairs of words from translated sentences. But such realignment methods were found to not always improve results across languages and tasks, which raises the question of whether aligned representations are truly beneficial for cross-lingual transfer. We provide evidence that alignment is actually significantly correlated with cross-lingual transfer across languages, models and random seeds. We show that fine-tuning can have a significant impact on alignment, depending mainly on the downstream task and the model. Finally, we show that realignment can, in some instances, improve cross-lingual transfer, and we identify conditions in which realignment methods provide significant improvements. Namely, we find that realignment works better on tasks for which alignment is correlated with cross-lingual transfer when generalizing to a distant language and with smaller models, as well as when using a bilingual dictionary rather than FastAlign to extract realignment pairs. For example, for POS-tagging, between English and Arabic, realignment can bring a +15.8 accuracy improvement on distilmBERT, even outperforming XLM-R Large by 1.7. We thus advocate for further research on realignment methods for smaller multilingual models as an alternative to scaling.</abstract>
      <url hash="a7038cf9">2023.findings-acl.189</url>
      <bibkey>gaschi-etal-2023-exploring</bibkey>
      <doi>10.18653/v1/2023.findings-acl.189</doi>
    </paper>
    <paper id="190">
      <title>Aerial Vision-and-Dialog Navigation</title>
      <author><first>Yue</first><last>Fan</last><affiliation>University of California, Santa Cruz</affiliation></author>
      <author><first>Winson</first><last>Chen</last><affiliation>University of California, Santa Cruz</affiliation></author>
      <author><first>Tongzhou</first><last>Jiang</last><affiliation>UC Santa Cruz</affiliation></author>
      <author><first>Chun</first><last>Zhou</last><affiliation>University of California Santa Cruz</affiliation></author>
      <author><first>Yi</first><last>Zhang</last><affiliation>University of California Santa Cruz</affiliation></author>
      <author><first>Xin</first><last>Wang</last><affiliation>University of California, Santa Cruz</affiliation></author>
      <pages>3043-3061</pages>
      <abstract>The ability to converse with humans and follow natural language commands is crucial for intelligent unmanned aerial vehicles (a.k.a. drones). It can relieve people’s burden of holding a controller all the time, allow multitasking, and make drone control more accessible for people with disabilities or with their hands occupied. To this end, we introduce Aerial Vision-and-Dialog Navigation (AVDN), to navigate a drone via natural language conversation. We build a drone simulator with a continuous photorealistic environment and collect a new AVDN dataset of over 3k recorded navigation trajectories with asynchronous human-human dialogs between commanders and followers. The commander provides initial navigation instruction and further guidance by request, while the follower navigates the drone in the simulator and asks questions when needed. During data collection, followers’ attention on the drone’s visual observation is also recorded. Based on the AVDN dataset, we study the tasks of aerial navigation from (full) dialog history and propose an effective Human Attention Aided Transformer model (HAA-Transformer), which learns to predict both navigation waypoints and human attention.</abstract>
      <url hash="f4dfdd07">2023.findings-acl.190</url>
      <bibkey>fan-etal-2023-aerial</bibkey>
      <doi>10.18653/v1/2023.findings-acl.190</doi>
    </paper>
    <paper id="191">
      <title>Improved Logical Reasoning of Language Models via Differentiable Symbolic Programming</title>
      <author><first>Hanlin</first><last>Zhang</last><affiliation>Carnegie Mellon University</affiliation></author>
      <author><first>Jiani</first><last>Huang</last><affiliation>University of Pennsylvania</affiliation></author>
      <author><first>Ziyang</first><last>Li</last><affiliation>University of Pennsylvania</affiliation></author>
      <author><first>Mayur</first><last>Naik</last><affiliation>UPenn</affiliation></author>
      <author><first>Eric</first><last>Xing</last><affiliation>Carnegie Mellon University</affiliation></author>
      <pages>3062-3077</pages>
      <abstract>Pre-trained large language models (LMs) struggle to perform logical reasoning reliably despite advances in scale and compositionality. In this work, we tackle this challenge through the lens of symbolic programming. We propose DSR-LM, a Differentiable Symbolic Reasoning framework where pre-trained LMs govern the perception of factual knowledge, and a symbolic module performs deductive reasoning. In contrast to works that rely on hand-crafted logic rules, our differentiable symbolic reasoning framework efficiently learns weighted rules and applies semantic loss to further improve LMs. DSR-LM is scalable, interpretable, and allows easy integration of prior knowledge, thereby supporting extensive symbolic programming to robustly derive a logical conclusion. The results of our experiments suggest that DSR-LM improves the logical reasoning abilities of pre-trained language models, resulting in a significant increase in accuracy of over 20% on deductive reasoning benchmarks. Furthermore, DSR-LM outperforms a variety of competitive baselines when faced with systematic changes in sequence length.</abstract>
      <url hash="3214caa0">2023.findings-acl.191</url>
      <bibkey>zhang-etal-2023-improved</bibkey>
      <doi>10.18653/v1/2023.findings-acl.191</doi>
    </paper>
    <paper id="192">
      <title><fixed-case>B</fixed-case>2<fixed-case>T</fixed-case> Connection: Serving Stability and Performance in Deep Transformers</title>
      <author><first>Sho</first><last>Takase</last><affiliation>LINE Corporation</affiliation></author>
      <author><first>Shun</first><last>Kiyono</last><affiliation>LINE Corporation</affiliation></author>
      <author><first>Sosuke</first><last>Kobayashi</last><affiliation>Preferred Networks / Tohoku University</affiliation></author>
      <author><first>Jun</first><last>Suzuki</last><affiliation>Tohoku University / RIKEN Center for AIP</affiliation></author>
      <pages>3078-3095</pages>
      <abstract>In the perspective of a layer normalization (LN) position, the architecture of Transformers can be categorized into two types: Post-LN and Pre-LN.Recent Transformers prefer to select Pre-LN because the training in Post-LN with deep Transformers, e.g., ten or more layers, often becomes unstable, resulting in useless models. However, in contrast, Post-LN has also consistently achieved better performance than Pre-LN in relatively shallow Transformers, e.g., six or fewer layers. This study first investigates the reason for these discrepant observations empirically and theoretically and discovers 1, the LN in Post-LN is the source of the vanishing gradient problem that mainly leads the unstable training whereas Pre-LN prevents it, and 2, Post-LN tends to preserve larger gradient norms in higher layers during the back-propagation that may lead an effective training. Exploiting the new findings, we propose a method that can equip both higher stability and effective training by a simple modification from Post-LN.We conduct experiments on a wide range of text generation tasks and demonstrate that our method outperforms Pre-LN, and stable training regardless of the shallow or deep layer settings.</abstract>
      <url hash="ffb0293a">2023.findings-acl.192</url>
      <bibkey>takase-etal-2023-b2t</bibkey>
      <doi>10.18653/v1/2023.findings-acl.192</doi>
    </paper>
    <paper id="193">
      <title>Boosting Zero-shot Cross-lingual Retrieval by Training on Artificially Code-Switched Data</title>
      <author><first>Robert</first><last>Litschko</last><affiliation>LMU Munich</affiliation></author>
      <author><first>Ekaterina</first><last>Artemova</last><affiliation>LMU Munich</affiliation></author>
      <author><first>Barbara</first><last>Plank</last><affiliation>LMU Munich</affiliation></author>
      <pages>3096-3108</pages>
      <abstract>Transferring information retrieval (IR) models from a high-resource language (typically English) to other languages in a zero-shot fashion has become a widely adopted approach. In this work, we show that the effectiveness of zero-shot rankers diminishes when queries and documents are present in different languages. Motivated by this, we propose to train ranking models on artificially code-switched data instead, which we generate by utilizing bilingual lexicons. To this end, we experiment with lexicons induced from (1) cross-lingual word embeddings and (2) parallel Wikipedia page titles. We use the mMARCO dataset to extensively evaluate reranking models on 36 language pairs spanning Monolingual IR (MoIR), Cross-lingual IR (CLIR), and Multilingual IR (MLIR). Our results show that code-switching can yield consistent and substantial gains of 5.1 MRR@10 in CLIR and 3.9 MRR@10 in MLIR, while maintaining stable performance in MoIR. Encouragingly, the gains are especially pronounced for distant languages (up to 2x absolute gain). We further show that our approach is robust towards the ratio of code-switched tokens and also extends to unseen languages. Our results demonstrate that training on code-switched data is a cheap and effective way of generalizing zero-shot rankers for cross-lingual and multilingual retrieval.</abstract>
      <url hash="99a1f915">2023.findings-acl.193</url>
      <bibkey>litschko-etal-2023-boosting</bibkey>
      <doi>10.18653/v1/2023.findings-acl.193</doi>
    </paper>
    <paper id="194">
      <title>Domain-specific Attention with Distributional Signatures for Multi-Domain End-to-end Task-Oriented Dialogue</title>
      <author><first>Xing</first><last>Ma</last><affiliation>University of Tianjin</affiliation></author>
      <author><first>Peng</first><last>Zhang</last><affiliation>Tianjin University</affiliation></author>
      <author><first>Feifei</first><last>Zhao</last><affiliation>Beijing Wenge Technology Co.,Ltd,The State Key Laboratory for Management and Control of Complex Systems,Institute of Automation,Chinese Academy of Sciences.</affiliation></author>
      <pages>3109-3122</pages>
      <abstract>The end-to-end task-oriented dialogue system has achieved great success in recent years. Most of these dialogue systems need to accommodate multi-domain dialogue in real-world scenarios. However, due to the high cost of dialogue data annotation and the scarcity of labeled dialogue data, existing methods are difficult to extend to new domains. Therefore, it is important to use limited data to construct multi-domain dialogue systems. To solve this problem, we propose a novel domain attention module. It use the distributional signatures to construct a multi-domain dialogue system effectively with limited data, which has strong extensibility. We also define a adjacent n-gram pattern to explore potential patterns for dialogue entities. Experimental results show that our approach outperforms the baseline models on most metrics. In the few-shot scenario, we show our method get a great improvement compared with previous methods while keeping smaller model scale.</abstract>
      <url hash="20887453">2023.findings-acl.194</url>
      <bibkey>ma-etal-2023-domain</bibkey>
      <doi>10.18653/v1/2023.findings-acl.194</doi>
    </paper>
    <paper id="195">
      <title><fixed-case>CKDST</fixed-case>: Comprehensively and Effectively Distill Knowledge from Machine Translation to End-to-End Speech Translation</title>
      <author><first>Yikun</first><last>Lei</last><affiliation>Tianjin university</affiliation></author>
      <author><first>Zhengshan</first><last>Xue</last><affiliation>Tianjin University</affiliation></author>
      <author><first>Xiaohu</first><last>Zhao</last><affiliation>Tianjin University</affiliation></author>
      <author><first>Haoran</first><last>Sun</last><affiliation>Tianjin University</affiliation></author>
      <author><first>Shaolin</first><last>Zhu</last><affiliation>Tianjin university</affiliation></author>
      <author><first>Xiaodong</first><last>Lin</last><affiliation>Rutgers University</affiliation></author>
      <author><first>Deyi</first><last>Xiong</last><affiliation>Tianjin University</affiliation></author>
      <pages>3123-3137</pages>
      <abstract>Distilling knowledge from a high-resource task, e.g., machine translation, is an effective way to alleviate the data scarcity problem of end-to-end speech translation. However, previous works simply use the classical knowledge distillation that does not allow for adequate transfer of knowledge from machine translation. In this paper, we propose a comprehensive knowledge distillation framework for speech translation, CKDST, which is capable of comprehensively and effectively distilling knowledge from machine translation to speech translation from two perspectives: cross-modal contrastive representation distillation and simultaneous decoupled knowledge distillation. In the former, we leverage a contrastive learning objective to optmize the mutual information between speech and text representations for representation distillation in the encoder. In the later, we decouple the non-target class knowledge from target class knowledge for logits distillation in the decoder. Experiments on the MuST-C benchmark dataset demonstrate that our CKDST substantially improves the baseline by 1.2 BLEU on average in all translation directions, and outperforms previous state-of-the-art end-to-end and cascaded speech translation models.</abstract>
      <url hash="ecd6f65d">2023.findings-acl.195</url>
      <bibkey>lei-etal-2023-ckdst</bibkey>
      <doi>10.18653/v1/2023.findings-acl.195</doi>
    </paper>
    <paper id="196">
      <title>Follow the leader(board) with confidence: Estimating p-values from a single test set with item and response variance</title>
      <author><first>Shira</first><last>Wein</last><affiliation>Georgetown University</affiliation></author>
      <author><first>Christopher</first><last>Homan</last><affiliation>Rochester Institute of Technology</affiliation></author>
      <author><first>Lora</first><last>Aroyo</last><affiliation>Google</affiliation></author>
      <author><first>Chris</first><last>Welty</last><affiliation/></author>
      <pages>3138-3161</pages>
      <abstract>Among the problems with leaderboard culture in NLP has been the widespread lack of confidence estimation in reported results. In this work, we present a framework and simulator for estimating p-values for comparisons between the results of two systems, in order to understand the confidence that one is actually better (i.e. ranked higher) than the other. What has made this difficult in the past is that each system must itself be evaluated by comparison to a gold standard. We define a null hypothesis that each system’s metric scores are drawn from the same distribution, using variance found naturally (though rarely reported) in test set items and individual labels on an item (responses) to produce the metric distributions. We create a test set that evenly mixes the responses of the two systems under the assumption the null hypothesis is true. Exploring how to best estimate the true p-value from a single test set under different metrics, tests, and sampling methods, we find that the presence of response variance (from multiple raters or multiple model versions) has a profound impact on p-value estimates for model comparison, and that choice of metric and sampling method is critical to providing statistical guarantees on model comparisons.</abstract>
      <url hash="ba8e9ecd">2023.findings-acl.196</url>
      <bibkey>wein-etal-2023-follow</bibkey>
      <doi>10.18653/v1/2023.findings-acl.196</doi>
    </paper>
    <paper id="197">
      <title>Parallel Data Helps Neural Entity Coreference Resolution</title>
      <author><first>Gongbo</first><last>Tang</last><affiliation>Beijing Language and Culture University</affiliation></author>
      <author><first>Christian</first><last>Hardmeier</last><affiliation>IT University of Copenhagen</affiliation></author>
      <pages>3162-3171</pages>
      <abstract>Coreference resolution is the task of finding expressions that refer to the same entity in a text. Coreference models are generally trained on monolingual annotated data but annotating coreference is expensive and challenging. Hardmeier et al. (2013) have shown that parallel data contains latent anaphoric knowledge, but it has not been explored in end-to-end neural models yet. In this paper, we propose a simple yet effective model to exploit coreference knowledge from parallel data. In addition to the conventional modules learning coreference from annotations, we introduce an unsupervised module to capture cross-lingual coreference knowledge. Our proposed cross-lingual model achieves consistent improvements, up to 1.74 percentage points, on the OntoNotes 5.0 English dataset using 9 different synthetic parallel datasets. These experimental results confirm that parallel data can provide additional coreference knowledge which is beneficial to coreference resolution tasks.</abstract>
      <url hash="fbc54d06">2023.findings-acl.197</url>
      <bibkey>tang-hardmeier-2023-parallel</bibkey>
      <doi>10.18653/v1/2023.findings-acl.197</doi>
    </paper>
    <paper id="198">
      <title>Towards Open-Domain <fixed-case>T</fixed-case>witter User Profile Inference</title>
      <author><first>Haoyang</first><last>Wen</last><affiliation>Carnegie Mellon University</affiliation></author>
      <author><first>Zhenxin</first><last>Xiao</last><affiliation>Carnegie Mellon University</affiliation></author>
      <author><first>Eduard</first><last>Hovy</last><affiliation>University of Melbourne</affiliation></author>
      <author><first>Alexander</first><last>Hauptmann</last><affiliation>Carnegie Mellon University</affiliation></author>
      <pages>3172-3188</pages>
      <abstract>Twitter user profile inference utilizes information from Twitter to predict user attributes (e.g., occupation, location), which is controversial because of its usefulness for downstream applications and its potential to reveal users’ privacy. Therefore, it is important for researchers to determine the extent of profiling in a safe environment to facilitate proper use and make the public aware of the potential risks. Contrary to existing approaches on limited attributes, we explore open-domain Twitter user profile inference. We conduct a case study where we collect publicly available WikiData public figure profiles and use diverse WikiData predicates for profile inference. After removing sensitive attributes, our data contains over 150K public figure profiles from WikiData, over 50 different attribute predicates, and over 700K attribute values. We further propose a prompt-based generation method, which can infer values that are implicitly mentioned in the Twitter information. Experimental results show that the generation-based approach can infer more comprehensive user profiles than baseline extraction-based methods, but limitations still remain to be applied for real-world use. We also enclose a detailed ethical statement for our data, potential benefits and risks from this work, and our efforts to mitigate the risks.</abstract>
      <url hash="e660d2be">2023.findings-acl.198</url>
      <bibkey>wen-etal-2023-towards</bibkey>
      <doi>10.18653/v1/2023.findings-acl.198</doi>
    </paper>
    <paper id="199">
      <title>Eliciting Affective Events from Language Models by Multiple View Co-prompting</title>
      <author><first>Yuan</first><last>Zhuang</last><affiliation>University of Utah</affiliation></author>
      <author><first>Ellen</first><last>Riloff</last><affiliation>University of Utah</affiliation></author>
      <pages>3189-3201</pages>
      <abstract>Prior research on affective event classification showed that exploiting weakly labeled data for training can improve model performance. In this work, we propose a simpler and more effective approach for generating training data by automatically acquiring and labeling affective events with Multiple View Co-prompting, which leverages two language model prompts that provide independent views of an event. The approach starts with a modest amount of gold data and prompts pre-trained language models to generate new events. Next, information about the probable affective polarity of each event is collected from two complementary language model prompts and jointly used to assign polarity labels. Experimental results on two datasets show that the newly acquired events improve a state-of-the-art affective event classifier. We also present analyses which show that using multiple views produces polarity labels of higher quality than either view on its own.</abstract>
      <url hash="3a88b3ce">2023.findings-acl.199</url>
      <bibkey>zhuang-riloff-2023-eliciting</bibkey>
      <doi>10.18653/v1/2023.findings-acl.199</doi>
    </paper>
    <paper id="200">
      <title><fixed-case>Z</fixed-case>ero<fixed-case>AE</fixed-case>: Pre-trained Language Model based Autoencoder for Transductive Zero-shot Text Classification</title>
      <author><first>Kaihao</first><last>Guo</last><affiliation>Ant Group; ShanghaiTech University</affiliation></author>
      <author><first>Hang</first><last>Yu</last><affiliation>Ant Group</affiliation></author>
      <author><first>Cong</first><last>Liao</last><affiliation>Ant Group</affiliation></author>
      <author><first>Jianguo</first><last>Li</last><affiliation>Ant Group</affiliation></author>
      <author><first>Haipeng</first><last>Zhang</last><affiliation>ShanghaiTech University</affiliation></author>
      <pages>3202-3219</pages>
      <abstract>Many text classification tasks require handling unseen domains with plenty of unlabeled data, thus giving rise to the self-adaption or the so-called transductive zero-shot learning (TZSL) problem. However, current methods based solely on encoders or decoders overlook the possibility that these two modules may promote each other. As a first effort to bridge this gap, we propose an autoencoder named ZeroAE. Specifically, the text is encoded with two separate BERT-based encoders into two disentangled spaces, i.e., label-relevant (for classification) and label-irrelevant respectively. The two latent spaces are then decoded by prompting GPT-2 to recover the text as well as to further generate text with labels in the unseen domains to train the encoder in turn. To better exploit the unlabeled data, a novel indirect uncertainty-aware sampling (IUAS) approach is proposed to train ZeroAE. Extensive experiments show that ZeroAE largely surpasses the SOTA methods by 15.93% and 8.70% on average respectively in the label-partially-unseen and label-fully-unseen scenario. Notably, the label-fully-unseen ZeroAE even possesses superior performance to the label-partially-unseen SOTA methods.</abstract>
      <url hash="a355ccf2">2023.findings-acl.200</url>
      <bibkey>guo-etal-2023-zeroae</bibkey>
      <doi>10.18653/v1/2023.findings-acl.200</doi>
    </paper>
    <paper id="201">
      <title><fixed-case>PRAM</fixed-case>: An End-to-end Prototype-based Representation Alignment Model for Zero-resource Cross-lingual Named Entity Recognition</title>
      <author><first>Yucheng</first><last>Huang</last><affiliation>School of Computer Science and Technology, Xi’an Jiaotong University</affiliation></author>
      <author><first>Wenqiang</first><last>Liu</last><affiliation>Tencent</affiliation></author>
      <author><first>Xianli</first><last>Zhang</last><affiliation>Tencent</affiliation></author>
      <author><first>Jun</first><last>Lang</last><affiliation>Tencent</affiliation></author>
      <author><first>Tieliang</first><last>Gong</last><affiliation>Xi’an Jiaotong University</affiliation></author>
      <author><first>Chen</first><last>Li</last><affiliation>Xi’an Jiaotong University</affiliation></author>
      <pages>3220-3233</pages>
      <abstract>Zero-resource cross-lingual named entity recognition (ZRCL-NER) aims to leverage rich labeled source language data to address the NER problem in the zero-resource target language. Existing methods are built either based on data transfer or representation transfer. However, the former usually leads to additional computation costs, and the latter lacks explicit optimization specific to the NER task. To overcome the above limitations, we propose a novel prototype-based representation alignment model (PRAM) for the challenging ZRCL-NER task. PRAM models the cross-lingual (CL) NER task and transfers knowledge from source languages to target languages in a unified neural network, and performs end-to-end training, avoiding additional computation costs. Moreover, PRAM borrows the CL inference ability of multilingual language models and enhances it with a novel training objective—attribution-prediction consistency (APC)—for explicitly enforcing the entity-level alignment between entity representations and predictions, as well as that across languages using prototypes as bridges. The experimental results show that PRAM significantly outperforms existing state-of-the-art methods, especially in some challenging scenarios.</abstract>
      <url hash="66186c77">2023.findings-acl.201</url>
      <bibkey>huang-etal-2023-pram</bibkey>
      <doi>10.18653/v1/2023.findings-acl.201</doi>
    </paper>
    <paper id="202">
      <title>It Takes Two to Tango: Navigating Conceptualizations of <fixed-case>NLP</fixed-case> Tasks and Measurements of Performance</title>
      <author><first>Arjun</first><last>Subramonian</last><affiliation>University of California, Los Angeles</affiliation></author>
      <author><first>Xingdi</first><last>Yuan</last><affiliation>Microsoft Research</affiliation></author>
      <author><first>Hal</first><last>Daumé III</last><affiliation>UMD</affiliation></author>
      <author><first>Su Lin</first><last>Blodgett</last><affiliation>Microsoft Research</affiliation></author>
      <pages>3234-3279</pages>
      <abstract>Progress in NLP is increasingly measured through benchmarks; hence, contextualizing progress requires understanding when and why practitioners may disagree about the validity of benchmarks. We develop a taxonomy of disagreement, drawing on tools from measurement modeling, and distinguish between two types of disagreement: 1) how tasks are conceptualized and 2) how measurements of model performance are operationalized. To provide evidence for our taxonomy, we conduct a meta-analysis of relevant literature to understand how NLP tasks are conceptualized, as well as a survey of practitioners about their impressions of different factors that affect benchmark validity. Our meta-analysis and survey across eight tasks, ranging from coreference resolution to question answering, uncover that tasks are generally not clearly and consistently conceptualized and benchmarks suffer from operationalization disagreements. These findings support our proposed taxonomy of disagreement. Finally, based on our taxonomy, we present a framework for constructing benchmarks and documenting their limitations.</abstract>
      <url hash="4ccdf304">2023.findings-acl.202</url>
      <bibkey>subramonian-etal-2023-takes</bibkey>
      <doi>10.18653/v1/2023.findings-acl.202</doi>
    </paper>
    <paper id="203">
      <title>Task-adaptive Label Dependency Transfer for Few-shot Named Entity Recognition</title>
      <author><first>Shan</first><last>Zhang</last><affiliation>Zhejiang University of Technology</affiliation></author>
      <author><first>Bin</first><last>Cao</last><affiliation>Zhejiang University of Technology</affiliation></author>
      <author><first>Tianming</first><last>Zhang</last><affiliation>Zhejiang University of Technology</affiliation></author>
      <author><first>Yuqi</first><last>Liu</last><affiliation>Zhejiang University of Technology</affiliation></author>
      <author><first>Jing</first><last>Fan</last><affiliation>Zhejiang University of Technology</affiliation></author>
      <pages>3280-3293</pages>
      <abstract>Named Entity Recognition (NER), as a crucial subtask in natural language processing (NLP), suffers from limited labeled samples (a.k.a. few-shot). Meta-learning methods are widely used for few-shot NER, but these existing methods overlook the importance of label dependency for NER, resulting in suboptimal performance. However, applying meta-learning methods to label dependency learning faces a special challenge, that is, due to the discrepancy of label sets in different domains, the label dependencies can not be transferred across domains. In this paper, we propose the Task-adaptive Label Dependency Transfer (TLDT) method to make label dependency transferable and effectively adapt to new tasks by a few samples. TLDT improves the existing optimization-based meta-learning methods by learning general initialization and individual parameter update rule for label dependency. Extensive experiments show that TLDT achieves significant improvement over the state-of-the-art methods.</abstract>
      <url hash="a6ebb976">2023.findings-acl.203</url>
      <bibkey>zhang-etal-2023-task</bibkey>
      <doi>10.18653/v1/2023.findings-acl.203</doi>
    </paper>
    <paper id="204">
      <title><fixed-case>WYWEB</fixed-case>: A <fixed-case>NLP</fixed-case> Evaluation Benchmark For Classical <fixed-case>C</fixed-case>hinese</title>
      <author><first>Bo</first><last>Zhou</last><affiliation>Zhejiang University</affiliation></author>
      <author><first>Qianglong</first><last>Chen</last><affiliation>Zhejiang University</affiliation></author>
      <author><first>Tianyu</first><last>Wang</last><affiliation>Xiaoniao.ai</affiliation></author>
      <author><first>Xiaomi</first><last>Zhong</last><affiliation>Xiaoniao.ai</affiliation></author>
      <author><first>Yin</first><last>Zhang</last><affiliation>Zhejiang University</affiliation></author>
      <pages>3294-3319</pages>
      <abstract>To fully evaluate the overall performance of different NLP models in a given domain, many evaluation benchmarks are proposed, such as GLUE, SuperGLUE and CLUE. The field of natural language understanding has traditionally focused on benchmarks for various tasks in languages such as Chinese, English, and multilingual, however, there has been a lack of attention given to the area of classical Chinese, also known as "wen yan wen (文言文)", which has a rich history spanning thousands of years and holds significant cultural and academic value. For the prosperity of the NLP community, in this paper, we introduce the WYWEB evaluation benchmark, which consists of nine NLP tasks in classical Chinese, implementing sentence classification, sequence labeling, reading comprehension, and machine translation. We evaluate the existing pre-trained language models, which are all struggling with this benchmark. We also introduce a number of supplementary datasets and additional tools to help facilitate further progress on classical Chinese NLU. The github repository is <url>https://github.com/baudzhou/WYWEB</url>.</abstract>
      <url hash="307edba1">2023.findings-acl.204</url>
      <bibkey>zhou-etal-2023-wyweb</bibkey>
      <doi>10.18653/v1/2023.findings-acl.204</doi>
    </paper>
    <paper id="205">
      <title>A Fused <fixed-case>G</fixed-case>romov-<fixed-case>W</fixed-case>asserstein Framework for Unsupervised Knowledge Graph Entity Alignment</title>
      <author><first>Jianheng</first><last>Tang</last><affiliation>Hong Kong University of Science and Technology;</affiliation></author>
      <author><first>Kangfei</first><last>Zhao</last><affiliation>Tencent AI Lab</affiliation></author>
      <author><first>Jia</first><last>Li</last><affiliation>Hong Kong University of Science and Technology</affiliation></author>
      <pages>3320-3334</pages>
      <abstract>Entity alignment is the task of identifying corresponding entities across different knowledge graphs (KGs). Although recent embedding-based entity alignment methods have shown significant advancements, they still struggle to fully utilize KG structural information. In this paper, we introduce FGWEA, an unsupervised entity alignment framework that leverages the Fused Gromov-Wasserstein (FGW) distance, allowing for a comprehensive comparison of entity semantics and KG structures within a joint optimization framework. To address the computational challenges associated with optimizing FGW, we devise a three-stage progressive optimization algorithm. It starts with a basic semantic embedding matching, proceeds to approximate cross-KG structural and relational similarity matching based on iterative updates of high-confidence entity links, and ultimately culminates in a global structural comparison between KGs. We perform extensive experiments on four entity alignment datasets covering 14 distinct KGs across five languages. Without any supervision or hyper-parameter tuning, FGWEA surpasses 21 competitive baselines, including cutting-edge supervised entity alignment methods. Our code is available at <url>https://github.com/squareRoot3/FusedGW-Entity-Alignment</url>.</abstract>
      <url hash="1e915d6f">2023.findings-acl.205</url>
      <bibkey>tang-etal-2023-fused</bibkey>
      <doi>10.18653/v1/2023.findings-acl.205</doi>
    </paper>
    <paper id="206">
      <title>Two Examples are Better than One: Context Regularization for Gradient-based Prompt Tuning</title>
      <author><first>Hyeonmin</first><last>Ha</last><affiliation>Seoul National University</affiliation></author>
      <author><first>Soyoung</first><last>Jung</last><affiliation>Seoul National University</affiliation></author>
      <author><first>Jinsol</first><last>Park</last><affiliation>Seoul National University</affiliation></author>
      <author><first>Minjoon</first><last>Seo</last><affiliation>KAIST</affiliation></author>
      <author><first>Seung-won</first><last>Hwang</last><affiliation>Seoul National University</affiliation></author>
      <author><first>Byung-Gon</first><last>Chun</last><affiliation>Seoul National University, FriendliAI</affiliation></author>
      <pages>3335-3350</pages>
      <abstract>Prompting has gained tremendous attention as an efficient method for the adaptation of large-scale language models. However, prompts often act against human intuition and report unstable performances, which has motivated methods that automatically find effective prompts. One popular approach is gradient-based search, which iteratively updates a (randomly) initialized prompt towards the optimal one with the guide of gradients. We propose a novel regularization method, CoRe, for gradient-based prompt tuning techniques, which guides a prompt to produce a task context properly. CoRe realizes two regularization effects — context attuning and context filtering — that improve prediction performance in a zero-shot in-context learning setting where a model makes inferences only with the prompt tuned by CoRe, without any demonstration examples for in-context learning. Context attuning guides the context generated by the input and the tuned prompt toward embedding the appropriate context for the task. In our theoretical analysis, regularizing the context extends to improving zero-shot in-context learning performance. Context filtering steers the prompt to select only the task-related context so that context attuning solely focuses on creating and sending the right task context. We evaluate CoRe on natural language understanding datasets and two large language models, GPT2-XL and GPT-J.Our training scheme shows performance improvements up to 11.9% on GPT2-XL, and up to 6.3% on GPT-J in zero-shot settings.</abstract>
      <url hash="0235cd78">2023.findings-acl.206</url>
      <bibkey>ha-etal-2023-two</bibkey>
      <doi>10.18653/v1/2023.findings-acl.206</doi>
    </paper>
    <paper id="207">
      <title>An Investigation of Noise in Morphological Inflection</title>
      <author><first>Adam</first><last>Wiemerslage</last><affiliation>University of Colorado Boulder</affiliation></author>
      <author><first>Changbing</first><last>Yang</last><affiliation>University of British Columbia</affiliation></author>
      <author><first>Garrett</first><last>Nicolai</last><affiliation>University of British Columbia</affiliation></author>
      <author><first>Miikka</first><last>Silfverberg</last><affiliation>University of British Columbia</affiliation></author>
      <author><first>Katharina</first><last>Kann</last><affiliation>University of Colorado Boulder</affiliation></author>
      <pages>3351-3365</pages>
      <abstract>With a growing focus on morphological inflection systems for languages where high-quality data is scarce, training data noise is a serious but so far largely ignored concern. We aim at closing this gap by investigating the types of noise encountered within a pipeline for truly unsupervised morphological paradigm completion and its impact on morphological inflection systems: First, we propose an error taxonomy and annotation pipeline for inflection training data. Then, we compare the effect of different types of noise on multiple state-of-the- art inflection models. Finally, we propose a novel character-level masked language modeling (CMLM) pretraining objective and explore its impact on the models’ resistance to noise. Our experiments show that various architectures are impacted differently by separate types of noise, but encoder-decoders tend to be more robust to noise than models trained with a copy bias. CMLM pretraining helps transformers, but has lower impact on LSTMs.</abstract>
      <url hash="3cfd59df">2023.findings-acl.207</url>
      <bibkey>wiemerslage-etal-2023-investigation</bibkey>
      <doi>10.18653/v1/2023.findings-acl.207</doi>
    </paper>
    <paper id="208">
      <title>Graph Reasoning for Question Answering with Triplet Retrieval</title>
      <author><first>Shiyang</first><last>Li</last><affiliation>UC Santa Barbara</affiliation></author>
      <author><first>Yifan</first><last>Gao</last><affiliation>Amazon</affiliation></author>
      <author><first>Haoming</first><last>Jiang</last><affiliation>Amazon Search</affiliation></author>
      <author><first>Qingyu</first><last>Yin</last><affiliation>Amazon</affiliation></author>
      <author><first>Zheng</first><last>Li</last><affiliation>Amazon</affiliation></author>
      <author><first>Xifeng</first><last>Yan</last><affiliation>University of California at Santa Barbara</affiliation></author>
      <author><first>Chao</first><last>Zhang</last><affiliation>Georgia Tech</affiliation></author>
      <author><first>Bing</first><last>Yin</last><affiliation>Amazon.com</affiliation></author>
      <pages>3366-3375</pages>
      <abstract>Answering complex questions often requires reasoning over knowledge graphs (KGs). State-of-the-art methods often utilize entities in questions to retrieve local subgraphs, which are then fed into KG encoder, e.g. graph neural networks (GNNs), to model their local structures and integrated into language models for question answering. However, this paradigm constrains retrieved knowledge in local subgraphs and discards more diverse triplets buried in KGs that are disconnected but useful for question answering. In this paper, we propose a simple yet effective method to first retrieve the most relevant triplets from KGs and then rerank them, which are then concatenated with questions to be fed into language models. Extensive results on both CommonsenseQA and OpenbookQA datasets show that our method can outperform state-of-the-art up to 4.6% absolute accuracy.</abstract>
      <url hash="ad78e2a2">2023.findings-acl.208</url>
      <bibkey>li-etal-2023-graph</bibkey>
      <doi>10.18653/v1/2023.findings-acl.208</doi>
    </paper>
    <paper id="209">
      <title>End-to-End Argument Mining over Varying Rhetorical Structures</title>
      <author><first>Elena</first><last>Chistova</last><affiliation>FRC CSC RAS</affiliation></author>
      <pages>3376-3391</pages>
      <abstract>Rhetorical Structure Theory implies no single discourse interpretation of a text, and the limitations of RST parsers further exacerbate inconsistent parsing of similar structures. Therefore, it is important to take into account that the same argumentative structure can be found in semantically similar texts with varying rhetorical structures. In this work, the differences between paraphrases within the same argument scheme are evaluated from a rhetorical perspective. The study proposes a deep dependency parsing model to assess the connection between rhetorical and argument structures. The model utilizes rhetorical relations; RST structures of paraphrases serve as training data augmentations. The method allows for end-to-end argumentation analysis using a rhetorical tree instead of a word sequence. It is evaluated on the bilingual Microtexts corpus, and the first results on fully-fledged argument parsing for the Russian version of the corpus are reported. The results suggest that argument mining can benefit from multiple variants of discourse structure.</abstract>
      <url hash="5cdb71a0">2023.findings-acl.209</url>
      <bibkey>chistova-2023-end</bibkey>
      <doi>10.18653/v1/2023.findings-acl.209</doi>
    </paper>
    <paper id="210">
      <title>Unsupervised Task Graph Generation from Instructional Video Transcripts</title>
      <author><first>Lajanugen</first><last>Logeswaran</last><affiliation>LG AI Research</affiliation></author>
      <author><first>Sungryull</first><last>Sohn</last><affiliation>LG AI Research Center, Ann Arbor</affiliation></author>
      <author><first>Yunseok</first><last>Jang</last><affiliation>University of Michigan</affiliation></author>
      <author><first>Moontae</first><last>Lee</last><affiliation>University of Illinois at Chicago</affiliation></author>
      <author><first>Honglak</first><last>Lee</last><affiliation>LG AI Research/ University of Michigan</affiliation></author>
      <pages>3392-3406</pages>
      <abstract>This work explores the problem of generating task graphs of real-world activities. Different from prior formulations, we consider a setting where text transcripts of instructional videos performing a real-world activity (e.g., making coffee) are provided and the goal is to identify the key steps relevant to the task as well as the dependency relationship between these key steps. We propose a novel task graph generation approach that combines the reasoning capabilities of instruction-tuned language models along with clustering and ranking components to generate accurate task graphs in a completely unsupervised manner. We show that the proposed approach generates more accurate task graphs compared to a supervised learning approach on tasks from the ProceL and CrossTask datasets.</abstract>
      <url hash="14d78dd7">2023.findings-acl.210</url>
      <bibkey>logeswaran-etal-2023-unsupervised</bibkey>
      <doi>10.18653/v1/2023.findings-acl.210</doi>
    </paper>
    <paper id="211">
      <title>Exploiting Hierarchically Structured Categories in Fine-grained <fixed-case>C</fixed-case>hinese Named Entity Recognition</title>
      <author><first>Jiuding</first><last>Yang</last><affiliation>University of Alberta</affiliation></author>
      <author><first>Jinwen</first><last>Luo</last><affiliation>Tencent</affiliation></author>
      <author><first>Weidong</first><last>Guo</last><affiliation>Tencent</affiliation></author>
      <author><first>Di</first><last>Niu</last><affiliation>University of Alberta</affiliation></author>
      <author><first>Yu</first><last>Xu</last><affiliation>Tencent</affiliation></author>
      <pages>3407-3421</pages>
      <abstract>Chinese Named Entity Recognition (CNER) is a widely used technology in various applications. While recent studies have focused on utilizing additional information of the Chinese language and characters to enhance CNER performance, this paper focuses on a specific aspect of CNER known as fine-grained CNER (FG-CNER). FG-CNER involves the use of hierarchical, fine-grained categories (e.g. Person-MovieStar) to label named entities. To promote research in this area, we introduce the FiNE dataset, a dataset for FG-CNER consisting of 30,000 sentences from various domains and containing 67,651 entities in 54 fine-grained flattened hierarchical categories. Additionally, we propose SoftFiNE, a novel approach for FG-CNER that utilizes a custom-designed relevance scoring function based on label structures to learn the potential relevance between different flattened hierarchical labels. Our experimental results demonstrate that the proposed SoftFiNE method outperforms the state-of-the-art baselines on the FiNE dataset. Furthermore, we conduct extensive experiments on three other datasets, including OntoNotes 4.0, Weibo, and Resume, where SoftFiNE achieved state-of-the-art performance on all three datasets.</abstract>
      <url hash="d429b06c">2023.findings-acl.211</url>
      <bibkey>yang-etal-2023-exploiting</bibkey>
      <doi>10.18653/v1/2023.findings-acl.211</doi>
    </paper>
    <paper id="212">
      <title>Adversarial Textual Robustness on Visual Dialog</title>
      <author><first>Lu</first><last>Yu</last><affiliation>Tianjin University of Technology</affiliation></author>
      <author><first>Verena</first><last>Rieser</last><affiliation>Heriot-Watt University</affiliation></author>
      <pages>3422-3438</pages>
      <abstract>Adversarial robustness evaluates the worst-case performance scenario of a machine learning model to ensure its safety and reliability. For example, cases where the user input contains a minimal change, e.g. a synonym, which causes the previously correct model to return a wrong answer. Using this scenario, this study is the first to investigate the robustness of visually grounded dialog models towards textual attacks. We first aim to understand how multimodal input components contribute to model robustness. Our results show that models which encode dialog history are more robust by providing redundant information. This is in contrast to prior work which finds that dialog history is negligible for model performance on this task. We also evaluate how to generate adversarial test examples which successfully fool the model but remain undetected by the user/software designer. Our analysis shows that the textual, as well as the visual context are important to generate plausible attacks.</abstract>
      <url hash="5a19ca48">2023.findings-acl.212</url>
      <bibkey>yu-rieser-2023-adversarial</bibkey>
      <doi>10.18653/v1/2023.findings-acl.212</doi>
    </paper>
    <paper id="213">
      <title>Language Model Analysis for Ontology Subsumption Inference</title>
      <author><first>Yuan</first><last>He</last><affiliation>University of Oxford</affiliation></author>
      <author><first>Jiaoyan</first><last>Chen</last><affiliation>The University of Manchester</affiliation></author>
      <author><first>Ernesto</first><last>Jimenez-Ruiz</last><affiliation>City, University of London</affiliation></author>
      <author><first>Hang</first><last>Dong</last><affiliation>Department of Computer Science, University of Oxford</affiliation></author>
      <author><first>Ian</first><last>Horrocks</last><affiliation>University of Oxford</affiliation></author>
      <pages>3439-3453</pages>
      <abstract>Investigating whether pre-trained language models (LMs) can function as knowledge bases (KBs) has raised wide research interests recently. However, existing works focus on simple, triple-based, relational KBs, but omit more sophisticated, logic-based, conceptualised KBs such as OWL ontologies. To investigate an LM’s knowledge of ontologies, we propose OntoLAMA, a set of inference-based probing tasks and datasets from ontology subsumption axioms involving both atomic and complex concepts. We conduct extensive experiments on ontologies of different domains and scales, and our results demonstrate that LMs encode relatively less background knowledge of Subsumption Inference (SI) than traditional Natural Language Inference (NLI) but can improve on SI significantly when a small number of samples are given. We will open-source our code and datasets.</abstract>
      <url hash="ccadc3bb">2023.findings-acl.213</url>
      <bibkey>he-etal-2023-language</bibkey>
      <doi>10.18653/v1/2023.findings-acl.213</doi>
    </paper>
    <paper id="214">
      <title>Exploring Automatically Perturbed Natural Language Explanations in Relation Extraction</title>
      <author><first>Wanyun</first><last>Cui</last><affiliation>Shanghai University of Finance and Economics</affiliation></author>
      <author><first>Xingran</first><last>Chen</last><affiliation>University of Michigan</affiliation></author>
      <pages>3454-3467</pages>
      <abstract>Previous research has demonstrated that natural language explanations provide valuable inductive biases that guide models, thereby improving the generalization ability and data efficiency. In this paper, we undertake a systematic examination of the effectiveness of these explanations. Remarkably, we find that corrupted explanations with diminished inductive biases can achieve competitive or superior performance compared to the original explanations. Our findings furnish novel insights into the characteristics of natural language explanations in the following ways: (1) the impact of explanations varies across different training styles and datasets, with previously believed improvements primarily observed in frozen language models. (2) While previous research has attributed the effect of explanations solely to their inductive biases, our study shows that the effect persists even when the explanations are completely corrupted. We propose that the main effect is due to the provision of additional context space. (3) Utilizing the proposed automatic perturbed context, we were able to attain comparable results to annotated explanations, but with a significant increase in computational efficiency, 20-30 times faster.</abstract>
      <url hash="12bb211d">2023.findings-acl.214</url>
      <bibkey>cui-chen-2023-exploring</bibkey>
      <doi>10.18653/v1/2023.findings-acl.214</doi>
    </paper>
    <paper id="215">
      <title>Varta: A Large-Scale Headline-Generation Dataset for <fixed-case>I</fixed-case>ndic Languages</title>
      <author><first>Rahul</first><last>Aralikatte</last><affiliation>Mila</affiliation></author>
      <author><first>Ziling</first><last>Cheng</last><affiliation>McGill University, Mila</affiliation></author>
      <author><first>Sumanth</first><last>Doddapaneni</last><affiliation>Indian Institute of Technology Madras</affiliation></author>
      <author><first>Jackie Chi Kit</first><last>Cheung</last><affiliation>Mila / McGill University</affiliation></author>
      <pages>3468-3492</pages>
      <abstract>We present Varta, a large-scale multilingual dataset for headline generation in Indic languages. This dataset includes more than 41 million pairs of headlines and articles in 14 different Indic languages (and English), which come from a variety of high-quality news sources. To the best of our knowledge, this is the largest collection of curated news articles for Indic languages currently available. We use the collected data in a series of experiments to answer important questions related to Indic NLP and multilinguality research in general. We show that the dataset is challenging even for state-of-the-art abstractive models and that they perform only slightly better than extractive baselines. Owing to its size, we also show that the dataset can be used to pre-train strong language models that outperform competitive baselines in both NLU and NLG benchmarks.</abstract>
      <url hash="3f5fcf45">2023.findings-acl.215</url>
      <bibkey>aralikatte-etal-2023-varta</bibkey>
      <doi>10.18653/v1/2023.findings-acl.215</doi>
    </paper>
    <paper id="216">
      <title>Better Zero-Shot Reasoning with Self-Adaptive Prompting</title>
      <author><first>Xingchen</first><last>Wan</last><affiliation>University of Oxford</affiliation></author>
      <author><first>Ruoxi</first><last>Sun</last><affiliation>Google</affiliation></author>
      <author><first>Hanjun</first><last>Dai</last><affiliation>Google</affiliation></author>
      <author><first>Sercan</first><last>Arik</last><affiliation>Google</affiliation></author>
      <author><first>Tomas</first><last>Pfister</last><affiliation>Google Inc.</affiliation></author>
      <pages>3493-3514</pages>
      <abstract>Modern large language models (LLMs) have demonstrated impressive capabilities at sophisticated tasks, often through step-by-step reasoning similar to humans. This is made possible by their strong few- and zero-shot abilities – they can effectively learn from a handful of handcrafted, completed responses (“in-context examples”), or are prompted to reason spontaneously through specially designed triggers. Nonetheless, some limitations have been observed. First, performance in the few-shot setting is sensitive to the choice of the examples, whose design requires significant human effort. Moreover, given the diverse downstream tasks of LLMs, it may be difficult or laborious to handcraft per-task labels. Second, while the zero-shot setting does not require handcrafting, its performance is limited due to the lack of guidance to the LLMs. To address these limitations, we propose Consistency-based Self-adaptive Prompting (COSP), a novel prompt design method for LLMs. Requiring neither handcrafted responses nor ground-truth labels, COSP selects and builds the set of examples from the LLM zero-shot outputs via carefully designed criteria combining consistency, diversity and repetition. In the zero-shot setting for three different LLMs, we show that using only LLM predictions, COSP significantly improves performance up to 15% compared to zero-shot baselines and matches or exceeds few-shot baselines at a range of reasoning tasks.</abstract>
      <url hash="c10af029">2023.findings-acl.216</url>
      <bibkey>wan-etal-2023-better</bibkey>
      <doi>10.18653/v1/2023.findings-acl.216</doi>
    </paper>
    <paper id="217">
      <title>Multimodal Recommendation Dialog with Subjective Preference: A New Challenge and Benchmark</title>
      <author><first>Yuxing</first><last>Long</last><affiliation>Beijing University of Posts and Telecommunications</affiliation></author>
      <author><first>Binyuan</first><last>Hui</last><affiliation>Alibaba Group</affiliation></author>
      <author><first>Caixia</first><last>Yuan</last><affiliation>Beijing University of Posts and Telecommunications</affiliation></author>
      <author><first>Fei</first><last>Huang</last><affiliation>Alibaba DAMO Academy</affiliation></author>
      <author><first>Yongbin</first><last>Li</last><affiliation>Alibaba Group</affiliation></author>
      <author><first>Xiaojie</first><last>Wang</last><affiliation>Beijing University of Posts and Telecommunications</affiliation></author>
      <pages>3515-3533</pages>
      <abstract>Existing multimodal task-oriented dialog data fails to demonstrate the diverse expressions of user subjective preferences and recommendation acts in the real-life shopping scenario. This paper introduces a new dataset SURE (Multimodal Recommendation Dialog with Subjective Preference), which contains 12K shopping dialogs in complex store scenes. The data is built in two phases with human annotations to ensure quality and diversity. SURE is well-annotated with subjective preferences and recommendation acts proposed by sales experts. A comprehensive analysis is given to reveal the distinguishing features of SURE. Three benchmark tasks are then proposed on the data to evaluate the capability of multimodal recommendation agents. Basing on the SURE, we propose a baseline model, powered by a state-of-the-art multimodal model, for these tasks.</abstract>
      <url hash="c63e7120">2023.findings-acl.217</url>
      <bibkey>long-etal-2023-multimodal</bibkey>
      <doi>10.18653/v1/2023.findings-acl.217</doi>
    </paper>
    <paper id="218">
      <title><fixed-case>ANALOGICAL</fixed-case> - A Novel Benchmark for Long Text Analogy Evaluation in Large Language Models</title>
      <author><first>Thilini</first><last>Wijesiriwardene</last><affiliation>University of South Carolina</affiliation></author>
      <author><first>Ruwan</first><last>Wickramarachchi</last><affiliation>AI Institute, University of South Carolina</affiliation></author>
      <author><first>Bimal</first><last>Gajera</last><affiliation>Nirma University</affiliation></author>
      <author><first>Shreeyash</first><last>Gowaikar</last><affiliation>Birla Institute of Technology and Science, Pilani Goa Campus</affiliation></author>
      <author><first>Chandan</first><last>Gupta</last><affiliation>Indraprastha Institute of Information Technology Delhi</affiliation></author>
      <author><first>Aman</first><last>Chadha</last><affiliation>Stanford University</affiliation></author>
      <author><first>Aishwarya Naresh</first><last>Reganti</last><affiliation>IIIT-Sri City</affiliation></author>
      <author><first>Amit</first><last>Sheth</last><affiliation>AI Institute, University of South Carolina</affiliation></author>
      <author><first>Amitava</first><last>Das</last><affiliation>University of South Carolina</affiliation></author>
      <pages>3534-3549</pages>
      <abstract>Over the past decade, analogies, in the form of word-level analogies, have played a significant role as an intrinsic measure of evaluating the quality of word embedding methods such as word2vec. Modern large language models (LLMs), however, are primarily evaluated on extrinsic measures based on benchmarks such as GLUE and SuperGLUE, and there are only a few investigations on whether LLMs can draw analogies between long texts. In this paper, we present ANALOGICAL, a new benchmark to intrinsically evaluate LLMs across a taxonomy of analogies of long text with six levels of complexity – (i) word, (ii) word vs. sentence, (iii) syntactic, (iv) negation, (v) entailment, and (vi) metaphor. Using thirteen datasets and three different distance measures, we evaluate the abilities of eight LLMs in identifying analogical pairs in the semantic vector space. Our evaluation finds that it is increasingly challenging for LLMs to identify analogies when going up the analogy taxonomy.</abstract>
      <url hash="1ccf801c">2023.findings-acl.218</url>
      <bibkey>wijesiriwardene-etal-2023-analogical</bibkey>
      <doi>10.18653/v1/2023.findings-acl.218</doi>
    </paper>
    <paper id="219">
      <title>Financial Numeric Extreme Labelling: A dataset and benchmarking</title>
      <author><first>Soumya</first><last>Sharma</last><affiliation>Indian Institute of Technology, Kharagpur</affiliation></author>
      <author><first>Subhendu</first><last>Khatuya</last><affiliation>IIT Kharagpur</affiliation></author>
      <author><first>Manjunath</first><last>Hegde</last><affiliation>Goldman Sachs</affiliation></author>
      <author><first>Afreen</first><last>Shaikh</last><affiliation>Goldmansachs</affiliation></author>
      <author><first>Koustuv</first><last>Dasgupta</last><affiliation>Goldman Sachs</affiliation></author>
      <author><first>Pawan</first><last>Goyal</last><affiliation>IIT Kharagpur</affiliation></author>
      <author><first>Niloy</first><last>Ganguly</last><affiliation>IIT Kharagpur</affiliation></author>
      <pages>3550-3561</pages>
      <abstract>The U.S. Securities and Exchange Commission (SEC) mandates all public companies to file periodic financial statements that should contain numerals annotated with a particular label from a taxonomy. In this paper, we formulate the task of automating the assignment of a label to a particular numeral span in a sentence from an extremely large label set. Towards this task, we release a dataset, Financial Numeric Extreme Labelling (FNXL), annotated with 2,794 labels. We benchmark the performance of the FNXL dataset by formulating the task as (a) a sequence labelling problem and (b) a pipeline with span extraction followed by Extreme Classification. Although the two approaches perform comparably, the pipeline solution provides a slight edge for the least frequent labels.</abstract>
      <url hash="c6f9f02e">2023.findings-acl.219</url>
      <bibkey>sharma-etal-2023-financial</bibkey>
      <doi>10.18653/v1/2023.findings-acl.219</doi>
    </paper>
    <paper id="220">
      <title>Multilingual Summarization with Factual Consistency Evaluation</title>
      <author><first>Roee</first><last>Aharoni</last><affiliation>Google</affiliation></author>
      <author><first>Shashi</first><last>Narayan</last><affiliation>Google</affiliation></author>
      <author><first>Joshua</first><last>Maynez</last><affiliation>Google</affiliation></author>
      <author><first>Jonathan</first><last>Herzig</last><affiliation>Google Research</affiliation></author>
      <author><first>Elizabeth</first><last>Clark</last><affiliation>Google Research</affiliation></author>
      <author><first>Mirella</first><last>Lapata</last><affiliation>School of Informatics, University of Edinburgh</affiliation></author>
      <pages>3562-3591</pages>
      <abstract>Abstractive summarization has enjoyed renewed interest in recent years, thanks to pre-trained language models and the availability of large-scale datasets. Despite promising results, current models still suffer from generating factually inconsistent summaries, reducing their utility for real-world application. Several recent efforts attempt to address this by devising models that automatically detect factual inconsistencies in machine generated summaries. However, they focus exclusively on English, a language with abundant resources. In this work, we leverage factual consistency evaluation models to improve <i>multilingual</i> summarization. We explore two intuitive approaches to mitigate hallucinations based on the signal provided by a multilingual NLI model, namely data filtering and controlled generation. Experimental results in the 45 languages from the XLSum dataset show gains over strong baselines in both automatic and human evaluation. We release models and human judgements of summaries to foster progress towards more factually consistent multilingual summarization.</abstract>
      <url hash="d4d7b0dc">2023.findings-acl.220</url>
      <bibkey>aharoni-etal-2023-multilingual</bibkey>
      <doi>10.18653/v1/2023.findings-acl.220</doi>
    </paper>
    <paper id="221">
      <title>Enhancing Out-of-Vocabulary Estimation with Subword Attention</title>
      <author><first>Raj</first><last>Patel</last><affiliation>George Mason University</affiliation></author>
      <author><first>Carlotta</first><last>Domeniconi</last><affiliation>George Mason University</affiliation></author>
      <pages>3592-3601</pages>
      <abstract>Word embedding methods like word2vec and GloVe have been shown to learn strong representations of words. However, these methods only learn representations for words in the training corpus and therefore struggle to handle unknown and new words, known as out-of-vocabulary (OOV) words. As a result, there have been multiple attempts to learn OOV word representations in a similar fashion to how humans learn new words, using word roots/subwords and/or surrounding words. However, while most of these approaches use advanced architectures like attention on the context of the OOV word, they tend to use simple structures like ngram addition or character based convolutional neural networks (CNN) to handle processing subword information. In response to this, we propose SubAtt, a transformer based OOV estimation model that uses attention mechanisms on both the context and the subwords. In addition to attention, we also show that pretraining subword representations also leads to improvement in OOV estimation. We show SubAtt outperforms current state-of-the-art OOV estimation models.</abstract>
      <url hash="28d58940">2023.findings-acl.221</url>
      <bibkey>patel-domeniconi-2023-enhancing</bibkey>
      <doi>10.18653/v1/2023.findings-acl.221</doi>
    </paper>
    <paper id="222">
      <title>Encoder and Decoder, Not One Less for Pre-trained Language Model Sponsored <fixed-case>NMT</fixed-case></title>
      <author><first>Sufeng</first><last>Duan</last><affiliation>Shanghai Jiao Tong University</affiliation></author>
      <author><first>Hai</first><last>Zhao</last><affiliation>Shanghai Jiao Tong University</affiliation></author>
      <pages>3602-3613</pages>
      <abstract>Well pre-trained contextualized representations from pre-trained language model (PLM) have been shown helpful for enhancing various natural language processing tasks, surely including neural machine translation (NMT). However, existing methods either consider encoder-only enhancement or rely on specific multilingual PLMs, which leads to a much larger model or give up potentially helpful knowledge from target PLMs. In this paper, we propose a new monolingual PLM-sponsored NMT model to let both encoder and decoder enjoy PLM enhancement to alleviate such obvious inconvenience. Especially, incorporating a newly proposed frequency-weighted embedding transformation algorithm, PLM embeddings can be effectively exploited in terms of the representations of the NMT decoder. We evaluate our model on IWSLT14 En-De, De-En, WMT14 En-De, and En-Fr tasks, and the results show that our proposed PLM enhancement gives significant improvement and even helps achieve new state-of-the-art.</abstract>
      <url hash="c7c95482">2023.findings-acl.222</url>
      <bibkey>duan-zhao-2023-encoder</bibkey>
      <doi>10.18653/v1/2023.findings-acl.222</doi>
    </paper>
    <paper id="223">
      <title><fixed-case>T</fixed-case>rans<fixed-case>GEC</fixed-case>: Improving Grammatical Error Correction with Translationese</title>
      <author><first>Tao</first><last>Fang</last><affiliation>University of Macau</affiliation></author>
      <author><first>Xuebo</first><last>Liu</last><affiliation>Harbin Institute of Technology, Shenzhen</affiliation></author>
      <author><first>Derek F.</first><last>Wong</last><affiliation>University of Macau</affiliation></author>
      <author><first>Runzhe</first><last>Zhan</last><affiliation>University of Macau</affiliation></author>
      <author><first>Liang</first><last>Ding</last><affiliation>JD Explore Academy, JD.com Inc. &amp; The University of Sydney</affiliation></author>
      <author><first>Lidia S.</first><last>Chao</last><affiliation>University of Macau</affiliation></author>
      <author><first>Dacheng</first><last>Tao</last><affiliation>School of Computer Science, The University of Sydney</affiliation></author>
      <author><first>Min</first><last>Zhang</last><affiliation>Harbin Institute of Technology (Shenzhen)</affiliation></author>
      <pages>3614-3633</pages>
      <abstract>Data augmentation is an effective way to improve model performance of grammatical error correction (GEC). This paper identifies a critical side-effect of GEC data augmentation, which is due to the style discrepancy between the data used in GEC tasks (i.e., texts produced by non-native speakers) and data augmentation (i.e., native texts). To alleviate this issue, we propose to use an alternative data source, translationese (i.e., human-translated texts), as input for GEC data augmentation, which 1) is easier to obtain and usually has better quality than non-native texts, and 2) has a more similar style to non-native texts. Experimental results on the CoNLL14 and BEA19 English, NLPCC18 Chinese, Falko-MERLIN German, and RULEC-GEC Russian GEC benchmarks show that our approach consistently improves correction accuracy over strong baselines. Further analyses reveal that our approach is helpful for overcoming mainstream correction difficulties such as the corrections of frequent words, missing words, and substitution errors. Data, code, models and scripts are freely available at <url>https://github.com/NLP2CT/TransGEC</url>.</abstract>
      <url hash="acad3560">2023.findings-acl.223</url>
      <bibkey>fang-etal-2023-transgec</bibkey>
      <doi>10.18653/v1/2023.findings-acl.223</doi>
    </paper>
    <paper id="224">
      <title><fixed-case>N</fixed-case>ews<fixed-case>D</fixed-case>ialogues: Towards Proactive News Grounded Conversation</title>
      <author><first>Siheng</first><last>Li</last><affiliation>Tsinghua Shenzhen International Graduate School, Tsinghua University</affiliation></author>
      <author><first>Yichun</first><last>Yin</last><affiliation>Noah’s Ark Lab of Huawei</affiliation></author>
      <author><first>Cheng</first><last>Yang</last><affiliation>Tsinghua University</affiliation></author>
      <author><first>Wangjie</first><last>Jiang</last><affiliation>Tsinghua University</affiliation></author>
      <author><first>Yiwei</first><last>Li</last><affiliation>Beijing Institute of Technology</affiliation></author>
      <author><first>Zesen</first><last>Cheng</last><affiliation>School of Electronic and Computer Engineering, Peking University</affiliation></author>
      <author><first>Lifeng</first><last>Shang</last><affiliation>Noah’s Ark Lab Huawei Technologies Co. Ltd. Sha Tin, Hong Kong</affiliation></author>
      <author><first>Xin</first><last>Jiang</last><affiliation>Huawei Noah’s Ark Lab</affiliation></author>
      <author><first>Qun</first><last>Liu</last><affiliation>Huawei Noah’s Ark Lab</affiliation></author>
      <author><first>Yujiu</first><last>Yang</last><affiliation>tsinghua.edu.cn</affiliation></author>
      <pages>3634-3649</pages>
      <abstract>Hot news is one of the most popular topics in daily conversations. However, news grounded conversation has long been stymied by the lack of well-designed task definition and scarce data. In this paper, we propose a novel task, Proactive News Grounded Conversation, in which a dialogue system can proactively lead the conversation based on some key topics of the news. In addition, both information-seeking and chit-chat scenarios are included realistically, where the user may ask a series of questions about the news details or express their opinions and be eager to chat. To further develop this novel task, we collect a human-to-human Chinese dialogue dataset NewsDialogues, which includes 1K conversations with a total of 14.6K utterances and detailed annotations for target topics and knowledge spans. Furthermore, we propose a method named Predict-Generate-Rank, consisting of a generator for grounded knowledge prediction and response generation, and a ranker for the ranking of multiple responses to alleviate the exposure bias. We conduct comprehensive experiments to demonstrate the effectiveness of the proposed method and further present several key findings and challenges to prompt future research.</abstract>
      <url hash="68673af6">2023.findings-acl.224</url>
      <bibkey>li-etal-2023-newsdialogues</bibkey>
      <doi>10.18653/v1/2023.findings-acl.224</doi>
    </paper>
    <paper id="225">
      <title>Task-aware Retrieval with Instructions</title>
      <author><first>Akari</first><last>Asai</last><affiliation>University of Washington</affiliation></author>
      <author><first>Timo</first><last>Schick</last><affiliation>Meta AI</affiliation></author>
      <author><first>Patrick</first><last>Lewis</last><affiliation>Cohere, University College London</affiliation></author>
      <author><first>Xilun</first><last>Chen</last><affiliation>Meta AI</affiliation></author>
      <author><first>Gautier</first><last>Izacard</last><affiliation>Facebook AI Research</affiliation></author>
      <author><first>Sebastian</first><last>Riedel</last><affiliation>University College London / Facebook AI Research</affiliation></author>
      <author><first>Hannaneh</first><last>Hajishirzi</last><affiliation>University of Washington</affiliation></author>
      <author><first>Wen-tau</first><last>Yih</last><affiliation>Meta AI - FAIR</affiliation></author>
      <pages>3650-3675</pages>
      <abstract>We study the problem of retrieval with instructions, where users provide explicit descriptions of their intent along with their queries to guide a retrieval system. Our solution is a general-purpose task-aware retrieval system, trained using multi-task instruction tuning and can follow human-written instructions to find relevant documents to a given query. We introduce the first large-scale collection of 37 retrieval datasets with instructions, BERRI, and present TART, a single multi-task retrieval system trained on BERRI with instructions that can adapt to a new task without any parameter updates. TART advances the state of the art on two zero-shot retrieval benchmarks, BEIR and LOTTE, outperforming models up to three times larger. We further introduce a new evaluation setup, X2-Retrieval, to better reflect real-world scenarios in which diverse domains and tasks are pooled. TART significantly outperforms competitive baselines in this setup, further highlighting the effectiveness of guiding retrieval with instructions.</abstract>
      <url hash="6674a452">2023.findings-acl.225</url>
      <bibkey>asai-etal-2023-task</bibkey>
      <doi>10.18653/v1/2023.findings-acl.225</doi>
    </paper>
    <paper id="226">
      <title>Non-Repeatable Experiments and Non-Reproducible Results: The Reproducibility Crisis in Human Evaluation in <fixed-case>NLP</fixed-case></title>
      <author><first>Anya</first><last>Belz</last><affiliation>ADAPT Research Centre, Dublin City University</affiliation></author>
      <author><first>Craig</first><last>Thomson</last><affiliation>University of Aberdeen</affiliation></author>
      <author><first>Ehud</first><last>Reiter</last><affiliation>University of Aberdeen</affiliation></author>
      <author><first>Simon</first><last>Mille</last><affiliation>ADAPT Research Centre, Dublin City University</affiliation></author>
      <pages>3676-3687</pages>
      <abstract>Human evaluation is widely regarded as the litmus test of quality in NLP. A basic requirementof all evaluations, but in particular where they are used for meta-evaluation, is that they should support the same conclusions if repeated. However, the reproducibility of human evaluations is virtually never queried, let alone formally tested, in NLP which means that their repeatability and the reproducibility of their results is currently an open question. This focused contribution reports our review of human evaluation experiments reported in NLP papers over the past five years which we assessed in terms oftheir ability to be rerun. Overall, we estimatethat just 5% of human evaluations are repeatable in the sense that (i) there are no prohibitivebarriers to repetition, and (ii) sufficient information about experimental design is publicly available for rerunning them. Our estimate goesup to about 20% when author help is sought. We complement this investigation with a survey of results concerning the reproducibilityof human evaluations where those are repeatable in the first place. Here we find worryinglylow degrees of reproducibility, both in terms ofsimilarity of scores and of findings supportedby them. We summarise what insights can begleaned so far regarding how to make humanevaluations in NLP more repeatable and morereproducible.</abstract>
      <url hash="8d4b16fe">2023.findings-acl.226</url>
      <bibkey>belz-etal-2023-non</bibkey>
      <doi>10.18653/v1/2023.findings-acl.226</doi>
    </paper>
    <paper id="227">
      <title>Define, Evaluate, and Improve Task-Oriented Cognitive Capabilities for Instruction Generation Models</title>
      <author><first>Lingjun</first><last>Zhao</last><affiliation>University of Maryland, College Park</affiliation></author>
      <author><first>Khanh</first><last>Nguyen</last><affiliation>Princeton University</affiliation></author>
      <author><first>Hal</first><last>Daumé III</last><affiliation>UMD</affiliation></author>
      <pages>3688-3706</pages>
      <abstract>Recent work studies the cognitive capabilities of language models through psychological tests designed for humans. While these studies are helpful for understanding the general capabilities of these models, there is no guarantee that a model possessing sufficient capabilities to pass those tests would actually use those capabilities in performing real-life tasks. In this work, we formulate task-oriented cognitive capabilities, which are human-like cognitive capabilities that language models leverage to perform tasks. These capabilities are (i) the ability to quickly generate good candidate utterances (the search capability) (ii) the ability to predict how a listener interprets those utterances and choose the most appropriate one (the pragmatic capability). We design an evaluation scheme for comparing these capabilities of a language model with those of a human. Applying this scheme to examine various models in a navigation instruction generation problem, we find that their pragmatic capability is severely lacking. This insight leads us to augment them with better models of the listener and obtain a significant boost of 11% in success rate in guiding real humans. Our work advocates for having a principled procedure for aligning language models with humans that involves (i) formulating task-oriented capabilities, (ii) devising a method to quantify their deficiency, and (iii) iteratively improving them.</abstract>
      <url hash="006db232">2023.findings-acl.227</url>
      <bibkey>zhao-etal-2023-define</bibkey>
      <doi>10.18653/v1/2023.findings-acl.227</doi>
    </paper>
    <paper id="228">
      <title>Robustness of Multi-Source <fixed-case>MT</fixed-case> to Transcription Errors</title>
      <author><first>Dominik</first><last>Macháček</last><affiliation>Charles University, MFF UFAL</affiliation></author>
      <author><first>Peter</first><last>Polák</last><affiliation>Charles University, MFF UFAL</affiliation></author>
      <author><first>Ondřej</first><last>Bojar</last><affiliation>Charles University, MFF UFAL</affiliation></author>
      <author><first>Raj</first><last>Dabre</last><affiliation>NICT</affiliation></author>
      <pages>3707-3723</pages>
      <abstract>Automatic speech translation is sensitive to speech recognition errors, but in a multilingual scenario, the same content may be available in various languages via simultaneous interpreting, dubbing or subtitling. In this paper, we hypothesize that leveraging multiple sources will improve translation quality if the sources complement one another in terms of correct information they contain. To this end, we first show that on a 10-hour ESIC corpus, the ASR errors in the original English speech and its simultaneous interpreting into German and Czech are mutually independent. We then use two sources, English and German, in a multi-source setting for translation into Czech to establish its robustness to ASR errors. Furthermore, we observe this robustness when translating both noisy sources together in a simultaneous translation setting. Our results show that multi-source neural machine translation has the potential to be useful in a real-time simultaneous translation setting, thereby motivating further investigation in this area.</abstract>
      <url hash="48b9982f">2023.findings-acl.228</url>
      <bibkey>machacek-etal-2023-robustness</bibkey>
      <doi>10.18653/v1/2023.findings-acl.228</doi>
    </paper>
    <paper id="229">
      <title>Not The End of Story: An Evaluation of <fixed-case>C</fixed-case>hat<fixed-case>GPT</fixed-case>-Driven Vulnerability Description Mappings</title>
      <author><first>Xin</first><last>Liu</last><affiliation>Lanzhou University</affiliation></author>
      <author><first>Yuan</first><last>Tan</last><affiliation>Lanzhou University</affiliation></author>
      <author><first>Zhenghang</first><last>Xiao</last><affiliation>Hunan University</affiliation></author>
      <author><first>Jianwei</first><last>Zhuge</last><affiliation>Tsinghua University, Zhongguancun Laboratory</affiliation></author>
      <author><first>Rui</first><last>Zhou</last><affiliation>Lanzhou University</affiliation></author>
      <pages>3724-3731</pages>
      <abstract>As the number of vulnerabilities increases day by day, security management requires more and more structured data. In addition to textual descriptions of vulnerabilities, security engineers must classify and assess vulnerabilities and clarify their associated techniques. Vulnerability Description Mapping (VDM) refers to mapping vulnerabilities to Common Weakness Enumeration (CWE), Common Attack Pattern Enumeration and Classification, ATT&amp;CK Techniques, and other classifications. Accurate VDM is necessary to reduce the pressure of security management and improve the speed of security emergency response. ChatGPT is the latest state-of-the-art closed-source conversational large language model (LLM), which performs excellently on many tasks. This paper explores the application of closed-source LLMs to real-world security management scenarios by evaluating ChatGPT’s performance on VDM tasks. The results show that although ChatGPT may be close to the level of human experts on some tasks, it still cannot replace the critical role of professional security engineers in vulnerability analysis. In a word, closed-source LLM is not the end of story.</abstract>
      <url hash="e4bea165">2023.findings-acl.229</url>
      <bibkey>liu-etal-2023-end</bibkey>
      <doi>10.18653/v1/2023.findings-acl.229</doi>
    </paper>
    <paper id="230">
      <title><fixed-case>M</fixed-case>ulti3<fixed-case>NLU</fixed-case>++: A Multilingual, Multi-Intent, Multi-Domain Dataset for Natural Language Understanding in Task-Oriented Dialogue</title>
      <author><first>Nikita</first><last>Moghe</last><affiliation>University of Edinburgh</affiliation></author>
      <author><first>Evgeniia</first><last>Razumovskaia</last><affiliation>University of Cambridge</affiliation></author>
      <author><first>Liane</first><last>Guillou</last><affiliation>The University of Edinburgh</affiliation></author>
      <author><first>Ivan</first><last>Vulić</last><affiliation>University of Cambridge</affiliation></author>
      <author><first>Anna</first><last>Korhonen</last><affiliation>University of Cambridge</affiliation></author>
      <author><first>Alexandra</first><last>Birch</last><affiliation>University of Edinburgh</affiliation></author>
      <pages>3732-3755</pages>
      <abstract>Task-oriented dialogue (ToD) systems have been widely deployed in many industries as they deliver more efficient customer support. These systems are typically constructed for a single domain or language and do not generalise well beyond this. To support work on Natural Language Understanding (NLU) in ToD across multiple languages and domains simultaneously, we constructed Multi3NLU++, a multilingual, multi-intent, multi-domain dataset. Multi3NLU++ extends the English-only NLU++ dataset to include manual translations into a range of high, medium, and low resource languages (Spanish, Marathi, Turkish and Amharic), in two domains (banking and hotels). Because of its multi-intent property, Multi3NLU++ represents complex and natural user goals, and therefore allows us to measure the realistic performance of ToD systems in a varied set of the world’s languages. We use Multi3NLU++ to benchmark state-of-the-art multilingual models for the NLU tasks of intent detection and slot labeling for ToD systems in the multilingual setting. The results demonstrate the challenging nature of the dataset, particularly in the low-resource language setting, offering ample room for future experimentation in multi-domain multilingual ToD setups.</abstract>
      <url hash="f35ed5c5">2023.findings-acl.230</url>
      <bibkey>moghe-etal-2023-multi3nlu</bibkey>
      <doi>10.18653/v1/2023.findings-acl.230</doi>
    </paper>
    <paper id="231">
      <title>A Robust Information-Masking Approach for Domain Counterfactual Generation</title>
      <author><first>Pengfei</first><last>Hong</last><affiliation>Singapore University of Technology and Design</affiliation></author>
      <author><first>Rishabh</first><last>Bhardwaj</last><affiliation>Singapore University of Technology and Design</affiliation></author>
      <author><first>Navonil</first><last>Majumder</last><affiliation>Singapore University of Technology and Design</affiliation></author>
      <author><first>Somak</first><last>Aditya</last><affiliation>IIT Kharagpur</affiliation></author>
      <author><first>Soujanya</first><last>Poria</last><affiliation>Singapore University of Technology and Design</affiliation></author>
      <pages>3756-3769</pages>
      <abstract>Domain shift is a big challenge in NLP. Many approaches, thus, resort to learning domain-invariant features to mitigate the hurdles of domain shift during inference. Such methods, however, inexorably fail to leverage the domain-specific nuances relevant to the task at hand. To avoid such drawbacks, domain counterfactual generation has recently been proposed that aims to transform a text from the source domain to a given target domain. To achieve this, the existing method uses a frequency-based approach to identify and mask the source-domain-specific tokens in a text. A pretrained LM is then prompted to fill the masks with target-domain-specific tokens. We, however, have observed that, due to limitations of the available data, such a frequency-based method may either miss some domain-token associations or lead to some spurious domain-token associations. To this end, we additionally employ attention norm-based scores to identify additional token-domain associations from a domain classifier. To minimize spurious associations, we also devise an iterative unmasking heuristic that unmasks the masked tokens to minimize the confidence of a domain classifier in the source domain. Our experiments empirically show that the counterfactual samples sourced from our masked text lead to improved domain transfer across various classification tasks. The proposed approach outperforms the baselines on 10 out of 12 domain-counterfactual classification settings with an average of 1.7% improvement in accuracy metric.</abstract>
      <url hash="c9c240b2">2023.findings-acl.231</url>
      <bibkey>hong-etal-2023-robust</bibkey>
      <doi>10.18653/v1/2023.findings-acl.231</doi>
    </paper>
    <paper id="232">
      <title>Misleading Relation Classifiers by Substituting Words in Texts</title>
      <author><first>Tian</first><last>Jiang</last><affiliation>Key Laboratory of Aerospace Information Security and Trusted Computing, Ministry of Education, School of Cyber Science and Engineering, Wuhan University</affiliation></author>
      <author><first>Yunqi</first><last>Liu</last><affiliation>Key Laboratory of Aerospace Information Security and Trusted Computing, Ministry of Education, School of Cyber Science and Engineering, Wuhan University</affiliation></author>
      <author><first>Yan</first><last>Feng</last><affiliation>Key Laboratory of Aerospace Information Security and Trusted Computing, Ministry of Education, School of Cyber Science and Engineering, Wuhan University</affiliation></author>
      <author><first>Yuqing</first><last>Li</last><affiliation>Key Laboratory of Aerospace Information Security and Trusted Computing, Ministry of Education, School of Cyber Science and Engineering, Wuhan University</affiliation></author>
      <author><first>Xiaohui</first><last>Cui</last><affiliation>Wuhan University</affiliation></author>
      <pages>3770-3785</pages>
      <abstract>Relation classification is to determine the semantic relationship between two entities in a given sentence. However, many relation classifiers are vulnerable to adversarial attacks, which is using adversarial examples to lead victim models to output wrong results. In this paper, we propose a simple but effective method for misleading relation classifiers. We first analyze the most important parts of speech (POSs) from the syntax and morphology perspectives, then we substitute words labeled with these POS tags in original samples with synonyms or hyponyms. Experimental results show that our method can generate adversarial texts of high quality, and most of the relationships between entities can be correctly identified in the process of human evaluation. Furthermore, the adversarial examples generated by our method possess promising transferability, and they are also helpful for improving the robustness of victim models.</abstract>
      <url hash="c9fbde52">2023.findings-acl.232</url>
      <bibkey>jiang-etal-2023-misleading</bibkey>
      <doi>10.18653/v1/2023.findings-acl.232</doi>
    </paper>
    <paper id="233">
      <title>Automatic Table Union Search with Tabular Representation Learning</title>
      <author><first>Xuming</first><last>Hu</last><affiliation>School of Software, Tsinghua University</affiliation></author>
      <author><first>Shen</first><last>Wang</last><affiliation>Amazon</affiliation></author>
      <author><first>Xiao</first><last>Qin</last><affiliation>AWS</affiliation></author>
      <author><first>Chuan</first><last>Lei</last><affiliation>AWS AI/ML</affiliation></author>
      <author><first>Zhengyuan</first><last>Shen</last><affiliation>Amazon</affiliation></author>
      <author><first>Christos</first><last>Faloutsos</last><affiliation>CMU</affiliation></author>
      <author><first>Asterios</first><last>Katsifodimos</last><affiliation>Amazon Web Services</affiliation></author>
      <author><first>George</first><last>Karypis</last><affiliation>University of Minnesota</affiliation></author>
      <author><first>Lijie</first><last>Wen</last><affiliation>School of Software, Tsinghua University</affiliation></author>
      <author><first>Philip S.</first><last>Yu</last><affiliation>University of Illinois at Chicago</affiliation></author>
      <pages>3786-3800</pages>
      <abstract>Given a data lake of tabular data as well as a query table, how can we retrieve all the tables in the data lake that can be unioned with the query table? Table union search constitutes an essential task in data discovery and preparation as it enables data scientists to navigate massive open data repositories. Existing methods identify uniability based on column representations (word surface forms or token embeddings) and column relation represented by column representation similarity. However, the semantic similarity obtained between column representations is often insufficient to reveal latent relational features to describe the column relation between pair of columns and not robust to the table noise. To address these issues, in this paper, we propose a multi-stage self-supervised table union search framework called AutoTUS, which represents column relation as a vector– column relational representation and learn column relational representation in a multi-stage manner that can better describe column relation for unionability prediction. In particular, the large language model powered contextualized column relation encoder is updated by adaptive clustering and pseudo label classification iteratively so that the better column relational representation can be learned. Moreover, to improve the robustness of the model against table noises, we propose table noise generator to add table noise to the training table data. Experiments on real-world datasets as well as synthetic test set augmented with table noise show that AutoTUS achieves 5.2% performance gain over the SOTA baseline.</abstract>
      <url hash="fc2b0a80">2023.findings-acl.233</url>
      <bibkey>hu-etal-2023-automatic</bibkey>
      <doi>10.18653/v1/2023.findings-acl.233</doi>
    </paper>
    <paper id="234">
      <title>Bidirectional Transformer Reranker for Grammatical Error Correction</title>
      <author><first>Ying</first><last>Zhang</last><affiliation>Tokyo Institute of Technology</affiliation></author>
      <author><first>Hidetaka</first><last>Kamigaito</last><affiliation>Nara Institute of Science and Technology</affiliation></author>
      <author><first>Manabu</first><last>Okumura</last><affiliation>Tokyo Institute of Technology</affiliation></author>
      <pages>3801-3825</pages>
      <abstract>Pre-trained seq2seq models have achieved state-of-the-art results in the grammatical error correction task. However, these models still suffer from a prediction bias due to their unidirectional decoding. Thus, we propose a bidirectional Transformer reranker (BTR), that re-estimates the probability of each candidate sentence generated by the pre-trained seq2seq model. The BTR preserves the seq2seq-style Transformer architecture but utilizes a BERT-style self-attention mechanism in the decoder to compute the probability of each target token by using masked language modeling to capture bidirectional representations from the target context. For guiding the reranking, the BTR adopts negative sampling in the objective function to minimize the unlikelihood. During inference, the BTR gives final results after comparing the reranked top-1 results with the original ones by an acceptance threshold. Experimental results show that, in reranking candidates from a pre-trained seq2seq model, T5-base, the BTR on top of T5-base could yield 65.47 and 71.27 F0.5 scores on the CoNLL-14 and BEA test sets, respectively, and yield 59.52 GLEU score on the JFLEG corpus, with improvements of 0.36, 0.76 and 0.48 points compared with the original T5-base. Furthermore, when reranking candidates from T5-large, the BTR on top of T5-base improved the original T5-large by 0.26 points on the BEA test set.</abstract>
      <url hash="5149cca9">2023.findings-acl.234</url>
      <bibkey>zhang-etal-2023-bidirectional</bibkey>
      <doi>10.18653/v1/2023.findings-acl.234</doi>
    </paper>
    <paper id="235">
      <title>Not Enough Data to Pre-train Your Language Model? <fixed-case>MT</fixed-case> to the Rescue!</title>
      <author><first>Gorka</first><last>Urbizu</last><affiliation>Orai NLP Technologies</affiliation></author>
      <author><first>Iñaki</first><last>San Vicente</last><affiliation>Orai NLP Technologies</affiliation></author>
      <author><first>Xabier</first><last>Saralegi</last><affiliation>Orai NLP Technologies</affiliation></author>
      <author><first>Ander</first><last>Corral</last><affiliation>Orai NLP Technologies</affiliation></author>
      <pages>3826-3836</pages>
      <abstract>In recent years, pre-trained transformer-based language models (LM) have become a key resource for implementing most NLP tasks. However, pre-training such models demands large text collections not available in most languages. In this paper, we study the use of machine-translated corpora for pre-training LMs. We answer the following research questions: RQ1: Is MT-based data an alternative to real data for learning a LM?; RQ2: Can real data be complemented with translated data and improve the resulting LM? In order to validate these two questions, several BERT models for Basque have been trained, combining real data and synthetic data translated from Spanish.The evaluation carried out on 9 NLU tasks indicates that models trained exclusively on translated data offer competitive results. Furthermore, models trained with real data can be improved with synthetic data, although further research is needed on the matter.</abstract>
      <url hash="62c29752">2023.findings-acl.235</url>
      <bibkey>urbizu-etal-2023-enough</bibkey>
      <doi>10.18653/v1/2023.findings-acl.235</doi>
    </paper>
    <paper id="236">
      <title><fixed-case>UMSE</fixed-case>: Unified Multi-scenario Summarization Evaluation</title>
      <author><first>Shen</first><last>Gao</last><affiliation>Shandong University</affiliation></author>
      <author><first>Zhitao</first><last>Yao</last><affiliation>Shandong University</affiliation></author>
      <author><first>Chongyang</first><last>Tao</last><affiliation>Microsoft Corporation</affiliation></author>
      <author><first>Xiuying</first><last>Chen</last><affiliation>KAUST</affiliation></author>
      <author><first>Pengjie</first><last>Ren</last><affiliation>Shandong University</affiliation></author>
      <author><first>Zhaochun</first><last>Ren</last><affiliation>Shandong University</affiliation></author>
      <author><first>Zhumin</first><last>Chen</last><affiliation>Shandong University</affiliation></author>
      <pages>3837-3849</pages>
      <abstract>Summarization quality evaluation is a non-trivial task in text summarization. Contemporary methods can be mainly categorized into two scenarios: (1) reference-based: evaluating with human-labeled reference summary; (2) reference-free: evaluating the summary consistency of the document. Recent studies mainly focus on one of these scenarios and explore training neural models built on PLMs to align with human criteria. However, the models from different scenarios are optimized individually, which may result in sub-optimal performance since they neglect the shared knowledge across different scenarios. Besides, designing individual models for each scenario caused inconvenience to the user. Inspired by this, we propose Unified Multi-scenario Summarization Evaluation Model (UMSE). More specifically, we propose a perturbed prefix tuning method to share cross-scenario knowledge between scenarios and use a self-supervised training paradigm to optimize the model without extra human labeling. Our UMSE is the first unified summarization evaluation framework engaged with the ability to be used in three evaluation scenarios. Experimental results across three typical scenarios on the benchmark dataset SummEval indicate that our UMSE can achieve comparable performance with several existing strong methods which are specifically designed for each scenario.</abstract>
      <url hash="873b3ae2">2023.findings-acl.236</url>
      <bibkey>gao-etal-2023-umse</bibkey>
      <doi>10.18653/v1/2023.findings-acl.236</doi>
    </paper>
    <paper id="237">
      <title>Maximum Entropy Loss, the Silver Bullet Targeting Backdoor Attacks in Pre-trained Language Models</title>
      <author><first>Zhengxiao</first><last>Liu</last><affiliation>Institute of Information Engineering, CAS</affiliation></author>
      <author><first>Bowen</first><last>Shen</last><affiliation>Institute of Information Engineering, Chinese Academy of Sciences</affiliation></author>
      <author><first>Zheng</first><last>Lin</last><affiliation>Institute of Information Engineering, Chinese Academy of Sciences</affiliation></author>
      <author><first>Fali</first><last>Wang</last><affiliation>The Pennsylvania State University</affiliation></author>
      <author><first>Weiping</first><last>Wang</last><affiliation>Institute of Information Engineering, Chinese Academy of Sciences</affiliation></author>
      <pages>3850-3868</pages>
      <abstract>Pre-trained language model (PLM) can be stealthily misled to target outputs by backdoor attacks when encountering poisoned samples, without performance degradation on clean samples. The stealthiness of backdoor attacks is commonly attained through minimal cross-entropy loss fine-tuning on a union of poisoned and clean samples. Existing defense paradigms provide a workaround by detecting and removing poisoned samples at pre-training or inference time. On the contrary, we provide a new perspective where the backdoor attack is directly reversed. Specifically, maximum entropy loss is incorporated in training to neutralize the minimal cross-entropy loss fine-tuning on poisoned data. We defend against a range of backdoor attacks on classification tasks and significantly lower the attack success rate. In extension, we explore the relationship between intended backdoor attacks and unintended dataset bias, and demonstrate the feasibility of the maximum entropy principle in de-biasing.</abstract>
      <url hash="cfde485c">2023.findings-acl.237</url>
      <bibkey>liu-etal-2023-maximum</bibkey>
      <doi>10.18653/v1/2023.findings-acl.237</doi>
    </paper>
    <paper id="238">
      <title>Improving Named Entity Recognition via Bridge-based Domain Adaptation</title>
      <author><first>Jingyun</first><last>Xu</last><affiliation>South China University of Technology</affiliation></author>
      <author><first>Changmeng</first><last>Zheng</last><affiliation>The Hong Kong Polytechnic University</affiliation></author>
      <author><first>Yi</first><last>Cai</last><affiliation>South China University of Technology</affiliation></author>
      <author><first>Tat-Seng</first><last>Chua</last><affiliation>National University of Singapore</affiliation></author>
      <pages>3869-3882</pages>
      <abstract>Recent studies have shown remarkable success in cross-domain named entity recognition (cross-domain NER). Despite the promising results, existing methods mainly utilize pre-training language models like BERT to represent words. As such, the original chaotic representations may challenge them to distinguish entity types of entities, leading to entity type misclassification. To this end, we attempt to utilize contrastive learning to refine the original representations and propose a model-agnostic framework named MoCL for cross-domain NER. Additionally, we respectively combine MoCL with two distinctive cross-domain NER methods and two pre-training language models to explore its generalization ability. Empirical results on seven domains show the effectiveness and good generalization ability of MoCL.</abstract>
      <url hash="07bee3b2">2023.findings-acl.238</url>
      <bibkey>xu-etal-2023-improving</bibkey>
      <doi>10.18653/v1/2023.findings-acl.238</doi>
    </paper>
    <paper id="239">
      <title><fixed-case>SANTA</fixed-case>: Separate Strategies for Inaccurate and Incomplete Annotation Noise in Distantly-Supervised Named Entity Recognition</title>
      <author><first>Shuzheng</first><last>Si</last><affiliation>Peking University</affiliation></author>
      <author><first>Zefan</first><last>Cai</last><affiliation>Peking University</affiliation></author>
      <author><first>Shuang</first><last>Zeng</last><affiliation>Institute of Computational Linguistics, Peking University</affiliation></author>
      <author><first>Guoqiang</first><last>Feng</last><affiliation>Peking University</affiliation></author>
      <author><first>Jiaxing</first><last>Lin</last><affiliation>Peking University</affiliation></author>
      <author><first>Baobao</first><last>Chang</last><affiliation>Peking University</affiliation></author>
      <pages>3883-3896</pages>
      <abstract>Distantly-Supervised Named Entity Recognition effectively alleviates the burden of time-consuming and expensive annotation in the supervised setting. But the context-free matching process and the limited coverage of knowledge bases introduce inaccurate and incomplete annotation noise respectively. Previous studies either considered only incomplete one or indiscriminately handle two types of noise with the same strategy. In this paper, we argue that the different causes of two types of noise bring up the requirement of different strategies in model architecture. Therefore, we propose the SANTA to handle these two types of noise separately with (1) Memory-smoothed Focal Loss and Entity-aware KNN to relieve the entity ambiguity problem caused by inaccurate annotation, and (2) Boundary Mixup to alleviate decision boundary shifting problem caused by incomplete annotation and a noise-tolerant loss to improve the model’s robustness. Benefiting from our separate tailored strategies, we confirm in the experiment that the two types of noise are well mitigated.SANTA also achieves a new state-of-the-art on five public datasets.</abstract>
      <url hash="3b367de4">2023.findings-acl.239</url>
      <bibkey>si-etal-2023-santa</bibkey>
      <doi>10.18653/v1/2023.findings-acl.239</doi>
    </paper>
    <paper id="240">
      <title>The State of Profanity Obfuscation in Natural Language Processing Scientific Publications</title>
      <author><first>Debora</first><last>Nozza</last><affiliation>Bocconi University</affiliation></author>
      <author><first>Dirk</first><last>Hovy</last><affiliation>Bocconi University</affiliation></author>
      <pages>3897-3909</pages>
      <abstract>Work on hate speech has made considering rude and harmful examples in scientific publications inevitable. This situation raises various problems, such as whether or not to obscure profanities. While science must accurately disclose what it does, the unwarranted spread of hate speech can harm readers and increases its internet frequency. While maintaining publications’ professional appearance, obfuscating profanities makes it challenging to evaluate the content, especially for non-native speakers. Surveying 150 ACL papers, we discovered that obfuscation is usually used for English but not other languages, and even then, quite unevenly. We discuss the problems with obfuscation and suggest a multilingual community resource called PrOf with a Python module to standardize profanity obfuscation processes. We believe PrOf can help scientific publication policies to make hate speech work accessible and comparable, irrespective of language.</abstract>
      <url hash="29f4b0c3">2023.findings-acl.240</url>
      <bibkey>nozza-hovy-2023-state</bibkey>
      <doi>10.18653/v1/2023.findings-acl.240</doi>
    </paper>
    <paper id="241">
      <title>Teacher and Student Models of Offensive Language in Social Media</title>
      <author><first>Tharindu</first><last>Ranasinghe</last><affiliation>Aston University</affiliation></author>
      <author><first>Marcos</first><last>Zampieri</last><affiliation>George Mason University</affiliation></author>
      <pages>3910-3922</pages>
      <abstract>State-of-the-art approaches to identifying offensive language online make use of large pre-trained transformer models. However, the inference time, disk, and memory requirements of these transformer models present challenges for their wide usage in the real world. Even the distilled transformer models remain prohibitively large for many usage scenarios. To cope with these challenges, in this paper, we propose transferring knowledge from transformer models to much smaller neural models to make predictions at the token- and at the post-level. We show that this approach leads to lightweight offensive language identification models that perform on par with large transformers but with 100 times fewer parameters and much less memory usage</abstract>
      <url hash="43f3b2c7">2023.findings-acl.241</url>
      <bibkey>ranasinghe-zampieri-2023-teacher</bibkey>
      <doi>10.18653/v1/2023.findings-acl.241</doi>
    </paper>
    <paper id="242">
      <title>A Simple Yet Strong Domain-Agnostic De-bias Method for Zero-Shot Sentiment Classification</title>
      <author><first>Yang</first><last>Zhao</last><affiliation>IBM Research - Tokyo, Japan</affiliation></author>
      <author><first>Tetsuya</first><last>Nasukawa</last><affiliation>IBM Research - Tokyo</affiliation></author>
      <author><first>Masayasu</first><last>Muraoka</last><affiliation>IBM Research - Tokyo</affiliation></author>
      <author><first>Bishwaranjan</first><last>Bhattacharjee</last><affiliation>IBM T.J.Watson Researcg</affiliation></author>
      <pages>3923-3931</pages>
      <abstract>Zero-shot prompt-based learning has made much progress in sentiment analysis, and considerable effort has been dedicated to designing high-performing prompt templates. However, two problems exist; First, large language models are often biased to their pre-training data, leading to poor performance in prompt templates that models have rarely seen. Second, in order to adapt to different domains, re-designing prompt templates is usually required, which is time-consuming and inefficient. To remedy both shortcomings, we propose a simple yet strong data construction method to de-bias a given prompt template, yielding a large performance improvement in sentiment analysis tasks across different domains, pre-trained language models, and prompt templates. Also, we demonstrate the advantage of using domain-agnostic generic responses over the in-domain ground-truth data.</abstract>
      <url hash="c36983a0">2023.findings-acl.242</url>
      <bibkey>zhao-etal-2023-simple</bibkey>
      <doi>10.18653/v1/2023.findings-acl.242</doi>
    </paper>
    <paper id="243">
      <title>Balancing the Effect of Training Dataset Distribution of Multiple Styles for Multi-Style Text Transfer</title>
      <author><first>Debarati</first><last>Das</last><affiliation>University of Minnesota Twin Cities</affiliation></author>
      <author><first>David</first><last>Ma</last><affiliation>University of Minnesota</affiliation></author>
      <author><first>Dongyeop</first><last>Kang</last><affiliation>University of Minnesota</affiliation></author>
      <pages>3932-3943</pages>
      <abstract>Text style transfer is an exciting task within the field of natural language generation that is often plagued by the need for high-quality paired datasets. Furthermore, training a model for multi-attribute text style transfer requires datasets with sufficient support across all combinations of the considered stylistic attributes, adding to the challenges of training a style transfer model. This paper explores the impact of training data input diversity on the quality of the generated text from the multi-style transfer model. We construct a pseudo-parallel dataset by devising heuristics to adjust the style distribution in the training samples. We balance our training dataset using marginal and joint distributions to train our style transfer models. We observe that a balanced dataset produces more effective control effects over multiple styles than an imbalanced or skewed one. Through quantitative analysis, we explore the impact of multiple style distributions in training data on style-transferred output. These findings will better inform the design of style-transfer datasets.</abstract>
      <url hash="4e3d3990">2023.findings-acl.243</url>
      <bibkey>das-etal-2023-balancing</bibkey>
      <doi>10.18653/v1/2023.findings-acl.243</doi>
    </paper>
    <paper id="244">
      <title>A Benchmark on Extremely Weakly Supervised Text Classification: Reconcile Seed Matching and Prompting Approaches</title>
      <author><first>Zihan</first><last>Wang</last><affiliation>University of California San Diego</affiliation></author>
      <author><first>Tianle</first><last>Wang</last><affiliation>Shanghai Jiao Tong University</affiliation></author>
      <author><first>Dheeraj</first><last>Mekala</last><affiliation>University of California San Diego</affiliation></author>
      <author><first>Jingbo</first><last>Shang</last><affiliation>University of California, San Diego</affiliation></author>
      <pages>3944-3962</pages>
      <abstract>Extremely Weakly Supervised Text Classification (XWS-TC) refers to text classification based on minimal high-level human guidance, such as a few label-indicative seed words or classification instructions. There are two mainstream approaches for XWS-TC, however, never being rigorously compared: (1) training classifiers based on pseudo-labels generated by (softly) matching seed words (Seed) and (2) prompting (and calibrating) language models using classification instruction (and raw texts) to decode label words (Prompt). This paper presents the first XWS-TC benchmark to compare the two approaches on fair grounds, where the datasets, supervisions, and hyperparameter choices are standardized across methods. Our benchmarking results suggest that (1) Both Seed and Prompt approaches are competitive and there is no clear winner; (2) Seed is empirically more tolerant than Prompt to human guidance (e.g., seed words, classification instructions, and label words) changes; (3) Seed is empirically more selective than Prompt to the pre-trained language models; (4) Recent Seed and Prompt methods have close connections and a clustering post-processing step based on raw in-domain texts is a strong performance booster to both. We hope this benchmark serves as a guideline in selecting XWS-TC methods in different scenarios and stimulate interest in developing guidance- and model-robust XWS-TC methods.</abstract>
      <url hash="9c881e03">2023.findings-acl.244</url>
      <bibkey>wang-etal-2023-benchmark</bibkey>
      <doi>10.18653/v1/2023.findings-acl.244</doi>
    </paper>
    <paper id="245">
      <title>Ambiguity Meets Uncertainty: Investigating Uncertainty Estimation for Word Sense Disambiguation</title>
      <author><first>Zhu</first><last>Liu</last><affiliation>Tsinghua University</affiliation></author>
      <author><first>Ying</first><last>Liu</last><affiliation>Department of Chinese language and literature,Tsinghua University</affiliation></author>
      <pages>3963-3977</pages>
      <abstract>Word sense disambiguation (WSD), which aims to determine an appropriate sense for a target word given its context, is crucial for natural language understanding. Existing supervised methods treat WSD as a classification task and have achieved remarkable performance. However, they ignore uncertainty estimation (UE) in the real-world setting, where the data is always noisy and out of distribution. This paper extensively studies UE on the benchmark designed for WSD. Specifically, we first compare four uncertainty scores for a state-of-the-art WSD model and verify that the conventional predictive probabilities obtained at the end of the model are inadequate to quantify uncertainty. Then, we examine the capability of capturing data and model uncertainties by the model with the selected UE score on well-designed test scenarios and discover that the model reflects data uncertainty satisfactorily but underestimates model uncertainty. Furthermore, we explore numerous lexical properties that intrinsically affect data uncertainty and provide a detailed analysis of four critical aspects: the syntactic category, morphology, sense granularity, and semantic relations.</abstract>
      <url hash="3e91bf0a">2023.findings-acl.245</url>
      <bibkey>liu-liu-2023-ambiguity</bibkey>
      <doi>10.18653/v1/2023.findings-acl.245</doi>
    </paper>
    <paper id="246">
      <title>Zemi: Learning Zero-Shot Semi-Parametric Language Models from Multiple Tasks</title>
      <author><first>Zhenhailong</first><last>Wang</last><affiliation>University of Illinois at Urbana-Champaign</affiliation></author>
      <author><first>Xiaoman</first><last>Pan</last><affiliation>Tencent AI Lab</affiliation></author>
      <author><first>Dian</first><last>Yu</last><affiliation>Tencent AI Lab</affiliation></author>
      <author><first>Dong</first><last>Yu</last><affiliation>Tencent AI Lab</affiliation></author>
      <author><first>Jianshu</first><last>Chen</last><affiliation>Tencent AI Lab</affiliation></author>
      <author><first>Heng</first><last>Ji</last><affiliation>University of Illinois at Urbana-Champaign and Amazon (Amazon Scholar)</affiliation></author>
      <pages>3978-4004</pages>
      <abstract>Although large language models have exhibited impressive zero-shot ability, the huge model size generally incurs high cost. Recently, semi-parametric language models, which augment a smaller language model with retrieved related background knowledge, alleviate the need for storing everything into the model parameters. Although existing semi-parametric language models have demonstrated promising language modeling capabilities, it remains unclear whether they can exhibit competitive zero-shot abilities as their fully-parametric counterparts. In this work, we introduce Zemi, a semi-parametric language model for zero-shot task generalization. To our best knowledge, this is the first semi-parametric language model that can demonstrate strong zero-shot performance on a wide range of held-out unseen tasks. We train Zemi with semi-parametric multitask training, which shows significant improvement compared with the parametric multitask training as proposed by T0. Specifically, during both training and inference, Zemi is equipped with a retrieval system based on the unlabeled pretraining corpus of our backbone model. To address the unique challenges from large-scale retrieval, we further propose a novel retrieval-augmentation fusion module that can effectively incorporate noisy retrieved documents. Finally, we show detailed analysis and ablation studies on the key ingredients towards building effective zero-shot semi-parametric language models. Notably, our proposed Zemi_Large model outperforms T0-3B by 16% across seven diverse evaluation tasks while being 3.8x smaller in scale.</abstract>
      <url hash="2e909c81">2023.findings-acl.246</url>
      <bibkey>wang-etal-2023-zemi</bibkey>
      <doi>10.18653/v1/2023.findings-acl.246</doi>
    </paper>
    <paper id="247">
      <title>Why Can <fixed-case>GPT</fixed-case> Learn In-Context? Language Models Secretly Perform Gradient Descent as Meta-Optimizers</title>
      <author><first>Damai</first><last>Dai</last><affiliation>MOE Key Laboratory of Computational Linguistics, Peking University, China</affiliation></author>
      <author><first>Yutao</first><last>Sun</last><affiliation>Tsinghua University</affiliation></author>
      <author><first>Li</first><last>Dong</last><affiliation>Microsoft Research</affiliation></author>
      <author><first>Yaru</first><last>Hao</last><affiliation>Microsoft Research Asia</affiliation></author>
      <author><first>Shuming</first><last>Ma</last><affiliation>Microsoft Research Asia</affiliation></author>
      <author><first>Zhifang</first><last>Sui</last><affiliation>Peking University</affiliation></author>
      <author><first>Furu</first><last>Wei</last><affiliation>Microsoft Research</affiliation></author>
      <pages>4005-4019</pages>
      <abstract>Large pretrained language models have shown surprising in-context learning (ICL) ability. With a few demonstration input-label pairs, they can predict the label for an unseen input without parameter updates. Despite the great success in performance, its working mechanism still remains an open question. In this paper, we explain language models as meta-optimizers and understand in-context learning as implicit finetuning. Theoretically, we figure out that Transformer attention has a dual form of gradient descent. On top of it, we understand ICL as follows: GPT first produces meta-gradients according to the demonstration examples, and then these meta-gradients are applied to the original GPT to build an ICL model. We comprehensively compare the behaviors of in-context learning and explicit finetuning on real tasks to provide empirical evidence that supports our understanding. Experimental results show that in-context learning behaves similarly to explicit finetuning from multiple perspectives. Inspired by the dual form between Transformer attention and gradient descent, we design a momentum-based attention by analogy with gradient descent with momentum. The improved performance over vanilla attention further supports our understanding from another perspective, and more importantly, shows the potential to utilize our understanding for future model design. The code is available at <url>https://aka.ms/icl</url>.</abstract>
      <url hash="4cdc2245">2023.findings-acl.247</url>
      <bibkey>dai-etal-2023-gpt</bibkey>
      <doi>10.18653/v1/2023.findings-acl.247</doi>
    </paper>
    <paper id="248">
      <title>Dramatic Conversation Disentanglement</title>
      <author><first>Kent</first><last>Chang</last><affiliation>UC Berkeley</affiliation></author>
      <author><first>Danica</first><last>Chen</last><affiliation>University of California, Berkeley</affiliation></author>
      <author><first>David</first><last>Bamman</last><affiliation>University of California, Berkeley</affiliation></author>
      <pages>4020-4046</pages>
      <abstract>We present a new dataset for studying conversation disentanglement in movies and TV series. While previous work has focused on conversation disentanglement in IRC chatroom dialogues, movies and TV shows provide a space for studying complex pragmatic patterns of floor and topic change in face-to-face multi-party interactions. In this work, we draw on theoretical research in sociolinguistics, sociology, and film studies to operationalize a conversational thread (including the notion of a floor change) in dramatic texts, and use that definition to annotate a dataset of 10,033 dialogue turns (comprising 2,209 threads) from 831 movies. We compare the performance of several disentanglement models on this dramatic dataset, and apply the best-performing model to disentangle 808 movies. We see that, contrary to expectation, average thread lengths do not decrease significantly over the past 40 years, and characters portrayed by actors who are women, while underrepresented, initiate more new conversational threads relative to their speaking time.</abstract>
      <url hash="3169fd5f">2023.findings-acl.248</url>
      <bibkey>chang-etal-2023-dramatic</bibkey>
      <doi>10.18653/v1/2023.findings-acl.248</doi>
    </paper>
    <paper id="249">
      <title>Injecting Comparison Skills in Task-Oriented Dialogue Systems for Database Search Results Disambiguation</title>
      <author><first>Yongil</first><last>Kim</last><affiliation>Seoul National University</affiliation></author>
      <author><first>Yerin</first><last>Hwang</last><affiliation>Seoul National University</affiliation></author>
      <author><first>Joongbo</first><last>Shin</last><affiliation>LG AI Research</affiliation></author>
      <author><first>Hyunkyung</first><last>Bae</last><affiliation>LG AI Research</affiliation></author>
      <author><first>Kyomin</first><last>Jung</last><affiliation>Seoul National University</affiliation></author>
      <pages>4047-4065</pages>
      <abstract>In task-oriented dialogue (TOD) systems designed to aid users accomplish specific goals in one or more domains, the agent retrieves entities that satisfy user constraints from the database. However, when multiple database search results exist, an ambiguity occurs regarding which results to select and present to the user. Existing TOD systems handle this ambiguity by randomly selecting one or few results and presenting their names to the user. However, in a real scenario, users do not always accept a randomly recommended entity, and users should have access to more comprehensive information about the search results. To address this limitation, we propose a novel task called Comparison-Based database search Ambiguity handling (CBA), which handles ambiguity in database search results by comparing the properties of multiple entities to enable users to choose according to their preferences. Accordingly, we introduce a new framework for automatically collecting high-quality dialogue data along with the Disambiguating Schema-guided Dialogue (DSD) dataset, an augmented version of the SGD dataset. Experimental studies on the DSD dataset demonstrate that training baseline models with the dataset effectively address the CBA task. Our dataset and code will be publicized.</abstract>
      <url hash="11a7857a">2023.findings-acl.249</url>
      <bibkey>kim-etal-2023-injecting</bibkey>
      <doi>10.18653/v1/2023.findings-acl.249</doi>
    </paper>
    <paper id="250">
      <title>Emergent Modularity in Pre-trained Transformers</title>
      <author><first>Zhengyan</first><last>Zhang</last><affiliation>Tsinghua University</affiliation></author>
      <author><first>Zhiyuan</first><last>Zeng</last><affiliation>Tsinghua University</affiliation></author>
      <author><first>Yankai</first><last>Lin</last><affiliation>Gaoling School of Artificial Intelligence, Renmin University of China</affiliation></author>
      <author><first>Chaojun</first><last>Xiao</last><affiliation>Tsinghua University</affiliation></author>
      <author><first>Xiaozhi</first><last>Wang</last><affiliation>Tsinghua University</affiliation></author>
      <author><first>Xu</first><last>Han</last><affiliation>Tsinghua University</affiliation></author>
      <author><first>Zhiyuan</first><last>Liu</last><affiliation>Tsinghua University</affiliation></author>
      <author><first>Ruobing</first><last>Xie</last><affiliation>WeChat, Tencent</affiliation></author>
      <author><first>Maosong</first><last>Sun</last><affiliation>Tsinghua University</affiliation></author>
      <author><first>Jie</first><last>Zhou</last><affiliation>Tencent Inc.</affiliation></author>
      <pages>4066-4083</pages>
      <abstract>This work examines the presence of modularity in pre-trained Transformers, a feature commonly found in human brains and thought to be vital for general intelligence. In analogy to human brains, we consider two main characteristics of modularity: (1) functional specialization of neurons: we evaluate whether each neuron is mainly specialized in a certain function, and find that the answer is yes. (2) function-based neuron grouping: we explore to find a structure that groups neurons into modules by function, and each module works for its corresponding function. Given the enormous amount of possible structures, we focus on Mixture-of-Experts as a promising candidate, which partitions neurons into experts and usually activates different experts for different inputs. Experimental results show that there are functional experts, where clustered are the neurons specialized in a certain function. Moreover, perturbing the activations of functional experts significantly affects the corresponding function. Finally, we study how modularity emerges during pre-training, and find that the modular structure is stabilized at the early stage, which is faster than neuron stabilization. It suggests that Transformer first constructs the modular structure and then learns fine-grained neuron functions. Our code and data are available at <url>https://github.com/THUNLP/modularity-analysis</url>.</abstract>
      <url hash="27308aab">2023.findings-acl.250</url>
      <bibkey>zhang-etal-2023-emergent</bibkey>
      <doi>10.18653/v1/2023.findings-acl.250</doi>
    </paper>
    <paper id="251">
      <title>Universal Information Extraction with Meta-Pretrained Self-Retrieval</title>
      <author><first>Xin</first><last>Cong</last><affiliation>Institute of Information Engineering, CAS</affiliation></author>
      <author><first>Bowen</first><last>Yu</last><affiliation>DAMO Academy, Alibaba Group</affiliation></author>
      <author><first>Mengcheng</first><last>Fang</last><affiliation>Zhejiang University</affiliation></author>
      <author><first>Tingwen</first><last>Liu</last><affiliation>Institute of Information Engineering, Chinese Academy of Sciences</affiliation></author>
      <author><first>Haiyang</first><last>Yu</last><affiliation>Allibaba Group</affiliation></author>
      <author><first>Zhongkai</first><last>Hu</last><affiliation>Alibaba Group</affiliation></author>
      <author><first>Fei</first><last>Huang</last><affiliation>Alibaba DAMO Academy</affiliation></author>
      <author><first>Yongbin</first><last>Li</last><affiliation>Alibaba Group</affiliation></author>
      <author><first>Bin</first><last>Wang</last><affiliation>Xiaomi AI Lab</affiliation></author>
      <pages>4084-4100</pages>
      <abstract>Universal Information Extraction (Universal IE) aims to solve different extraction tasks in a uniform text-to-structure generation manner. Such a generation procedure tends to struggle when there exist complex information structures to be extracted. Retrieving knowledge from external knowledge bases may help models to overcome this problem but it is impossible to construct a knowledge base suitable for various IE tasks. Inspired by the fact that large amount of knowledge are stored in the pretrained language models (PLM) and can be retrieved explicitly, in this paper, we propose MetaRetriever to retrieve task-specific knowledge from PLMs to enhance universal IE. As different IE tasks need different knowledge, we further propose a Meta-Pretraining Algorithm which allows MetaRetriever to quicktly achieve maximum task-specific retrieval performance when fine-tuning on downstream IE tasks. Experimental results show that MetaRetriever achieves the new state-of-the-art on 4 IE tasks, 12 datasets under fully-supervised, low-resource and few-shot scenarios.</abstract>
      <url hash="783fbdaf">2023.findings-acl.251</url>
      <bibkey>cong-etal-2023-universal</bibkey>
      <doi>10.18653/v1/2023.findings-acl.251</doi>
    </paper>
    <paper id="252">
      <title><fixed-case>SETI</fixed-case>: Systematicity Evaluation of Textual Inference</title>
      <author><first>Xiyan</first><last>Fu</last><affiliation>Heidelberg University</affiliation></author>
      <author><first>Anette</first><last>Frank</last><affiliation>Heidelberg University</affiliation></author>
      <pages>4101-4114</pages>
      <abstract>We propose SETI (Systematicity Evaluation of Textual Inference), a novel and comprehensive benchmark designed for evaluating pre-trained language models (PLMs) for their systematicity capabilities in the domain of textual inference. Specifically, SETI offers three different NLI tasks and corresponding datasets to evaluate various types of systematicity in reasoning processes. In order to solve these tasks, models are required to perform compositional inference based on known primitive constituents. We conduct experiments of SETI on six widely used PLMs. Results show that various PLMs are able to solve unseen compositional inferences when having encountered the knowledge of how to combine primitives, with good performance. However, they are considerably limited when this knowledge is unknown to the model (40-100 % points decrease). Furthermore, we find that PLMs are able to improve dramatically once exposed to crucial compositional knowledge in minimalistic shots. These findings position SETI as the first benchmark for measuring the future progress of PLMs in achieving systematicity generalization in the textual inference.</abstract>
      <url hash="6968f24f">2023.findings-acl.252</url>
      <bibkey>fu-frank-2023-seti</bibkey>
      <doi>10.18653/v1/2023.findings-acl.252</doi>
    </paper>
    <paper id="253">
      <title>Coarse-to-fine Few-shot Learning for Named Entity Recognition</title>
      <author><first>Ruotian</first><last>Ma</last><affiliation>Fudan University</affiliation></author>
      <author><first>Zhang</first><last>Lin</last><affiliation>13765304537</affiliation></author>
      <author><first>Xuanting</first><last>Chen</last><affiliation>fudan university</affiliation></author>
      <author><first>Xin</first><last>Zhou</last><affiliation>Fudan University</affiliation></author>
      <author><first>Junzhe</first><last>Wang</last><affiliation>Fudan University</affiliation></author>
      <author><first>Tao</first><last>Gui</last><affiliation>fudan university</affiliation></author>
      <author><first>Qi</first><last>Zhang</last><affiliation>Fudan University</affiliation></author>
      <author><first>Xiang</first><last>Gao</last><affiliation>DataGrand Inc.</affiliation></author>
      <author><first>Yun Wen</first><last>Chen</last><affiliation>DataGrand Inc.</affiliation></author>
      <pages>4115-4129</pages>
      <abstract>Recently, Few-shot Named Entity Recognition has received wide attention with the growing need for NER models to learn new classes with minimized annotation costs. However, one common yet understudied situation is to transfer a model trained with coarse-grained classes to recognize fine-grained classes, such as separating a product category into sub-classes. We find that existing few-shot NER solutions are not suitable for such a situation since they do not consider the sub-class discrimination during coarse training and various granularity of new classes during few-shot learning. In this work, we introduce the Coarse-to-fine Few-shot NER (C2FNER) task and propose an effective solution. Specifically, during coarse training, we propose a cluster-based prototype margin loss to learn group-wise discriminative representations, so as to benefit fine-grained learning. Targeting various granularity of new classes, we separate the coarse classes into extra-fine clusters and propose a novel prototype retrieval and bootstrapping algorithm to retrieve representative clusters for each fine class. We then adopt a mixture prototype loss to efficiently learn the representations of fine classes. We conduct experiments on both in-domain and cross-domain C2FNER settings with various target granularity, and the proposed method shows superior performance over the baseline methods.</abstract>
      <url hash="90bb44f5">2023.findings-acl.253</url>
      <bibkey>ma-etal-2023-coarse</bibkey>
      <doi>10.18653/v1/2023.findings-acl.253</doi>
    </paper>
    <paper id="254">
      <title>Self-Evolution Learning for Discriminative Language Model Pretraining</title>
      <author><first>Qihuang</first><last>Zhong</last><affiliation>Wuhan University</affiliation></author>
      <author><first>Liang</first><last>Ding</last><affiliation>JD Explore Academy, JD.com Inc. &amp; The University of Sydney</affiliation></author>
      <author><first>Juhua</first><last>Liu</last><affiliation>Wuhan University</affiliation></author>
      <author><first>Bo</first><last>Du</last><affiliation>Wuhan University</affiliation></author>
      <author><first>Dacheng</first><last>Tao</last><affiliation>School of Computer Science, The University of Sydney</affiliation></author>
      <pages>4130-4145</pages>
      <abstract>Masked language modeling, widely used in discriminative language model (e.g., BERT) pretraining, commonly adopts a random masking strategy. However, random masking does not consider the importance of the different words in the sentence meaning, where some of them are more worthy to be predicted. Therefore, various masking strategies (e.g., entity-level masking) are proposed, but most of them require expensive prior knowledge and generally train from scratch without reusing existing model weights. In this paper, we present Self-Evolution learning (SE), a simple and effective token masking and learning method to fully and wisely exploit the knowledge from data. SE focuses on learning the informative yet under-explored tokens and adaptively regularizes the training by introducing a novel Token-specific Label Smoothing approach. Experiments on 10 tasks show that our SE brings consistent and significant improvements (+1.43 2.12 average scores) upon different PLMs. In-depth analyses demonstrate that SE improves linguistic knowledge learning and generalization.</abstract>
      <url hash="4c7b1292">2023.findings-acl.254</url>
      <bibkey>zhong-etal-2023-self</bibkey>
      <doi>10.18653/v1/2023.findings-acl.254</doi>
    </paper>
    <paper id="255">
      <title><fixed-case>Q</fixed-case>uery<fixed-case>F</fixed-case>orm: A Simple Zero-shot Form Entity Query Framework</title>
      <author><first>Zifeng</first><last>Wang</last><affiliation>Northeastern University</affiliation></author>
      <author><first>Zizhao</first><last>Zhang</last><affiliation>Google</affiliation></author>
      <author><first>Jacob</first><last>Devlin</last><affiliation>Google</affiliation></author>
      <author><first>Chen-Yu</first><last>Lee</last><affiliation>Google</affiliation></author>
      <author><first>Guolong</first><last>Su</last><affiliation>Google</affiliation></author>
      <author><first>Hao</first><last>Zhang</last><affiliation>Google Research</affiliation></author>
      <author><first>Jennifer</first><last>Dy</last><affiliation>Northeastern University</affiliation></author>
      <author><first>Vincent</first><last>Perot</last><affiliation>Google AI</affiliation></author>
      <author><first>Tomas</first><last>Pfister</last><affiliation>Google Inc.</affiliation></author>
      <pages>4146-4159</pages>
      <abstract>Zero-shot transfer learning for document understanding is a crucial yet under-investigated scenario to help reduce the high cost involved in annotating document entities. We present a novel query-based framework, QueryForm, that extracts entity values from form-like documents in a zero-shot fashion. QueryForm contains a dual prompting mechanism that composes both the document schema and a specific entity type into a query, which is used to prompt a Transformer model to perform a single entity extraction task. Furthermore, we propose to leverage large-scale query-entity pairs generated from form-like webpages with weak HTML annotations to pre-train QueryForm. By unifying pre-training and fine-tuning into the same query-based framework, QueryForm enables models to learn from structured documents containing various entities and layouts, leading to better generalization to target document types without the need for target-specific training data. QueryForm sets new state-of-the-art average F1 score on both the XFUND (+4.6% 10.1%) and the Payment (+3.2% 9.5%) zero-shot benchmark, with a smaller model size and no additional image input.</abstract>
      <url hash="f35bdad7">2023.findings-acl.255</url>
      <bibkey>wang-etal-2023-queryform</bibkey>
      <doi>10.18653/v1/2023.findings-acl.255</doi>
    </paper>
    <paper id="256">
      <title>Search-Oriented Conversational Query Editing</title>
      <author><first>Kelong</first><last>Mao</last><affiliation>Gaoling School of Artificial Intelligence, Renmin University of China</affiliation></author>
      <author><first>Zhicheng</first><last>Dou</last><affiliation>Renmin University of China</affiliation></author>
      <author><first>Bang</first><last>Liu</last><affiliation>University of Montreal</affiliation></author>
      <author><first>Hongjin</first><last>Qian</last><affiliation>Renmin University of China</affiliation></author>
      <author><first>Fengran</first><last>Mo</last><affiliation>Universite de Montreal</affiliation></author>
      <author><first>Xiangli</first><last>Wu</last><affiliation>Huawei Poisson Lab</affiliation></author>
      <author><first>Xiaohua</first><last>Cheng</last><affiliation>Huawei Poisson Lab</affiliation></author>
      <author><first>Zhao</first><last>Cao</last><affiliation>Huawei</affiliation></author>
      <pages>4160-4172</pages>
      <abstract>Conversational query rewriting (CQR) realizes conversational search by reformulating the search dialogue into a standalone rewrite. However, existing CQR models either are not learned toward improving the downstream search performance or inefficiently generate the rewrite token-by-token from scratch while neglecting the fact that the search dialogue often has a large overlap with the rewrite. In this paper, we propose EdiRCS, a new text editing-based CQR model tailored for conversational search. In EdiRCS, most of the rewrite tokens are selected from the dialogue in a non-autoregressive fashion and only a few new tokens are generated to supplement the final rewrite, which makes EdiRCS highly efficient. In particular, the learning of EdiRCS is augmented with two search-oriented objectives, including contrastive ranking augmentation and contextualization knowledge transfer, which effectively improve it to select and generate more useful tokens from the view of retrieval. We show that EdiRCS outperforms state-of-the-art CQR models on three conversational search benchmarks while having low rewriting latency, and is robust to out-of-domain search dialogues and long dialogue contexts.</abstract>
      <url hash="fa3de088">2023.findings-acl.256</url>
      <bibkey>mao-etal-2023-search</bibkey>
      <doi>10.18653/v1/2023.findings-acl.256</doi>
    </paper>
    <paper id="257">
      <title><fixed-case>TAPIR</fixed-case>: Learning Adaptive Revision for Incremental Natural Language Understanding with a Two-Pass Model</title>
      <author><first>Patrick</first><last>Kahardipraja</last><affiliation>University of Potsdam</affiliation></author>
      <author><first>Brielen</first><last>Madureira</last><affiliation>University of Potsdam</affiliation></author>
      <author><first>David</first><last>Schlangen</last><affiliation>University of Potsdam</affiliation></author>
      <pages>4173-4197</pages>
      <abstract>Language is by its very nature incremental in how it is produced and processed. This property can be exploited by NLP systems to produce fast responses, which has been shown to be beneficial for real-time interactive applications. Recent neural network-based approaches for incremental processing mainly use RNNs or Transformers. RNNs are fast but monotonic (cannot correct earlier output, which can be necessary in incremental processing). Transformers, on the other hand, consume whole sequences, and hence are by nature non-incremental. A restart-incremental interface that repeatedly passes longer input prefixes can be used to obtain partial outputs, while providing the ability to revise. However, this method becomes costly as the sentence grows longer. In this work, we propose the Two-pass model for AdaPtIve Revision (TAPIR) and introduce a method to obtain an incremental supervision signal for learning an adaptive revision policy. Experimental results on sequence labelling show that our model has better incremental performance and faster inference speed compared to restart-incremental Transformers, while showing little degradation on full sequences.</abstract>
      <url hash="3071b888">2023.findings-acl.257</url>
      <bibkey>kahardipraja-etal-2023-tapir</bibkey>
      <doi>10.18653/v1/2023.findings-acl.257</doi>
    </paper>
    <paper id="258">
      <title>Speaking the Language of Your Listener: Audience-Aware Adaptation via Plug-and-Play Theory of Mind</title>
      <author><first>Ece</first><last>Takmaz</last><affiliation>University of Amsterdam</affiliation></author>
      <author><first>Nicolo’</first><last>Brandizzi</last><affiliation>Sapienza University of Rome</affiliation></author>
      <author><first>Mario</first><last>Giulianelli</last><affiliation>University of Amsterdam</affiliation></author>
      <author><first>Sandro</first><last>Pezzelle</last><affiliation>University of Amsterdam</affiliation></author>
      <author><first>Raquel</first><last>Fernandez</last><affiliation>ILLC, University of Amsterdam</affiliation></author>
      <pages>4198-4217</pages>
      <abstract>Dialogue participants may have varying levels of knowledge about the topic under discussion. In such cases, it is essential for speakers to adapt their utterances by taking their audience into account. Yet, it is an open question how such adaptation can be modelled in computational agents. In this paper, we model a visually grounded referential game between a knowledgeable speaker and a listener with more limited visual and linguistic experience. Inspired by psycholinguistic theories, we endow our speaker with the ability to adapt its referring expressions via a simulation module that monitors the effectiveness of planned utterances from the listener’s perspective. We propose an adaptation mechanism building on plug-and-play approaches to controlled language generation, where utterance generation is steered on the fly by the simulator without finetuning the speaker’s underlying language model. Our results and analyses show that our approach is effective: the speaker’s utterances become closer to the listener’s domain of expertise, which leads to higher communicative success.</abstract>
      <url hash="d4f85d5e">2023.findings-acl.258</url>
      <bibkey>takmaz-etal-2023-speaking</bibkey>
      <doi>10.18653/v1/2023.findings-acl.258</doi>
    </paper>
    <paper id="259">
      <title>A Semi-Autoregressive Graph Generative Model for Dependency Graph Parsing</title>
      <author><first>Ye</first><last>Ma</last><affiliation>Hithink RoyalFlush Information Network Co.,Ltd.</affiliation></author>
      <author><first>Mingming</first><last>Sun</last><affiliation>Baidu Research</affiliation></author>
      <author><first>Ping</first><last>Li</last><affiliation>LinkedIn</affiliation></author>
      <pages>4218-4230</pages>
      <abstract>Recent years have witnessed the impressive progress in Neural Dependency Parsing. According to the different factorization approaches to the graph joint probabilities, existing parsers can be roughly divided into autoregressive and non-autoregressive patterns. The former means that the graph should be factorized into multiple sequentially dependent components, then it can be built up component by component. And the latter assumes these components to be independent so that they can be outputted in a one-shot manner. However, when treating the directed edge as an explicit dependency relationship, we discover that there is a mixture of independent and interdependent components in the dependency graph, signifying that both aforementioned models fail to precisely capture the explicit dependencies among nodes and edges. Based on this property, we design a Semi-Autoregressive Dependency Parser to generate dependency graphs via adding node groups and edge groups autoregressively while pouring out all group elements in parallel. The model gains a trade-off between non-autoregression and autoregression, which respectively suffer from the lack of target inter-dependencies and the uncertainty of graph generation orders. The experiments show the proposed parser outperforms strong baselines on Enhanced Universal Dependencies of multiple languages, especially achieving 4% average promotion at graph-level accuracy. Also, the performances of model variations show the importance of specific parts.</abstract>
      <url hash="34d87d4c">2023.findings-acl.259</url>
      <bibkey>ma-etal-2023-semi</bibkey>
      <doi>10.18653/v1/2023.findings-acl.259</doi>
    </paper>
    <paper id="260">
      <title><fixed-case>AMR</fixed-case>-<fixed-case>TST</fixed-case>: <fixed-case>A</fixed-case>bstract <fixed-case>M</fixed-case>eaning <fixed-case>R</fixed-case>epresentation-based Text Style Transfer</title>
      <author><first>Kaize</first><last>Shi</last><affiliation>University of Technology Sydney</affiliation></author>
      <author><first>Xueyao</first><last>Sun</last><affiliation>The Hong Kong Polytechnic University</affiliation></author>
      <author><first>Li</first><last>He</last><affiliation>university of technology sydney</affiliation></author>
      <author><first>Dingxian</first><last>Wang</last><affiliation>Etsy</affiliation></author>
      <author><first>Qing</first><last>Li</last><affiliation>the Hong Kong Polytechnic University</affiliation></author>
      <author><first>Guandong</first><last>Xu</last><affiliation>University of Technology, Sydney</affiliation></author>
      <pages>4231-4243</pages>
      <abstract>Abstract Meaning Representation (AMR) is a semantic representation that can enhance natural language generation (NLG) by providing a logical semantic input. In this paper, we propose the AMR-TST, an AMR-based text style transfer (TST) technique. The AMR-TST converts the source text to an AMR graph and generates the transferred text based on the AMR graph modified by a TST policy named style rewriting. Our method combines both the explainability and diversity of explicit and implicit TST methods. The experiments show that the proposed method achieves state-of-the-art results compared with other baseline models in automatic and human evaluations. The generated transferred text in qualitative evaluation proves the AMR-TST have significant advantages in keeping semantic features and reducing hallucinations. To the best of our knowledge, this work is the first to apply the AMR method focusing on node-level features to the TST task.</abstract>
      <url hash="efa1c746">2023.findings-acl.260</url>
      <bibkey>shi-etal-2023-amr</bibkey>
      <doi>10.18653/v1/2023.findings-acl.260</doi>
    </paper>
    <paper id="261">
      <title>Understanding the Cooking Process with <fixed-case>E</fixed-case>nglish Recipe Text</title>
      <author><first>Yi</first><last>Fan</last><affiliation>Heidelberg Institute for Theoretical Studies</affiliation></author>
      <author><first>Anthony</first><last>Hunter</last><affiliation>University College London</affiliation></author>
      <pages>4244-4264</pages>
      <abstract>Translating procedural text, like recipes, into a graphical representation can be important for visualizing the text, and can offer a machine-readable formalism for use in software. There are proposals for translating recipes into a flow graph representation, where each node represents an ingredient, action, location, or equipment, and each arc between the nodes denotes the steps of the recipe. However, these proposals have had performance problems with both named entity recognition and relationship extraction. To address these problems, we propose a novel framework comprising two modules to construct a flow graph from the input recipe. The first module identifies the named entities in the input recipe text using BERT, Bi-LSTM and CRF, and the second module uses BERT to predict the relationships between the entities. We evaluate our framework on the English recipe flow graph corpus. Our framework can predict the edge label and achieve the overall F1 score of 92.2, while the baseline F1 score is 43.3 without the edge label predicted.</abstract>
      <url hash="a3693eaf">2023.findings-acl.261</url>
      <bibkey>fan-hunter-2023-understanding</bibkey>
      <doi>10.18653/v1/2023.findings-acl.261</doi>
    </paper>
    <paper id="262">
      <title>Follow the Wisdom of the Crowd: Effective Text Generation via Minimum <fixed-case>B</fixed-case>ayes Risk Decoding</title>
      <author><first>Mirac</first><last>Suzgun</last><affiliation>Stanford University</affiliation></author>
      <author><first>Luke</first><last>Melas-Kyriazi</last><affiliation>Harvard University</affiliation></author>
      <author><first>Dan</first><last>Jurafsky</last><affiliation>Stanford University</affiliation></author>
      <pages>4265-4293</pages>
      <abstract>In open-ended natural-language generation, existing text decoding methods typically struggle to produce text which is both diverse and high-quality. Greedy and beam search are known to suffer from text degeneration and linguistic diversity issues, while temperature, top-k, and nucleus sampling yield diverse but often lower-quality outputs. In this work, we build upon Minimum Bayes Risk Decoding (MBRD), a family of decoding methods based on Bayesian risk minimization, to address this diversity-quality trade-off. Inspired by the principle of the wisdom of the crowd, MBRD seeks to select a candidate from a pool of candidates that has the least expected risk under a generative model according to a given utility function. The crowd of candidates serves as an approximation for the distribution over human-generated references. We show that MBRD generalizes numerous decoding methods, including majority voting, and can be used as a drop-in replacement for existing sampling methods. Across a wide range of tasks—such as summarization, data-to-text, translation, and textual style transfer—MBRD yields 3-7 ROUGE and BLEU point improvements, including state-of-the-art results on WebNLG and WMT’16.</abstract>
      <url hash="512c9f28">2023.findings-acl.262</url>
      <bibkey>suzgun-etal-2023-follow</bibkey>
      <doi>10.18653/v1/2023.findings-acl.262</doi>
    </paper>
    <paper id="263">
      <title><fixed-case>R</fixed-case>obust<fixed-case>QA</fixed-case>: Benchmarking the Robustness of Domain Adaptation for Open-Domain Question Answering</title>
      <author><first>Rujun</first><last>Han</last><affiliation>Amazon</affiliation></author>
      <author><first>Peng</first><last>Qi</last><affiliation>AWS AI Labs</affiliation></author>
      <author><first>Yuhao</first><last>Zhang</last><affiliation>Amazon AWS AI</affiliation></author>
      <author><first>Lan</first><last>Liu</last><affiliation>Amazon</affiliation></author>
      <author><first>Juliette</first><last>Burger</last><affiliation>Amazon</affiliation></author>
      <author><first>William Yang</first><last>Wang</last><affiliation>Unversity of California, Santa Barbara</affiliation></author>
      <author><first>Zhiheng</first><last>Huang</last><affiliation>Amazon AI</affiliation></author>
      <author><first>Bing</first><last>Xiang</last><affiliation>Amazon</affiliation></author>
      <author><first>Dan</first><last>Roth</last><affiliation>University of Pennsylvania</affiliation></author>
      <pages>4294-4311</pages>
      <abstract>Open-domain question answering (ODQA) is a crucial task in natural language processing. A typical ODQA system relies on a retriever module to select relevant contexts from a large corpus for a downstream reading comprehension model. Existing ODQA datasets consist mainly of Wikipedia corpus, and are insufficient to study models’ generalizability across diverse domains as models are trained and evaluated on the same genre of data. We propose **RobustQA**, a novel benchmark consisting of datasets from 8 different domains, which facilitates the evaluation of ODQA’s domain robustness. To build **RobustQA**, we annotate QA pairs in retrieval datasets with rigorous quality control. We further examine improving QA performances by incorporating unsupervised learning methods with target-domain corpus and adopting large generative language models. These methods can effectively improve model performances on **RobustQA**. However, experimental results demonstrate a significant gap from in-domain training, suggesting that **RobustQA** is a challenging benchmark to evaluate ODQA domain robustness.</abstract>
      <url hash="0fcf2387">2023.findings-acl.263</url>
      <bibkey>han-etal-2023-robustqa</bibkey>
      <doi>10.18653/v1/2023.findings-acl.263</doi>
    </paper>
    <paper id="264">
      <title><fixed-case>S</fixed-case>ente<fixed-case>C</fixed-case>on: Leveraging Lexicons to Learn Human-Interpretable Language Representations</title>
      <author><first>Victoria</first><last>Lin</last><affiliation>Carnegie Mellon University</affiliation></author>
      <author><first>Louis-Philippe</first><last>Morency</last><affiliation>Carnegie Mellon University</affiliation></author>
      <pages>4312-4331</pages>
      <abstract>Although deep language representations have become the dominant form of language featurization in recent years, in many settings it is important to understand a model’s decision-making process. This necessitates not only an interpretable model but also interpretable features. In particular, language must be featurized in a way that is interpretable while still characterizing the original text well. We present SenteCon, a method for introducing human interpretability in deep language representations. Given a passage of text, SenteCon encodes the text as a layer of interpretable categories in which each dimension corresponds to the relevance of a specific category. Our empirical evaluations indicate that encoding language with SenteCon provides high-level interpretability at little to no cost to predictive performance on downstream tasks. Moreover, we find that SenteCon outperforms existing interpretable language representations with respect to both its downstream performance and its agreement with human characterizations of the text.</abstract>
      <url hash="d3486b14">2023.findings-acl.264</url>
      <bibkey>lin-morency-2023-sentecon</bibkey>
      <doi>10.18653/v1/2023.findings-acl.264</doi>
    </paper>
    <paper id="265">
      <title>Reinforcement Learning for Topic Models</title>
      <author><first>Jeremy</first><last>Costello</last><affiliation>University of Alberta</affiliation></author>
      <author><first>Marek</first><last>Reformat</last><affiliation>University of Alberta</affiliation></author>
      <pages>4332-4351</pages>
      <abstract>We apply reinforcement learning techniques to topic modeling by replacing the variational autoencoder in ProdLDA with a continuous action space reinforcement learning policy. We train the system with a policy gradient algorithm REINFORCE. Additionally, we introduced several modifications: modernize the neural network architecture, weight the ELBO loss, use contextual embeddings, and monitor the learning process via computing topic diversity and coherence for each training step. Experiments areperformed on 11 data sets. Our unsupervised model outperforms all other unsupervised models and performs on par with or better than most models using supervised labeling. Our model is outperformed on certain data sets by a model using supervised labeling and contrastive learning. We have also conducted an ablation study to provide empirical evidence of performance improvements from changes we made to ProdLDA and found that the reinforcement learning formulation boosts performance. We open-source our code implementation.</abstract>
      <url hash="62a0a402">2023.findings-acl.265</url>
      <bibkey>costello-reformat-2023-reinforcement</bibkey>
      <doi>10.18653/v1/2023.findings-acl.265</doi>
    </paper>
    <paper id="266">
      <title>Contextualized Soft Prompts for Extraction of Event Arguments</title>
      <author><first>Chien</first><last>Nguyen</last><affiliation>VinAI Research, Vietnam</affiliation></author>
      <author><first>Hieu</first><last>Man</last><affiliation>VinAi Research</affiliation></author>
      <author><first>Thien</first><last>Nguyen</last><affiliation>University of Oregon</affiliation></author>
      <pages>4352-4361</pages>
      <abstract>Event argument extraction (EAE) is a sub-task of event extraction where the goal is to identify roles of entity mentions for events in text. The current state-of-the-art approaches for this problem explore prompt-based methods to prompt pre-trained language models for arguments over input context. However, existing prompt-based methods mainly rely on discrete and manually-designed prompts that cannot exploit specific context for each example to improve customization for optimal performance. In addition, the discrete nature of current prompts prevents the incorporation of relevant context from multiple external documents to enrich prompts for EAE. To this end, we propose a novel prompt-based method for EAE that introduces soft prompts to facilitate the encoding of individual example context and multiple relevant documents to boost EAE. We extensively evaluate the proposed method on benchmark datasets for EAE to demonstrate its benefits with state-of-the-art performance.</abstract>
      <url hash="e5453ea4">2023.findings-acl.266</url>
      <bibkey>nguyen-etal-2023-contextualized</bibkey>
      <doi>10.18653/v1/2023.findings-acl.266</doi>
    </paper>
    <paper id="267">
      <title><fixed-case>T</fixed-case>ext<fixed-case>V</fixed-case>erifier: Robustness Verification for Textual Classifiers with Certifiable Guarantees</title>
      <author><first>Siqi</first><last>Sun</last><affiliation>University of Liverpool</affiliation></author>
      <author><first>Wenjie</first><last>Ruan</last><affiliation>University of Exeter</affiliation></author>
      <pages>4362-4380</pages>
      <abstract>When textual classifiers are deployed in safety-critical workflows, they must withstand the onslaught of AI-enabled model confusion caused by adversarial examples with minor alterations. In this paper, the main objective is to provide a formal verification framework, called TextVerifier, with certifiable guarantees on deep neural networks in natural language processing against word-level alteration attacks. We aim to provide an approximation of the maximal safe radius by deriving provable bounds both mathematically and automatically, where a minimum word-level L_0 distance is quantified as a guarantee for the classification invariance of victim models. Here, we illustrate three strengths of our strategy: i) certifiable guarantee: effective verification with convergence to ensure approximation of maximal safe radius with tight bounds ultimately; ii) high-efficiency: it yields an efficient speed edge by a novel parallelization strategy that can process a set of candidate texts simultaneously on GPUs; and iii) reliable anytime estimation: the verification can return intermediate bounds, and robustness estimates that are gradually, but strictly, improved as the computation proceeds. Furthermore, experiments are conducted on text classification on four datasets over three victim models to demonstrate the validity of tightening bounds. Our tool TextVerifier is available at <url>https://github.com/TrustAI/TextVerifer</url>.</abstract>
      <url hash="86f2acab">2023.findings-acl.267</url>
      <bibkey>sun-ruan-2023-textverifier</bibkey>
      <doi>10.18653/v1/2023.findings-acl.267</doi>
    </paper>
    <paper id="268">
      <title><fixed-case>OAS</fixed-case>um: Large-Scale Open Domain Aspect-based Summarization</title>
      <author><first>Xianjun</first><last>Yang</last><affiliation>University of California, Santa Barbara</affiliation></author>
      <author><first>Kaiqiang</first><last>Song</last><affiliation>Tencent AI Lab</affiliation></author>
      <author><first>Sangwoo</first><last>Cho</last><affiliation>Tecent AI Lab</affiliation></author>
      <author><first>Xiaoyang</first><last>Wang</last><affiliation>Tencent AI Lab</affiliation></author>
      <author><first>Xiaoman</first><last>Pan</last><affiliation>Tencent AI Lab</affiliation></author>
      <author><first>Linda</first><last>Petzold</last><affiliation>UC Santa Barbara</affiliation></author>
      <author><first>Dong</first><last>Yu</last><affiliation>Tencent AI Lab</affiliation></author>
      <pages>4381-4401</pages>
      <abstract>Aspect or query-based summarization has recently caught more attention, as it can generate differentiated summaries based on users’ interests. However, the current dataset for aspect or query-based summarization either focuses on specific domains, on a relatively small scale, or contains only a few aspect types. Such limitations hinder further explorations in this direction. In this work, we take advantage of crowd-sourcing knowledge on Wikipedia and automatically create a high-quality, large-scale open-domain aspect-based summarization dataset named OASum, which contains more than 3.7 million instances with around 1 million different aspects on 2 million Wikipedia pages. We provide benchmark results on OASum and demonstrate its ability for diverse aspect-based summarization generation. To overcome the data scarcity problem on specific domains, we also perform zero-shot, few-shot, and fine-tuning on seven downstream datasets. Specifically, zero/few-shot and fine-tuning results show that the model pre-trained on our corpus demonstrates a strong aspect or query-focused generation ability compared with the backbone model. Our dataset and pre-trained checkpoints are publicly available.</abstract>
      <url hash="03358834">2023.findings-acl.268</url>
      <bibkey>yang-etal-2023-oasum</bibkey>
      <doi>10.18653/v1/2023.findings-acl.268</doi>
    </paper>
    <paper id="269">
      <title>On the Limitations of Simulating Active Learning</title>
      <author><first>Katerina</first><last>Margatina</last><affiliation>University of Sheffield</affiliation></author>
      <author><first>Nikolaos</first><last>Aletras</last><affiliation>University of Sheffield</affiliation></author>
      <pages>4402-4419</pages>
      <abstract>Active learning (AL) is a human-and-model-in-the-loop paradigm that iteratively selects informative unlabeled data for human annotation, aiming to improve data efficiency over random sampling. However, performing AL experiments with human annotations on-the-fly is a laborious and expensive process, thus unrealistic for academic research. An easy fix to this impediment is to simulate AL, by treating an already labeled and publicly available dataset as the pool of unlabeled data. In this position paper, we first survey recent literature and highlight the challenges across all different steps within the AL loop. We further unveil neglected caveats in the experimental setup that can significantly affect the quality of AL research. We continue with an exploration of how the simulation setting can govern empirical findings, arguing that it might be one of the answers behind the ever posed question “Why do Active Learning algorithms sometimes fail to outperform random sampling?”. We argue that evaluating AL algorithms on available labeled datasets might provide a lower bound as to their effectiveness in real data. We believe it is essential to collectively shape the best practices for AL research, especially now that the stellar engineering advances (e.g. ChatGPT) shift the research focus to data-driven approaches. To this end, we present guidelines for future work, hoping that by bringing these limitations to the community’s attention, we can explore ways to address them.</abstract>
      <url hash="06e175c5">2023.findings-acl.269</url>
      <bibkey>margatina-aletras-2023-limitations</bibkey>
      <doi>10.18653/v1/2023.findings-acl.269</doi>
    </paper>
    <paper id="270">
      <title>Towards Alleviating the Object Bias in Prompt Tuning-based Factual Knowledge Extraction</title>
      <author><first>Yuhang</first><last>Wang</last><affiliation>Beijing Jiaotong University</affiliation></author>
      <author><first>Dongyuan</first><last>Lu</last><affiliation>University of International Business and Economics</affiliation></author>
      <author><first>Chao</first><last>Kong</last><affiliation>BeijingJiaoTong University</affiliation></author>
      <author><first>Jitao</first><last>Sang</last><affiliation>BJTU</affiliation></author>
      <pages>4420-4432</pages>
      <abstract>Many works employed prompt tuning methods to automatically optimize prompt queries and extract the factual knowledge stored in Pre-trained Language Models. In this paper, we observe that the optimized prompts, including discrete prompts and continuous prompts, exhibit undesirable object bias. To handle this problem, we propose a novel prompt tuning method called MeCoD consisting of three modules: Prompt Encoder, Object Equalization and Biased Object Obstruction. Experimental results show that MeCoD can significantly reduce the object bias and at the same time improve accuracy of factual knowledge extraction.</abstract>
      <url hash="0dc2aa40">2023.findings-acl.270</url>
      <bibkey>wang-etal-2023-towards-alleviating</bibkey>
      <doi>10.18653/v1/2023.findings-acl.270</doi>
    </paper>
    <paper id="271">
      <title>v<fixed-case>ONTSS</fixed-case>: v<fixed-case>MF</fixed-case> based semi-supervised neural topic modeling with optimal transport</title>
      <author><first>Weijie</first><last>Xu</last><affiliation>Amazon</affiliation></author>
      <author><first>Xiaoyu</first><last>Jiang</last><affiliation>Snap</affiliation></author>
      <author><first>Srinivasan</first><last>Sengamedu Hanumantha Rao</last><affiliation>Amazon</affiliation></author>
      <author><first>Francis</first><last>Iannacci</last><affiliation>Amazon</affiliation></author>
      <author><first>Jinjin</first><last>Zhao</last><affiliation>Amazon</affiliation></author>
      <pages>4433-4457</pages>
      <abstract>Recently, Neural Topic Models (NTM), inspired by variational autoencoders, have attracted a lot of research interest; however, these methods have limited applications in the real world due to the challenge of incorporating human knowledge. This work presents a semi-supervised neural topic modeling method, vONTSS, which uses von Mises-Fisher (vMF) based variational autoencoders and optimal transport. When a few keywords per topic are provided, vONTSS in the semi-supervised setting generates potential topics and optimizes topic-keyword quality and topic classification. Experiments show that vONTSS outperforms existing semi-supervised topic modeling methods in classification accuracy and diversity. vONTSS also supports unsupervised topic modeling. Quantitative and qualitative experiments show that vONTSS in the unsupervised setting outperforms recent NTMs on multiple aspects: vONTSS discovers highly clustered and coherent topics on benchmark datasets. It is also much faster than the state-of-the-art weakly supervised text classification method while achieving similar classification performance. We further prove the equivalence of optimal transport loss and cross-entropy loss at the global minimum.</abstract>
      <url hash="426c37d7">2023.findings-acl.271</url>
      <bibkey>xu-etal-2023-vontss</bibkey>
      <doi>10.18653/v1/2023.findings-acl.271</doi>
    </paper>
    <paper id="272">
      <title>Bias Beyond <fixed-case>E</fixed-case>nglish: Counterfactual Tests for Bias in Sentiment Analysis in Four Languages</title>
      <author><first>Seraphina</first><last>Goldfarb-Tarrant</last><affiliation>University of Edinburgh</affiliation></author>
      <author><first>Adam</first><last>Lopez</last><affiliation>University of Edinburgh</affiliation></author>
      <author><first>Roi</first><last>Blanco</last><affiliation>Amazon</affiliation></author>
      <author><first>Diego</first><last>Marcheggiani</last><affiliation>Amazon</affiliation></author>
      <pages>4458-4468</pages>
      <abstract>Sentiment analysis (SA) systems are used in many products and hundreds of languages. Gender and racial biases are well-studied in English SA systems, but understudied in other languages, with few resources for such studies. To remedy this, we build a counterfactual evaluation corpus for gender and racial/migrant bias in four languages. We demonstrate its usefulness by answering a simple but important question that an engineer might need to answer when deploying a system: What biases do systems import from pre-trained models when compared to a baseline with no pre-training? Our evaluation corpus, by virtue of being counterfactual, not only reveals which models have less bias, but also pinpoints changes in model bias behaviour, which enables more targeted mitigation strategies. We release our code and evaluation corpora to facilitate future research.</abstract>
      <url hash="12398b2e">2023.findings-acl.272</url>
      <bibkey>goldfarb-tarrant-etal-2023-bias</bibkey>
      <doi>10.18653/v1/2023.findings-acl.272</doi>
    </paper>
    <paper id="273">
      <title>Complementary Explanations for Effective In-Context Learning</title>
      <author><first>Xi</first><last>Ye</last><affiliation>The University of Texas at Austin</affiliation></author>
      <author><first>Srinivasan</first><last>Iyer</last><affiliation>Facebook</affiliation></author>
      <author><first>Asli</first><last>Celikyilmaz</last><affiliation>FAIR @ Meta</affiliation></author>
      <author><first>Veselin</first><last>Stoyanov</last><affiliation>Facebook</affiliation></author>
      <author><first>Greg</first><last>Durrett</last><affiliation>UT Austin</affiliation></author>
      <author><first>Ramakanth</first><last>Pasunuru</last><affiliation>Meta</affiliation></author>
      <pages>4469-4484</pages>
      <abstract>Large language models (LLMs) have exhibited remarkable capabilities in learning from expla- nations in prompts, but there has been limited understanding of exactly how these explana- tions function or why they are effective. This work aims to better understand the mechanisms by which explanations are used for in-context learning. We first study the impact of two dif- ferent factors on the performance of prompts with explanations: the computation trace (the way the solution is decomposed) and the natural language used to express the prompt. By per- turbing explanations on three controlled tasks, we show that both factors contribute to the ef- fectiveness of explanations. We further study how to form maximally effective sets of expla- nations for solving a given test query. We find that LLMs can benefit from the complemen- tarity of the explanation set: diverse reasoning skills shown by different exemplars can lead to better performance. Therefore, we propose a maximal marginal relevance-based exemplar selection approach for constructing exemplar sets that are both relevant as well as comple- mentary, which successfully improves the in- context learning performance across three real- world tasks on multiple LLMs.</abstract>
      <url hash="ad41fa08">2023.findings-acl.273</url>
      <bibkey>ye-etal-2023-complementary</bibkey>
      <doi>10.18653/v1/2023.findings-acl.273</doi>
    </paper>
    <paper id="274">
      <title><fixed-case>MISMATCH</fixed-case>: Fine-grained Evaluation of Machine-generated Text with Mismatch Error Types</title>
      <author><first>Keerthiram</first><last>Murugesan</last><affiliation>IBM Research</affiliation></author>
      <author><first>Sarathkrishna</first><last>Swaminathan</last><affiliation>IBM Research</affiliation></author>
      <author><first>Soham</first><last>Dan</last><affiliation>IBM</affiliation></author>
      <author><first>Subhajit</first><last>Chaudhury</last><affiliation>IBM Research</affiliation></author>
      <author><first>Chulaka</first><last>Gunasekara</last><affiliation>IBM Research</affiliation></author>
      <author><first>Maxwell</first><last>Crouse</last><affiliation>IBM Research</affiliation></author>
      <author><first>Diwakar</first><last>Mahajan</last><affiliation>IBM Research</affiliation></author>
      <author><first>Ibrahim</first><last>Abdelaziz</last><affiliation>IBM Research</affiliation></author>
      <author><first>Achille</first><last>Fokoue</last><affiliation>IBM Research</affiliation></author>
      <author><first>Pavan</first><last>Kapanipathi</last><affiliation>IBM Research</affiliation></author>
      <author><first>Salim</first><last>Roukos</last><affiliation>IBM Research AI</affiliation></author>
      <author><first>Alexander</first><last>Gray</last><affiliation>IBM Research</affiliation></author>
      <pages>4485-4503</pages>
      <abstract>With the growing interest in large language models, the need for evaluating the quality of machine text compared to reference (typically human-generated) text has become focal attention. Most recent works focus either on task-specific evaluation metrics or study the properties of machine-generated text captured by the existing metrics. In this work, we propose a new evaluation scheme to model human judgments in 7 NLP tasks, based on the fine-grained mismatches between a pair of texts. Inspired by the recent efforts in several NLP tasks for fine-grained evaluation, we introduce a set of 13 mismatch error types such as spatial/geographic errors, entity errors, etc, to guide the model for better prediction of human judgments. We propose a neural framework for evaluating machine texts that uses these mismatch error types as auxiliary tasks and re-purposes the existing single-number evaluation metrics as additional scalar features, in addition to textual features extracted from the machine and reference texts. Our experiments reveal key insights about the existing metrics via the mismatch errors. We show that the mismatch errors between the sentence pairs on the held-out datasets from 7 NLP tasks align well with the human evaluation.</abstract>
      <url hash="ac6c2df6">2023.findings-acl.274</url>
      <bibkey>murugesan-etal-2023-mismatch</bibkey>
      <doi>10.18653/v1/2023.findings-acl.274</doi>
    </paper>
    <paper id="275">
      <title><fixed-case>RHO</fixed-case>: Reducing Hallucination in Open-domain Dialogues with Knowledge Grounding</title>
      <author><first>Ziwei</first><last>Ji</last><affiliation>The Hong Kong University of Science and Technology</affiliation></author>
      <author><first>Zihan</first><last>Liu</last><affiliation>Nvidia</affiliation></author>
      <author><first>Nayeon</first><last>Lee</last><affiliation>Hong Kong University of Science and Technology</affiliation></author>
      <author><first>Tiezheng</first><last>Yu</last><affiliation>The Hong Kong University of Science and Technology</affiliation></author>
      <author><first>Bryan</first><last>Wilie</last><affiliation>The Hong Kong University of Science and Technology</affiliation></author>
      <author><first>Min</first><last>Zeng</last><affiliation>Hong Kong University of Science and Technology</affiliation></author>
      <author><first>Pascale</first><last>Fung</last><affiliation>Hong Kong University of Science and Technology</affiliation></author>
      <pages>4504-4522</pages>
      <abstract>Dialogue systems can leverage large pre-trained language models and knowledge to generate fluent and informative responses. However, these models are still prone to produce hallucinated responses not supported by the input source, which greatly hinders their application. The heterogeneity between external knowledge and dialogue context challenges representation learning and source integration, which further contributes to unfaithfulness. To handle this challenge and generate more faithful responses, this paper presents RHO (ρ) utilizing the representations of linked entities and relation predicates from a knowledge graph (KG). We propose (1) local knowledge grounding to combine textual embeddings with the corresponding KG embeddings; and (2) global knowledge grounding to equip RHO with multi-hop reasoning abilities via the attention mechanism. In addition, we devise a response re-ranking technique based on walks over KG sub-graphs for better conversational reasoning. Experimental results on OpenDialKG (Moon et al., 2019) show that our approach significantly outperforms state-of-the-art methods on both automatic and human evaluation by a large margin, especially in hallucination reduction (17.54% in FeQA (Durmus et al., 2020)).</abstract>
      <url hash="30f72dcd">2023.findings-acl.275</url>
      <bibkey>ji-etal-2023-rho</bibkey>
      <doi>10.18653/v1/2023.findings-acl.275</doi>
    </paper>
    <paper id="276">
      <title>Transformer Language Models Handle Word Frequency in Prediction Head</title>
      <author><first>Goro</first><last>Kobayashi</last><affiliation>Tohoku University / RIKEN</affiliation></author>
      <author><first>Tatsuki</first><last>Kuribayashi</last><affiliation>MBZUAI</affiliation></author>
      <author><first>Sho</first><last>Yokoi</last><affiliation>Tohoku University / RIKEN</affiliation></author>
      <author><first>Kentaro</first><last>Inui</last><affiliation>Tohoku University / Riken</affiliation></author>
      <pages>4523-4535</pages>
      <abstract>Prediction head is a crucial component of Transformer language models. Despite its direct impact on prediction, this component has often been overlooked in analyzing Transformers.In this study, we investigate the inner workings of the prediction head, specifically focusing on bias parameters. Our experiments with BERT and GPT-2 models reveal that the biases in their word prediction heads play a significant role in the models’ ability to reflect word frequency in a corpus, aligning with the logit adjustment method commonly used in long-tailed learning. We also quantify the effect of controlling the biases in practical auto-regressive text generation scenarios;under a particular setting, more diverse text can be generated without compromising text quality.</abstract>
      <url hash="be82cc79">2023.findings-acl.276</url>
      <bibkey>kobayashi-etal-2023-transformer</bibkey>
      <doi>10.18653/v1/2023.findings-acl.276</doi>
    </paper>
    <paper id="277">
      <title>Prompted <fixed-case>LLM</fixed-case>s as Chatbot Modules for Long Open-domain Conversation</title>
      <author><first>Gibbeum</first><last>Lee</last><affiliation>Krafton</affiliation></author>
      <author><first>Volker</first><last>Hartmann</last><affiliation>Krafton Inc</affiliation></author>
      <author><first>Jongho</first><last>Park</last><affiliation>Krafton Inc.</affiliation></author>
      <author><first>Dimitris</first><last>Papailiopoulos</last><affiliation>University of Wisconsin-Madison, Assistant Professor</affiliation></author>
      <author><first>Kangwook</first><last>Lee</last><affiliation>UW Madison</affiliation></author>
      <pages>4536-4554</pages>
      <abstract>In this paper, we propose MPC (Modular Prompted Chatbot), a new approach for creating high-quality conversational agents without the need for fine-tuning. Our method utilizes pre-trained large language models (LLMs) as individual modules for long-term consistency and flexibility, by using techniques such as few-shot prompting, chain-of-thought (CoT), and external memory. Our human evaluation results show that MPC is on par with fine-tuned chatbot models in open-domain conversations, making it an effective solution for creating consistent and engaging chatbots.</abstract>
      <url hash="7624ca40">2023.findings-acl.277</url>
      <bibkey>lee-etal-2023-prompted</bibkey>
      <doi>10.18653/v1/2023.findings-acl.277</doi>
    </paper>
    <paper id="278">
      <title>Prompt to be Consistent is Better than Self-Consistent? Few-Shot and Zero-Shot Fact Verification with Pre-trained Language Models</title>
      <author><first>Fengzhu</first><last>Zeng</last><affiliation>Singapore Management University</affiliation></author>
      <author><first>Wei</first><last>Gao</last><affiliation>Singapore Management University</affiliation></author>
      <pages>4555-4569</pages>
      <abstract>Few-shot or zero-shot fact verification only relies on a few or no labeled training examples. In this paper, we propose a novel method called ProToCo, to Prompt pre-trained language models (PLMs) To be Consistent, for improving the factuality assessment capability of PLMs in the few-shot and zero-shot settings. Given a claim-evidence pair, ProToCo generates multiple variants of the claim with different relations and frames a simple consistency mechanism as constraints for making compatible predictions across these variants. We update PLMs by using parameter-efficient fine-tuning (PEFT), leading to more accurate predictions in few-shot and zero-shot fact verification tasks. Our experiments on three public verification datasets show that ProToCo significantly outperforms state-of-the-art few-shot fact verification baselines. With a small number of unlabeled instances, ProToCo also outperforms the strong zero-shot learner T0 on zero-shot verification. Compared to large PLMs using in-context learning (ICL) method, ProToCo outperforms OPT-30B and the Self-Consistency-enabled OPT-6.7B model in both few- and zero-shot settings.</abstract>
      <url hash="a099d8e5">2023.findings-acl.278</url>
      <bibkey>zeng-gao-2023-prompt</bibkey>
      <doi>10.18653/v1/2023.findings-acl.278</doi>
    </paper>
    <paper id="279">
      <title>Model Analysis &amp; Evaluation for Ambiguous Question Answering</title>
      <author><first>Konstantinos</first><last>Papakostas</last><affiliation>University of Amsterdam</affiliation></author>
      <author><first>Irene</first><last>Papadopoulou</last><affiliation>University of Amsterdam</affiliation></author>
      <pages>4570-4580</pages>
      <abstract>Ambiguous questions are a challenge for Question Answering models, as they require answers that cover multiple interpretations of the original query. To this end, these models are required to generate long-form answers that often combine conflicting pieces of information. Although recent advances in the field have shown strong capabilities in generating fluent responses, certain research questions remain unanswered. Does model/data scaling improve the answers’ quality? Do automated metrics align with human judgment? To what extent do these models ground their answers in evidence? In this study, we aim to thoroughly investigate these aspects, and provide valuable insights into the limitations of the current approaches. To aid in reproducibility and further extension of our work, we open-source our code.</abstract>
      <url hash="aa73eb0b">2023.findings-acl.279</url>
      <bibkey>papakostas-papadopoulou-2023-model</bibkey>
      <doi>10.18653/v1/2023.findings-acl.279</doi>
    </paper>
    <paper id="280">
      <title>Debiasing should be Good and Bad: Measuring the Consistency of Debiasing Techniques in Language Models</title>
      <author><first>Robert</first><last>Morabito</last><affiliation>Brock University</affiliation></author>
      <author><first>Jad</first><last>Kabbara</last><affiliation>MIT</affiliation></author>
      <author><first>Ali</first><last>Emami</last><affiliation>Brock University</affiliation></author>
      <pages>4581-4597</pages>
      <abstract>Debiasing methods that seek to mitigate the tendency of Language Models (LMs) to occasionally output toxic or inappropriate text have recently gained traction. In this paper, we propose a standardized protocol which distinguishes methods that yield not only desirable results, but are also consistent with their mechanisms and specifications. For example, we ask, given a debiasing method that is developed to reduce toxicity in LMs, if the definition of toxicity used by the debiasing method is reversed, would the debiasing results also be reversed? We used such considerations to devise three criteria for our new protocol: Specification Polarity, Specification Importance, and Domain Transferability. As a case study, we apply our protocol to a popular debiasing method, Self-Debiasing, and compare it to one we propose, called Instructive Debiasing, and demonstrate that consistency is as important an aspect to debiasing viability as is simply a desirable result. We show that our protocol provides essential insights into the generalizability and interpretability of debiasing methods that may otherwise go overlooked.</abstract>
      <url hash="deff400a">2023.findings-acl.280</url>
      <bibkey>morabito-etal-2023-debiasing</bibkey>
      <doi>10.18653/v1/2023.findings-acl.280</doi>
    </paper>
    <paper id="281">
      <title>Critic-Guided Decoding for Controlled Text Generation</title>
      <author><first>Minbeom</first><last>Kim</last><affiliation>Seoul National University</affiliation></author>
      <author><first>Hwanhee</first><last>Lee</last><affiliation>Seoul National University</affiliation></author>
      <author><first>Kang Min</first><last>Yoo</last><affiliation>NAVER AI Lab</affiliation></author>
      <author><first>Joonsuk</first><last>Park</last><affiliation>University of Richmond</affiliation></author>
      <author><first>Hwaran</first><last>Lee</last><affiliation>NAVER AI Lab</affiliation></author>
      <author><first>Kyomin</first><last>Jung</last><affiliation>Seoul National University</affiliation></author>
      <pages>4598-4612</pages>
      <abstract>Steering language generation towards objectives or away from undesired content has been a long-standing goal in utilizing language models (LM). Recent work has demonstrated reinforcement learning and weighted decoding as effective approaches to achieve a higher level of language control and quality with pros and cons. In this work, we propose a novel critic decoding method for controlled language generation (CriticControl) that combines the strengths of reinforcement learning and weighted decoding. Specifically, we adopt the actor-critic framework and train an LM-steering critic from reward models. Similar to weighted decoding, our method freezes the language model and manipulates the output token distribution using a critic to improve training efficiency and stability. Evaluation of our method on three controlled generation tasks, topic control, sentiment control, and detoxification, shows that our approach generates more coherent and well-controlled texts than previous methods. In addition, CriticControl demonstrates superior generalization ability in zero-shot settings. Human evaluation studies also corroborate our findings.</abstract>
      <url hash="abb7517e">2023.findings-acl.281</url>
      <bibkey>kim-etal-2023-critic</bibkey>
      <doi>10.18653/v1/2023.findings-acl.281</doi>
    </paper>
    <paper id="282">
      <title><fixed-case>M</fixed-case>ed<fixed-case>N</fixed-case>gage: A Dataset for Understanding Engagement in Patient-Nurse Conversations</title>
      <author><first>Yan</first><last>Wang</last><affiliation>University of Pittsburgh</affiliation></author>
      <author><first>Heidi</first><last>Donovan</last><affiliation>University of Pittsburgh</affiliation></author>
      <author><first>Sabit</first><last>Hassan</last><affiliation>University of Pittsburgh</affiliation></author>
      <author><first>Malihe</first><last>Alikhani</last><affiliation>University of Pittsburgh</affiliation></author>
      <pages>4613-4630</pages>
      <abstract>Patients who effectively manage their symptoms often demonstrate higher levels of engagement in conversations and interventions with healthcare practitioners. This engagement is multifaceted, encompassing cognitive and social dimensions. Consequently, it is crucial for AI systems to understand the engagement in natural conversations between patients and practitioners to better contribute toward patient care. In this paper, we present a novel dataset (MedNgage), which consists of patient-nurse conversations about cancer symptom management. We manually annotate the dataset with a novel framework of categories of patient engagement from two different angles, namely: i) socio-affective engagement (3.1K spans), and ii) cognitive engagement (1.8K spans). Through statistical analysis of the data that is annotated using our framework, we show a positive correlation between patient symptom management outcomes and their engagement in conversations. Additionally, we demonstrate that pre-trained transformer models fine-tuned on our dataset can reliably predict engagement categories in patient-nurse conversations. Lastly, we use LIME (Ribeiro et al., 2016) to analyze the underlying challenges of the tasks that state-of-the-art transformer models encounter. The de-identified data is available for research purposes upon request.</abstract>
      <url hash="324989e9">2023.findings-acl.282</url>
      <bibkey>wang-etal-2023-medngage</bibkey>
      <doi>10.18653/v1/2023.findings-acl.282</doi>
    </paper>
    <paper id="283">
      <title><fixed-case>SEAG</fixed-case>: Structure-Aware Event Causality Generation</title>
      <author><first>Zhengwei</first><last>Tao</last><affiliation>Peking University</affiliation></author>
      <author><first>Zhi</first><last>Jin</last><affiliation>Peking University</affiliation></author>
      <author><first>Xiaoying</first><last>Bai</last><affiliation>AIBD</affiliation></author>
      <author><first>Haiyan</first><last>Zhao</last><affiliation>Peking University</affiliation></author>
      <author><first>Chengfeng</first><last>Dou</last><affiliation>Peking University</affiliation></author>
      <author><first>Yongqiang</first><last>Zhao</last><affiliation>peking university</affiliation></author>
      <author><first>Fang</first><last>Wang</last><affiliation>Peking University</affiliation></author>
      <author><first>Chongyang</first><last>Tao</last><affiliation>Peking University</affiliation></author>
      <pages>4631-4644</pages>
      <abstract>Extracting event causality underlies a broad spectrum of natural language processing applications. Cutting-edge methods break this task into Event Detection and Event Causality Identification. Although the pipelined solutions succeed in achieving acceptable results, the inherent nature of separating the task incurs limitations. On the one hand, it suffers from the lack of cross-task dependencies and may cause error propagation. On the other hand, it predicts events and relations separately, undermining the integrity of the event causality graph (ECG). To address such issues, in this paper, we propose an approach for Structure-Aware Event Causality Generation (SEAG). With a graph linearization module, we generate the ECG structure in a way of text2text generation based on a pre-trained language model. To foster the structural representation of the ECG, we introduce the novel Causality Structural Discrimination training paradigm in which we perform structural discriminative training alongside auto-regressive generation enabling the model to distinguish from constructed incorrect ECGs. We conduct experiments on three datasets. The experimental results demonstrate the effectiveness of structural event causality generation and the causality structural discrimination training.</abstract>
      <url hash="e855b05a">2023.findings-acl.283</url>
      <bibkey>tao-etal-2023-seag</bibkey>
      <doi>10.18653/v1/2023.findings-acl.283</doi>
    </paper>
    <paper id="284">
      <title>Large Language Models Can be Lazy Learners: Analyze Shortcuts in In-Context Learning</title>
      <author><first>Ruixiang</first><last>Tang</last><affiliation>Rice University</affiliation></author>
      <author><first>Dehan</first><last>Kong</last><affiliation>Alibaba Group</affiliation></author>
      <author><first>Longtao</first><last>Huang</last><affiliation>Alibaba Group</affiliation></author>
      <author><first>Hui</first><last>Xue</last><affiliation>alibaba</affiliation></author>
      <pages>4645-4657</pages>
      <abstract>Large language models (LLMs) have recently shown great potential for in-context learning, where LLMs learn a new task simply by conditioning on a few input-label pairs (prompts). Despite their potential, our understanding of the factors influencing end-task performance and the robustness of in-context learning remains limited. This paper aims to bridge this knowledge gap by investigating the reliance of LLMs on shortcuts or spurious correlations within prompts. Through comprehensive experiments on classification and extraction tasks, we reveal that LLMs are “lazy learners” that tend to exploit such shortcuts. Additionally, we uncover a surprising finding that larger models are more likely to utilize shortcuts in prompts during inference. Our findings provide a new perspective on evaluating robustness in in-context learning and pose new challenges for detecting and mitigating the use of shortcuts in prompts.</abstract>
      <url hash="c07dbc40">2023.findings-acl.284</url>
      <bibkey>tang-etal-2023-large</bibkey>
      <doi>10.18653/v1/2023.findings-acl.284</doi>
    </paper>
    <paper id="285">
      <title>A Two-Stage Decoder for Efficient <fixed-case>ICD</fixed-case> Coding</title>
      <author><first>Thanh-Tung</first><last>Nguyen</last><affiliation>ASUS</affiliation></author>
      <author><first>Viktor</first><last>Schlegel</last><affiliation>ASUS AICS</affiliation></author>
      <author><first>Abhinav</first><last>Ramesh Kashyap</last><affiliation>ASUS AICS</affiliation></author>
      <author><first>Stefan</first><last>Winkler</last><affiliation>ASUS Intelligent Cloud Services (AICS)</affiliation></author>
      <pages>4658-4665</pages>
      <abstract>Clinical notes in healthcare facilities are tagged with the International Classification of Diseases (ICD) code; a list of classification codes for medical diagnoses and procedures. ICD coding is a challenging multilabel text classification problem due to noisy clinical document inputs and long-tailed label distribution. Recent automated ICD coding efforts improve performance by encoding medical notes and codes with additional data and knowledge bases. However, most of them do not reflect how human coders generate the code: first, the coders select general code categories and then look for specific subcategories that are relevant to a patient’s condition. Inspired by this, we propose a two-stage decoding mechanism to predict ICD codes. Our model uses the hierarchical properties of the codes to split the prediction into two steps: At first, we predict the parent code and then predict the child code based on the previous prediction. Experiments on the public MIMIC-III data set have shown that our model performs well in single-model settings without external data or knowledge.</abstract>
      <url hash="6c6c35a6">2023.findings-acl.285</url>
      <bibkey>nguyen-etal-2023-two</bibkey>
      <doi>10.18653/v1/2023.findings-acl.285</doi>
    </paper>
    <paper id="286">
      <title>Asymmetric feature interaction for interpreting model predictions</title>
      <author><first>Xiaolei</first><last>Lu</last><affiliation>City University of Hong Kong</affiliation></author>
      <author><first>Jianghong</first><last>Ma</last><affiliation>HIT,shenzhen</affiliation></author>
      <author><first>Haode</first><last>Zhang</last><affiliation>The Hong Kong Polytechnic University</affiliation></author>
      <pages>4666-4678</pages>
      <abstract>In natural language processing (NLP), deep neural networks (DNNs) could model complex interactions between context and have achieved impressive results on a range of NLP tasks. Prior works on feature interaction attribution mainly focus on studying symmetric interaction that only explains the additional influence of a set of words in combination, which fails to capture asymmetric influence that contributes to model prediction. In this work, we propose an asymmetric feature interaction attribution explanation model that aims to explore asymmetric higher-order feature interactions in the inference of deep neural NLP models. By representing our explanation with an directed interaction graph, we experimentally demonstrate interpretability of the graph to discover asymmetric feature interactions. Experimental results on two sentiment classification datasets show the superiority of our model against the state-of-the-art feature interaction attribution methods in identifying influential features for model predictions.</abstract>
      <url hash="c7f541fb">2023.findings-acl.286</url>
      <bibkey>lu-etal-2023-asymmetric</bibkey>
      <doi>10.18653/v1/2023.findings-acl.286</doi>
    </paper>
    <paper id="287">
      <title>Disagreement Matters: Preserving Label Diversity by Jointly Modeling Item and Annotator Label Distributions with <fixed-case>D</fixed-case>is<fixed-case>C</fixed-case>o</title>
      <author><first>Tharindu Cyril</first><last>Weerasooriya</last><affiliation>Rochester Institute of Technology</affiliation></author>
      <author><first>Alexander</first><last>Ororbia</last><affiliation>Rochester Institute of Technology</affiliation></author>
      <author><first>Raj</first><last>Bhensadadia</last><affiliation>Rochester Institute of Technology</affiliation></author>
      <author><first>Ashiqur</first><last>KhudaBukhsh</last><affiliation>Rochester Institute of Technology</affiliation></author>
      <author><first>Christopher</first><last>Homan</last><affiliation>Rochester Institute of Technology</affiliation></author>
      <pages>4679-4695</pages>
      <abstract>Annotator disagreement is common whenever human judgment is needed for supervised learning. It is conventional to assume that one label per item represents ground truth. However, this obscures minority opinions, if present. We regard “ground truth” as the distribution of all labels that a population of annotators could produce, if asked (and of which we only have a small sample). We next introduce DisCo (Distribution from Context), a simple neural model that learns to predict this distribution. The model takes annotator-item pairs, rather than items alone, as input, and performs inference by aggregating over all annotators. Despite its simplicity, our experiments show that, on six benchmark datasets, our model is competitive with, and frequently outperforms, other, more complex models that either do not model specific annotators or were not designed for label distribution learning.</abstract>
      <url hash="dfa5624d">2023.findings-acl.287</url>
      <bibkey>weerasooriya-etal-2023-disagreement</bibkey>
      <doi>10.18653/v1/2023.findings-acl.287</doi>
    </paper>
    <paper id="288">
      <title>Domain Aligned Prefix Averaging for Domain Generalization in Abstractive Summarization</title>
      <author><first>Pranav</first><last>Nair</last><affiliation>Indian Institute of Technology (BHU), Varanasi</affiliation></author>
      <author><first>Sukomal</first><last>Pal</last><affiliation>IIT(BHU)</affiliation></author>
      <author><first>Pradeepika</first><last>Verma</last><affiliation>Technology Innovation Hub, IIT Patna</affiliation></author>
      <pages>4696-4710</pages>
      <abstract>Domain generalization is hitherto an underexplored area applied in abstractive summarization. Moreover, most existing works on domain generalization have sophisticated training algorithms. In this paper, we propose a lightweight, weight averaging based, Domain Aligned Prefix Averaging approach to domain generalization for abstractive summarization. Given a number of source domains, our method first trains a prefix for each one of them. These source prefixes generate summaries for a small number of target domain documents. The similarity of the generated summaries to their corresponding source documents is used for calculating weights required to average source prefixes. In DAPA, prefix tuning allows for lightweight finetuning, and weight averaging allows for the computationally efficient addition of new source domains. When evaluated on four diverse summarization domains, DAPA shows comparable or better performance against the baselines demonstrating the effectiveness of its prefix averaging scheme.</abstract>
      <url hash="e059868a">2023.findings-acl.288</url>
      <bibkey>nair-etal-2023-domain</bibkey>
      <doi>10.18653/v1/2023.findings-acl.288</doi>
    </paper>
    <paper id="289">
      <title><fixed-case>C</fixed-case>laim<fixed-case>D</fixed-case>iff: Comparing and Contrasting Claims on Contentious Issues</title>
      <author><first>Miyoung</first><last>Ko</last><affiliation>KAIST</affiliation></author>
      <author><first>Ingyu</first><last>Seong</last><affiliation>Korea University</affiliation></author>
      <author><first>Hwaran</first><last>Lee</last><affiliation>NAVER AI Lab</affiliation></author>
      <author><first>Joonsuk</first><last>Park</last><affiliation>University of Richmond</affiliation></author>
      <author><first>Minsuk</first><last>Chang</last><affiliation>Google</affiliation></author>
      <author><first>Minjoon</first><last>Seo</last><affiliation>KAIST</affiliation></author>
      <pages>4711-4731</pages>
      <abstract>With the growing importance of detecting misinformation, many studies have focused on verifying factual claims by retrieving evidence. However, canonical fact verification tasks do not apply to catching subtle differences in factually consistent claims, which might still bias the readers, especially on contentious political or economic issues. Our underlying assumption is that among the trusted sources, one’s argument is not necessarily more true than the other, requiring comparison rather than verification. In this study, we propose ClaimDIff, a novel dataset that primarily focuses on comparing the nuance between claim pairs. In ClaimDiff, we provide human-labeled 2,941 claim pairs from 268 news articles. We observe that while humans are capable of detecting the nuances between claims, strong baselines struggle to detect them, showing over a 19% absolute gap with the humans. We hope this initial study could help readers to gain an unbiased grasp of contentious issues through machine-aided comparison.</abstract>
      <url hash="b2c4edd1">2023.findings-acl.289</url>
      <bibkey>ko-etal-2023-claimdiff</bibkey>
      <doi>10.18653/v1/2023.findings-acl.289</doi>
    </paper>
    <paper id="290">
      <title>Unsupervised Paraphrasing of Multiword Expressions</title>
      <author><first>Takashi</first><last>Wada</last><affiliation>The University of Melbourne</affiliation></author>
      <author><first>Yuji</first><last>Matsumoto</last><affiliation>Riken Center for Advanced Intelligence Project</affiliation></author>
      <author><first>Timothy</first><last>Baldwin</last><affiliation>MBZUAI</affiliation></author>
      <author><first>Jey Han</first><last>Lau</last><affiliation>The University of Melbourne</affiliation></author>
      <pages>4732-4746</pages>
      <abstract>We propose an unsupervised approach to paraphrasing multiword expressions (MWEs) in context. Our model employs only monolingual corpus data and pre-trained language models (without fine-tuning), and does not make use of any external resources such as dictionaries. We evaluate our method on the SemEval 2022 idiomatic semantic text similarity task, and show that it outperforms all unsupervised systems and rivals supervised systems.</abstract>
      <url hash="36ad51b4">2023.findings-acl.290</url>
      <bibkey>wada-etal-2023-unsupervised</bibkey>
      <doi>10.18653/v1/2023.findings-acl.290</doi>
    </paper>
    <paper id="291">
      <title><fixed-case>G</fixed-case>-Tuning: Improving Generalization of Pre-trained Language Models with Generative Adversarial Network</title>
      <author><first>Rongxiang</first><last>Weng</last><affiliation>Alibaba DAMO Academy</affiliation></author>
      <author><first>Wen Sen</first><last>Cheng</last><affiliation>mihoyo</affiliation></author>
      <author><first>Min</first><last>Zhang</last><affiliation>SooChow University</affiliation></author>
      <pages>4747-4755</pages>
      <abstract>The generalization ability of pre-trained language models (Plms) in downstream tasks is heavily influenced by fine-tuning. The objective of fine-tuning is to transform the latent representation of Plms from a universal space to a target space, allowing the model to be applied to downstream tasks with the capability of generalizing to unseen samples. However, the effect of Plms will be diminished when the training data coverage is insufficient, in which fine-tuning is inadequate to learn the complete mapping. In this study, we propose a new fine-tuning framework, referred to as G-Tuning, that aims to preserve the generalization ability of Plms in downstream tasks. Specifically, we integrate a generative adversarial network into the fine-tuning process to aid in the transformation of the latent representation in the entire space. Empirical evaluations on the GLUE benchmark, as well as two additional demanding scenarios involving domain and language generalization, demonstrate that G-Tuning can accurately map the universal representation to the target space, thus effectively enhancing the generalization performance of Plms across various downstream tasks.</abstract>
      <url hash="9c78ba32">2023.findings-acl.291</url>
      <bibkey>weng-etal-2023-g</bibkey>
      <doi>10.18653/v1/2023.findings-acl.291</doi>
    </paper>
    <paper id="292">
      <title>Unified Language Representation for Question Answering over Text, Tables, and Images</title>
      <author><first>Bowen</first><last>Yu</last><affiliation>DAMO Academy, Alibaba Group</affiliation></author>
      <author><first>Cheng</first><last>Fu</last><affiliation>Alibaba</affiliation></author>
      <author><first>Haiyang</first><last>Yu</last><affiliation>Allibaba Group</affiliation></author>
      <author><first>Fei</first><last>Huang</last><affiliation>Alibaba DAMO Academy</affiliation></author>
      <author><first>Yongbin</first><last>Li</last><affiliation>Alibaba Group</affiliation></author>
      <pages>4756-4765</pages>
      <abstract>When trying to answer complex questions, people often rely on multiple sources of information, such as visual, textual, and tabular data. Previous approaches to this problem have focused on designing input features or model structure in the multi-modal space, which is inflexible for cross-modal reasoning or data-efficient training. In this paper, we call for an alternative paradigm, which transforms the images and tables into unified language representations, so that we can simplify the task into a simpler textual QA problem that can be solved using three steps: retrieval, ranking, and generation, all within a language space. This idea takes advantage of the power of pre-trained language models and is implemented in a framework called Solar. Our experimental results show that Solar outperforms all existing methods by 10.6-32.3 pts on two datasets, MultimodalQA and MMCoQA, across ten different metrics. Additionally, Solar achieves the best performance on the WebQA leaderboard.</abstract>
      <url hash="a2dfae76">2023.findings-acl.292</url>
      <bibkey>yu-etal-2023-unified</bibkey>
      <doi>10.18653/v1/2023.findings-acl.292</doi>
    </paper>
    <paper id="293">
      <title>A Set Prediction Network For Extractive Summarization</title>
      <author><first>Xiaoxia</first><last>Cheng</last><affiliation>Zhejiang University</affiliation></author>
      <author><first>Yongliang</first><last>Shen</last><affiliation>Zhejiang University</affiliation></author>
      <author><first>Weiming</first><last>Lu</last><affiliation>Zhejiang University</affiliation></author>
      <pages>4766-4777</pages>
      <abstract>Extractive summarization focuses on extracting salient sentences from the source document and incorporating them in the summary without changing their wording or structure. The naive approach for extractive summarization is sentence classification, which makes independent binary decisions for each sentence, resulting in the model cannot detect the dependencies between sentences in the summary. Recent approaches introduce an autoregressive decoder to detect redundancy relationship between sentences by step-by-step sentence selection, but bring train-inference gap. To address these issues, we formulate extractive summarization as a salient sentence set recognition task. To solve the sentence set recognition task, we propose a set prediction network (<b>SetSum</b>), which sets up a fixed set of learnable queries to extract the entire sentence set of the summary, while capturing the dependencies between them.Different from previous methods with an auto-regressive decoder, we employ a non-autoregressive decoder to predict the sentences within the summary in parallel during both the training and inference process, which eliminates the train-inference gap. Experimental results on both single-document and multi-document extracted summary datasets show that our approach outperforms previous state-of-the-art models.</abstract>
      <url hash="9c1cd092">2023.findings-acl.293</url>
      <bibkey>cheng-etal-2023-set</bibkey>
      <doi>10.18653/v1/2023.findings-acl.293</doi>
    </paper>
    <paper id="294">
      <title>Geo-Seq2seq: <fixed-case>T</fixed-case>witter User Geolocation on Noisy Data through Sequence to Sequence Learning</title>
      <author><first>Jingyu</first><last>Zhang</last><affiliation>Johns Hopkins University</affiliation></author>
      <author><first>Alexandra</first><last>DeLucia</last><affiliation>Johns Hopkins University</affiliation></author>
      <author><first>Chenyu</first><last>Zhang</last><affiliation>Stanford University</affiliation></author>
      <author><first>Mark</first><last>Dredze</last><affiliation>Johns Hopkins University</affiliation></author>
      <pages>4778-4794</pages>
      <abstract>Location information can support social media analyses by providing geographic context. Some of the most accurate and popular Twitter geolocation systems rely on rule-based methods that examine the user-provided profile location, which fail to handle informal or noisy location names. We propose Geo-Seq2seq, a sequence-to-sequence (seq2seq) model for Twitter user geolocation that rewrites noisy, multilingual user-provided location strings into structured English location names. We train our system on tens of millions of multilingual location string and geotagged-tweet pairs. Compared to leading methods, our model vastly increases coverage (i.e., the number of users we can geolocate) while achieving comparable or superior accuracy. Our error analysis reveals that constrained decoding helps the model produce valid locations according to a location database. Finally, we measure biases across language, country of origin, and time to evaluate fairness, and find that while our model can generalize well to unseen temporal data, performance does vary by language and country.</abstract>
      <url hash="5325bed9">2023.findings-acl.294</url>
      <bibkey>zhang-etal-2023-geo</bibkey>
      <doi>10.18653/v1/2023.findings-acl.294</doi>
    </paper>
    <paper id="295">
      <title>Predicting Numerals in Text Using Nearest Neighbor Language Models</title>
      <author><first>Taku</first><last>Sakamoto</last><affiliation>The University of Tokyo</affiliation></author>
      <author><first>Akiko</first><last>Aizawa</last><affiliation>National Institute of Informatics</affiliation></author>
      <pages>4795-4809</pages>
      <abstract>Commonsense about quantitative properties is essential for a deep understanding of texts containing numerals. However, naive language models (LMs) treat numerals as string tokens; therefore, they lack an understanding of the magnitudes of numerals, resulting in a difficulty in acquiring the commonsense. In this study, we apply the <tex-math>k</tex-math>-nearest neighbor LM (<tex-math>k</tex-math>NN-LM) to the masked numeral prediction (MNP) task, which measures the quantitative commonsense of LMs.<tex-math>k</tex-math>NN-LM extends pre-trained neural LMs with the <tex-math>k</tex-math>-nearest neighbor (<tex-math>k</tex-math>NN) search.Since it can utilize patterns that appear in the datastore for prediction, we expect an improvement in numeral prediction accuracy, which is associated with a high rate of occurrence of out-of-vocabulary (OOV) words.Through experiments, we verified that the retrieval-based method is effective for fine-grained predictions of numerals from context, especially for the OOV numerals.We also compared two different context spans for context representations to improve the accuracy of <tex-math>k</tex-math>NN search by using only the words that are closely related to the masked numeral: the mask and its surrounding words, and the mask and its subsequent words.Our results reveal that using only the embeddings of mask tokens for numerals in <tex-math>k</tex-math>NN search is the most effective approach for realizing MNP tasks.</abstract>
      <url hash="355fb982">2023.findings-acl.295</url>
      <bibkey>sakamoto-aizawa-2023-predicting</bibkey>
      <doi>10.18653/v1/2023.findings-acl.295</doi>
    </paper>
    <paper id="296">
      <title><fixed-case>H</fixed-case>onest<fixed-case>B</fixed-case>ait: Forward References for Attractive but Faithful Headline Generation</title>
      <author><first>Chih Yao</first><last>Chen</last><affiliation>Academia Sinica</affiliation></author>
      <author><first>Dennis</first><last>Wu</last><affiliation>Northwestern University</affiliation></author>
      <author><first>Lun-Wei</first><last>Ku</last><affiliation>Academia Sinica</affiliation></author>
      <pages>4810-4824</pages>
      <abstract>Current methods for generating attractive headlines often learn directly from data, which bases attractiveness on the number of user clicks and views. Although clicks or views do reflect user interest, they can fail to reveal how much interest is raised by the writing style and how much is due to the event or topic itself. Also, such approaches can lead to harmful inventions by over-exaggerating the content, aggravating the spread of false information. In this work, we propose HonestBait, a novel framework for solving these issues from another aspect: generating headlines using forward references (FRs), a writing technique often used for clickbait. A self-verification process is included during training to avoid spurious inventions. We begin with a preliminary user study to understand how FRs affect user interest, after which we present PANCO, an innovative dataset containing pairs of fake news with verified news for attractive but faithful news headline generation. Auto matic metrics and human evaluations show that our framework yields more attractive results (+11.25% compared to human-written verified news headlines) while maintaining high veracity, which helps promote real information to fight against fake news.</abstract>
      <url hash="0ae67629">2023.findings-acl.296</url>
      <bibkey>chen-etal-2023-honestbait</bibkey>
      <doi>10.18653/v1/2023.findings-acl.296</doi>
    </paper>
    <paper id="297">
      <title>Few Shot Rationale Generation using Self-Training with Dual Teachers</title>
      <author><first>Aditya Srikanth</first><last>Veerubhotla</last><affiliation>Language Technologies Institute, Carnegie Mellon University</affiliation></author>
      <author><first>Lahari</first><last>Poddar</last><affiliation>Amazon</affiliation></author>
      <author><first>Jun</first><last>Yin</last><affiliation>Amazon</affiliation></author>
      <author><first>György</first><last>Szarvas</last><affiliation>Amazon Development Center Germany GmbH</affiliation></author>
      <author><first>Sharanya</first><last>Eswaran</last><affiliation>Amazon</affiliation></author>
      <pages>4825-4838</pages>
      <abstract>Self-rationalizing models that also generate a free-text explanation for their predicted labels are an important tool to build trustworthy AI applications. Since generating explanations for annotated labels is a laborious and costly process, recent models rely on large pretrained language models (PLMs) as their backbone and few-shot learning. In this work we explore a self-training approach leveraging both labeled and unlabeled data to further improve few-shot models, under the assumption that neither human written rationales nor annotated task labels are available at scale. We introduce a novel dual-teacher learning framework, which learns two specialized teacher models for task prediction and rationalization using self-training and distills their knowledge into a multi-tasking student model that can jointly generate the task label and rationale. Furthermore, we formulate a new loss function, Masked Label Regularization(MLR) which promotes explanations to be strongly conditioned on predicted labels. Evaluation on three public datasets demonstrate that the proposed methods are effective in modeling task labels and generating faithful rationales.</abstract>
      <url hash="9a0cc012">2023.findings-acl.297</url>
      <bibkey>veerubhotla-etal-2023-shot</bibkey>
      <doi>10.18653/v1/2023.findings-acl.297</doi>
    </paper>
    <paper id="298">
      <title>Towards Accurate Translation via Semantically Appropriate Application of Lexical Constraints</title>
      <author><first>Yujin</first><last>Baek</last><affiliation>Korea Advanced Institute of Science and Technology</affiliation></author>
      <author><first>Koanho</first><last>Lee</last><affiliation>Korea Advanced Institute of Science and Technology</affiliation></author>
      <author><first>Dayeon</first><last>Ki</last><affiliation>Korea University</affiliation></author>
      <author><first>Cheonbok</first><last>Park</last><affiliation>NAVER Corp,</affiliation></author>
      <author><first>Hyoung-Gyu</first><last>Lee</last><affiliation>NAVER Corp.</affiliation></author>
      <author><first>Jaegul</first><last>Choo</last><affiliation>KAIST</affiliation></author>
      <pages>4839-4855</pages>
      <abstract>Lexically-constrained NMT (LNMT) aims to incorporate user-provided terminology into translations. Despite its practical advantages, existing work has not evaluated LNMT models under challenging real-world conditions. In this paper, we focus on two important but understudied issues that lie in the current evaluation process of LNMT studies. The model needs to cope with challenging lexical constraints that are “homographs” or “unseen” during training. To this end, we first design a homograph disambiguation module to differentiate the meanings of homographs. Moreover, we propose PLUMCOT which integrates contextually rich information about unseen lexical constraints from pre-trained language models and strengthens a copy mechanism of the pointer network via direct supervision of a copying score. We also release HOLLY, an evaluation benchmark for assessing the ability of model to cope with “homographic” and “unseen” lexical constraints. Experiments on HOLLY and the previous test setup show the effectiveness of our method. The effects of PLUMCOT are shown to be remarkable in “unseen” constraints. Our dataset is available at <url>https://github.com/papago-lab/HOLLY-benchmark</url>.</abstract>
      <url hash="183aa634">2023.findings-acl.298</url>
      <bibkey>baek-etal-2023-towards</bibkey>
      <doi>10.18653/v1/2023.findings-acl.298</doi>
    </paper>
    <paper id="299">
      <title><fixed-case>N</fixed-case>oisywiki<fixed-case>H</fixed-case>ow: A Benchmark for Learning with Real-world Noisy Labels in Natural Language Processing</title>
      <author><first>Tingting</first><last>Wu</last><affiliation>Harbin Institute of Technology</affiliation></author>
      <author><first>Xiao</first><last>Ding</last><affiliation>Harbin Institute of Technology</affiliation></author>
      <author><first>Minji</first><last>Tang</last><affiliation>Harbin Institute of Technology</affiliation></author>
      <author><first>Hao</first><last>Zhang</last><affiliation>Harbin Institute of Technology</affiliation></author>
      <author><first>Bing</first><last>Qin</last><affiliation>Harbin Institute of Technology</affiliation></author>
      <author><first>Ting</first><last>Liu</last><affiliation>Harbin Institute of Technology</affiliation></author>
      <pages>4856-4873</pages>
      <abstract>Large-scale datasets in the real world inevitably involve label noise. Deep models can gradually overfit noisy labels and thus degrade model generalization. To mitigate the effects of label noise, learning with noisy labels (LNL) methods are designed to achieve better generalization performance. Due to the lack of suitable datasets, previous studies have frequently employed synthetic label noise to mimic real-world label noise. However, synthetic noise is not instance-dependent, making this approximation not always effective in practice. Recent research has proposed benchmarks for learning with real-world noisy labels. However, the noise sources within may be single or fuzzy, making benchmarks different from data with heterogeneous label noises in the real world. To tackle these issues, we contribute NoisywikiHow, the largest NLP benchmark built with minimal supervision. Specifically, inspired by human cognition, we explicitly construct multiple sources of label noise to imitate human errors throughout the annotation, replicating real-world noise, whose corruption is affected by both ground-truth labels and instances. Moreover, we provide a variety of noise levels to support controlled experiments on noisy data, enabling us to evaluate LNL methods systematically and comprehensively. After that, we conduct extensive multi-dimensional experiments on a broad range of LNL methods, obtaining new and intriguing findings.</abstract>
      <url hash="e0b6c537">2023.findings-acl.299</url>
      <bibkey>wu-etal-2023-noisywikihow</bibkey>
      <doi>10.18653/v1/2023.findings-acl.299</doi>
    </paper>
    <paper id="300">
      <title>Sampling Better Negatives for Distantly Supervised Named Entity Recognition</title>
      <author><first>Lu</first><last>Xu</last><affiliation>None</affiliation></author>
      <author><first>Lidong</first><last>Bing</last><affiliation>Alibaba DAMO Academy</affiliation></author>
      <author><first>Wei</first><last>Lu</last><affiliation>Singapore University of Technology and Design</affiliation></author>
      <pages>4874-4882</pages>
      <abstract>Distantly supervised named entity recognition (DS-NER) has been proposed to exploit the automatically labeled training data instead of human annotations. The distantly annotated datasets are often noisy and contain a considerable number of false negatives. The recent approach uses a weighted sampling approach to select a subset of negative samples for training. However, it requires a good classifier to assign weights to the negative samples. In this paper, we propose a simple and straightforward approach for selecting the top negative samples that have high similarities with all the positive samples for training. Our method achieves consistent performance improvements on four distantly supervised NER datasets. Our analysis also shows that it is critical to differentiate the true negatives from the false negatives.</abstract>
      <url hash="730c008b">2023.findings-acl.300</url>
      <bibkey>xu-etal-2023-sampling</bibkey>
      <doi>10.18653/v1/2023.findings-acl.300</doi>
    </paper>
    <paper id="301">
      <title>Prototype-Based Interpretability for Legal Citation Prediction</title>
      <author><first>Chu Fei</first><last>Luo</last><affiliation>Queen’s University</affiliation></author>
      <author><first>Rohan</first><last>Bhambhoria</last><affiliation>Queen’s University</affiliation></author>
      <author><first>Samuel</first><last>Dahan</last><affiliation>Queen’s</affiliation></author>
      <author><first>Xiaodan</first><last>Zhu</last><affiliation>Queen’s University</affiliation></author>
      <pages>4883-4898</pages>
      <abstract>Deep learning has made significant progress in the past decade, and demonstrates potential to solve problems with extensive social impact. In high-stakes decision making areas such as law, experts often require interpretability for automatic systems to be utilized in practical settings. In this work, we attempt to address these requirements applied to the important problem of legal citation prediction (LCP). We design the task with parallels to the thought-process of lawyers, i.e., with reference to both precedents and legislative provisions. After initial experimental results, we refine the target citation predictions with the feedback of legal experts. Additionally, we introduce a prototype architecture to add interpretability, achieving strong performance while adhering to decision parameters used by lawyers. Our study builds on and leverages the state-of-the-art language processing models for law, while addressing vital considerations for high-stakes tasks with practical societal impact.</abstract>
      <url hash="5b291e89">2023.findings-acl.301</url>
      <bibkey>luo-etal-2023-prototype</bibkey>
      <doi>10.18653/v1/2023.findings-acl.301</doi>
    </paper>
    <paper id="302">
      <title><fixed-case>LM</fixed-case>s stand their Ground: Investigating the Effect of Embodiment in Figurative Language Interpretation by Language Models</title>
      <author><first>Philipp</first><last>Wicke</last><affiliation>Institute for Information and Language Processing, LMU</affiliation></author>
      <pages>4899-4913</pages>
      <abstract>Figurative language is a challenge for language models since its interpretation is based on the use of words in a way that deviates from their conventional order and meaning. Yet, humans can easily understand and interpret metaphors, similes or idioms as they can be derived from embodied metaphors. Language is a proxy for embodiment and if a metaphor is conventional and lexicalised, it becomes easier for a system without a body to make sense of embodied concepts. Yet, the intricate relation between embodiment and features such as concreteness or age of acquisition has not been studied in the context of figurative language interpretation concerning language models. Hence, the presented study shows how larger language models perform better at interpreting metaphoric sentences when the action of the metaphorical sentence is more embodied. The analysis rules out multicollinearity with other features (e.g. word length or concreteness) and provides initial evidence that larger language models conceptualise embodied concepts to a degree that facilitates figurative language understanding.</abstract>
      <url hash="e8d3fffc">2023.findings-acl.302</url>
      <bibkey>wicke-2023-lms</bibkey>
      <doi>10.18653/v1/2023.findings-acl.302</doi>
    </paper>
    <paper id="303">
      <title>Making Better Use of Training Corpus: Retrieval-based Aspect Sentiment Triplet Extraction via Label Interpolation</title>
      <author><first>Guoxin</first><last>Yu</last><affiliation>Institute of Computing Technology, Chinese Academy of Sciences</affiliation></author>
      <author><first>Lemao</first><last>Liu</last><affiliation>Tencent AI Lab</affiliation></author>
      <author><first>Haiyun</first><last>Jiang</last><affiliation>Tencent AI Lab</affiliation></author>
      <author><first>Shuming</first><last>Shi</last><affiliation>Tencent AI Lab</affiliation></author>
      <author><first>Xiang</first><last>Ao</last><affiliation>Institute of Computing Technology, Chinese Academy of Sciences</affiliation></author>
      <pages>4914-4927</pages>
      <abstract>In this paper, we aim to adapt the idea of retrieval-based neural approaches to the Aspect Sentiment Triplet Extraction (ASTE) task. Different from previous studies retrieving semantic similar neighbors, the ASTE task has its specialized challenges when adapting, i.e., the purpose includes predicting the sentiment polarity and it is usually aspect-dependent. Semantic similar neighbors with different polarities will be infeasible even counterproductive. To tackle this issue, we propose a retrieval-based neural ASTE approach, named RLI (Retrieval-based Aspect Sentiment Triplet Extraction via Label Interpolation), which exploits the label information of neighbors. Given an aspect-opinion term pair, we retrieve semantic similar triplets from the training corpus and interpolate their label information into the augmented representation of the target pair. The retriever is jointly trained with the whole ASTE framework, and neighbors with both similar semantics and sentiments can be recalled with the aid of this distant supervision. In addition, we design a simple yet effective pre-train method for the retriever that implicitly encodes the label similarities. Extensive experiments and analysis on two widely-used benchmarks show that the proposed model establishes a new state-of-the-art on ASTE.</abstract>
      <url hash="7e18c81f">2023.findings-acl.303</url>
      <bibkey>yu-etal-2023-making</bibkey>
      <doi>10.18653/v1/2023.findings-acl.303</doi>
    </paper>
    <paper id="304">
      <title>Multi-Domain Dialogue State Tracking with Disentangled Domain-Slot Attention</title>
      <author><first>Longfei</first><last>Yang</last><affiliation>Tokyo Institute of Technology</affiliation></author>
      <author><first>Jiyi</first><last>Li</last><affiliation>University of Yamanashi</affiliation></author>
      <author><first>Sheng</first><last>Li</last><affiliation>National Institute of Information and Communications Technology (NICT), Advanced Speech Technology Laboratory</affiliation></author>
      <author><first>Takahiro</first><last>Shinozaki</last><affiliation>Tokyo Institute of Technology</affiliation></author>
      <pages>4928-4938</pages>
      <abstract>As the core of task-oriented dialogue systems, dialogue state tracking (DST) is designed to track the dialogue state through the conversation between users and systems. Multi-domain DST has been an important challenge in which the dialogue states across multiple domains need to consider. In recent mainstream approaches, each domain and slot are aggregated and regarded as a single query feeding into attention with the dialogue history to obtain domain-slot specific representations. In this work, we propose disentangled domain-slot attention for multi-domain dialogue state tracking. The proposed approach disentangles the domain-slot specific information extraction in a flexible and context-dependent manner by separating the query about domains and slots in the attention component. Through a series of experiments on MultiWOZ 2.0 and MultiWOZ 2.4 datasets, we demonstrate that our proposed approach outperforms the standard multi-head attention with aggregated domain-slot query.</abstract>
      <url hash="932aceee">2023.findings-acl.304</url>
      <bibkey>yang-etal-2023-multi</bibkey>
      <doi>10.18653/v1/2023.findings-acl.304</doi>
    </paper>
    <paper id="305">
      <title>Improved Visual Story Generation with Adaptive Context Modeling</title>
      <author><first>Zhangyin</first><last>Feng</last><affiliation>Harbin Institute of Technology</affiliation></author>
      <author><first>Yuchen</first><last>Ren</last><affiliation>Renmin University of China</affiliation></author>
      <author><first>Xinmiao</first><last>Yu</last><affiliation>Harbin Institute of Technology</affiliation></author>
      <author><first>Xiaocheng</first><last>Feng</last><affiliation>Harbin Institute of Technology,SCIR lab</affiliation></author>
      <author><first>Duyu</first><last>Tang</last><affiliation>Tencent</affiliation></author>
      <author><first>Shuming</first><last>Shi</last><affiliation>Tencent AI Lab</affiliation></author>
      <author><first>Bing</first><last>Qin</last><affiliation>Harbin Institute of Technology</affiliation></author>
      <pages>4939-4955</pages>
      <abstract>Diffusion models developed on top of powerful text-to-image generation models like Stable Diffusion achieve remarkable success in visual story generation. However, the best-performing approach considers historically generated results as flattened memory cells, ignoring the fact that not all preceding images contribute equally to the generation of the characters and scenes at the current stage. To address this, we present a simple method that improves the leading system with adaptive context modeling, which is not only incorporated in the encoder but also adopted as additional guidance in the sampling stage to boost the global consistency of the generated story. We evaluate our model on PororoSV and FlintstonesSV datasets and show that our approach achieves state-of-the-art FID scores on both story visualization and continuation scenarios. We conduct detailed model analysis and show that our model excels at generating semantically consistent images for stories.</abstract>
      <url hash="30ae61ce">2023.findings-acl.305</url>
      <bibkey>feng-etal-2023-improved</bibkey>
      <doi>10.18653/v1/2023.findings-acl.305</doi>
    </paper>
    <paper id="306">
      <title>Question-Interlocutor Scope Realized Graph Modeling over Key Utterances for Dialogue Reading Comprehension</title>
      <author><first>Jiangnan</first><last>Li</last><affiliation>Institute of Information Engineering, Chinese Academy of Sciences</affiliation></author>
      <author><first>Mo</first><last>Yu</last><affiliation>Tencent Inc.</affiliation></author>
      <author><first>Fandong</first><last>Meng</last><affiliation>WeChat AI, Tencent</affiliation></author>
      <author><first>Zheng</first><last>Lin</last><affiliation>Institute of Information Engineering, Chinese Academy of Sciences</affiliation></author>
      <author><first>Peng</first><last>Fu</last><affiliation>Institute of Information Engineering, Chinese Academy of Sciences</affiliation></author>
      <author><first>Weiping</first><last>Wang</last><affiliation>Institute of Information Engineering, Chinese Academy of Sciences</affiliation></author>
      <author><first>Jie</first><last>Zhou</last><affiliation>Tencent Inc.</affiliation></author>
      <pages>4956-4968</pages>
      <abstract>We focus on dialogue reading comprehension (DRC) that extracts answers from dialogues. Compared to standard RC tasks, DRC has raised challenges because of the complex speaker information and noisy dialogue context. Essentially, the challenges come from the speaker-centric nature of dialogue utterances — an utterance is usually insufficient in its surface form, but requires to incorporate the role of its speaker and the dialogue context to fill the latent pragmatic and intention information. We propose to deal with these problems in two folds. First, we propose a new key-utterances-extracting method, which can realize more answer-contained utterances. Second, based on the extracted utterances, we then propose a Question-Interlocutor Scope Realized Graph (QuISG). QuISG involves the question and question-mentioning speaker as nodes. To realize interlocutor scopes, utterances are connected with corresponding speakers in the dialogue. Experiments on the benchmarks show that our method achieves state-of-the-art performance against previous works.</abstract>
      <url hash="548de513">2023.findings-acl.306</url>
      <bibkey>li-etal-2023-question</bibkey>
      <doi>10.18653/v1/2023.findings-acl.306</doi>
    </paper>
    <paper id="307">
      <title>Speech-to-Speech Translation for a Real-world Unwritten Language</title>
      <author><first>Peng-Jen</first><last>Chen</last><affiliation>Meta Inc.</affiliation></author>
      <author><first>Kevin</first><last>Tran</last><affiliation>Meta AI</affiliation></author>
      <author><first>Yilin</first><last>Yang</last><affiliation>Meta AI</affiliation></author>
      <author><first>Jingfei</first><last>Du</last><affiliation>Facebook</affiliation></author>
      <author><first>Justine</first><last>Kao</last><affiliation>Meta AI</affiliation></author>
      <author><first>Yu-An</first><last>Chung</last><affiliation>Massachusetts Institute of Technology</affiliation></author>
      <author><first>Paden</first><last>Tomasello</last><affiliation>Facebook</affiliation></author>
      <author><first>Paul-Ambroise</first><last>Duquenne</last><affiliation>Meta AI</affiliation></author>
      <author><first>Holger</first><last>Schwenk</last><affiliation>Facebook Artificial Intelligence Research</affiliation></author>
      <author><first>Hongyu</first><last>Gong</last><affiliation>Facebook AI Research</affiliation></author>
      <author><first>Hirofumi</first><last>Inaguma</last><affiliation>Meta AI</affiliation></author>
      <author><first>Sravya</first><last>Popuri</last><affiliation>Meta</affiliation></author>
      <author><first>Changhan</first><last>Wang</last><affiliation>Meta - Fundamental AI Research (FAIR)</affiliation></author>
      <author><first>Juan</first><last>Pino</last><affiliation>Facebook</affiliation></author>
      <author><first>Wei-Ning</first><last>Hsu</last><affiliation>Facebook</affiliation></author>
      <author><first>Ann</first><last>Lee</last><affiliation>Meta AI</affiliation></author>
      <pages>4969-4983</pages>
      <abstract>We study speech-to-speech translation (S2ST) that translates speech from one language into another language and focuses on building systems to support languages without standard text writing systems. We use English-Taiwanese Hokkien as a case study, and present an end-to-end solution from training data collection, modeling choices to benchmark dataset release. First, we present efforts on creating human annotated data, automatically mining data from large unlabeled speech datasets, and adopting pseudo-labeling to produce weakly supervised data. On the modeling, we take advantage of recent advances in applying self-supervised discrete representations as target for prediction in S2ST and show the effectiveness of leveraging additional text supervision from Mandarin, a language similar to Hokkien, in model training. Finally, we release an S2ST benchmark set to facilitate future research in this field.</abstract>
      <url hash="a0709d2a">2023.findings-acl.307</url>
      <bibkey>chen-etal-2023-speech</bibkey>
      <doi>10.18653/v1/2023.findings-acl.307</doi>
    </paper>
    <paper id="308">
      <title>Code Execution with Pre-trained Language Models</title>
      <author><first>Chenxiao</first><last>Liu</last><affiliation>Peking University</affiliation></author>
      <author><first>Shuai</first><last>Lu</last><affiliation>Microsoft</affiliation></author>
      <author><first>Weizhu</first><last>Chen</last><affiliation>Microsoft</affiliation></author>
      <author><first>Daxin</first><last>Jiang</last><affiliation>STCA, Microsoft</affiliation></author>
      <author><first>Alexey</first><last>Svyatkovskiy</last><affiliation>Microsoft</affiliation></author>
      <author><first>Shengyu</first><last>Fu</last><affiliation>Microsoft Corp.</affiliation></author>
      <author><first>Neel</first><last>Sundaresan</last><affiliation>Microsoft Corp.</affiliation></author>
      <author><first>Nan</first><last>Duan</last><affiliation>Microsoft Research Asia</affiliation></author>
      <pages>4984-4999</pages>
      <abstract>Code execution is a fundamental aspect of programming language semantics that reflects the exact behavior of the code. However, most pre-trained models for code intelligence ignore the execution trace and only rely on source code and syntactic structures. In this paper, we investigate how well pre-trained models can understand and perform code execution. We develop a mutation-based data augmentation technique to create a large-scale and realistic Python dataset and task for code execution, which challenges existing models such as Codex. We then present CodeExecutor, a Transformer model that leverages code execution pre-training and curriculum learning to enhance its semantic comprehension. We evaluate CodeExecutor on code execution and show its promising performance and limitations. We also demonstrate its potential benefits for code intelligence tasks such as zero-shot code-to-code search and text-to-code generation. Our analysis provides insights into the learning and generalization abilities of pre-trained models for code execution.</abstract>
      <url hash="d213ab2d">2023.findings-acl.308</url>
      <bibkey>liu-etal-2023-code</bibkey>
      <doi>10.18653/v1/2023.findings-acl.308</doi>
    </paper>
    <paper id="309">
      <title><fixed-case>B</fixed-case>ert<fixed-case>N</fixed-case>et: Harvesting Knowledge Graphs with Arbitrary Relations from Pretrained Language Models</title>
      <author><first>Shibo</first><last>Hao</last><affiliation>UC San Diego</affiliation></author>
      <author><first>Bowen</first><last>Tan</last><affiliation>Carnegie Mellon University</affiliation></author>
      <author><first>Kaiwen</first><last>Tang</last><affiliation>University of Singapore</affiliation></author>
      <author><first>Bin</first><last>Ni</last><affiliation>University of California, San Diego</affiliation></author>
      <author><first>Xiyan</first><last>Shao</last><affiliation>UCSD</affiliation></author>
      <author><first>Hengzhe</first><last>Zhang</last><affiliation>VUW</affiliation></author>
      <author><first>Eric</first><last>Xing</last><affiliation>Carnegie Mellon University</affiliation></author>
      <author><first>Zhiting</first><last>Hu</last><affiliation>UC San Diego</affiliation></author>
      <pages>5000-5015</pages>
      <abstract>It is crucial to automatically construct knowledge graphs (KGs) of diverse new relations to support knowledge discovery and broad applications. Previous KG construction methods, based on either crowdsourcing or text mining, are often limited to a small predefined set of relations due to manual cost or restrictions in text corpus. Recent research proposed to use pretrained language models (LMs) as implicit knowledge bases that accept knowledge queries with prompts. Yet, the implicit knowledge lacks many desirable properties of a full-scale symbolic KG, such as easy access, navigation, editing, and quality assurance. In this paper, we propose a new approach of harvesting massive KGs of arbitrary relations from pretrained LMs. With minimal input of a relation definition (a prompt and a few shot of example entity pairs), the approach efficiently searches in the vast entity pair space to extract diverse accurate knowledge of the desired relation. We develop an effective search-and-rescore mechanism for improved efficiency and accuracy. We deploy the approach to harvest KGs of over 400 new relations, from LMs of varying capacities such as RoBERTaNet. Extensive human and automatic evaluations show our approach manages to extract diverse accurate knowledge, including tuples of complex relations (e.g., “A is capable of but not good at B”). The resulting KGs as a symbolic interpretation of the source LMs also reveal new insights into the LMs’ knowledge capacities.</abstract>
      <url hash="b166fcad">2023.findings-acl.309</url>
      <bibkey>hao-etal-2023-bertnet</bibkey>
      <doi>10.18653/v1/2023.findings-acl.309</doi>
    </paper>
    <paper id="310">
      <title>Sequential Path Signature Networks for Personalised Longitudinal Language Modeling</title>
      <author><first>Talia</first><last>Tseriotou</last><affiliation>Queen Mary University of London</affiliation></author>
      <author><first>Adam</first><last>Tsakalidis</last><affiliation>Queen Mary University of London</affiliation></author>
      <author><first>Peter</first><last>Foster</last><affiliation>The Alan Turing Institute</affiliation></author>
      <author><first>Terence</first><last>Lyons</last><affiliation>University of Oxford</affiliation></author>
      <author><first>Maria</first><last>Liakata</last><affiliation>Queen Mary University of London</affiliation></author>
      <pages>5016-5031</pages>
      <abstract>Longitudinal user modeling can provide a strong signal for various downstream tasks. Despite the rapid progress in representation learning, dynamic aspects of modelling individuals’ language have only been sparsely addressed. We present a novel extension of neural sequential models using the notion of path signatures from rough path theory, which constitute graduated summaries of continuous paths and have the ability to capture non-linearities in trajectories. By combining path signatures of users’ history with contextual neural representations and recursive neural networks we can produce compact time-sensitive user representations. Given the magnitude of mental health conditions with symptoms manifesting in language, we show the applicability of our approach on the task of identifying changes in individuals’ mood by analysing their online textual content. By directly integrating signature transforms of users’ history in the model architecture we jointly address the two most important aspects of the task, namely sequentiality and temporality. Our approach achieves state-of-the-art performance on macro-average F1 score on the two available datasets for the task, outperforming or performing on-par with state-of-the-art models utilising only historical posts and even outperforming prior models which also have access to future posts of users.</abstract>
      <url hash="83375c05">2023.findings-acl.310</url>
      <bibkey>tseriotou-etal-2023-sequential</bibkey>
      <doi>10.18653/v1/2023.findings-acl.310</doi>
    </paper>
    <paper id="311">
      <title>A Multi-modal Debiasing Model with Dynamical Constraint for Robust Visual Question Answering</title>
      <author><first>Yu</first><last>Li</last><affiliation>Beijing Jiaotong University</affiliation></author>
      <author><first>Bojie</first><last>Hu</last><affiliation>Tencent</affiliation></author>
      <author><first>Fengshuo</first><last>Zhang</last><affiliation>Beijing Jiaotong University</affiliation></author>
      <author><first>Yahan</first><last>Yu</last><affiliation>Tencent</affiliation></author>
      <author><first>Jian</first><last>Liu</last><affiliation>Beijing Jiaotong University</affiliation></author>
      <author><first>Yufeng</first><last>Chen</last><affiliation>Beijing Jiaotong University</affiliation></author>
      <author><first>Jinan</first><last>Xu</last><affiliation>Beijing Jiaotong University</affiliation></author>
      <pages>5032-5045</pages>
      <abstract>Recent studies have pointed out that many well-developed Visual Question Answering (VQA) systems suffer from bias problem. Despite the remarkable performance gained on In-Distribution (ID) datasets, the VQA model might merely capture the superficial correlation from question to answer rather than showing real reasoning abilities. Therefore, when switching to Out-of-Distribution (OOD) dataset, whose test distribution is unknown or even reversed with the training set, significant drops might be demonstrated. Although efforts have been devoted to easing the negative bias effect brought by language prior and analysing its inherent cause, they are still limited by the following two aspects. First, most current debiasing methods achieve promising OOD generalization ability with a major sacrifice of the ID performance. Second, existing researches are restricted by exploiting comprehensive biases, since weakening the language bias is mainly focused, while only a few works consider vision bias. In this paper, we investigate a straightforward way to mitigate bias problem for VQA task. Specifically, we reduce bias effect by subtracting bias score from standard VQA base score. Based on such a direct strategy, we design two bias learning branches to detect more bias information, which are combined with a dynamical constraint loss to alleviate the problem of over-correction and insufficient debiasing effect. We evaluate our method on the challenging VQA v2.0 and VQA-CP V2,0 datasets and the proposed method achievessignificant improvement.</abstract>
      <url hash="2198d2bb">2023.findings-acl.311</url>
      <bibkey>li-etal-2023-multi-modal-debiasing</bibkey>
      <doi>10.18653/v1/2023.findings-acl.311</doi>
    </paper>
    <paper id="312">
      <title>Trigger-Argument based Explanation for Event Detection</title>
      <author><first>Yong</first><last>Guan</last><affiliation>Tsinghua University</affiliation></author>
      <author><first>Jiaoyan</first><last>Chen</last><affiliation>The University of Manchester</affiliation></author>
      <author><first>Freddy</first><last>Lecue</last><affiliation>Inria</affiliation></author>
      <author><first>Jeff</first><last>Pan</last><affiliation>University of Edinburgh</affiliation></author>
      <author><first>Juanzi</first><last>Li</last><affiliation>Tsinghua University</affiliation></author>
      <author><first>Ru</first><last>Li</last><affiliation>School of Computer and Information Technology,Shanxi University</affiliation></author>
      <pages>5046-5058</pages>
      <abstract>Event Detection (ED) is a critical task that aims to identify events of certain types in plain text. Neural models have achieved great success on ED, thus coming with a desire for higher interpretability. Existing works mainly exploit words or phrases of the input text to explain models’ inner mechanisms. However, for ED, the event structure, comprising of an event trigger and a set of arguments, are more enlightening clues to explain model behaviors. To this end, we propose a Trigger-Argument based Explanation method (TAE), which can utilize event structure knowledge to uncover a faithful interpretation for the existing ED models at neuron level. Specifically, we design group, sparsity, support mechanisms to construct the event structure from structuralization, compactness, and faithfulness perspectives. We evaluate our model on the large-scale MAVEN and the widely-used ACE 2005 datasets, and observe that TAE is able to reveal the process by which the model predicts. Experimental results also demonstrate that TAE can not only improve the interpretability on standard evaluation metrics, but also effectively facilitate the human understanding.</abstract>
      <url hash="0397d6be">2023.findings-acl.312</url>
      <bibkey>guan-etal-2023-trigger</bibkey>
      <doi>10.18653/v1/2023.findings-acl.312</doi>
    </paper>
    <paper id="313">
      <title>Interactive Concept Learning for Uncovering Latent Themes in Large Text Collections</title>
      <author><first>Maria Leonor</first><last>Pacheco</last><affiliation>University of Colorado Boulder / Microsoft Research</affiliation></author>
      <author><first>Tunazzina</first><last>Islam</last><affiliation>Purdue University</affiliation></author>
      <author><first>Lyle</first><last>Ungar</last><affiliation>University of Pennsylvania</affiliation></author>
      <author><first>Ming</first><last>Yin</last><affiliation>Purdue University</affiliation></author>
      <author><first>Dan</first><last>Goldwasser</last><affiliation>Purdue University</affiliation></author>
      <pages>5059-5080</pages>
      <abstract>Experts across diverse disciplines are often interested in making sense of large text collections. Traditionally, this challenge is approached either by noisy unsupervised techniques such as topic models, or by following a manual theme discovery process. In this paper, we expand the definition of a theme to account for more than just a word distribution, and include generalized concepts deemed relevant by domain experts. Then, we propose an interactive framework that receives and encodes expert feedback at different levels of abstraction. Our framework strikes a balance between automation and manual coding, allowing experts to maintain control of their study while reducing the manual effort required.</abstract>
      <url hash="1afc5b5d">2023.findings-acl.313</url>
      <bibkey>pacheco-etal-2023-interactive</bibkey>
      <doi>10.18653/v1/2023.findings-acl.313</doi>
    </paper>
    <paper id="314">
      <title><fixed-case>N</fixed-case>orm<fixed-case>M</fixed-case>ark: A Weakly Supervised <fixed-case>M</fixed-case>arkov Model for Socio-cultural Norm Discovery</title>
      <author><first>Farhad</first><last>Moghimifar</last><affiliation>Monash University</affiliation></author>
      <author><first>Shilin</first><last>Qu</last><affiliation>Monash University</affiliation></author>
      <author><first>Tongtong</first><last>Wu</last><affiliation>Monash University</affiliation></author>
      <author><first>Yuan-Fang</first><last>Li</last><affiliation>Monash University</affiliation></author>
      <author><first>Gholamreza</first><last>Haffari</last><affiliation>Monash University</affiliation></author>
      <pages>5081-5089</pages>
      <abstract>Norms, which are culturally accepted guidelines for behaviours, can be integrated into conversational models to generate utterances that are appropriate for the socio-cultural context. Existing methods for norm recognition tend to focus only on surface-level features of dialogues and do not take into account the interactions within a conversation. To address this issue, we propose NormMark, a probabilistic generative Markov model to carry the latent features throughout a dialogue. These features are captured by discrete and continuous latent variables conditioned on the conversation history, and improve the model’s ability in norm recognition. The model is trainable on weakly annotated data using the variational technique. On a dataset with limited norm annotations, we show that our approach achieves higher F1 score, outperforming current state-of-the-art methods, including GPT3.</abstract>
      <url hash="5a29f6c8">2023.findings-acl.314</url>
      <bibkey>moghimifar-etal-2023-normmark</bibkey>
      <doi>10.18653/v1/2023.findings-acl.314</doi>
    </paper>
    <paper id="315">
      <title><fixed-case>V</fixed-case>ote<fixed-case>TRANS</fixed-case>: Detecting Adversarial Text without Training by Voting on Hard Labels of Transformations</title>
      <author><first>Hoang-Quoc</first><last>Nguyen-Son</last><affiliation>KDDI Research Inc.</affiliation></author>
      <author><first>Seira</first><last>Hidano</last><affiliation>KDDI Research, Inc.</affiliation></author>
      <author><first>Kazuhide</first><last>Fukushima</last><affiliation>KDDI Research, Inc.</affiliation></author>
      <author><first>Shinsaku</first><last>Kiyomoto</last><affiliation>KDDI Research Inc.</affiliation></author>
      <author><first>Isao</first><last>Echizen</last><affiliation>National Institute of Informatics</affiliation></author>
      <pages>5090-5104</pages>
      <abstract>Adversarial attacks reveal serious flaws in deep learning models. More dangerously, these attacks preserve the original meaning and escape human recognition. Existing methods for detecting these attacks need to be trained using original/adversarial data. In this paper, we propose detection without training by voting on hard labels from predictions of transformations, namely, VoteTRANS. Specifically, VoteTRANS detects adversarial text by comparing the hard labels of input text and its transformation. The evaluation demonstrates that VoteTRANS effectively detects adversarial text across various state-of-the-art attacks, models, and datasets.</abstract>
      <url hash="10b0ed14">2023.findings-acl.315</url>
      <bibkey>nguyen-son-etal-2023-votetrans</bibkey>
      <doi>10.18653/v1/2023.findings-acl.315</doi>
    </paper>
    <paper id="316">
      <title>Fusion or Defusion? Flexible Vision-and-Language Pre-Training</title>
      <author><first>Rongyi</first><last>Sun</last><affiliation>Tsinghua Shenzhen International Graduate School, Tsinghua University</affiliation></author>
      <author><first>Ziran</first><last>Li</last><affiliation>Meituan</affiliation></author>
      <author><first>Yifeng</first><last>Ding</last><affiliation>Tsinghua University</affiliation></author>
      <author><first>Qifan</first><last>Wang</last><affiliation>Meta AI</affiliation></author>
      <author><first>Jingang</first><last>Wang</last><affiliation>Meituan</affiliation></author>
      <author><first>Haitao</first><last>Zheng</last><affiliation>Tsinghua University, Shenzhen International Graduate School.</affiliation></author>
      <author><first>Wei</first><last>Wu</last><affiliation/></author>
      <author><first>Yunsen</first><last>Xian</last><affiliation>Meituan</affiliation></author>
      <pages>5105-5119</pages>
      <abstract>Existing approaches in the vision-and-language pre-training (VLP) paradigm mainly deploy either fusion-based encoders or dual-encoders, failing to achieve both effectiveness and efficiency in downstream multimodal tasks. In this paper, we build a flexible VLP model by incorporating cross-modal fusions into a dual-encoder architecture, where the introduced fusion modules can be easily decoupled from the dual encoder so as to switch the model to a fusion-free one. To better absorb cross-modal features from the fusion modules, we design a cross-modal knowledge transfer strategy along with other comprehensive pre-training tasks to guide the training process, which can further strengthen both the fusion-based and fusion-free representation learning. Extensive experiments conducted on various downstream vision-language tasks show that our proposed model is well-equipped with effectiveness as well as efficiency, demonstrating a superior performance compared with other strong VLP models.</abstract>
      <url hash="7b42b717">2023.findings-acl.316</url>
      <bibkey>sun-etal-2023-fusion</bibkey>
      <doi>10.18653/v1/2023.findings-acl.316</doi>
    </paper>
    <paper id="317">
      <title><fixed-case>COCKATIEL</fixed-case>: <fixed-case>CO</fixed-case>ntinuous Concept ran<fixed-case>K</fixed-case>ed <fixed-case>AT</fixed-case>tribution with Interpretable <fixed-case>EL</fixed-case>ements for explaining neural net classifiers on <fixed-case>NLP</fixed-case></title>
      <author><first>Fanny</first><last>Jourdan</last><affiliation>IRIT Institut de Recherche en Informatique de Toulouse</affiliation></author>
      <author><first>Agustin</first><last>Picard</last><affiliation>IRT Saint-Exupery</affiliation></author>
      <author><first>Thomas</first><last>Fel</last><affiliation>ANITI, Brown University</affiliation></author>
      <author><first>Laurent</first><last>Risser</last><affiliation>CNRS, Institut de Mathematiques de Toulouse</affiliation></author>
      <author><first>Jean-Michel</first><last>Loubes</last><affiliation>Université Toulouse 3, Institut de Mathématiques</affiliation></author>
      <author><first>Nicholas</first><last>Asher</last><affiliation>CNRS Institut de Recherche en Informatique de Toulouse</affiliation></author>
      <pages>5120-5136</pages>
      <abstract>Transformer architectures are complex and their use in NLP, while it has engendered many successes, makes their interpretability or explainability challenging. Recent debates have shown that attention maps and attribution methods are unreliable (Pruthi et al., 2019; Brunner et al., 2019). In this paper, we present some of their limitations and introduce COCKATIEL, which successfully addresses some of them. COCKATIEL is a novel, post-hoc, concept-based, model-agnostic XAI technique that generates meaningful explanations from the last layer of a neural net model trained on an NLP classification task by using Non-Negative Matrix Factorization (NMF) to discover the concepts the model leverages to make predictions and by exploiting a Sensitivity Analysis to estimate accurately the importance of each of these concepts for the model. It does so without compromising the accuracy of the underlying model or requiring a new one to be trained. We conduct experiments in single and multi-aspect sentiment analysis tasks and we show COCKATIEL’s superior ability to discover concepts that align with humans’ on Transformer models without any supervision, we objectively verify the faithfulness of its explanations through fidelity metrics, and we showcase its ability to provide meaningful explanations in two different datasets. Our code is freely available: <url>https://github.com/fanny-jourdan/cockatiel</url></abstract>
      <url hash="def49af5">2023.findings-acl.317</url>
      <bibkey>jourdan-etal-2023-cockatiel</bibkey>
      <doi>10.18653/v1/2023.findings-acl.317</doi>
    </paper>
    <paper id="318">
      <title>Code-Switched Text Synthesis in Unseen Language Pairs</title>
      <author><first>I-Hung</first><last>Hsu</last><affiliation>USC Information Sciences Institute</affiliation></author>
      <author><first>Avik</first><last>Ray</last><affiliation>Amazon</affiliation></author>
      <author><first>Shubham</first><last>Garg</last><affiliation>Amazon.com</affiliation></author>
      <author><first>Nanyun</first><last>Peng</last><affiliation>University of California, Los Angeles</affiliation></author>
      <author><first>Jing</first><last>Huang</last><affiliation>Amazon</affiliation></author>
      <pages>5137-5151</pages>
      <abstract>Existing efforts on text synthesis for code-switching mostly require training on code-switched texts in the target language pairs, limiting the deployment of the models to cases lacking code-switched data. In this work, we study the problem of synthesizing code-switched texts for language pairs absent from the training data. We introduce GLOSS, a model built on top of a pre-trained multilingual machine translation model (PMMTM) with an additional code-switching module. This module, either an adapter or extra prefixes, learns code-switching patterns from code-switched data during training, while the primary component of GLOSS, i.e., the PMMTM, is frozen. The design of only adjusting the code-switching module prevents our model from overfitting to the constrained training data for code-switching. Hence, GLOSS exhibits the ability to generalize and synthesize code-switched texts across a broader spectrum of language pairs. Additionally, we develop a self-training algorithm on target language pairs further to enhance the reliability of GLOSS. Automatic evaluations on four language pairs show that GLOSS achieves at least 55% relative BLEU and METEOR scores improvements compared to strong baselines. Human evaluations on two language pairs further validate the success of GLOSS.</abstract>
      <url hash="d138bc12">2023.findings-acl.318</url>
      <bibkey>hsu-etal-2023-code</bibkey>
      <doi>10.18653/v1/2023.findings-acl.318</doi>
    </paper>
    <paper id="319">
      <title>Imagination is All You Need! Curved Contrastive Learning for Abstract Sequence Modeling Utilized on Long Short-Term Dialogue Planning</title>
      <author><first>Justus-Jonas</first><last>Erker</last><affiliation>Maastricht Univsersity</affiliation></author>
      <author><first>Stefan</first><last>Schaffer</last><affiliation>DFKI</affiliation></author>
      <author><first>Gerasimos</first><last>Spanakis</last><affiliation>Maastricht University</affiliation></author>
      <pages>5152-5173</pages>
      <abstract>Inspired by the curvature of space-time, we introduce Curved Contrastive Learning (CCL), a novel representation learning technique for learning the relative turn distance between utterance pairs in multi-turn dialogues. The resulting bi-encoder models can guide transformers as a response ranking model towards a goal in a zero-shot fashion by projecting the goal utterance and the corresponding reply candidates into a latent space. Here the cosine similarity indicates the distance/reachability of a candidate utterance toward the corresponding goal. Furthermore, we explore how these forward-entailing language representations can be utilized for assessing the likelihood of sequences by the entailment strength i.e. through the cosine similarity of its individual members (encoded separately) as an emergent property in the curved space. These non-local properties allow us to imagine the likelihood of future patterns in dialogues, specifically by ordering/identifying future goal utterances that are multiple turns away, given a dialogue context. As part of our analysis, we investigate characteristics that make conversations (un)plannable and find strong evidence of planning capability over multiple turns (in 61.56% over 3 turns) in conversations from the DailyDialog dataset. Finally, we show how we achieve higher efficiency in sequence modeling tasks compared to previous work thanks to our relativistic approach, where only the last utterance needs to be encoded and computed during inference.</abstract>
      <url hash="734c5e18">2023.findings-acl.319</url>
      <bibkey>erker-etal-2023-imagination</bibkey>
      <doi>10.18653/v1/2023.findings-acl.319</doi>
    </paper>
    <paper id="320">
      <title>Data-Efficient <fixed-case>F</fixed-case>rench Language Modeling with <fixed-case>C</fixed-case>amem<fixed-case>BERT</fixed-case>a</title>
      <author><first>Wissam</first><last>Antoun</last><affiliation>Inria</affiliation></author>
      <author><first>Benoît</first><last>Sagot</last><affiliation>Inria</affiliation></author>
      <author><first>Djamé</first><last>Seddah</last><affiliation>Inria</affiliation></author>
      <pages>5174-5185</pages>
      <abstract>Recent advances in NLP have significantly improved the performance of language models on a variety of tasks. While these advances are largely driven by the availability of large amounts of data and computational power, they also benefit from the development of better training methods and architectures. In this paper, we introduce CamemBERTa, a French DeBERTa model that builds upon the DeBERTaV3 architecture and training objective. We evaluate our model’s performance on a variety of French downstream tasks and datasets, including question answering, part-of-speech tagging, dependency parsing, named entity recognition, and the FLUE benchmark, and compare against CamemBERT, the state-of-the-art monolingual model for French. Our results show that, given the same amount of training tokens, our model outperforms BERT-based models trained with MLM on most tasks. Furthermore, our new model reaches similar or superior performance on downstream tasks compared to CamemBERT, despite being trained on only 30% of its total number of input tokens. In addition to our experimental results, we also publicly release the weights and code implementation of CamemBERTa, making it the first publicly available DeBERTaV3 model outside of the original paper and the first openly available implementation of a DeBERTaV3 training objective.</abstract>
      <url hash="ca5aa7fd">2023.findings-acl.320</url>
      <bibkey>antoun-etal-2023-data</bibkey>
      <doi>10.18653/v1/2023.findings-acl.320</doi>
    </paper>
    <paper id="321">
      <title>Coupling Large Language Models with Logic Programming for Robust and General Reasoning from Text</title>
      <author><first>Zhun</first><last>Yang</last><affiliation>Arizona State University</affiliation></author>
      <author><first>Adam</first><last>Ishay</last><affiliation>Arizona State University</affiliation></author>
      <author><first>Joohyung</first><last>Lee</last><affiliation>Arizona State University / Samsung Research</affiliation></author>
      <pages>5186-5219</pages>
      <abstract>While large language models (LLMs), such as GPT-3, appear to be robust and general, their reasoning ability is not at a level to compete with the best models trained for specific natural language reasoning problems. In this study, we observe that a large language model can serve as a highly effective few-shot semantic parser. It can convert natural language sentences into a logical form that serves as input for answer set programs, a logic-based declarative knowledge representation formalism. The combination results in a robust and general system that can handle multiple question-answering tasks without requiring retraining for each new task. It only needs a few examples to guide the LLM’s adaptation to a specific task, along with reusable ASP knowledge modules that can be applied to multiple tasks. We demonstrate that this method achieves state-of-the-art performance on several NLP benchmarks, including bAbI, StepGame, CLUTRR, and gSCAN. Additionally, it successfully tackles robot planning tasks that an LLM alone fails to solve.</abstract>
      <url hash="9712d4ef">2023.findings-acl.321</url>
      <bibkey>yang-etal-2023-coupling</bibkey>
      <doi>10.18653/v1/2023.findings-acl.321</doi>
    </paper>
    <paper id="322">
      <title>Evaluating the Factual Consistency of Large Language Models Through News Summarization</title>
      <author><first>Derek</first><last>Tam</last><affiliation>University of North Carolina at Chapel Hill</affiliation></author>
      <author><first>Anisha</first><last>Mascarenhas</last><affiliation>University of North Carolina at Chapel Hill</affiliation></author>
      <author><first>Shiyue</first><last>Zhang</last><affiliation>The University of North Carolina at Chapel Hill</affiliation></author>
      <author><first>Sarah</first><last>Kwan</last><affiliation>None</affiliation></author>
      <author><first>Mohit</first><last>Bansal</last><affiliation>University of North Carolina at Chapel Hill</affiliation></author>
      <author><first>Colin</first><last>Raffel</last><affiliation>University of North Carolina/Hugging Face</affiliation></author>
      <pages>5220-5255</pages>
      <abstract>While large language models (LLMs) have proven to be effective on a large variety of tasks, they are also known to hallucinate information. To measure whether an LLM prefers factually consistent continuations of its input, we propose a new benchmark called FIB (Factual Inconsistency Benchmark) that focuses on the task of summarization. Specifically, our benchmark involves comparing the scores an LLM assigns to a factually consistent versus a factually inconsistent summary for an input news article. For factually consistent summaries, we use human-written reference summaries that we manually verify as factually consistent. To generate summaries that are factually inconsistent, we generate summaries from a suite of summarization models that we have manually annotated as factually inconsistent. A model’s factual consistency is then measured according to its accuracy, i.e. the proportion of documents where it assigns a higher score to the factually consistent summary. To validate the usefulness of {pasted macro ‘BENCHMARK’}, we evaluate 23 large language models ranging from 1B to 176B parameters from six different model families including BLOOM and OPT. We find that existing LLMs generally assign a higher score to factually consistent summaries than to factually inconsistent summaries. However, if the factually inconsistent summaries occur verbatim in the document, then LLMs assign a higher score to these factually inconsistent summaries than factually consistent summaries. We validate design choices in our benchmark including the scoring method and source of distractor summaries.</abstract>
      <url hash="1cc3b1bd">2023.findings-acl.322</url>
      <bibkey>tam-etal-2023-evaluating</bibkey>
      <doi>10.18653/v1/2023.findings-acl.322</doi>
    </paper>
    <paper id="323">
      <title>Text Generation Model Enhanced with Semantic Information in Aspect Category Sentiment Analysis</title>
      <author><first>Tu</first><last>Tran</last><affiliation>Japan Advanced Institute of Science And Technology (JAIST)</affiliation></author>
      <author><first>Kiyoaki</first><last>Shirai</last><affiliation>Japan Advanced Institute of Science and Technology</affiliation></author>
      <author><first>Natthawut</first><last>Kertkeidkachorn</last><affiliation>Japan Advanced Institute of Science and Technology</affiliation></author>
      <pages>5256-5268</pages>
      <abstract>Aspect Category Sentiment Analysis (ACSA) is one of the main subtasks of sentiment analysis, which aims at predicting polarity over a given aspect category. Recently, generative methods emerge as an efficient way to utilize a pre-trained language model for solving ACSA. However, those methods fail to model relations of target words and opinion words in a sentence including multiple aspects. To tackle this problem, this paper proposes a method to incorporate Abstract Meaning Representation (AMR), which describes semantic representation of a sentence as a directed graph, into a text generation model. Furthermore, two regularizers are designed to guide cross attention weights allocation over AMR graphs. One is the identical regularizer that constrains attention weights of aligned nodes, the other is the entropy regularizer that helps the decoder generate tokens by heavily considering only a few related nodes in the AMR graph. Experimental results on three datasets show that the proposed method outperforms state-of-the-art methods, proving the effectiveness of our model.</abstract>
      <url hash="97d681c7">2023.findings-acl.323</url>
      <bibkey>tran-etal-2023-text</bibkey>
      <doi>10.18653/v1/2023.findings-acl.323</doi>
    </paper>
    <paper id="324">
      <title>Mind the Biases: Quantifying Cognitive Biases in Language Model Prompting</title>
      <author><first>Ruixi</first><last>Lin</last><affiliation>National University of Singapore</affiliation></author>
      <author><first>Hwee Tou</first><last>Ng</last><affiliation>National University of Singapore</affiliation></author>
      <pages>5269-5281</pages>
      <abstract>We advocate the importance of exposing uncertainty on results of language model prompting which display bias modes resembling cognitive biases, and propose to help users grasp the level of uncertainty via simple quantifying metrics. Cognitive biases in the human decision making process can lead to flawed responses when we are under uncertainty. Not surprisingly, we have seen biases in language models resembling cognitive biases as a result of training on biased textual data, raising dangers in downstream tasks that are centered around people’s lives if users trust their results too much. In this work, we reveal two bias modes leveraging cognitive biases when we prompt BERT, accompanied by two bias metrics. On a drug-drug interaction extraction task, our bias measurements reveal an error pattern similar to the availability bias when the labels for training prompts are imbalanced, and show that a toning-down transformation of the drug-drug description in a prompt can elicit a bias similar to the framing effect, warning users to distrust when prompting language models for answers.</abstract>
      <url hash="ecc3720d">2023.findings-acl.324</url>
      <bibkey>lin-ng-2023-mind</bibkey>
      <doi>10.18653/v1/2023.findings-acl.324</doi>
    </paper>
    <paper id="325">
      <title><fixed-case>C</fixed-case>ode<fixed-case>P</fixed-case>rompt: Task-Agnostic Prefix Tuning for Program and Language Generation</title>
      <author><first>YunSeok</first><last>Choi</last><affiliation>Sungkyunkwan University</affiliation></author>
      <author><first>Jee-Hyong</first><last>Lee</last><affiliation>Sungkyunkwan Univ</affiliation></author>
      <pages>5282-5297</pages>
      <abstract>In order to solve the inefficient parameter update and storage issues of fine-tuning in Natural Language Generation (NLG) tasks, prompt-tuning methods have emerged as lightweight alternatives. Furthermore, efforts to reduce the gap between pre-training and fine-tuning have shown successful results in low-resource settings. As large Pre-trained Language Models (PLMs) for Program and Language Generation (PLG) tasks are constantly being developed, prompt tuning methods are necessary for the tasks. However, due to the gap between pre-training and fine-tuning different from PLMs for natural language, a prompt tuning method that reflects the traits of PLM for program language is needed. In this paper, we propose a Task-Agnostic prompt tuning method for the PLG tasks, CodePrompt, that combines Input-Dependent Prompt Template (to bridge the gap between pre-training and fine-tuning of PLMs for program and language) and Corpus-Specific Prefix Tuning (to update the parameters of PLMs for program and language efficiently).Also, we propose a method to provide richer prefix word information for limited prefix lengths. We prove that our method is effective in three PLG tasks, not only in the full-data setting but also in the low-resource setting and cross-domain setting.</abstract>
      <url hash="775fd6d9">2023.findings-acl.325</url>
      <bibkey>choi-lee-2023-codeprompt</bibkey>
      <doi>10.18653/v1/2023.findings-acl.325</doi>
    </paper>
    <paper id="326">
      <title>Honey, <fixed-case>I</fixed-case> Shrunk the Language: Language Model Behavior at Reduced Scale.</title>
      <author><first>Vijeta</first><last>Deshpande</last><affiliation>University of Massachusetts Lowell</affiliation></author>
      <author><first>Dan</first><last>Pechi</last><affiliation>Tufts, Charles River Analytics</affiliation></author>
      <author><first>Shree</first><last>Thatte</last><affiliation>University of Massachusetts Lowell</affiliation></author>
      <author><first>Vladislav</first><last>Lialin</last><affiliation>University of Massachusetts Lowell</affiliation></author>
      <author><first>Anna</first><last>Rumshisky</last><affiliation>University of Massachusetts Lowell</affiliation></author>
      <pages>5298-5314</pages>
      <abstract>In recent years, language models have drastically grown in size, and the abilities of these models have been shown to improve with scale. The majority of recent scaling laws studies focused on high-compute high-parameter count settings, leaving the question of when these abilities begin to emerge largely unanswered. In this paper, we investigate whether the effects of pre-training can be observed when the problem size is reduced, modeling a smaller, reduced-vocabulary language. We show the benefits of pre-training with masked language modeling (MLM) objective in models as small as 1.25M parameters, and establish a strong correlation between pre-training perplexity and downstream performance (GLUE benchmark). We examine downscaling effects, extending scaling laws to models as small as ~1M parameters. At this scale, we observe a break of the power law for compute-optimal models and show that the MLM loss does not scale smoothly with compute-cost (FLOPs) below <tex-math>2.2 \times 10^{15}</tex-math> FLOPs. We also find that adding layers does not always benefit downstream performance.Our filtered pre-training data, reduced English vocabulary, and code are available at <url>https://github.com/text-machine-lab/mini_bert</url><tex-math>github.com/text-machine-lab/mini\_bert</tex-math></abstract>
      <url hash="cbda06b0">2023.findings-acl.326</url>
      <bibkey>deshpande-etal-2023-honey</bibkey>
      <doi>10.18653/v1/2023.findings-acl.326</doi>
    </paper>
    <paper id="327">
      <title>Communication Efficient Federated Learning for Multilingual Neural Machine Translation with Adapter</title>
      <author><first>Yi</first><last>Liu</last><affiliation>School of Computer Science, Peking University</affiliation></author>
      <author><first>Xiaohan</first><last>Bi</last><affiliation>Peking University</affiliation></author>
      <author><first>Lei</first><last>Li</last><affiliation>Peking University</affiliation></author>
      <author><first>Sishuo</first><last>Chen</last><affiliation>Center for Data Science, Peking University</affiliation></author>
      <author><first>Wenkai</first><last>Yang</last><affiliation>Peking University</affiliation></author>
      <author><first>Xu</first><last>Sun</last><affiliation>Peking University</affiliation></author>
      <pages>5315-5328</pages>
      <abstract>Federated Multilingual Neural Machine Translation (Fed-MNMT) has emerged as a promising paradigm for institutions with limited language resources. This approach allows multiple institutions to act as clients and train a unified model through model synchronization, rather than collecting sensitive data for centralized training. This significantly reduces the cost of corpus collection and preserves data privacy. However, as pre-trained language models (PLMs) continue to increase in size, the communication cost for transmitting parameters during synchronization has become a training speed bottleneck. In this paper, we propose a communication-efficient Fed-MNMT framework that addresses this issue by keeping PLMs frozen and only transferring lightweight adapter modules between clients. Since different language pairs exhibit substantial discrepancies in data distributions, adapter parameters of clients may conflict with each other. To tackle this, we explore various clustering strategies to group parameters for integration and mitigate the negative effects of conflicting parameters. Experimental results demonstrate that our framework reduces communication cost by over 98% while achieving similar or even better performance compared to competitive baselines. Further analysis reveals that clustering strategies effectively solve the problem of linguistic discrepancy and pruning adapter modules further improves communication efficiency.</abstract>
      <url hash="d3229664">2023.findings-acl.327</url>
      <bibkey>liu-etal-2023-communication</bibkey>
      <doi>10.18653/v1/2023.findings-acl.327</doi>
    </paper>
    <paper id="328">
      <title>Cross-task Knowledge Transfer for Extremely Weakly Supervised Text Classification</title>
      <author><first>Seongmin</first><last>Park</last><affiliation>ActionPower</affiliation></author>
      <author><first>Kyungho</first><last>Kim</last><affiliation>ActionPower</affiliation></author>
      <author><first>Jihwa</first><last>Lee</last><affiliation>ActionPower</affiliation></author>
      <pages>5329-5341</pages>
      <abstract>Text classification with extremely weak supervision (EWS) imposes stricter supervision constraints compared to regular weakly supervise classification. Absolutely no labeled training samples or hand-crafted rules specific to the evaluation data are allowed. Such restrictions limit state-of-the-art EWS classification methods to indirect weak labeling techniques that assign unnatural label uncertainty estimates. We present PLAT, a framework that creates weak labels by leveraging recent developments in zero-shot text classification. PLAT employs models trained for sub-tasks other than classification to label documents. Most importantly, PLAT refrains from assigning overly confident weak labels and improves soft-label training performance for downstream classifiers. Classifiers trained with PLAT significantly outperform those trained on weak labels generated by the previous state-of-the-art in extremely weakly supervised text classification.</abstract>
      <url hash="30641ecc">2023.findings-acl.328</url>
      <bibkey>park-etal-2023-cross</bibkey>
      <doi>10.18653/v1/2023.findings-acl.328</doi>
    </paper>
    <paper id="329">
      <title><fixed-case>GV</fixed-case>doc - Graph-based Visual <fixed-case>DO</fixed-case>cument Classification</title>
      <author><first>Fnu</first><last>Mohbat</last><affiliation>Rensselaer Polytechnic Institute</affiliation></author>
      <author><first>Mohammed J</first><last>Zaki</last><affiliation>Rensselaer Polytechnic Institute</affiliation></author>
      <author><first>Catherine</first><last>Finegan-Dollak</last><affiliation>University of Richmond</affiliation></author>
      <author><first>Ashish</first><last>Verma</last><affiliation>Amazon</affiliation></author>
      <pages>5342-5357</pages>
      <abstract>The robustness of a model for real-world deployment is decided by how well it performs on unseen data and distinguishes between in-domain and out-of-domain samples. Visual document classifiers have shown impressive performance on in-distribution test sets. However, they tend to have a hard time correctly classifying and differentiating out-of-distribution examples. Image-based classifiers lack the text component, whereas multi-modality transformer-based models face the token serialization problem in visual documents due to their diverse layouts. They also require a lot of computing power during inference, making them impractical for many real-world applications. We propose, GVdoc, a graph-based document classification model that addresses both of these challenges. Our approach generates a document graph based on its layout, and then trains a graph neural network to learn node and graph embeddings. Through experiments, we show that our model, even with fewer parameters, outperforms state-of-the-art models on out-of-distribution data while retaining comparable performance on the in-distribution test set.</abstract>
      <url hash="e2b74b58">2023.findings-acl.329</url>
      <bibkey>mohbat-etal-2023-gvdoc</bibkey>
      <doi>10.18653/v1/2023.findings-acl.329</doi>
    </paper>
    <paper id="330">
      <title>A Sequence-to-Sequence&amp;Set Model for Text-to-Table Generation</title>
      <author><first>Tong</first><last>Li</last><affiliation>Xiamen University</affiliation></author>
      <author><first>Zhihao</first><last>Wang</last><affiliation>Xiamen University</affiliation></author>
      <author><first>Liangying</first><last>Shao</last><affiliation>Xiamen University</affiliation></author>
      <author><first>Xuling</first><last>Zheng</last><affiliation>Xiamen University</affiliation></author>
      <author><first>Xiaoli</first><last>Wang</last><affiliation>Xiamen University</affiliation></author>
      <author><first>Jinsong</first><last>Su</last><affiliation>Xiamen university</affiliation></author>
      <pages>5358-5370</pages>
      <abstract>Recently, the text-to-table generation task has attracted increasing attention due to its wide applications. In this aspect, the dominant model formalizes this task as a sequence-to-sequence generation task and serializes each table into a token sequence during training by concatenating all rows in a top-down order. However, it suffers from two serious defects: 1) the predefined order introduces a wrong bias during training, which highly penalizes shifts in the order between rows; 2) the error propagation problem becomes serious when the model outputs a long token sequence. In this paper, we first conduct a preliminary study to demonstrate the generation of most rows is order-insensitive. Furthermore, we propose a novel sequence-to-sequence&amp;set text-to-table generation model. Specifically, in addition to a text encoder encoding the input text, our model is equipped with a table header generator to first output a table header, i.e., the first row of the table, in the manner of sequence generation. Then we use a table body generator with learnable row embeddings and column embeddings to generate a set of table body rows in parallel. Particularly, to deal with the issue that there is no correspondence between each generated table body row and target during training, we propose a target assignment strategy based on the bipartite matching between the first cells of generated table body rows and targets. Experiment results show that our model significantly surpasses the baselines, achieving state-of-the-art performance on commonly-used datasets.</abstract>
      <url hash="c11e074c">2023.findings-acl.330</url>
      <bibkey>li-etal-2023-sequence-sequence</bibkey>
      <doi>10.18653/v1/2023.findings-acl.330</doi>
    </paper>
    <paper id="331">
      <title>Automatic Readability Assessment for Closely Related Languages</title>
      <author><first>Joseph Marvin</first><last>Imperial</last><affiliation>National University</affiliation></author>
      <author><first>Ekaterina</first><last>Kochmar</last><affiliation>MBZUAI</affiliation></author>
      <pages>5371-5386</pages>
      <abstract>In recent years, the main focus of research on automatic readability assessment (ARA) has shifted towards using expensive deep learning-based methods with the primary goal of increasing models’ accuracy. This, however, is rarely applicable for low-resource languages where traditional handcrafted features are still widely used due to the lack of existing NLP tools to extract deeper linguistic representations. In this work, we take a step back from the technical component and focus on how linguistic aspects such as mutual intelligibility or degree of language relatedness can improve ARA in a low-resource setting. We collect short stories written in three languages in the Philippines—Tagalog, Bikol, and Cebuano—to train readability assessment models and explore the interaction of data and features in various cross-lingual setups. Our results show that the inclusion of CrossNGO, a novel specialized feature exploiting n-gram overlap applied to languages with high mutual intelligibility, significantly improves the performance of ARA models compared to the use of off-the-shelf large multilingual language models alone. Consequently, when both linguistic representations are combined, we achieve state-of-the-art results for Tagalog and Cebuano, and baseline scores for ARA in Bikol.</abstract>
      <url hash="d7cc3981">2023.findings-acl.331</url>
      <bibkey>imperial-kochmar-2023-automatic</bibkey>
      <doi>10.18653/v1/2023.findings-acl.331</doi>
    </paper>
    <paper id="332">
      <title>Towards Robust Ranker for Text Retrieval</title>
      <author><first>Yucheng</first><last>Zhou</last><affiliation>University of Technology Sydney</affiliation></author>
      <author><first>Tao</first><last>Shen</last><affiliation>University of Technology Sydney</affiliation></author>
      <author><first>Xiubo</first><last>Geng</last><affiliation>STCA NLP Group, Microsoft</affiliation></author>
      <author><first>Chongyang</first><last>Tao</last><affiliation>Microsoft Corporation</affiliation></author>
      <author><first>Can</first><last>Xu</last><affiliation>STCA NLP Group, Microsoft</affiliation></author>
      <author><first>Guodong</first><last>Long</last><affiliation>University of Technology Sydney</affiliation></author>
      <author><first>Binxing</first><last>Jiao</last><affiliation>Microsoft</affiliation></author>
      <author><first>Daxin</first><last>Jiang</last><affiliation>STCA, Microsoft</affiliation></author>
      <pages>5387-5401</pages>
      <abstract>A neural ranker plays an indispensable role in the de facto ‘retrieval &amp; rerank’ pipeline, but its training still lags behind due to the weak negative mining during contrastive learning. Compared to retrievers boosted by self-adversarial (i.e., in-distribution) negative mining, the ranker’s heavy structure suffers from query-document combinatorial explosions, so it can only resort to the negative sampled by the fast yet out-of-distribution retriever. Thereby, the moderate negatives compose ineffective contrastive learning samples, becoming the main barrier to learning a robust ranker. To alleviate this, we propose a multi-adversarial training strategy that leverages multiple retrievers as generators to challenge a ranker, where i) diverse hard negatives from a joint distribution are prone to fool the ranker for more effective adversarial learning and ii) involving extensive out-of-distribution label noises renders the ranker against each noise distribution, leading to more challenging and robust contrastive learning. To evaluate our robust ranker (dubbed R2anker), we conduct experiments in various settings on the passage retrieval benchmarks, including BM25-reranking, full-ranking, retriever distillation, etc. The empirical results verify the new state-of-the-art effectiveness of our model.</abstract>
      <url hash="2bc04996">2023.findings-acl.332</url>
      <bibkey>zhou-etal-2023-towards-robust</bibkey>
      <doi>10.18653/v1/2023.findings-acl.332</doi>
    </paper>
    <paper id="333">
      <title>Semi-Supervised Domain Adaptation for Emotion-Related Tasks</title>
      <author><first>Mahshid</first><last>Hosseini</last><affiliation>University of Illinois at Chicago</affiliation></author>
      <author><first>Cornelia</first><last>Caragea</last><affiliation>University of Illinois at Chicago</affiliation></author>
      <pages>5402-5410</pages>
      <abstract>Semi-supervised domain adaptation (SSDA) adopts a model trained from a label-rich source domain to a new but related domain with a few labels of target data. It is shown that, in an SSDA setting, a simple combination of domain adaptation (DA) with semi-supervised learning (SSL) techniques often fails to effectively utilize the target supervision and cannot address distribution shifts across different domains due to the training data bias toward the source-labeled samples. In this paper, inspired by the co-learning of multiple classifiers for the computer vision tasks, we propose to decompose the SSDA framework for emotion-related tasks into two subcomponents of unsupervised domain adaptation (UDA) from the source to the target domain and semi-supervised learning (SSL) in the target domain where the two models iteratively teach each other by interchanging their high confident predictions. We further propose a novel data cartography-based regularization technique for pseudo-label denoising that employs training dynamics to further hone our models’ performance. We publicly release our code.</abstract>
      <url hash="1538d8bb">2023.findings-acl.333</url>
      <bibkey>hosseini-caragea-2023-semi</bibkey>
      <doi>10.18653/v1/2023.findings-acl.333</doi>
    </paper>
    <paper id="334">
      <title>Boosting Distress Support Dialogue Responses with Motivational Interviewing Strategy</title>
      <author><first>Anuradha</first><last>Welivita</last><affiliation>École polytechnique fédérale de Lausanne</affiliation></author>
      <author><first>Pearl</first><last>Pu</last><affiliation>EPFL</affiliation></author>
      <pages>5411-5432</pages>
      <abstract>AI-driven chatbots have become an emerging solution to address psychological distress. Due to the lack of psychotherapeutic data, researchers use dialogues scraped from online peer support forums to train them. But since the responses in such platforms are not given by professionals, they contain both conforming and non-conforming responses. In this work, we attempt to recognize these conforming and non-conforming response types present in online distress-support dialogues using labels adapted from a well-established behavioral coding scheme named Motivational Interviewing Treatment Integrity (MITI) code and show how some response types could be rephrased into a more MI adherent form that can, in turn, enable chatbot responses to be more compliant with the MI strategy. As a proof of concept, we build several rephrasers by fine-tuning Blender and GPT3 to rephrase MI non-adherent Advise without permission responses into Advise with permission. We show how this can be achieved with the construction of pseudo-parallel corpora avoiding costs for human labor. Through automatic and human evaluation we show that in the presence of less training data, techniques such as prompting and data augmentation can be used to produce substantially good rephrasings that reflect the intended style and preserve the content of the original text.</abstract>
      <url hash="3afc4d02">2023.findings-acl.334</url>
      <bibkey>welivita-pu-2023-boosting</bibkey>
      <doi>10.18653/v1/2023.findings-acl.334</doi>
    </paper>
    <paper id="335">
      <title><fixed-case>ECOLA</fixed-case>: Enhancing Temporal Knowledge Embeddings with Contextualized Language Representations</title>
      <author><first>Zhen</first><last>Han</last><affiliation>Amazon</affiliation></author>
      <author><first>Ruotong</first><last>Liao</last><affiliation>LMU Munich</affiliation></author>
      <author><first>Jindong</first><last>Gu</last><affiliation>University of Oxford</affiliation></author>
      <author><first>Yao</first><last>Zhang</last><affiliation>LMU Munich</affiliation></author>
      <author><first>Zifeng</first><last>Ding</last><affiliation>LMU Munich</affiliation></author>
      <author><first>Yujia</first><last>Gu</last><affiliation>Technical University of Munich</affiliation></author>
      <author><first>Heinz</first><last>Koeppl</last><affiliation>TU Darmstadt</affiliation></author>
      <author><first>Hinrich</first><last>Schütze</last><affiliation>Center for Information and Language Processing, University of Munich</affiliation></author>
      <author><first>Volker</first><last>Tresp</last><affiliation>LMU</affiliation></author>
      <pages>5433-5447</pages>
      <abstract>Since conventional knowledge embedding models cannot take full advantage of the abundant textual information, there have been extensive research efforts in enhancing knowledge embedding using texts. However, existing enhancement approaches cannot apply to <i>temporal knowledge graphs</i> (tKGs), which contain time-dependent event knowledge with complex temporal dynamics. Specifically, existing enhancement approaches often assume knowledge embedding is time-independent. In contrast, the entity embedding in tKG models usually evolves, which poses the challenge of aligning <i>temporally relevant</i> texts with entities. To this end, we propose to study enhancing temporal knowledge embedding with textual data in this paper. As an approach to this task, we propose Enhanced Temporal Knowledge Embeddings with Contextualized Language Representations (ECOLA), which takes the temporal aspect into account and injects textual information into temporal knowledge embedding. To evaluate ECOLA, we introduce three new datasets for training and evaluating ECOLA. Extensive experiments show that ECOLA significantly enhances temporal KG embedding models with up to 287% relative improvements regarding Hits@1 on the link prediction task. The code and models are publicly available on <url>https://github.com/mayhugotong/ECOLA</url>.</abstract>
      <url hash="755f4196">2023.findings-acl.335</url>
      <bibkey>han-etal-2023-ecola</bibkey>
      <doi>10.18653/v1/2023.findings-acl.335</doi>
    </paper>
    <paper id="336">
      <title>Gender-tuning: Empowering Fine-tuning for Debiasing Pre-trained Language Models</title>
      <author><first>Somayeh</first><last>Ghanbarzadeh</last><affiliation>University of North Texas</affiliation></author>
      <author><first>Yan</first><last>Huang</last><affiliation>University of North Texas</affiliation></author>
      <author><first>Hamid</first><last>Palangi</last><affiliation>Microsoft Research</affiliation></author>
      <author><first>Radames</first><last>Cruz Moreno</last><affiliation>Microsoft</affiliation></author>
      <author><first>Hamed</first><last>Khanpour</last><affiliation>Microsoft</affiliation></author>
      <pages>5448-5458</pages>
      <abstract>Recent studies have revealed that the widely-used Pre-trained Language Models (PLMs) propagate societal biases from the large unmoderated pre-training corpora. Existing solutions require debiasing training processes and datasets for debiasing, which are resource-intensive and costly. Furthermore, these methods hurt the PLMs’ performance on downstream tasks. In this study, we propose Gender-tuning, which debiases the PLMs through fine-tuning on downstream tasks’ datasets. For this aim, Gender-tuning integrates Masked Language Modeling (MLM) training objectives into fine-tuning’s training process. Comprehensive experiments show that Gender-tuning outperforms the state-of-the-art baselines in terms of average gender bias scores in PLMs while improving PLMs’ performance on downstream tasks solely using the downstream tasks’ dataset. Also, Gender-tuning is a deployable debiasing tool for any PLM that works with original fine-tuning.</abstract>
      <url hash="9d31c8d2">2023.findings-acl.336</url>
      <bibkey>ghanbarzadeh-etal-2023-gender</bibkey>
      <doi>10.18653/v1/2023.findings-acl.336</doi>
    </paper>
    <paper id="337">
      <title><fixed-case>T</fixed-case>ext<fixed-case>O</fixed-case>bfuscator: Making Pre-trained Language Model a Privacy Protector via Obfuscating Word Representations</title>
      <author><first>Xin</first><last>Zhou</last><affiliation>Fudan University</affiliation></author>
      <author><first>Yi</first><last>Lu</last><affiliation>Northeastern University</affiliation></author>
      <author><first>Ruotian</first><last>Ma</last><affiliation>Fudan University</affiliation></author>
      <author><first>Tao</first><last>Gui</last><affiliation>fudan university</affiliation></author>
      <author><first>Yuran</first><last>Wang</last><affiliation>Honor Device Co., Ltd</affiliation></author>
      <author><first>Yong</first><last>Ding</last><affiliation>honor</affiliation></author>
      <author><first>Yibo</first><last>Zhang</last><affiliation>Honor Device Co., Ltd</affiliation></author>
      <author><first>Qi</first><last>Zhang</last><affiliation>Fudan University</affiliation></author>
      <author><first>Xuanjing</first><last>Huang</last><affiliation>Fudan University</affiliation></author>
      <pages>5459-5473</pages>
      <abstract>In real-world applications, pre-trained language models are typically deployed on the cloud, allowing clients to upload data and perform compute-intensive inference remotely. To avoid sharing sensitive data directly with service providers, clients can upload numerical representations rather than plain text to the cloud. However, recent text reconstruction techniques have demonstrated that it is possible to transform representations into original words, suggesting that privacy risk remains. In this paper, we propose TextObfuscator, a novel framework for protecting inference privacy by applying random perturbations to clustered representations. The random perturbations make the representations indistinguishable from surrounding clustered representations, thus obscuring word information while retaining the original word functionality. To achieve this, we utilize prototypes to learn clustered representation, where tokens of similar functionality are encouraged to be closer to the same prototype during training. Additionally, we design different methods to find prototypes for token-level and sentence-level tasks, which can improve performance by incorporating semantic and task information. Experimental results on token and sentence classification tasks show that TextObfuscator achieves improvement over compared methods without increasing inference cost.</abstract>
      <url hash="542fad60">2023.findings-acl.337</url>
      <bibkey>zhou-etal-2023-textobfuscator</bibkey>
      <doi>10.18653/v1/2023.findings-acl.337</doi>
    </paper>
    <paper id="338">
      <title>Mini-Model Adaptation: Efficiently Extending Pretrained Models to New Languages via Aligned Shallow Training</title>
      <author><first>Kelly</first><last>Marchisio</last><affiliation>Johns Hopkins University</affiliation></author>
      <author><first>Patrick</first><last>Lewis</last><affiliation>Cohere, University College London</affiliation></author>
      <author><first>Yihong</first><last>Chen</last><affiliation>University College London</affiliation></author>
      <author><first>Mikel</first><last>Artetxe</last><affiliation>Reka AI</affiliation></author>
      <pages>5474-5490</pages>
      <abstract>Prior work shows that it is possible to expand pretrained Masked Language Models (MLMs) to new languages by learning a new set of embeddings, while keeping the transformer body frozen. Despite learning a small subset of parameters, this approach is not compute-efficient, as training the new embeddings requires a full forward and backward pass over the entire model. We propose mini-model adaptation, a compute-efficient alternative that builds a shallow mini-model from a fraction of a large model’s parameters. New language-specific embeddings can then be efficiently trained over the mini-model and plugged into the aligned large model for rapid cross-lingual transfer. We explore two approaches to learn mini-models: MINIJOINT, which jointly pretrains the primary model and the mini-model using a single transformer with a secondary MLM head at a middle layer; and MINIPOST, where we start from a regular pretrained model, build a mini-model by extracting and freezing a few layers, and learn a small number of parameters on top. Experiments on XNLI, MLQA and PAWS-X show that mini-model adaptation matches the performance of the standard approach using up to 2.3x less compute on average.</abstract>
      <url hash="ecf5bea5">2023.findings-acl.338</url>
      <bibkey>marchisio-etal-2023-mini</bibkey>
      <doi>10.18653/v1/2023.findings-acl.338</doi>
    </paper>
    <paper id="339">
      <title><fixed-case>DSP</fixed-case>: Discriminative Soft Prompts for Zero-Shot Entity and Relation Extraction</title>
      <author><first>Bo</first><last>Lv</last><affiliation>University of Chinese Academy of Sciences; Peng Cheng Laboratory</affiliation></author>
      <author><first>Xin</first><last>Liu</last><affiliation>Peng Cheng Laboratory</affiliation></author>
      <author><first>Shaojie</first><last>Dai</last><affiliation>University of Chinese Academy of Sciences, Peng Cheng Laboratory</affiliation></author>
      <author><first>Nayu</first><last>Liu</last><affiliation>Aerospace Information Research Institute, Chinese Academy of Sciences, Beijing 100190, China; School of Electronic, Electrical and Communication Engineering, University of Chinese Academy of Sciences, Beijing 100190, China; Key Laboratory of Network Information System Technology (NIST), Aerospace Information Research Institute, Chinese Academy of Sciences, Beijing 100190, China</affiliation></author>
      <author><first>Fan</first><last>Yang</last><affiliation>CASIA</affiliation></author>
      <author><first>Ping</first><last>Luo</last><affiliation>Institute of Computing Technology, CAS</affiliation></author>
      <author><first>Yue</first><last>Yu</last><affiliation>Pengcheng lab</affiliation></author>
      <pages>5491-5505</pages>
      <abstract>Prompt-based methods have shown their efficacy in transferring general knowledge within pre-trained language models (PLMs) for low-resource scenarios. Typically, prompt-based methods convert downstream tasks to cloze-style problems and map all labels to verbalizers.However, when applied to zero-shot entity and relation extraction, vanilla prompt-based methods may struggle with the limited coverage of verbalizers to labels and the slow inference speed. In this work, we propose a novel Discriminate Soft Prompts (DSP) approach to take advantage of the prompt-based methods to strengthen the transmission of general knowledge. Specifically, we develop a discriminative prompt method, which reformulates zero-shot tasks into token discrimination tasks without having to construct verbalizers.Furthermore, to improve the inference speed of the prompt-based methods, we design a soft prompt co-reference strategy, which leverages soft prompts to approximately refer to the vector representation of text tokens. The experimental results show that, our model outperforms baselines on two zero-shot entity recognition datasets with higher inference speed, and obtains a 7.5% average relation F1-score improvement over previous state-of-the-art models on Wiki-ZSL and FewRel.</abstract>
      <url hash="9998367c">2023.findings-acl.339</url>
      <bibkey>lv-etal-2023-dsp</bibkey>
      <doi>10.18653/v1/2023.findings-acl.339</doi>
    </paper>
    <paper id="340">
      <title>Exploring Robust Overfitting for Pre-trained Language Models</title>
      <author><first>Bin</first><last>Zhu</last><affiliation>Sun Yat-sen University</affiliation></author>
      <author><first>Yanghui</first><last>Rao</last><affiliation>School of Computer Science and Engineering, Sun Yat-sen University</affiliation></author>
      <pages>5506-5522</pages>
      <abstract>We identify the robust overfitting issue for pre-trained language models by showing that the robust test loss increases as the epoch grows. Through comprehensive exploration of the robust loss on the training set, we attribute robust overfitting to the model’s memorization of the adversarial training data. We attempt to mitigate robust overfitting by combining regularization methods with adversarial training. Following the philosophy that prevents the model from memorizing the adversarial data, we find that flooding, a regularization method with loss scaling, can mitigate robust overfitting for pre-trained language models. Eventually, we investigate the effect of flooding levels and evaluate the models’ adversarial robustness under textual attacks. Extensive experiments demonstrate that our methods can mitigate robust overfitting upon three top adversarial training methods and further promote adversarial robustness.</abstract>
      <url hash="c052446b">2023.findings-acl.340</url>
      <bibkey>zhu-rao-2023-exploring</bibkey>
      <doi>10.18653/v1/2023.findings-acl.340</doi>
    </paper>
    <paper id="341">
      <title>Improving Cross-task Generalization of Unified Table-to-text Models with Compositional Task Configurations</title>
      <author><first>Jifan</first><last>Chen</last><affiliation>UT Austin</affiliation></author>
      <author><first>Yuhao</first><last>Zhang</last><affiliation>Amazon AWS AI</affiliation></author>
      <author><first>Lan</first><last>Liu</last><affiliation>Amazon</affiliation></author>
      <author><first>Rui</first><last>Dong</last><affiliation>AWS AI Labs</affiliation></author>
      <author><first>Xinchi</first><last>Chen</last><affiliation>Amazon AWS</affiliation></author>
      <author><first>Patrick</first><last>Ng</last><affiliation>Amazon.com</affiliation></author>
      <author><first>William Yang</first><last>Wang</last><affiliation>Amazon AWS AI Labs</affiliation></author>
      <author><first>Zhiheng</first><last>Huang</last><affiliation>Amazon AI</affiliation></author>
      <pages>5523-5539</pages>
      <abstract>There has been great progress in unifying various table-to-text tasks using a single encoder-decoder model trained via multi-task learning (Xie et al., 2022).However, existing methods typically encode task information with a simple dataset name as a prefix to the encoder. This not only limits the effectiveness of multi-task learning, but also hinders the model’s ability to generalize to new domains or tasks that were not seen during training, which is crucial for real-world applications. In this paper, we propose compositional task configurations, a set of prompts prepended to the encoder to improve cross-task generalization of unified models. We design the task configurations to explicitly specify the task type, as well as its input and output types. We show that this not only allows the model to better learn shared knowledge across different tasks at training, but also allows us to control the model by composing new configurations that apply novel input-output combinations in a zero-shot manner. We demonstrate via experiments over ten table-to-text tasks that our method outperforms the UnifiedSKG baseline by noticeable margins in both in-domain and zero-shot settings, with average improvements of +0.5 and +12.6 from using a T5-large backbone, respectively.</abstract>
      <url hash="761a960e">2023.findings-acl.341</url>
      <bibkey>chen-etal-2023-improving-cross</bibkey>
      <doi>10.18653/v1/2023.findings-acl.341</doi>
    </paper>
    <paper id="342">
      <title><fixed-case>D</fixed-case>-<fixed-case>CALM</fixed-case>: A Dynamic Clustering-based Active Learning Approach for Mitigating Bias</title>
      <author><first>Sabit</first><last>Hassan</last><affiliation>University of Pittsburgh</affiliation></author>
      <author><first>Malihe</first><last>Alikhani</last><affiliation>University of Pittsburgh</affiliation></author>
      <pages>5540-5553</pages>
      <abstract>Despite recent advancements, NLP models continue to be vulnerable to bias. This bias often originates from the uneven distribution of real-world data and can propagate through the annotation process. Escalated integration of these models in our lives calls for methods to mitigate bias without overbearing annotation costs. While active learning (AL) has shown promise in training models with a small amount of annotated data, AL’s reliance on the model’s behavior for selective sampling can lead to an accumulation of unwanted bias rather than bias mitigation. However, infusing clustering with AL can overcome the bias issue of both AL and traditional annotation methods while exploiting AL’s annotation efficiency. In this paper, we propose a novel adaptive clustering-based active learning algorithm, D-CALM, that dynamically adjusts clustering and annotation efforts in response to an estimated classifier error-rate. Experiments on eight datasets for a diverse set of text classification tasks, including emotion, hatespeech, dialog act, and book type detection, demonstrate that our proposed algorithm significantly outperforms baseline AL approaches with both pretrained transformers and traditional Support Vector Machines. D-CALM showcases robustness against different measures of information gain and, as evident from our analysis of label and error distribution, can significantly reduce unwanted model bias.</abstract>
      <url hash="a236fc5f">2023.findings-acl.342</url>
      <bibkey>hassan-alikhani-2023-calm</bibkey>
      <doi>10.18653/v1/2023.findings-acl.342</doi>
    </paper>
    <paper id="343">
      <title>Language Anisotropic Cross-Lingual Model Editing</title>
      <author><first>Yang</first><last>Xu</last><affiliation>Harbin Institute of Technology</affiliation></author>
      <author><first>Yutai</first><last>Hou</last><affiliation>Harbin Institute of Technology</affiliation></author>
      <author><first>Wanxiang</first><last>Che</last><affiliation>Harbin Institute of Technology</affiliation></author>
      <author><first>Min</first><last>Zhang</last><affiliation>Harbin Institute of Technology (Shenzhen)</affiliation></author>
      <pages>5554-5569</pages>
      <abstract>Multilingual pre-trained language models can learn task-specific abilities or memorize facts across multiple languages but inevitably make undesired predictions with specific inputs. Under similar observation, model editing aims to post-hoc calibrate a model targeted to specific inputs with keeping the model’s raw behavior. However, existing work only studies the monolingual scenario, which lacks the cross-lingual transferability to perform editing simultaneously across languages. In this work, we focus on cross-lingual model editing. Firstly, we define the cross-lingual model editing task and corresponding metrics, where an edit in one language propagates to the others. Next, we propose a framework to naturally adapt monolingual model editing approaches to the cross-lingual scenario using parallel corpus. Further, we propose language anisotropic editing to improve cross-lingual editing by amplifying different subsets of parameters for each language. On the newly defined cross-lingual model editing task, we empirically demonstrate the failure of monolingual baselines in propagating the edit to multiple languages and the effectiveness of the proposed language anisotropic model editing. Our code is publicly available at <url>https://github.com/franklear/LiME</url>.</abstract>
      <url hash="0843788b">2023.findings-acl.343</url>
      <bibkey>xu-etal-2023-language-anisotropic</bibkey>
      <doi>10.18653/v1/2023.findings-acl.343</doi>
    </paper>
    <paper id="344">
      <title>Diverse Retrieval-Augmented In-Context Learning for Dialogue State Tracking</title>
      <author><first>Brendan</first><last>King</last><affiliation>University of California, Santa Cruz</affiliation></author>
      <author><first>Jeffrey</first><last>Flanigan</last><affiliation>UC Santa Cruz</affiliation></author>
      <pages>5570-5585</pages>
      <abstract>There has been significant interest in zero and few-shot learning for dialogue state tracking (DST) due to the high cost of collecting and annotating task-oriented dialogues. Recent work has demonstrated that in-context learning requires very little data and zero parameter updates, and even outperforms trained methods in the few-shot setting. We propose RefPyDST, which advances the state of the art with three advancements to in-context learning for DST.First, we formulate DST as a Python programming task, explicitly modeling language coreference as variable reference in Python. Second, since in-context learning depends highly on the context examples, we propose a method to retrieve a diverse set of relevant examples to improve performance. Finally, we introduce a novel re-weighting method during decoding that takes into account probabilities of competing surface forms, and produces a more accurate dialogue state prediction. We evaluate our approach using MultiWOZ and achieve state-of-the-art multi-domain joint-goal accuracy in zero and few-shot settings.</abstract>
      <url hash="e38ab663">2023.findings-acl.344</url>
      <bibkey>king-flanigan-2023-diverse</bibkey>
      <revision id="1" href="2023.findings-acl.344v1" hash="0dbddef5"/>
      <revision id="2" href="2023.findings-acl.344v2" hash="e38ab663" date="2023-07-31">Various fixes.</revision>
      <doi>10.18653/v1/2023.findings-acl.344</doi>
    </paper>
    <paper id="345">
      <title>Pre-Trained Language-Meaning Models for Multilingual Parsing and Generation</title>
      <author><first>Chunliu</first><last>Wang</last><affiliation>University of Groningen</affiliation></author>
      <author><first>Huiyuan</first><last>Lai</last><affiliation>University of Groningen</affiliation></author>
      <author><first>Malvina</first><last>Nissim</last><affiliation>University of Groningen</affiliation></author>
      <author><first>Johan</first><last>Bos</last><affiliation>University of Groningen</affiliation></author>
      <pages>5586-5600</pages>
      <abstract>Pre-trained language models (PLMs) have achieved great success in NLP and have recently been used for tasks in computational semantics. However, these tasks do not fully benefit from PLMs since meaning representations are not explicitly included. We introduce multilingual pre-trained language-meaning models based on Discourse Representation Structures (DRSs), including meaning representations besides natural language texts in the same model, and design a new strategy to reduce the gap between the pre-training and fine-tuning objectives. Since DRSs are language neutral, cross-lingual transfer learning is adopted to further improve the performance of non-English tasks. Automatic evaluation results show that our approach achieves the best performance on both the multilingual DRS parsing and DRS-to-text generation tasks. Correlation analysis between automatic metrics and human judgements on the generation task further validates the effectiveness of our model. Human inspection reveals that out-of-vocabulary tokens are the main cause of erroneous results.</abstract>
      <url hash="ef0093c5">2023.findings-acl.345</url>
      <bibkey>wang-etal-2023-pre</bibkey>
      <doi>10.18653/v1/2023.findings-acl.345</doi>
    </paper>
    <paper id="346">
      <title>Multi-modal Sarcasm Generation: Dataset and Solution</title>
      <author><first>Wenye</first><last>Zhao</last><affiliation>Guangxi University</affiliation></author>
      <author><first>Qingbao</first><last>Huang</last><affiliation>Guangxi University</affiliation></author>
      <author><first>Dongsheng</first><last>Xu</last><affiliation>Guangxi University</affiliation></author>
      <author><first>Peizhi</first><last>Zhao</last><affiliation>Guangxi University</affiliation></author>
      <pages>5601-5613</pages>
      <abstract>As an interesting and challenging task, sarcasm generation has attracted widespread attention. Although very recent studies have made promising progress, none of them considers generating a sarcastic description for a given image - as what people are doing on Twitter. In this paper, we present a Multi-modal Sarcasm Generation (MSG) task: Given an image with hashtags that provide the sarcastic target, MSG aims to generate sarcastic descriptions like humans. Different from textual sarcasm generation, MSG is more challenging as it is difficult to accurately capture the key information from images, hashtags, and OCR tokens and exploit multi-modal incongruity to generate sarcastic descriptions. To support the research on MSG, we develop MuSG, a new dataset with 5000 images and related Twitter text. We also propose a multi-modal Transformer-based method as a solution to this MSG task. The input features are embedded in the common space and passed through the multi-modal Transformer layers to generate the sarcastic descriptions by the auto-regressive paradigm. Both automatic and manual evaluations demonstrate the superiority of our method. The dataset and code will be available soon.</abstract>
      <url hash="0e311659">2023.findings-acl.346</url>
      <bibkey>zhao-etal-2023-multi</bibkey>
      <doi>10.18653/v1/2023.findings-acl.346</doi>
    </paper>
    <paper id="347">
      <title>Rethinking Semi-supervised Learning with Language Models</title>
      <author><first>Zhengxiang</first><last>Shi</last><affiliation>University College London</affiliation></author>
      <author><first>Francesco</first><last>Tonolini</last><affiliation>Amazon</affiliation></author>
      <author><first>Nikolaos</first><last>Aletras</last><affiliation>University of Sheffield</affiliation></author>
      <author><first>Emine</first><last>Yilmaz</last><affiliation>UCL &amp; Amazon</affiliation></author>
      <author><first>Gabriella</first><last>Kazai</last><affiliation>Amazon</affiliation></author>
      <author><first>Yunlong</first><last>Jiao</last><affiliation>Amazon</affiliation></author>
      <pages>5614-5634</pages>
      <abstract>Semi-supervised learning (SSL) is a popular setting aiming to effectively utilize unlabelled data to improve model performance in downstream natural language processing (NLP) tasks. Currently, there are two popular approaches to make use of the unlabelled data: Self-training (ST) and Task-adaptive pre-training (TAPT). ST uses a teacher model to assign pseudo-labels to the unlabelled data, while TAPT continues pre-training on the unlabelled data before fine-tuning. To the best of our knowledge, the effectiveness of TAPT in SSL tasks has not been systematically studied, and no previous work has directly compared TAPT and ST in terms of their ability to utilize the pool of unlabelled data. In this paper, we provide an extensive empirical study comparing five state-of-the-art ST approaches and TAPT across various NLP tasks and data sizes, including in- and out-of domain settings. Surprisingly, we find that TAPT is a strong and more robust SSL learner, even when using just a few hundred unlabelled samples or in the presence of domain shifts, compared to more sophisticated ST approaches, and tends to bring greater improvements in SSL than in fully-supervised settings. Our further analysis demonstrates the risks of using ST approaches when the size of labelled or unlabelled data is small or when domain shifts exist, and highlights TAPT as a potential solution.</abstract>
      <url hash="bf32036f">2023.findings-acl.347</url>
      <bibkey>shi-etal-2023-rethinking</bibkey>
      <doi>10.18653/v1/2023.findings-acl.347</doi>
    </paper>
    <paper id="348">
      <title>Retrieval-Based Transformer for Table Augmentation</title>
      <author><first>Michael</first><last>Glass</last><affiliation>IBM</affiliation></author>
      <author><first>Xueqing</first><last>Wu</last><affiliation>University of Illinois Urbana-Champaign</affiliation></author>
      <author><first>Ankita Rajaram</first><last>Naik</last><affiliation>University of Massachusetts Amherst</affiliation></author>
      <author><first>Gaetano</first><last>Rossiello</last><affiliation>IBM Research AI</affiliation></author>
      <author><first>Alfio</first><last>Gliozzo</last><affiliation>IBM Research AI</affiliation></author>
      <pages>5635-5648</pages>
      <abstract>Data preparation, also called data wrangling, is considered one of the most expensive and time-consuming steps when performing analytics or building machine learning models. Preparing data typically involves collecting and merging data from complex heterogeneous, and often large-scale data sources, such as data lakes. In this paper, we introduce a novel approach toward automatic data wrangling in an attempt to alleviate the effort of end-users, e.g. data analysts, in structuring dynamic views from data lakes in the form of tabular data. Given a corpus of tables, we propose a retrieval augmented transformer model that is self-trained for the table augmentation tasks of row/column population and data imputation. Our self-learning strategy consists in randomly ablating tables from the corpus and training the retrieval-based model with the objective of reconstructing the partial tables given as input with the original values or headers. We adopt this strategy to first train the dense neural retrieval model encoding portions of tables to vectors, and then the end-to-end model trained to perform table augmentation tasks. We test on EntiTables, the standard benchmark for table augmentation, as well as introduce a new benchmark to advance further research: WebTables. Our model consistently and substantially outperforms both supervised statistical methods and the current state-of-the-art transformer-based models.</abstract>
      <url hash="da2a8c33">2023.findings-acl.348</url>
      <bibkey>glass-etal-2023-retrieval</bibkey>
      <doi>10.18653/v1/2023.findings-acl.348</doi>
    </paper>
    <paper id="349">
      <title><fixed-case>ECG</fixed-case>-<fixed-case>QALM</fixed-case>: Entity-Controlled Synthetic Text Generation using Contextual <fixed-case>Q</fixed-case>&amp;<fixed-case>A</fixed-case> for <fixed-case>NER</fixed-case></title>
      <author><first>Karan</first><last>Aggarwal</last><affiliation>Amazon.com Inc</affiliation></author>
      <author><first>Henry</first><last>Jin</last><affiliation>Harvard University</affiliation></author>
      <author><first>Aitzaz</first><last>Ahmad</last><affiliation>Amazon</affiliation></author>
      <pages>5649-5660</pages>
      <abstract>Named Entity Recognition (NER) state-of-the-art methods requires high-quality labeled datasets. Issues such as scarcity of labeled data, under-representation of entities, and privacy concerns with using sensitive data for training, can be significant barriers. Generating synthetic data to train models is a promising solution to mitigate these problems. We propose ECG-QALM, a contextual question and answering approach using pre-trained language models to synthetically generate entity-controlled text. Generated text is then used to augment small labeled datasets for downstream NER tasks. We evaluate our method on two publicly available datasets. We find ECG-QALM is capable of producing full text samples with desired entities appearing in a controllable way, while retaining sentence coherence closest to the real world data. Evaluations on NER tasks show significant improvements (75% - 140%) in low-labeled data regimes.</abstract>
      <url hash="f16fa699">2023.findings-acl.349</url>
      <bibkey>aggarwal-etal-2023-ecg</bibkey>
      <doi>10.18653/v1/2023.findings-acl.349</doi>
    </paper>
    <paper id="350">
      <title>Tokenization Impacts Multilingual Language Modeling: Assessing Vocabulary Allocation and Overlap Across Languages</title>
      <author><first>Tomasz</first><last>Limisiewicz</last><affiliation>Charles University in Prague</affiliation></author>
      <author><first>Jiří</first><last>Balhar</last><affiliation>Charles University</affiliation></author>
      <author><first>David</first><last>Mareček</last><affiliation>Charles University</affiliation></author>
      <pages>5661-5681</pages>
      <abstract>Multilingual language models have recently gained attention as a promising solution for representing multiple languages in a single model. In this paper, we propose new criteria to evaluate the quality of lexical representation and vocabulary overlap observed in sub-word tokenizers.Our findings show that the overlap of vocabulary across languages can be actually detrimental to certain downstream tasks (POS, dependency tree labeling). In contrast, NER and sentence-level tasks (cross-lingual retrieval, NLI) benefit from sharing vocabulary. We also observe that the coverage of the language-specific tokens in the multilingual vocabulary significantly impacts the word-level tasks. Our study offers a deeper understanding of the role of tokenizers in multilingual language models and guidelines for future model developers to choose the most suitable tokenizer for their specific application before undertaking costly model pre-training.</abstract>
      <url hash="acf2d4ca">2023.findings-acl.350</url>
      <bibkey>limisiewicz-etal-2023-tokenization</bibkey>
      <doi>10.18653/v1/2023.findings-acl.350</doi>
    </paper>
    <paper id="351">
      <title>The Whole Truth and Nothing But the Truth: Faithful and Controllable Dialogue Response Generation with Dataflow Transduction and Constrained Decoding</title>
      <author><first>Hao</first><last>Fang</last><affiliation>Microsoft Semantic Machines</affiliation></author>
      <author><first>Anusha</first><last>Balakrishnan</last><affiliation>Inflection AI</affiliation></author>
      <author><first>Harsh</first><last>Jhamtani</last><affiliation>Microsoft</affiliation></author>
      <author><first>John</first><last>Bufe</last><affiliation>Microsoft</affiliation></author>
      <author><first>Jean</first><last>Crawford</last><affiliation>Microsoft</affiliation></author>
      <author><first>Jayant</first><last>Krishnamurthy</last><affiliation>Microsoft</affiliation></author>
      <author><first>Adam</first><last>Pauls</last><affiliation>Microsoft</affiliation></author>
      <author><first>Jason</first><last>Eisner</last><affiliation>Johns Hopkins University + Microsoft Corporation</affiliation></author>
      <author><first>Jacob</first><last>Andreas</last><affiliation>MIT</affiliation></author>
      <author><first>Dan</first><last>Klein</last><affiliation>UC Berkeley / Microsoft</affiliation></author>
      <pages>5682-5700</pages>
      <abstract>In a real-world dialogue system, generated text must be truthful and informative while remaining fluent and adhering to a prescribed style. Satisfying these constraints simultaneously isdifficult for the two predominant paradigms in language generation: neural language modeling and rule-based generation. We describe a hybrid architecture for dialogue response generation that combines the strengths of both paradigms. The first component of this architecture is a rule-based content selection model defined using a new formal framework called dataflow transduction, which uses declarative rules to transduce a dialogue agent’s actions and their results (represented as dataflow graphs) into context-free grammars representing the space of contextually acceptable responses. The second component is a constrained decoding procedure that uses these grammars to constrain the output of a neural language model, which selects fluent utterances. Our experiments show that this system outperforms both rule-based and learned approaches in human evaluations of fluency, relevance, and truthfulness.</abstract>
      <url hash="12ce131a">2023.findings-acl.351</url>
      <bibkey>fang-etal-2023-whole</bibkey>
      <doi>10.18653/v1/2023.findings-acl.351</doi>
    </paper>
    <paper id="352">
      <title>Know What <fixed-case>I</fixed-case> don’t Know: Handling Ambiguous and Unknown Questions for Text-to-<fixed-case>SQL</fixed-case></title>
      <author><first>Bing</first><last>Wang</last><affiliation>Beihang University</affiliation></author>
      <author><first>Yan</first><last>Gao</last><affiliation>Microsoft</affiliation></author>
      <author><first>Zhoujun</first><last>Li</last><affiliation>Beihang University</affiliation></author>
      <author><first>Jian-Guang</first><last>Lou</last><affiliation>Microsoft</affiliation></author>
      <pages>5701-5714</pages>
      <abstract>The task of text-to-SQL aims to convert a natural language question into its corresponding SQL query within the context of relational tables. Existing text-to-SQL parsers generate a plausible SQL query for an arbitrary user question, thereby failing to correctly handle problematic user questions. To formalize this problem, we conduct a preliminary study on the observed ambiguous and unanswerable cases in text-to-SQL and summarize them into 6 feature categories. Correspondingly, we identify the causes behind each category and propose requirements for handling ambiguous and unanswerable questions. Following this study, we propose a simple yet effective counterfactual example generation approach that automatically produces ambiguous and unanswerable text-to-SQL examples. Furthermore, we propose a weakly supervised DTE (Detecting-Then-Explaining) model for error detection, localization, and explanation. Experimental results show that our model achieves the best result on both real-world examples and generated examples compared with various baselines. We release our data and code at: <url>https://github.com/wbbeyourself/DTE</url>.</abstract>
      <url hash="d562c099">2023.findings-acl.352</url>
      <bibkey>wang-etal-2023-know</bibkey>
      <doi>10.18653/v1/2023.findings-acl.352</doi>
    </paper>
    <paper id="353">
      <title>Rethinking Document-Level Relation Extraction: A Reality Check</title>
      <author><first>Jing</first><last>Li</last><affiliation>Harbin Institute of Technology</affiliation></author>
      <author><first>Yequan</first><last>Wang</last><affiliation>Beijing Academy of Artificial Intelligence</affiliation></author>
      <author><first>Shuai</first><last>Zhang</last><affiliation>ETH Zurich</affiliation></author>
      <author><first>Min</first><last>Zhang</last><affiliation>SooChow University</affiliation></author>
      <pages>5715-5730</pages>
      <abstract>Recently, numerous efforts have continued to push up performance boundaries of document-level relation extraction (DocRE) and have claimed significant progress in DocRE. In this paper, we do not aim at proposing a novel model for DocRE. Instead, we take a closer look at the field to see if these performance gains are actually true. By taking a comprehensive literature review and a thorough examination of popular DocRE datasets, we find that these performance gains are achieved upon a strong or even untenable assumption in common: all named entities are perfectly localized, normalized, and typed in advance. Next, we construct four types of entity mention attacks to examine the robustness of typical DocRE models by behavioral probing. We also have a close check on model usability in a more realistic setting. Our findings reveal that most of current DocRE models are vulnerable to entity mention attacks and difficult to be deployed in real-world end-user NLP applications. Our study calls more attentions for future research to stop simplifying problem setups, and to model DocRE in the wild rather than in an unrealistic Utopian world.</abstract>
      <url hash="746b657d">2023.findings-acl.353</url>
      <bibkey>li-etal-2023-rethinking</bibkey>
      <doi>10.18653/v1/2023.findings-acl.353</doi>
    </paper>
    <paper id="354">
      <title>Optimizing Test-Time Query Representations for Dense Retrieval</title>
      <author><first>Mujeen</first><last>Sung</last><affiliation>Korea University</affiliation></author>
      <author><first>Jungsoo</first><last>Park</last><affiliation>Naver</affiliation></author>
      <author><first>Jaewoo</first><last>Kang</last><affiliation>Korea University</affiliation></author>
      <author><first>Danqi</first><last>Chen</last><affiliation>Princeton University</affiliation></author>
      <author><first>Jinhyuk</first><last>Lee</last><affiliation>Google Research</affiliation></author>
      <pages>5731-5746</pages>
      <abstract>Recent developments of dense retrieval rely on quality representations of queries and contexts from pre-trained query and context encoders. In this paper, we introduce TOUR (Test-Time Optimization of Query Representations), which further optimizes instance-level query representations guided by signals from test-time retrieval results. We leverage a cross-encoder re-ranker to provide fine-grained pseudo labels over retrieval results and iteratively optimize query representations with gradient descent. Our theoretical analysis reveals that TOUR can be viewed as a generalization of the classical Rocchio algorithm for pseudo relevance feedback, and we present two variants that leverage pseudo-labels as hard binary or soft continuous labels. We first apply TOUR on phrase retrieval with our proposed phrase re-ranker, and also evaluate its effectiveness on passage retrieval with an off-the-shelf re-ranker. TOUR greatly improves end-to-end open-domain question answering accuracy, as well as passage retrieval performance. TOUR also consistently improves direct re-ranking by up to 2.0% while running 1.3–2.4x faster with an efficient implementation.</abstract>
      <url hash="fbeab7bf">2023.findings-acl.354</url>
      <bibkey>sung-etal-2023-optimizing</bibkey>
      <doi>10.18653/v1/2023.findings-acl.354</doi>
    </paper>
    <paper id="355">
      <title>A Customized Text Sanitization Mechanism with Differential Privacy</title>
      <author><first>Sai</first><last>Chen</last><affiliation>East China Normal University</affiliation></author>
      <author><first>Fengran</first><last>Mo</last><affiliation>Universite de Montreal</affiliation></author>
      <author><first>Yanhao</first><last>Wang</last><affiliation>East China Normal University</affiliation></author>
      <author><first>Cen</first><last>Chen</last><affiliation>East China Normal University</affiliation></author>
      <author><first>Jian-Yun</first><last>Nie</last><affiliation>University of Montreal</affiliation></author>
      <author><first>Chengyu</first><last>Wang</last><affiliation>Alibaba Group</affiliation></author>
      <author><first>Jamie</first><last>Cui</last><affiliation>Ant Group</affiliation></author>
      <pages>5747-5758</pages>
      <abstract>As privacy issues are receiving increasing attention within the Natural Language Processing (NLP) community, numerous methods have been proposed to sanitize texts subject to differential privacy. However, the state-of-the-art text sanitization mechanisms based on a relaxed notion of metric local differential privacy (MLDP) do not apply to non-metric semantic similarity measures and cannot achieve good privacy-utility trade-offs. To address these limitations, we propose a novel Customized Text sanitization (CusText) mechanism based on the original <tex-math>\epsilon</tex-math>-differential privacy (DP) definition, which is compatible with any similarity measure.Moreover, CusText assigns each input token a customized output set to provide more advanced privacy protection at the token level.Extensive experiments on several benchmark datasets show that CusText achieves a better trade-off between privacy and utility than existing mechanisms.The code is available at <url>https://github.com/sai4july/CusText</url>.</abstract>
      <url hash="613daf06">2023.findings-acl.355</url>
      <bibkey>chen-etal-2023-customized</bibkey>
      <doi>10.18653/v1/2023.findings-acl.355</doi>
    </paper>
    <paper id="356">
      <title><fixed-case>LABO</fixed-case>: Towards Learning Optimal Label Regularization via Bi-level Optimization</title>
      <author><first>Peng</first><last>Lu</last><affiliation>University of Montreal/Huawei Noah’s Ark Lab</affiliation></author>
      <author><first>Ahmad</first><last>Rashid</last><affiliation>University of Waterloo; Huawei Noah’s Ark Lab</affiliation></author>
      <author><first>Ivan</first><last>Kobyzev</last><affiliation>Huawei Noah’s Ark Lab</affiliation></author>
      <author><first>Mehdi</first><last>Rezagholizadeh</last><affiliation>Noah’s Ark Lab Huawei</affiliation></author>
      <author><first>Phillippe</first><last>Langlais</last><affiliation>Université de Montréal</affiliation></author>
      <pages>5759-5774</pages>
      <abstract>Regularization techniques are crucial to improving the generalization performance and training efficiency of deep neural networks. Many deep learning algorithms rely on weight decay, dropout, batch/layer normalization to converge faster and generalize. Label Smoothing (LS) is another simple, versatile and efficient regularization which can be applied to various supervised classification tasks. Conventional LS, however, regardless of the training instance assumes that each non-target class is equally likely. In this work, we present a general framework for training with label regularization, which includes conventional LS but can also model instance-specific variants. Based on this formulation, we propose an efficient way of learning LAbel regularization by devising a Bi-level Optimization (LABO) problem. We derive a deterministic and interpretable solution of the inner loop as the optimal label smoothing without the need to store the parameters or the output of a trained model. Finally, we conduct extensive experiments and demonstrate our LABO consistently yields improvement over conventional label regularization on various fields, including seven machine translation and three image classification tasks across various neural network architectures while maintaining training efficiency.</abstract>
      <url hash="1620106e">2023.findings-acl.356</url>
      <bibkey>lu-etal-2023-labo</bibkey>
      <doi>10.18653/v1/2023.findings-acl.356</doi>
    </paper>
    <paper id="357">
      <title>Frustratingly Easy Label Projection for Cross-lingual Transfer</title>
      <author><first>Yang</first><last>Chen</last><affiliation>Georgia Institute of Technology</affiliation></author>
      <author><first>Chao</first><last>Jiang</last><affiliation>Georgia Institute of Technology</affiliation></author>
      <author><first>Alan</first><last>Ritter</last><affiliation>Georgia Institute of Technology</affiliation></author>
      <author><first>Wei</first><last>Xu</last><affiliation>Georgia Institute of Technology</affiliation></author>
      <pages>5775-5796</pages>
      <abstract>Translating training data into many languages has emerged as a practical solution for improving cross-lingual transfer. For tasks that involve span-level annotations, such as information extraction or question answering, an additional label projection step is required to map annotated spans onto the translated texts. Recently, a few efforts have utilized a simple mark-then-translate method to jointly perform translation and projection by inserting special markers around the labeled spans in the original sentence. However, as far as we are aware, no empirical analysis has been conducted on how this approach compares to traditional annotation projection based on word alignment. In this paper, we present an extensive empirical study across 57 languages and three tasks (QA, NER, and Event Extraction) to evaluate the effectiveness and limitations of both methods, filling an important gap in the literature. Experimental results show that our optimized version of mark-then-translate, which we call EasyProject, is easily applied to many languages and works surprisingly well, outperforming the more complex word alignment-based methods. We analyze several key factors that affect the end-task performance, and show EasyProject works well because it can accurately preserve label span boundaries after translation. We will publicly release all our code and data.</abstract>
      <url hash="c2e5ffb9">2023.findings-acl.357</url>
      <bibkey>chen-etal-2023-frustratingly</bibkey>
      <doi>10.18653/v1/2023.findings-acl.357</doi>
    </paper>
    <paper id="358">
      <title>Enhancing Hierarchical Text Classification through Knowledge Graph Integration</title>
      <author><first>Ye</first><last>Liu</last><affiliation>University of Science and Technology of China</affiliation></author>
      <author><first>Kai</first><last>Zhang</last><affiliation>university of science and technology of china</affiliation></author>
      <author><first>Zhenya</first><last>Huang</last><affiliation>University of Science and Technology of China</affiliation></author>
      <author><first>Kehang</first><last>Wang</last><affiliation>University of Science and Technology of China</affiliation></author>
      <author><first>Yanghai</first><last>Zhang</last><affiliation>University of Science and Technology of China</affiliation></author>
      <author><first>Qi</first><last>Liu</last><affiliation>University of Science and Technology of China</affiliation></author>
      <author><first>Enhong</first><last>Chen</last><affiliation>University of Science and Technology of China</affiliation></author>
      <pages>5797-5810</pages>
      <abstract>Hierarchical Text Classification (HTC) is an essential and challenging subtask of multi-label text classification with a taxonomic hierarchy. Recent advances in deep learning and pre-trained language models have led to significant breakthroughs in the HTC problem. However, despite their effectiveness, these methods are often restricted by a lack of domain knowledge, which leads them to make mistakes in a variety of situations. Generally, when manually classifying a specific document to the taxonomic hierarchy, experts make inference based on their prior knowledge and experience. For machines to achieve this capability, we propose a novel Knowledge-enabled Hierarchical Text Classification model (K-HTC), which incorporates knowledge graphs into HTC. Specifically, K-HTC innovatively integrates knowledge into both the text representation and hierarchical label learning process, addressing the knowledge limitations of traditional methods. Additionally, a novel knowledge-aware contrastive learning strategy is proposed to further exploit the information inherent in the data. Extensive experiments on two publicly available HTC datasets show the efficacy of our proposed method, and indicate the necessity of incorporating knowledge graphs in HTC tasks.</abstract>
      <url hash="91d4afaf">2023.findings-acl.358</url>
      <bibkey>liu-etal-2023-enhancing</bibkey>
      <doi>10.18653/v1/2023.findings-acl.358</doi>
    </paper>
    <paper id="359">
      <title>How Many Answers Should <fixed-case>I</fixed-case> Give? An Empirical Study of Multi-Answer Reading Comprehension</title>
      <author><first>Chen</first><last>Zhang</last><affiliation>Peking University</affiliation></author>
      <author><first>Jiuheng</first><last>Lin</last><affiliation>Peking University</affiliation></author>
      <author><first>Xiao</first><last>Liu</last><affiliation>Peking University</affiliation></author>
      <author><first>Yuxuan</first><last>Lai</last><affiliation>Peking University</affiliation></author>
      <author><first>Yansong</first><last>Feng</last><affiliation>Peking University</affiliation></author>
      <author><first>Dongyan</first><last>Zhao</last><affiliation>pku.edu.cn</affiliation></author>
      <pages>5811-5827</pages>
      <abstract>The multi-answer phenomenon, where a question may have multiple answers scattered in the document, can be well handled by humans but is challenging enough for machine reading comprehension (MRC) systems. Despite recent progress in multi-answer MRC, there lacks a systematic analysis of how this phenomenon arises and how to better address it. In this work, we design a taxonomy to categorize commonly-seen multi-answer MRC instances, with which we inspect three multi-answer datasets and analyze where the multi-answer challenge comes from. We further analyze how well different paradigms of current multi-answer MRC models deal with different types of multi-answer instances. We find that some paradigms capture well the key information in the questions while others better model the relation between questions and contexts. We thus explore strategies to make the best of the strengths of different paradigms. Experiments show that generation models can be a promising platform to incorporate different paradigms. Our annotations and code are released for further research.</abstract>
      <url hash="958fd7bb">2023.findings-acl.359</url>
      <bibkey>zhang-etal-2023-many</bibkey>
      <doi>10.18653/v1/2023.findings-acl.359</doi>
    </paper>
    <paper id="360">
      <title>An Exploration of Encoder-Decoder Approaches to Multi-Label Classification for Legal and Biomedical Text</title>
      <author><first>Yova</first><last>Kementchedjhieva</last><affiliation>University of Copenhagen</affiliation></author>
      <author><first>Ilias</first><last>Chalkidis</last><affiliation>University of Copenhagen</affiliation></author>
      <pages>5828-5843</pages>
      <abstract>Standard methods for multi-label text classification largely rely on encoder-only pre-trained language models, whereas encoder-decoder models have proven more effective in other classification tasks. In this study, we compare four methods for multi-label classification, two based on an encoder only, and two based on an encoder-decoder. We carry out experiments on four datasets—two in the legal domain and two in the biomedical domain, each with two levels of label granularity— and always depart from the same pre-trained model, T5. Our results show that encoder-decoder methods outperform encoder-only methods, with a growing advantage on more complex datasets and labeling schemes of finer granularity. Using encoder-decoder models in a non-autoregressive fashion, in particular, yields the best performance overall, so we further study this approach through ablations to better understand its strengths.</abstract>
      <url hash="8850388d">2023.findings-acl.360</url>
      <bibkey>kementchedjhieva-chalkidis-2023-exploration</bibkey>
      <doi>10.18653/v1/2023.findings-acl.360</doi>
    </paper>
    <paper id="361">
      <title>Domain Incremental Lifelong Learning in an Open World</title>
      <author><first>Yi</first><last>Dai</last><affiliation>Tsinghua University</affiliation></author>
      <author><first>Hao</first><last>Lang</last><affiliation>Alibaba Group</affiliation></author>
      <author><first>Yinhe</first><last>Zheng</last><affiliation>miHoYo</affiliation></author>
      <author><first>Bowen</first><last>Yu</last><affiliation>DAMO Academy, Alibaba Group</affiliation></author>
      <author><first>Fei</first><last>Huang</last><affiliation>Alibaba DAMO Academy</affiliation></author>
      <author><first>Yongbin</first><last>Li</last><affiliation>Alibaba Group</affiliation></author>
      <pages>5844-5865</pages>
      <abstract>Lifelong learning (LL) is an important ability for NLP models to learn new tasks continuously. Architecture-based approaches are reported to be effective implementations for LL models. However, it is non-trivial to extend previous approaches to domain incremental LL scenarios since they either require access to task identities in the testing phase or cannot handle samples from unseen tasks. In this paper, we propose Diana: a dynamic architecture-based lifelong learning model that tries to learn a sequence of tasks with a prompt-enhanced language model. Four types of hierarchically organized prompts are used in Diana to capture knowledge from different granularities. Specifically, we dedicate task-level prompts to capture task-specific knowledge to retain high LL performances and maintain instance-level prompts to learn knowledge shared across input samples to improve the model’s generalization performance. Moreover, we dedicate separate prompts to explicitly model unseen tasks and introduce a set of prompt key vectors to facilitate knowledge sharing between tasks. Extensive experiments demonstrate that Diana outperforms state-of-the-art LL models, especially in handling unseen tasks.</abstract>
      <url hash="932ed092">2023.findings-acl.361</url>
      <bibkey>dai-etal-2023-domain</bibkey>
      <doi>10.18653/v1/2023.findings-acl.361</doi>
    </paper>
    <paper id="362">
      <title>Improving Knowledge Graph Completion with Generative Hard Negative Mining</title>
      <author><first>Zile</first><last>Qiao</last><affiliation>Peking University</affiliation></author>
      <author><first>Wei</first><last>Ye</last><affiliation>Peking University</affiliation></author>
      <author><first>Dingyao</first><last>Yu</last><affiliation>School of Software and Microelectronics, Peking University</affiliation></author>
      <author><first>Tong</first><last>Mo</last><affiliation>Peking University</affiliation></author>
      <author><first>Weiping</first><last>Li</last><affiliation>Peking University</affiliation></author>
      <author><first>Shikun</first><last>Zhang</last><affiliation>Peking University</affiliation></author>
      <pages>5866-5878</pages>
      <abstract>Contrastive learning has recently shown great potential to improve text-based knowledge graph completion (KGC). In this paper, we propose to learn a more semantically structured entity representation space in text-based KGC via hard negatives mining. Specifically, we novelly leverage a sequence-to-sequence architecture to generate high-quality hard negatives. These negatives are sampled from the same decoding distributions as the anchor (or correct entity), inherently being semantically close to the anchor and thus enjoying good hardness. A self-information-enhanced contrasting strategy is further incorporated into the Seq2Seq generator to systematically diversify the produced negatives. Extensive experiments on three KGC benchmarks demonstrate the sound hardness and diversity of our generated negatives and the resulting performance superiority on KGC.</abstract>
      <url hash="e232dd14">2023.findings-acl.362</url>
      <bibkey>qiao-etal-2023-improving</bibkey>
      <doi>10.18653/v1/2023.findings-acl.362</doi>
    </paper>
    <paper id="363">
      <title>Visually-Enhanced Phrase Understanding</title>
      <author><first>Tsu-Yuan</first><last>Hsu</last><affiliation>National Taiwan University</affiliation></author>
      <author><first>Chen-An</first><last>Li</last><affiliation>National Taiwan University</affiliation></author>
      <author><first>Chao-Wei</first><last>Huang</last><affiliation>National Taiwan University</affiliation></author>
      <author><first>Yun-Nung</first><last>Chen</last><affiliation>National Taiwan University</affiliation></author>
      <pages>5879-5888</pages>
      <abstract>Large-scale vision-language pre-training has exhibited strong performance in various visual and textual understanding tasks. Recently, the textual encoders of multi-modal pre-trained models have been shown to generate high-quality textual representations, which often outperform models that are purely text-based, such as BERT. In this study, our objective is to utilize both textual and visual encoders of multi-modal pre-trained models to enhance language understanding tasks. We achieve this by generating an image associated with a textual prompt, thus enriching the representation of a phrase for downstream tasks. Results from experiments conducted on four benchmark datasets demonstrate that our proposed method, which leverages visually-enhanced text representations, significantly improves performance in the entity clustering task.</abstract>
      <url hash="5a6485fe">2023.findings-acl.363</url>
      <bibkey>hsu-etal-2023-visually</bibkey>
      <doi>10.18653/v1/2023.findings-acl.363</doi>
    </paper>
    <paper id="364">
      <title>Reasoning in Large Language Models Through Symbolic Math Word Problems</title>
      <author><first>Vedant</first><last>Gaur</last><affiliation>Aragon High School</affiliation></author>
      <author><first>Nikunj</first><last>Saunshi</last><affiliation>Google Research</affiliation></author>
      <pages>5889-5903</pages>
      <abstract>Large language models (LLMs) have revolutionized NLP by solving downstream tasks with little to no labeled data. Despite their versatile abilities, the larger question of their ability to reason remains ill-understood. This paper addresses reasoning in math word problems (MWPs) by studying symbolic versions of the numeric problems, since a symbolic expression is a “concise explanation” of the numeric answer. We create and use a symbolic version of the SVAMP dataset and find that GPT-3’s davinci-002 model also has good zero-shot accuracy on symbolic MWPs. To evaluate the faithfulness of the model’s reasoning, we go beyond accuracy and additionally evaluate the alignment between the final answer and the outputted reasoning, which correspond to numeric and symbolic answers respectively for MWPs. We explore a self-prompting approach to encourage the symbolic reasoning to align with the numeric answer, thus equipping the LLM with the ability to provide a concise and verifiable reasoning and making it more interpretable. Surprisingly, self-prompting also improves the symbolic accuracy to be higher than both the numeric and symbolic accuracies, thus providing an ensembling effect. The SVAMP-Sym dataset will be released for future research on symbolic math problems.</abstract>
      <url hash="57bb5d93">2023.findings-acl.364</url>
      <bibkey>gaur-saunshi-2023-reasoning</bibkey>
      <doi>10.18653/v1/2023.findings-acl.364</doi>
    </paper>
    <paper id="365">
      <title>It’s not Sexually Suggestive; It’s Educative | Separating Sex Education from Suggestive Content on <fixed-case>T</fixed-case>ik<fixed-case>T</fixed-case>ok videos</title>
      <author><first>Enfa</first><last>George</last><affiliation>University Of Arizona</affiliation></author>
      <author><first>Mihai</first><last>Surdeanu</last><affiliation>University of Arizona</affiliation></author>
      <pages>5904-5915</pages>
      <abstract>We introduce SexTok, a multi-modal dataset composed of TikTok videos labeled as sexually suggestive (from the annotator’s point of view), sex-educational content, or neither. Such a dataset is necessary to address the challenge of distinguishing between sexually suggestive content and virtual sex education videos on TikTok. Children’s exposure to sexually suggestive videos has been shown to have adversarial effects on their development (Collins et al. 2017). Meanwhile, virtual sex education, especially on subjects that are more relevant to the LGBTQIA+ community, is very valuable (Mitchell et al. 2014). The platform’s current system removes/punishes some of both types of videos, even though they serve different purposes. Our dataset contains video URLs, and it is also audio transcribed. To validate its importance, we explore two transformer-based models for classifying the videos. Our preliminary results suggest that the task of distinguishing between these types of videos is learnable but challenging. These experiments suggest that this dataset is meaningful and invites further study on the subject.</abstract>
      <url hash="ed7cac30">2023.findings-acl.365</url>
      <bibkey>george-surdeanu-2023-sexually</bibkey>
      <doi>10.18653/v1/2023.findings-acl.365</doi>
    </paper>
    <paper id="366">
      <title>Dynamic Structured Neural Topic Model with Self-Attention Mechanism</title>
      <author><first>Nozomu</first><last>Miyamoto</last><affiliation>The University of Tokyo</affiliation></author>
      <author><first>Masaru</first><last>Isonuma</last><affiliation>The University of Tokyo</affiliation></author>
      <author><first>Sho</first><last>Takase</last><affiliation/></author>
      <author><first>Junichiro</first><last>Mori</last><affiliation>The University of Tokyo</affiliation></author>
      <author><first>Ichiro</first><last>Sakata</last><affiliation>The University of Tokyo</affiliation></author>
      <pages>5916-5930</pages>
      <abstract>This study presents a dynamic structured neural topic model, which can handle the time-series development of topics while capturing their dependencies. Our model captures the topic branching and merging processes by modeling topic dependencies based on a self-attention mechanism. Additionally, we introduce citation regularization, which induces attention weights to represent citation relations by modeling text and citations jointly. Our model outperforms a prior dynamic embedded topic model regarding perplexity and coherence, while maintaining sufficient diversity across topics. Furthermore, we confirm that our model can potentially predict emerging topics from academic literature.</abstract>
      <url hash="3500a977">2023.findings-acl.366</url>
      <bibkey>miyamoto-etal-2023-dynamic</bibkey>
      <doi>10.18653/v1/2023.findings-acl.366</doi>
    </paper>
    <paper id="367">
      <title>Hybrid-Regressive Paradigm for Accurate and Speed-Robust Neural Machine Translation</title>
      <author><first>Qiang</first><last>Wang</last><affiliation>Hithink RoyalFlush AI Research Institute, China</affiliation></author>
      <author><first>Xinhui</first><last>Hu</last><affiliation>Hithink Flush Information Network Co Ltd</affiliation></author>
      <author><first>Ming</first><last>Chen</last><affiliation>Hithink RoyalFlush AI Research Institute</affiliation></author>
      <pages>5931-5945</pages>
      <abstract>This work empirically confirms that non-autoregressive translation (NAT) is less robust in decoding batch size and hardware settings than autoregressive translation (AT). To address this issue, we demonstrate that prompting a small number of AT predictions can significantly reduce the performance gap between AT and NAT through synthetic experiments. Following this line, we propose hybrid-regressive translation (HRT), a two-stage translation prototype that combines the strengths of AT and NAT. Specifically, HRT first generates discontinuous sequences via autoregression (e.g., make a prediction for every <tex-math>k</tex-math> tokens, <tex-math>k&gt;1</tex-math>) and then fills in all previously skipped tokens at once in a non-autoregressive manner. Experiments on five translation tasks show that HRT achieves comparable translation quality with AT while having at least 1.5x faster inference regardless of batch size and device. Additionally, HRT successfully inherits the sound characteristics of AT in the deep-encoder-shallow-decoder architecture, allowing for further speedup without BLEU loss.</abstract>
      <url hash="d9014a5f">2023.findings-acl.367</url>
      <bibkey>wang-etal-2023-hybrid</bibkey>
      <doi>10.18653/v1/2023.findings-acl.367</doi>
    </paper>
    <paper id="368">
      <title>Commonsense Knowledge Transfer for Pre-trained Language Models</title>
      <author><first>Wangchunshu</first><last>Zhou</last><affiliation>ETH Zurich</affiliation></author>
      <author><first>Ronan</first><last>Le Bras</last><affiliation>Allen Institute for AI</affiliation></author>
      <author><first>Yejin</first><last>Choi</last><affiliation>University of Washington</affiliation></author>
      <pages>5946-5960</pages>
      <abstract>Despite serving as the foundation models for a wide range of NLP benchmarks, pre-trained language models have shown limited capabilities of acquiring implicit commonsense knowledge from self-supervision alone, compared to learning linguistic and factual knowledge that appear more explicitly in the surface patterns in text. In this work, we introduce commonsense knowledge transfer, a framework to transfer the commonsense knowledge stored in a neural commonsense knowledge model to a general-purpose pre-trained language model. It first exploits general texts to form queries for extracting commonsense knowledge from the neural commonsense knowledge model and then refines the language model with two self-supervised objectives: commonsense mask infilling and commonsense relation prediction, which align human language with the underlying commonsense knowledge. Empirical results show that our approach consistently improves the model’s performance on downstream tasks that require commonsense reasoning. Moreover, we find that the improvement is more significant in the few-shot setting. This suggests that our approach helps language models better transfer to downstream tasks without extensive supervision by injecting commonsense knowledge into their parameters.</abstract>
      <url hash="166e7a48">2023.findings-acl.368</url>
      <bibkey>zhou-etal-2023-commonsense</bibkey>
      <doi>10.18653/v1/2023.findings-acl.368</doi>
    </paper>
    <paper id="369">
      <title>Shielded Representations: Protecting Sensitive Attributes Through Iterative Gradient-Based Projection</title>
      <author><first>Shadi</first><last>Iskander</last><affiliation>Technion</affiliation></author>
      <author><first>Kira</first><last>Radinsky</last><affiliation>Technion</affiliation></author>
      <author><first>Yonatan</first><last>Belinkov</last><affiliation>Technion</affiliation></author>
      <pages>5961-5977</pages>
      <abstract>Natural language processing models tend to learn and encode social biases present in the data. One popular approach for addressing such biases is to eliminate encoded information from the model’s representations. However, current methods are restricted to removing only linearly encoded information. In this work, we propose Iterative Gradient-Based Projection (IGBP), a novel method for removing non-linear encoded concepts from neural representations. Our method consists of iteratively training neural classifiers to predict a particular attribute we seek to eliminate, followed by a projection of the representation on a hypersurface, such that the classifiers become oblivious to the target attribute. We evaluate the effectiveness of our method on the task of removing gender and race information as sensitive attributes. Our results demonstrate that IGBP is effective in mitigating bias through intrinsic and extrinsic evaluations, with minimal impact on downstream task accuracy.</abstract>
      <url hash="a91f45cb">2023.findings-acl.369</url>
      <bibkey>iskander-etal-2023-shielded</bibkey>
      <doi>10.18653/v1/2023.findings-acl.369</doi>
    </paper>
    <paper id="370">
      <title>Focal Training and Tagger Decouple for Grammatical Error Correction</title>
      <author><first>Minghuan</first><last>Tan</last><affiliation>Shenzhen Institutes of Advanced Technology, Chinese Academy of Sciences</affiliation></author>
      <author><first>Min</first><last>Yang</last><affiliation>Chinese Academy of Sciences</affiliation></author>
      <author><first>Ruifeng</first><last>Xu</last><affiliation>Harbin Institute of Technology, Shenzhen</affiliation></author>
      <pages>5978-5985</pages>
      <abstract>In this paper, we investigate how to improve tagging-based Grammatical Error Correction models. We address two issues of current tagging-based approaches, label imbalance issue, and tagging entanglement issue. Then we propose to down-weight the loss of well-classified labels using Focal Loss and decouple the error detection layer from the label tagging layer through an extra self-attention-based matching module. Experiments over three latest Chinese Grammatical Error Correction datasets show that our proposed methods are effective. We further analyze choices of hyper-parameters for Focal Loss and inference tweaking.</abstract>
      <url hash="34e67fa9">2023.findings-acl.370</url>
      <bibkey>tan-etal-2023-focal</bibkey>
      <doi>10.18653/v1/2023.findings-acl.370</doi>
    </paper>
    <paper id="371">
      <title><fixed-case>LET</fixed-case>: Leveraging Error Type Information for Grammatical Error Correction</title>
      <author><first>Lingyu</first><last>Yang</last><affiliation>Tsinghua University</affiliation></author>
      <author><first>Hongjia</first><last>Li</last><affiliation>Tsinghua University</affiliation></author>
      <author><first>Lei</first><last>Li</last><affiliation>Tsinghua University</affiliation></author>
      <author><first>Chengyin</first><last>Xu</last><affiliation>Tsinghua University</affiliation></author>
      <author><first>Shutao</first><last>Xia</last><affiliation>Tsinghua University</affiliation></author>
      <author><first>Chun</first><last>Yuan</last><affiliation>Tsinghua University</affiliation></author>
      <pages>5986-5998</pages>
      <abstract>Grammatical error correction (GEC) aims to correct errors in given sentences and is significant to many downstream natural language understanding tasks. Recent work introduces the idea of grammatical error detection (GED) to improve the GEC task performance. In contrast, these explicit multi-stage works propagate and amplify the problem of misclassification of the GED module. To introduce more convincing error type information, we propose an end-to-end framework in this paper, which Leverages Error Type (LET) information in the generation process. First, the input text is fed into a classification module to obtain the error type corresponding to each token. Then, we introduce the category information into the decoder’s input and cross-attention module in two ways, respectively. Experiments on various datasets show that our proposed method outperforms existing methods by a clear margin.</abstract>
      <url hash="3e396155">2023.findings-acl.371</url>
      <bibkey>yang-etal-2023-leveraging</bibkey>
      <doi>10.18653/v1/2023.findings-acl.371</doi>
    </paper>
    <paper id="372">
      <title>On the Role of Parallel Data in Cross-lingual Transfer Learning</title>
      <author><first>Machel</first><last>Reid</last><affiliation>Google</affiliation></author>
      <author><first>Mikel</first><last>Artetxe</last><affiliation>Reka AI</affiliation></author>
      <pages>5999-6006</pages>
      <abstract>While prior work has established that the use of parallel data is conducive for cross-lingual learning, it is unclear if the improvements come from the data itself, or if it is the modeling of parallel interactions that matters. Exploring this, we examine the usage of unsupervised machine translation to generate synthetic parallel data, and compare it to supervised machine translation and gold parallel data. We find that even model generated parallel data can be useful for downstream tasks, in both a general setting (continued pretraining) as well as the task-specific setting (translate-train), although our best results are still obtained using real parallel data. Our findings suggest that existing multilingual models do not exploit the full potential of monolingual data, and prompt the community to reconsider the traditional categorization of cross-lingual learning approaches.</abstract>
      <url hash="a328acb8">2023.findings-acl.372</url>
      <bibkey>reid-artetxe-2023-role</bibkey>
      <doi>10.18653/v1/2023.findings-acl.372</doi>
    </paper>
    <paper id="373">
      <title><fixed-case>C</fixed-case>o<fixed-case>M</fixed-case>ave: Contrastive Pre-training with Multi-scale Masking for Attribute Value Extraction</title>
      <author><first>Xinnan</first><last>Guo</last><affiliation>Southeast University</affiliation></author>
      <author><first>Wentao</first><last>Deng</last><affiliation>Ant Group</affiliation></author>
      <author><first>Yongrui</first><last>Chen</last><affiliation>Southeast University</affiliation></author>
      <author><first>Yang</first><last>Li</last><affiliation>Ant Group</affiliation></author>
      <author><first>Mengdi</first><last>Zhou</last><affiliation>Ant Group</affiliation></author>
      <author><first>Guilin</first><last>Qi</last><affiliation>Southeast University</affiliation></author>
      <author><first>Tianxing</first><last>Wu</last><affiliation>Southeast University</affiliation></author>
      <author><first>Dong</first><last>Yang</last><affiliation>antfin</affiliation></author>
      <author><first>Liubin</first><last>Wang</last><affiliation>Ant Group</affiliation></author>
      <author><first>Yong</first><last>Pan</last><affiliation>alipay</affiliation></author>
      <pages>6007-6018</pages>
      <abstract>Attribute Value Extraction (AVE) aims to automatically obtain attribute value pairs from product descriptions to aid e-commerce. Despite the progressive performance of existing approaches in e-commerce platforms, they still suffer from two challenges: 1) difficulty in identifying values at different scales simultaneously; 2) easy confusion by some highly similar fine-grained attributes. This paper proposes a pre-training technique for AVE to address these issues. In particular, we first improve the conventional token-level masking strategy, guiding the language model to understand multi-scale values by recovering spans at the phrase and sentence level. Second, we apply clustering to build a challenging negative set for each example and design a pre-training objective based on contrastive learning to force the model to discriminate similar attributes. Comprehensive experiments show that our solution provides a significant improvement over traditional pre-trained models in the AVE task, and achieves state-of-the-art on four benchmarks.</abstract>
      <url hash="c04dda08">2023.findings-acl.373</url>
      <bibkey>guo-etal-2023-comave</bibkey>
      <doi>10.18653/v1/2023.findings-acl.373</doi>
    </paper>
    <paper id="374">
      <title>Phrase Retrieval for Open Domain Conversational Question Answering with Conversational Dependency Modeling via Contrastive Learning</title>
      <author><first>Soyeong</first><last>Jeong</last><affiliation>Korea Advanced Institute of Science and Technology</affiliation></author>
      <author><first>Jinheon</first><last>Baek</last><affiliation>Korea Advanced Institute of Science and Technology</affiliation></author>
      <author><first>Sung Ju</first><last>Hwang</last><affiliation>KAIST</affiliation></author>
      <author><first>Jong</first><last>Park</last><affiliation>KAIST</affiliation></author>
      <pages>6019-6031</pages>
      <abstract>Open-Domain Conversational Question Answering (ODConvQA) aims at answering questions through a multi-turn conversation based on a retriever-reader pipeline, which retrieves passages and then predicts answers with them. However, such a pipeline approach not only makes the reader vulnerable to the errors propagated from the retriever, but also demands additional effort to develop both the retriever and the reader, which further makes it slower since they are not runnable in parallel. In this work, we propose a method to directly predict answers with a phrase retrieval scheme for a sequence of words, reducing the conventional two distinct subtasks into a single one. Also, for the first time, we study its capability for ODConvQA tasks. However, simply adopting it is largely problematic, due to the dependencies between previous and current turns in a conversation. To address this problem, we further introduce a novel contrastive learning strategy, making sure to reflect previous turns when retrieving the phrase for the current context, by maximizing representational similarities of consecutive turns in a conversation while minimizing irrelevant conversational contexts. We validate our model on two ODConvQA datasets, whose experimental results show that it substantially outperforms the relevant baselines with the retriever-reader. Code is available at: <url>https://github.com/starsuzi/PRO-ConvQA</url>.</abstract>
      <url hash="6f973d26">2023.findings-acl.374</url>
      <bibkey>jeong-etal-2023-phrase</bibkey>
      <doi>10.18653/v1/2023.findings-acl.374</doi>
    </paper>
    <paper id="375">
      <title>Unlearning Bias in Language Models by Partitioning Gradients</title>
      <author><first>Charles</first><last>Yu</last><affiliation>University of Illinois Urbana-Champaign</affiliation></author>
      <author><first>Sullam</first><last>Jeoung</last><affiliation>UIUC</affiliation></author>
      <author><first>Anish</first><last>Kasi</last><affiliation>UIUC</affiliation></author>
      <author><first>Pengfei</first><last>Yu</last><affiliation>Department of Computer Science, University of Illinois at Urbana-Champaign</affiliation></author>
      <author><first>Heng</first><last>Ji</last><affiliation>University of Illinois at Urbana-Champaign and Amazon (Amazon Scholar)</affiliation></author>
      <pages>6032-6048</pages>
      <abstract>Recent research has shown that large-scale pretrained language models, specifically transformers, tend to exhibit issues relating to racism, sexism, religion bias, and toxicity in general. Unfortunately, these pretrained language models are used almost universally in downstream tasks, and natural language processing is often applied to make real-world predictions. Thus, debiasing these language models as early in development as possible is increasingly crucial for preventing unintentional harms caused by natural language systems. To this end, we propose a new technique called partitioned contrastive gradient unlearning (PCGU), a gray-box method for debiasing pretrained masked language models. PCGU aims to optimize only the weights that contribute most to a specific domain of bias, doing so by computing a first-order approximation based on the gradients of contrastive sentence pairs. Our experiments show that PCGU is both low-cost and seems particularly effective at pinpointing the sources of implicit social bias in large pretrained transformers. Although we train using PCGU in the gender-profession domain only, we find that doing so can also partially mitigate bias across other domains. All code for our implementation and experiments can be found at <url>https://github.com/CharlesYu2000/PCGU-UnlearningBias</url>.</abstract>
      <url hash="5917e570">2023.findings-acl.375</url>
      <bibkey>yu-etal-2023-unlearning</bibkey>
      <doi>10.18653/v1/2023.findings-acl.375</doi>
    </paper>
    <paper id="376">
      <title>Meta-training with Demonstration Retrieval for Efficient Few-shot Learning</title>
      <author><first>Aaron</first><last>Mueller</last><affiliation>The Johns Hopkins University</affiliation></author>
      <author><first>Kanika</first><last>Narang</last><affiliation>Facebook AI</affiliation></author>
      <author><first>Lambert</first><last>Mathias</last><affiliation>Meta</affiliation></author>
      <author><first>Qifan</first><last>Wang</last><affiliation>Meta AI</affiliation></author>
      <author><first>Hamed</first><last>Firooz</last><affiliation>Facebook AI</affiliation></author>
      <pages>6049-6064</pages>
      <abstract>Large language models show impressive results on few-shot NLP tasks. However, these models are memory and computation-intensive. Meta-training allows one to leverage smaller models for few-shot generalization in a domain-general and task-agnostic manner; however, these methods alone results in models that may not have sufficient parameterization or knowledge to adapt quickly to a large variety of tasks. To overcome this issue, we propose meta-training with demonstration retrieval, where we use a dense passage retriever to retrieve semantically similar labeled demonstrations to each example for more varied supervision. By separating external knowledge from model parameters, we can use meta-training to train parameter-efficient models that generalize well on a larger variety of tasks. We construct a meta-training set from UnifiedQA and CrossFit, and propose a demonstration bank based on UnifiedQA tasks. To our knowledge, our work is the first to combine retrieval with meta-training, to use DPR models to retrieve demonstrations, and to leverage demonstrations from many tasks simultaneously, rather than randomly sampling demonstrations from the training set of the target task. Our approach outperforms a variety of targeted parameter-efficient and retrieval-augmented few-shot methods on QA, NLI, and text classification tasks (including SQuAD, QNLI, and TREC). Our approach can be meta-trained and fine-tuned quickly on a single GPU.</abstract>
      <url hash="9cc4df63">2023.findings-acl.376</url>
      <bibkey>mueller-etal-2023-meta</bibkey>
      <doi>10.18653/v1/2023.findings-acl.376</doi>
    </paper>
    <paper id="377">
      <title><fixed-case>VCSUM</fixed-case>: A Versatile <fixed-case>C</fixed-case>hinese Meeting Summarization Dataset</title>
      <author><first>Han</first><last>Wu</last><affiliation>City University of Hong Kong</affiliation></author>
      <author><first>Mingjie</first><last>Zhan</last><affiliation>SenseTime Research</affiliation></author>
      <author><first>Haochen</first><last>Tan</last><affiliation>City University of Hong Kong</affiliation></author>
      <author><first>Zhaohui</first><last>Hou</last><affiliation>SenseTime Research</affiliation></author>
      <author><first>Ding</first><last>Liang</last><affiliation>SenseTime Research</affiliation></author>
      <author><first>Linqi</first><last>Song</last><affiliation>City University of Hong Kong</affiliation></author>
      <pages>6065-6079</pages>
      <abstract>Compared to news and chat summarization, the development of meeting summarization is hugely decelerated by the limited data. To this end, we introduce a versatile Chinese meeting summarization dataset, dubbed VCSum, consisting of 239 real-life meetings, with a total duration of over 230 hours. We claim our dataset is versatile because we provide the annotations of topic segmentation, headlines, segmentation summaries, overall meeting summaries, and salient sentences for each meeting transcript. As such, the dataset can adapt to various summarization tasks or methods, including segmentation-based summarization, multi-granularity summarization and retrieval-then-generate summarization. Our analysis confirms the effectiveness and robustness of VCSum. We also provide a set of benchmark models regarding different downstream summarization tasks on VCSum to facilitate further research.</abstract>
      <url hash="4ccd4647">2023.findings-acl.377</url>
      <bibkey>wu-etal-2023-vcsum</bibkey>
      <doi>10.18653/v1/2023.findings-acl.377</doi>
    </paper>
    <paper id="378">
      <title><fixed-case>LEDA</fixed-case>: a Large-Organization Email-Based Decision-Dialogue-Act Analysis Dataset</title>
      <author><first>Mladen</first><last>Karan</last><affiliation>Queen Mary University</affiliation></author>
      <author><first>Prashant</first><last>Khare</last><affiliation>Queen Mary University of London</affiliation></author>
      <author><first>Ravi</first><last>Shekhar</last><affiliation>University of Essex</affiliation></author>
      <author><first>Stephen</first><last>McQuistin</last><affiliation>University of Glasgow</affiliation></author>
      <author><first>Ignacio</first><last>Castro</last><affiliation>Queen Mary University of London</affiliation></author>
      <author><first>Gareth</first><last>Tyson</last><affiliation>QMUL</affiliation></author>
      <author><first>Colin</first><last>Perkins</last><affiliation>University of Glasgow</affiliation></author>
      <author><first>Patrick</first><last>Healey</last><affiliation>Queen Mary, University of London</affiliation></author>
      <author><first>Matthew</first><last>Purver</last><affiliation>Queen Mary University of London</affiliation></author>
      <pages>6080-6089</pages>
      <abstract>Collaboration increasingly happens online. This is especially true for large groups working on global tasks, with collaborators all around the globe. The size and distributed nature of such groups makes decision-making challenging. This paper proposes a set of dialog acts for the study of decision-making mechanisms in such groups, and provides a new annotated dataset based on real-world data from the public mail-archives of one such organisation – the Internet Engineering Task Force (IETF). We provide an initial data analysis showing that this dataset can be used to better understand decision-making in such organisations. Finally, we experiment with a preliminary transformer-based dialog act tagging model.</abstract>
      <url hash="86ee255f">2023.findings-acl.378</url>
      <bibkey>karan-etal-2023-leda</bibkey>
      <doi>10.18653/v1/2023.findings-acl.378</doi>
    </paper>
    <paper id="379">
      <title>Negation Scope Refinement via Boundary Shift Loss</title>
      <author><first>Yin</first><last>Wu</last><affiliation>Nanyang Technological University</affiliation></author>
      <author><first>Aixin</first><last>Sun</last><affiliation>Nanyang Technological University</affiliation></author>
      <pages>6090-6099</pages>
      <abstract>Negation in natural language may affect many NLP applications, e.g., information extraction and sentiment analysis. The key sub-task of negation detection is negation scope resolution which aims to extract the portion of a sentence that is being negated by a negation cue (e.g., keyword “not” and never”) in the sentence. Due to the long spans, existing methods tend to make wrong predictions around the scope boundaries. In this paper, we propose a simple yet effective model named R-BSL which engages the Boundary Shift Loss to refine the predicted boundary. On multiple benchmark datasets, we show that the extremely simple R-BSL achieves best results.</abstract>
      <url hash="744c7a1c">2023.findings-acl.379</url>
      <bibkey>wu-sun-2023-negation</bibkey>
      <doi>10.18653/v1/2023.findings-acl.379</doi>
    </paper>
    <paper id="380">
      <title>Towards Diverse and Effective Question-Answer Pair Generation from Children Storybooks</title>
      <author><first>Sugyeong</first><last>Eo</last><affiliation>Korea University</affiliation></author>
      <author><first>Hyeonseok</first><last>Moon</last><affiliation>Korea University</affiliation></author>
      <author><first>Jinsung</first><last>Kim</last><affiliation>Korea University</affiliation></author>
      <author><first>Yuna</first><last>Hur</last><affiliation>Korea University</affiliation></author>
      <author><first>Jeongwook</first><last>Kim</last><affiliation>Korea University</affiliation></author>
      <author><first>SongEun</first><last>Lee</last><affiliation>Hyundai Motor Group</affiliation></author>
      <author><first>Changwoo</first><last>Chun</last><affiliation>Hyundai Motor Company</affiliation></author>
      <author><first>Sungsoo</first><last>Park</last><affiliation>Hyundai Motor Company</affiliation></author>
      <author><first>Heuiseok</first><last>Lim</last><affiliation>Korea University</affiliation></author>
      <pages>6100-6115</pages>
      <abstract>Recent advances in QA pair generation (QAG) have raised interest in applying this technique to the educational field. However, the diversity of QA types remains a challenge despite its contributions to comprehensive learning and assessment of children. In this paper, we propose a QAG framework that enhances QA type diversity by producing different interrogative sentences and implicit/explicit answers. Our framework comprises a QFS-based answer generator, an iterative QA generator, and a relevancy-aware ranker. The two generators aim to expand the number of candidates while covering various types. The ranker trained on the in-context negative samples clarifies the top-N outputs based on the ranking score. Extensive evaluations and detailed analyses demonstrate that our approach outperforms previous state-of-the-art results by significant margins, achieving improved diversity and quality. Our task-oriented processes are consistent with real-world demand, which highlights our system’s high applicability.</abstract>
      <url hash="46067c3b">2023.findings-acl.380</url>
      <bibkey>eo-etal-2023-towards</bibkey>
      <doi>10.18653/v1/2023.findings-acl.380</doi>
    </paper>
    <paper id="381">
      <title>Pulling Out All The Full Stops: Punctuation Sensitivity in Neural Machine Translation and Evaluation</title>
      <author><first>Prathyusha</first><last>Jwalapuram</last><affiliation>Rakuten</affiliation></author>
      <pages>6116-6130</pages>
      <abstract>Much of the work testing machine translation systems for robustness and sensitivity has been adversarial or tended towards testing noisy input such as spelling errors, or non-standard input such as dialects. In this work, we take a step back to investigate a sensitivity problem that can seem trivial and is often overlooked: punctuation. We perform basic sentence-final insertion and deletion perturbation tests with full stops, exclamation and questions marks across source languages and demonstrate a concerning finding: commercial, production-level machine translation systems are vulnerable to mere single punctuation insertion or deletion, resulting in unreliable translations. Moreover, we demonstrate that both string-based and model-based evaluation metrics also suffer from this vulnerability, producing significantly different scores when translations only differ in a single punctuation, with model-based metrics penalizing each punctuation differently. Our work calls into question the reliability of machine translation systems and their evaluation metrics, particularly for real-world use cases, where inconsistent punctuation is often the most common and the least disruptive noise.</abstract>
      <url hash="3f2145ea">2023.findings-acl.381</url>
      <bibkey>jwalapuram-2023-pulling</bibkey>
      <doi>10.18653/v1/2023.findings-acl.381</doi>
    </paper>
    <paper id="382">
      <title>Reimagining Retrieval Augmented Language Models for Answering Queries</title>
      <author><first>Wang-Chiew</first><last>Tan</last><affiliation>Meta</affiliation></author>
      <author><first>Yuliang</first><last>Li</last><affiliation>Meta</affiliation></author>
      <author><first>Pedro</first><last>Rodriguez</last><affiliation>Meta FAIR</affiliation></author>
      <author><first>Richard</first><last>James</last><affiliation>Meta</affiliation></author>
      <author><first>Xi Victoria</first><last>Lin</last><affiliation>Meta AI</affiliation></author>
      <author><first>Alon</first><last>Halevy</last><affiliation>Facebook AI</affiliation></author>
      <author><first>Wen-tau</first><last>Yih</last><affiliation>Meta AI - FAIR</affiliation></author>
      <pages>6131-6146</pages>
      <abstract>We present a reality check on large language models and inspect the promise of retrieval-augmented language models in comparison. Such language models are semi-parametric, where models integrate model parameters and knowledge from external data sources to make their predictions, as opposed to the parametric nature of vanilla large language models. We give initial experimental findings that semi-parametric architectures can be enhanced with views, a query analyzer/planner, and provenance to make a significantly more powerful system for question answering in terms of accuracy and efficiency, and potentially for other NLP tasks.</abstract>
      <url hash="34c9c266">2023.findings-acl.382</url>
      <bibkey>tan-etal-2023-reimagining</bibkey>
      <doi>10.18653/v1/2023.findings-acl.382</doi>
      <revision id="1" href="2023.findings-acl.382v1" hash="42b82d7d"/>
      <revision id="2" href="2023.findings-acl.382v2" hash="34c9c266" date="2023-09-17">Removed a comment.</revision>
    </paper>
    <paper id="383">
      <title>Numeric Magnitude Comparison Effects in Large Language Models</title>
      <author><first>Raj</first><last>Shah</last><affiliation>Georgia Institute of Technology</affiliation></author>
      <author><first>Vijay</first><last>Marupudi</last><affiliation>Georgia Tech</affiliation></author>
      <author><first>Reba</first><last>Koenen</last><affiliation>Georgia Tech</affiliation></author>
      <author><first>Khushi</first><last>Bhardwaj</last><affiliation>Georgia Tech</affiliation></author>
      <author><first>Sashank</first><last>Varma</last><affiliation>Georgia Tech</affiliation></author>
      <pages>6147-6161</pages>
      <abstract>Large Language Models (LLMs) do not differentially represent numbers, which are pervasive in text. In contrast, neuroscience research has identified distinct neural representations for numbers and words. In this work, we investigate how well popular LLMs capture the magnitudes of numbers (e.g., that 4&lt;5) from a behavioral lens. Prior research on the representational capabilities of LLMs evaluates whether they show human-level performance, for instance, high overall accuracy on standard benchmarks. Here, we ask a different question, one inspired by cognitive science: How closely do the number representations of LLMscorrespond to those of human language users, who typically demonstrate the distance, size, and ratio effects? We depend on a linking hypothesis to map the similarities among the model embeddings of number words and digits to human response times. The results reveal surprisingly human-like representations across language models of different architectures, despite the absence of the neural circuitry that directly supports these representations in the human brain. This research shows the utility of understanding LLMs using behavioral benchmarks and points the way to future work on the number of representations of LLMs and their cognitive plausibility.</abstract>
      <url hash="4f641d34">2023.findings-acl.383</url>
      <bibkey>shah-etal-2023-numeric</bibkey>
      <doi>10.18653/v1/2023.findings-acl.383</doi>
    </paper>
    <paper id="384">
      <title>Multi-Relational Probabilistic Event Representation Learning via Projected <fixed-case>G</fixed-case>aussian Embedding</title>
      <author><first>Linhai</first><last>Zhang</last><affiliation>Southeast University</affiliation></author>
      <author><first>Congzhi</first><last>Zhang</last><affiliation>Southeast University</affiliation></author>
      <author><first>Deyu</first><last>Zhou</last><affiliation>Southeast University</affiliation></author>
      <pages>6162-6174</pages>
      <abstract>Event representation learning has been shown beneficial in various downstream tasks. Current event representation learning methods, which mainly focus on capturing the semantics of events via deterministic vector embeddings, have made notable progress. However, they ignore two important properties: the multiple relations between events and the uncertainty within events. In this paper, we propose a novel approach to learning multi-relational probabilistic event embeddings based on contrastive learning. Specifically, the proposed method consists of three major modules, a multi-relational event generation module to automatically generate multi-relational training data, a probabilistic event encoding module to model uncertainty of events by Gaussian density embeddings, and a relation-aware projection module to adapt unseen relations by projecting Gaussian embeddings into relation-aware subspaces. Moreover, a novel contrastive learning loss is elaborately designed for learning the multi-relational probabilistic embeddings. Since the existing benchmarks for event representation learning ignore relations and uncertainty of events, a novel dataset named MRPES is constructed to investigate whether multiple relations between events and uncertainty within events are learned. Experimental results show that the proposed approach outperforms other state-of-the-art baselines on both existing and newly constructed datasets.</abstract>
      <url hash="27850a8e">2023.findings-acl.384</url>
      <bibkey>zhang-etal-2023-multi</bibkey>
      <doi>10.18653/v1/2023.findings-acl.384</doi>
    </paper>
    <paper id="385">
      <title><fixed-case>P</fixed-case>ragmati<fixed-case>CQA</fixed-case>: A Dataset for Pragmatic Question Answering in Conversations</title>
      <author><first>Peng</first><last>Qi</last><affiliation>AWS AI Labs</affiliation></author>
      <author><first>Nina</first><last>Du</last><affiliation>Stanford University</affiliation></author>
      <author><first>Christopher</first><last>Manning</last><affiliation>Stanford University</affiliation></author>
      <author><first>Jing</first><last>Huang</last><affiliation>Amazon</affiliation></author>
      <pages>6175-6191</pages>
      <abstract>Pragmatic reasoning about another speaker’s unspoken intent and state of mind is crucial to efficient and effective human communication. It is virtually omnipresent in conversations between humans, e.g., when someone asks “do you have a minute?”, instead of interpreting it literally as a query about your schedule, you understand that the speaker might have requests that take time, and respond accordingly. In this paper, we present PragmatiCQA, the first large-scale open-domain question answering (QA) dataset featuring 6873 QA pairs that explores pragmatic reasoning in conversations over a diverse set of topics. We designed innovative crowdsourcing mechanisms for interest-based and task-driven data collection to address the common issue of incentive misalignment between crowdworkers and potential users. To compare computational models’ capability at pragmatic reasoning, we also propose several quantitative metrics to evaluate question answering systems on PragmatiCQA. We find that state-of-the-art systems still struggle to perform human-like pragmatic reasoning, and highlight their limitations for future research.</abstract>
      <url hash="9bda0e38">2023.findings-acl.385</url>
      <bibkey>qi-etal-2023-pragmaticqa</bibkey>
      <doi>10.18653/v1/2023.findings-acl.385</doi>
    </paper>
    <paper id="386">
      <title>Modular and On-demand Bias Mitigation with Attribute-Removal Subnetworks</title>
      <author><first>Lukas</first><last>Hauzenberger</last><affiliation>Johannes Kepler University</affiliation></author>
      <author><first>Shahed</first><last>Masoudian</last><affiliation>Johannes Kepler University</affiliation></author>
      <author><first>Deepak</first><last>Kumar</last><affiliation>Institute of Computational Perception, Johannes Kepler University Linz</affiliation></author>
      <author><first>Markus</first><last>Schedl</last><affiliation>Johannes Kepler University Linz</affiliation></author>
      <author><first>Navid</first><last>Rekabsaz</last><affiliation>Johannes Kepler University (JKU)</affiliation></author>
      <pages>6192-6214</pages>
      <abstract>Societal biases are reflected in large pre-trained language models and their fine-tuned versions on downstream tasks. Common in-processing bias mitigation approaches, such as adversarial training and mutual information removal, introduce additional optimization criteria, and update the model to reach a new debiased state. However, in practice, end-users and practitioners might prefer to switch back to the original model, or apply debiasing only on a specific subset of protected attributes. To enable this, we propose a novel modular bias mitigation approach, consisting of stand-alone highly sparse debiasing subnetworks, where each debiasing module can be integrated into the core model on-demand at inference time. Our approach draws from the concept of diff pruning, and proposes a novel training regime adaptable to various representation disentanglement optimizations. We conduct experiments on three classification tasks with gender, race, and age as protected attributes. The results show that our modular approach, while maintaining task performance, improves (or at least remains on-par with) the effectiveness of bias mitigation in comparison with baseline finetuning. Particularly on a two-attribute dataset, our approach with separately learned debiasing subnetworks shows effective utilization of either or both the subnetworks for selective bias mitigation.</abstract>
      <url hash="7644ac29">2023.findings-acl.386</url>
      <bibkey>hauzenberger-etal-2023-modular</bibkey>
      <doi>10.18653/v1/2023.findings-acl.386</doi>
    </paper>
    <paper id="387">
      <title>Scientific Fact-Checking: A Survey of Resources and Approaches</title>
      <author><first>Juraj</first><last>Vladika</last><affiliation>Technical University of Munich</affiliation></author>
      <author><first>Florian</first><last>Matthes</last><affiliation>Technische Universit�t M�nchen</affiliation></author>
      <pages>6215-6230</pages>
      <abstract>The task of fact-checking deals with assessing the veracity of factual claims based on credible evidence and background knowledge. In particular, scientific fact-checking is the variation of the task concerned with verifying claims rooted in scientific knowledge. This task has received significant attention due to the growing importance of scientific and health discussions on online platforms. Automated scientific fact-checking methods based on NLP can help combat the spread of misinformation, assist researchers in knowledge discovery, and help individuals understand new scientific breakthroughs. In this paper, we present a comprehensive survey of existing research in this emerging field and its related tasks. We provide a task description, discuss the construction process of existing datasets, and analyze proposed models and approaches. Based on our findings, we identify intriguing challenges and outline potential future directions to advance the field.</abstract>
      <url hash="68ff7dbf">2023.findings-acl.387</url>
      <bibkey>vladika-matthes-2023-scientific</bibkey>
      <doi>10.18653/v1/2023.findings-acl.387</doi>
    </paper>
    <paper id="388">
      <title>Uni-Encoder: A Fast and Accurate Response Selection Paradigm for Generation-Based Dialogue Systems</title>
      <author><first>Chiyu</first><last>Song</last><affiliation>Zhejiang University, Westlake University</affiliation></author>
      <author><first>Hongliang</first><last>He</last><affiliation>Westlake University</affiliation></author>
      <author><first>Haofei</first><last>Yu</last><affiliation>Carnegie Mellon University</affiliation></author>
      <author><first>Pengfei</first><last>Fang</last><affiliation>the Australian National University</affiliation></author>
      <author><first>Leyang</first><last>Cui</last><affiliation>Tencent AI LAB</affiliation></author>
      <author><first>Zhenzhong</first><last>Lan</last><affiliation>Westlake University</affiliation></author>
      <pages>6231-6244</pages>
      <abstract>Sample-and-rank is a key decoding strategy for modern generation-based dialogue systems. It helps achieve diverse and high-quality responses by selecting an answer from a small pool of generated candidates. The current state-of-the-art ranking methods mainly use an encoding paradigm called Cross-Encoder, which separately encodes each context-candidate pair and ranks the candidates according to their fitness scores. However, Cross-Encoder repeatedly encodes the same lengthy context for each candidate, resulting in high computational costs. Poly-Encoder addresses the above problems by reducing the interaction between context and candidates, but with a price of performance drop. In this work, we develop a new paradigm called Uni-Encoder, that keeps the full attention over each pair as in Cross-Encoder while only encoding the context once, as in Poly-Encoder. Uni-Encoder encodes all the candidates with the context in one forward pass. We use the same positional embedding for all candidates to ensure they are treated equally and design a new attention mechanism to avoid confusion. Our Uni-Encoder can simulate other ranking paradigms using different attention and response concatenation methods. Extensive experiments show that our proposed paradigm achieves new state-of-the-art results on four benchmark datasets with high computational efficiency. For instance, it improves R10@1 by 2.9% with an approximately 4X faster inference speed on the Ubuntu V2 dataset.</abstract>
      <url hash="100b77a0">2023.findings-acl.388</url>
      <bibkey>song-etal-2023-uni</bibkey>
      <doi>10.18653/v1/2023.findings-acl.388</doi>
    </paper>
    <paper id="389">
      <title><fixed-case>DLAMA</fixed-case>: A Framework for Curating Culturally Diverse Facts for Probing the Knowledge of Pretrained Language Models</title>
      <author><first>Amr</first><last>Keleg</last><affiliation>The University of Edinburgh</affiliation></author>
      <author><first>Walid</first><last>Magdy</last><affiliation>The University of Edinburgh</affiliation></author>
      <pages>6245-6266</pages>
      <abstract>A few benchmarking datasets have been released to evaluate the factual knowledge of pretrained language models. These benchmarks (e.g., LAMA, and ParaRel) are mainly developed in English and later are translated to form new multilingual versions (e.g., mLAMA, and mParaRel). Results on these multilingual benchmarks suggest that using English prompts to recall the facts from multilingual models usually yields significantly better and more consistent performance than using non-English prompts. Our analysis shows that mLAMA is biased toward facts from Western countries, which might affect the fairness of probing models. We propose a new framework for curating factual triples from Wikidata that are culturally diverse. A new benchmark DLAMA-v1 is built of factual triples from three pairs of contrasting cultures having a total of 78,259 triples from 20 relation predicates. The three pairs comprise facts representing the (Arab and Western), (Asian and Western), and (South American and Western) countries respectively. Having a more balanced benchmark (DLAMA-v1) supports that mBERT performs better on Western facts than non-Western ones, while monolingual Arabic, English, and Korean models tend to perform better on their culturally proximate facts. Moreover, both monolingual and multilingual models tend to make a prediction that is culturally or geographically relevant to the correct label, even if the prediction is wrong.</abstract>
      <url hash="ae93f895">2023.findings-acl.389</url>
      <bibkey>keleg-magdy-2023-dlama</bibkey>
      <doi>10.18653/v1/2023.findings-acl.389</doi>
    </paper>
    <paper id="390">
      <title>Self-adaptive Context and Modal-interaction Modeling For Multimodal Emotion Recognition</title>
      <author><first>Haozhe</first><last>Yang</last><affiliation>Shandong University</affiliation></author>
      <author><first>Xianqiang</first><last>Gao</last><affiliation>Shandong University</affiliation></author>
      <author><first>Jianlong</first><last>Wu</last><affiliation>Harbin Institute of Technology (Shenzhen)</affiliation></author>
      <author><first>Tian</first><last>Gan</last><affiliation>Shandong University</affiliation></author>
      <author><first>Ning</first><last>Ding</last><affiliation>Tmall Genie of Alibaba Group</affiliation></author>
      <author><first>Feijun</first><last>Jiang</last><affiliation>Tmall Genie of Alibaba Group</affiliation></author>
      <author><first>Liqiang</first><last>Nie</last><affiliation>Harbin Institute of Technology (Shenzhen)</affiliation></author>
      <pages>6267-6281</pages>
      <abstract>The multimodal emotion recognition in conversation task aims to predict the emotion label for a given utterance with its context and multiple modalities. Existing approaches achieve good results but also suffer from the following two limitations: 1) lacking modeling of diverse dependency ranges, i.e., long, short, and independent context-specific representations and without consideration of the different recognition difficulty for each utterance; 2) consistent treatment of the contribution for various modalities. To address the above challenges, we propose the Self-adaptive Context and Modal-interaction Modeling (SCMM) framework. We first design the context representation module, which consists of three submodules to model multiple contextual representations. Thereafter, we propose the modal-interaction module, including three interaction submodules to make full use of each modality. Finally, we come up with a self-adaptive path selection module to select an appropriate path in each module and integrate the features to obtain the final representation. Extensive experiments under four settings on three multimodal datasets, including IEMOCAP, MELD, and MOSEI, demonstrate that our proposed method outperforms the state-of-the-art approaches.</abstract>
      <url hash="6eaa0066">2023.findings-acl.390</url>
      <bibkey>yang-etal-2023-self</bibkey>
      <doi>10.18653/v1/2023.findings-acl.390</doi>
    </paper>
    <paper id="391">
      <title>Structure-Discourse Hierarchical Graph for Conditional Question Answering on Long Documents</title>
      <author><first>Haowei</first><last>Du</last><affiliation>Peking University</affiliation></author>
      <author><first>Yansong</first><last>Feng</last><affiliation>Peking University</affiliation></author>
      <author><first>Chen</first><last>Li</last><affiliation>Ant Group</affiliation></author>
      <author><first>Yang</first><last>Li</last><affiliation>Ant Group</affiliation></author>
      <author><first>Yunshi</first><last>Lan</last><affiliation>East China Normal University</affiliation></author>
      <author><first>Dongyan</first><last>Zhao</last><affiliation>pku.edu.cn</affiliation></author>
      <pages>6282-6293</pages>
      <abstract>Conditional question answering on long documents aims to find probable answers and identify conditions that need to be satisfied to make the answers correct over long documents. Existing approaches solve this task by segmenting long documents into multiple sections, and attending information at global and local tokens to predict the answers and corresponding conditions. However, the natural structure of the document and discourse relations between sentences in each document section are ignored, which are crucial for condition retrieving across sections, as well as logical interaction over the question and conditions. To address this issue, this paper constructs a Structure-Discourse Hierarchical Graph (SDHG) and conducts bottom-up information propagation. Firstly we build the sentence-level discourse graphs for each section and encode the discourse relations by graph attention. Secondly, we construct a section-level structure graph based on natural structures, and conduct interactions over the question and contexts. Finally different levels of representations are integrated into jointly answer and condition decoding. The experiments on the benchmark ConditionalQA shows our approach gains over the prior state-of-the-art, by 3.0 EM score and 2.4 F1 score on answer measuring, as well as 2.2 EM score and 1.9 F1 score on jointly answer and condition measuring.</abstract>
      <url hash="5439df4e">2023.findings-acl.391</url>
      <bibkey>du-etal-2023-structure</bibkey>
      <doi>10.18653/v1/2023.findings-acl.391</doi>
    </paper>
    <paper id="392">
      <title><fixed-case>COBRA</fixed-case> Frames: Contextual Reasoning about Effects and Harms of Offensive Statements</title>
      <author><first>Xuhui</first><last>Zhou</last><affiliation>Carnegie Mellon University</affiliation></author>
      <author><first>Hao</first><last>Zhu</last><affiliation>Carnegie Mellon University</affiliation></author>
      <author><first>Akhila</first><last>Yerukola</last><affiliation>Carnegie Mellon University</affiliation></author>
      <author><first>Thomas</first><last>Davidson</last><affiliation>Rutgers University</affiliation></author>
      <author><first>Jena D.</first><last>Hwang</last><affiliation>Allen Institute for AI</affiliation></author>
      <author><first>Swabha</first><last>Swayamdipta</last><affiliation>University of Southern California</affiliation></author>
      <author><first>Maarten</first><last>Sap</last><affiliation>Carnegie Mellon University</affiliation></author>
      <pages>6294-6315</pages>
      <abstract>Warning: This paper contains content that may be offensive or upsetting. Understanding the harms and offensiveness of statements requires reasoning about the social and situational context in which statements are made. For example, the utterance “your English is very good” may implicitly signal an insult when uttered by a white man to a non-white colleague, but uttered by an ESL teacher to their student would be interpreted as a genuine compliment. Such contextual factors have been largely ignored by previous approaches to toxic language detection. We introduce COBRA frames, the first context-aware formalism for explaining the intents, reactions, and harms of offensive or biased statements grounded in their social and situational context. We create COBRACORPUS, a dataset of 33k potentially offensive statements paired with machine-generated contexts and free-text explanations of offensiveness, implied biases, speaker intents, and listener reactions. To study the contextual dynamics of offensiveness, we train models to generate COBRA explanations, with and without access to the context. We find that explanations by context-agnostic models are significantly worse than by context-aware ones, especially in situations where the context inverts the statement’s offensiveness (29% accuracy drop). Our work highlights the importance and feasibility of contextualized NLP by modeling social factors.</abstract>
      <url hash="3631077d">2023.findings-acl.392</url>
      <bibkey>zhou-etal-2023-cobra</bibkey>
      <doi>10.18653/v1/2023.findings-acl.392</doi>
    </paper>
    <paper id="393">
      <title>Distilling Calibrated Knowledge for Stance Detection</title>
      <author><first>Yingjie</first><last>Li</last><affiliation>Westlake University</affiliation></author>
      <author><first>Cornelia</first><last>Caragea</last><affiliation>University of Illinois at Chicago</affiliation></author>
      <pages>6316-6329</pages>
      <abstract>Stance detection aims to determine the position of an author toward a target and provides insights into people’s views on controversial topics such as marijuana legalization. Despite recent progress in this task, most existing approaches use hard labels (one-hot vectors) during training, which ignores meaningful signals among categories offered by soft labels. In this work, we explore knowledge distillation for stance detection and present a comprehensive analysis. Our contributions are: 1) we propose to use knowledge distillation over multiple generations in which a student is taken as a new teacher to transfer knowledge to a new fresh student; 2) we propose a novel dynamic temperature scaling for knowledge distillation to calibrate teacher predictions in each generation step. Extensive results on three stance detection datasets show that knowledge distillation benefits stance detection and a teacher is able to transfer knowledge to a student more smoothly via calibrated guiding signals. We publicly release our code to facilitate future research.</abstract>
      <url hash="382f59de">2023.findings-acl.393</url>
      <bibkey>li-caragea-2023-distilling</bibkey>
      <doi>10.18653/v1/2023.findings-acl.393</doi>
    </paper>
    <paper id="394">
      <title><fixed-case>PTCS</fixed-case>pell: Pre-trained Corrector Based on Character Shape and <fixed-case>P</fixed-case>inyin for <fixed-case>C</fixed-case>hinese Spelling Correction</title>
      <author><first>Xiao</first><last>Wei</last><affiliation>Shanghai University</affiliation></author>
      <author><first>Jianbao</first><last>Huang</last><affiliation>Shanghai University</affiliation></author>
      <author><first>Hang</first><last>Yu</last><affiliation>Shanghai University</affiliation></author>
      <author><first>Qian</first><last>Liu</last><affiliation>Nanyang Technological University</affiliation></author>
      <pages>6330-6343</pages>
      <abstract>Chinese spelling correction (CSC) is a challenging task with the goal of correcting each wrong character in Chinese texts. Incorrect characters in a Chinese text are mainly due to the similar shape and similar pronunciation of Chinese characters. Recently, the paradigm of pre-training and fine-tuning has achieved remarkable success in natural language processing. However, the pre-training objectives in existing methods are not tailored for the CSC task since they neglect the visual and phonetic properties of characters, resulting in suboptimal spelling correction. In this work, we propose to pre-train a new corrector named PTCSpell for the CSC task under the detector-corrector architecture. The corrector we propose has the following two improvements. First, we design two novel pre-training objectives to capture pronunciation and shape information in Chinese characters. Second, we propose a new strategy to tackle the issue that the detector’s prediction results mislead the corrector by balancing the loss of wrong characters and correct characters. Experiments on three benchmarks (i.e., SIGHAN 2013, 2014, and 2015) show that our model achieves an average of 5.8% F1 improvements at the correction level over state-of-the-art methods, verifying its effectiveness.</abstract>
      <url hash="c26fb127">2023.findings-acl.394</url>
      <bibkey>wei-etal-2023-ptcspell</bibkey>
      <doi>10.18653/v1/2023.findings-acl.394</doi>
    </paper>
    <paper id="395">
      <title>Disentangling Text Representation With Counter-Template For Unsupervised Opinion Summarization</title>
      <author><first>Yanyue</first><last>Zhang</last><affiliation>Southeast University</affiliation></author>
      <author><first>Deyu</first><last>Zhou</last><affiliation>Southeast University</affiliation></author>
      <pages>6344-6357</pages>
      <abstract>Approaches for unsupervised opinion summarization are generally based on the reconstruction model and generate a summary by decoding the aggregated representation of inputs. Recent work has shown that aggregating via simple average leads to vector degeneration, generating the generic summary. To tackle the challenge, some approaches select the inputs before aggregating. However, we argue that the selection is too coarse as not all information in each input is equally essential for the summary. For example, the content information such as “great coffee maker, easy to set up” is more valuable than the pattern such as “this is a great product”. Therefore, we propose a novel framework for unsupervised opinion summarization based on text representation disentanglement with counter-template. In specific, a disentangling module is added to the encoder-decoder architecture which decouples the input text representation into two parts: content and pattern. To capture the pattern information, a counter-template is utilized as supervision, which is automatically generated based on contrastive learning. Experimental results on two benchmark datasets show that the proposed approach outperforms the state-of-the-art baselines on both quality and stability.</abstract>
      <url hash="cbb30c8d">2023.findings-acl.395</url>
      <bibkey>zhang-zhou-2023-disentangling</bibkey>
      <doi>10.18653/v1/2023.findings-acl.395</doi>
    </paper>
    <paper id="396">
      <title>Evaluation of Question Generation Needs More References</title>
      <author><first>Shinhyeok</first><last>Oh</last><affiliation>Riiid</affiliation></author>
      <author><first>Hyojun</first><last>Go</last><affiliation>Riiid</affiliation></author>
      <author><first>Hyeongdon</first><last>Moon</last><affiliation>None</affiliation></author>
      <author><first>Yunsung</first><last>Lee</last><affiliation>Riiid</affiliation></author>
      <author><first>Myeongho</first><last>Jeong</last><affiliation>Riiid</affiliation></author>
      <author><first>Hyun Seung</first><last>Lee</last><affiliation>Riiid</affiliation></author>
      <author><first>Seungtaek</first><last>Choi</last><affiliation>Riiid</affiliation></author>
      <pages>6358-6367</pages>
      <abstract>Question generation (QG) is the task of generating a valid and fluent question based on a given context and the target answer. According to various purposes, even given the same context, instructors can ask questions about different concepts, and even the same concept can be written in different ways. However, the evaluation for QG usually depends on single reference-based similarity metrics, such as n-gram-based metric or learned metric, which is not sufficient to fully evaluate the potential of QG methods. To this end, we propose to paraphrase the reference question for a more robust QG evaluation. Using large language models such as GPT-3, we created semantically and syntactically diverse questions, then adopt the simple aggregation of the popular evaluation metrics as the final scores. Through our experiments, we found that using multiple (pseudo) references is more effective for QG evaluation while showing a higher correlation with human evaluations than evaluation with a single reference.</abstract>
      <url hash="2ccc80d1">2023.findings-acl.396</url>
      <bibkey>oh-etal-2023-evaluation</bibkey>
      <doi>10.18653/v1/2023.findings-acl.396</doi>
    </paper>
    <paper id="397">
      <title><fixed-case>X</fixed-case>treme<fixed-case>CLIP</fixed-case>: Extremely Parameter-efficient Tuning for Low-resource Vision Language Understanding</title>
      <author><first>Moming</first><last>Tang</last><affiliation>East China Normal University</affiliation></author>
      <author><first>Chengyu</first><last>Wang</last><affiliation>Alibaba Group</affiliation></author>
      <author><first>Jianing</first><last>Wang</last><affiliation>East China Normal University</affiliation></author>
      <author><first>Chuanqi</first><last>Tan</last><affiliation>Alibaba Group</affiliation></author>
      <author><first>Songfang</first><last>Huang</last><affiliation>Alibaba DAMO Academy</affiliation></author>
      <author><first>Cen</first><last>Chen</last><affiliation>East China Normal University</affiliation></author>
      <author><first>Weining</first><last>Qian</last><affiliation>East China Normal University</affiliation></author>
      <pages>6368-6376</pages>
      <abstract>Recently, Contrastive Visual-Language Pre-training (CLIP) has demonstrated remarkable capability in various Visual Language Understanding (VLU) tasks. Yet, most CLIP-based methods require tasks-specific designs and sufficient training data. In this paper, we introduce a simple yet efficient paradigm for low-resource VLU named XtremeCLIP, which involves very few trainable parameters to improve the generalization ability of the trained models. In our XtremeCLIP framework, we reformulate a series of VLU tasks as a unified open-book affinity-matching problem. Furthermore, to handle the insufficient supervised signals in small datasets, we adopt contrastive learning to utilize the implicit sorting information of ground-truth labels to provide more supervised cues. Extensive experiments over multiple datasets on visual entailment, visual question answering, and image classification show that XtremeCLIP consistently outperforms existing baselines in low-resource settings.</abstract>
      <url hash="c4354cea">2023.findings-acl.397</url>
      <bibkey>tang-etal-2023-xtremeclip</bibkey>
      <doi>10.18653/v1/2023.findings-acl.397</doi>
    </paper>
    <paper id="398">
      <title><fixed-case>FACTUAL</fixed-case>: A Benchmark for Faithful and Consistent Textual Scene Graph Parsing</title>
      <author><first>Zhuang</first><last>Li</last><affiliation>Monash University</affiliation></author>
      <author><first>Yuyang</first><last>Chai</last><affiliation>Wuhan University</affiliation></author>
      <author><first>Terry Yue</first><last>Zhuo</last><affiliation>CSIRO’s Data61 and Monash University</affiliation></author>
      <author><first>Lizhen</first><last>Qu</last><affiliation>Monash University</affiliation></author>
      <author><first>Gholamreza</first><last>Haffari</last><affiliation>Monash University</affiliation></author>
      <author><first>Fei</first><last>Li</last><affiliation>Wuhan University</affiliation></author>
      <author><first>Donghong</first><last>Ji</last><affiliation>Wuhan University</affiliation></author>
      <author><first>Quan Hung</first><last>Tran</last><affiliation>Adobe Research</affiliation></author>
      <pages>6377-6390</pages>
      <abstract>Textual scene graph parsing has become increasingly important in various vision-language applications, including image caption evaluation and image retrieval. However, existing scene graph parsers that convert image captions into scene graphs often suffer from two types of errors. First, the generated scene graphs fail to capture the true semantics of the captions or the corresponding images, resulting in a lack of faithfulness. Second, the generated scene graphs have high inconsistency, with the same semantics represented by different annotations. To address these challenges, we propose a novel dataset, which involves re-annotating the captions in Visual Genome (VG) using a new intermediate representation called FACTUAL-MR. FACTUAL-MR can be directly converted into faithful and consistent scene graph annotations. Our experimental results clearly demonstrate that the parser trained on our dataset outperforms existing approaches in terms of faithfulness and consistency. This improvement leads to a significant performance boost in both image caption evaluation and zero-shot image retrieval tasks. Furthermore, we introduce a novel metric for measuring scene graph similarity, which, when combined with the improved scene graph parser, achieves state-of-the-art (SOTA) results on multiple benchmark datasets for the aforementioned tasks.</abstract>
      <url hash="341eae6a">2023.findings-acl.398</url>
      <bibkey>li-etal-2023-factual</bibkey>
      <doi>10.18653/v1/2023.findings-acl.398</doi>
    </paper>
    <paper id="399">
      <title>Target-Oriented Relation Alignment for Cross-Lingual Stance Detection</title>
      <author><first>Ruike</first><last>Zhang</last><affiliation>Institute of Automation, Chinese Academy of Sciences</affiliation></author>
      <author><first>Nan</first><last>Xu</last><affiliation>Institute of Automation, Chinese Academy of Sciences</affiliation></author>
      <author><first>Hanxuan</first><last>Yang</last><affiliation>University of Chinese Academy of Sciences</affiliation></author>
      <author><first>Yuan</first><last>Tian</last><affiliation>Institute of Automation, Chinese Academy of Sciences</affiliation></author>
      <author><first>Wenji</first><last>Mao</last><affiliation>Chinese Academy of Sciences</affiliation></author>
      <pages>6391-6404</pages>
      <abstract>Stance detection is an important task in text mining and social media analytics, aiming to automatically identify the user’s attitude toward a specific target from text, and has wide applications in a variety of domains. Previous work on stance detection has mainly focused on monolingual setting. To address the problem of imbalanced language resources, cross-lingual stance detection is proposed to transfer the knowledge learned from a high-resource (source) language (typically English) to another low-resource (target) language. However, existing research on cross-lingual stance detection has ignored the inconsistency in the occurrences and distributions of targets between languages, which consequently degrades the performance of stance detection in low-resource languages. In this paper, we first identify the target inconsistency issue in cross-lingual stance detection, and propose a fine-grained Target-oriented Relation Alignment (TaRA) method for the task, which considers both target-level associations and language-level alignments. Specifically, we propose the Target Relation Graph to learn the in-language and cross-language target associations. We further devise the relation alignment strategy to enable knowledge transfer between semantically correlated targets across languages. Experimental results on the representative datasets demonstrate the effectiveness of our method compared to competitive methods under variant settings.</abstract>
      <url hash="ecd0ffca">2023.findings-acl.399</url>
      <bibkey>zhang-etal-2023-target</bibkey>
      <doi>10.18653/v1/2023.findings-acl.399</doi>
    </paper>
    <paper id="400">
      <title><fixed-case>N</fixed-case>on<fixed-case>F</fixed-case>act<fixed-case>S</fixed-case>: <fixed-case>N</fixed-case>on<fixed-case>F</fixed-case>actual Summary Generation for Factuality Evaluation in Document Summarization</title>
      <author><first>Amir</first><last>Soleimani</last><affiliation>University of Amsterdam</affiliation></author>
      <author><first>Christof</first><last>Monz</last><affiliation>University of Amsterdam</affiliation></author>
      <author><first>Marcel</first><last>Worring</last><affiliation>university of amsterdam</affiliation></author>
      <pages>6405-6419</pages>
      <abstract>Pre-trained abstractive summarization models can generate fluent summaries and achieve high ROUGE scores. Previous research has found that these models often generate summaries that are inconsistent with their context document and contain nonfactual information. To evaluate factuality in document summarization, a document-level Natural Language Inference (NLI) classifier can be used. However, training such a classifier requires large-scale high-quality factual and nonfactual samples. To that end, we introduce NonFactS, a data generation model, to synthesize nonfactual summaries given a context document and a human-annotated (reference) factual summary. Compared to previous methods, our nonfactual samples are more abstractive and more similar to their corresponding factual samples, resulting in state-of-the-art performance on two factuality evaluation benchmarks, FALSESUM and SUMMAC. Our experiments demonstrate that even without human-annotated summaries, NonFactS can use random sentences to generate nonfactual summaries and a classifier trained on these samples generalizes to out-of-domain documents.</abstract>
      <url hash="2913222a">2023.findings-acl.400</url>
      <bibkey>soleimani-etal-2023-nonfacts</bibkey>
      <doi>10.18653/v1/2023.findings-acl.400</doi>
    </paper>
    <paper id="401">
      <title>When to Read Documents or <fixed-case>QA</fixed-case> History: On Unified and Selective Open-domain <fixed-case>QA</fixed-case></title>
      <author><first>Kyungjae</first><last>Lee</last><affiliation>LG AI Research</affiliation></author>
      <author><first>Sang-eun</first><last>Han</last><affiliation>Seoul National University</affiliation></author>
      <author><first>Seung-won</first><last>Hwang</last><affiliation>Seoul National University</affiliation></author>
      <author><first>Moontae</first><last>Lee</last><affiliation>University of Illinois at Chicago</affiliation></author>
      <pages>6420-6432</pages>
      <abstract>This paper studies the problem of open-domain question answering, with the aim of answering a diverse range of questions leveraging knowledge resources. Two types of sources, QA-pair and document corpora, have been actively leveraged with the following complementary strength. The former is highly precise when the paraphrase of given question q was seen and answered during training, often posed as a retrieval problem, while the latter generalizes better for unseen questions. A natural follow-up is thus leveraging both models, while a naive pipelining or integration approaches have failed to bring additional gains over either model alone. Our distinction is interpreting the problem as calibration, which estimates the confidence of predicted answers as an indicator to decide when to use a document or QA-pair corpus. The effectiveness of our method was validated on widely adopted benchmarks such as Natural Questions and TriviaQA.</abstract>
      <url hash="43f0b855">2023.findings-acl.401</url>
      <bibkey>lee-etal-2023-read</bibkey>
      <doi>10.18653/v1/2023.findings-acl.401</doi>
    </paper>
    <paper id="402">
      <title>Interpretable Automatic Fine-grained Inconsistency Detection in Text Summarization</title>
      <author><first>Hou Pong</first><last>Chan</last><affiliation>University of Macau</affiliation></author>
      <author><first>Qi</first><last>Zeng</last><affiliation>University of Illinois at Urbana-Champaign</affiliation></author>
      <author><first>Heng</first><last>Ji</last><affiliation>University of Illinois at Urbana-Champaign and Amazon (Amazon Scholar)</affiliation></author>
      <pages>6433-6444</pages>
      <abstract>Existing factual consistency evaluation approaches for text summarization provide binary predictions and limited insights into the weakness of summarization systems. Therefore, we propose the task of fine-grained inconsistency detection, the goal of which is to predict the fine-grained types of factual errors in a summary. Motivated by how humans inspect factual inconsistency in summaries, we propose an interpretable fine-grained inconsistency detection model, FineGrainFact, which explicitly represents the facts in the documents and summaries with semantic frames extracted by semantic role labeling, and highlights the related semantic frames to predict inconsistency. The highlighted semantic frames help verify predicted error types and correct inconsistent summaries. Experiment results demonstrate that our model outperforms strong baselines and provides evidence to support or refute the summary.</abstract>
      <url hash="3bf89bdb">2023.findings-acl.402</url>
      <bibkey>chan-etal-2023-interpretable</bibkey>
      <doi>10.18653/v1/2023.findings-acl.402</doi>
    </paper>
    <paper id="403">
      <title>A Multi-dimensional study on Bias in Vision-Language models</title>
      <author><first>Gabriele</first><last>Ruggeri</last><affiliation>Università degli studi di Trieste</affiliation></author>
      <author><first>Debora</first><last>Nozza</last><affiliation>Bocconi University</affiliation></author>
      <pages>6445-6455</pages>
      <abstract>In recent years, joint Vision-Language (VL) models have increased in popularity and capability. Very few studies have attempted to investigate bias in VL models, even though it is a well-known issue in both individual modalities. This paper presents the first multi-dimensional analysis of bias in English VL models, focusing on gender, ethnicity, and age as dimensions. When subjects are input as images, pre-trained VL models complete a neutral template with a hurtful word 5% of the time, with higher percentages for female and young subjects. Bias presence in downstream models has been tested on Visual Question Answering. We developed a novel bias metric called the Vision-Language Association Test based on questions designed to elicit biased associations between stereotypical concepts and targets. Our findings demonstrate that pre-trained VL models contain biases that are perpetuated in downstream tasks.</abstract>
      <url hash="30921b38">2023.findings-acl.403</url>
      <bibkey>ruggeri-nozza-2023-multi</bibkey>
      <doi>10.18653/v1/2023.findings-acl.403</doi>
    </paper>
    <paper id="404">
      <title>Correction of Errors in Preference Ratings from Automated Metrics for Text Generation</title>
      <author><first>Jan</first><last>Deriu</last><affiliation>Zurich University of Applied Sciences</affiliation></author>
      <author><first>Pius</first><last>von Däniken</last><affiliation>Zurich University of Applied Sciences ZHAW</affiliation></author>
      <author><first>Don</first><last>Tuggener</last><affiliation>Zurich University of Applied Sciences</affiliation></author>
      <author><first>Mark</first><last>Cieliebak</last><affiliation>Zurich University of Applied Sciences</affiliation></author>
      <pages>6456-6474</pages>
      <abstract>A major challenge in the field of Text Generation is evaluation: Human evaluations are cost-intensive, and automated metrics often display considerable disagreements with human judgments. In this paper, we propose to apply automated metrics for Text Generation in a preference-based evaluation protocol. The protocol features a statistical model that incorporates various levels of uncertainty to account for the error-proneness of the metrics. We show that existing metrics are generally over-confident in assigning significant differences between systems. As a remedy, the model allows to combine human ratings with automated ratings. We show that it can reduce the required amounts of human ratings to arrive at robust and statistically significant results by more than 50%, while yielding the same evaluation outcome as the pure human evaluation in 95% of cases. We showcase the benefits of the evaluation protocol for three text generation tasks: dialogue systems, machine translation, and text summarization.</abstract>
      <url hash="09517fa8">2023.findings-acl.404</url>
      <bibkey>deriu-etal-2023-correction</bibkey>
      <doi>10.18653/v1/2023.findings-acl.404</doi>
    </paper>
    <paper id="405">
      <title><fixed-case>PEER</fixed-case>: Pre-training <fixed-case>ELECTRA</fixed-case> Extended by Ranking</title>
      <author><first>Ru</first><last>He</last><affiliation>Alibaba DAMO Academy</affiliation></author>
      <author><first>Wei</first><last>Wang</last><affiliation>Alibaba Group</affiliation></author>
      <author><first>Songfang</first><last>Huang</last><affiliation>Alibaba DAMO Academy</affiliation></author>
      <author><first>Fei</first><last>Huang</last><affiliation>Alibaba DAMO Academy</affiliation></author>
      <pages>6475-6491</pages>
      <abstract>The BERT model and its variants have made great achievements in many downstream natural language processing tasks. The achievements of these models, however, demand highly expensive pre-training computation cost. To address this pre-training efficiency issue, the ELECTRA model is proposed to use a discriminator to perform replaced token detection (RTD) task, that is, to classify whether each input token is original or replaced by a generator. The RTD task performed by the ELECTRA accelerates pre-training so substantially, such that it is very challenging to further improve the pre-training efficiency established by the ELECTRA by using or adding other pre-training tasks, as the recent comprehensive study of Bajaj et al. (2022) summarizes. To further advance this pre-training efficiency frontier, in this paper we propose to extend the RTD task into a task of ranking input tokens according to K different quality levels. Essentially, we generalize the binary classifier in the ELECTRA into a K-level ranker to undertake a more precise task with negligible additional computation cost. Our extensive experiments show that our proposed method is able to outperform the state-of-the-art pre-training efficient models including ELECTRA in downstream GLUE tasks given the same computation cost.</abstract>
      <url hash="9ac27abb">2023.findings-acl.405</url>
      <bibkey>he-etal-2023-peer</bibkey>
      <doi>10.18653/v1/2023.findings-acl.405</doi>
    </paper>
    <paper id="406">
      <title><fixed-case>ML</fixed-case>-<fixed-case>LMCL</fixed-case>: Mutual Learning and Large-Margin Contrastive Learning for Improving <fixed-case>ASR</fixed-case> Robustness in Spoken Language Understanding</title>
      <author><first>Xuxin</first><last>Cheng</last><affiliation>Peking University</affiliation></author>
      <author><first>Bowen</first><last>Cao</last><affiliation>Peking University</affiliation></author>
      <author><first>Qichen</first><last>Ye</last><affiliation>Peking University</affiliation></author>
      <author><first>Zhihong</first><last>Zhu</last><affiliation>Peking University</affiliation></author>
      <author><first>Hongxiang</first><last>Li</last><affiliation>Peking University</affiliation></author>
      <author><first>Yuexian</first><last>Zou</last><affiliation>Peking University</affiliation></author>
      <pages>6492-6505</pages>
      <abstract>Spoken language understanding (SLU) is a fundamental task in the task-oriented dialogue systems. However, the inevitable errors from automatic speech recognition (ASR) usually impair the understanding performance and lead to error propagation. Although there are some attempts to address this problem through contrastive learning, they (1) treat clean manual transcripts and ASR transcripts equally without discrimination in fine-tuning; (2) neglect the fact that the semantically similar pairs are still pushed away when applying contrastive learning; (3) suffer from the problem of Kullback–Leibler (KL) vanishing. In this paper, we propose Mutual Learning and Large-Margin Contrastive Learning (ML-LMCL), a novel framework for improving ASR robustness in SLU. Specifically, in fine-tuning, we apply mutual learning and train two SLU models on the manual transcripts and the ASR transcripts, respectively, aiming to iteratively share knowledge between these two models. We also introduce a distance polarization regularizer to avoid pushing away the intra-cluster pairs as much as possible. Moreover, we use a cyclical annealing schedule to mitigate KL vanishing issue. Experiments on three datasets show that ML-LMCL outperforms existing models and achieves new state-of-the-art performance.</abstract>
      <url hash="11df11d7">2023.findings-acl.406</url>
      <bibkey>cheng-etal-2023-ml</bibkey>
      <doi>10.18653/v1/2023.findings-acl.406</doi>
    </paper>
    <paper id="407">
      <title>Guiding Dialogue Agents to Complex Semantic Targets by Dynamically Completing Knowledge Graph</title>
      <author><first>Yue</first><last>Tan</last><affiliation>Tianjin University</affiliation></author>
      <author><first>Bo</first><last>Wang</last><affiliation>Tianjin University</affiliation></author>
      <author><first>Anqi</first><last>Liu</last><affiliation>TianJin University</affiliation></author>
      <author><first>Dongming</first><last>Zhao</last><affiliation>Artificial Intelligence Laboratory of China Mobile Communications Group Tianjin Co., Ltd</affiliation></author>
      <author><first>Kun</first><last>Huang</last><affiliation>China Mobile</affiliation></author>
      <author><first>Ruifang</first><last>He</last><affiliation>Tianjin University</affiliation></author>
      <author><first>Yuexian</first><last>Hou</last><affiliation>Tianjin University</affiliation></author>
      <pages>6506-6518</pages>
      <abstract>In the target-oriented dialogue, the representation and achievement of targets are two interrelated essential issues. In current approaches, the target is typically supposed to be a single object represented as a word, which makes it relatively easy to achieve the target through dialogue with the help of a knowledge graph (KG). However, when the target has complex semantics, the existing knowledge graph is often incomplete in tracking complex semantic relations. This paper studies target-oriented dialog where the target is a topic sentence. We combine the methods of knowledge retrieval and relationship prediction to construct a context-related dynamic KG. On dynamic KG, we can track the implicit semantic paths in the speaker’s mind that may not exist in the existing KGs. In addition, we also designed a novel metric to evaluate the tracked path automatically. The experimental results show that our method can control the agent more logically and smoothly toward the complex target.</abstract>
      <url hash="ea6c504d">2023.findings-acl.407</url>
      <bibkey>tan-etal-2023-guiding</bibkey>
      <doi>10.18653/v1/2023.findings-acl.407</doi>
    </paper>
    <paper id="408">
      <title>Chain of Thought Prompting Elicits Knowledge Augmentation</title>
      <author><first>Dingjun</first><last>Wu</last><affiliation>Tsinghua University</affiliation></author>
      <author><first>Jing</first><last>Zhang</last><affiliation>Renmin University of China</affiliation></author>
      <author><first>Xinmei</first><last>Huang</last><affiliation>Renmin University of China</affiliation></author>
      <pages>6519-6534</pages>
      <abstract>The knowledge-augmented deep learning paradigm refers to a paradigm in which domain knowledge is identified and integrated into deep models. Conventional methods typically employ task-specific approaches to gather external knowledge from various sources. In contrast, large language models are extensively pre-trained and can serve as a comprehensive source of external knowledge. In this paper, we propose CoT-KA, a Chain-of-Thought-based method that augments knowledge for deep learning. CoT-KA avoids the need for additional knowledge retrieval or knowledge reasoning models, as required in conventional augmentation methods. Our results demonstrate that CoT-KA outperforms both pure CoT-based methods and the non-augmented method across the majority of eleven publicly available benchmarks for various reasoning tasks.</abstract>
      <url hash="38b2b7c8">2023.findings-acl.408</url>
      <bibkey>wu-etal-2023-chain</bibkey>
      <doi>10.18653/v1/2023.findings-acl.408</doi>
    </paper>
    <paper id="409">
      <title><fixed-case>TACR</fixed-case>: A Table Alignment-based Cell Selection Method for <fixed-case>H</fixed-case>ybrid<fixed-case>QA</fixed-case></title>
      <author><first>Jian</first><last>Wu</last><affiliation>tokyo institute of technology</affiliation></author>
      <author><first>Yicheng</first><last>Xu</last><affiliation>Nanyang Technological University</affiliation></author>
      <author><first>Yan</first><last>Gao</last><affiliation>Microsoft</affiliation></author>
      <author><first>Jian-Guang</first><last>Lou</last><affiliation>Microsoft</affiliation></author>
      <author><first>Börje</first><last>Karlsson</last><affiliation>Beijing Academy of Artificial Intelligence (BAAI)</affiliation></author>
      <author><first>Manabu</first><last>Okumura</last><affiliation>Tokyo Institute of Technology</affiliation></author>
      <pages>6535-6549</pages>
      <abstract>Hybrid Question-Answering (HQA), which targets reasoning over tables and passages linked from table cells, has witnessed significant research in recent years. A common challenge in HQA and other passage-table QA datasets is that it is generally unrealistic to iterate over all table rows, columns, and linked passages to retrieve evidence. Such a challenge made it difficult for previous studies to show their reasoning ability in retrieving answers. To bridge this gap, we propose a novel Table-alignment-based Cell-selection and Reasoning model (TACR) for hybrid text and table QA, evaluated on the HybridQA and WikiTableQuestions datasets. In evidence retrieval, we design a table-question-alignment enhanced cell-selection method to retrieve fine-grained evidence. In answer reasoning, we incorporate a QA module that treats the row containing selected cells as context. Experimental results over the HybridQA and WikiTableQuestions (WTQ) datasets show that TACR achieves state-of-the-art results on cell selection and outperforms fine-grained evidence retrieval baselines on HybridQA, while achieving competitive performance on WTQ. We also conducted a detailed analysis to demonstrate that being able to align questions to tables in the cell-selection stage can result in important gains from experiments of over 90% table row and column selection accuracy, meanwhile also improving output explainability.</abstract>
      <url hash="d8bfe448">2023.findings-acl.409</url>
      <bibkey>wu-etal-2023-tacr</bibkey>
      <doi>10.18653/v1/2023.findings-acl.409</doi>
    </paper>
    <paper id="410">
      <title>Modeling Cross-Cultural Pragmatic Inference with Codenames Duet</title>
      <author><first>Omar</first><last>Shaikh</last><affiliation>Stanford University</affiliation></author>
      <author><first>Caleb</first><last>Ziems</last><affiliation>Georgia Institute of Technology</affiliation></author>
      <author><first>William</first><last>Held</last><affiliation>Georgia Tech</affiliation></author>
      <author><first>Aryan</first><last>Pariani</last><affiliation>Georgia Institute of Technology</affiliation></author>
      <author><first>Fred</first><last>Morstatter</last><affiliation>USC Information Sciences Institute</affiliation></author>
      <author><first>Diyi</first><last>Yang</last><affiliation>Stanford University</affiliation></author>
      <pages>6550-6569</pages>
      <abstract>Pragmatic reference enables efficient interpersonal communication. Prior work uses simple reference games to test models of pragmatic reasoning, often with unidentified speakers and listeners. In practice, however, speakers’ sociocultural background shapes their pragmatic assumptions. For example, readers of this paper assume NLP refers to Natural Language Processing, and not “Neuro-linguistic Programming.” This work introduces the Cultural Codes dataset, which operationalizes sociocultural pragmatic inference in a simple word reference game. Cultural Codes is based on the multi-turn collaborative two-player game, Codenames Duet. Our dataset consists of 794 games with 7,703 turns, distributed across 153 unique players. Alongside gameplay, we collect information about players’ personalities, values, and demographics. Utilizing theories of communication and pragmatics, we predict each player’s actions via joint modeling of their sociocultural priors and the game context. Our experiments show that accounting for background characteristics significantly improves model performance for tasks related to both clue-giving and guessing, indicating that sociocultural priors play a vital role in gameplay decisions.</abstract>
      <url hash="af75f956">2023.findings-acl.410</url>
      <bibkey>shaikh-etal-2023-modeling</bibkey>
      <doi>10.18653/v1/2023.findings-acl.410</doi>
    </paper>
    <paper id="411">
      <title>Werewolf Among Us: Multimodal Resources for Modeling Persuasion Behaviors in Social Deduction Games</title>
      <author><first>Bolin</first><last>Lai</last><affiliation>Georgia Institute of Technology</affiliation></author>
      <author><first>Hongxin</first><last>Zhang</last><affiliation>Shanghai Jiao Tong University</affiliation></author>
      <author><first>Miao</first><last>Liu</last><affiliation>META AI</affiliation></author>
      <author><first>Aryan</first><last>Pariani</last><affiliation>Georgia Institute of Technology</affiliation></author>
      <author><first>Fiona</first><last>Ryan</last><affiliation>Georgia Institute of Technology</affiliation></author>
      <author><first>Wenqi</first><last>Jia</last><affiliation>Georgia Institute of Technology</affiliation></author>
      <author><first>Shirley Anugrah</first><last>Hayati</last><affiliation>University of Minnesota</affiliation></author>
      <author><first>James</first><last>Rehg</last><affiliation>University of Illinois, Urbana-Champaign</affiliation></author>
      <author><first>Diyi</first><last>Yang</last><affiliation>Stanford University</affiliation></author>
      <pages>6570-6588</pages>
      <abstract>Persuasion modeling is a key building block for conversational agents. Existing works in this direction are limited to analyzing textual dialogue corpus. We argue that visual signals also play an important role in understanding human persuasive behaviors. In this paper, we introduce the first multimodal dataset for modeling persuasion behaviors. Our dataset includes 199 dialogue transcriptions and videos captured in a multi-player social deduction game setting, 26,647 utterance level annotations of persuasion strategy, and game level annotations of deduction game outcomes. We provide extensive experiments to show how dialogue context and visual signals benefit persuasion strategy prediction. We also explore the generalization ability of language models for persuasion modeling and the role of persuasion strategies in predicting social deduction game outcomes. Our dataset can be found at https://persuasion-deductiongame. socialai-data.org. The codes and models are available at <url>https://github.com/SALT-NLP/PersuationGames</url>.</abstract>
      <url hash="b07ac726">2023.findings-acl.411</url>
      <bibkey>lai-etal-2023-werewolf</bibkey>
      <doi>10.18653/v1/2023.findings-acl.411</doi>
    </paper>
    <paper id="412">
      <title>Long to reign over us: A Case Study of Machine Translation and a New Monarch</title>
      <author><first>Rebecca</first><last>Knowles</last><affiliation>National Research Council Canada</affiliation></author>
      <author><first>Samuel</first><last>Larkin</last><affiliation>National Research Council Canada</affiliation></author>
      <pages>6589-6598</pages>
      <abstract>Novel terminology and changes in terminology are often a challenge for machine translation systems. The passing of Queen Elizabeth II and the accession of King Charles III provide a striking example of translation shift in the real world, particularly in translation contexts that have ambiguity. Examining translation between French and English, we present a focused case-study of translations about King Charles III as produced both by publicly-available MT systems and by a neural machine translation system trained specifically on Canadian parliamentary text. We find that even in cases where human translators would have adequate context to disambiguate terms from the source language, machine translation systems do not always produce the expected output. Where we are able to analyze the training data, we note that this may represent artifacts in the data, raising important questions about machine translation updates in light of real world events.</abstract>
      <url hash="bb201bf1">2023.findings-acl.412</url>
      <bibkey>knowles-larkin-2023-long</bibkey>
      <doi>10.18653/v1/2023.findings-acl.412</doi>
    </paper>
    <paper id="413">
      <title>A Unified Generative Approach to Product Attribute-Value Identification</title>
      <author><first>Keiji</first><last>Shinzato</last><affiliation>Rakuten USA Inc.</affiliation></author>
      <author><first>Naoki</first><last>Yoshinaga</last><affiliation>Institute of Industrial Science, The University of Tokyo</affiliation></author>
      <author><first>Yandi</first><last>Xia</last><affiliation>Rakuten USA inc.</affiliation></author>
      <author><first>Wei-Te</first><last>Chen</last><affiliation>Rakuten USA Inc.</affiliation></author>
      <pages>6599-6612</pages>
      <abstract>Product attribute-value identification (PAVI) has been studied to link products on e-commerce sites with their attribute values (e.g., ⟨Material, Cotton⟩) using product text as clues. Technical demands from real-world e-commerce platforms require PAVI methods to handle unseen values, multi-attribute values, and canonicalized values, which are only partly addressed in existing extraction- and classification-based approaches. Motivated by this, we explore a generative approach to the PAVI task. We finetune a pre-trained generative model, T5, to decode a set of attribute-value pairs as a target sequence from the given product text. Since the attribute value pairs are unordered set elements, how to linearize them will matter; we, thus, explore methods of composing an attribute-value pair and ordering the pairs for the task. Experimental results confirm that our generation-based approach outperforms the existing extraction and classification-based methods on large-scale real-world datasets meant for those methods.</abstract>
      <url hash="6de61497">2023.findings-acl.413</url>
      <bibkey>shinzato-etal-2023-unified</bibkey>
      <doi>10.18653/v1/2023.findings-acl.413</doi>
    </paper>
    <paper id="414">
      <title>K-<fixed-case>U</fixed-case>ni<fixed-case>M</fixed-case>orph: <fixed-case>K</fixed-case>orean <fixed-case>U</fixed-case>niversal <fixed-case>M</fixed-case>orphology and its Feature Schema</title>
      <author><first>Eunkyul</first><last>Jo</last><affiliation>University of British Columbia</affiliation></author>
      <author><first>Kim</first><last>Kyuwon</last><affiliation>Seoul National University</affiliation></author>
      <author><first>Xihan</first><last>Wu</last><affiliation>University of British Columbia</affiliation></author>
      <author><first>KyungTae</first><last>Lim</last><affiliation>Seoul National University of Science and Technology</affiliation></author>
      <author><first>Jungyeul</first><last>Park</last><affiliation>The University of British Columbia</affiliation></author>
      <author><first>Chulwoo</first><last>Park</last><affiliation>Anyang University</affiliation></author>
      <pages>6613-6623</pages>
      <abstract>We present in this work a new Universal Morphology dataset for Korean. Previously, the Korean language has been underrepresented in the field of morphological paradigms amongst hundreds of diverse world languages. Hence, we propose this Universal Morphological paradigms for the Korean language that preserve its distinct characteristics. For our K-UniMorph dataset, we outline each grammatical criterion in detail for the verbal endings, clarify how to extract inflected forms, and demonstrate how we generate the morphological schemata. This dataset adopts morphological feature schema from CITATION and CITATION for the Korean language as we extract inflected verb forms from the Sejong morphologically analyzed corpus that is one of the largest annotated corpora for Korean. During the data creation, our methodology also includes investigating the correctness of the conversion from the Sejong corpus. Furthermore, we carry out the inflection task using three different Korean word forms: letters, syllables and morphemes. Finally, we discuss and describe future perspectives on Korean morphological paradigms and the dataset.</abstract>
      <url hash="9e72c497">2023.findings-acl.414</url>
      <bibkey>jo-etal-2023-k</bibkey>
      <doi>10.18653/v1/2023.findings-acl.414</doi>
    </paper>
    <paper id="415">
      <title>How does the brain process syntactic structure while listening?</title>
      <author><first>Subba Reddy</first><last>Oota</last><affiliation>Inria-Research, France</affiliation></author>
      <author><first>Mounika</first><last>Marreddy</last><affiliation>IIITH</affiliation></author>
      <author><first>Manish</first><last>Gupta</last><affiliation>IIIT</affiliation></author>
      <author><first>Raju</first><last>Bapi</last><affiliation>International Institute of Information Technology Hyderabad</affiliation></author>
      <pages>6624-6647</pages>
      <abstract>Syntactic parsing is the task of assigning a syntactic structure to a sentence. There are two popular syntactic parsing methods: constituency and dependency parsing. Recent works have used syntactic embeddings based on constituency trees, incremental top-down parsing, and other word syntactic features for brain activity prediction given the text stimuli to study how the syntax structure is represented in the brain’s language network. However, the effectiveness of dependency parse trees or the relative predictive power of the various syntax parsers across brain areas, especially for the listening task, is yet unexplored. In this study, we investigate the predictive power of the brain encoding models in three settings: (i) individual performance of the constituency and dependency syntactic parsing based embedding methods, (ii) efficacy of these syntactic parsing based embedding methods when controlling for basic syntactic signals, (iii) relative effectiveness of each of the syntactic embedding methods when controlling for the other. Further, we explore the relative importance of syntactic information (from these syntactic embedding methods) versus semantic information using BERT embeddings. We find that constituency parsers help explain activations in the temporal lobe and middle-frontal gyrus, while dependency parsers better encode syntactic structure in the angular gyrus and posterior cingulate cortex. Although semantic signals from BERT are more effective compared to any of the syntactic features or embedding methods, syntactic embedding methods explain additional variance for a few brain regions.</abstract>
      <url hash="cc6d43a5">2023.findings-acl.415</url>
      <bibkey>oota-etal-2023-brain</bibkey>
      <doi>10.18653/v1/2023.findings-acl.415</doi>
    </paper>
    <paper id="416">
      <title>Towards Imperceptible Document Manipulations against Neural Ranking Models</title>
      <author><first>Xuanang</first><last>Chen</last><affiliation>University of Chinese Academy of Sciences</affiliation></author>
      <author><first>Ben</first><last>He</last><affiliation>University of Chinese Academy of Sciences</affiliation></author>
      <author><first>Zheng</first><last>Ye</last><affiliation>South-Central University for Nationalities</affiliation></author>
      <author><first>Le</first><last>Sun</last><affiliation>ISCAS</affiliation></author>
      <author><first>Yingfei</first><last>Sun</last><affiliation>University of Chinese Academy of Sciences</affiliation></author>
      <pages>6648-6664</pages>
      <abstract>Adversarial attacks have gained traction in order to identify vulnerabilities in neural ranking models (NRMs), but current attack methods often introduce noticeable errors. Moreover, current methods rely heavily on using a well-imitated surrogate NRM to guarantee the attack effect, making them difficult to use in practice. This paper proposes a framework called Imperceptible DocumEnt Manipulation (IDEM) to produce adversarial documents that are less noticeable to both algorithms and humans. IDEM instructs a well-established generative language model like BART to generate error-free connection sentences, and employs a separate position-wise merging strategy to balance between relevance and coherence of the perturbed text. Evaluation results on the MS MARCO benchmark demonstrate that IDEM outperforms strong baselines while preserving fluency and correctness of the target documents. Furthermore, the separation of adversarial text generation from the surrogate NRM makes IDEM more robust and less affected by the quality of the surrogate NRM.</abstract>
      <url hash="f0c581d5">2023.findings-acl.416</url>
      <bibkey>chen-etal-2023-towards</bibkey>
      <doi>10.18653/v1/2023.findings-acl.416</doi>
    </paper>
    <paper id="417">
      <title>Ask an Expert: Leveraging Language Models to Improve Strategic Reasoning in Goal-Oriented Dialogue Models</title>
      <author><first>Qiang</first><last>Zhang</last><affiliation>The University of Tokyo</affiliation></author>
      <author><first>Jason</first><last>Naradowsky</last><affiliation>University of Tokyo</affiliation></author>
      <author><first>Yusuke</first><last>Miyao</last><affiliation>University of Tokyo</affiliation></author>
      <pages>6665-6694</pages>
      <abstract>Existing dialogue models may encounter scenarios which are not well-represented in the training data, and as a result generate responses that are unnatural, inappropriate, or unhelpful. We propose the “Ask an Expert” framework in which the model is trained with access to an “expert” which it can consult at each turn. Advice is solicited via a structured dialogue with the expert, and the model is optimized to selectively utilize (or ignore) it given the context and dialogue history. In this work the expert takes the form of an LLM.We evaluate this framework in a mental health support domain, where the structure of the expert conversation is outlined by pre-specified prompts which reflect a reasoning strategy taught to practitioners in the field. Blenderbot models utilizing “Ask an Expert” show quality improvements across all expert sizes, including those with fewer parameters than the dialogue model itself. Our best model provides a ~10% improvement over baselines, approaching human-level scores on “engingingness” and “helpfulness” metrics.</abstract>
      <url hash="db2c6501">2023.findings-acl.417</url>
      <bibkey>zhang-etal-2023-ask</bibkey>
      <doi>10.18653/v1/2023.findings-acl.417</doi>
    </paper>
    <paper id="418">
      <title><fixed-case>S</fixed-case>ci<fixed-case>R</fixed-case>eview<fixed-case>G</fixed-case>en: A Large-scale Dataset for Automatic Literature Review Generation</title>
      <author><first>Tetsu</first><last>Kasanishi</last><affiliation>The University of Tokyo</affiliation></author>
      <author><first>Masaru</first><last>Isonuma</last><affiliation>The University of Tokyo</affiliation></author>
      <author><first>Junichiro</first><last>Mori</last><affiliation>The University of Tokyo</affiliation></author>
      <author><first>Ichiro</first><last>Sakata</last><affiliation>The University of Tokyo</affiliation></author>
      <pages>6695-6715</pages>
      <abstract>Automatic literature review generation is one of the most challenging tasks in natural language processing. Although large language models have tackled literature review generation, the absence of large-scale datasets has been a stumbling block to the progress. We release SciReviewGen, consisting of over 10,000 literature reviews and 690,000 papers cited in the reviews. Based on the dataset, we evaluate recent transformer-based summarization models on the literature review generation task, including Fusion-in-Decoder extended for literature review generation. Human evaluation results show that some machine-generated summaries are comparable to human-written reviews, while revealing the challenges of automatic literature review generation such as hallucinations and a lack of detailed information. Our dataset and code are available at [<url>https://github.com/tetsu9923/SciReviewGen</url>](<url>https://github.com/tetsu9923/SciReviewGen</url>).</abstract>
      <url hash="19a02c1e">2023.findings-acl.418</url>
      <bibkey>kasanishi-etal-2023-scireviewgen</bibkey>
      <doi>10.18653/v1/2023.findings-acl.418</doi>
    </paper>
    <paper id="419">
      <title>Revisiting Sample Size Determination in Natural Language Understanding</title>
      <author><first>Ernie</first><last>Chang</last><affiliation>Meta AI</affiliation></author>
      <author><first>Muhammad Hassan</first><last>Rashid</last><affiliation>Saarland University</affiliation></author>
      <author><first>Pin-Jie</first><last>Lin</last><affiliation>Saarland Univeristy</affiliation></author>
      <author><first>Changsheng</first><last>Zhao</last><affiliation>Meta</affiliation></author>
      <author><first>Vera</first><last>Demberg</last><affiliation>Saarland University</affiliation></author>
      <author><first>Yangyang</first><last>Shi</last><affiliation>Meta AI</affiliation></author>
      <author><first>Vikas</first><last>Chandra</last><affiliation>Meta</affiliation></author>
      <pages>6716-6724</pages>
      <abstract>Knowing exactly how many data points need to be labeled to achieve a certain model performance is a hugely beneficial step towards reducing the overall budgets for annotation. It pertains to both active learning and traditional data annotation, and is particularly beneficial for low resource scenarios. Nevertheless, it remains a largely under-explored area of research in NLP. We therefore explored various techniques for estimating the training sample size necessary to achieve a targeted performance value. We derived a simple yet effective approach to predict the maximum achievable model performance based on small amount of training samples – which serves as an early indicator during data annotation for data quality and sample size determination. We performed ablation studies on four language understanding tasks, and showed that the proposed approach allows us to forecast model performance within a small margin of mean absolute error (~0.9%) with only 10% data.</abstract>
      <url hash="1ff37832">2023.findings-acl.419</url>
      <bibkey>chang-etal-2023-revisiting</bibkey>
      <doi>10.18653/v1/2023.findings-acl.419</doi>
    </paper>
    <paper id="420">
      <title><fixed-case>T</fixed-case>rans<fixed-case>ESC</fixed-case>: Smoothing Emotional Support Conversation via Turn-Level State Transition</title>
      <author><first>Weixiang</first><last>Zhao</last><affiliation>Harbin Institute of Technology</affiliation></author>
      <author><first>Yanyan</first><last>Zhao</last><affiliation>Harbin Institute of Technology</affiliation></author>
      <author><first>Shilong</first><last>Wang</last><affiliation>Harbin Institute of Technology</affiliation></author>
      <author><first>Bing</first><last>Qin</last><affiliation>Harbin Institute of Technology</affiliation></author>
      <pages>6725-6739</pages>
      <abstract>Emotion Support Conversation (ESC) is an emerging and challenging task with the goal of reducing the emotional distress of people. Previous attempts fail to maintain smooth transitions between utterances in ESC because they ignoring to grasp the fine-grained transition information at each dialogue turn. To solve this problem, we propose to take into account turn-level state Transitions of ESC (TransESC) from three perspectives, including semantics transition, strategy transition and emotion transition, to drive the conversation in a smooth and natural way. Specifically, we construct the state transition graph with a two-step way, named transit-then-interact, to grasp such three types of turn-level transition information. Finally, they are injected into the transition aware decoder to generate more engaging responses. Both automatic and human evaluations on the benchmark dataset demonstrate the superiority of TransESC to generate more smooth and effective supportive responses. Our source code will be publicly available.</abstract>
      <url hash="8ea87149">2023.findings-acl.420</url>
      <bibkey>zhao-etal-2023-transesc</bibkey>
      <doi>10.18653/v1/2023.findings-acl.420</doi>
    </paper>
    <paper id="421">
      <title>Residual Prompt Tuning: improving prompt tuning with residual reparameterization</title>
      <author><first>Anastasiia</first><last>Razdaibiedina</last><affiliation>University of Toronto</affiliation></author>
      <author><first>Yuning</first><last>Mao</last><affiliation>Meta Platforms, Inc.</affiliation></author>
      <author><first>Madian</first><last>Khabsa</last><affiliation>Facebook</affiliation></author>
      <author><first>Mike</first><last>Lewis</last><affiliation>Facebook AI Research</affiliation></author>
      <author><first>Rui</first><last>Hou</last><affiliation>Meta</affiliation></author>
      <author><first>Jimmy</first><last>Ba</last><affiliation>University of Toronto</affiliation></author>
      <author><first>Amjad</first><last>Almahairi</last><affiliation>Meta AI</affiliation></author>
      <pages>6740-6757</pages>
      <abstract>Prompt tuning is one of the successful approaches for parameter-efficient tuning of pre-trained language models. Despite being arguably the most parameter-efficient (tuned soft prompts constitute &lt;0.1% of total parameters), it typically performs worse than other efficient tuning methods and is quite sensitive to hyper-parameters. In this work, we introduce Residual Prompt Tuning - a simple and efficient method that significantly improves the performance and stability of prompt tuning. We propose to reparameterize soft prompt embeddings using a shallow network with a residual connection. Our experiments show that Residual Prompt Tuning significantly outperforms prompt tuning across T5-Large, T5-Base and BERT-Base models. Notably, our method reaches +7 points improvement over prompt tuning on SuperGLUE benchmark with T5-Base model and allows to reduce the prompt length by 10 times without hurting performance. In addition, we show that our approach is robust to the choice of learning rate and prompt initialization, and is effective in few-shot settings.</abstract>
      <url hash="de441963">2023.findings-acl.421</url>
      <bibkey>razdaibiedina-etal-2023-residual</bibkey>
      <doi>10.18653/v1/2023.findings-acl.421</doi>
    </paper>
    <paper id="422">
      <title>Attend, Select and Eliminate: Accelerating Multi-turn Response Selection with Dual-attention-based Content Elimination</title>
      <author><first>Jianxin</first><last>Liang</last><affiliation>Peking University</affiliation></author>
      <author><first>Chang</first><last>Liu</last><affiliation>Peking University</affiliation></author>
      <author><first>Chongyang</first><last>Tao</last><affiliation>Peking University</affiliation></author>
      <author><first>Jiazhan</first><last>Feng</last><affiliation>Peking University</affiliation></author>
      <author><first>Dongyan</first><last>Zhao</last><affiliation>pku.edu.cn</affiliation></author>
      <pages>6758-6770</pages>
      <abstract>Although the incorporation of pre-trained language models (PLMs) significantly pushes the research frontier of multi-turn response selection, it brings a new issue of heavy computation costs. To alleviate this problem and make the PLM-based response selection model both effective and efficient, we propose an inference framework together with a post-training strategy that builds upon any pre-trained transformer-based response selection models to accelerate inference by progressively selecting and eliminating unimportant content under the guidance of context-response dual-attention. Specifically, at each transformer layer, we first identify the importance of each word based on context-to-response and response-to-context attention, then select a number of unimportant words to be eliminated following a retention configuration derived from evolutionary search while passing the rest of the representations into deeper layers. To mitigate the training-inference gap posed by content elimination, we introduce a post-training strategy where we use knowledge distillation to force the model with progressively eliminated content to mimic the predictions of the original model with no content elimination. Experiments on three benchmarks indicate that our method can effectively speeds-up SOTA models without much performance degradation and shows a better trade-off between speed and performance than previous methods.</abstract>
      <url hash="7b40098d">2023.findings-acl.422</url>
      <bibkey>liang-etal-2023-attend</bibkey>
      <doi>10.18653/v1/2023.findings-acl.422</doi>
    </paper>
    <paper id="423">
      <title>Medical Dialogue Generation via Dual Flow Modeling</title>
      <author><first>Kaishuai</first><last>Xu</last><affiliation>The Hong Kong Polytechnic University</affiliation></author>
      <author><first>Wenjun</first><last>Hou</last><affiliation>The Hong Kong Polytechnic University</affiliation></author>
      <author><first>Yi</first><last>Cheng</last><affiliation>Hong Kong Polytechnic University</affiliation></author>
      <author><first>Jian</first><last>Wang</last><affiliation>The Hong Kong Polytechnic University</affiliation></author>
      <author><first>Wenjie</first><last>Li</last><affiliation>The Hong Kong Polytechnic University</affiliation></author>
      <pages>6771-6784</pages>
      <abstract>Medical dialogue systems (MDS) aim to provide patients with medical services, such as diagnosis and prescription. Since most patients cannot precisely describe their symptoms, dialogue understanding is challenging for MDS. Previous studies mainly addressed this by extracting the mentioned medical entities as critical dialogue history information. In this work, we argue that it is also essential to capture the transitions of the medical entities and the doctor’s dialogue acts in each turn, as they help the understanding of how the dialogue flows and enhance the prediction of the entities and dialogue acts to be adopted in the following turn. Correspondingly, we propose a Dual Flow enhanced Medical (DFMed) dialogue generation framework. It extracts the medical entities and dialogue acts used in the dialogue history and models their transitions with an entity-centric graph flow and a sequential act flow, respectively. We employ two sequential models to encode them and devise an interweaving component to enhance their interactions. Experiments on two datasets demonstrate that our method exceeds baselines in both automatic and manual evaluations.</abstract>
      <url hash="904f669c">2023.findings-acl.423</url>
      <bibkey>xu-etal-2023-medical</bibkey>
      <doi>10.18653/v1/2023.findings-acl.423</doi>
    </paper>
    <paper id="424">
      <title>Listen, Decipher and Sign: Toward Unsupervised Speech-to-Sign Language Recognition</title>
      <author><first>Liming</first><last>Wang</last><affiliation>University of Illinois, Urbana Champaign</affiliation></author>
      <author><first>Junrui</first><last>Ni</last><affiliation>Department of Electrical and Computer Engineering, University of Illinois at Urbana-Champaign</affiliation></author>
      <author><first>Heting</first><last>Gao</last><affiliation>University of Illinois at Urbana-Champaign</affiliation></author>
      <author><first>Jialu</first><last>Li</last><affiliation>University of Illinois at Urbana-Champaign</affiliation></author>
      <author><first>Kai Chieh</first><last>Chang</last><affiliation>University of Illinois at Urbana Champaign</affiliation></author>
      <author><first>Xulin</first><last>Fan</last><affiliation>University of Illinois at Urbana-Champaign</affiliation></author>
      <author><first>Junkai</first><last>Wu</last><affiliation>University of Illinois Urbana-Champaign</affiliation></author>
      <author><first>Mark</first><last>Hasegawa-Johnson</last><affiliation>University of Illinois</affiliation></author>
      <author><first>Chang</first><last>Yoo</last><affiliation>kaist</affiliation></author>
      <pages>6785-6800</pages>
      <abstract>Existing supervised sign language recognition systems rely on an abundance of well-annotated data. Instead, an unsupervised speech-to-sign language recognition (SSR-U) system learns to translate between spoken and sign languages by observing only non-parallel speech and sign-language corpora. We propose speech2sign-U, a neural network-based approach capable of both character-level and word-level SSR-U. Our approach significantly outperforms baselines directly adapted from unsupervised speech recognition (ASR-U) models by as much as 50% recall@10 on several challenging American sign language corpora with various levels of sample sizes, vocabulary sizes, and audio and visual variability. The code is available at <url>https://github.com/cactuswiththoughts/UnsupSpeech2Sign.gitcactuswiththoughts/UnsupSpeech2Sign.git</url>.</abstract>
      <url hash="08f92715">2023.findings-acl.424</url>
      <bibkey>wang-etal-2023-listen</bibkey>
      <doi>10.18653/v1/2023.findings-acl.424</doi>
    </paper>
    <paper id="425">
      <title>Distinguishing Address vs. Reference Mentions of Personal Names in Text</title>
      <author><first>Vinodkumar</first><last>Prabhakaran</last><affiliation>Google</affiliation></author>
      <author><first>Aida</first><last>Mostafazadeh Davani</last><affiliation>Google Research</affiliation></author>
      <author><first>Melissa</first><last>Ferguson</last><affiliation>Yale University</affiliation></author>
      <author><first>Stav</first><last>Atir</last><affiliation>University of Wisconsin-Madison</affiliation></author>
      <pages>6801-6809</pages>
      <abstract>Detecting named entities in text has long been a core NLP task. However, not much work has gone into distinguishing whether an entity mention is addressing the entity vs. referring to the entity; e.g., <i>John, would you turn the light off?</i> vs. <i>John turned the light off</i>. While this distinction is marked by a <i>vocative case</i> marker in some languages, many modern Indo-European languages such as English do not use such explicit vocative markers, and the distinction is left to be interpreted in context. In this paper, we present a new annotated dataset that captures the <i>address</i> vs. <i>reference</i> distinction in English, an automatic tagger that performs at 85% accuracy in making this distinction, and demonstrate how this distinction is important in NLP and computational social science applications in English language.</abstract>
      <url hash="4a155658">2023.findings-acl.425</url>
      <bibkey>prabhakaran-etal-2023-distinguishing</bibkey>
      <doi>10.18653/v1/2023.findings-acl.425</doi>
    </paper>
    <paper id="426">
      <title>“Low-Resource” Text Classification: A Parameter-Free Classification Method with Compressors</title>
      <author><first>Zhiying</first><last>Jiang</last><affiliation>University of Waterloo</affiliation></author>
      <author><first>Matthew</first><last>Yang</last><affiliation>University of Waterloo</affiliation></author>
      <author><first>Mikhail</first><last>Tsirlin</last><affiliation>University of Waterloo</affiliation></author>
      <author><first>Raphael</first><last>Tang</last><affiliation>Comcast</affiliation></author>
      <author><first>Yiqin</first><last>Dai</last><affiliation>AFAIK</affiliation></author>
      <author><first>Jimmy</first><last>Lin</last><affiliation>University of Waterloo</affiliation></author>
      <pages>6810-6828</pages>
      <abstract>Deep neural networks (DNNs) are often used for text classification due to their high accuracy. However, DNNs can be computationally intensive, requiring millions of parameters and large amounts of labeled data, which can make them expensive to use, to optimize, and to transfer to out-of-distribution (OOD) cases in practice. In this paper, we propose a non-parametric alternative to DNNs that’s easy, lightweight, and universal in text classification: a combination of a simple compressor like <i>gzip</i> with a <tex-math>k</tex-math>-nearest-neighbor classifier. Without any training parameters, our method achieves results that are competitive with non-pretrained deep learning methods on six in-distribution datasets.It even outperforms BERT on all five OOD datasets, including four low-resource languages. Our method also excels in the few-shot setting, where labeled data are too scarce to train DNNs effectively.</abstract>
      <url hash="0c1efe53">2023.findings-acl.426</url>
      <bibkey>jiang-etal-2023-low</bibkey>
      <doi>10.18653/v1/2023.findings-acl.426</doi>
    </paper>
    <paper id="427">
      <title><fixed-case>LR</fixed-case>-Sum: Summarization for Less-Resourced Languages</title>
      <author><first>Chester</first><last>Palen-Michel</last><affiliation>Brandeis University</affiliation></author>
      <author><first>Constantine</first><last>Lignos</last><affiliation>Brandeis University</affiliation></author>
      <pages>6829-6844</pages>
      <abstract>We introduce LR-Sum, a new permissively-licensed dataset created with the goal of enabling further research in automatic summarization for less-resourced languages.LR-Sum contains human-written summaries for 40 languages, many of which are less-resourced. We describe our process for extracting and filtering the dataset from the Multilingual Open Text corpus (Palen-Michel et al., 2022).The source data is public domain newswire collected from from Voice of America websites, and LR-Sum is released under a Creative Commons license (CC BY 4.0), making it one of the most openly-licensed multilingual summarization datasets. We describe abstractive and extractive summarization experiments to establish baselines and discuss the limitations of this dataset.</abstract>
      <url hash="6c954d7e">2023.findings-acl.427</url>
      <bibkey>palen-michel-lignos-2023-lr</bibkey>
      <doi>10.18653/v1/2023.findings-acl.427</doi>
    </paper>
    <paper id="428">
      <title><fixed-case>RQUGE</fixed-case>: Reference-Free Metric for Evaluating Question Generation by Answering the Question</title>
      <author><first>Alireza</first><last>Mohammadshahi</last><affiliation>IDIAP</affiliation></author>
      <author><first>Thomas</first><last>Scialom</last><affiliation>Meta AI</affiliation></author>
      <author><first>Majid</first><last>Yazdani</last><affiliation>BYJU’S Lab</affiliation></author>
      <author><first>Pouya</first><last>Yanki</last><affiliation>Meta</affiliation></author>
      <author><first>Angela</first><last>Fan</last><affiliation>Facebook AI Research</affiliation></author>
      <author><first>James</first><last>Henderson</last><affiliation>Idiap Research Institute</affiliation></author>
      <author><first>Marzieh</first><last>Saeidi</last><affiliation>Shiftlab AI</affiliation></author>
      <pages>6845-6867</pages>
      <abstract>Existing metrics for evaluating the quality of automatically generated questions such as BLEU, ROUGE, BERTScore, and BLEURT compare the reference and predicted questions, providing a high score when there is a considerable lexical overlap or semantic similarity between the candidate and the reference questions. This approach has two major shortcomings. First, we need expensive human-provided reference questions. Second, it penalises valid questions that may not have high lexical or semantic similarity to the reference questions. In this paper, we propose a new metric, RQUGE, based on the answerability of the candidate question given the context. The metric consists of a question-answering and a span scorer modules, using pre-trained models from existing literature, thus it can be used without any further training. We demonstrate that RQUGE has a higher correlation with human judgment without relying on the reference question. Additionally, RQUGE is shown to be more robust to several adversarial corruptions. Furthermore, we illustrate that we can significantly improve the performance of QA models on out-of-domain datasets by fine-tuning on synthetic data generated by a question generation model and reranked by RQUGE.</abstract>
      <url hash="689a7211">2023.findings-acl.428</url>
      <bibkey>mohammadshahi-etal-2023-rquge</bibkey>
      <doi>10.18653/v1/2023.findings-acl.428</doi>
    </paper>
    <paper id="429">
      <title>Unsupervised Semantic Variation Prediction using the Distribution of Sibling Embeddings</title>
      <author><first>Taichi</first><last>Aida</last><affiliation>Tokyo Metropolitan University</affiliation></author>
      <author><first>Danushka</first><last>Bollegala</last><affiliation>University of Liverpool/Amazon</affiliation></author>
      <pages>6868-6882</pages>
      <abstract>Languages are dynamic entities, where the meanings associated with words constantly change with time. Detecting the semantic variation of words is an important task for various NLP applications that must make time-sensitive predictions. Existing work on semantic variation prediction have predominantly focused on comparing some form of an averaged contextualised representation of a target word computed from a given corpus. However, some of the previously associated meanings of a target word can become obsolete over time (e.g. meaning of gay as happy), while novel usages of existing words are observed (e.g. meaning of cell as a mobile phone).We argue that mean representations alone cannot accurately capture such semantic variations and propose a method that uses the entire cohort of the contextualised embeddings of the target word, which we refer to as the sibling distribution. Experimental results on SemEval-2020 Task 1 benchmark dataset for semantic variation prediction show that our method outperforms prior work that consider only the mean embeddings, and is comparable to the current state-of-the-art. Moreover, a qualitative analysis shows that our method detects important semantic changes in words that are not captured by the existing methods.</abstract>
      <url hash="bb2fc117">2023.findings-acl.429</url>
      <bibkey>aida-bollegala-2023-unsupervised</bibkey>
      <doi>10.18653/v1/2023.findings-acl.429</doi>
    </paper>
    <paper id="430">
      <title><fixed-case>T</fixed-case>ran<fixed-case>SF</fixed-case>ormer: Slow-Fast Transformer for Machine Translation</title>
      <author><first>Bei</first><last>Li</last><affiliation>Northeastern University</affiliation></author>
      <author><first>Yi</first><last>Jing</last><affiliation>NLP Lab Northeastern University</affiliation></author>
      <author><first>Xu</first><last>Tan</last><affiliation>Microsoft Research Asia</affiliation></author>
      <author><first>Zhen</first><last>Xing</last><affiliation>Fudan University</affiliation></author>
      <author><first>Tong</first><last>Xiao</last><affiliation>Northeastern University</affiliation></author>
      <author><first>Jingbo</first><last>Zhu</last><affiliation>Northeastern University</affiliation></author>
      <pages>6883-6896</pages>
      <abstract>Learning multiscale Transformer models has been evidenced as a viable approach to augmenting machine translation systems. Prior research has primarily focused on treating subwords as basic units in developing such systems. However, the incorporation of fine-grained character-level features into multiscale Transformer has not yet been explored. In this work, we present a <b>S</b>low-<b>F</b>ast two-stream learning model, referred to as Tran<b>SF</b>ormer, which utilizes a “slow” branch to deal with subword sequences and a “fast” branch to deal with longer character sequences. This model is efficient since the fast branch is very lightweight by reducing the model width, and yet provides useful fine-grained features for the slow branch. Our TranSFormer shows consistent BLEU improvements (larger than 1 BLEU point) on several machine translation benchmarks.</abstract>
      <url hash="a017f2ae">2023.findings-acl.430</url>
      <bibkey>li-etal-2023-transformer</bibkey>
      <doi>10.18653/v1/2023.findings-acl.430</doi>
    </paper>
    <paper id="431">
      <title>Mitigating the Learning Bias towards Repetition by Self-Contrastive Training for Open-Ended Generation</title>
      <author><first>Jian</first><last>Guan</last><affiliation>Tsinghua University</affiliation></author>
      <author><first>Minlie</first><last>Huang</last><affiliation>Tsinghua University</affiliation></author>
      <pages>6897-6909</pages>
      <abstract>Despite the huge progress in myriad generation tasks, pretrained language models (LMs) such as GPT2 still tend to generate repetitive texts with maximization-based decoding algorithms for open-ended generation. We attribute their overestimation of token-level repetition probabilities to the learning bias: LMs capture simple repetitive patterns faster with the MLE loss. We propose self-contrastive training to penalize the output of a premature checkpoint of the same model when it incorrectly predicts repetition, which is shown to mitigate repetition effectively while maintaining fluency on two datasets. Furthermore, we find that LMs use longer-range dependencies to predict repetitive tokens than non-repetitive ones, which may be the cause of sentence-level repetition loops.</abstract>
      <url hash="00a1b69f">2023.findings-acl.431</url>
      <bibkey>guan-huang-2023-mitigating</bibkey>
      <doi>10.18653/v1/2023.findings-acl.431</doi>
    </paper>
    <paper id="432">
      <title>Digging out Discrimination Information from Generated Samples for Robust Visual Question Answering</title>
      <author><first>Zhiquan</first><last>Wen</last><affiliation>South China University of Technology</affiliation></author>
      <author><first>Yaowei</first><last>Wang</last><affiliation>Peng Cheng Laboratory</affiliation></author>
      <author><first>Mingkui</first><last>Tan</last><affiliation>South China University of Technology</affiliation></author>
      <author><first>Qingyao</first><last>Wu</last><affiliation>South China University of Technology</affiliation></author>
      <author><first>Qi</first><last>Wu</last><affiliation>University of Adelaide</affiliation></author>
      <pages>6910-6928</pages>
      <abstract>Visual Question Answering (VQA) aims to answer a textual question based on a given image. Nevertheless, recent studies have shown that VQA models tend to capture the biases to answer the question, instead of using the reasoning ability, resulting in poor generalisation ability. To alleviate the issue, some existing methods consider the natural distribution of the data, and construct samples to balance the dataset, achieving remarkable performance. However, these methods may encounter some limitations: 1) rely on additional annotations, 2) the generated samples may be inaccurate, e.g., assigned wrong answers, and 3) ignore the power of positive samples. In this paper, we propose a method to Dig out Discrimination information from Generated samples (DDG) to address the above limitations. Specifically, we first construct positive and negative samples in vision and language modalities, without using additional annotations. Then, we introduce a knowledge distillation mechanism to promote the learning of the original samples by the positive samples. Moreover, we impel the VQA models to focus on vision and language modalities using the negative samples. Experimental results on the VQA-CP v2 and VQA v2 datasets show the effectiveness of our DDG.</abstract>
      <url hash="29226dad">2023.findings-acl.432</url>
      <bibkey>wen-etal-2023-digging</bibkey>
      <doi>10.18653/v1/2023.findings-acl.432</doi>
    </paper>
    <paper id="433">
      <title>Words as Gatekeepers: Measuring Discipline-specific Terms and Meanings in Scholarly Publications</title>
      <author><first>Li</first><last>Lucy</last><affiliation>University of California, Berkeley</affiliation></author>
      <author><first>Jesse</first><last>Dodge</last><affiliation>Allen Institute for AI</affiliation></author>
      <author><first>David</first><last>Bamman</last><affiliation>University of California, Berkeley</affiliation></author>
      <author><first>Katherine</first><last>Keith</last><affiliation>Williams College</affiliation></author>
      <pages>6929-6947</pages>
      <abstract>Scholarly text is often laden with jargon, or specialized language that can facilitate efficient in-group communication within fields but hinder understanding for out-groups. In this work, we develop and validate an interpretable approach for measuring scholarly jargon from text. Expanding the scope of prior work which focuses on word types, we use word sense induction to also identify words that are widespread but overloaded with different meanings across fields. We then estimate the prevalence of these discipline-specific words and senses across hundreds of subfields, and show that word senses provide a complementary, yet unique view of jargon alongside word types. We demonstrate the utility of our metrics for science of science and computational sociolinguistics by highlighting two key social implications. First, though most fields reduce their use of jargon when writing for general-purpose venues, and some fields (e.g., biological sciences) do so less than others. Second, the direction of correlation between jargon and citation rates varies among fields, but jargon is nearly always negatively correlated with interdisciplinary impact. Broadly, our findings suggest that though multidisciplinary venues intend to cater to more general audiences, some fields’ writing norms may act as barriers rather than bridges, and thus impede the dispersion of scholarly ideas.</abstract>
      <url hash="b50cc405">2023.findings-acl.433</url>
      <bibkey>lucy-etal-2023-words</bibkey>
      <doi>10.18653/v1/2023.findings-acl.433</doi>
    </paper>
    <paper id="434">
      <title>Trade-Offs Between Fairness and Privacy in Language Modeling</title>
      <author><first>Cleo</first><last>Matzken</last><affiliation>Technische Universitaet Darmstadt</affiliation></author>
      <author><first>Steffen</first><last>Eger</last><affiliation>NLLG Lab, Bielefeld University</affiliation></author>
      <author><first>Ivan</first><last>Habernal</last><affiliation>Technical University of Darmstadt</affiliation></author>
      <pages>6948-6969</pages>
      <abstract>Protecting privacy in contemporary NLP models is gaining in importance. So does the need to mitigate social biases of such models. But can we have both at the same time? Existing research suggests that privacy preservation comes at the price of worsening biases in classification tasks. In this paper, we explore the extent to which this tradeoff really holds when we incorporate both privacy preservation and de-biasing techniques into training text generation models. How does improving the model along one dimension affect the other dimension as well as the utility of the model? We conduct an extensive set of experiments that include bias detection, privacy attacks, language modeling, and performance on downstream tasks.</abstract>
      <url hash="d6706958">2023.findings-acl.434</url>
      <bibkey>matzken-etal-2023-trade</bibkey>
      <doi>10.18653/v1/2023.findings-acl.434</doi>
    </paper>
    <paper id="435">
      <title><fixed-case>CSS</fixed-case>: A Large-scale Cross-schema <fixed-case>C</fixed-case>hinese Text-to-<fixed-case>SQL</fixed-case> Medical Dataset</title>
      <author><first>Hanchong</first><last>Zhang</last><affiliation>Shanghai Jiao Tong University</affiliation></author>
      <author><first>Jieyu</first><last>Li</last><affiliation>Shanghai Jiao Tong University</affiliation></author>
      <author><first>Lu</first><last>Chen</last><affiliation>Shanghai Jiao Tong University</affiliation></author>
      <author><first>Ruisheng</first><last>Cao</last><affiliation>Shanghai Jiao Tong University</affiliation></author>
      <author><first>Yunyan</first><last>Zhang</last><affiliation>Tencent Jarvis Lab</affiliation></author>
      <author><first>Yu</first><last>Huang</last><affiliation>Tencent Jarvis Lab</affiliation></author>
      <author><first>Yefeng</first><last>Zheng</last><affiliation>Tencent</affiliation></author>
      <author><first>Kai</first><last>Yu</last><affiliation>Shanghai Jiao Tong University</affiliation></author>
      <pages>6970-6983</pages>
      <abstract>The cross-domain text-to-SQL task aims to build a system that can parse user questions into SQL on complete unseen databases, and the single-domain text-to-SQL task evaluates the performance on identical databases. Both of these setups confront unavoidable difficulties in real-world applications. To this end, we introduce the cross-schema text-to-SQL task, where the databases of evaluation data are different from that in the training data but come from the same domain. Furthermore, we present CSS, a large-scale CrosS-Schema Chinese text-to-SQL dataset, to carry on corresponding studies. CSS originally consisted of 4,340 question/SQL pairs across 2 databases. In order to generalize models to different medical systems, we extend CSS and create 19 new databases along with 29,280 corresponding dataset examples. Moreover, CSS is also a large corpus for single-domain Chinese text-to-SQL studies. We present the data collection approach and a series of analyses of the data statistics. To show the potential and usefulness of CSS, benchmarking baselines have been conducted and reported. Our dataset is publicly available at <url>https://huggingface.co/datasets/zhanghanchong/css</url>.</abstract>
      <url hash="99956793">2023.findings-acl.435</url>
      <bibkey>zhang-etal-2023-css</bibkey>
      <doi>10.18653/v1/2023.findings-acl.435</doi>
    </paper>
    <paper id="436">
      <title>Silver Syntax Pre-training for Cross-Domain Relation Extraction</title>
      <author><first>Elisa</first><last>Bassignana</last><affiliation>IT University of Copenhagen</affiliation></author>
      <author><first>Filip</first><last>Ginter</last><affiliation>University of Turku</affiliation></author>
      <author><first>Sampo</first><last>Pyysalo</last><affiliation>University of Turku</affiliation></author>
      <author><first>Rob</first><last>van der Goot</last><affiliation>IT University of Copenhagen</affiliation></author>
      <author><first>Barbara</first><last>Plank</last><affiliation>LMU Munich</affiliation></author>
      <pages>6984-6993</pages>
      <abstract>Relation Extraction (RE) remains a challenging task, especially when considering realistic out-of-domain evaluations. One of the main reasons for this is the limited training size of current RE datasets: obtaining high-quality (manually annotated) data is extremely expensive and cannot realistically be repeated for each new domain. An intermediate training step on data from related tasks has shown to be beneficial across many NLP tasks. However, this setup still requires supplementary annotated data, which is often not available. In this paper, we investigate intermediate pre-training specifically for RE. We exploit the affinity between syntactic structure and semantic RE, and identify the syntactic relations which are closely related to RE by being on the shortest dependency path between two entities. We then take advantage of the high accuracy of current syntactic parsers in order to automatically obtain large amounts of low-cost pre-training data. By pre-training our RE model on the relevant syntactic relations, we are able to outperform the baseline in five out of six cross-domain setups, without any additional annotated data.</abstract>
      <url hash="5aacb290">2023.findings-acl.436</url>
      <bibkey>bassignana-etal-2023-silver</bibkey>
      <doi>10.18653/v1/2023.findings-acl.436</doi>
    </paper>
    <paper id="437">
      <title><fixed-case>F</fixed-case>ast<fixed-case>D</fixed-case>iff 2: Revisiting and Incorporating <fixed-case>GAN</fixed-case>s and Diffusion Models in High-Fidelity Speech Synthesis</title>
      <author><first>Rongjie</first><last>Huang</last><affiliation>Zhejiang University</affiliation></author>
      <author><first>Yi</first><last>Ren</last><affiliation>Bytedance</affiliation></author>
      <author><first>Ziyue</first><last>Jiang</last><affiliation>Zhejiang university</affiliation></author>
      <author><first>Chenye</first><last>Cui</last><affiliation>Zhejiang University</affiliation></author>
      <author><first>Jinglin</first><last>Liu</last><affiliation>ByteDance</affiliation></author>
      <author><first>Zhou</first><last>Zhao</last><affiliation>zhejiang university</affiliation></author>
      <pages>6994-7009</pages>
      <abstract>Generative adversarial networks (GANs) and denoising diffusion probabilistic models (DDPMs) have recently achieved impressive performances in image and audio synthesis. After revisiting their success in conditional speech synthesis, we find that 1) GANs sacrifice sample diversity for quality and speed, 2) diffusion models exhibit outperformed sample quality and diversity at a high computational cost, where achieving high-quality, fast, and diverse speech synthesis challenges all neural synthesizers. In this work, we propose to converge advantages from GANs and diffusion models by incorporating both classes, introducing dual-empowered modeling perspectives: 1) FastDiff 2 (DiffGAN), a diffusion model whose denoising process is parametrized by conditional GANs, and the non-Gaussian denoising distribution makes it much more stable to implement the reverse process with large steps sizes; and 2) FastDiff 2 (GANDiff), a generative adversarial network whose forward process is constructed by multiple denoising diffusion iterations, which exhibits better sample diversity than traditional GANs. Experimental results show that both variants enjoy an efficient 4-step sampling process and demonstrate superior sample quality and diversity. Audio samples are available at <url>https://RevisitSpeech.github.io/</url></abstract>
      <url hash="6325fd00">2023.findings-acl.437</url>
      <bibkey>huang-etal-2023-fastdiff</bibkey>
      <doi>10.18653/v1/2023.findings-acl.437</doi>
    </paper>
    <paper id="438">
      <title>Uncovering Hidden Consequences of Pre-training Objectives in Sequence-to-Sequence Models</title>
      <author><first>Tannon</first><last>Kew</last><affiliation>University of Zurich</affiliation></author>
      <author><first>Rico</first><last>Sennrich</last><affiliation>University of Zurich</affiliation></author>
      <pages>7010-7022</pages>
      <abstract>Some variants of self-supervised denoising objectives for pre-training encoder-decoder language models have been reported to have a negligible impact on downstream performance. Yet the design of these pre-training objectives leads to behavioural differences that can be uncovered with specific manipulations. We reproduce a recently proposed zero-shot control method and find that it is only successful on a subset of models. To understand what causes the difference in its effectiveness, we perform a set of controlled experiments, varying only the pre-training objective, and find unexpected interactions between the pre-training method and downstream controllability of models after fine-tuning. Our results show that different pre-training objectives have consequences that may not be visible in standard downstream evaluation, but which should be taken into account when developing models with controllability in mind.</abstract>
      <url hash="e6cf487c">2023.findings-acl.438</url>
      <bibkey>kew-sennrich-2023-uncovering</bibkey>
      <doi>10.18653/v1/2023.findings-acl.438</doi>
    </paper>
    <paper id="439">
      <title>Exploring Anisotropy and Outliers in Multilingual Language Models for Cross-Lingual Semantic Sentence Similarity</title>
      <author><first>Katharina</first><last>Haemmerl</last><affiliation>Center for Information and Language Processing, LMU</affiliation></author>
      <author><first>Alina</first><last>Fastowski</last><affiliation>Center for Information and Language Processing, LMU Munich</affiliation></author>
      <author><first>Jindřich</first><last>Libovický</last><affiliation>Charles Univeristy</affiliation></author>
      <author><first>Alexander</first><last>Fraser</last><affiliation>Ludwig-Maximilians-Universität München</affiliation></author>
      <pages>7023-7037</pages>
      <abstract>Previous work has shown that the representations output by contextual language models are more anisotropic than static type embeddings, and typically display outlier dimensions. This seems to be true for both monolingual and multilingual models, although much less work has been done on the multilingual context. Why these outliers occur and how they affect the representations is still an active area of research. We investigate outlier dimensions and their relationship to anisotropy in multiple pre-trained multilingual language models. We focus on cross-lingual semantic similarity tasks, as these are natural tasks for evaluating multilingual representations. Specifically, we examine sentence representations. Sentence transformers which are fine-tuned on parallel resources (that are not always available) perform better on this task, and we show that their representations are more isotropic. However, we aim to improve multilingual representations in general. We investigate how much of the performance difference can be made up by only transforming the embedding space without fine-tuning, and visualise the resulting spaces. We test different operations: Removing individual outlier dimensions, cluster-based isotropy enhancement, and ZCA whitening. We publish our code for reproducibility.</abstract>
      <url hash="853e34e2">2023.findings-acl.439</url>
      <bibkey>haemmerl-etal-2023-exploring</bibkey>
      <doi>10.18653/v1/2023.findings-acl.439</doi>
    </paper>
    <paper id="440">
      <title>Revisiting Sentence Union Generation as a Testbed for Text Consolidation</title>
      <author><first>Eran</first><last>Hirsch</last><affiliation>Bar-Ilan University</affiliation></author>
      <author><first>Valentina</first><last>Pyatkin</last><affiliation>Bar-Ilan University</affiliation></author>
      <author><first>Ruben</first><last>Wolhandler</last><affiliation>Bar-Ilan University</affiliation></author>
      <author><first>Avi</first><last>Caciularu</last><affiliation>Bar-Ilan University</affiliation></author>
      <author><first>Asi</first><last>Shefer</last><affiliation>One AI</affiliation></author>
      <author><first>Ido</first><last>Dagan</last><affiliation>Bar-Ilan University</affiliation></author>
      <pages>7038-7058</pages>
      <abstract>Tasks involving text generation based on multiple input texts, such as multi-document summarization, long-form question answering and contemporary dialogue applications, challenge models for their ability to properly consolidate partly-overlapping multi-text information. However, these tasks entangle the consolidation phase with the often subjective and ill-defined content selection requirement, impeding proper assessment of models’ consolidation capabilities. In this paper, we suggest revisiting the sentence union generation task as an effective well-defined testbed for assessing text consolidation capabilities, decoupling the consolidation challenge from subjective content selection. To support research on this task, we present refined annotation methodology and tools for crowdsourcing sentence union, create the largest union dataset to date and provide an analysis of its rich coverage of various consolidation aspects. We then propose a comprehensive evaluation protocol for union generation, including both human and automatic evaluation. Finally, as baselines, we evaluate state-of-the-art language models on the task, along with a detailed analysis of their capacity to address multi-text consolidation challenges and their limitations.</abstract>
      <url hash="458f08b0">2023.findings-acl.440</url>
      <bibkey>hirsch-etal-2023-revisiting</bibkey>
      <doi>10.18653/v1/2023.findings-acl.440</doi>
    </paper>
    <paper id="441">
      <title>Distilling Reasoning Capabilities into Smaller Language Models</title>
      <author><first>Kumar</first><last>Shridhar</last><affiliation>ETH Zürich</affiliation></author>
      <author><first>Alessandro</first><last>Stolfo</last><affiliation>ETH Zurich</affiliation></author>
      <author><first>Mrinmaya</first><last>Sachan</last><affiliation>ETH Zurich</affiliation></author>
      <pages>7059-7073</pages>
      <abstract>Step-by-step reasoning approaches like chain of thought (CoT) have proved to be very effective in inducing reasoning capabilities in large language models. However, the success of the CoT approach is fundamentally tied to the model size, and billion parameter-scale models are often needed to get CoT to work. In this paper, we propose a knowledge distillation approach that leverages the step-by-step CoT reasoning capabilities of larger models and distills these abilities into smaller models. In this work, we propose an alternative reasoning scheme, Socratic CoT that learns a decomposition of the original problem into a sequence of subproblems and uses it to guide the intermediate reasoning steps. We use Socratic CoT to train a combination of two small distilled models: a problem decomposer and a subproblem solver. In practice, given a new problem, the two distilled models work in sync to decompose and solve complex problems. On multiple reasoning datasets (GSM8K, StrategyQA, and SVAMP), our proposed distillation strategies boosts the performance of smaller models over 70% compared to the baselines. Finally, we investigate when Socratic CoT is an effective alternative to CoT, demonstrating cases where a much smaller model (GPT-2 large) can outperform a 10X larger model (GPT-3 6B). Our code is available: <url>https://github.com/kumar-shridhar/Distiiling-LM</url>.</abstract>
      <url hash="7a9228c7">2023.findings-acl.441</url>
      <bibkey>shridhar-etal-2023-distilling</bibkey>
      <doi>10.18653/v1/2023.findings-acl.441</doi>
    </paper>
    <paper id="442">
      <title><fixed-case>A</fixed-case>lign<fixed-case>STS</fixed-case>: Speech-to-Singing Conversion via Cross-Modal Alignment</title>
      <author><first>Ruiqi</first><last>Li</last><affiliation>Zhejiang University</affiliation></author>
      <author><first>Rongjie</first><last>Huang</last><affiliation>Zhejiang University</affiliation></author>
      <author><first>Lichao</first><last>Zhang</last><affiliation>Zhejiang University</affiliation></author>
      <author><first>Jinglin</first><last>Liu</last><affiliation>ByteDance</affiliation></author>
      <author><first>Zhou</first><last>Zhao</last><affiliation>zhejiang university</affiliation></author>
      <pages>7074-7088</pages>
      <abstract>The speech-to-singing (STS) voice conversion task aims to generate singing samples corresponding to speech recordings while facing a major challenge: the alignment between the target (singing) pitch contour and the source (speech) content is difficult to learn in a text-free situation. This paper proposes AlignSTS, an STS model based on explicit cross-modal alignment, which views speech variance such as pitch and content as different modalities. Inspired by the mechanism of how humans will sing the lyrics to the melody, AlignSTS: 1) adopts a novel rhythm adaptor to predict the target rhythm representation to bridge the modality gap between content and pitch, where the rhythm representation is computed in a simple yet effective way and is quantized into a discrete space; and 2) uses the predicted rhythm representation to re-align the content based on cross-attention and conducts a cross-modal fusion for re-synthesize. Extensive experiments show that AlignSTS achieves superior performance in terms of both objective and subjective metrics. Audio samples are available at <url>https://alignsts.github.io</url>.</abstract>
      <url hash="3260a223">2023.findings-acl.442</url>
      <bibkey>li-etal-2023-alignsts</bibkey>
      <doi>10.18653/v1/2023.findings-acl.442</doi>
    </paper>
    <paper id="443">
      <title>A New Task and Dataset on Detecting Attacks on Human Rights Defenders</title>
      <author><first>Shihao</first><last>Ran</last><affiliation>Dataminr</affiliation></author>
      <author><first>Di</first><last>Lu</last><affiliation>Dataminr</affiliation></author>
      <author><first>Aoife</first><last>Cahill</last><affiliation>Dataminr</affiliation></author>
      <author><first>Joel</first><last>Tetreault</last><affiliation>Dataminr</affiliation></author>
      <author><first>Alejandro</first><last>Jaimes</last><affiliation>Dataminr</affiliation></author>
      <pages>7089-7113</pages>
      <abstract>The ability to conduct retrospective analyses of attacks on human rights defenders over time and by location is important for humanitarian organizations to better understand historical or ongoing human rights violations and thus better manage the global impact of such events. We hypothesize that NLP can support such efforts by quickly processing large collections of news articles to detect and summarize the characteristics of attacks on human rights defenders. To that end, we propose a new dataset for detecting Attacks on Human Rights Defenders (HRDsAttack) consisting of crowdsourced annotations on 500 online news articles. The annotations include fine-grained information about the type and location of the attacks, as well as information about the victim(s). We demonstrate the usefulness of the dataset by using it to train and evaluate baseline models on several sub-tasks to predict the annotated characteristics.</abstract>
      <url hash="9e6e8cf1">2023.findings-acl.443</url>
      <bibkey>ran-etal-2023-new</bibkey>
      <doi>10.18653/v1/2023.findings-acl.443</doi>
    </paper>
    <paper id="444">
      <title>Improving Language Model Integration for Neural Machine Translation</title>
      <author><first>Christian</first><last>Herold</last><affiliation>RWTH Aachen University</affiliation></author>
      <author><first>Yingbo</first><last>Gao</last><affiliation>RWTH Aachen University</affiliation></author>
      <author><first>Mohammad</first><last>Zeineldeen</last><affiliation>RWTH Aachen University / AppTek</affiliation></author>
      <author><first>Hermann</first><last>Ney</last><affiliation>RWTH Aachen University</affiliation></author>
      <pages>7114-7123</pages>
      <abstract>The integration of language models for neural machine translation has been extensively studied in the past. It has been shown that an external language model, trained on additional target-side monolingual data, can help improve translation quality. However, there has always been the assumption that the translation model also learns an implicit target-side language model during training, which interferes with the external language model at decoding time. Recently, some works on automatic speech recognition have demonstrated that, if the implicit language model is neutralized in decoding, further improvements can be gained when integrating an external language model. In this work, we transfer this concept to the task of machine translation and compare with the most prominent way of including additional monolingual data - namely back-translation. We find that accounting for the implicit language model significantly boosts the performance of language model fusion, although this approach is still outperformed by back-translation.</abstract>
      <url hash="9c65db32">2023.findings-acl.444</url>
      <bibkey>herold-etal-2023-improving</bibkey>
      <doi>10.18653/v1/2023.findings-acl.444</doi>
    </paper>
    <paper id="445">
      <title>Type Enhanced <fixed-case>BERT</fixed-case> for Correcting <fixed-case>NER</fixed-case> Errors</title>
      <author><first>Kuai</first><last>Li</last><affiliation>8616619895070</affiliation></author>
      <author><first>Chen</first><last>Chen</last><affiliation>Tencent Inc.</affiliation></author>
      <author><first>Tao</first><last>Yang</last><affiliation>Tencent. Corp.</affiliation></author>
      <author><first>Tianming</first><last>Du</last><affiliation>Tencent</affiliation></author>
      <author><first>Peijie</first><last>Yu</last><affiliation>tencent</affiliation></author>
      <author><first>Dong</first><last>Du</last><affiliation>tencent</affiliation></author>
      <author><first>Feng</first><last>Zhang</last><affiliation>tencent AI Lab</affiliation></author>
      <pages>7124-7131</pages>
      <abstract>We introduce the task of correcting named entity recognition (NER) errors without re-training model. After an NER model is trained and deployed in production,it makes prediction errors, which usually need to be fixed quickly. To address this problem, we firstly construct a gazetteer containing named entities and corresponding possible entity types. And then, we propose type enhanced BERT (TyBERT),a method that integrates the named entity’s type information into BERT by an adapter layer. When errors are identified, we can repair the model by updating the gazetteer. In other words, the gazetteer becomes a trigger to control NER model’s output. The experiment results in multiple corpus show the effectiveness of our method, which outperforms strong baselines.x</abstract>
      <url hash="0e37096b">2023.findings-acl.445</url>
      <bibkey>li-etal-2023-type</bibkey>
      <doi>10.18653/v1/2023.findings-acl.445</doi>
    </paper>
    <paper id="446">
      <title>Bridge the Gap Between <fixed-case>CV</fixed-case> and <fixed-case>NLP</fixed-case>! A Gradient-based Textual Adversarial Attack Framework</title>
      <author><first>Lifan</first><last>Yuan</last><affiliation>Huazhong University of Science and Technology</affiliation></author>
      <author><first>YiChi</first><last>Zhang</last><affiliation>Huazhong University of Science &amp; Technology</affiliation></author>
      <author><first>Yangyi</first><last>Chen</last><affiliation>UIUC</affiliation></author>
      <author><first>Wei</first><last>Wei</last><affiliation>Huazhong University of Science and Technology</affiliation></author>
      <pages>7132-7146</pages>
      <abstract>Despite recent success on various tasks, deep learning techniques still perform poorly on adversarial examples with small perturbations. While optimization-based methods for adversarial attacks are well-explored in the field of computer vision, it is impractical to directly apply them in natural language processing due to the discrete nature of the text. To address the problem, we propose a unified framework to extend the existing optimization-based adversarial attack methods in the vision domain to craft textual adversarial samples. In this framework, continuously optimized perturbations are added to the embedding layer and amplified in the forward propagation process. Then the final perturbed latent representations are decoded with a masked language model head to obtain potential adversarial samples. In this paper, we instantiate our framework with an attack algorithm named Textual Projected Gradient Descent (T-PGD). We find our algorithm effective even using proxy gradient information. Therefore, we perform the more challenging transfer black-box attack and conduct comprehensive experiments to evaluate our attack algorithm with several models on three benchmark datasets. Experimental results demonstrate that our method achieves overall better performance and produces more fluent and grammatical adversarial samples compared to strong baseline methods. The code and data are available at <url>https://github.com/Phantivia/T-PGD</url>.</abstract>
      <url hash="254f97da">2023.findings-acl.446</url>
      <bibkey>yuan-etal-2023-bridge</bibkey>
      <doi>10.18653/v1/2023.findings-acl.446</doi>
    </paper>
    <paper id="447">
      <title><fixed-case>DUB</fixed-case>: Discrete Unit Back-translation for Speech Translation</title>
      <author><first>Dong</first><last>Zhang</last><affiliation>School of Computer Science, Fudan University</affiliation></author>
      <author><first>Rong</first><last>Ye</last><affiliation>ByteDance AI Lab</affiliation></author>
      <author><first>Tom</first><last>Ko</last><affiliation>ByteDance AI Lab</affiliation></author>
      <author><first>Mingxuan</first><last>Wang</last><affiliation>Bytedance AI Lab</affiliation></author>
      <author><first>Yaqian</first><last>Zhou</last><affiliation>Fudan University</affiliation></author>
      <pages>7147-7164</pages>
      <abstract>How can speech-to-text translation (ST) perform as well as machine translation (MT)? The key point is to bridge the modality gap between speech and text so that useful MT techniques can be applied to ST.Recently, the approach of representing speech with unsupervised discrete units yields a new way to ease the modality problem. This motivates us to propose Discrete Unit Back-translation(DUB) to answer two questions (1) Is it better to represent speech with discrete units than with continuous features in direct ST? (2) How much benefit can useful MT techniques bring to ST? With DUB, the back-translation technique can successfully be applied on direct ST and obtains an average boost of 5.5 BLEU on MuST-C En-De/Fr/Es. In the low-resource language scenario, our method achieves comparable performance to existing methods that rely on large-scale external data. Code and models are available at <url>https://anonymous.4open.science/r/DUB/</url>.</abstract>
      <url hash="304374b1">2023.findings-acl.447</url>
      <bibkey>zhang-etal-2023-dub</bibkey>
      <doi>10.18653/v1/2023.findings-acl.447</doi>
    </paper>
    <paper id="448">
      <title>Knowledge Graph Embeddings using Neural <fixed-case>I</fixed-case>to Process: From Multiple Walks to Stochastic Trajectories</title>
      <author><first>Mojtaba</first><last>Nayyeri</last><affiliation>University Of Stuttgart</affiliation></author>
      <author><first>Bo</first><last>Xiong</last><affiliation>University of Stuttgart</affiliation></author>
      <author><first>Majid</first><last>Mohammadi</last><affiliation>Vrije Universiteit</affiliation></author>
      <author><first>Mst. Mahfuja</first><last>Akter</last><affiliation>University of Bonn</affiliation></author>
      <author><first>Mirza Mohtashim</first><last>Alam</last><affiliation>PhD student</affiliation></author>
      <author><first>Jens</first><last>Lehmann</last><affiliation>Amazon, TU Dresden, InfAI</affiliation></author>
      <author><first>Steffen</first><last>Staab</last><affiliation>University of Stuttgart &amp; University of Southampton</affiliation></author>
      <pages>7165-7179</pages>
      <abstract>Knowledge graphs mostly exhibit a mixture of branching relations, e.g., hasFriend, and complex structures, e.g., hierarchy and loop. Most knowledge graph embeddings have problems expressing them, because they model a specific relation r from a head h to tails by starting at the node embedding of h and transitioning deterministically to exactly one other point in the embedding space. We overcome this issue in our novel framework ItCAREToE by modeling relations between nodes by relation-specific, stochastic transitions. Our framework is based on stochastic ItCARETo processes, which operate on low-dimensional manifolds. ItCAREToE is highly expressive and generic subsuming various state-of-the-art models operating on different, also non-Euclidean, manifolds. Experimental results show the superiority of ItCAREToE over other deterministic embedding models with regard to the KG completion task.</abstract>
      <url hash="c7c3b8d0">2023.findings-acl.448</url>
      <bibkey>nayyeri-etal-2023-knowledge</bibkey>
      <doi>10.18653/v1/2023.findings-acl.448</doi>
    </paper>
    <paper id="449">
      <title>Leveraging Denoised <fixed-case>A</fixed-case>bstract <fixed-case>M</fixed-case>eaning <fixed-case>R</fixed-case>epresentation for Grammatical Error Correction</title>
      <author><first>Hejing</first><last>Cao</last><affiliation>Peking University</affiliation></author>
      <author><first>Dongyan</first><last>Zhao</last><affiliation>pku.edu.cn</affiliation></author>
      <pages>7180-7188</pages>
      <abstract>Grammatical Error Correction (GEC) is the task of correcting errorful sentences into grammatically correct, semantically consistent, and coherent sentences. Popular GEC models either use large-scale synthetic corpora or use a large number of human-designed rules. The former is costly to train, while the latter requires quite a lot of human expertise. In recent years, AMR, a semantic representation framework, has been widely used by many natural language tasks due to its completeness and flexibility. A non-negligible concern is that AMRs of grammatically incorrect sentences may not be exactly reliable. In this paper, we propose the AMR-GEC, a seq-to-seq model that incorporates denoised AMR as additional knowledge. Specifically, We design a semantic aggregated GEC model and explore denoising methods to get AMRs more reliable. Experiments on the BEA-2019 shared task and the CoNLL-2014 shared task have shown that AMR-GEC performs comparably to a set of strong baselines with a large number of synthetic data. Compared with the T5 model with synthetic data, AMR-GEC can reduce the training time by 32% while inference time is comparable. To the best of our knowledge, we are the first to incorporate AMR for grammatical error correction.</abstract>
      <url hash="28515213">2023.findings-acl.449</url>
      <bibkey>cao-zhao-2023-leveraging</bibkey>
      <doi>10.18653/v1/2023.findings-acl.449</doi>
    </paper>
    <paper id="450">
      <title>Prediction and Calibration: Complex Reasoning over Knowledge Graph with Bi-directional Directed Acyclic Graph Neural Network</title>
      <author><first>Yao</first><last>Xu</last><affiliation>Institute of Automation, Chinese Academy of Sciences</affiliation></author>
      <author><first>Shizhu</first><last>He</last><affiliation>Institute of Automation, Chinese Academy of Sciences</affiliation></author>
      <author><first>Li</first><last>Cai</last><affiliation>Meituan Group</affiliation></author>
      <author><first>Kang</first><last>Liu</last><affiliation>Institute of Automation, Chinese Academy of Sciences</affiliation></author>
      <author><first>Jun</first><last>Zhao</last><affiliation>NLPR, Institute of Automation, Chinese Academy of Sciences</affiliation></author>
      <pages>7189-7198</pages>
      <abstract>Answering complex logical queries is a challenging task for knowledge graph (KG) reasoning. Recently, query embedding (QE) has been proposed to encode queries and entities into the same vector space, and obtain answers based on numerical computation. However, such models obtain the node representations of a query only based on its predecessor nodes, which ignore the information contained in successor nodes. In this paper, we proposed a Bi-directional Directed Acyclic Graph neural network (BiDAG) that splits the reasoning process into prediction and calibration. The joint probability of all nodes is considered by applying a graph neural network (GNN) to the query graph in the calibration process. By the prediction in the first layer and the calibration in deep layers of GNN, BiDAG can outperform previous QE based methods on FB15k, FB15k-237, and NELL995.</abstract>
      <url hash="8735a47c">2023.findings-acl.450</url>
      <bibkey>xu-etal-2023-prediction</bibkey>
      <doi>10.18653/v1/2023.findings-acl.450</doi>
    </paper>
    <paper id="451">
      <title>Prompt-Based Metric Learning for Few-Shot <fixed-case>NER</fixed-case></title>
      <author><first>Yanru</first><last>Chen</last><affiliation>IIIS, Tsinghua University</affiliation></author>
      <author><first>Yanan</first><last>Zheng</last><affiliation>Tsinghua University</affiliation></author>
      <author><first>Zhilin</first><last>Yang</last><affiliation/></author>
      <pages>7199-7212</pages>
      <abstract>Few-shot named entity recognition (NER) targets generalizing to unseen labels and/or domains with few labeled examples. Existing metric learning methods compute token-level similarities between query and support sets, but are not able to fully incorporate label semantics into modeling. To address this issue, we propose a simple method to largely improve metric learning for NER: 1) multiple prompt schemas are designed to enhance label semantics; 2) we propose a novel architecture to effectively combine multiple prompt-based representations. Empirically, our method achieves new state-of-the-art (SOTA) results under 16 of the 18 considered settings, substantially outperforming the previous SOTA by an average of 9.12% and a maximum of 34.51% in relative gains of micro F1.</abstract>
      <url hash="8e2735f7">2023.findings-acl.451</url>
      <bibkey>chen-etal-2023-prompt</bibkey>
      <doi>10.18653/v1/2023.findings-acl.451</doi>
    </paper>
    <paper id="452">
      <title><fixed-case>O</fixed-case>pen<fixed-case>PI</fixed-case>-<fixed-case>C</fixed-case>: A Better Benchmark and Stronger Baseline for Open-Vocabulary State Tracking</title>
      <author><first>Xueqing</first><last>Wu</last><affiliation>University of Illinois Urbana-Champaign</affiliation></author>
      <author><first>Sha</first><last>Li</last><affiliation>University of Illinois Urbana-Champaign</affiliation></author>
      <author><first>Heng</first><last>Ji</last><affiliation>University of Illinois at Urbana-Champaign and Amazon (Amazon Scholar)</affiliation></author>
      <pages>7213-7222</pages>
      <abstract>Open-vocabulary state tracking is a more practical version of state tracking that aims to track state changes of entities throughout a process without restricting the state space and entity space. OpenPI (Tandon et al., 2020) is to date the only dataset annotated for open-vocabulary state tracking. However, we identify issues with the dataset quality and evaluation metric. For the dataset, we categorize 3 types of problems on the procedure level, step level and state change level respectively, and build a clean dataset OpenPI-C using multiple rounds of human judgment. For the evaluation metric, we propose a cluster-based metric to fix the original metric’s preference for repetition. Model-wise, we enhance the seq2seq generation baseline by reinstating two key properties for state tracking: temporal dependency and entity awareness. The state of the world after an action is inherently dependent on the previous state. We model this dependency through a dynamic memory bank and allow the model to attend to the memory slots during decoding. On the other hand, the state of the world is naturally a union of the states of involved entities. Since the entities are unknown in the open-vocabulary setting, we propose a two-stage model that refines the state change prediction conditioned on entities predicted from the first stage. Empirical results show the effectiveness of our proposed model, especially on the cleaned dataset and the cluster-based metric. The code and data are released at <url>https://github.com/shirley-wu/openpi-c</url></abstract>
      <url hash="b7d2acc7">2023.findings-acl.452</url>
      <bibkey>wu-etal-2023-openpi</bibkey>
      <doi>10.18653/v1/2023.findings-acl.452</doi>
      <revision id="1" href="2023.findings-acl.452v1" hash="b7d2acc7"/>
      <revision id="2" href="2023.findings-acl.452v2" hash="16dde634" date="2023-09-17">Minor updates.</revision>
    </paper>
    <paper id="453">
      <title><fixed-case>I</fixed-case> run as fast as a rabbit, can you? A Multilingual Simile Dialogues Datasets</title>
      <author><first>Longxuan</first><last>Ma</last><affiliation>Research Center for Social Computing and Information Retrieval, Harbin Institute of Technology</affiliation></author>
      <author><first>Wei-Nan</first><last>Zhang</last><affiliation>Harbin Institute of Technology</affiliation></author>
      <author><first>Shuhan</first><last>Zhou</last><affiliation>Beijing Language and Culture University</affiliation></author>
      <author><first>Churui</first><last>Sun</last><affiliation>Harbin Institute of Technology</affiliation></author>
      <author><first>Changxin</first><last>Ke</last><affiliation>Harbin Institute of Technology</affiliation></author>
      <author><first>Ting</first><last>Liu</last><affiliation>Harbin Institute of Technology</affiliation></author>
      <pages>7223-7237</pages>
      <abstract>A simile is a figure of speech that compares two different things (called the tenor and the vehicle) via shared properties. The tenor and the vehicle are usually connected with comparator words such as “like” or “as”. The simile phenomena are unique and complex in a real-life dialogue scene where the tenor and the vehicle can be verbal phrases or sentences, mentioned by different speakers, exist in different sentences, or occur in reversed order. However, the current simile research usually focuses on similes in a triplet tuple (tenor, property, vehicle) or a single sentence where the tenor and vehicle are usually entities or noun phrases, which could not reflect complex simile phenomena in real scenarios. In this paper, we propose a novel and high-quality multilingual simile dialogue (MSD) dataset to facilitate the study of complex simile phenomena. The MSD is the largest manually annotated simile data (~21K) and it contains both English and Chinese data. Meanwhile, the MSD data can also be used on dialogue tasks to test the ability of dialogue systems when using similes. We design 3 simile tasks (recognition, interpretation, and generation) and 2 dialogue tasks (retrieval and generation) with MSD. For each task, we provide experimental results from strong pre-trained or state-of-the-art models. The experiments demonstrate the challenge of MSD and we will release the data/code on GitHub.</abstract>
      <url hash="6b203aa7">2023.findings-acl.453</url>
      <bibkey>ma-etal-2023-run</bibkey>
      <doi>10.18653/v1/2023.findings-acl.453</doi>
    </paper>
    <paper id="454">
      <title>Controllable Conversation Generation with Conversation Structures via Diffusion Models</title>
      <author><first>Jiaao</first><last>Chen</last><affiliation>Georgia Institute of Technology</affiliation></author>
      <author><first>Diyi</first><last>Yang</last><affiliation>Stanford University</affiliation></author>
      <pages>7238-7251</pages>
      <abstract>Generating coherent conversation is an important and challenging long text generation task, as it has various applications such as daily entertainment, children education or building conversational AI to facilitate human-computer interaction. However, current generation models often fail to effectively utilize rich linguistic and world knowledge to generate conversations just like human. In this work, we introduce a novel conversation generation framework to effectively incorporate human knowledge and conversation structures with both controllability and interpretability for better conversation generation. Specifically, we first generate the prototype conversations from short descriptions. We then gradually and strategically incorporate different levels of conversation structures including the action triples, dialogue acts and discourse relations via diffusion models to directly edit the prototype conversations. We demonstrate the effectiveness of our framework through experiments on two datasets by comparing our method with the state-of-the-art baseline models.</abstract>
      <url hash="f37994b6">2023.findings-acl.454</url>
      <bibkey>chen-yang-2023-controllable</bibkey>
      <doi>10.18653/v1/2023.findings-acl.454</doi>
    </paper>
    <paper id="455">
      <title>Few-shot Low-resource Knowledge Graph Completion with Reinforced Task Generation</title>
      <author><first>Shichao</first><last>Pei</last><affiliation>University of Notre Dame</affiliation></author>
      <author><first>Qiannan</first><last>Zhang</last><affiliation>King Abdullah University of Science and Technology</affiliation></author>
      <author><first>Xiangliang</first><last>Zhang</last><affiliation>University of Notre Dame</affiliation></author>
      <pages>7252-7264</pages>
      <abstract>Despite becoming a prevailing paradigm for organizing knowledge, most knowledge graphs (KGs) suffer from the low-resource issue due to the deficiency of data sources. The enrichment of KGs by automatic knowledge graph completion is impeded by the intrinsic long-tail property of KGs. In spite of their prosperity, existing few-shot learning-based models have difficulty alleviating the impact of the long-tail issue on low-resource KGs because of the lack of training tasks. To tackle the challenging long-tail issue on low-resource KG completion, in this paper, we propose a novel few-shot low-resource knowledge graph completion framework, which is composed of three components, i.e., few-shot learner, task generator, and task selector. The key idea is to generate and then select the beneficial few-shot tasks that complement the current tasks and enable the optimization of the few-shot learner using the selected few-shot tasks. Extensive experiments conducted on several real-world knowledge graphs validate the effectiveness of our proposed method.</abstract>
      <url hash="2e4671eb">2023.findings-acl.455</url>
      <bibkey>pei-etal-2023-shot</bibkey>
      <doi>10.18653/v1/2023.findings-acl.455</doi>
    </paper>
    <paper id="456">
      <title>Incomplete Utterance Rewriting as Sequential Greedy Tagging</title>
      <author><first>Yunshan</first><last>Chen</last><affiliation>SF Technology Co., Ltd.</affiliation></author>
      <pages>7265-7276</pages>
      <abstract>The task of incomplete utterance rewriting has recently gotten much attention. Previous models struggled to extract information from the dialogue context, as evidenced by the low restoration scores. To address this issue, we propose a novel sequence tagging-based model, which is more adept at extracting information from context. Meanwhile, we introduce speaker-aware embedding to model speaker variation. Experiments on multiple public datasets show that our model achieves optimal results on all nine restoration scores while having other metric scores comparable to previous state-of-the-art models. Furthermore, benefitting from the model’s simplicity, our approach outperforms most previous models on inference speed.</abstract>
      <url hash="44534891">2023.findings-acl.456</url>
      <bibkey>chen-2023-incomplete</bibkey>
      <doi>10.18653/v1/2023.findings-acl.456</doi>
    </paper>
    <paper id="457">
      <title>Exploiting Commonsense Knowledge about Objects for Visual Activity Recognition</title>
      <author><first>Tianyu</first><last>Jiang</last><affiliation>University of Utah</affiliation></author>
      <author><first>Ellen</first><last>Riloff</last><affiliation>University of Utah</affiliation></author>
      <pages>7277-7285</pages>
      <abstract>Situation recognition is the task of recognizing the activity depictedin an image, including the people and objects involved. Previousmodels for this task typically train a classifier to identify theactivity using a backbone image feature extractor. We propose thatcommonsense knowledge about the objects depicted in an image can alsobe a valuable source of information for activity identification. Previous NLP research has argued that knowledge about the prototypicalfunctions of physical objects is important for language understanding,and NLP techniques have been developed to acquire this knowledge. Our work investigates whether this prototypical function knowledgecan also be beneficial for visual situation recognition. Webuild a framework that incorporates this type of commonsense knowledgein a transformer-based model that is trained to predict the actionverb for situation recognition. Our experimental results show thatadding prototypical function knowledge about physical objects doesimprove performance for the visual activity recognition task.</abstract>
      <url hash="e9c84803">2023.findings-acl.457</url>
      <bibkey>jiang-riloff-2023-exploiting</bibkey>
      <doi>10.18653/v1/2023.findings-acl.457</doi>
    </paper>
    <paper id="458">
      <title>Tucker Decomposition with Frequency Attention for Temporal Knowledge Graph Completion</title>
      <author><first>Likang</first><last>Xiao</last><affiliation>Beihang University</affiliation></author>
      <author><first>Richong</first><last>Zhang</last><affiliation>Beihang University</affiliation></author>
      <author><first>Zijie</first><last>Chen</last><affiliation>University of Toronto</affiliation></author>
      <author><first>Junfan</first><last>Chen</last><affiliation>Beihang University</affiliation></author>
      <pages>7286-7300</pages>
      <abstract>Temporal Knowledge Graph Completion aims to complete missing entities or relations under temporal constraints. Previous tensor decomposition-based models for TKGC only independently consider the combination of one single relation with one single timestamp, ignoring the global nature of the embedding. We propose a Frequency Attention (FA) model to capture the global temporal dependencies between one relation and the entire timestamp. Specifically, we use Discrete Cosine Transform (DCT) to capture the frequency of the timestamp embedding and further compute the frequency attention weight to scale embedding. Meanwhile, the previous temporal tucker decomposition method uses a simple norm regularization to constrain the core tensor, which limits the optimization performance. Thus, we propose Orthogonal Regularization (OR) variants for the core tensor, which can limit the non-superdiagonal elements of the 3-rd core tensor. Experiments on three standard TKGC datasets demonstrate that our method outperforms the state-of-the-art results on several metrics. The results suggest that the direct-current component is not the best feature for TKG representation learning. Additional analysis shows the effectiveness of our FA and OR models, even with smaller embedding dimensions.</abstract>
      <url hash="825bf7ab">2023.findings-acl.458</url>
      <bibkey>xiao-etal-2023-tucker</bibkey>
      <doi>10.18653/v1/2023.findings-acl.458</doi>
    </paper>
    <paper id="459">
      <title>Another Dead End for Morphological Tags? Perturbed Inputs and Parsing</title>
      <author><first>Alberto</first><last>Muñoz-Ortiz</last><affiliation>Universidade da Coruña, CITIC</affiliation></author>
      <author><first>David</first><last>Vilares</last><affiliation>Universidade da Coruña, CITIC</affiliation></author>
      <pages>7301-7310</pages>
      <abstract>The usefulness of part-of-speech tags for parsing has been heavily questioned due to the success of word-contextualized parsers. Yet, most studies are limited to coarse-grained tags and high quality written content; while we know little about their influence when it comes to models in production that face lexical errors. We expand these setups and design an adversarial attack to verify if the use of morphological information by parsers: (i) contributes to error propagation or (ii) if on the other hand it can play a role to correct mistakes that word-only neural parsers make. The results on 14 diverse UD treebanks show that under such attacks, for transition- and graph-based models their use contributes to degrade the performance even faster, while for the (lower-performing) sequence labeling parsers they are helpful. We also show that if morphological tags were utopically robust against lexical perturbations, they would be able to correct parsing mistakes.</abstract>
      <url hash="e6e335ed">2023.findings-acl.459</url>
      <bibkey>munoz-ortiz-vilares-2023-another</bibkey>
      <doi>10.18653/v1/2023.findings-acl.459</doi>
    </paper>
    <paper id="460">
      <title><fixed-case>H</fixed-case>e<fixed-case>G</fixed-case>e<fixed-case>L</fixed-case>: A Novel Dataset for Geo-Location from <fixed-case>H</fixed-case>ebrew Text</title>
      <author><first>Tzuf</first><last>Paz-Argaman</last><affiliation>Bar-Ilan University</affiliation></author>
      <author><first>Tal</first><last>Bauman</last><affiliation>Technion - Israel Institute of Technology</affiliation></author>
      <author><first>Itai</first><last>Mondshine</last><affiliation>Bar Ilan University</affiliation></author>
      <author><first>Itzhak</first><last>Omer</last><affiliation>Tel Aviv University</affiliation></author>
      <author><first>Sagi</first><last>Dalyot</last><affiliation>The Technion</affiliation></author>
      <author><first>Reut</first><last>Tsarfaty</last><affiliation>Bar-Ilan University</affiliation></author>
      <pages>7311-7321</pages>
      <abstract>The task of textual geolocation — retrieving the coordinates of a place based on a free-form language description — calls for not only grounding but also natural language understanding and geospatial reasoning. Even though there are quite a few datasets in English used for geolocation, they are currently based on open-source data (Wikipedia and Twitter), where the location of the described place is mostly implicit, such that the location retrieval resolution is limited. Furthermore, there are no datasets available for addressing the problem of textual geolocation in morphologically rich and resource-poor languages, such as Hebrew. In this paper, we present the Hebrew Geo-Location (HeGeL) corpus, designed to collect literal place descriptions and analyze lingual geospatial reasoning. We crowdsourced 5,649 literal Hebrew place descriptions of various place types in three cities in Israel. Qualitative and empirical analysis show that the data exhibits abundant use of geospatial reasoning and requires a novel environmental representation.</abstract>
      <url hash="d21aaf36">2023.findings-acl.460</url>
      <bibkey>paz-argaman-etal-2023-hegel</bibkey>
      <doi>10.18653/v1/2023.findings-acl.460</doi>
    </paper>
    <paper id="461">
      <title>Modeling Adversarial Attack on Pre-trained Language Models as Sequential Decision Making</title>
      <author><first>Xuanjie</first><last>Fang</last><affiliation>Fudan University</affiliation></author>
      <author><first>Sijie</first><last>Cheng</last><affiliation>Fudan University</affiliation></author>
      <author id="yang-liu"><first>Yang</first><last>Liu</last><affiliation>Tsinghua University</affiliation></author>
      <author><first>Wei</first><last>Wang</last><affiliation>fudan university</affiliation></author>
      <pages>7322-7336</pages>
      <abstract>Pre-trained language models (PLMs) have been widely used to underpin various downstream tasks. However, the adversarial attack task has found that PLMs are vulnerable to small perturbations. Mainstream methods adopt a detached two-stage framework to attack without considering the subsequent influence of substitution at each step. In this paper, we formally model the adversarial attack task on PLMs as a sequential decision-making problem, where the whole attack process is sequential with two decision-making problems, i.e., word finder and word substitution. Considering the attack process can only receive the final state without any direct intermediate signals, we propose to use reinforcement learning to find an appropriate sequential attack path to generate adversaries, named SDM-ATTACK. Our experimental results show that SDM-ATTACK achieves the highest attack success rate with a comparable modification rate and semantic similarity to attack fine-tuned BERT. Furthermore, our analyses demonstrate the generalization and transferability of SDM-ATTACK.Resources of this work will be released after this paper’s publication.</abstract>
      <url hash="249c6c96">2023.findings-acl.461</url>
      <bibkey>fang-etal-2023-modeling</bibkey>
      <doi>10.18653/v1/2023.findings-acl.461</doi>
    </paper>
    <paper id="462">
      <title>Towards Robust Personalized Dialogue Generation via Order-Insensitive Representation Regularization</title>
      <author><first>Liang</first><last>Chen</last><affiliation>The Chinese University of Hong Kong</affiliation></author>
      <author><first>Hongru</first><last>Wang</last><affiliation>The Chinese University of Hong Kong</affiliation></author>
      <author><first>Yang</first><last>Deng</last><affiliation>The Chinese University of Hong Kong</affiliation></author>
      <author><first>Wai Chung</first><last>Kwan</last><affiliation>The Chinese University of Hong Kong</affiliation></author>
      <author><first>Zezhong</first><last>Wang</last><affiliation>The Chinese University of Hong Kong</affiliation></author>
      <author><first>Kam-Fai</first><last>Wong</last><affiliation>Department of Systems Engineering and Engineering Management, The Chinese University of Hong Kong, Hong Kong</affiliation></author>
      <pages>7337-7345</pages>
      <abstract>Generating persona consistent dialogue response is important for developing an intelligent conversational agent. Recent works typically fine-tune large-scale pre-trained models on this task by concatenating persona texts and dialogue history as a single input sequence to generate the target response. While simple and effective, our analysis shows that this popular practice is seriously affected by order sensitivity where different input orders of persona sentences significantly impact the quality and consistency of generated response, resulting in severe performance fluctuations (i.e., 29.4% on GPT2 and 83.2% on BART). To mitigate the order sensitivity problem, we propose a model-agnostic framework, ORder Insensitive Generation (ORIG), which enables dialogue models to learn robust representation under different persona orders and improve the consistency of response generation. Experiments on the Persona-Chat dataset justify the effectiveness and superiority of our method with two dominant pre-trained models (GPT2 and BART).</abstract>
      <url hash="afcfbcb4">2023.findings-acl.462</url>
      <bibkey>chen-etal-2023-towards-robust</bibkey>
      <doi>10.18653/v1/2023.findings-acl.462</doi>
    </paper>
    <paper id="463">
      <title>Cost-effective Distillation of Large Language Models</title>
      <author><first>Sayantan</first><last>Dasgupta</last><affiliation>University of Melbourne</affiliation></author>
      <author><first>Trevor</first><last>Cohn</last><affiliation>University of Melbourne</affiliation></author>
      <author><first>Timothy</first><last>Baldwin</last><affiliation>MBZUAI</affiliation></author>
      <pages>7346-7354</pages>
      <abstract>Knowledge distillation (KD) involves training a small “student” model to replicate the strong performance of a high-capacity “teacher” model, enabling efficient deployment in resource-constrained settings. Top-performing methods tend to be task- or architecture-specific and lack generalizability. Several existing approaches require pretraining of the teacher on task-specific datasets, which can be costly for large and unstable for small datasets. Here we propose an approach for improving KD through a novel distillation loss agnostic to the task and model architecture. We successfully apply our method to the distillation of the BERT-base and achieve highly competitive results from the distilled student across a range of GLUE tasks, especially for tasks with smaller datasets.</abstract>
      <url hash="4248ce68">2023.findings-acl.463</url>
      <bibkey>dasgupta-etal-2023-cost</bibkey>
      <doi>10.18653/v1/2023.findings-acl.463</doi>
    </paper>
    <paper id="464">
      <title>Task-Optimized Adapters for an End-to-End Task-Oriented Dialogue System</title>
      <author><first>Namo</first><last>Bang</last><affiliation>Department of Artificial Intelligence, Sogang University</affiliation></author>
      <author><first>Jeehyun</first><last>Lee</last><affiliation>Department of Artificial Intelligence, Sogang University</affiliation></author>
      <author><first>Myoung-Wan</first><last>Koo</last><affiliation>Sogang University</affiliation></author>
      <pages>7355-7369</pages>
      <abstract>Task-Oriented Dialogue (TOD) systems are designed to carry out specific tasks by tracking dialogue states and generating appropriate responses to help users achieve defined goals. Recently, end-to-end dialogue models pre-trained based on large datasets have shown promising performance in the conversational system. However, they share the same parameters to train tasks of the dialogue system (NLU, DST, NLG), so debugging each task is challenging. Also, they require a lot of effort to fine-tune large parameters to create a task-oriented chatbot, making it difficult for non-experts to handle. Therefore, we intend to train relatively lightweight and fast models compared to PLM. In this paper, we propose an End-to-end TOD system with Task-Optimized Adapters which learn independently per task, adding only small number of parameters after fixed layers of pre-trained network. We also enhance the performance of the DST and NLG modules through reinforcement learning, overcoming the learning curve that has lacked at the adapter learning and enabling the natural and consistent response generation that is appropriate for the goal. Our method is a model-agnostic approach and does not require prompt-tuning as only input data without a prompt. As results of the experiment, our method shows competitive performance on the MultiWOZ benchmark compared to the existing end-to-end models. In particular, we attain state-of-the-art performance on the DST task of 2.2 dataset.</abstract>
      <url hash="c251b20d">2023.findings-acl.464</url>
      <bibkey>bang-etal-2023-task</bibkey>
      <doi>10.18653/v1/2023.findings-acl.464</doi>
    </paper>
    <paper id="465">
      <title><fixed-case>I</fixed-case> Spy a Metaphor: Large Language Models and Diffusion Models Co-Create Visual Metaphors</title>
      <author><first>Tuhin</first><last>Chakrabarty</last><affiliation>Columbia University</affiliation></author>
      <author><first>Arkadiy</first><last>Saakyan</last><affiliation>Columbia University</affiliation></author>
      <author><first>Olivia</first><last>Winn</last><affiliation>Columbia University</affiliation></author>
      <author><first>Artemis</first><last>Panagopoulou</last><affiliation>University of Pennsylvania</affiliation></author>
      <author><first>Yue</first><last>Yang</last><affiliation>University of Pennsylvania</affiliation></author>
      <author><first>Marianna</first><last>Apidianaki</last><affiliation>University of Pennsylvania</affiliation></author>
      <author><first>Smaranda</first><last>Muresan</last><affiliation>Columbia University</affiliation></author>
      <pages>7370-7388</pages>
      <abstract>Visual metaphors are powerful rhetorical devices used to persuade or communicate creative ideas through images. Similar to linguistic metaphors, they convey meaning implicitly through symbolism and juxtaposition of the symbols. We propose a new task of generating visual metaphors from linguistic metaphors. This is a challenging task for diffusion-based text-to-image models, such as DALL<tex-math>\cdot</tex-math>E 2, since it requires the ability to model implicit meaning and compositionality. We propose to solve the task through the collaboration between Large Language Models (LLMs) and Diffusion Models: Instruct GPT-3 (davinci-002) with Chain-of-Thought prompting generates text that represents a visual elaboration of the linguistic metaphor containing the implicit meaning and relevant objects, which is then used as input to the diffusion-based text-to-image models. Using a human-AI collaboration framework, where humans interact both with the LLM and the top-performing diffusion model, we create a high-quality dataset containing 6,476 visual metaphors for 1,540 linguistic metaphors and their associated visual elaborations. Evaluation by professional illustrators shows the promise of LLM-Diffusion Model collaboration for this task.To evaluate the utility of our Human-AI collaboration framework and the quality of our dataset, we perform both an intrinsic human-based evaluation and an extrinsic evaluation using visual entailment as a downstream task.</abstract>
      <url hash="0f62ce0f">2023.findings-acl.465</url>
      <bibkey>chakrabarty-etal-2023-spy</bibkey>
      <doi>10.18653/v1/2023.findings-acl.465</doi>
    </paper>
    <paper id="466">
      <title>Text Augmentation Using Dataset Reconstruction for Low-Resource Classification</title>
      <author><first>Adir</first><last>Rahamim</last><affiliation>Technion</affiliation></author>
      <author><first>Guy</first><last>Uziel</last><affiliation>IBM</affiliation></author>
      <author><first>Esther</first><last>Goldbraich</last><affiliation>IBM</affiliation></author>
      <author><first>Ateret</first><last>Anaby Tavor</last><affiliation>IBM Research AI</affiliation></author>
      <pages>7389-7402</pages>
      <abstract>In the deployment of real-world text classification models, label scarcity is a common problem and as the number of classes increases, this problem becomes even more complex. An approach to addressing this problem is by applying text augmentation methods. One of the more prominent methods involves using the text-generation capabilities of language models. In this paper, we propose Text AUgmentation by Dataset Reconstruction (TAU-DR), a novel method of data augmentation for text classification. We conduct experiments on several multi-class datasets, showing that our approach improves the current state-of-the-art techniques for data augmentation.</abstract>
      <url hash="33bcd49c">2023.findings-acl.466</url>
      <bibkey>rahamim-etal-2023-text</bibkey>
      <doi>10.18653/v1/2023.findings-acl.466</doi>
    </paper>
    <paper id="467">
      <title><fixed-case>L</fixed-case>a<fixed-case>SQ</fixed-case>u<fixed-case>E</fixed-case>: Improved Zero-Shot Classification from Explanations Through Quantifier Modeling and Curriculum Learning</title>
      <author><first>Sayan</first><last>Ghosh</last><affiliation>Department of Computer Science, University of North Carolina at Chapel Hill</affiliation></author>
      <author><first>Rakesh</first><last>R. Menon</last><affiliation>University of North Carolina Chapel Hill</affiliation></author>
      <author><first>Shashank</first><last>Srivastava</last><affiliation>UNC Chapel Hill</affiliation></author>
      <pages>7403-7419</pages>
      <abstract>A hallmark of human intelligence is the ability to learn new concepts purely from language. Several recent approaches have explored training machine learning models via natural language supervision. However, these approaches fall short in leveraging linguistic quantifiers (such as ‘always’ or ‘rarely’) and mimicking humans in compositionally learning complex tasks. Here, we present LaSQuE, a method that can learn zero-shot classifiers from language explanations by using three new strategies - (1) modeling the semantics of linguistic quantifiers in explanations (including exploiting ordinal strength relationships, such as ‘always’ &gt; ‘likely’), (2) aggregating information from multiple explanations using an attention-based mechanism, and (3) model training via curriculum learning. With these strategies, LaSQuE outperforms prior work, showing an absolute gain of up to 7% in generalizing to unseen real-world classification tasks.</abstract>
      <url hash="264b3401">2023.findings-acl.467</url>
      <bibkey>ghosh-etal-2023-lasque</bibkey>
      <doi>10.18653/v1/2023.findings-acl.467</doi>
    </paper>
    <paper id="468">
      <title>Learned Adapters Are Better Than Manually Designed Adapters</title>
      <author><first>Yuming</first><last>Zhang</last><affiliation>UW</affiliation></author>
      <author><first>Peng</first><last>Wang</last><affiliation>PAHT</affiliation></author>
      <author><first>Ming</first><last>Tan</last><affiliation>Tencent</affiliation></author>
      <author><first>Wei</first><last>Zhu</last><affiliation>East China Normal University</affiliation></author>
      <pages>7420-7437</pages>
      <abstract>Recently, a series of works have looked into further improving the adapter-based tuning by manually designing better adapter architectures. Understandably, these manually designed solutions are sub-optimal. In this work, we propose the Learned Adapter framework to automatically learn the optimal adapter architectures for better task adaptation of pre-trained models (PTMs). First, we construct a unified search space for adapter architecture designs. In terms of the optimization method on the search space, we propose a simple-yet-effective method, GDNAS for better architecture optimization. Extensive experiments show that our Learned Adapter framework can outperform the previous parameter-efficient tuning (PETuning) baselines while tuning comparable or fewer parameters. Moreover: (a) the learned adapter architectures are explainable and transferable across tasks. (b) We demonstrate that our architecture search space design is valid.</abstract>
      <url hash="6f2be612">2023.findings-acl.468</url>
      <bibkey>zhang-etal-2023-learned</bibkey>
      <doi>10.18653/v1/2023.findings-acl.468</doi>
    </paper>
    <paper id="469">
      <title>Automatic Identification of Code-Switching Functions in Speech Transcripts</title>
      <author><first>Ritu</first><last>Belani</last><affiliation>The Harker School</affiliation></author>
      <author><first>Jeffrey</first><last>Flanigan</last><affiliation>UC Santa Cruz</affiliation></author>
      <pages>7438-7448</pages>
      <abstract>Code-switching, or switching between languages, occurs for many reasons and has important linguistic, sociological, and cultural implications. Multilingual speakers code-switch for a variety of communicative functions, such as expressing emotions, borrowing terms, making jokes, introducing a new topic, etc. The function of code-switching may be quite useful for the analysis of linguists, cognitive scientists, speech therapists, and others, but is not readily apparent. To remedy this situation, we annotate and release a new dataset of functions of code-switching in Spanish-English. We build the first system (to our knowledge) to automatically identify a wide range of functions for which speakers code-switch in everyday speech, achieving an accuracy of 75% across all functions.</abstract>
      <url hash="4cb0f54a">2023.findings-acl.469</url>
      <bibkey>belani-flanigan-2023-automatic</bibkey>
      <doi>10.18653/v1/2023.findings-acl.469</doi>
    </paper>
    <paper id="470">
      <title>Federated Domain Adaptation for Named Entity Recognition via Distilling with Heterogeneous Tag Sets</title>
      <author><first>Rui</first><last>Wang</last><affiliation>Duke University</affiliation></author>
      <author><first>Tong</first><last>Yu</last><affiliation>Adobe Research</affiliation></author>
      <author><first>Junda</first><last>Wu</last><affiliation>New York University</affiliation></author>
      <author><first>Handong</first><last>Zhao</last><affiliation>Adobe Research</affiliation></author>
      <author><first>Sungchul</first><last>Kim</last><affiliation>Adobe</affiliation></author>
      <author><first>Ruiyi</first><last>Zhang</last><affiliation>Adobe Research</affiliation></author>
      <author><first>Subrata</first><last>Mitra</last><affiliation>Adobe Research</affiliation></author>
      <author><first>Ricardo</first><last>Henao</last><affiliation>Duke University</affiliation></author>
      <pages>7449-7463</pages>
      <abstract>Federated learning involves collaborative training with private data from multiple platforms, while not violating data privacy. We study the problem of federated domain adaptation for Named Entity Recognition (NER), where we seek to transfer knowledge across different platforms with data of multiple domains. In addition, we consider a practical and challenging scenario, where NER datasets of different platforms of federated learning are annotated with heterogeneous tag sets, i.e., different sets of entity types. The goal is to train a global model with federated learning, such that it can predict with a complete tag set, i.e., with all the occurring entity types for data across all platforms. To cope with the heterogeneous tag sets in a multi-domain setting, we propose a distillation approach along with a mechanism of instance weighting to facilitate knowledge transfer across platforms. Besides, we release two re-annotated clinic NER datasets, for testing the proposed method in the clinic domain. Our method shows superior empirical performance for NER with federated learning.</abstract>
      <url hash="fdd2dc65">2023.findings-acl.470</url>
      <bibkey>wang-etal-2023-federated</bibkey>
      <doi>10.18653/v1/2023.findings-acl.470</doi>
    </paper>
    <paper id="471">
      <title>Interpreting Sentiment Composition with Latent Semantic Tree</title>
      <author><first>Zhongtao</first><last>Jiang</last><affiliation>Institute of Automation, Chinese Academy of Sciences</affiliation></author>
      <author><first>Yuanzhe</first><last>Zhang</last><affiliation>Institute of Automation, Chinese Academy of Sciences</affiliation></author>
      <author><first>Cao</first><last>Liu</last><affiliation>Meituan</affiliation></author>
      <author><first>Jiansong</first><last>Chen</last><affiliation>Meituan</affiliation></author>
      <author><first>Jun</first><last>Zhao</last><affiliation>Chinese Academy of Sciences</affiliation></author>
      <author><first>Kang</first><last>Liu</last><affiliation>Institute of Automation, Chinese Academy of Sciences</affiliation></author>
      <pages>7464-7478</pages>
      <abstract>As the key to sentiment analysis, sentiment composition considers the classification of a constituent via classifications of its contained sub-constituents and rules operated on them. Such compositionality has been widely studied previously in the form of hierarchical trees including untagged and sentiment ones, which are intrinsically suboptimal in our view. To address this, we propose semantic tree, a new tree form capable of interpreting the sentiment composition in a principled way. Semantic tree is a derivation of a context-free grammar (CFG) describing the specific composition rules on difference semantic roles, which is designed carefully following previous linguistic conclusions. However, semantic tree is a latent variable since there is no its annotation in regular datasets. Thus, in our method, it is marginalized out via inside algorithm and learned to optimize the classification performance. Quantitative and qualitative results demonstrate that our method not only achieves better or competitive results compared to baselines in the setting of regular and domain adaptation classification, and also generates plausible tree explanations.</abstract>
      <url hash="85422e00">2023.findings-acl.471</url>
      <bibkey>jiang-etal-2023-interpreting</bibkey>
      <doi>10.18653/v1/2023.findings-acl.471</doi>
    </paper>
    <paper id="472">
      <title>Beyond Positive Scaling: How Negation Impacts Scaling Trends of Language Models</title>
      <author><first>Yuhui</first><last>Zhang</last><affiliation>Stanford University</affiliation></author>
      <author><first>Michihiro</first><last>Yasunaga</last><affiliation>Stanford University</affiliation></author>
      <author><first>Zhengping</first><last>Zhou</last><affiliation>Stanford University</affiliation></author>
      <author><first>Jeff Z.</first><last>HaoChen</last><affiliation>Stanford University</affiliation></author>
      <author><first>James</first><last>Zou</last><affiliation>Stanford University</affiliation></author>
      <author><first>Percy</first><last>Liang</last><affiliation>Stanford University</affiliation></author>
      <author><first>Serena</first><last>Yeung</last><affiliation>Stanford University</affiliation></author>
      <pages>7479-7498</pages>
      <abstract>Language models have been shown to exhibit positive scaling, where performance improves as models are scaled up in terms of size, compute, or data. In this work, we introduce NeQA, a dataset consisting of questions with negation in which language models do not exhibit straightforward positive scaling. We show that this task can exhibit inverse scaling, U-shaped scaling, or positive scaling, and the three scaling trends shift in this order as we use more powerful prompting methods or model families. We hypothesize that solving NeQA depends on two subtasks: question answering (task 1) and negation understanding (task 2). We find that task 1 has linear scaling, while task 2 has sigmoid-shaped scaling with an emergent transition point, and composing these two scaling trends yields the final scaling trend of NeQA. Our work reveals and provides a way to analyze the complex scaling trends of language models.</abstract>
      <url hash="66194370">2023.findings-acl.472</url>
      <bibkey>zhang-etal-2023-beyond</bibkey>
      <doi>10.18653/v1/2023.findings-acl.472</doi>
    </paper>
    <paper id="473">
      <title>Contrastive Training Improves Zero-Shot Classification of Semi-structured Documents</title>
      <author><first>Muhammad</first><last>Khalifa</last><affiliation>University of Michigan</affiliation></author>
      <author><first>Yogarshi</first><last>Vyas</last><affiliation>AWS AI Labs</affiliation></author>
      <author><first>Shuai</first><last>Wang</last><affiliation>Amazon AI</affiliation></author>
      <author><first>Graham</first><last>Horwood</last><affiliation>Amazon Web Services</affiliation></author>
      <author><first>Sunil</first><last>Mallya</last><affiliation>Flip AI</affiliation></author>
      <author><first>Miguel</first><last>Ballesteros</last><affiliation>Amazon</affiliation></author>
      <pages>7499-7508</pages>
      <abstract>We investigate semi-structured document classification in a zero-shot setting. Classification of semi-structured documents is more challenging than that of standard unstructured documents, as positional, layout, and style information play a vital role in interpreting such documents. The standard classification setting where categories are fixed during both training and testing falls short in dynamic environments where new classification categories could potentially emerge. We focus exclusively on the zero-shot learning setting where inference is done on new unseen classes. To address this task, we propose a matching-based approach that relies on a pairwise contrastive objective for both pretraining and fine-tuning. Our results show a significant boost in Macro F1 from the proposed pretraining step and comparable performance of the contrastive fine-tuning to a standard prediction objective in both supervised and unsupervised zero-shot settings.</abstract>
      <url hash="90785065">2023.findings-acl.473</url>
      <bibkey>khalifa-etal-2023-contrastive</bibkey>
      <doi>10.18653/v1/2023.findings-acl.473</doi>
    </paper>
    <paper id="474">
      <title>Extracting Shopping Interest-Related Product Types from the Web</title>
      <author><first>Yinghao</first><last>Li</last><affiliation>Georgia Institute of Technology</affiliation></author>
      <author><first>Colin</first><last>Lockard</last><affiliation>Amazon</affiliation></author>
      <author><first>Prashant</first><last>Shiralkar</last><affiliation>Amazon</affiliation></author>
      <author><first>Chao</first><last>Zhang</last><affiliation>Georgia Tech</affiliation></author>
      <pages>7509-7525</pages>
      <abstract>Recommending a diversity of product types (PTs) is important for a good shopping experience when customers are looking for products around their high-level shopping interests (SIs) such as hiking. However, the SI-PT connection is typically absent in e-commerce product catalogs and expensive to construct manually due to the volume of potential SIs, which prevents us from establishing a recommender with easily accessible knowledge systems. To establish such connections, we propose to extract PTs from the Web pages containing hand-crafted PT recommendations for SIs. The extraction task is formulated as binary HTML node classification given the general observation that an HTML node in our target Web pages can present one and only one PT phrase. Accordingly, we introduce TrENC, which stands for Tree-Transformer Encoders for Node Classification. It improves the inter-node dependency modeling with modified attention mechanisms that preserve the long-term sibling and ancestor-descendant relations. TrENC also injects SI into node features for better semantic representation. Trained on pages regarding limited SIs, TrEnc is ready to be applied to other unobserved interests. Experiments on our manually constructed dataset, WebPT, show that TrENC outperforms the best baseline model by 2.37 F1 points in the zero-shot setup. The performance indicates the feasibility of constructing SI-PT relations and using them to power downstream applications such as search and recommendation.</abstract>
      <url hash="81b8d7f6">2023.findings-acl.474</url>
      <bibkey>li-etal-2023-extracting</bibkey>
      <doi>10.18653/v1/2023.findings-acl.474</doi>
    </paper>
    <paper id="475">
      <title>Multilingual Pre-training with Self-supervision from Global Co-occurrence Information</title>
      <author><first>Xi</first><last>Ai</last><affiliation>Chongqing University</affiliation></author>
      <author><first>Bin</first><last>Fang</last><affiliation>Chongqing University</affiliation></author>
      <pages>7526-7543</pages>
      <abstract>Global co-occurrence information is the primary source of structural information on multilingual corpora, and we find that analogical/parallel compound words across languages have similar co-occurrence counts/frequencies (normalized) giving weak but stable self-supervision for cross-lingual transfer. Following the observation, we aim at associating contextualized representations with relevant (contextualized) representations across languages with the help of co-occurrence counts. The result is MLM-GC (MLM with Global Co-occurrence) pre-training that the model learns local bidirectional information from MLM and global co-occurrence information from a log-bilinear regression. Experiments show that MLM-GC pre-training substantially outperforms MLM pre-training for 4 downstream cross-lingual tasks and 1 additional monolingual task, showing the advantages of forming isomorphic spaces across languages.</abstract>
      <url hash="aa988462">2023.findings-acl.475</url>
      <bibkey>ai-fang-2023-multilingual</bibkey>
      <doi>10.18653/v1/2023.findings-acl.475</doi>
    </paper>
    <paper id="476">
      <title>Low-Rank Updates of pre-trained Weights for Multi-Task Learning</title>
      <author><first>Alexandre</first><last>Audibert</last><affiliation>Université Grenoble Alpes</affiliation></author>
      <author><first>Massih R</first><last>Amini</last><affiliation>University Grenoble Alps</affiliation></author>
      <author><first>Konstantin</first><last>Usevich</last><affiliation>CRAN, CNRS and Univ. Lorraine</affiliation></author>
      <author><first>Marianne</first><last>Clausel</last><affiliation>University of Lorraine</affiliation></author>
      <pages>7544-7554</pages>
      <abstract>Multi-Task Learning used with pre-trained models has been quite popular in the field of Natural Language Processing in recent years. This framework remains still challenging due to the complexity of the tasks and the challenges associated with fine-tuning large pre-trained models. In this paper, we propose a new approach for Multi-task learning which is based on stacking the weights of Neural Networks as a tensor. We show that low-rank updates in the canonical polyadic tensor decomposition of this tensor of weights lead to a simple, yet efficient algorithm, which without loss of performance allows to reduce considerably the model parameters. We investigate the interactions between tasks inside the model as well as the inclusion of sparsity to find the best tensor rank and to increase the compression rate. Our strategy is consistent with recent efforts that attempt to use constraints to fine-tune some model components. More precisely, we achieve equivalent performance as the state-of-the-art on the General Language Understanding Evaluation benchmark by training only 0.3 of the parameters per task while not modifying the baseline weights.</abstract>
      <url hash="22e7f813">2023.findings-acl.476</url>
      <bibkey>audibert-etal-2023-low</bibkey>
      <doi>10.18653/v1/2023.findings-acl.476</doi>
    </paper>
    <paper id="477">
      <title>Sequential Integrated Gradients: a simple but effective method for explaining language models</title>
      <author><first>Joseph</first><last>Enguehard</last><affiliation>Babylon Health</affiliation></author>
      <pages>7555-7565</pages>
      <abstract>Several explanation methods such as Integrated Gradients (IG) can be characterised as path-based methods, as they rely on a straight line between the data and an uninformative baseline. However, when applied to language models, these methods produce a path for each word of a sentence simultaneously, which could lead to creating sentences from interpolated words either having no clear meaning, or having a significantly different meaning compared to the original sentence. In order to keep the meaning of these sentences as close as possible to the original one, we propose Sequential Integrated Gradients (SIG), which computes the importance of each word in a sentence by keeping fixed every other words, only creating interpolations between the baseline and the word of interest. Moreover, inspired by the training procedure of language models, we also propose to replace the baseline token “pad” with the trained token “mask”. While being a simple improvement over the original IG method, we show on various models and datasets that SIG proves to be a very effective method for explaining language models.</abstract>
      <url hash="bbdbe26c">2023.findings-acl.477</url>
      <bibkey>enguehard-2023-sequential</bibkey>
      <doi>10.18653/v1/2023.findings-acl.477</doi>
    </paper>
    <paper id="478">
      <title><fixed-case>D</fixed-case>iffu<fixed-case>D</fixed-case>etox: A Mixed Diffusion Model for Text Detoxification</title>
      <author><first>Griffin</first><last>Floto</last><affiliation>University of Toronto</affiliation></author>
      <author><first>Mohammad Mahdi</first><last>Abdollah Pour</last><affiliation>University of Toronto</affiliation></author>
      <author><first>Parsa</first><last>Farinneya</last><affiliation>University of Toronto</affiliation></author>
      <author><first>Zhenwei</first><last>Tang</last><affiliation>University of Toronto</affiliation></author>
      <author><first>Ali</first><last>Pesaranghader</last><affiliation>LG Toronto AI Lab</affiliation></author>
      <author><first>Manasa</first><last>Bharadwaj</last><affiliation>LG Toronto AI Lab</affiliation></author>
      <author><first>Scott</first><last>Sanner</last><affiliation>University of Toronto</affiliation></author>
      <pages>7566-7574</pages>
      <abstract>Text detoxification is a conditional text generation task aiming to remove offensive content from toxic text. It is highly useful for online forums and social media, where offensive content is frequently encountered. Intuitively, there are diverse ways to detoxify sentences while preserving their meanings, and we can select from detoxified sentences before displaying text to users. Conditional diffusion models are particularly suitable for this task given their demonstrated higher generative diversity than existing conditional text generation models based on language models. Nonetheless, text fluency declines when they are trained with insufficient data, which is the case for this task. In this work, we propose DiffuDetox, a mixed conditional and unconditional diffusion model for text detoxification. The conditional model takes toxic text as the condition and reduces its toxicity, yielding a diverse set of detoxified sentences. The unconditional model is trained to recover the input text, which allows the introduction of additional fluent text for training and thus ensures text fluency. Extensive experimental results and in-depth analysis demonstrate the effectiveness of our proposed DiffuDetox.</abstract>
      <url hash="f187a213">2023.findings-acl.478</url>
      <bibkey>floto-etal-2023-diffudetox</bibkey>
      <doi>10.18653/v1/2023.findings-acl.478</doi>
    </paper>
    <paper id="479">
      <title>Separating Context and Pattern: Learning Disentangled Sentence Representations for Low-Resource Extractive Summarization</title>
      <author><first>Ruifeng</first><last>Yuan</last><affiliation>The Hong Kong Polytechnic University</affiliation></author>
      <author><first>Shichao</first><last>Sun</last><affiliation>The Hong Kong Polytechnic University</affiliation></author>
      <author><first>Zili</first><last>Wang</last><affiliation>Xiaohongshu Inc</affiliation></author>
      <author><first>Ziqiang</first><last>Cao</last><affiliation>Soochow University</affiliation></author>
      <author><first>Wenjie</first><last>Li</last><affiliation>The Hong Kong Polytechnic University</affiliation></author>
      <pages>7575-7586</pages>
      <abstract>Extractive summarization aims to select a set of salient sentences from the source document to form a summary. Context information has been considered one of the key factors for this task. Meanwhile, there also exist other pattern factors that can identify sentence importance, such as sentence position or certain n-gram tokens. However, such pattern information is only effective in specific datasets or domains and can not be generalized like the context information when there only exists limited data. In this case, current extractive summarization models may suffer from a performance drop when transferring to a new dataset. In this paper, we attempt to apply disentangled representation learning on extractive summarization, and separate the two key factors for the task, context and pattern, for a better generalization ability in the low-resource setting. To achieve this, we propose two groups of losses for encoding and disentangling sentence representations into context representations and pattern representations. In this case, we can either use only the context information in the zero-shot setting or fine-tune the pattern information in the few-shot setting. Experimental results on three summarization datasets from different domains show the effectiveness of our proposed approach.</abstract>
      <url hash="8851c63e">2023.findings-acl.479</url>
      <bibkey>yuan-etal-2023-separating</bibkey>
      <doi>10.18653/v1/2023.findings-acl.479</doi>
    </paper>
    <paper id="480">
      <title>Disentangling Reasoning Capabilities from Language Models with Compositional Reasoning Transformers</title>
      <author><first>Wanjun</first><last>Zhong</last><affiliation>Sun Yat-Sen University</affiliation></author>
      <author><first>Tingting</first><last>Ma</last><affiliation>Harbin Institute of Technology</affiliation></author>
      <author><first>Jiahai</first><last>Wang</last><affiliation>Sun Yat-sen University</affiliation></author>
      <author><first>Jian</first><last>Yin</last><affiliation>Sun Yat-Sen University</affiliation></author>
      <author><first>Tiejun</first><last>Zhao</last><affiliation>Harbin Institute of Technology</affiliation></author>
      <author><first>Chin-Yew</first><last>Lin</last><affiliation>Microsoft Research</affiliation></author>
      <author><first>Nan</first><last>Duan</last><affiliation>Microsoft Research Asia</affiliation></author>
      <pages>7587-7600</pages>
      <abstract>This paper presents ReasonFormer, a unified reasoning framework for mirroring the modular and compositional reasoning process of humans in complex decision-making. Inspired by dual-process theory in cognitive science, the representation module (automatic thinking) and reasoning modules (controlled thinking) are decoupled to capture different levels of cognition. Upon the top of the representation module, the pre-trained reasoning modules are modular and professional in specific and fundamental reasoning skills (e.g., logic, simple QA, etc). To mimic the controlled compositional thinking process, different reasoning modules are dynamically activated and composed in both parallel and cascaded manners to control what reasoning skills are activated and how deep the reasoning process will be reached to solve the current problems. The unified reasoning framework solves multiple tasks with a single model, and is trained and inferred in an end-to-end manner. Evaluated on 11 datasets requiring different reasoning skills and complexity, ReasonFormer demonstrates substantial performance boosts, revealing the compositional reasoning ability. Few-shot experiments exhibit better generalization ability by learning to compose pre-trained skills for new tasks with limited data, and decoupling the representation module and the reasoning modules. Further analysis shows the modularity of reasoning modules as different tasks activate distinct reasoning skills at different reasoning depths.</abstract>
      <url hash="be373abc">2023.findings-acl.480</url>
      <bibkey>zhong-etal-2023-disentangling</bibkey>
      <doi>10.18653/v1/2023.findings-acl.480</doi>
    </paper>
    <paper id="481">
      <title>Towards Argument-Aware Abstractive Summarization of Long Legal Opinions with Summary Reranking</title>
      <author><first>Mohamed</first><last>Elaraby</last><affiliation>University of Pittsburgh</affiliation></author>
      <author><first>Yang</first><last>Zhong</last><affiliation>University of Pittsburgh</affiliation></author>
      <author><first>Diane</first><last>Litman</last><affiliation>University of Pittsburgh</affiliation></author>
      <pages>7601-7612</pages>
      <abstract>We propose a simple approach for the abstractive summarization of long legal opinions that takes into account the argument structure of the document. Legal opinions often contain complex and nuanced argumentation, making it challenging to generate a concise summary that accurately captures the main points of the legal opinion. Our approach involves using argument role information to generate multiple candidate summaries, then reranking these candidates based on alignment with the document’s argument structure. We demonstrate the effectiveness of our approach on a dataset of long legal opinions and show that it outperforms several strong baselines.</abstract>
      <url hash="d5c68eab">2023.findings-acl.481</url>
      <bibkey>elaraby-etal-2023-towards</bibkey>
      <doi>10.18653/v1/2023.findings-acl.481</doi>
    </paper>
    <paper id="482">
      <title>Probabilistic Transformer: A Probabilistic Dependency Model for Contextual Word Representation</title>
      <author><first>Haoyi</first><last>Wu</last><affiliation>ShanghaiTech University</affiliation></author>
      <author><first>Kewei</first><last>Tu</last><affiliation>ShanghaiTech University</affiliation></author>
      <pages>7613-7636</pages>
      <abstract>Syntactic structures used to play a vital role in natural language processing (NLP), but since the deep learning revolution, NLP has been gradually dominated by neural models that do not consider syntactic structures in their design. One vastly successful class of neural models is transformers. When used as an encoder, a transformer produces contextual representation of words in the input sentence. In this work, we propose a new model of contextual word representation, not from a neural perspective, but from a purely syntactic and probabilistic perspective. Specifically, we design a conditional random field that models discrete latent representations of all words in a sentence as well as dependency arcs between them; and we use mean field variational inference for approximate inference. Strikingly, we find that the computation graph of our model resembles transformers, with correspondences between dependencies and self-attention and between distributions over latent representations and contextual embeddings of words. Experiments show that our model performs competitively to transformers on small to medium sized datasets. We hope that our work could help bridge the gap between traditional syntactic and probabilistic approaches and cutting-edge neural approaches to NLP, and inspire more linguistically-principled neural approaches in the future.</abstract>
      <url hash="29769e37">2023.findings-acl.482</url>
      <bibkey>wu-tu-2023-probabilistic</bibkey>
      <doi>10.18653/v1/2023.findings-acl.482</doi>
    </paper>
    <paper id="483">
      <title>Joint Speech Transcription and Translation: Pseudo-Labeling with Out-of-Distribution Data</title>
      <author><first>Mozhdeh</first><last>Gheini</last><affiliation>University of Southern California</affiliation></author>
      <author><first>Tatiana</first><last>Likhomanenko</last><affiliation>Apple</affiliation></author>
      <author><first>Matthias</first><last>Sperber</last><affiliation>Apple</affiliation></author>
      <author><first>Hendra</first><last>Setiawan</last><affiliation>Apple Inc.</affiliation></author>
      <pages>7637-7650</pages>
      <abstract>Self-training has been shown to be helpful in addressing data scarcity for many domains, including vision, speech, and language. Specifically, self-training, or pseudo-labeling, labels unsupervised data and adds that to the training pool. In this work, we investigate and use pseudo-labeling for a recently proposed novel setup: joint transcription and translation of speech, which suffers from an absence of sufficient parallel data resources. We show that under such data-deficient circumstances, the unlabeled data can significantly vary in domain from the supervised data, which results in pseudo-label quality degradation. We investigate two categories of remedies that require no additional supervision and target the domain mismatch: pseudo-label filtering and data augmentation. We show that pseudo-label analysis and processing in this way results in additional gains on top of the vanilla pseudo-labeling setup providing a total improvement of up to 0.4% absolute WER and 2.1 BLEU points for En–De and 0.6% absolute WER and 2.2 BLEU points for En–Zh.</abstract>
      <url hash="a13af34b">2023.findings-acl.483</url>
      <bibkey>gheini-etal-2023-joint</bibkey>
      <doi>10.18653/v1/2023.findings-acl.483</doi>
    </paper>
    <paper id="484">
      <title>Word-level Prefix/Suffix Sense Detection: A Case Study on Negation Sense with Few-shot Learning</title>
      <author><first>Yameng</first><last>Li</last><affiliation>Soochow University</affiliation></author>
      <author><first>Zicheng</first><last>Li</last><affiliation>Soochow University</affiliation></author>
      <author><first>Ying</first><last>Chen</last><affiliation>China Agricultural University</affiliation></author>
      <author><first>Shoushan</first><last>Li</last><affiliation>Soochow University</affiliation></author>
      <pages>7651-7658</pages>
      <abstract>Morphological analysis is an important research issue in the field of natural language processing. In this study, we propose a context-free morphological analysis task, namely word-level prefix/suffix sense detection, which deals with the ambiguity of sense expressed by prefix/suffix. To research this novel task, we first annotate a corpus with prefixes/suffixes expressing negation (e.g., il-, un-, -less) and then propose a novel few-shot learning approach that applies an input-augmentation prompt to a token-replaced detection pre-training model. Empirical studies demonstrate the effectiveness of the proposed approach to word-level prefix/suffix negation sense detection.</abstract>
      <url hash="b4426ca6">2023.findings-acl.484</url>
      <bibkey>li-etal-2023-word</bibkey>
      <doi>10.18653/v1/2023.findings-acl.484</doi>
    </paper>
    <paper id="485">
      <title>End-to-End Simultaneous Speech Translation with Differentiable Segmentation</title>
      <author><first>Shaolei</first><last>Zhang</last><affiliation>Institute of Computing Technology, Chinese Academy of Sciences</affiliation></author>
      <author><first>Yang</first><last>Feng</last><affiliation>Institute of Computing Technology, Chinese Academy of Sciences</affiliation></author>
      <pages>7659-7680</pages>
      <abstract>End-to-end simultaneous speech translation (SimulST) outputs translation while receiving the streaming speech inputs (a.k.a. streaming speech translation), and hence needs to segment the speech inputs and then translate based on the current received speech. However, segmenting the speech inputs at unfavorable moments can disrupt the acoustic integrity and adversely affect the performance of the translation model. Therefore, learning to segment the speech inputs at those moments that are beneficial for the translation model to produce high-quality translation is the key to SimulST. Existing SimulST methods, either using the fixed-length segmentation or external segmentation model, always separate segmentation from the underlying translation model, where the gap results in segmentation outcomes that are not necessarily beneficial for the translation process. In this paper, we propose Differentiable Segmentation (DiSeg) for SimulST to directly learn segmentation from the underlying translation model. DiSeg turns hard segmentation into differentiable through the proposed expectation training, enabling it to be jointly trained with the translation model and thereby learn translation-beneficial segmentation. Experimental results demonstrate that DiSeg achieves state-of-the-art performance and exhibits superior segmentation capability.</abstract>
      <url hash="00af27b0">2023.findings-acl.485</url>
      <bibkey>zhang-feng-2023-end</bibkey>
      <doi>10.18653/v1/2023.findings-acl.485</doi>
    </paper>
    <paper id="486">
      <title>Joint Generator-Ranker Learning for Natural Language Generation</title>
      <author><first>Weizhou</first><last>Shen</last><affiliation>School of Computer Science and Engineering, Sun Yat-sen University</affiliation></author>
      <author><first>Yeyun</first><last>Gong</last><affiliation>Microsoft Research Asia</affiliation></author>
      <author><first>Yelong</first><last>Shen</last><affiliation>Microsoft</affiliation></author>
      <author><first>Song</first><last>Wang</last><affiliation>Microsoft Azure AI</affiliation></author>
      <author><first>Xiaojun</first><last>Quan</last><affiliation>School of Computer Science and Engineering, Sun Yat-sen University</affiliation></author>
      <author><first>Nan</first><last>Duan</last><affiliation>Microsoft Research Asia</affiliation></author>
      <author><first>Weizhu</first><last>Chen</last><affiliation>Microsoft</affiliation></author>
      <pages>7681-7699</pages>
      <abstract>Generate-then-rank is a widely used mechanism for text generation, where a generator produces multiple text candidates and a ranker chooses the best one among the text candidates. However, existing methods usually train the generator and the ranker individually, neglecting the mutual feedback that could further enhance the generation quality. To tackle this limitation, we propose JGR, a novel joint training algorithm that integrates the generator and the ranker in a single framework. JGR optimizes the generator with a hybrid objective that combines data likelihood and ranker reward, and trains the ranker with a contrastive loss that compares the generator outputs. By iteratively updating the generator and the ranker, JGR can effectively harmonize their learning and enhance their quality jointly. We evaluate JGR on various text generation tasks and demonstrate that it surpasses existing methods on four public datasets across three common generation scenarios. Our code and models are publicly available at <url>https://github.com/microsoft/ProphetNet/tree/master/JGR</url>.</abstract>
      <url hash="ed3b29c1">2023.findings-acl.486</url>
      <bibkey>shen-etal-2023-joint</bibkey>
      <doi>10.18653/v1/2023.findings-acl.486</doi>
    </paper>
    <paper id="487">
      <title>Multilingual Sequence-to-Sequence Models for <fixed-case>H</fixed-case>ebrew <fixed-case>NLP</fixed-case></title>
      <author><first>Matan</first><last>Eyal</last><affiliation>Google Research</affiliation></author>
      <author><first>Hila</first><last>Noga</last><affiliation>Google</affiliation></author>
      <author><first>Roee</first><last>Aharoni</last><affiliation>Google</affiliation></author>
      <author><first>Idan</first><last>Szpektor</last><affiliation>Google Research</affiliation></author>
      <author><first>Reut</first><last>Tsarfaty</last><affiliation>Bar-Ilan University</affiliation></author>
      <pages>7700-7708</pages>
      <abstract>Recent work attributes progress in NLP to large language models (LMs) with increased model size and large quantities of pretraining data. Despite this, current state-of-the-art LMs for Hebrew are both under-parameterized and under-trained compared to LMs in other languages. Additionally, previous work on pretrained Hebrew LMs focused on encoder-only models. While the encoder-only architecture is beneficial for classification tasks, it does not cater well for sub-word prediction tasks, such as Named Entity Recognition, when considering the morphologically rich nature of Hebrew. In this paper we argue that sequence-to-sequence generative architectures are more suitable for large LMs in morphologically rich languages (MRLs) such as Hebrew. We demonstrate this by casting tasks in the Hebrew NLP pipeline as text-to-text tasks, for which we can leverage powerful multilingual, pretrained sequence-to-sequence models as mT5, eliminating the need for a separate, specialized, morpheme-based, decoder. Using this approach, our experiments show substantial improvements over previously published results on all existing Hebrew NLP benchmarks. These results suggest that multilingual sequence-to-sequence models present a promising building block for NLP for MRLs.</abstract>
      <url hash="9fa68aed">2023.findings-acl.487</url>
      <bibkey>eyal-etal-2023-multilingual</bibkey>
      <doi>10.18653/v1/2023.findings-acl.487</doi>
    </paper>
    <paper id="488">
      <title>Multilingual Knowledge Graph Completion from Pretrained Language Models with Knowledge Constraints</title>
      <author><first>Ran</first><last>Song</last><affiliation>Kunming University of Science and Technology</affiliation></author>
      <author><first>Shizhu</first><last>He</last><affiliation>Institute of Automation, Chinese Academy of Sciences</affiliation></author>
      <author><first>Shengxiang</first><last>Gao</last><affiliation>Kunming University of Science and Technology</affiliation></author>
      <author><first>Li</first><last>Cai</last><affiliation>Meituan Group</affiliation></author>
      <author><first>Kang</first><last>Liu</last><affiliation>Institute of Automation, Chinese Academy of Sciences</affiliation></author>
      <author><first>Zhengtao</first><last>Yu</last><affiliation>Kunming University of Science and Technology</affiliation></author>
      <author><first>Jun</first><last>Zhao</last><affiliation>NLPR, Institute of Automation, Chinese Academy of Sciences</affiliation></author>
      <pages>7709-7721</pages>
      <abstract>Multilingual Knowledge Graph Completion (mKGC) aim at solving queries in different languages by reasoning a tail entity thus improving multilingual knowledge graphs. Previous studies leverage multilingual pretrained language models (PLMs) and the generative paradigm to achieve mKGC. Although multilingual pretrained language models contain extensive knowledge of different languages, its pretraining tasks cannot be directly aligned with the mKGC tasks. Moreover, the majority of KGs and PLMs currently available exhibit a pronounced English-centric bias. This makes it difficult for mKGC to achieve good results, particularly in the context of low-resource languages. To overcome previous problems, this paper introduces global and local knowledge constraints for mKGC. The former is used to constrain the reasoning of answer entities , while the latter is used to enhance the representation of query contexts. The proposed method makes the pretrained model better adapt to the mKGC task. Experimental results on public datasets demonstrate that our method outperforms the previous SOTA on Hits@1 and Hits@10 by an average of 12.32% and 16.03%, which indicates that our proposed method has significant enhancement on mKGC.</abstract>
      <url hash="6e5c1e8c">2023.findings-acl.488</url>
      <bibkey>song-etal-2023-multilingual</bibkey>
      <doi>10.18653/v1/2023.findings-acl.488</doi>
    </paper>
    <paper id="489">
      <title>Towards Better Hierarchical Text Classification with Data Generation</title>
      <author><first>Yue</first><last>Wang</last><affiliation>Soochow University</affiliation></author>
      <author><first>Dan</first><last>Qiao</last><affiliation>Soochow University</affiliation></author>
      <author><first>Juntao</first><last>Li</last><affiliation>Soochow University</affiliation></author>
      <author><first>Jinxiong</first><last>Chang</last><affiliation>Ant Group</affiliation></author>
      <author><first>Qishen</first><last>Zhang</last><affiliation>Ant Group</affiliation></author>
      <author><first>Zhongyi</first><last>Liu</last><affiliation>Ant Group</affiliation></author>
      <author><first>Guannan</first><last>Zhang</last><affiliation>Ant Group</affiliation></author>
      <author><first>Min</first><last>Zhang</last><affiliation>Harbin Institute of Technology (Shenzhen)</affiliation></author>
      <pages>7722-7739</pages>
      <abstract>Hierarchical text classification (HTC) focuses on classifying one text into multiple labels, which are organized as a hierarchical taxonomy. Due to its wide involution in realistic scenarios, HTC attracts long-term attention from both industry and academia. However, the high cost of hierarchical multi-label annotation makes HTC suffer from the data scarcity problem. In view of the difficulty in balancing the controllability of multiple structural labels and text diversity, automatically generating high-quality data for HTC is challenging and under-explored. To fill this blank, we propose a novel data generation framework tailored for HTC, which can achieve both label controllability and text diversity by extracting high-quality semantic-level and phrase-level hierarchical label information. Experimental results on three benchmarks demonstrate that, compared with existing data augmentation methods, the data generated from our method can bring the most significant performance improvements of several strong HTC models. Extensive analysis confirms that the improvements yielded by our proposed method do correlate to the enhancement of label controllability and text diversity.</abstract>
      <url hash="90345c3f">2023.findings-acl.489</url>
      <bibkey>wang-etal-2023-towards-better</bibkey>
      <doi>10.18653/v1/2023.findings-acl.489</doi>
    </paper>
    <paper id="490">
      <title>History repeats: Overcoming catastrophic forgetting for event-centric temporal knowledge graph completion</title>
      <author><first>Mehrnoosh</first><last>Mirtaheri</last><affiliation>USC Information Sciences Institute</affiliation></author>
      <author><first>Mohammad</first><last>Rostami</last><affiliation>USC Information Sciences Institute</affiliation></author>
      <author><first>Aram</first><last>Galstyan</last><affiliation>USC Information Sciences Institute</affiliation></author>
      <pages>7740-7755</pages>
      <abstract>Temporal knowledge graph (TKG) completion models typically rely on having access to the entire graph during training. However, in real-world scenarios, TKG data is often received incrementally as events unfold, leading to a dynamic non-stationary data distribution over time. While one could incorporate fine-tuning to existing methods to allow them to adapt to evolving TKG data, this can lead to forgetting previously learned patterns. Alternatively, retraining the model with the entire updated TKG can mitigate forgetting but is computationally burdensome. To address these challenges, we propose a general continual training framework that is applicable to any TKG completion method, and leverages two key ideas: (i) a temporal regularization that encourages repurposing of less important model parameters for learning new knowledge, and (ii) a clustering-based experience replay that reinforces the past knowledge by selectively preserving only a small portion of the past data. Our experimental results on widely used event-centric TKG datasets demonstrate the effectiveness of our proposed continual training framework in adapting to new events while reducing catastrophic forgetting. Further, we perform ablation studies to show the effectiveness of each component of our proposed framework. Finally, we investigate the relation between the memory dedicated to experience replay and the benefit gained from our clustering-based sampling strategy.</abstract>
      <url hash="c7e9920d">2023.findings-acl.490</url>
      <bibkey>mirtaheri-etal-2023-history</bibkey>
      <doi>10.18653/v1/2023.findings-acl.490</doi>
    </paper>
    <paper id="491">
      <title>Multi-Agent Language Learning: Symbolic Mapping</title>
      <author><first>Yicheng</first><last>Feng</last><affiliation>Peking University</affiliation></author>
      <author><first>Zongqing</first><last>Lu</last><affiliation>Peking University</affiliation></author>
      <pages>7756-7770</pages>
      <abstract>The study of emergent communication has long been devoted to coax neural network agents to learn a language sharing similar properties with human language. In this paper, we try to find a ‘natural’ way to help agents learn a compositional and symmetric language in complex settings like dialog games. Inspired by the theory that human language was originated from simple interactions, we hypothesize that language may evolve from simple tasks to difficult tasks. We propose a curriculum learning method called task transfer, and propose a novel architecture called symbolic mapping. We find that task transfer distinctly helps language learning in difficult tasks, and symbolic mapping promotes the effect. Further, we explore vocabulary expansion, and show that with the help of symbolic mapping, agents can easily learn to use new symbols when the environment becomes more complex. All in all, we find that a process from simplicity to complexity can serve as a natural way to help multi-agent language learning, and the proposed symbolic mapping is effective for this process.</abstract>
      <url hash="6003d34d">2023.findings-acl.491</url>
      <bibkey>feng-lu-2023-multi</bibkey>
      <doi>10.18653/v1/2023.findings-acl.491</doi>
    </paper>
    <paper id="492">
      <title>Scaling Laws for <fixed-case>BERT</fixed-case> in Low-Resource Settings</title>
      <author><first>Gorka</first><last>Urbizu</last><affiliation>Orai NLP Technologies</affiliation></author>
      <author><first>Iñaki</first><last>San Vicente</last><affiliation>Orai NLP Technologies</affiliation></author>
      <author><first>Xabier</first><last>Saralegi</last><affiliation>Orai NLP Technologies</affiliation></author>
      <author><first>Rodrigo</first><last>Agerri</last><affiliation>HiTZ Center - Ixa, University of the Basque Country UPV/EHU</affiliation></author>
      <author><first>Aitor</first><last>Soroa</last><affiliation>HiTZ Center - Ixa, University of the Basque Country UPV/EHU</affiliation></author>
      <pages>7771-7789</pages>
      <abstract>Large language models are very resource intensive, both financially and environmentally, and require an amount of training data which is simply unobtainable for the majority of NLP practitioners. Previous work has researched the scaling laws of such models, but optimal ratios of model parameters, dataset size, and computation costs focused on the large scale. In contrast, we analyze the effect those variables have on the performance of language models in constrained settings, by building three lightweight BERT models (16M/51M/124M parameters) trained over a set of small corpora (5M/25M/125M words).We experiment on four languages of different linguistic characteristics (Basque, Spanish, Swahili and Finnish), and evaluate the models on MLM and several NLU tasks. We conclude that the power laws for parameters, data and compute for low-resource settings differ from the optimal scaling laws previously inferred, and data requirements should be higher. Our insights are consistent across all the languages we study, as well as across the MLM and downstream tasks. Furthermore, we experimentally establish when the cost of using a Transformer-based approach is worth taking, instead of favouring other computationally lighter solutions.</abstract>
      <url hash="ae7f3f17">2023.findings-acl.492</url>
      <bibkey>urbizu-etal-2023-scaling</bibkey>
      <doi>10.18653/v1/2023.findings-acl.492</doi>
    </paper>
    <paper id="493">
      <title>Pre-trained Language Model with Prompts for Temporal Knowledge Graph Completion</title>
      <author><first>Wenjie</first><last>Xu</last><affiliation>School of Computer Science, Wuhan University</affiliation></author>
      <author><first>Ben</first><last>Liu</last><affiliation>School of Computer Science, Wuhan University</affiliation></author>
      <author><first>Miao</first><last>Peng</last><affiliation>School of Computer Science, Wuhan University</affiliation></author>
      <author><first>Xu</first><last>Jia</last><affiliation>Wuhan University</affiliation></author>
      <author><first>Min</first><last>Peng</last><affiliation>School of Computer Science, Wuhan University</affiliation></author>
      <pages>7790-7803</pages>
      <abstract>Temporal Knowledge graph completion (TKGC) is a crucial task that involves reasoning at known timestamps to complete the missing part of facts and has attracted more and more attention in recent years. Most existing methods focus on learning representations based on graph neural networks while inaccurately extracting information from timestamps and insufficiently utilizing the implied information in relations. To address these problems, we propose a novel TKGC model, namely Pre-trained Language Model with Prompts for TKGC (PPT). We convert a series of sampled quadruples into pre-trained language model inputs and convert intervals between timestamps into different prompts to make coherent sentences with implicit semantic information. We train our model with a masking strategy to convert TKGC task into a masked token prediction task, which can leverage the semantic information in pre-trained language models. Experiments on three benchmark datasets and extensive analysis demonstrate that our model has great competitiveness compared to other models with four metrics. Our model can effectively incorporate information from temporal knowledge graphs into the language models.</abstract>
      <url hash="748b04e9">2023.findings-acl.493</url>
      <bibkey>xu-etal-2023-pre</bibkey>
      <doi>10.18653/v1/2023.findings-acl.493</doi>
    </paper>
    <paper id="494">
      <title>Is Continuous Prompt a Combination of Discrete Prompts? Towards a Novel View for Interpreting Continuous Prompts</title>
      <author><first>Tianjie</first><last>Ju</last><affiliation>Shanghai Jiao Tong University</affiliation></author>
      <author><first>Yubin</first><last>Zheng</last><affiliation>Shanghai Jiao Tong university</affiliation></author>
      <author><first>Hanyi</first><last>Wang</last><affiliation>Shanghai Jiao Tong University</affiliation></author>
      <author><first>Haodong</first><last>Zhao</last><affiliation>Shanghai Jiao Tong University</affiliation></author>
      <author><first>Gongshen</first><last>Liu</last><affiliation>Shanghai Jiao Tong University</affiliation></author>
      <pages>7804-7819</pages>
      <abstract>The broad adoption of continuous prompts has brought state-of-the-art results on a diverse array of downstream natural language processing (NLP) tasks. Nonetheless, little attention has been paid to the interpretability and transferability of continuous prompts. Faced with the challenges, we investigate the feasibility of interpreting continuous prompts as the weighting of discrete prompts by jointly optimizing prompt fidelity and downstream fidelity. Our experiments show that: (1) one can always find a combination of discrete prompts as the replacement of continuous prompts that performs well on downstream tasks; (2) our interpretable framework faithfully reflects the reasoning process of source prompts; (3) our interpretations provide effective readability and plausibility, which is helpful to understand the decision-making of continuous prompts and discover potential shortcuts. Moreover, through the bridge constructed between continuous prompts and discrete prompts using our interpretations, it is promising to implement the cross-model transfer of continuous prompts without extra training signals. We hope this work will lead to a novel perspective on the interpretations of continuous prompts.</abstract>
      <url hash="7319e844">2023.findings-acl.494</url>
      <bibkey>ju-etal-2023-continuous</bibkey>
      <doi>10.18653/v1/2023.findings-acl.494</doi>
    </paper>
    <paper id="495">
      <title>Putting Natural in Natural Language Processing</title>
      <author><first>Grzegorz</first><last>Chrupała</last><affiliation>Tilburg University</affiliation></author>
      <pages>7820-7827</pages>
      <abstract>Human language is firstly spoken and only secondarily written. Text, however, is a very convenient and efficient representation oflanguage, and modern civilization has made it ubiquitous. Thus the field of NLP has overwhelmingly focused on processing written ratherthan spoken language. Work on spoken language, on the other hand, has been siloed off within the largely separate speech processingcommunity which has been inordinately preoccupied with transcribing speech into text. Recent advances in deep learning have led to afortuitous convergence in methods between speech processing and mainstream NLP. Arguably, the time is ripe for a unification of thesetwo fields, and for starting to take spoken language seriously as the primary mode of human communication. Truly natural language processingcould lead to better integration with the rest of language science and could lead to systems which are more data-efficient and morehuman-like, and which can communicate beyond the textual modality.</abstract>
      <url hash="db20822d">2023.findings-acl.495</url>
      <bibkey>chrupala-2023-putting</bibkey>
      <doi>10.18653/v1/2023.findings-acl.495</doi>
    </paper>
    <paper id="496">
      <title>Impact of Adversarial Training on Robustness and Generalizability of Language Models</title>
      <author><first>Enes</first><last>Altinisik</last><affiliation>QCRI</affiliation></author>
      <author><first>Hassan</first><last>Sajjad</last><affiliation>Dalhousie University</affiliation></author>
      <author><first>Husrev</first><last>Sencar</last><affiliation>Qatar Computing Research Institute</affiliation></author>
      <author><first>Safa</first><last>Messaoud</last><affiliation>QCRI</affiliation></author>
      <author><first>Sanjay</first><last>Chawla</last><affiliation>QCRI</affiliation></author>
      <pages>7828-7840</pages>
      <abstract>Adversarial training is widely acknowledged as the most effective defense against adversarial attacks. However, it is also well established that achieving both robustness and generalization in adversarially trained models involves a trade-off. The goal of this work is to provide an in depth comparison of different approaches for adversarial training in language models. Specifically, we study the effect of pre-training data augmentation as well as training time input perturbations vs. embedding space perturbations on the robustness and generalization of transformer-based language models. Our findings suggest that better robustness can be achieved by pre-training data augmentation or by training with input space perturbation. However, training with embedding space perturbation significantly improves generalization. A linguistic correlation analysis of neurons of the learned models reveal that the improved generalization is due to ‘more specialized’ neurons. To the best of our knowledge, this is the first work to carry out a deep qualitative analysis of different methods of generating adversarial examples in adversarial training of language models.</abstract>
      <url hash="4caf7c85">2023.findings-acl.496</url>
      <bibkey>altinisik-etal-2023-impact</bibkey>
      <doi>10.18653/v1/2023.findings-acl.496</doi>
    </paper>
    <paper id="497">
      <title>Benchmarking Diverse-Modal Entity Linking with Generative Models</title>
      <author><first>Sijia</first><last>Wang</last><affiliation>Virginia Tech</affiliation></author>
      <author><first>Alexander Hanbo</first><last>Li</last><affiliation>AWS AI Labs</affiliation></author>
      <author><first>Henghui</first><last>Zhu</last><affiliation>Amazon</affiliation></author>
      <author><first>Sheng</first><last>Zhang</last><affiliation>Amazon</affiliation></author>
      <author><first>Pramuditha</first><last>Perera</last><affiliation>AWS AI Labs</affiliation></author>
      <author><first>Chung-Wei</first><last>Hang</last><affiliation>AWS AI Labs</affiliation></author>
      <author><first>Jie</first><last>Ma</last><affiliation>AWS AI Lab</affiliation></author>
      <author><first>William Yang</first><last>Wang</last><affiliation>Amazon AWS AI Labs</affiliation></author>
      <author><first>Zhiguo</first><last>Wang</last><affiliation>AWS AI Labs</affiliation></author>
      <author><first>Vittorio</first><last>Castelli</last><affiliation>AWS AI Labs</affiliation></author>
      <author><first>Bing</first><last>Xiang</last><affiliation>Amazon</affiliation></author>
      <author><first>Patrick</first><last>Ng</last><affiliation>Amazon.com</affiliation></author>
      <pages>7841-7857</pages>
      <abstract>Entities can be expressed in diverse formats, such as texts, images, or column names and cell values in tables. While existing entity linking (EL) models work well on per modality configuration, such as text-only EL, visual grounding or schema linking, it is more challenging to design a unified model for diverse modality configurations. To bring various modality configurations together, we constructed a benchmark for diverse-modal EL (DMEL) from existing EL datasets, covering all three modalities including text, image and table. To approach the DMEL task, we proposed a generative diverse-modal model (GDMM) following a multimodal-encoder-decoder paradigm. Pre-training GDMM with rich corpora builds a solid foundation for DMEL without storing the entire KB for inference. Fine-tuning GDMM builds a stronger DMEL baseline, outperforming state-of-the-art task-specific EL models by 8.51 F1 score on average. Additionally, extensive error analyses are conducted to highlight the challenge of DMEL, facilitating future researches on this task.</abstract>
      <url hash="4c9ca390">2023.findings-acl.497</url>
      <bibkey>wang-etal-2023-benchmarking</bibkey>
      <doi>10.18653/v1/2023.findings-acl.497</doi>
    </paper>
    <paper id="498">
      <title>Improving Empathetic Dialogue Generation by Dynamically Infusing Commonsense Knowledge</title>
      <author><first>Hua</first><last>Cai</last><affiliation>UniDT</affiliation></author>
      <author><first>Xuli</first><last>Shen</last><affiliation>Fudan University</affiliation></author>
      <author><first>Qing</first><last>Xu</last><affiliation>UniDT</affiliation></author>
      <author><first>Weilin</first><last>Shen</last><affiliation>UNIDT</affiliation></author>
      <author><first>Xiaomei</first><last>Wang</last><affiliation>UniDT</affiliation></author>
      <author><first>Weifeng</first><last>Ge</last><affiliation>Fudan University</affiliation></author>
      <author><first>Xiaoqing</first><last>Zheng</last><affiliation>Fudan University</affiliation></author>
      <author><first>Xiangyang</first><last>Xue</last><affiliation>Fudan University</affiliation></author>
      <pages>7858-7873</pages>
      <abstract>In empathetic conversations, individuals express their empathy towards others. Previous work has mainly focused on generating empathetic responses by utilizing the speaker’s emotion. Besides, external commonsense knowledge has been applied to enhance the system’s understandings of the speaker’s situation. However, given an event, commonsense knowledge base contains various relations, potentially leading to confusion for the dialogue system. Consequently, inconsistencies arise among the emotion, generated response and speaker’s contextual information. To this end, we propose a novel approach for empathetic response generation, which incorporates an adaptive module for commonsense knowledge selection to ensure consistency between the generated empathetic responses and the speaker’s situation. This selected knowledge is used to refine the commonsense cognition and empathy expression for generated responses. Experimental results show that our approach significantly outperforms baseline models in both automatic and human evaluations, exhibiting the generation of more coherent and empathetic responses. Moreover, case studies highlight the interpretability of knowledge selection in the responses and the effectiveness of adaptive module in our model. Code: <url>https://github.com/Hanscal/DCKS</url>.</abstract>
      <url hash="909f6030">2023.findings-acl.498</url>
      <bibkey>cai-etal-2023-improving</bibkey>
      <doi>10.18653/v1/2023.findings-acl.498</doi>
    </paper>
    <paper id="499">
      <title>Additive manifesto decomposition: A policy domain aware method for understanding party positioning</title>
      <author><first>Tanise</first><last>Ceron</last><affiliation>University of Stuttgart</affiliation></author>
      <author><first>Dmitry</first><last>Nikolaev</last><affiliation>University of Stuttgart</affiliation></author>
      <author><first>Sebastian</first><last>Padó</last><affiliation>Stuttgart University</affiliation></author>
      <pages>7874-7890</pages>
      <abstract>Automatic extraction of party (dis)similarities from texts such as party election manifestos or parliamentary speeches plays an increasing role in computational political science. However, existing approaches are fundamentally limited to targeting only global party (dis)-similarity: they condense the relationship between a pair of parties into a single figure, their similarity. In aggregating over all policy domains (e.g., health or foreign policy), they do not provide any qualitative insights into which domains parties agree or disagree on. This paper proposes a workflow for estimating policy domain aware party similarity that overcomes this limitation. The workflow covers (a) definition of suitable policy domains; (b) automatic labeling of domains, if no manual labels are available; (c) computation of domain-level similarities and aggregation at a global level; (d) extraction of interpretable party positions on major policy axes via multidimensional scaling. We evaluate our workflow on manifestos from the German federal elections. We find that our method (a) yields high correlation when predicting party similarity at a global level and (b) provides accurate party-specific positions, even with automatically labelled policy domains.</abstract>
      <url hash="ce120275">2023.findings-acl.499</url>
      <bibkey>ceron-etal-2023-additive</bibkey>
      <doi>10.18653/v1/2023.findings-acl.499</doi>
    </paper>
    <paper id="500">
      <title>Similarizing the Influence of Words with Contrastive Learning to Defend Word-level Adversarial Text Attack</title>
      <author><first>Pengwei</first><last>Zhan</last><affiliation>Institute of Information Engineering, Chinese Academy of Sciences; School of Cyber Security, University of Chinese Academy of Sciences</affiliation></author>
      <author><first>Jing</first><last>Yang</last><affiliation>Institute of Information Engneering, Chinese Academy of Science</affiliation></author>
      <author><first>He</first><last>Wang</last><affiliation>Institute of Information Engineering, Chinese Academy of Sciences</affiliation></author>
      <author><first>Chao</first><last>Zheng</last><affiliation>Institute of Information Engineering, Chinese Academy of Sciences</affiliation></author>
      <author><first>Xiao</first><last>Huang</last><affiliation>Institute of Information Engineering, Chinese Academy of Sciences</affiliation></author>
      <author><first>Liming</first><last>Wang</last><affiliation>Institute of Information Engineering, Chinese Academy of Sciences</affiliation></author>
      <pages>7891-7906</pages>
      <abstract>Neural language models are vulnerable to word-level adversarial text attacks, which generate adversarial examples by directly substituting discrete input words. Previous search methods for word-level attacks assume that the information in the important words is more influential on prediction than unimportant words. In this paper, motivated by this assumption, we propose a self-supervised regularization method for Similarizing the Influence of Words with Contrastive Learning (SIWCon) that encourages the model to learn sentence representations in which words of varying importance have a more uniform influence on prediction. Experiments show that SIWCon is compatible with various training methods and effectively improves model robustness against various unforeseen adversarial attacks. The effectiveness of SIWCon is also intuitively shown through qualitative analysis and visualization of the loss landscape, sentence representation, and changes in model confidence.</abstract>
      <url hash="f53cb19d">2023.findings-acl.500</url>
      <bibkey>zhan-etal-2023-similarizing</bibkey>
      <doi>10.18653/v1/2023.findings-acl.500</doi>
    </paper>
    <paper id="501">
      <title>Responsibility Perspective Transfer for <fixed-case>I</fixed-case>talian Femicide News</title>
      <author><first>Gosse</first><last>Minnema</last><affiliation>University of Groningen</affiliation></author>
      <author><first>Huiyuan</first><last>Lai</last><affiliation>University of Groningen</affiliation></author>
      <author><first>Benedetta</first><last>Muscato</last><affiliation>University of Catania</affiliation></author>
      <author><first>Malvina</first><last>Nissim</last><affiliation>University of Groningen</affiliation></author>
      <pages>7907-7918</pages>
      <abstract>Different ways of linguistically expressing the same real-world event can lead to different perceptions of what happened. Previous work has shown that different descriptions of gender-based violence (GBV) influence the reader’s perception of who is to blame for the violence, possibly reinforcing stereotypes which see the victim as partly responsible, too. As a contribution to raise awareness on perspective-based writing, and to facilitate access to alternative perspectives, we introduce the novel task of automatically rewriting GBV descriptions as a means to alter the perceived level of blame on the perpetrator. We present a quasi-parallel dataset of sentences with low and high perceived responsibility levels for the perpetrator, and experiment with unsupervised (mBART-based), zero-shot and few-shot (GPT3-based) methods for rewriting sentences. We evaluate our models using a questionnaire study and a suite of automatic metrics.</abstract>
      <url hash="814f8ada">2023.findings-acl.501</url>
      <bibkey>minnema-etal-2023-responsibility</bibkey>
      <doi>10.18653/v1/2023.findings-acl.501</doi>
    </paper>
    <paper id="502">
      <title>Stereotypes and Smut: The (Mis)representation of Non-cisgender Identities by Text-to-Image Models</title>
      <author><first>Eddie</first><last>Ungless</last><affiliation>University of Edinburgh</affiliation></author>
      <author><first>Bjorn</first><last>Ross</last><affiliation>University of Edinburgh</affiliation></author>
      <author><first>Anne</first><last>Lauscher</last><affiliation>University of Hamburg</affiliation></author>
      <pages>7919-7942</pages>
      <abstract>Cutting-edge image generation has been praised for producing high-quality images, suggesting a ubiquitous future in a variety of applications. However, initial studies have pointed to the potential for harm due to predictive bias, reflecting and potentially reinforcing cultural stereotypes. In this work, we are the first to investigate how multimodal models handle diverse gender identities. Concretely, we conduct a thorough analysis in which we compare the output of three image generation models for prompts containing cisgender vs. non-cisgender identity terms. Our findings demonstrate that certain non-cisgender identities are consistently (mis)represented as less human, more stereotyped and more sexualised. We complement our experimental analysis with (a) a survey among non-cisgender individuals and (b) a series of interviews, to establish which harms affected individuals anticipate, and how they would like to be represented. We find respondents are particularly concerned about misrepresentation, and the potential to drive harmful behaviours and beliefs. Simple heuristics to limit offensive content are widely rejected, and instead respondents call for community involvement, curated training data and the ability to customise. These improvements could pave the way for a future where change is led by the affected community, and technology is used to positively ”[portray] queerness in ways that we haven’t even thought of”’ rather than reproducing stale, offensive stereotypes.</abstract>
      <url hash="e9d33060">2023.findings-acl.502</url>
      <bibkey>ungless-etal-2023-stereotypes</bibkey>
      <doi>10.18653/v1/2023.findings-acl.502</doi>
    </paper>
    <paper id="503">
      <title>Fine-grained Artificial Neurons in Audio-transformers for Disentangling Neural Auditory Encoding</title>
      <author><first>Mengyue</first><last>Zhou</last><affiliation>School of Automation,Northwestern Polytechnical University</affiliation></author>
      <author><first>Xu</first><last>Liu</last><affiliation>Northwestern Polytechnical University</affiliation></author>
      <author><first>David</first><last>Liu</last><affiliation>Athens Academy</affiliation></author>
      <author><first>Zihao</first><last>Wu</last><affiliation>University of Georgia</affiliation></author>
      <author><first>Zhengliang</first><last>Liu</last><affiliation>University of Georgia</affiliation></author>
      <author><first>Lin</first><last>Zhao</last><affiliation>University of Georgia</affiliation></author>
      <author><first>Dajiang</first><last>Zhu</last><affiliation>University of Texas at Arlington</affiliation></author>
      <author><first>Lei</first><last>Guo</last><affiliation>Northwestern Polytechnical University</affiliation></author>
      <author><first>Junwei</first><last>Han</last><affiliation>Northwestern Polytechnical University</affiliation></author>
      <author><first>Tianming</first><last>Liu</last><affiliation>University of Georgia</affiliation></author>
      <author><first>Xintao</first><last>Hu</last><affiliation>Northwestern Polytechnical University</affiliation></author>
      <pages>7943-7956</pages>
      <abstract>The Wav2Vec and its variants have achieved unprecedented success in computational auditory and speech processing. Meanwhile, neural encoding studies that integrate the superb representation capability of Wav2Vec and link those representations to brain activities have provided novel insights into a fundamental question of how auditory and speech processing unfold in the human brain. Without an explicit definition, most existing studies treat each transformer encoding layer in Wav2Vec as a single artificial neuron (AN). That is, the layer-level embeddings are used to predict neural responses. However, the comprehensive layer-level embedding aggregates multiple types of contextual attention captured by multi-head self-attention (MSA) modules. Thus, the layer-level ANs lack fine-granularity for neural encoding. To address this limitation, we define the elementary units, i.e., each hidden dimension, as neuron-level ANs in Wav2Vec2.0, quantify their temporal responses, and couple those ANs with their biological-neuron (BN) counterparts in the human brain. Our experimental results demonstrated that: 1) The proposed neuron-level ANs carry meaningful neurolinguistic information; 2) Those ANs anchor to their BN signatures; 3) The AN-BN anchoring patterns are interpretable from a neurolinguistic perspective. More importantly, our results suggest an intermediate stage in both the computational representation in Wav2Vec2.0 and the cortical representation in the brain. Our study validates the fine-grained ANs in Wav2Vec2.0, which may serve as a novel and general strategy to link transformer-based deep learning models to neural responses for probing the sensory processing in the brain.</abstract>
      <url hash="477168c3">2023.findings-acl.503</url>
      <bibkey>zhou-etal-2023-fine</bibkey>
      <doi>10.18653/v1/2023.findings-acl.503</doi>
    </paper>
    <paper id="504">
      <title>Deeply Coupled Cross-Modal Prompt Learning</title>
      <author><first>Xuejing</first><last>Liu</last><affiliation>SenseTime</affiliation></author>
      <author><first>Wei</first><last>Tang</last><affiliation>Nanjing University of Science and Technology</affiliation></author>
      <author><first>Jinghui</first><last>Lu</last><affiliation>SenseTime Research, University College Dublin</affiliation></author>
      <author><first>Rui</first><last>Zhao</last><affiliation>SenseTime Group Limited</affiliation></author>
      <author><first>Zhaojun</first><last>Guo</last><affiliation>Fudan University</affiliation></author>
      <author><first>Fei</first><last>Tan</last><affiliation>Sensetime Research</affiliation></author>
      <pages>7957-7970</pages>
      <abstract>Recent advancements in multimodal foundation models (e.g., CLIP) have excelled in zero-shot generalization. Prompt tuning involved in the knowledge transfer from foundation models to downstream tasks has gained significant attention recently. Existing prompt-tuning methods in cross-modal learning, however, either solely focus on language branch, or learn vision-language interaction in a shallow mechanism. In this context, we propose a Deeply coupled Cross-modal Prompt learning (DCP) method based on CLIP. DCP flexibly accommodates the interplay between vision and language with a Cross-Modal Prompt Attention (CMPA) mechanism, which enables the mutual exchange of respective representation through a well-connected multi-head attention progressively and strongly. We then conduct comprehensive few-shot learning experiments on 11 image classification datasets and analyze the robustness to domain shift as well. Thorough experimental analysis evidently demonstrates the superb few-shot generalization and compelling domain adaption capacity of a well-executed DCP.</abstract>
      <url hash="de876f1e">2023.findings-acl.504</url>
      <bibkey>liu-etal-2023-deeply</bibkey>
      <doi>10.18653/v1/2023.findings-acl.504</doi>
    </paper>
    <paper id="505">
      <title>Opinion Tree Parsing for Aspect-based Sentiment Analysis</title>
      <author><first>Xiaoyi</first><last>Bao</last><affiliation>Soochow University</affiliation></author>
      <author><first>Xiaotong</first><last>Jiang</last><affiliation>Soochow University</affiliation></author>
      <author><first>Zhongqing</first><last>Wang</last><affiliation>Soochow University</affiliation></author>
      <author><first>Yue</first><last>Zhang</last><affiliation>Westlake University</affiliation></author>
      <author><first>Guodong</first><last>Zhou</last><affiliation>Soochow University</affiliation></author>
      <pages>7971-7984</pages>
      <abstract>Extracting sentiment elements using pre-trained generative models has recently led to large improvements in aspect-based sentiment analysis benchmarks. These models avoid explicit modeling of structure between sentiment elements, which are succinct yet lack desirable properties such as structure well-formedness guarantees or built-in elements alignments. In this study, we propose an opinion tree parsing model, aiming to parse all the sentiment elements from an opinion tree, which can explicitly reveal a more comprehensive and complete aspect-level sentiment structure. In particular, we first introduce a novel context-free opinion grammar to normalize the sentiment structure. We then employ a neural chart-based opinion tree parser to fully explore the correlations among sentiment elements and parse them in the opinion tree form. Extensive experiments show the superiority of our proposed model and the capacity of the opinion tree parser with the proposed context-free opinion grammar. More importantly, our model is much faster than previous models.</abstract>
      <url hash="0a294a63">2023.findings-acl.505</url>
      <bibkey>bao-etal-2023-opinion</bibkey>
      <doi>10.18653/v1/2023.findings-acl.505</doi>
    </paper>
    <paper id="506">
      <title><fixed-case>C</fixed-case>o<fixed-case>M</fixed-case>ix: Guide Transformers to Code-Mix using <fixed-case>POS</fixed-case> structure and Phonetics</title>
      <author><first>Gaurav</first><last>Arora</last><affiliation>Amazon</affiliation></author>
      <author><first>Srujana</first><last>Merugu</last><affiliation>Amazon</affiliation></author>
      <author><first>Vivek</first><last>Sembium</last><affiliation>Amazon</affiliation></author>
      <pages>7985-8002</pages>
      <abstract>Code-mixing is ubiquitous in multilingual societies, which makes it vital to build models for code-mixed data to power human language interfaces. Existing multilingual transformer models trained on pure corpora lack the ability to intermix words of one language into the structure of another. These models are also not robust to orthographic variations. We propose CoMixCoMix is not a trademark and only used to refer to our models for code-mixed data for presentational brevity., a pretraining approach to improve representation of code-mixed data in transformer models by incorporating phonetic signals, a modified attention mechanism, and weak supervision guided generation by parts-of-speech constraints. We show that CoMix improves performance across four code-mixed tasks: machine translation, sequence classification, named entity recognition (NER), and abstractive summarization. It also achieves the new SOTA performance for English-Hinglish translation and NER on LINCE Leaderboard and provides better generalization on out-of-domain translation. Motivated by variations in human annotations, we also propose a new family of metrics based on phonetics and demonstrate that the phonetic variant of BLEU correlates better with human judgement than BLEU on code-mixed text.</abstract>
      <url hash="be5548c0">2023.findings-acl.506</url>
      <bibkey>arora-etal-2023-comix</bibkey>
      <doi>10.18653/v1/2023.findings-acl.506</doi>
    </paper>
    <paper id="507">
      <title>Distilling Step-by-Step! Outperforming Larger Language Models with Less Training Data and Smaller Model Sizes</title>
      <author><first>Cheng-Yu</first><last>Hsieh</last><affiliation>University of Washington</affiliation></author>
      <author><first>Chun-Liang</first><last>Li</last><affiliation>Google</affiliation></author>
      <author><first>Chih-kuan</first><last>Yeh</last><affiliation>Google Inc</affiliation></author>
      <author><first>Hootan</first><last>Nakhost</last><affiliation>Google</affiliation></author>
      <author><first>Yasuhisa</first><last>Fujii</last><affiliation>Google</affiliation></author>
      <author><first>Alex</first><last>Ratner</last><affiliation>UW</affiliation></author>
      <author><first>Ranjay</first><last>Krishna</last><affiliation>University of Washington</affiliation></author>
      <author><first>Chen-Yu</first><last>Lee</last><affiliation>Google</affiliation></author>
      <author><first>Tomas</first><last>Pfister</last><affiliation>Google Inc.</affiliation></author>
      <pages>8003-8017</pages>
      <abstract>Deploying large language models (LLMs) is challenging because they are memory inefficient and compute-intensive for practical applications. In reaction, researchers train smaller task-specific models by either finetuning with human labels or distilling using LLM-generated labels. However, finetuning and distillation require large amounts of training data to achieve comparable performance to LLMs. We introduce Distilling step-by-step, a new mechanism that (a) trains smaller models that outperform LLMs, and (b) achieves so by leveraging less training data needed by finetuning or distillation. Our method extracts LLM rationales as additional supervision for training small models within a multi-task framework. We present three findings across 4 NLP benchmarks: First, compared to both finetuning and distillation, our mechanism achieves better performance with much fewer labeled/unlabeled training examples. Second, compared to few-shot prompted LLMs, we achieve better performance using substantially smaller model sizes. Third, we reduce both the model size and the amount of data required to outperform LLMs; our finetuned 770M T5 model outperforms the few-shot prompted 540B PaLM model using only 80% of available data on a benchmark, whereas standard finetuning the same T5 model struggles to match even by using 100% of the dataset.</abstract>
      <url hash="4761c5cc">2023.findings-acl.507</url>
      <bibkey>hsieh-etal-2023-distilling</bibkey>
      <doi>10.18653/v1/2023.findings-acl.507</doi>
    </paper>
    <paper id="508">
      <title>Prosody-<fixed-case>TTS</fixed-case>: Improving Prosody with Masked Autoencoder and Conditional Diffusion Model For Expressive Text-to-Speech</title>
      <author><first>Rongjie</first><last>Huang</last><affiliation>Zhejiang University</affiliation></author>
      <author><first>Chunlei</first><last>Zhang</last><affiliation>Tencent AI Lab</affiliation></author>
      <author><first>Yi</first><last>Ren</last><affiliation>Bytedance</affiliation></author>
      <author><first>Zhou</first><last>Zhao</last><affiliation>zhejiang university</affiliation></author>
      <author><first>Dong</first><last>Yu</last><affiliation>Tencent AI Lab</affiliation></author>
      <pages>8018-8034</pages>
      <abstract>Expressive text-to-speech aims to generate high-quality samples with rich and diverse prosody, which is hampered by <b>dual challenges</b>: 1) prosodic attributes in highly dynamic voices are difficult to capture and model without intonation; and 2) highly multimodal prosodic representations cannot be well learned by simple regression (e.g., MSE) objectives, which causes blurry and over-smoothing predictions. This paper proposes Prosody-TTS, a two-stage pipeline that enhances <b>prosody modeling and sampling</b> by introducing several components: 1) a self-supervised masked autoencoder to model the prosodic representation without relying on text transcriptions or local prosody attributes, which ensures to cover diverse speaking voices with superior generalization; and 2) a diffusion model to sample diverse prosodic patterns within the latent space, which prevents TTS models from generating samples with dull prosodic performance. Experimental results show that Prosody-TTS achieves new state-of-the-art in text-to-speech with natural and expressive synthesis. Both subjective and objective evaluation demonstrate that it exhibits superior audio quality and prosody naturalness with rich and diverse prosodic attributes. Audio samples are available at <url>https://improved_prosody.github.io</url></abstract>
      <url hash="51560c7a">2023.findings-acl.508</url>
      <bibkey>huang-etal-2023-prosody</bibkey>
      <doi>10.18653/v1/2023.findings-acl.508</doi>
    </paper>
    <paper id="509">
      <title>Duplex Diffusion Models Improve Speech-to-Speech Translation</title>
      <author><first>Xianchao</first><last>Wu</last><affiliation>NVIDIA</affiliation></author>
      <pages>8035-8047</pages>
      <abstract>Speech-to-speech translation is a typical sequence-to-sequence learning task that naturally has two directions. How to effectively leverage bidirectional supervision signals to produce high-fidelity audio for both directions? Existing approaches either train two separate models or a multitask-learned model with low efficiency and inferior performance. In this paper, we propose a duplex diffusion model that applies diffusion probabilistic models to both sides of a reversible duplex Conformer, so that either end can simultaneously input and output a distinct language’s speech. Our model enables reversible speech translation by simply flipping the input and output ends. Experiments show that our model achieves the first success of reversible speech translation with significant improvements of ASR-BLEU scores compared with a list of state-of-the-art baselines.</abstract>
      <url hash="31b9decd">2023.findings-acl.509</url>
      <bibkey>wu-2023-duplex</bibkey>
      <doi>10.18653/v1/2023.findings-acl.509</doi>
    </paper>
    <paper id="510">
      <title>Global and Local Hierarchy-aware Contrastive Framework for Implicit Discourse Relation Recognition</title>
      <author><first>Yuxin</first><last>Jiang</last><affiliation>The Hong Kong University of Science and Technology</affiliation></author>
      <author><first>Linhan</first><last>Zhang</last><affiliation>University of New South Wales</affiliation></author>
      <author><first>Wei</first><last>Wang</last><affiliation>HKUST(GZ)</affiliation></author>
      <pages>8048-8064</pages>
      <abstract>Due to the absence of explicit connectives, implicit discourse relation recognition (IDRR) remains a challenging task in discourse analysis. The critical step for IDRR is to learn high-quality discourse relation representations between two arguments. Recent methods tend to integrate the whole hierarchical information of senses into discourse relation representations for multi-level sense recognition. Nevertheless, they insufficiently incorporate the static hierarchical structure containing all senses (defined as global hierarchy), and ignore the hierarchical sense label sequence corresponding to each instance (defined as local hierarchy). For the purpose of sufficiently exploiting global and local hierarchies of senses to learn better discourse relation representations, we propose a novel GlObal and Local Hierarchy-aware Contrastive Framework (GOLF), to model two kinds of hierarchies with the aid of multi-task learning and contrastive learning. Experimental results on PDTB 2.0 and PDTB 3.0 datasets demonstrate that our method remarkably outperforms current state-of-the-art models at all hierarchical levels.</abstract>
      <url hash="95cf27d6">2023.findings-acl.510</url>
      <bibkey>jiang-etal-2023-global</bibkey>
      <doi>10.18653/v1/2023.findings-acl.510</doi>
    </paper>
    <paper id="511">
      <title><fixed-case>P</fixed-case>re<fixed-case>Q</fixed-case>uant: A Task-agnostic Quantization Approach for Pre-trained Language Models</title>
      <author><first>Zhuocheng</first><last>Gong</last><affiliation>Peking University</affiliation></author>
      <author><first>Jiahao</first><last>Liu</last><affiliation>Meituan</affiliation></author>
      <author><first>Qifan</first><last>Wang</last><affiliation>Meta AI</affiliation></author>
      <author><first>Yang</first><last>Yang</last><affiliation>Meituan</affiliation></author>
      <author><first>Jingang</first><last>Wang</last><affiliation>Meituan</affiliation></author>
      <author><first>Wei</first><last>Wu</last><affiliation/></author>
      <author><first>Yunsen</first><last>Xian</last><affiliation>Meituan</affiliation></author>
      <author><first>Dongyan</first><last>Zhao</last><affiliation>pku.edu.cn</affiliation></author>
      <author><first>Rui</first><last>Yan</last><affiliation>Renmin University of China</affiliation></author>
      <pages>8065-8079</pages>
      <abstract>While transformer-based pre-trained language models (PLMs) have dominated a number of NLP applications, these models are heavy to deploy and expensive to use. Therefore, effectively compressing large-scale PLMs becomes an increasingly important problem. Quantization, which represents high-precision tensors with low-bit fix-point format, is a viable solution. However, most existing quantization methods are task-specific, requiring customized training and quantization with a large number of trainable parameters on each individual task. Inspired by the observation that the over-parameterization nature of PLMs makes it possible to freeze most of the parameters during the fine-tuning stage, in this work, we propose a novel “quantize before fine-tuning” framework, PreQuant, that differs from both quantization-aware training and post-training quantization. {pasted macro ‘OUR’} is compatible with various quantization strategies, with outlier-aware parameter-efficient fine-tuning incorporated to correct the induced quantization error. We demonstrate the effectiveness of PreQuant on the GLUE benchmark using BERT, RoBERTa, and T5. We also provide an empirical investigation into the workflow of PreQuant, which sheds light on its efficacy.</abstract>
      <url hash="3af9d748">2023.findings-acl.511</url>
      <bibkey>gong-etal-2023-prequant</bibkey>
      <doi>10.18653/v1/2023.findings-acl.511</doi>
    </paper>
    <paper id="512">
      <title>Synthetic Pre-Training Tasks for Neural Machine Translation</title>
      <author><first>Zexue</first><last>He</last><affiliation>University of California, San Diego</affiliation></author>
      <author><first>Graeme</first><last>Blackwood</last><affiliation>IBM Research AI</affiliation></author>
      <author><first>Rameswar</first><last>Panda</last><affiliation>MIT-IBM Watson AI Lab</affiliation></author>
      <author><first>Julian</first><last>McAuley</last><affiliation>UCSD</affiliation></author>
      <author><first>Rogerio</first><last>Feris</last><affiliation>IBM</affiliation></author>
      <pages>8080-8098</pages>
      <abstract>Pre-training models with large crawled corpora can lead to issues such as toxicity and bias, as well as copyright and privacy concerns. A promising way of alleviating such concerns is to conduct pre-training with synthetic tasks and data, since no real-world information is ingested by the model. Our goal in this paper is to understand the factors that contribute to the effectiveness of pre-training models when using synthetic resources, particularly in the context of neural machine translation. We propose several novel approaches to pre-training translation models that involve different levels of lexical and structural knowledge, including: 1) generating obfuscated data from a large parallel corpus 2) concatenating phrase pairs extracted from a small word-aligned corpus, and 3) generating synthetic parallel data without real human language corpora. Our experiments on multiple language pairs reveal that pre-training benefits can be realized even with high levels of obfuscation or purely synthetic parallel data. We hope the findings from our comprehensive empirical analysis will shed light on understanding what matters for NMT pre-training, as well as pave the way for the development of more efficient and less toxic models.</abstract>
      <url hash="f915935d">2023.findings-acl.512</url>
      <bibkey>he-etal-2023-synthetic</bibkey>
      <doi>10.18653/v1/2023.findings-acl.512</doi>
    </paper>
    <paper id="513">
      <title><fixed-case>IDOL</fixed-case>: Indicator-oriented Logic Pre-training for Logical Reasoning</title>
      <author><first>Zihang</first><last>Xu</last><affiliation>iFLYTEK Research</affiliation></author>
      <author><first>Ziqing</first><last>Yang</last><affiliation>iFLYTEK Research</affiliation></author>
      <author><first>Yiming</first><last>Cui</last><affiliation>Joint Laboratory of HIT and iFLYTEK Research</affiliation></author>
      <author><first>Shijin</first><last>Wang</last><affiliation>iFLYTEK Research</affiliation></author>
      <pages>8099-8111</pages>
      <abstract>In the field of machine reading comprehension (MRC), existing systems have surpassed the average performance of human beings in many tasks like SQuAD. However, there is still a long way to go when it comes to logical reasoning. Although some methods for it have been put forward, they either are designed in a quite complicated way or rely too much on external structures. In this paper, we proposed IDOL (InDicator-Oriented Logic Pre-training), an easy-to-understand but highly effective further pre-training task which logically strengthens the pre-trained models with the help of 6 types of logical indicators and a logically rich dataset LoGic Pre-training (LGP). IDOL achieves state-of-the-art performance on ReClor and LogiQA, the two most representative benchmarks in logical reasoning MRC, and is proven to be capable of generalizing to different pre-trained models and other types of MRC benchmarks like RACE and SQuAD 2.0 while keeping competitive general language understanding ability through testing on tasks in GLUE. Besides, at the beginning of the era of large language models, we take several of them like ChatGPT into comparison and find that IDOL still shows its advantage.</abstract>
      <url hash="7dec1a54">2023.findings-acl.513</url>
      <bibkey>xu-etal-2023-idol</bibkey>
      <doi>10.18653/v1/2023.findings-acl.513</doi>
    </paper>
    <paper id="514">
      <title>Adversarial Training for Low-Resource Disfluency Correction</title>
      <author><first>Vineet</first><last>Bhat</last><affiliation>IIT Bombay</affiliation></author>
      <author><first>Preethi</first><last>Jyothi</last><affiliation>Indian Institute of Technology Bombay</affiliation></author>
      <author><first>Pushpak</first><last>Bhattacharyya</last><affiliation>Indian Institute of Technology Bombay and Patna</affiliation></author>
      <pages>8112-8122</pages>
      <abstract>Disfluencies commonly occur in conversational speech. Speech with disfluencies can result in noisy Automatic Speech Recognition (ASR) transcripts, which affects downstream tasks like machine translation. In this paper, we propose an adversarially-trained sequence-tagging model for Disfluency Correction (DC) that utilizes a small amount of labeled real disfluent data in conjunction with a large amount of unlabeled data. We show the benefit of our proposed technique, which crucially depends on synthetically generated disfluent data, by evaluating it for DC in three Indian languages- Bengali, Hindi, and Marathi (all from the Indo-Aryan family). Our technique also performs well in removing stuttering disfluencies in ASR transcripts introduced by speech impairments. We achieve an average 6.15 points improvement in F1-score over competitive baselines across all three languages mentioned. To the best of our knowledge, we are the first to utilize adversarial training for DC and use it to correct stuttering disfluencies in English, establishing a new benchmark for this task.</abstract>
      <url hash="8ea08f86">2023.findings-acl.514</url>
      <bibkey>bhat-etal-2023-adversarial</bibkey>
      <doi>10.18653/v1/2023.findings-acl.514</doi>
    </paper>
    <paper id="515">
      <title>Computer says “No”: The Case Against Empathetic Conversational <fixed-case>AI</fixed-case></title>
      <author><first>Alba</first><last>Cercas Curry</last><affiliation>University of Leeds</affiliation></author>
      <author><first>Amanda</first><last>Cercas Curry</last><affiliation>Bocconi University</affiliation></author>
      <pages>8123-8130</pages>
      <abstract>Emotions are an integral part of human cognition and they guide not only our understanding of the world but also our actions within it. As such, whether we soothe or flame an emotion is not inconsequential. Recent work in conversational AI has focused on responding empathetically to users, validating and soothing their emotions without a real basis. This AI-aided emotional regulation can have negative consequences for users and society, tending towards a one-noted happiness defined as only the absence of “negative” emotions. We argue that we must carefully consider whether and how to respond to users’ emotions.</abstract>
      <url hash="0265d328">2023.findings-acl.515</url>
      <bibkey>cercas-curry-cercas-curry-2023-computer</bibkey>
      <doi>10.18653/v1/2023.findings-acl.515</doi>
    </paper>
    <paper id="516">
      <title>Stubborn Lexical Bias in Data and Models</title>
      <author><first>Sofia</first><last>Serrano</last><affiliation>University of Washington</affiliation></author>
      <author><first>Jesse</first><last>Dodge</last><affiliation>Allen Institute for AI</affiliation></author>
      <author><first>Noah A.</first><last>Smith</last><affiliation>University of Washington</affiliation></author>
      <pages>8131-8146</pages>
      <abstract>In NLP, recent work has seen increased focus on spurious correlations between various features and labels in training data, and how these influence model behavior. However, the presence and effect of such correlations are typically examined feature by feature. We investigate the cumulative impact on a model of many such intersecting features. Using a new statistical method, we examine whether such spurious patterns in data appear in models trained on the data. We select two tasks— natural language inference and duplicate-question detection— for which any unigram feature on its own should ideally be uninformative, which gives us a large pool of automatically extracted features with which to experiment. The large size of this pool allows us to investigate the intersection of features spuriously associated with (potentially different) labels. We then apply an optimization approach to *reweight* the training data, reducing thousands of spurious correlations, and examine how doing so affects models trained on the reweighted data. Surprisingly, though this method can successfully reduce lexical biases in the training data, we still find strong evidence of corresponding bias in the trained models, including worsened bias for slightly more complex features (bigrams). We close with discussion about the implications of our results on what it means to “debias” training data, and how issues of data quality can affect model bias.</abstract>
      <url hash="dcf0757f">2023.findings-acl.516</url>
      <bibkey>serrano-etal-2023-stubborn</bibkey>
      <doi>10.18653/v1/2023.findings-acl.516</doi>
    </paper>
    <paper id="517">
      <title>Distilling Efficient Language-Specific Models for Cross-Lingual Transfer</title>
      <author><first>Alan</first><last>Ansell</last><affiliation>University of Cambridge</affiliation></author>
      <author><first>Edoardo Maria</first><last>Ponti</last><affiliation>University of Edinburgh / University of Cambridge</affiliation></author>
      <author><first>Anna</first><last>Korhonen</last><affiliation>University of Cambridge</affiliation></author>
      <author><first>Ivan</first><last>Vulić</last><affiliation>University of Cambridge</affiliation></author>
      <pages>8147-8165</pages>
      <abstract>Massively multilingual Transformers (MMTs), such as mBERT and XLM-R, are widely used for cross-lingual transfer learning. While these are pretrained to represent hundreds of languages, end users of NLP systems are often interested only in individual languages. For such purposes, the MMTs’ language coverage makes them unnecessarily expensive to deploy in terms of model size, inference time, energy, and hardware cost. We thus propose to extract compressed, language-specific models from MMTs which retain the capacity of the original MMTs for cross-lingual transfer. This is achieved by distilling the MMT *bilingually*, i.e., using data from only the source and target language of interest. Specifically, we use a two-phase distillation approach, termed BiStil: (i) the first phase distils a general bilingual model from the MMT, while (ii) the second, task-specific phase sparsely fine-tunes the bilingual “student” model using a task-tuned variant of the original MMT as its “teacher”. We evaluate this distillation technique in zero-shot cross-lingual transfer across a number of standard cross-lingual benchmarks. The key results indicate that the distilled models exhibit minimal degradation in target language performance relative to the base MMT despite being significantly smaller and faster. Furthermore, we find that they outperform multilingually distilled models such as DistilmBERT and MiniLMv2 while having a very modest training budget in comparison, even on a per-language basis. We also show that bilingual models distilled from MMTs greatly outperform bilingual models trained from scratch.</abstract>
      <url hash="21c061e9">2023.findings-acl.517</url>
      <bibkey>ansell-etal-2023-distilling</bibkey>
      <doi>10.18653/v1/2023.findings-acl.517</doi>
    </paper>
    <paper id="518">
      <title>An Extensive Exploration of Back-Translation in 60 Languages</title>
      <author><first>Paul</first><last>McNamee</last><affiliation>Johns Hopkins University</affiliation></author>
      <author><first>Kevin</first><last>Duh</last><affiliation>Johns Hopkins University</affiliation></author>
      <pages>8166-8183</pages>
      <abstract>Back-translation is a data augmentation technique that has been shown to improve model quality through the creation of synthetic training bitext. Early studies showed the promise of the technique and follow on studies have produced additional refinements. We have undertaken a broad investigation using back-translation to train models from 60 languages into English; the majority of these languages are considered moderate- or low-resource languages. We observed consistent gains, though compared to prior work we saw conspicuous gains in quite a number of lower-resourced languages. We analyzed differences in translations between baseline and back-translation models, and observed many indications of improved translation quality. Translation of both rare and common terms is improved, and these improvements occur despite the less natural synthetic source-language text used in training.</abstract>
      <url hash="79a956b8">2023.findings-acl.518</url>
      <bibkey>mcnamee-duh-2023-extensive</bibkey>
      <doi>10.18653/v1/2023.findings-acl.518</doi>
    </paper>
    <paper id="519">
      <title><fixed-case>A</fixed-case>o<fixed-case>M</fixed-case>: Detecting Aspect-oriented Information for Multimodal Aspect-Based Sentiment Analysis</title>
      <author><first>Ru</first><last>Zhou</last><affiliation>Nankai University</affiliation></author>
      <author><first>Wenya</first><last>Guo</last><affiliation>Nankai University</affiliation></author>
      <author><first>Xumeng</first><last>Liu</last><affiliation>Nankai University</affiliation></author>
      <author><first>Shenglong</first><last>Yu</last><affiliation>Nankai University</affiliation></author>
      <author><first>Ying</first><last>Zhang</last><affiliation>Nankai University</affiliation></author>
      <author><first>Xiaojie</first><last>Yuan</last><affiliation>Nankai University</affiliation></author>
      <pages>8184-8196</pages>
      <abstract>Multimodal aspect-based sentiment analysis (MABSA) aims to extract aspects from text-image pairs and recognize their sentiments. Existing methods make great efforts to align the whole image to corresponding aspects. However, different regions of the image may relate to different aspects in the same sentence, and coarsely establishing image-aspect alignment will introduce noise to aspect-based sentiment analysis (i.e., visual noise). Besides, the sentiment of a specific aspect can also be interfered by descriptions of other aspects (i.e., textual noise). Considering the aforementioned noises, this paper proposes an Aspect-oriented Method (AoM) to detect aspect-relevant semantic and sentiment information. Specifically, an aspect-aware attention module is designed to simultaneously select textual tokens and image blocks that are semantically related to the aspects. To accurately aggregate sentiment information, we explicitly introduce sentiment embedding into AoM, and use a graph convolutional network to model the vision-text and text-text interaction. Extensive experiments demonstrate the superiority of AoM to existing methods.</abstract>
      <url hash="1ad774f5">2023.findings-acl.519</url>
      <bibkey>zhou-etal-2023-aom</bibkey>
      <doi>10.18653/v1/2023.findings-acl.519</doi>
    </paper>
    <paper id="520">
      <title>Forecasting Earnings Surprises from Conference Call Transcripts</title>
      <author><first>Ross</first><last>Koval</last><affiliation>University of California at Santa Barbara</affiliation></author>
      <author><first>Nicholas</first><last>Andrews</last><affiliation>Johns Hopkins University</affiliation></author>
      <author><first>Xifeng</first><last>Yan</last><affiliation>University of California at Santa Barbara</affiliation></author>
      <pages>8197-8209</pages>
      <abstract>There is a multitude of textual data relevant to the financial markets, spanning genres such as financial news, earnings conference calls, and social media posts. Earnings conference calls are one of the most important to information flow as they reflect a direct communication between company executives, financial analysts, and large shareholders. Since these calls contain content that is forward-looking in nature, they can be used to forecast the future performance of the company relative to market expectations. However, they typically contain over 5,000 words of text and large amounts of industry jargon. This length and domain-specific language present problems for many generic pretrained language models. In this work, we introduce a novel task of predicting earnings surprises from earnings call transcripts and contribute a new long document dataset that tests financial understanding with complex signals. We explore a variety of approaches for this long document classification task and establish some strong baselines. Furthermore, we demonstrate that it is possible to predict companies’ future earnings surprises from solely the text of their conference calls with reasonable accuracy. Finally, we probe the models through different interpretability methods and reveal some intuitive explanations of the linguistic features captured that go beyond traditional sentiment analysis.</abstract>
      <url hash="eb65f4d7">2023.findings-acl.520</url>
      <bibkey>koval-etal-2023-forecasting</bibkey>
      <doi>10.18653/v1/2023.findings-acl.520</doi>
    </paper>
    <paper id="521">
      <title><fixed-case>MTC</fixed-case>ue: Learning Zero-Shot Control of Extra-Textual Attributes by Leveraging Unstructured Context in Neural Machine Translation</title>
      <author><first>Sebastian</first><last>Vincent</last><affiliation>University of Sheffield</affiliation></author>
      <author><first>Robert</first><last>Flynn</last><affiliation>University of Sheffield</affiliation></author>
      <author><first>Carolina</first><last>Scarton</last><affiliation>University of Sheffield</affiliation></author>
      <pages>8210-8226</pages>
      <abstract>Efficient utilisation of both intra- and extra-textual context remains one of the critical gaps between machine and human translation. Existing research has primarily focused on providing individual, well-defined types of context in translation, such as the surrounding text or discrete external variables like the speaker’s gender. This work introduces MTCue, a novel neural machine translation (NMT) framework that interprets all context (including discrete variables) as text. MTCue learns an abstract representation of context, enabling transferability across different data settings and leveraging similar attributes in low-resource scenarios. With a focus on a dialogue domain with access to document and metadata context, we extensively evaluate MTCue in four language pairs in both translation directions. Our framework demonstrates significant improvements in translation quality over a parameter-matched non-contextual baseline, as measured by BLEU (+0.88) and Comet (+1.58). Moreover, MTCue significantly outperforms a “tagging” baseline at translating English text. Analysis reveals that the context encoder of MTCue learns a representation space that organises context based on specific attributes, such as formality, enabling effective zero-shot control. Pre-training on context embeddings also improves MTCue’s few-shot performance compared to the “tagging” baseline. Finally, an ablation study conducted on model components and contextual variables further supports the robustness of MTCue for context-based NMT.</abstract>
      <url hash="9198bba3">2023.findings-acl.521</url>
      <bibkey>vincent-etal-2023-mtcue</bibkey>
      <doi>10.18653/v1/2023.findings-acl.521</doi>
    </paper>
    <paper id="522">
      <title>Evaluation for Change</title>
      <author><first>Rishi</first><last>Bommasani</last><affiliation>Stanford University</affiliation></author>
      <pages>8227-8239</pages>
      <abstract>Evaluation is the central means for assessing, understanding, and communicating about NLP models. In this position paper, we argue evaluation should be more than that: it is a force for driving change, carrying a sociological and political character beyond its technical dimensions. As a force, evaluation’s power arises from its adoption: under our view, evaluation succeeds when it achieves the desired change in the field. Further, by framing evaluation as a force, we consider how it competes with other forces. Under our analysis, we conjecture that the current trajectory of NLP suggests evaluation’s power is waning, in spite of its potential for realizing more pluralistic ambitions in the field. We conclude by discussing the legitimacy of this power, who acquires this power and how it distributes. Ultimately, we hope the research community will more aggressively harness evaluation to drive change.</abstract>
      <url hash="2b9760bd">2023.findings-acl.522</url>
      <bibkey>bommasani-2023-evaluation</bibkey>
      <doi>10.18653/v1/2023.findings-acl.522</doi>
    </paper>
    <paper id="523">
      <title>Reconstruction Probing</title>
      <author><first>Najoung</first><last>Kim</last><affiliation>Boston University</affiliation></author>
      <author><first>Jatin</first><last>Khilnani</last><affiliation>University of Pittsburgh</affiliation></author>
      <author><first>Alex</first><last>Warstadt</last><affiliation>ETH Zürich</affiliation></author>
      <author><first>Abdelrahim</first><last>Qaddoumi</last><affiliation>NYU</affiliation></author>
      <pages>8240-8255</pages>
      <abstract>We propose reconstruction probing, a new analysis method for contextualized representations based on reconstruction probabilities in masked language models (MLMs). This method relies on comparing the reconstruction probabilities of tokens in a given sequence when conditioned on the representation of a single token that has been fully contextualized and when conditioned on only the decontextualized lexical prior of the model. This comparison can be understood as quantifying the contribution of contextualization towards reconstruction—the difference in the reconstruction probabilities can only be attributed to the representational change of the single token induced by contextualization. We apply this analysis to three MLMs and find that contextualization boosts reconstructability of tokens that are close to the token being reconstructed in terms of linear and syntactic distance. Furthermore, we extend our analysis to finer-grained decomposition of contextualized representations, and we find that these boosts are largely attributable to static and positional embeddings at the input layer.</abstract>
      <url hash="90f94066">2023.findings-acl.523</url>
      <bibkey>kim-etal-2023-reconstruction</bibkey>
      <doi>10.18653/v1/2023.findings-acl.523</doi>
    </paper>
    <paper id="524">
      <title>Towards Distribution-shift Robust Text Classification of Emotional Content</title>
      <author><first>Luana</first><last>Bulla</last><affiliation>CNR</affiliation></author>
      <author><first>Aldo</first><last>Gangemi</last><affiliation>CNR</affiliation></author>
      <author><first>Misael</first><last>Mongiovi’</last><affiliation>CNR</affiliation></author>
      <pages>8256-8268</pages>
      <abstract>Supervised models based on Transformers have been shown to achieve impressive performances in many natural language processing tasks. However, besides requiring a large amount of costly manually annotated data, supervised models tend to adapt to the characteristics of the training dataset, which are usually created ad-hoc and whose data distribution often differs from the one in real applications, showing significant performance degradation in real-world scenarios. We perform an extensive assessment of the out-of-distribution performances of supervised models for classification in the emotion and hate-speech detection tasks and show that NLI-based zero-shot models often outperform them, making task-specific annotation useless when the characteristics of final-user data are not known in advance. To benefit from both supervised and zero-shot approaches, we propose to fine-tune an NLI-based model on the task-specific dataset. The resulting model often outperforms all available supervised models both in distribution and out of distribution, with only a few thousand training samples.</abstract>
      <url hash="683aed4f">2023.findings-acl.524</url>
      <bibkey>bulla-etal-2023-towards</bibkey>
      <doi>10.18653/v1/2023.findings-acl.524</doi>
    </paper>
    <paper id="525">
      <title>Multi-lingual and Multi-cultural Figurative Language Understanding</title>
      <author><first>Anubha</first><last>Kabra</last><affiliation>Carnegie Mellon University</affiliation></author>
      <author><first>Emmy</first><last>Liu</last><affiliation>Carnegie Mellon University</affiliation></author>
      <author><first>Simran</first><last>Khanuja</last><affiliation>Carnegie Mellon University</affiliation></author>
      <author><first>Alham Fikri</first><last>Aji</last><affiliation>MBZUAI</affiliation></author>
      <author><first>Genta</first><last>Winata</last><affiliation>Bloomberg</affiliation></author>
      <author><first>Samuel</first><last>Cahyawijaya</last><affiliation>HKUST</affiliation></author>
      <author><first>Anuoluwapo</first><last>Aremu</last><affiliation>Masakhane</affiliation></author>
      <author><first>Perez</first><last>Ogayo</last><affiliation>Carnegie Mellon University</affiliation></author>
      <author><first>Graham</first><last>Neubig</last><affiliation>Carnegie Mellon University</affiliation></author>
      <pages>8269-8284</pages>
      <abstract>Figurative language permeates human communication, but at the same time is relatively understudied in NLP. Datasets have been created in English to accelerate progress towards measuring and improving figurative language processing in language models (LMs). However, the use of figurative language is an expression of our cultural and societal experiences, making it difficult for these phrases to be universally applicable. In this work, we create a figurative language inference dataset, {pasted macro ‘DATASETNAME’}, for seven diverse languages associated with a variety of cultures: Hindi, Indonesian, Javanese, Kannada, Sundanese, Swahili and Yoruba. Our dataset reveals that each language relies on cultural and regional concepts for figurative expressions, with the highest overlap between languages originating from the same region. We assess multilingual LMs’ abilities to interpret figurative language in zero-shot and few-shot settings. All languages exhibit a significant deficiency compared to English, with variations in performance reflecting the availability of pre-training and fine-tuning data, emphasizing the need for LMs to be exposed to a broader range of linguistic and cultural variation during training. Data and code is released at <url>https://anonymous.4open.science/r/Multilingual-Fig-QA-7B03/</url></abstract>
      <url hash="2e4c865c">2023.findings-acl.525</url>
      <bibkey>kabra-etal-2023-multi</bibkey>
      <doi>10.18653/v1/2023.findings-acl.525</doi>
    </paper>
    <paper id="526">
      <title>Open-<fixed-case>W</fixed-case>iki<fixed-case>T</fixed-case>able : Dataset for Open Domain Question Answering with Complex Reasoning over Table</title>
      <author><first>Sunjun</first><last>Kweon</last><affiliation>KAIST</affiliation></author>
      <author><first>Yeonsu</first><last>Kwon</last><affiliation>KAIST</affiliation></author>
      <author><first>Seonhee</first><last>Cho</last><affiliation>KAIST</affiliation></author>
      <author><first>Yohan</first><last>Jo</last><affiliation>Amazon.com, Inc.</affiliation></author>
      <author><first>Edward</first><last>Choi</last><affiliation>KAIST</affiliation></author>
      <pages>8285-8297</pages>
      <abstract>Despite recent interest in open domain question answering (ODQA) over tables, many studies still rely on datasets that are not truly optimal for the task with respect to utilizing structural nature of table. These datasets assume answers reside as a single cell value and do not necessitate exploring over multiple cells such as aggregation, comparison, and sorting. Thus, we release Open-WikiTable, the first ODQA dataset that requires complex reasoning over tables. Open-WikiTable is built upon WikiSQL and WikiTableQuestions to be applicable in the open-domain setting. As each question is coupled with both textual answers and SQL queries, Open-WikiTable opens up a wide range of possibilities for future research, as both reader and parser methods can be applied. The dataset is publicly available.</abstract>
      <url hash="d007a86c">2023.findings-acl.526</url>
      <bibkey>kweon-etal-2023-open</bibkey>
      <doi>10.18653/v1/2023.findings-acl.526</doi>
    </paper>
    <paper id="527">
      <title>What In-Context Learning “Learns” In-Context: Disentangling Task Recognition and Task Learning</title>
      <author><first>Jane</first><last>Pan</last><affiliation>Princeton University</affiliation></author>
      <author><first>Tianyu</first><last>Gao</last><affiliation>Princeton University</affiliation></author>
      <author><first>Howard</first><last>Chen</last><affiliation>Princeton University</affiliation></author>
      <author><first>Danqi</first><last>Chen</last><affiliation>Princeton University</affiliation></author>
      <pages>8298-8319</pages>
      <abstract>Large language models (LLMs) exploit in-context learning (ICL) to solve tasks with only a few demonstrations, but its mechanisms are not yet well-understood. Some works suggest that LLMs only recall already learned concepts from pre-training, while others hint that ICL performs implicit learning over demonstrations. We characterize two ways through which ICL leverages demonstrations. Task recognition (TR) captures the extent to which LLMs can recognize a task through demonstrations – even without ground-truth labels – and apply their pre-trained priors, whereas task learning (TL) is the ability to capture new input-label mappings unseen in pre-training. Using a wide range of classification datasets and three LLM families (GPT-3, LLaMA and OPT), we design controlled experiments to disentangle the roles of TR and TL in ICL. We show that (1) models can achieve non-trivial performance with only TR, and TR does not further improve with larger models or more demonstrations; (2) LLMs acquire TL as the model scales, and TL’s performance consistently improves with more demonstrations in context. Our findings unravel two different forces behind ICL and we advocate for discriminating them in future ICL research due to their distinct nature.</abstract>
      <url hash="f1b2d5e6">2023.findings-acl.527</url>
      <bibkey>pan-etal-2023-context</bibkey>
      <doi>10.18653/v1/2023.findings-acl.527</doi>
    </paper>
    <paper id="528">
      <title>Cross-Lingual Retrieval Augmented Prompt for Low-Resource Languages</title>
      <author><first>Ercong</first><last>Nie</last><affiliation>Centre for Information and Language Processing, LMU Munich</affiliation></author>
      <author><first>Sheng</first><last>Liang</last><affiliation>Naver Labs Europe</affiliation></author>
      <author><first>Helmut</first><last>Schmid</last><affiliation>CIS, Ludwig-Maximilians-Universitaet</affiliation></author>
      <author><first>Hinrich</first><last>Schütze</last><affiliation>Center for Information and Language Processing, University of Munich</affiliation></author>
      <pages>8320-8340</pages>
      <abstract>Multilingual Pretrained Language Models (MPLMs) perform strongly in cross-lingual transfer. We propose Prompts Augmented by Retrieval Crosslingually (PARC) to improve zero-shot performance on low-resource languages (LRLs) by augmenting the context with prompts consisting of semantically similar sentences retrieved from a high-resource language (HRL). PARC improves zero-shot performance on three downstream tasks (sentiment classification, topic categorization, natural language inference) with multilingual parallel test sets across 10 LRLs covering 6 language families in unlabeled (+5.1%) and labeled settings (+16.3%). PARC also outperforms finetuning by 3.7%. We find a significant positive correlation between cross-lingual transfer performance on one side, and the similarity between high- and low-resource languages as well as the amount of low-resource pretraining data on the other side. A robustness analysis suggests that PARC has the potential to achieve even stronger performance with more powerful MPLMs.</abstract>
      <url hash="8d254cc8">2023.findings-acl.528</url>
      <bibkey>nie-etal-2023-cross</bibkey>
      <doi>10.18653/v1/2023.findings-acl.528</doi>
    </paper>
    <paper id="529">
      <title>Unsupervised Summarization Re-ranking</title>
      <author><first>Mathieu</first><last>Ravaut</last><affiliation>Nanyang Technological University</affiliation></author>
      <author><first>Shafiq</first><last>Joty</last><affiliation>Nanyang Technological University; Salesforce AI Research</affiliation></author>
      <author><first>Nancy</first><last>Chen</last><affiliation>Institute for Infocomm Research, A*STAR</affiliation></author>
      <pages>8341-8376</pages>
      <abstract>With the rise of task-specific pre-training objectives, abstractive summarization models like PEGASUS offer appealing zero-shot performance on downstream summarization tasks. However, the performance of such unsupervised models still lags significantly behind their supervised counterparts. Similarly to the supervised setup, we notice a very high variance in quality among summary candidates from these models while only one candidate is kept as the summary output. In this paper, we propose to re-rank summary candidates in an unsupervised manner, aiming to close the performance gap between unsupervised and supervised models. Our approach improves the unsupervised PEGASUS by up to 7.27% and ChatGPT by up to 6.86% relative mean ROUGE across four widely-adopted summarization benchmarks ; and achieves relative gains of 7.51% (up to 23.73% from XSum to WikiHow) averaged over 30 zero-shot transfer setups (finetuning on a dataset, evaluating on another).</abstract>
      <url hash="c5772c14">2023.findings-acl.529</url>
      <bibkey>ravaut-etal-2023-unsupervised</bibkey>
      <doi>10.18653/v1/2023.findings-acl.529</doi>
    </paper>
    <paper id="530">
      <title><fixed-case>GRACE</fixed-case>: Gradient-guided Controllable Retrieval for Augmenting Attribute-based Text Generation</title>
      <author><first>Zhihua</first><last>Wen</last><affiliation>National University of Defense Technology</affiliation></author>
      <author><first>Zhiliang</first><last>Tian</last><affiliation>National University of Defense Technology</affiliation></author>
      <author><first>Zhen</first><last>Huang</last><affiliation>National University of Defense Technology</affiliation></author>
      <author><first>Yuxin</first><last>Yang</last><affiliation>National University of Defense Technology</affiliation></author>
      <author><first>Zexin</first><last>Jian</last><affiliation>National University of Defense Technology</affiliation></author>
      <author><first>Changjian</first><last>Wang</last><affiliation>School of computer, National University of Defense Technology</affiliation></author>
      <author><first>Dongsheng</first><last>Li</last><affiliation>National University of Defense Technology</affiliation></author>
      <pages>8377-8398</pages>
      <abstract>Attribute-based generation methods are of growing significance in controlling the generation of large pre-trained language models (PLMs). Existing studies control the generation by (1) finetuning the model with attributes or (2) guiding the inference processing toward control signals while freezing the PLM. However, finetuning approaches infuse domain bias into generation, making it hard to generate out-of-domain texts. Besides, many methods guide the inference in its word-by-word generation, pushing the word probability to the target attributes, resulting in less fluent sentences. We argue that distilling controlling information from natural texts can produce fluent sentences while maintaining high controllability. In this paper, we propose <b>GRA</b>dient-guided <b>C</b>ontrollable r<b>E</b>trieval (GRACE), a retrieval-augmented generation framework to facilitate the generation of fluent sentences with high attribute relevance. GRACE memorizes the semantic and attribute information from unlabeled corpora and applies a controllable retrieval to obtain desired information. For the generation, we design techniques to eliminate the domain bias from the retrieval results and integrate it into the generation model. Additionally, we propose a gradient-guided generation scheme that iteratively steers generation toward higher attribute relevance. Experimental results and quantities of examples verify the effectiveness of our method.</abstract>
      <url hash="88fc9bc7">2023.findings-acl.530</url>
      <bibkey>wen-etal-2023-grace</bibkey>
      <doi>10.18653/v1/2023.findings-acl.530</doi>
    </paper>
    <paper id="531">
      <title>So many design choices: Improving and interpreting neural agent communication in signaling games</title>
      <author><first>Timothée</first><last>Bernard</last><affiliation>Université Paris Cité</affiliation></author>
      <author><first>Timothee</first><last>Mickus</last><affiliation>University of Helsinki</affiliation></author>
      <pages>8399-8413</pages>
      <abstract>Emergent language games are experimental protocols designed to model how communication may arise among a group of agents. In this paper, we focus on how to improve performances of neural agents playing a signaling game: a sender is exposed to an image and generates a sequence of symbols that is transmitted to a receiver, which uses it to distinguish between two images, one that is semantically related to the original image, and one that is not. We consider multiple design choices, such as pretraining the visual components of the agents, introducing regularization terms, how to sample training items from the dataset, and we study how these different choices impact the behavior and performances of the agents. To that end, we introduce a number of automated metrics to measure the properties of the emergent language. We find that some implementation choices are always beneficial, and that the information that is conveyed by the agents’ messages is shaped not only by the game, but also by the overall design of the agents as well as seemingly unrelated implementation choices.</abstract>
      <url hash="06c40203">2023.findings-acl.531</url>
      <bibkey>bernard-mickus-2023-many</bibkey>
      <doi>10.18653/v1/2023.findings-acl.531</doi>
    </paper>
    <paper id="532">
      <title>Constructing Word-Context-Coupled Space Aligned with Associative Knowledge Relations for Interpretable Language Modeling</title>
      <author><first>Fanyu</first><last>Wang</last><affiliation>College of Artificial Intellegence and Computer Science, Jiangnan University</affiliation></author>
      <author><first>Zhenping</first><last>Xie</last><affiliation>College of Artificial Intellegence and Computer Science, Jiangnan University</affiliation></author>
      <pages>8414-8427</pages>
      <abstract>As the foundation of current natural language processing methods, pre-trained language model has achieved excellent performance. However, the black-box structure of the deep neural network in pre-trained language models seriously limits the interpretability of the language modeling process. After revisiting the coupled requirement of deep neural representation and semantics logic of language modeling, a Word-Context-Coupled Space (W2CSpace) is proposed by introducing the alignment processing between uninterpretable neural representation and interpretable statistical logic. Moreover, a clustering process is also designed to connect the word- and context-level semantics. Specifically, an associative knowledge network (AKN), considered interpretable statistical logic, is introduced in the alignment process for word-level semantics. Furthermore, the context-relative distance is employed as the semantic feature for the downstream classifier, which is greatly different from the current uninterpretable semantic representations of pre-trained models. Our experiments for performance evaluation and interpretable analysis are executed on several types of datasets, including SIGHAN, Weibo, and ChnSenti. Wherein a novel evaluation strategy for the interpretability of machine learning models is first proposed. According to the experimental results, our language model can achieve better performance and highly credible interpretable ability compared to related state-of-the-art methods.</abstract>
      <url hash="124f4484">2023.findings-acl.532</url>
      <bibkey>wang-xie-2023-constructing</bibkey>
      <doi>10.18653/v1/2023.findings-acl.532</doi>
    </paper>
    <paper id="533">
      <title>Fixed Input Parameterization for Efficient Prompting</title>
      <author><first>Eunbi</first><last>Choi</last><affiliation>KAIST</affiliation></author>
      <author><first>Yongrae</first><last>Jo</last><affiliation>KAIST</affiliation></author>
      <author><first>Joel</first><last>Jang</last><affiliation>KAIST</affiliation></author>
      <author><first>Joonwon</first><last>Jang</last><affiliation>Pohang University of Science and Technology</affiliation></author>
      <author><first>Minjoon</first><last>Seo</last><affiliation>KAIST</affiliation></author>
      <pages>8428-8441</pages>
      <abstract>Recent works have shown that attaching prompts to the input is effective at conditioning Language Models (LM) to perform specific tasks. However, prompts are always included in the input text during inference, even when they are fixed, thus incurring substantial computational and memory overhead. Also, there is currently no straightforward method of utilizing prompts that are longer than the maximum input length of the LMs without incurring additional costs during inference. We formally define Fixed Input Parameterization (FIP) problem that focuses on injecting the fixed prompt into the parameters of an LM to be an efficient alternative to attaching fixed prompts to the input. We show that in scenarios with long fixed prompts, FIP can be up to 280 times more efficient in terms of total FLOPs than previous approaches. We further explore methodologies for FIP and show promising results in persona-dependent conversation, semantic parsing, and zero-shot learning with task instructions. Through these explorations, we show that FIP can be a promising direction for conditioning language models, in scenarios with long and fixed prompts.</abstract>
      <url hash="c4c15445">2023.findings-acl.533</url>
      <bibkey>choi-etal-2023-fixed</bibkey>
      <doi>10.18653/v1/2023.findings-acl.533</doi>
    </paper>
    <paper id="534">
      <title>Data Augmentation for Low-Resource Keyphrase Generation</title>
      <author><first>Krishna</first><last>Garg</last><affiliation>University of Illinois at Chicago</affiliation></author>
      <author><first>Jishnu</first><last>Ray Chowdhury</last><affiliation>University of Illinois, at Chicago</affiliation></author>
      <author><first>Cornelia</first><last>Caragea</last><affiliation>University of Illinois at Chicago</affiliation></author>
      <pages>8442-8455</pages>
      <abstract>Keyphrase generation is the task of summarizing the contents of any given article into a few salient phrases (or keyphrases). Existing works for the task mostly rely on large-scale annotated datasets, which are not easy to acquire. Very few works address the problem of keyphrase generation in low-resource settings, but they still rely on a lot of additional unlabeled data for pretraining and on automatic methods for pseudo-annotations. In this paper, we present data augmentation strategies specifically to address keyphrase generation in purely resource-constrained domains. We design techniques that use the full text of the articles to improve both present and absent keyphrase generation. We test our approach comprehensively on three datasets and show that the data augmentation strategies consistently improve the state-of-the-art performance. We release our source code at <url>https://github.com/kgarg8/kpgen-lowres-data-aug</url>.</abstract>
      <url hash="fd277d6e">2023.findings-acl.534</url>
      <bibkey>garg-etal-2023-data</bibkey>
      <doi>10.18653/v1/2023.findings-acl.534</doi>
    </paper>
    <paper id="535">
      <title><fixed-case>B</fixed-case>ig<fixed-case>V</fixed-case>ideo: A Large-scale Video Subtitle Translation Dataset for Multimodal Machine Translation</title>
      <author><first>Liyan</first><last>Kang</last><affiliation>Xiamen University</affiliation></author>
      <author><first>Luyang</first><last>Huang</last><affiliation>Bytedance</affiliation></author>
      <author><first>Ningxin</first><last>Peng</last><affiliation>ByteDance</affiliation></author>
      <author><first>Peihao</first><last>Zhu</last><affiliation>ByteDance AI Lab</affiliation></author>
      <author><first>Zewei</first><last>Sun</last><affiliation>ByteDance</affiliation></author>
      <author><first>Shanbo</first><last>Cheng</last><affiliation>Bytedance AI Lab</affiliation></author>
      <author><first>Mingxuan</first><last>Wang</last><affiliation>Bytedance AI Lab</affiliation></author>
      <author><first>Degen</first><last>Huang</last><affiliation>Dalian University of Technology</affiliation></author>
      <author><first>Jinsong</first><last>Su</last><affiliation>Xiamen university</affiliation></author>
      <pages>8456-8473</pages>
      <abstract>We present a large-scale video subtitle translation dataset, *BigVideo*, to facilitate the study of multi-modality machine translation. Compared with the widely used *How2* and *VaTeX* datasets, *BigVideo* is more than 10 times larger, consisting of 4.5 million sentence pairs and 9,981 hours of videos. We also introduce two deliberately designed test sets to verify the necessity of visual information: *Ambiguous* with the presence of ambiguous words, and *Unambiguous* in which the text context is self-contained for translation. To better model the common semantics shared across texts and videos, we introduce a contrastive learning method in the cross-modal encoder. Extensive experiments on the *BigVideo* shows that: a) Visual information consistently improves the NMT model in terms of BLEU, BLEURT and COMET on both Ambiguous and Unambiguous test sets. b) Visual information helps disambiguation, compared to the strong text baseline on terminology-targeted scores and human evaluation.</abstract>
      <url hash="bc91e274">2023.findings-acl.535</url>
      <bibkey>kang-etal-2023-bigvideo</bibkey>
      <doi>10.18653/v1/2023.findings-acl.535</doi>
    </paper>
    <paper id="536">
      <title>Constructing Procedural Graphs with Multiple Dependency Relations: A New Dataset and Baseline</title>
      <author><first>Haopeng</first><last>Ren</last><affiliation>South China University of Technology</affiliation></author>
      <author><first>Yushi</first><last>Zeng</last><affiliation>South China University of Technology</affiliation></author>
      <author><first>Yi</first><last>Cai</last><affiliation>South China University of Technology</affiliation></author>
      <author><first>Bihan</first><last>Zhou</last><affiliation>South China University of Technology</affiliation></author>
      <author><first>Zetao</first><last>Lian</last><affiliation>South China University of Technology</affiliation></author>
      <pages>8474-8486</pages>
      <abstract>Current structured and semi-structured knowledge bases mainly focus on representing descriptive knowledge but ignore another commonsense knowledge (Procedural Knowledge). To structure the procedural knowledge, existing methods are proposed to automatically generate flow graphs from procedural documents. They focus on extracting sequential dependency between sentences but neglect another two important dependencies (i.e., inclusion dependency and constraint dependency) in procedural documents. In our paper, we explore a problem of automatically generating procedural graph with multiple dependency relations to extend the flow graph constructed by existing methods and propose a procedural graph construction method with syntactic information and discourse structures. A new dataset (WHPG) is built and extensive experiments are conducted to evaluate the effectiveness of our proposed model.</abstract>
      <url hash="93fe87d1">2023.findings-acl.536</url>
      <bibkey>ren-etal-2023-constructing</bibkey>
      <doi>10.18653/v1/2023.findings-acl.536</doi>
    </paper>
    <paper id="537">
      <title>Multi-Dimensional Evaluation of Text Summarization with In-Context Learning</title>
      <author><first>Sameer</first><last>Jain</last><affiliation>Carnegie Mellon University</affiliation></author>
      <author><first>Vaishakh</first><last>Keshava</last><affiliation>Carnegie Mellon University</affiliation></author>
      <author><first>Swarnashree</first><last>Mysore Sathyendra</last><affiliation>Carnegie Mellon University</affiliation></author>
      <author><first>Patrick</first><last>Fernandes</last><affiliation>Carnegie Mellon University, Instituto de Telecomunicações</affiliation></author>
      <author><first>Pengfei</first><last>Liu</last><affiliation>Carnegie Mellon University</affiliation></author>
      <author><first>Graham</first><last>Neubig</last><affiliation>Carnegie Mellon University</affiliation></author>
      <author><first>Chunting</first><last>Zhou</last><affiliation>Meta AI</affiliation></author>
      <pages>8487-8495</pages>
      <abstract>Evaluation of natural language generation (NLG) is complex and multi-dimensional. Generated text can be evaluated for fluency, coherence, factuality, or any other dimensions of interest. Most frameworks that perform such multi-dimensional evaluation require training on large manually or synthetically generated datasets. In this paper, we study the efficacy of large language models as multi-dimensional evaluators using in-context learning, obviating the need for large training datasets. Our experiments show that in-context learning-based evaluators are competitive with learned evaluation frameworks for the task of text summarization, establishing state-of-the-art on dimensions such as relevance and factual consistency. We then analyze the effects of factors such as the selection and number of in-context examples on performance. Finally, we study the efficacy of in-context learning-based evaluators in evaluating zero-shot summaries written by large language models such as GPT-3.</abstract>
      <url hash="c42db0eb">2023.findings-acl.537</url>
      <bibkey>jain-etal-2023-multi</bibkey>
      <doi>10.18653/v1/2023.findings-acl.537</doi>
    </paper>
    <paper id="538">
      <title>Learning to Rank Utterances for Query-Focused Meeting Summarization</title>
      <author><first>Xingxian</first><last>Liu</last><affiliation>Beijing University of Posts and Telecommunications</affiliation></author>
      <author><first>Yajing</first><last>Xu</last><affiliation>Beijing University of Posts &amp; Telecommunications</affiliation></author>
      <pages>8496-8505</pages>
      <abstract>Query-focused meeting summarization(QFMS) aims to generate a specific summary for the given query according to the meeting transcripts. Due to the conflict between long meetings and limited input size, previous works mainly adopt extract-then-summarize methods, which use extractors to simulate binary labels or ROUGE scores to extract utterances related to the query and then generate a summary. However, the previous approach fails to fully use the comparison between utterances. To the extractor, comparison orders are more important than specific scores. In this paper, we propose a Ranker-Generator framework. It learns to rank the utterances by comparing them in pairs and learning from the global orders, then uses top utterances as the generator’s input. We show that learning to rank utterances helps to select utterances related to the query effectively, and the summarizer can benefit from it. Experimental results on QMSum show that the proposed model outperforms all existing multi-stage models with fewer parameters.</abstract>
      <url hash="5a832e32">2023.findings-acl.538</url>
      <bibkey>liu-xu-2023-learning</bibkey>
      <doi>10.18653/v1/2023.findings-acl.538</doi>
    </paper>
    <paper id="539">
      <title>Neural Architecture Search for Parameter-Efficient Fine-tuning of Large Pre-trained Language Models</title>
      <author><first>Neal</first><last>Lawton</last><affiliation>University of Southern California</affiliation></author>
      <author><first>Anoop</first><last>Kumar</last><affiliation>Amazon</affiliation></author>
      <author><first>Govind</first><last>Thattai</last><affiliation>Amazon</affiliation></author>
      <author><first>Aram</first><last>Galstyan</last><affiliation>USC Information Sciences Institute</affiliation></author>
      <author><first>Greg</first><last>Ver Steeg</last><affiliation>University of California Riverside</affiliation></author>
      <pages>8506-8515</pages>
      <abstract>Parameter-efficient tuning (PET) methods fit pre-trained language models (PLMs) to downstream tasks by either computing a small compressed update for a subset of model parameters, or appending and fine-tuning a small number of new model parameters to the pre-trained network. Hand-designed PET architectures from the literature perform well in practice, but have the potential to be improved via automated neural architecture search (NAS). We propose an efficient NAS method for learning PET architectures via structured and unstructured pruning. We present experiments on GLUE demonstrating the effectiveness of our algorithm and discuss how PET architectural design choices affect performance in practice.</abstract>
      <url hash="a1483029">2023.findings-acl.539</url>
      <bibkey>lawton-etal-2023-neural</bibkey>
      <doi>10.18653/v1/2023.findings-acl.539</doi>
    </paper>
    <paper id="540">
      <title>Aligning Offline Metrics and Human Judgments of Value for Code Generation Models</title>
      <author><first>Victor</first><last>Dibia</last><affiliation>Microsoft Research</affiliation></author>
      <author><first>Adam</first><last>Fourney</last><affiliation>Microsoft Research</affiliation></author>
      <author><first>Gagan</first><last>Bansal</last><affiliation>UW CSE</affiliation></author>
      <author><first>Forough</first><last>Poursabzi-Sangdeh</last><affiliation>Microsoft</affiliation></author>
      <author><first>Han</first><last>Liu</last><affiliation>University of Chicago</affiliation></author>
      <author><first>Saleema</first><last>Amershi</last><affiliation>Microsoft Research</affiliation></author>
      <pages>8516-8528</pages>
      <abstract>Large language models have demonstrated great potential to assist programmers in generating code. For such human-AI pair programming scenarios, we empirically demonstrate that while generated code are most often evaluated in terms of their functional correctness (i.e., whether generations pass available unit tests), correctness does not fully capture (e.g., may underestimate) the productivity gains these models may provide. Through a user study with N=49 experienced programmers, we show that while correctness captures high-value generations, programmers still rate code that fails unit tests as valuable if it reduces the overall effort needed to complete a coding task. Finally, we propose a hybrid metric that combines functional correctness and syntactic similarity and show that it achieves a 14% stronger correlation with value and can therefore better represent real-world gains when evaluating and comparing models.</abstract>
      <url hash="e330c793">2023.findings-acl.540</url>
      <bibkey>dibia-etal-2023-aligning</bibkey>
      <doi>10.18653/v1/2023.findings-acl.540</doi>
    </paper>
    <paper id="541">
      <title>Do transformer models do phonology like a linguist?</title>
      <author><first>Saliha</first><last>Muradoglu</last><affiliation>The Australian National University</affiliation></author>
      <author><first>Mans</first><last>Hulden</last><affiliation>University of Colorado</affiliation></author>
      <pages>8529-8537</pages>
      <abstract>Neural sequence-to-sequence models have been very successful at tasks in phonology and morphology that seemingly require a capacity for intricate linguistic generalisations. In this paper, we perform a detailed breakdown of the power of such models to capture various phonological generalisations and to benefit from exposure to one phonological rule to infer the behaviour of another similar rule. We present two types of experiments, one of which establishes the efficacy of the transformer model on 29 different processes. The second experiment type follows a priming and held-out case split where our model is exposed to two (or more) phenomena; one which is used as a primer to make the model aware of a linguistic category (e.g. voiceless stops) and a second one which contains a rule with a withheld case that the model is expected to infer (e.g. word-final devoicing with a missing training example such as b→p) results show that the transformer model can successfully model all 29 phonological phenomena considered, regardless of perceived process difficulty. We also show that the model can generalise linguistic categories and structures, such as vowels and syllables, through priming processes.</abstract>
      <url hash="1d4b446d">2023.findings-acl.541</url>
      <bibkey>muradoglu-hulden-2023-transformer</bibkey>
      <doi>10.18653/v1/2023.findings-acl.541</doi>
    </paper>
    <paper id="542">
      <title><fixed-case>D</fixed-case>i<fixed-case>MS</fixed-case>: Distilling Multiple Steps of Iterative Non-Autoregressive Transformers for Machine Translation</title>
      <author><first>Sajad</first><last>Norouzi</last><affiliation>Layer6 AI</affiliation></author>
      <author><first>Rasa</first><last>Hosseinzadeh</last><affiliation>Layer6 AI</affiliation></author>
      <author><first>Felipe</first><last>Perez</last><affiliation>Signal 1</affiliation></author>
      <author><first>Maksims</first><last>Volkovs</last><affiliation>Layer6 AI</affiliation></author>
      <pages>8538-8553</pages>
      <abstract>The computational benefits of iterative non-autoregressive transformers decrease as the number of decoding steps increases. As a remedy, we introduce Distill Multiple Steps (DiMS), a simple yet effective distillation technique to decrease the number of required steps to reach a certain translation quality. The distilled model enjoys the computational benefits of early iterations while preserving the enhancements from several iterative steps. DiMS relies on two models namely student and teacher. The student is optimized to predict the output of the teacher after multiple decoding steps while the teacher follows the student via a slow-moving average. The moving average keeps the teacher’s knowledge updated and enhances the quality of the labels provided by the teacher. During inference, the student is used for translation and no additional computation is added. We verify the effectiveness of DiMS on various models obtaining 7.8 and 12.9 BLEU points improvements in single-step translation accuracy on distilled and raw versions of WMT’14 De-En.Full code for this work is available here: <url>https://github.com/layer6ai-labs/DiMS</url></abstract>
      <url hash="91d7695d">2023.findings-acl.542</url>
      <bibkey>norouzi-etal-2023-dims</bibkey>
      <doi>10.18653/v1/2023.findings-acl.542</doi>
    </paper>
    <paper id="543">
      <title>Retrieval-augmented Video Encoding for Instructional Captioning</title>
      <author><first>Yeonjoon</first><last>Jung</last><affiliation>Yonsei University</affiliation></author>
      <author><first>Minsoo</first><last>Kim</last><affiliation>Seoul National University</affiliation></author>
      <author><first>Seungtaek</first><last>Choi</last><affiliation>Riiid</affiliation></author>
      <author><first>Jihyuk</first><last>Kim</last><affiliation>Yonsei University</affiliation></author>
      <author><first>Minji</first><last>Seo</last><affiliation>Seoul National University</affiliation></author>
      <author><first>Seung-won</first><last>Hwang</last><affiliation>Seoul National University</affiliation></author>
      <pages>8554-8568</pages>
      <abstract>Instructional videos make learning knowledge more efficient, by providing a detailed multimodal context of each procedure in instruction.A unique challenge posed by instructional videos is key-object degeneracy, where any single modality fails to sufficiently capture the key objects referred to in the procedure. For machine systems, such degeneracy can disturb the performance of a downstream task such as dense video captioning, leading to the generation of incorrect captions omitting key objects. To repair degeneracy, we propose a retrieval-based framework to augment the model representations in the presence of such key-object degeneracy. We validate the effectiveness and generalizability of our proposed framework over baselines using modalities with key-object degeneracy.</abstract>
      <url hash="a8df22c7">2023.findings-acl.543</url>
      <bibkey>jung-etal-2023-retrieval</bibkey>
      <doi>10.18653/v1/2023.findings-acl.543</doi>
    </paper>
    <paper id="544">
      <title>Bi-level Finetuning with Task-dependent Similarity Structure for Low-resource Training</title>
      <author><first>Sai Ashish</first><last>Somayajula</last><affiliation>University of California, San Diego</affiliation></author>
      <author><first>Lifeng</first><last>Jin</last><affiliation>Tencent AI Lab</affiliation></author>
      <author><first>Linfeng</first><last>Song</last><affiliation>Tencent AI Lab</affiliation></author>
      <author><first>Haitao</first><last>Mi</last><affiliation>Tencent America</affiliation></author>
      <author><first>Dong</first><last>Yu</last><affiliation>Tencent AI Lab</affiliation></author>
      <pages>8569-8588</pages>
      <abstract>Training a large language model in low-resource settings is challenging since they are susceptible to overfitting with limited generalization abilities. Previous work addresses this issue by approaches such as tunable parameters reduction or data augmentation. However, they either limit the trained models’ expressiveness or rely on task-independent knowledge. In this paper, we propose the Bi-level Finetuning with Task-dependent Similarity Structure framework where all parameters, including the embeddings for unseen tokens, are finetuned with task-dependent information from the training data only. In this framework, a task-dependent similarity structure is learned in a data-driven fashion, which in turn is used to compose soft embeddings from conventional embeddings to be used in training to update all parameters. In order to learn the similarity structure and model parameters, we propose a bi-level optimization algorithm with two stages—search and finetune—to ensure successful learning. Results of experiments on several classification datasets in low-resource scenarios demonstrate that models trained with our method outperform strong baselines. Ablation experiments further support the effectiveness of different components in our framework. Code is available at <url>https://github.com/Sai-Ashish/BFTSS</url>.</abstract>
      <url hash="d1480a33">2023.findings-acl.544</url>
      <bibkey>somayajula-etal-2023-bi</bibkey>
      <doi>10.18653/v1/2023.findings-acl.544</doi>
    </paper>
    <paper id="545">
      <title>Kanbun-<fixed-case>LM</fixed-case>: Reading and Translating Classical <fixed-case>C</fixed-case>hinese in <fixed-case>J</fixed-case>apanese Methods by Language Models</title>
      <author><first>Hao</first><last>Wang</last><affiliation>Waseda University</affiliation></author>
      <author><first>Hirofumi</first><last>Shimizu</last><affiliation>Waseda University</affiliation></author>
      <author><first>Daisuke</first><last>Kawahara</last><affiliation>Waseda University</affiliation></author>
      <pages>8589-8601</pages>
      <abstract>Recent studies in natural language processing (NLP) have focused on modern languages and achieved state-of-the-art results in many tasks. Meanwhile, little attention has been paid to ancient texts and related tasks. Classical Chinese first came to Japan approximately 2,000 years ago. It was gradually adapted to a Japanese form called Kanbun-Kundoku (Kanbun) in Japanese reading and translating methods, which has significantly impacted Japanese literature. However, compared to the rich resources of ancient texts in mainland China, Kanbun resources remain scarce in Japan.To solve this problem, we construct the first Classical-Chinese-to-Kanbun dataset in the world. Furthermore, we introduce two tasks, character reordering and machine translation, both of which play a significant role in Kanbun comprehension. We also test the current language models on these tasks and discuss the best evaluation method by comparing the results with human scores. We release our code and dataset on GitHub.</abstract>
      <url hash="24ae7c9b">2023.findings-acl.545</url>
      <bibkey>wang-etal-2023-kanbun</bibkey>
      <doi>10.18653/v1/2023.findings-acl.545</doi>
    </paper>
    <paper id="546">
      <title>Adaptive Attention for Sparse-based Long-sequence Transformer</title>
      <author><first>Xuanyu</first><last>Zhang</last><affiliation>Du Xiaoman Financial</affiliation></author>
      <author><first>Zhepeng</first><last>Lv</last><affiliation>DXM</affiliation></author>
      <author><first>Qing</first><last>Yang</last><affiliation>DXM</affiliation></author>
      <pages>8602-8610</pages>
      <abstract>Recently, Transformers have been widely used in various fields and have achieved remarkable results. But it is still difficult for Transformer-based models to process longer sequences because self-attention in them scales quadratically with the sequence length. Although some models attempt to use sparse attention to reduce computational complexity, hand-crafted attention patterns are unable to select useful tokens adaptively according to the context. Thus, in this paper, we propose a novel efficient Transformer model with adaptive attention, A2-Former, for long sequence modeling. It can select useful tokens automatically in sparse attention by learnable position vectors, which consist of meta position and offset position vectors. Because the learnable offset position is not an integer vector, we utilize the interpolation technique to gather corresponding vectors from the input embedding matrix by discrete indexes. Experiments on Long Range Arena (LRA), a systematic and unified benchmark with different tasks, show that our model has achieved further improvement in performance compared with other sparse-based Transformers.</abstract>
      <url hash="b1c7e940">2023.findings-acl.546</url>
      <bibkey>zhang-etal-2023-adaptive</bibkey>
      <doi>10.18653/v1/2023.findings-acl.546</doi>
    </paper>
    <paper id="547">
      <title>Sentiment Analysis using the Relationship between Users and Products</title>
      <author><first>Natthawut</first><last>Kertkeidkachorn</last><affiliation>Japan Advanced Institute of Science and Technology</affiliation></author>
      <author><first>Kiyoaki</first><last>Shirai</last><affiliation>Japan Advanced Institute of Science and Technology</affiliation></author>
      <pages>8611-8618</pages>
      <abstract>In product reviews, user and product aspects are useful in sentiment analysis. Nevertheless, previous studies mainly focus on modeling user and product aspects without considering the relationship between users and products. The relationship between users and products is typically helpful in estimating the bias of a user toward a product. In this paper, we, therefore, introduce the Graph Neural Network-based model with the pre-trained Language Model (GNNLM), where the relationship between users and products is incorporated. We conducted experiments on three well-known benchmarks for sentiment classification with the user and product information. The experimental results show that the relationship between users and products improves the performance of sentiment analysis. Furthermore, GNNLM achieves state-of-the-art results on yelp-2013 and yelp-2014 datasets.</abstract>
      <url hash="fe52aeb1">2023.findings-acl.547</url>
      <bibkey>kertkeidkachorn-shirai-2023-sentiment</bibkey>
      <doi>10.18653/v1/2023.findings-acl.547</doi>
    </paper>
    <paper id="548">
      <title>Entropy-guided Vocabulary Augmentation of Multilingual Language Models for Low-resource Tasks</title>
      <author><first>Arijit</first><last>Nag</last><affiliation>IIT Kharagpur</affiliation></author>
      <author><first>Bidisha</first><last>Samanta</last><affiliation>IIT KGP</affiliation></author>
      <author><first>Animesh</first><last>Mukherjee</last><affiliation>IIT Kharagpur</affiliation></author>
      <author><first>Niloy</first><last>Ganguly</last><affiliation>IIT Kharagpur</affiliation></author>
      <author><first>Soumen</first><last>Chakrabarti</last><affiliation>IIT Bombay</affiliation></author>
      <pages>8619-8629</pages>
      <abstract>Multilingual language models (MLLMs) like mBERTpromise to extend the benefits of NLP research to low-resource languages (LRLs). However, LRL words are under-represented in the wordpiece/subword vocabularies of MLLMs. This leads to many LRL words getting replaced by UNK, or concatenated from morphologically unrelated wordpieces, leading to low task accuracy. (Pre)-training MLLMs after including LRL documents is resource-intensive in terms of both human inputs and computational resources. In response, we propose EVALM (entropy-based vocabulary augmented language model), which uses a new task-cognizant measurement to detect the most vulnerable LRL words, whose wordpiece segmentations are undesirable. EVALM then provides reasonable initializations of their embeddings, followed by limited fine-tuning using the small LRL task corpus. Our experiments show significant performance improvements and also some surprising limits to such vocabulary augmentation strategies in various classification tasks for multiple diverse LRLs, as well as code-mixed texts. We will release the code and data to enable further research.</abstract>
      <url hash="f03fd4f7">2023.findings-acl.548</url>
      <bibkey>nag-etal-2023-entropy</bibkey>
      <doi>10.18653/v1/2023.findings-acl.548</doi>
    </paper>
    <paper id="549">
      <title>Class-Adaptive Self-Training for Relation Extraction with Incompletely Annotated Training Data</title>
      <author><first>Qingyu</first><last>Tan</last><affiliation>National University of Singapore</affiliation></author>
      <author><first>Lu</first><last>Xu</last><affiliation>None</affiliation></author>
      <author><first>Lidong</first><last>Bing</last><affiliation>Alibaba DAMO Academy</affiliation></author>
      <author><first>Hwee Tou</first><last>Ng</last><affiliation>National University of Singapore</affiliation></author>
      <pages>8630-8643</pages>
      <abstract>Relation extraction (RE) aims to extract relations from sentences and documents. Existing relation extraction models typically rely on supervised machine learning. However, recent studies showed that many RE datasets are incompletely annotated. This is known as the false negative problem in which valid relations are falsely annotated as ‘no_relation’. Models trained with such data inevitably make similar mistakes during the inference stage. Self-training has been proven effective in alleviating the false negative problem. However, traditional self-training is vulnerable to confirmation bias and exhibits poor performance in minority classes. To overcome this limitation, we proposed a novel class-adaptive re-sampling self-training framework. Specifically, we re-sampled the pseudo-labels for each class by precision and recall scores. Our re-sampling strategy favored the pseudo-labels of classes with high precision and low recall, which improved the overall recall without significantly compromising precision. We conducted experiments on document-level and biomedical relation extraction datasets, and the results showed that our proposed self-training framework consistently outperforms existing competitive methods on the Re-DocRED and ChemDisgene datasets when the training data are incompletely annotated.</abstract>
      <url hash="171e7c38">2023.findings-acl.549</url>
      <bibkey>tan-etal-2023-class</bibkey>
      <doi>10.18653/v1/2023.findings-acl.549</doi>
    </paper>
    <paper id="550">
      <title>Solving Cosine Similarity Underestimation between High Frequency Words by <tex-math>\ell_2</tex-math> Norm Discounting</title>
      <author><first>Saeth</first><last>Wannasuphoprasit</last><affiliation>University of Liverpool</affiliation></author>
      <author><first>Yi</first><last>Zhou</last><affiliation>Cardiff University</affiliation></author>
      <author><first>Danushka</first><last>Bollegala</last><affiliation>University of Liverpool/Amazon</affiliation></author>
      <pages>8644-8652</pages>
      <abstract>Cosine similarity between two words, computed using their contextualised token embeddings obtained from masked language models (MLMs) such as BERT has shown to underestimate the actual similarity between those words CITATION.This similarity underestimation problem is particularly severe for high frequent words. Although this problem has been noted in prior work, no solution has been proposed thus far. We observe that the <tex-math>\ell_2</tex-math> norm of contextualised embeddings of a word correlates with its log-frequency in the pretraining corpus.Consequently, the larger <tex-math>\ell_2</tex-math> norms associated with the high frequent words reduce the cosine similarity values measured between them, thus underestimating the similarity scores.To solve this issue, we propose a method to <i>discount</i> the <tex-math>\ell_2</tex-math> norm of a contextualised word embedding by the frequency of that word in a corpus when measuring the cosine similarities between words.We show that the so called <i>stop</i> words behave differently from the rest of the words, which require special consideration during their discounting process.Experimental results on a contextualised word similarity dataset show that our proposed discounting method accurately solves the similarity underestimation problem.An anonymized version of the source code of our proposed method is submitted to the reviewing system.</abstract>
      <url hash="4f4b4a32">2023.findings-acl.550</url>
      <bibkey>wannasuphoprasit-etal-2023-solving</bibkey>
      <doi>10.18653/v1/2023.findings-acl.550</doi>
    </paper>
    <paper id="551">
      <title>Do Large Language Models Know What They Don’t Know?</title>
      <author><first>Zhangyue</first><last>Yin</last><affiliation>Fudan University</affiliation></author>
      <author><first>Qiushi</first><last>Sun</last><affiliation>National University of Singapore</affiliation></author>
      <author><first>Qipeng</first><last>Guo</last><affiliation>Amazon Shanghai AI Lab</affiliation></author>
      <author><first>Jiawen</first><last>Wu</last><affiliation>Fudan University</affiliation></author>
      <author><first>Xipeng</first><last>Qiu</last><affiliation>Fudan University</affiliation></author>
      <author><first>Xuanjing</first><last>Huang</last><affiliation>Fudan University</affiliation></author>
      <pages>8653-8665</pages>
      <abstract>Large language models (LLMs) have a wealth of knowledge that allows them to excel in various Natural Language Processing (NLP) tasks. Current research focuses on enhancing their performance within their existing knowledge. Despite their vast knowledge, LLMs are still limited by the amount of information they can accommodate and comprehend. Therefore, the ability to understand their own limitations on the unknows, referred to as self-knowledge, is of paramount importance. This study aims to evaluate LLMs’ self-knowledge by assessing their ability to identify unanswerable or unknowable questions. We introduce an automated methodology to detect uncertainty in the responses of these models, providing a novel measure of their self-knowledge. We further introduce a unique dataset, SelfAware, consisting of unanswerable questions from five diverse categories and their answerable counterparts. Our extensive analysis, involving 20 LLMs including GPT-3, InstructGPT, and LLaMA, discovering an intrinsic capacity for self-knowledge within these models. Moreover, we demonstrate that in-context learning and instruction tuning can further enhance this self-knowledge. Despite this promising insight, our findings also highlight a considerable gap between the capabilities of these models and human proficiency in recognizing the limits of their knowledge.</abstract>
      <url hash="12571066">2023.findings-acl.551</url>
      <bibkey>yin-etal-2023-large</bibkey>
      <doi>10.18653/v1/2023.findings-acl.551</doi>
    </paper>
    <paper id="552">
      <title><fixed-case>A</fixed-case>lt<fixed-case>CLIP</fixed-case>: Altering the Language Encoder in <fixed-case>CLIP</fixed-case> for Extended Language Capabilities</title>
      <author><first>Zhongzhi</first><last>Chen</last><affiliation>Beihang University</affiliation></author>
      <author><first>Guang</first><last>Liu</last><affiliation>Beijing Academy of Artificial Intelligence</affiliation></author>
      <author><first>Bo-Wen</first><last>Zhang</last><affiliation>Beijing Academy of Artificial Intelligence</affiliation></author>
      <author><first>Qinghong</first><last>Yang</last><affiliation>Beihang University</affiliation></author>
      <author><first>Ledell</first><last>Wu</last><affiliation>Beijing Academy of Artificial Intelligence</affiliation></author>
      <pages>8666-8682</pages>
      <abstract>CLIP (Contrastive Language–Image Pretraining) is an English multimodal representation model learned from a massive amount of English text-image pairs and has achieved great success in various downstream tasks, including image classification, text-to-image retrieval, and image generation. When extending CLIP to other languages, the major problem is the lack of good-quality text-image pairs. In this work, we present AltCLIP, a simple and low-resource method to build a strong multilingual multimodal representation model. Instead of training a model from scratch on multilingual text-image pairs, we take the original CLIP model trained on English text-image pairs and alter its text encoder with a pre-trained multilingual text encoder (XLM-R). We then align text and image representations by a two-stage training schema consisting of teacher learning and contrastive learning. Our method utilizes the existence of rich parallel text data and pre-trained multilingual language models. We present extensive experimental evaluations to demonstrate the effectiveness of our proposed method. Our model sets new state-of-the-art zero-shot performances on a wide range of tasks in multilingual multimodal benchmarks, including ImageNet-CN/IT/JA/KO serials, Flicker30k-CN, COCO-CN, Multi30k, and XTD. Further, our model outperforms the original CLIP model on zero-shot cross-modal retrieval, Image Classification in the Wild (ICinW) tasks, and CLIP Benchmark. We plan to open-source our code, pre-trained model weights, and evaluation toolkits of multilingual multimodal tasks, to facilitate research on multilingual multimodal representation learning.</abstract>
      <url hash="dc7e67cf">2023.findings-acl.552</url>
      <bibkey>chen-etal-2023-altclip</bibkey>
      <doi>10.18653/v1/2023.findings-acl.552</doi>
    </paper>
    <paper id="553">
      <title><fixed-case>RHGN</fixed-case>: Relation-gated Heterogeneous Graph Network for Entity Alignment in Knowledge Graphs</title>
      <author><first>Xukai</first><last>Liu</last><affiliation>University of Science and Technology of China</affiliation></author>
      <author><first>Kai</first><last>Zhang</last><affiliation>university of science and technology of china</affiliation></author>
      <author><first>Ye</first><last>Liu</last><affiliation>University of Science and Technology of China</affiliation></author>
      <author><first>Enhong</first><last>Chen</last><affiliation>University of Science and Technology of China</affiliation></author>
      <author><first>Zhenya</first><last>Huang</last><affiliation>University of Science and Technology of China</affiliation></author>
      <author><first>Linan</first><last>Yue</last><affiliation>University of Science and Technology of China</affiliation></author>
      <author><first>Jiaxian</first><last>Yan</last><affiliation>University of Science and Technology of China</affiliation></author>
      <pages>8683-8696</pages>
      <abstract>Entity Alignment, which aims to identify equivalent entities from various Knowledge Graphs (KGs), is a fundamental and crucial task in knowledge graph fusion. Existing methods typically use triple or neighbor information to represent entities, and then align those entities using similarity matching. Most of them, however, fail to account for the heterogeneity among KGs and the distinction between KG entities and relations. To better solve these problems, we propose a Relation-gated Heterogeneous Graph Network (RHGN) for entity alignment. Specifically, RHGN contains a relation-gated convolutional layer to distinguish relations and entities in the KG. In addition, RHGN adopts a cross-graph embedding exchange module and a soft relation alignment module to address the neighbor heterogeneity and relation heterogeneity between different KGs, respectively. Extensive experiments on four benchmark datasets demonstrate that RHGN is superior to existing state-of-the-art entity alignment methods.</abstract>
      <url hash="76135af2">2023.findings-acl.553</url>
      <bibkey>liu-etal-2023-rhgn</bibkey>
      <doi>10.18653/v1/2023.findings-acl.553</doi>
    </paper>
    <paper id="554">
      <title>Feature Interactions Reveal Linguistic Structure in Language Models</title>
      <author><first>Jaap</first><last>Jumelet</last><affiliation>University of Amsterdam</affiliation></author>
      <author><first>Willem</first><last>Zuidema</last><affiliation>University of Amsterdam</affiliation></author>
      <pages>8697-8712</pages>
      <abstract>We study feature interactions in the context of feature attribution methods for post-hoc interpretability. In interpretability research, getting to grips with feature interactions is increasingly recognised as an important challenge, because interacting features are key to the success of neural networks. Feature interactions allow a model to build up hierarchical representations for its input, and might provide an ideal starting point for the investigation into linguistic structure in language models. However, uncovering the exact role that these interactions play is also difficult, and a diverse range of interaction attribution methods has been proposed. In this paper, we focus on the question which of these methods most faithfully reflects the inner workings of the target models. We work out a grey box methodology, in which we train models to perfection on a formal language classification task, using PCFGs. We show that under specific configurations, some methods are indeed able to uncover the grammatical rules acquired by a model. Based on these findings we extend our evaluation to a case study on language models, providing novel insights into the linguistic structure that these models have acquired.</abstract>
      <url hash="d3d3312f">2023.findings-acl.554</url>
      <bibkey>jumelet-zuidema-2023-feature</bibkey>
      <doi>10.18653/v1/2023.findings-acl.554</doi>
    </paper>
    <paper id="555">
      <title>Clustering-Aware Negative Sampling for Unsupervised Sentence Representation</title>
      <author><first>Jinghao</first><last>Deng</last><affiliation>School of Computer Science and Engineering, Sun Yat-sen University</affiliation></author>
      <author><first>Fanqi</first><last>Wan</last><affiliation>School of Computer Science and Engineering, Sun Yat-sen University</affiliation></author>
      <author><first>Tao</first><last>Yang</last><affiliation>School of Computer Science and Engineering, Sun Yat-Sen University</affiliation></author>
      <author><first>Xiaojun</first><last>Quan</last><affiliation>School of Computer Science and Engineering, Sun Yat-sen University</affiliation></author>
      <author><first>Rui</first><last>Wang</last><affiliation>Vipshop (China) Co., Ltd.</affiliation></author>
      <pages>8713-8729</pages>
      <abstract>Contrastive learning has been widely studied in sentence representation learning. However, earlier works mainly focus on the construction of positive examples, while in-batch samples are often simply treated as negative examples. This approach overlooks the importance of selecting appropriate negative examples, potentially leading to a scarcity of hard negatives and the inclusion of false negatives. To address these issues, we propose ClusterNS (Clustering-aware Negative Sampling), a novel method that incorporates cluster information into contrastive learning for unsupervised sentence representation learning. We apply a modified K-means clustering algorithm to supply hard negatives and recognize in-batch false negatives during training, aiming to solve the two issues in one unified framework. Experiments on semantic textual similarity (STS) tasks demonstrate that our proposed ClusterNS compares favorably with baselines in unsupervised sentence representation learning. Our code has been made publicly available at github.com/djz233/ClusterNS.</abstract>
      <url hash="1d447a56">2023.findings-acl.555</url>
      <bibkey>deng-etal-2023-clustering</bibkey>
      <doi>10.18653/v1/2023.findings-acl.555</doi>
    </paper>
    <paper id="556">
      <title>An Effective Deployment of Contrastive Learning in Multi-label Text Classification</title>
      <author><first>Nankai</first><last>Lin</last><affiliation>Guangdong University of Technology</affiliation></author>
      <author><first>Guanqiu</first><last>Qin</last><affiliation>Guangdong University of Technology</affiliation></author>
      <author><first>Gang</first><last>Wang</last><affiliation>Guangdong University of Technology</affiliation></author>
      <author><first>Dong</first><last>Zhou</last><affiliation>Guangdong University of Foreign Studies</affiliation></author>
      <author><first>Aimin</first><last>Yang</last><affiliation>Guangdong University of Technology</affiliation></author>
      <pages>8730-8744</pages>
      <abstract>The effectiveness of contrastive learning technology in natural language processing tasks is yet to be explored and analyzed. How to construct positive and negative samples correctly and reasonably is the core challenge of contrastive learning. It is even harder to discover contrastive objects in multi-label text classification tasks. There are very few contrastive losses proposed previously. In this paper, we investigate the problem from a different angle by proposing five novel contrastive losses for multi-label text classification tasks. These are Strict Contrastive Loss (SCL), Intra-label Contrastive Loss (ICL), Jaccard Similarity Contrastive Loss (JSCL), Jaccard Similarity Probability Contrastive Loss (JSPCL), and Stepwise Label Contrastive Loss (SLCL). We explore the effectiveness of contrastive learning for multi-label text classification tasks by the employment of these novel losses and provide a set of baseline models for deploying contrastive learning techniques on specific tasks. We further perform an interpretable analysis of our approach to show how different components of contrastive learning losses play their roles. The experimental results show that our proposed contrastive losses can bring improvement to multi-label text classification tasks. Our work also explores how contrastive learning should be adapted for multi-label text classification tasks.</abstract>
      <url hash="89401d8a">2023.findings-acl.556</url>
      <bibkey>lin-etal-2023-effective</bibkey>
      <doi>10.18653/v1/2023.findings-acl.556</doi>
    </paper>
    <paper id="557">
      <title>Segment-Level and Category-Oriented Network for Knowledge-Based Referring Expression Comprehension</title>
      <author><first>Yuqi</first><last>Bu</last><affiliation>South China University of Technology</affiliation></author>
      <author><first>Xin</first><last>Wu</last><affiliation>School of Software Engineering, South China University of Technology, Guangzhou, China</affiliation></author>
      <author><first>Liuwu</first><last>Li</last><affiliation>South China University of Technology</affiliation></author>
      <author><first>Yi</first><last>Cai</last><affiliation>South China University of Technology</affiliation></author>
      <author><first>Qiong</first><last>Liu</last><affiliation>South China University of Technology</affiliation></author>
      <author><first>Qingbao</first><last>Huang</last><affiliation>Guangxi University</affiliation></author>
      <pages>8745-8757</pages>
      <abstract>Knowledge-based referring expression comprehension (KB-REC) aims to identify visual objects referred to by expressions that incorporate knowledge. Existing methods employ sentence-level retrieval and fusion methods, which may lead to issues of similarity bias and interference from irrelevant information in unstructured knowledge sentences. To address these limitations, we propose a segment-level and category-oriented network (SLCO). Our approach includes a segment-level and prompt-based knowledge retrieval method to mitigate the similarity bias problem and a category-based grounding method to alleviate interference from irrelevant information in knowledge sentences. Experimental results show that our SLCO can eliminate interference and improve the overall performance of the KB-REC task.</abstract>
      <url hash="502a29c7">2023.findings-acl.557</url>
      <bibkey>bu-etal-2023-segment</bibkey>
      <doi>10.18653/v1/2023.findings-acl.557</doi>
    </paper>
    <paper id="558">
      <title><fixed-case>MVP</fixed-case>: Multi-task Supervised Pre-training for Natural Language Generation</title>
      <author><first>Tianyi</first><last>Tang</last><affiliation>Renmin University of China</affiliation></author>
      <author><first>Junyi</first><last>Li</last><affiliation>Gaoling School of Artificial Intelligence, Renmin University of China</affiliation></author>
      <author><first>Wayne Xin</first><last>Zhao</last><affiliation>RUC</affiliation></author>
      <author><first>Ji-Rong</first><last>Wen</last><affiliation>Renmin University of China</affiliation></author>
      <pages>8758-8794</pages>
      <abstract>Pre-trained language models (PLMs) have achieved remarkable success in natural language generation (NLG) tasks. Up to now, most NLG-oriented PLMs are pre-trained in an unsupervised manner using the large-scale general corpus. In the meanwhile, an increasing number of models pre-trained with labeled data (i.e. “supervised pre-training”) showcase superior performance compared to unsupervised pre-trained models. Motivated by the success of supervised pre-training, we propose Multi-task superVised Pre-training (MVP) for natural language generation. We collect a large-scale natural language generation corpus, MVPCorpus, from 77 datasets over 11 diverse NLG tasks. Then we unify these examples into a general text-to-text format to pre-train the text generation model MVP in a supervised manner. For each task, we further pre-train specific soft prompts to stimulate the model’s capacity to perform a specific task. Our MVP model can be seen as a practice that utilizes recent instruction tuning on relatively small PLMs. Extensive experiments have demonstrated the effectiveness and generality of our MVP model in a number of NLG tasks, which achieves state-of-the-art performance on 13 out of 17 datasets, outperforming BART by 9.3% and Flan-T5 by 5.8%.</abstract>
      <url hash="7a7fd21d">2023.findings-acl.558</url>
      <bibkey>tang-etal-2023-mvp</bibkey>
      <doi>10.18653/v1/2023.findings-acl.558</doi>
    </paper>
    <paper id="559">
      <title>From Alignment to Entailment: A Unified Textual Entailment Framework for Entity Alignment</title>
      <author><first>Yu</first><last>Zhao</last><affiliation>Nankai University</affiliation></author>
      <author><first>Yike</first><last>Wu</last><affiliation>Nankai University</affiliation></author>
      <author><first>Xiangrui</first><last>Cai</last><affiliation>Nankai University</affiliation></author>
      <author><first>Ying</first><last>Zhang</last><affiliation>Nankai University</affiliation></author>
      <author><first>Haiwei</first><last>Zhang</last><affiliation>Nankai University</affiliation></author>
      <author><first>Xiaojie</first><last>Yuan</last><affiliation>Nankai University</affiliation></author>
      <pages>8795-8806</pages>
      <abstract>Entity Alignment (EA) aims to find the equivalent entities between two Knowledge Graphs (KGs). Existing methods usually encode the triples of entities as embeddings and learn to align the embeddings, which prevents the direct interaction between the original information of the cross-KG entities. Moreover, they encode the relational triples and attribute triples of an entity in heterogeneous embedding spaces, which prevents them from helping each other. In this paper, we transform both triples into unified textual sequences, and model the EA task as a bi-directional textual entailment task between the sequences of cross-KG entities. Specifically, we feed the sequences of two entities simultaneously into a pre-trained language model (PLM) and propose two kinds of PLM-based entity aligners that model the entailment probability between sequences as the similarity between entities. Our approach captures the unified correlation pattern of two kinds of information between entities, and explicitly models the fine-grained interaction between original entity information. The experiments on five cross-lingual EA datasets show that our approach outperforms the state-of-the-art EA methods and enables the mutual enhancement of the heterogeneous information. Codes are available at <url>https://github.com/OreOZhao/TEA</url>.</abstract>
      <url hash="f3ea3ac9">2023.findings-acl.559</url>
      <bibkey>zhao-etal-2023-alignment</bibkey>
      <doi>10.18653/v1/2023.findings-acl.559</doi>
    </paper>
    <paper id="560">
      <title>It is a Bird Therefore it is a Robin: On <fixed-case>BERT</fixed-case>’s Internal Consistency Between Hypernym Knowledge and Logical Words</title>
      <author><first>Nicolas</first><last>Guerin</last><affiliation>Laboratoire de sciences cognitives et de psycholinguistique, Département d’études cognitives, ENS, EHESS, CNRS, PSL University</affiliation></author>
      <author><first>Emmanuel</first><last>Chemla</last><affiliation>CNRS</affiliation></author>
      <pages>8807-8817</pages>
      <abstract>The lexical knowledge of NLP systems shouldbe tested (i) for their internal consistency(avoiding groundedness issues) and (ii) bothfor content words and logical words. In thispaper we propose a new method to test the understandingof the hypernymy relationship bymeasuring its antisymmetry according to themodels. Previous studies often rely only on thedirect question (e.g., A robin is a ...), where weargue a correct answer could only rely on collocationalcues, rather than hierarchical cues. We show how to control for this, and how it isimportant. We develop a method to ask similarquestions about logical words that encode anentailment-like relation (e.g., because or therefore).Our results show important weaknessesof BERT-like models on these semantic tasks.</abstract>
      <url hash="54588a8f">2023.findings-acl.560</url>
      <bibkey>guerin-chemla-2023-bird</bibkey>
      <doi>10.18653/v1/2023.findings-acl.560</doi>
    </paper>
    <paper id="561">
      <title>Defending against Insertion-based Textual Backdoor Attacks via Attribution</title>
      <author><first>Jiazhao</first><last>Li</last><affiliation>University of Michigan</affiliation></author>
      <author><first>Zhuofeng</first><last>Wu</last><affiliation>University of Michigan</affiliation></author>
      <author><first>Wei</first><last>Ping</last><affiliation>Nvidia</affiliation></author>
      <author><first>Chaowei</first><last>Xiao</last><affiliation>Arizona State University</affiliation></author>
      <author><first>V.G.Vinod</first><last>Vydiswaran</last><affiliation>University of Michigan</affiliation></author>
      <pages>8818-8833</pages>
      <abstract>Textual backdoor attack, as a novel attack model, has been shown to be effective in adding a backdoor to the model during training. Defending against such backdoor attacks has become urgent and important. In this paper, we propose AttDef, an efficient attribution-based pipeline to defend against two insertion-based poisoning attacks, BadNL and InSent. Specifically, we regard the tokens with larger attribution scores as potential triggers since larger attribution words contribute more to the false prediction results and therefore are more likely to be poison triggers. Additionally, we further utilize an external pre-trained language model to distinguish whether input is poisoned or not. We show that our proposed method can generalize sufficiently well in two common attack scenarios (poisoning training data and testing data), which consistently improves previous methods. For instance, AttDef can successfully mitigate both attacks with an average accuracy of 79.97% (56.59% up) and 48.34% (3.99% up) under pre-training and post-training attack defense respectively, achieving the new state-of-the-art performance on prediction recovery over four benchmark datasets.</abstract>
      <url hash="fa64f6cd">2023.findings-acl.561</url>
      <bibkey>li-etal-2023-defending</bibkey>
      <doi>10.18653/v1/2023.findings-acl.561</doi>
    </paper>
    <paper id="562">
      <title><fixed-case>A</fixed-case>ctive<fixed-case>AED</fixed-case>: A Human in the Loop Improves Annotation Error Detection</title>
      <author><first>Leon</first><last>Weber</last><affiliation>LMU Munich</affiliation></author>
      <author><first>Barbara</first><last>Plank</last><affiliation>LMU Munich</affiliation></author>
      <pages>8834-8845</pages>
      <abstract>Manually annotated datasets are crucial for training and evaluating Natural Language Processing models. However, recent work has discovered that even widely-used benchmark datasets contain a substantial number of erroneous annotations. This problem has been addressed with Annotation Error Detection (AED) models, which can flag such errors for human re-annotation. However, even though many of these AED methods assume a final curation step in which a human annotator decides whether the annotation is erroneous, they have been developed as static models without any human-in-the-loop component. In this work, we propose ActiveAED, an AED method that can detect errors more accurately by repeatedly querying a human for error corrections in its prediction loop. We evaluate ActiveAED on eight datasets spanning five different tasks and find that it leads to improvements over the state of the art on seven of them, with gains of up to six percentage points in average precision.</abstract>
      <url hash="e575c46e">2023.findings-acl.562</url>
      <bibkey>weber-plank-2023-activeaed</bibkey>
      <doi>10.18653/v1/2023.findings-acl.562</doi>
    </paper>
    <paper id="563">
      <title>Assessing Word Importance Using Models Trained for Semantic Tasks</title>
      <author><first>Dávid</first><last>Javorský</last><affiliation>Charles Univerzity, Faculty of Mathematics and Physics</affiliation></author>
      <author><first>Ondřej</first><last>Bojar</last><affiliation>Charles University, MFF UFAL</affiliation></author>
      <author><first>François</first><last>Yvon</last><affiliation>ISIR CNRS &amp; Sorbonne Université</affiliation></author>
      <pages>8846-8856</pages>
      <abstract>Many NLP tasks require to automatically identify the most significant words in a text. In this work, we derive word significance from models trained to solve semantic task: Natural Language Inference and Paraphrase Identification. Using an attribution method aimed to explain the predictions of these models, we derive importance scores for each input token. We evaluate their relevance using a so-called cross-task evaluation: Analyzing the performance of one model on an input masked according to the other model’s weight, we show that our method is robust with respect to the choice of the initial task. Additionally, we investigate the scores from the syntax point of view and observe interesting patterns, e.g. words closer to the root of a syntactic tree receive higher importance scores. Altogether, these observations suggest that our method can be used to identify important words in sentences without any explicit word importance labeling in training.</abstract>
      <url hash="1682d59f">2023.findings-acl.563</url>
      <bibkey>javorsky-etal-2023-assessing</bibkey>
      <doi>10.18653/v1/2023.findings-acl.563</doi>
    </paper>
    <paper id="564">
      <title>In-context Examples Selection for Machine Translation</title>
      <author><first>Sweta</first><last>Agrawal</last><affiliation>University of Maryland</affiliation></author>
      <author><first>Chunting</first><last>Zhou</last><affiliation>Meta AI</affiliation></author>
      <author><first>Mike</first><last>Lewis</last><affiliation>Facebook AI Research</affiliation></author>
      <author><first>Luke</first><last>Zettlemoyer</last><affiliation>University of Washington; Meta</affiliation></author>
      <author><first>Marjan</first><last>Ghazvininejad</last><affiliation>FAIR</affiliation></author>
      <pages>8857-8873</pages>
      <abstract>Large-scale generative models show an impressive ability to perform a wide range of Natural Language Processing (NLP) tasks using in-context learning, where a few examples are used to describe a task to the model. For Machine Translation (MT), these examples are typically randomly sampled from the development dataset with a similar distribution as the evaluation set. However, it is unclear how the choice of these in context examples and their ordering impacts the output translation quality. In this work, we aim to understand the properties of good in-context examples for MT in both in-domain and out-of-domain settings. We show that the translation quality and the domain of the in-context examples matter and that 1-shot noisy unrelated examples can have a catastrophic impact on output quality. While concatenating multiple random examples reduces the effect of noise, a single good prompt optimized to maximize translation quality on the development dataset can elicit learned information from the pre-trained language model. Adding similar examples based on an n-gram overlap with the test source significantly and consistently improves the translation quality of the outputs, outperforming a strong kNN-MT baseline in 2 out of 4 out-of-domain datasets.</abstract>
      <url hash="ad75c290">2023.findings-acl.564</url>
      <bibkey>agrawal-etal-2023-context</bibkey>
      <doi>10.18653/v1/2023.findings-acl.564</doi>
    </paper>
    <paper id="565">
      <title><fixed-case>P</fixed-case>rop<fixed-case>S</fixed-case>egm<fixed-case>E</fixed-case>nt: A Large-Scale Corpus for Proposition-Level Segmentation and Entailment Recognition</title>
      <author><first>Sihao</first><last>Chen</last><affiliation>University of Pennsylvania</affiliation></author>
      <author><first>Senaka</first><last>Buthpitiya</last><affiliation>Google</affiliation></author>
      <author><first>Alex</first><last>Fabrikant</last><affiliation>Google Research</affiliation></author>
      <author><first>Dan</first><last>Roth</last><affiliation>University of Pennsylvania</affiliation></author>
      <author><first>Tal</first><last>Schuster</last><affiliation>Google</affiliation></author>
      <pages>8874-8893</pages>
      <abstract>The widely studied task of Natural Language Inference (NLI) requires a system to recognize whether one piece of text is textually entailed by another, i.e. whether the entirety of its meaning can be inferred from the other. In current NLI datasets and models, textual entailment relations are typically defined on the sentence- or paragraph-level. However, even a simple sentence often contains multiple propositions, i.e. distinct units of meaning conveyed by the sentence. As these propositions can carry different truth values in the context of a given premise, we argue for the need to recognize the textual entailment relation of each proposition in a sentence individually. We propose PropSegmEnt, a corpus of over 45K propositions annotated by expert human raters. Our dataset structure resembles the tasks of (1) segmenting sentences within a document to the set of propositions, and (2) classifying the entailment relation of each proposition with respect to a different yet topically-aligned document, i.e. documents describing the same event or entity. We establish strong baselines for the segmentation and entailment tasks. Through case studies on summary hallucination detection and document-level NLI, we demonstrate that our conceptual framework is potentially useful for understanding and explaining the compositionality of NLI labels.</abstract>
      <url hash="a3046d9c">2023.findings-acl.565</url>
      <bibkey>chen-etal-2023-propsegment</bibkey>
      <doi>10.18653/v1/2023.findings-acl.565</doi>
    </paper>
    <paper id="566">
      <title><fixed-case>CIF</fixed-case>-<fixed-case>PT</fixed-case>: Bridging Speech and Text Representations for Spoken Language Understanding via Continuous Integrate-and-Fire Pre-Training</title>
      <author><first>Linhao</first><last>Dong</last><affiliation>Bytedance</affiliation></author>
      <author><first>Zhecheng</first><last>An</last><affiliation>ByteDance Inc.</affiliation></author>
      <author><first>Peihao</first><last>Wu</last><affiliation>Bytedance</affiliation></author>
      <author><first>Jun</first><last>Zhang</last><affiliation>ByteDance</affiliation></author>
      <author><first>Lu</first><last>Lu</last><affiliation>Bytedance</affiliation></author>
      <author><first>Ma</first><last>Zejun</last><affiliation>ByteDance</affiliation></author>
      <pages>8894-8907</pages>
      <abstract>Speech or text representation generated by pre-trained models contains modal-specific information that could be combined for benefiting spoken language understanding (SLU) tasks. In this work, we propose a novel pre-training paradigm termed Continuous Integrate-and-Fire Pre-Training (CIF-PT). It relies on a simple but effective frame-to-token alignment: continuous integrate-and-fire (CIF) to bridge the representations between speech and text. It jointly performs speech-to-text training and language model distillation through CIF as the pre-training (PT). Evaluated on SLU benchmark SLURP dataset, CIF-PT outperforms the state-of-the-art model by 1.94% of accuracy and 2.71% of SLU-F1 on the tasks of intent classification and slot filling, respectively. We also observe the cross-modal representation extracted by CIF-PT obtains better performance than other neural interfaces for the tasks of SLU, including the dominant speech representation learned from self-supervised pre-training.</abstract>
      <url hash="ed69bc33">2023.findings-acl.566</url>
      <bibkey>dong-etal-2023-cif</bibkey>
      <doi>10.18653/v1/2023.findings-acl.566</doi>
    </paper>
    <paper id="567">
      <title>Improving Diachronic Word Sense Induction with a Nonparametric <fixed-case>B</fixed-case>ayesian method</title>
      <author><first>Ashjan</first><last>Alsulaimani</last><affiliation>Trinity College Dublin</affiliation></author>
      <author><first>Erwan</first><last>Moreau</last><affiliation>Trinity College Dublin</affiliation></author>
      <pages>8908-8925</pages>
      <abstract>Diachronic Word Sense Induction (DWSI) is the task of inducing the temporal representations of a word meaning from the context, as a set of senses and their prevalence over time. We introduce two new models for DWSI, based on topic modelling techniques: one is based on Hierarchical Dirichlet Processes (HDP), a nonparametric model; the other is based on the Dynamic Embedded Topic Model (DETM), a recent dynamic neural model. We evaluate these models against two state of the art DWSI models, using a time-stamped labelled dataset from the biomedical domain. We demonstrate that the two proposed models perform better than the state of the art. In particular, the HDP-based model drastically outperforms all the other models, including the dynamic neural model.</abstract>
      <url hash="fb2acb41">2023.findings-acl.567</url>
      <bibkey>alsulaimani-moreau-2023-improving</bibkey>
      <doi>10.18653/v1/2023.findings-acl.567</doi>
    </paper>
    <paper id="568">
      <title>What to Fuse and How to Fuse: Exploring Emotion and Personality Fusion Strategies for Explainable Mental Disorder Detection</title>
      <author><first>Sourabh</first><last>Zanwar</last><affiliation>RWTH Aachen University</affiliation></author>
      <author><first>Xiaofei</first><last>Li</last><affiliation>RWTH Aachen University</affiliation></author>
      <author><first>Daniel</first><last>Wiechmann</last><affiliation>Institute for Logic Language and Computation</affiliation></author>
      <author><first>Yu</first><last>Qiao</last><affiliation>RWTH-Achen</affiliation></author>
      <author><first>Elma</first><last>Kerz</last><affiliation>RWTH Aachen University</affiliation></author>
      <pages>8926-8940</pages>
      <abstract>Mental health disorders (MHD) are increasingly prevalent worldwide and constitute one of the greatest challenges facing our healthcare systems and modern societies in general. In response to this societal challenge, there has been a surge in digital mental health research geared towards the development of new techniques for unobtrusive and efficient automatic detection of MHD. Within this area of research, natural language processing techniques are playing an increasingly important role, showing promising detection results from a variety of textual data. Recently, there has been a growing interest in improving mental illness detection from textual data by way of leveraging emotions: ‘Emotion fusion’ refers to the process of integrating emotion information with general textual information to obtain enhanced information for decision-making. However, while the available research has shown that MHD prediction can be improved through a variety of different fusion strategies, previous works have been confined to a particular fusion strategy applied to a specific dataset, and so is limited by the lack of meaningful comparability. In this work, we integrate and extend this research by conducting extensive experiments with three types of deep learning-based fusion strategies: (i) feature-level fusion, where a pre-trained masked language model for mental health detection (MentalRoBERTa) was infused with a comprehensive set of engineered features, (ii) model fusion, where the MentalRoBERTa model was infused with hidden representations of other language models and (iii) task fusion, where a multi-task framework was leveraged to learn the features for auxiliary tasks. In addition to exploring the role of different fusion strategies, we expand on previous work by broadening the information infusion to include a second domain related to mental health, namely personality. We evaluate algorithm performance on data from two benchmark datasets, encompassing five mental health conditions: attention deficit hyperactivity disorder, anxiety, bipolar disorder, depression and psychological stress.</abstract>
      <url hash="fc907afe">2023.findings-acl.568</url>
      <bibkey>zanwar-etal-2023-fuse</bibkey>
      <doi>10.18653/v1/2023.findings-acl.568</doi>
    </paper>
    <paper id="569">
      <title>Adaptive Contrastive Knowledge Distillation for <fixed-case>BERT</fixed-case> Compression</title>
      <author><first>Jinyang</first><last>Guo</last><affiliation>Beihang University</affiliation></author>
      <author><first>Jiaheng</first><last>Liu</last><affiliation>Beihang University</affiliation></author>
      <author><first>Zining</first><last>Wang</last><affiliation>Beihang University</affiliation></author>
      <author><first>Yuqing</first><last>Ma</last><affiliation>Beihang University</affiliation></author>
      <author><first>Ruihao</first><last>Gong</last><affiliation>SenseTime</affiliation></author>
      <author><first>Ke</first><last>Xu</last><affiliation>Beihang University</affiliation></author>
      <author><first>Xianglong</first><last>Liu</last><affiliation>Beihang University</affiliation></author>
      <pages>8941-8953</pages>
      <abstract>In this paper, we propose a new knowledge distillation approach called adaptive contrastive knowledge distillation (ACKD) for BERT compression. Different from existing knowledge distillation methods for BERT that implicitly learn discriminative student features by mimicking the teacher features, we first introduce a novel contrastive distillation loss (CDL) based on hidden state features in BERT as the explicit supervision to learn discriminative student features. We further observe sentences with similar features may have completely different meanings, which makes them hard to distinguish. Existing methods do not pay sufficient attention to these hard samples with less discriminative features. Therefore, we propose a new strategy called sample adaptive reweighting (SAR) to adaptively pay more attention to these hard samples and strengthen their discrimination abilities. We incorporate our SAR strategy into our CDL and form the adaptive contrastive distillation loss, based on which we construct our ACKD framework. Comprehensive experiments on multiple natural language processing tasks demonstrate the effectiveness of our ACKD framework.</abstract>
      <url hash="d656c43b">2023.findings-acl.569</url>
      <bibkey>guo-etal-2023-adaptive</bibkey>
      <doi>10.18653/v1/2023.findings-acl.569</doi>
    </paper>
    <paper id="570">
      <title><fixed-case>F</fixed-case>ourier Transformer: Fast Long Range Modeling by Removing Sequence Redundancy with <fixed-case>FFT</fixed-case> Operator</title>
      <author><first>Ziwei</first><last>He</last><affiliation>Shanghai Jiao Tong University</affiliation></author>
      <author><first>Meng</first><last>Yang</last><affiliation>Netease BizEase</affiliation></author>
      <author><first>Minwei</first><last>Feng</last><affiliation>Netease BizEase</affiliation></author>
      <author><first>Jingcheng</first><last>Yin</last><affiliation>Netease</affiliation></author>
      <author><first>Xinbing</first><last>Wang</last><affiliation>Shanghai Jiaotong University, China</affiliation></author>
      <author><first>Jingwen</first><last>Leng</last><affiliation>Shanghai Jiao Tong University</affiliation></author>
      <author><first>Zhouhan</first><last>Lin</last><affiliation>Shanghai Jiao Tong University</affiliation></author>
      <pages>8954-8966</pages>
      <abstract>The transformer model is known to be computationally demanding, and prohibitively costly for long sequences, as the self-attention module uses a quadratic time and space complexity with respect to sequence length. Many researchers have focused on designing new forms of self-attention or introducing new parameters to overcome this limitation, however a large portion of them prohibits the model to inherit weights from large pretrained models. In this work, the transformer’s inefficiency has been taken care of from another perspective. We propose Fourier Transformer, a simple yet effective approach by progressively removing redundancies in hidden sequence using the ready-made Fast Fourier Transform (FFT) operator to perform Discrete Cosine Transformation (DCT). Fourier Transformer is able to significantly reduce computational costs while retain the ability to inherit from various large pretrained models. Experiments show that our model achieves state-of-the-art performances among all transformer-based models on the long-range modeling benchmark LRA with significant improvement in both speed and space. For generative seq-to-seq tasks including CNN/DailyMail and ELI5, by inheriting the BART weights our model outperforms the standard BART and other efficient models. Our code will be publicly available at <url>https://github.com/LUMIA-Group/FourierTransformer</url></abstract>
      <url hash="0b346ee5">2023.findings-acl.570</url>
      <bibkey>he-etal-2023-fourier</bibkey>
      <doi>10.18653/v1/2023.findings-acl.570</doi>
    </paper>
    <paper id="571">
      <title>Zero-Shot Classification by Logical Reasoning on Natural Language Explanations</title>
      <author><first>Chi</first><last>Han</last><affiliation>University of Illinois at Urbana-Champaign</affiliation></author>
      <author><first>Hengzhi</first><last>Pei</last><affiliation>University of Illinois Urbana Champaign</affiliation></author>
      <author><first>Xinya</first><last>Du</last><affiliation>University of Texas at Dallas</affiliation></author>
      <author><first>Heng</first><last>Ji</last><affiliation>University of Illinois at Urbana-Champaign and Amazon (Amazon Scholar)</affiliation></author>
      <pages>8967-8981</pages>
      <abstract>Humans can classify data of an unseen category by reasoning on its language explanations. This ability is owing to the compositional nature of language: we can combine previously seen attributes to describe the new category. For example, we might describe a sage thrasher as “it has a slim straight relatively short bill, yellow eyes and a long tail”, so that others can use their knowledge of attributes “slim straight relatively short bill”, “yellow eyes” and “long tail” to recognize a sage thrasher. Inspired by this observation, in this work we tackle zero-shot classification task by logically parsing and reasoning on natural language explanations. To this end, we propose the framework CLORE (Classification by LOgical Reasoning on Explanations). While previous methods usually regard textual information as implicit features, CLORE parses explanations into logical structures and then explicitly reasons along this structure on the input to produce a classification score. Experimental results on explanation-based zero-shot classification benchmarks demonstrate that CLORE is superior to baselines, which we show is mainly due to higher scores on tasks requiring more logical reasoning. We also demonstrate that our framework can be extended to zero-shot classification on visual modality. Alongside classification decisions, CLORE can provide the logical parsing and reasoning process as a clear form of rationale. Through empirical analysis we demonstrate that CLORE is also less affected by linguistic biases than baselines.</abstract>
      <url hash="d553940a">2023.findings-acl.571</url>
      <bibkey>han-etal-2023-zero</bibkey>
      <doi>10.18653/v1/2023.findings-acl.571</doi>
    </paper>
    <paper id="572">
      <title>Dual-Gated Fusion with Prefix-Tuning for Multi-Modal Relation Extraction</title>
      <author><first>Qian</first><last>Li</last><affiliation>School of Computer Science, Beihang University</affiliation></author>
      <author><first>Shu</first><last>Guo</last><affiliation>National Computer Network Emergency Response Technical Team &amp; Coordination Center of China</affiliation></author>
      <author><first>Cheng</first><last>Ji</last><affiliation>Beihang University</affiliation></author>
      <author><first>Xutan</first><last>Peng</last><affiliation>Huawei</affiliation></author>
      <author><first>Shiyao</first><last>Cui</last><affiliation>Institute of Information Engineering, Chinese Academy of Sciences, Beijing, China</affiliation></author>
      <author><first>Jianxin</first><last>Li</last><affiliation>Beihang University</affiliation></author>
      <author><first>Lihong</first><last>Wang</last><affiliation>CNCERT</affiliation></author>
      <pages>8982-8994</pages>
      <abstract>Multi-Modal Relation Extraction (MMRE) aims at identifying the relation between two entities in texts that contain visual clues. Rich visual content is valuable for the MMRE task, but existing works cannot well model finer associations among different modalities, failing to capture the truly helpful visual information and thus limiting relation extraction performance. In this paper, we propose a novel MMRE framework to better capture the deeper correlations of text, entity pair, and image/objects, so as to mine more helpful information for the task, termed as DGF-PT. We first propose a prompt-based autoregressive encoder, which builds the associations of intra-modal and inter-modal features related to the task, respectively by entity-oriented and object-oriented prefixes. To better integrate helpful visual information, we design a dual-gated fusion module to distinguish the importance of image/objects and further enrich text representations. In addition, a generative decoder is introduced with entity type restriction on relations, better filtering out candidates. Extensive experiments conducted on the benchmark dataset show that our approach achieves excellent performance compared to strong competitors, even in the few-shot situation.</abstract>
      <url hash="6d75e4e0">2023.findings-acl.572</url>
      <bibkey>li-etal-2023-dual-gated</bibkey>
      <doi>10.18653/v1/2023.findings-acl.572</doi>
    </paper>
    <paper id="573">
      <title>Pruning Pre-trained Language Models with Principled Importance and Self-regularization</title>
      <author><first>Siyu</first><last>Ren</last><affiliation>Shanghai Jiao Tong University</affiliation></author>
      <author><first>Kenny</first><last>Zhu</last><affiliation>Shanghai Jiao Tong University</affiliation></author>
      <pages>8995-9008</pages>
      <abstract>Iterative pruning is one of the most effective compression methods for pre-trained language models. We discovered that finding the optimal pruning decision is an equality-constrained 0-1 Integer Linear Programming problem. The solution to this optimization problem leads to a principled importance criterion which we use to rank parameters during iterative model pruning. To mitigate the poor generalization at high sparsity levels, we propose a self-regularization scheme where model prediction is regularized by the latest checkpoint with increasing sparsity throughout pruning. Our experiments on natural language understanding, question answering, named entity recognition, and data-to-text generation with various Transformer-based PLMs show the effectiveness of the approach at various sparsity levels.</abstract>
      <url hash="23a5c802">2023.findings-acl.573</url>
      <bibkey>ren-zhu-2023-pruning</bibkey>
      <doi>10.18653/v1/2023.findings-acl.573</doi>
    </paper>
    <paper id="574">
      <title>The Magic of <fixed-case>IF</fixed-case>: Investigating Causal Reasoning Abilities in Large Language Models of Code</title>
      <author><first>Xiao</first><last>Liu</last><affiliation>Peking University</affiliation></author>
      <author><first>Da</first><last>Yin</last><affiliation>University of California, Los Angeles (UCLA)</affiliation></author>
      <author><first>Chen</first><last>Zhang</last><affiliation>Peking University</affiliation></author>
      <author><first>Yansong</first><last>Feng</last><affiliation>Peking University</affiliation></author>
      <author><first>Dongyan</first><last>Zhao</last><affiliation>pku.edu.cn</affiliation></author>
      <pages>9009-9022</pages>
      <abstract>Causal reasoning, the ability to identify cause-and-effect relationship, is crucial in human thinking. Although large language models (LLMs) succeed in many NLP tasks, it is still challenging for them to conduct complex causal reasoning like abductive reasoning and counterfactual reasoning. Given the fact that programming code may express causal relations more often and explicitly with conditional statements like “if“, we want to explore whether Code-LLMs acquire better causal reasoning abilities. Our experiments show that compared to text-only LLMs, Code-LLMs with code prompts are better causal reasoners. We further intervene on the prompts from different aspects, and discover that the key point is the programming structure. Code and data are available at <url>https://github.com/xxxiaol/magic-if</url>.</abstract>
      <url hash="5a189970">2023.findings-acl.574</url>
      <bibkey>liu-etal-2023-magic</bibkey>
      <doi>10.18653/v1/2023.findings-acl.574</doi>
    </paper>
    <paper id="575">
      <title>Learning to Leverage High-Order Medical Knowledge Graph for Joint Entity and Relation Extraction</title>
      <author><first>Zhe</first><last>Yang</last><affiliation>China Mobile Research Institute</affiliation></author>
      <author><first>Yi</first><last>Huang</last><affiliation>China Mobile Research Institute</affiliation></author>
      <author><first>Junlan</first><last>Feng</last><affiliation>China Mobile Research Institute</affiliation></author>
      <pages>9023-9035</pages>
      <abstract>Automatic medical entity and relation extraction is essential for daily electronic medical record (EMR) analysis, and has attracted a lot of academic attention. Tremendous progress has been made in recent years. However, medical terms are difficult to understand, and their relations are more complicated than general ones. Based on this situation, domain knowledge gives better background and contexts for medical terms. Despite the benefits of medical domain knowledge, the utilization way of it for joint entity and relation extraction is inadequate. To foster this line of research, in this work, we propose to leverage the medical knowledge graph for extracting entities and relations for Chinese Medical Texts in a collective way. Specifically, we propose to construct a high-order heterogeneous graph based on medical knowledge graph, which is linked to the entity mentions in the text. In this way, neighbors from the high-order heterogeneous graph can pass the message to each other for better global context representations. Our experiments on real Chinese Medical Texts show that our method is more effective than state-of-the-art methods.</abstract>
      <url hash="162df36d">2023.findings-acl.575</url>
      <bibkey>yang-etal-2023-learning-leverage</bibkey>
      <doi>10.18653/v1/2023.findings-acl.575</doi>
    </paper>
    <paper id="576">
      <title>Data-Efficient Finetuning Using Cross-Task Nearest Neighbors</title>
      <author><first>Hamish</first><last>Ivison</last><affiliation>Allen Institute for AI</affiliation></author>
      <author><first>Noah A.</first><last>Smith</last><affiliation>University of Washington</affiliation></author>
      <author><first>Hannaneh</first><last>Hajishirzi</last><affiliation>University of Washington</affiliation></author>
      <author><first>Pradeep</first><last>Dasigi</last><affiliation>Allen Institute for Artificial Intelligence</affiliation></author>
      <pages>9036-9061</pages>
      <abstract>Obtaining labeled data to train a model for a task of interest is often expensive. Prior work shows training models on multitask data augmented with task descriptions (prompts) effectively transfers knowledge to new tasks. Towards efficiently building task-specific models, we assume access to a small number (32-1000) of unlabeled target-task examples and use those to retrieve the most similar labeled examples from a large pool of multitask data augmented with prompts. Compared to the current practice of finetuning models on uniformly sampled prompted multitask data (e.g.: FLAN, T0), our approach of finetuning on cross-task nearest neighbors is significantly more data-efficient. Using only 2% of the data from the P3 pool without any labeled target-task data, our models outperform strong baselines trained on all available data by 3-30% on 12 out of 14 datasets representing held-out tasks including legal and scientific document QA. Similarly, models trained on cross-task nearest neighbors from SuperNaturalInstructions, representing about 5% of the pool, obtain comparable performance to state-of-the-art models on 12 held-out tasks from that pool. Moreover, the models produced by our approach also provide a better initialization than single multitask finetuned models for few-shot finetuning on target-task data, as shown by a 2-23% relative improvement over few-shot finetuned T0-3B models on 8 datasets.</abstract>
      <url hash="ac25f1f8">2023.findings-acl.576</url>
      <bibkey>ivison-etal-2023-data</bibkey>
      <doi>10.18653/v1/2023.findings-acl.576</doi>
    </paper>
    <paper id="577">
      <title><fixed-case>C</fixed-case>o<fixed-case>A</fixed-case>ug: Combining Augmentation of Labels and Labelling Rules</title>
      <author><first>Rakesh</first><last>R. Menon</last><affiliation>University of North Carolina Chapel Hill</affiliation></author>
      <author><first>Bingqing</first><last>Wang</last><affiliation>Bosch Research &amp; Technology Center North America</affiliation></author>
      <author><first>Jun</first><last>Araki</last><affiliation>Bosch Research</affiliation></author>
      <author><first>Zhengyu</first><last>Zhou</last><affiliation>Bosch Research and Technology Center North America</affiliation></author>
      <author><first>Zhe</first><last>Feng</last><affiliation>Bosch</affiliation></author>
      <author><first>Liu</first><last>Ren</last><affiliation>Bosch Research North America</affiliation></author>
      <pages>9062-9071</pages>
      <abstract>Collecting labeled data for Named Entity Recognition (NER) tasks is challenging due to the high cost of manual annotations. Instead, researchers have proposed few-shot self-training and rule-augmentation techniques to minimize the reliance on large datasets. However, inductive biases and restricted logical language lexicon, respectively, can limit the ability of these models to perform well. In this work, we propose CoAug, a co-augmentation framework that allows us to improve few-shot models and rule-augmentation models by bootstrapping predictions from each model. By leveraging rules and neural model predictions to train our models, we complement the benefits of each and achieve the best of both worlds. In our experiments, we show that our best CoAug model can outperform strong weak-supervision-based NER models at least by 6.5 F1 points.</abstract>
      <url hash="58255d0b">2023.findings-acl.577</url>
      <bibkey>r-menon-etal-2023-coaug</bibkey>
      <doi>10.18653/v1/2023.findings-acl.577</doi>
    </paper>
    <paper id="578">
      <title>Entity-to-Text based Data Augmentation for various Named Entity Recognition Tasks</title>
      <author><first>Xuming</first><last>Hu</last><affiliation>School of Software, Tsinghua University</affiliation></author>
      <author><first>Yong</first><last>Jiang</last><affiliation>Alibaba DAMO Academy</affiliation></author>
      <author><first>Aiwei</first><last>Liu</last><affiliation>School of Software, Tsinghua University</affiliation></author>
      <author><first>Zhongqiang</first><last>Huang</last><affiliation>Alibaba Group</affiliation></author>
      <author><first>Pengjun</first><last>Xie</last><affiliation>Alibaba Group</affiliation></author>
      <author><first>Fei</first><last>Huang</last><affiliation>Alibaba DAMO Academy</affiliation></author>
      <author><first>Lijie</first><last>Wen</last><affiliation>School of Software, Tsinghua University</affiliation></author>
      <author><first>Philip S.</first><last>Yu</last><affiliation>University of Illinois at Chicago</affiliation></author>
      <pages>9072-9087</pages>
      <abstract>Data augmentation techniques have been used to alleviate the problem of scarce labeled data in various NER tasks (flat, nested, and discontinuous NER tasks). Existing augmentation techniques either manipulate the words in the original text that break the semantic coherence of the text, or exploit generative models that ignore preserving entities in the original text, which impedes the use of augmentation techniques on nested and discontinuous NER tasks. In this work, we propose a novel Entity-to-Text based data augmentation technique named EnTDA to add, delete, replace or swap entities in the entity list of the original texts, and adopt these augmented entity lists to generate semantically coherent and entity preserving texts for various NER tasks. Furthermore, we introduce a diversity beam search to increase the diversity during the text generation process. Experiments on thirteen NER datasets across three tasks (flat, nested, and discontinuous NER tasks) and two settings (full data and low resource settings) show that EnTDA could bring more performance improvements compared to the baseline augmentation techniques.</abstract>
      <url hash="8a2ce591">2023.findings-acl.578</url>
      <bibkey>hu-etal-2023-entity</bibkey>
      <doi>10.18653/v1/2023.findings-acl.578</doi>
    </paper>
    <paper id="579">
      <title>World Models for Math Story Problems</title>
      <author><first>Andreas</first><last>Opedal</last><affiliation>ETH Zurich</affiliation></author>
      <author><first>Niklas</first><last>Stoehr</last><affiliation>ETH Zurich</affiliation></author>
      <author><first>Abulhair</first><last>Saparov</last><affiliation>New York University</affiliation></author>
      <author><first>Mrinmaya</first><last>Sachan</last><affiliation>ETH Zurich</affiliation></author>
      <pages>9088-9115</pages>
      <abstract>Solving math story problems is a complex task for students and NLP models alike, requiring them to understand the world as described in the story and reason over it to compute an answer. Recent years have seen impressive performance on automatically solving these problems with large pre-trained language models and innovative techniques to prompt them. However, it remains unclear if these models possess accurate representations of mathematical concepts. This leads to lack of interpretability and trustworthiness which impedes their usefulness in various applications. In this paper, we consolidate previous work on categorizing and representing math story problems and develop MathWorld, which is a graph-based semantic formalism specific for the domain of math story problems. With MathWorld, we can assign world models to math story problems which represent the situations and actions introduced in the text and their mathematical relationships. We combine math story problems from several existing datasets and annotate a corpus of 1,019 problems and 3,204 logical forms with MathWorld. Using this data, we demonstrate the following use cases of MathWorld: (1) prompting language models with synthetically generated question-answer pairs to probe their reasoning and world modeling abilities, and (2) generating new problems by using the world models as a design space.</abstract>
      <url hash="a36df4d3">2023.findings-acl.579</url>
      <bibkey>opedal-etal-2023-world</bibkey>
      <doi>10.18653/v1/2023.findings-acl.579</doi>
    </paper>
    <paper id="580">
      <title><fixed-case>A</fixed-case>uto<fixed-case>M</fixed-case>o<fixed-case>E</fixed-case>: Heterogeneous Mixture-of-Experts with Adaptive Computation for Efficient Neural Machine Translation</title>
      <author><first>Ganesh</first><last>Jawahar</last><affiliation>The University of British Columbia</affiliation></author>
      <author><first>Subhabrata</first><last>Mukherjee</last><affiliation>Microsoft Research</affiliation></author>
      <author><first>Xiaodong</first><last>Liu</last><affiliation>Microsoft Research</affiliation></author>
      <author><first>Young Jin</first><last>Kim</last><affiliation>Microsoft</affiliation></author>
      <author><first>Muhammad</first><last>Abdul-Mageed</last><affiliation>The University of British Columbia</affiliation></author>
      <author><first>Laks</first><last>Lakshmanan, V.S.</last><affiliation>UBC</affiliation></author>
      <author><first>Ahmed Hassan</first><last>Awadallah</last><affiliation>Microsoft Research</affiliation></author>
      <author><first>Sebastien</first><last>Bubeck</last><affiliation>Microsoft Research</affiliation></author>
      <author><first>Jianfeng</first><last>Gao</last><affiliation>Microsoft Research, Redmond</affiliation></author>
      <pages>9116-9132</pages>
      <abstract>Mixture-of-Expert (MoE) models have obtained state-of-the-art performance in Neural Machine Translation (NMT) tasks. Existing works in MoE mostly consider a homogeneous design where the same number of experts of the same size are placed uniformly throughout the network. Furthermore, existing MoE works do not consider computational constraints (e.g., FLOPs, latency) to guide their design. To this end, we develop AutoMoE – a framework for designing heterogeneous MoE’s under computational constraints. AutoMoE leverages Neural Architecture Search (NAS) to obtain efficient sparse MoE sub-transformers with 4x inference speedup (CPU) and FLOPs reduction over manually designed Transformers, with parity in BLEU score over dense Transformer and within 1 BLEU point of MoE SwitchTransformer, on aggregate over benchmark datasets for NMT.Heterogeneous search space with dense and sparsely activated Transformer modules (e.g., how many experts? where to place them? what should be their sizes?) allows for adaptive compute – where different amounts of computations are used for different tokens in the input. Adaptivity comes naturally from routing decisions which send tokens to experts of different sizes. AutoMoE code, data, and trained models are available at <url>https://aka.ms/AutoMoE</url>.</abstract>
      <url hash="7c86ad9c">2023.findings-acl.580</url>
      <bibkey>jawahar-etal-2023-automoe</bibkey>
      <doi>10.18653/v1/2023.findings-acl.580</doi>
    </paper>
    <paper id="581">
      <title>Language Agnostic Multilingual Information Retrieval with Contrastive Learning</title>
      <author><first>Xiyang</first><last>Hu</last><affiliation>Carnegie Mellon University</affiliation></author>
      <author><first>Xinchi</first><last>Chen</last><affiliation>Amazon AWS</affiliation></author>
      <author><first>Peng</first><last>Qi</last><affiliation>AWS AI Labs</affiliation></author>
      <author><first>Deguang</first><last>Kong</last><affiliation>Amazon</affiliation></author>
      <author><first>Kunlun</first><last>Liu</last><affiliation>amazon</affiliation></author>
      <author><first>William Yang</first><last>Wang</last><affiliation>Amazon AWS AI Labs</affiliation></author>
      <author><first>Zhiheng</first><last>Huang</last><affiliation>Amazon AI</affiliation></author>
      <pages>9133-9146</pages>
      <abstract>Multilingual information retrieval (IR) is challenging since annotated training data is costly to obtain in many languages. We present an effective method to train multilingual IR systems when only English IR training data and some parallel corpora between English and other languages are available. We leverage parallel and non-parallel corpora to improve the pretrained multilingual language models’ cross-lingual transfer ability. We design a semantic contrastive loss to align representations of parallel sentences that share the same semantics in different languages, and a new language contrastive loss to leverage parallel sentence pairs to remove language-specific information in sentence representations from non-parallel corpora. When trained on English IR data with these losses and evaluated zero-shot on non-English data, our model demonstrates significant improvement to prior work on retrieval performance, while it requires much less computational effort. We also demonstrate the value of our model for a practical setting when a parallel corpus is only available for a few languages, but a lack of parallel corpora resources persists for many other low-resource languages. Our model can work well even with a small number of parallel sentences, and be used as an add-on module to any backbones and other tasks.</abstract>
      <url hash="3364faa4">2023.findings-acl.581</url>
      <bibkey>hu-etal-2023-language</bibkey>
      <doi>10.18653/v1/2023.findings-acl.581</doi>
    </paper>
    <paper id="582">
      <title>Easy to Decide, Hard to Agree: Reducing Disagreements Between Saliency Methods</title>
      <author><first>Josip</first><last>Jukić</last><affiliation>University of Zagreb, Faculty of Electrical Engineering and Computing</affiliation></author>
      <author><first>Martin</first><last>Tutek</last><affiliation>Technische Universität Darmstadt</affiliation></author>
      <author><first>Jan</first><last>Snajder</last><affiliation>University of Zagreb, Faculty of Electrical Engineering and Computing, Unska 3, 10000 Zagreb</affiliation></author>
      <pages>9147-9162</pages>
      <abstract>A popular approach to unveiling the black box of neural NLP models is to leverage saliency methods, which assign scalar importance scores to each input component. A common practice for evaluating whether an interpretability method is faithful has been to use evaluation-by-agreement – if multiple methods agree on an explanation, its credibility increases. However, recent work has found that saliency methods exhibit weak rank correlations even when applied to the same model instance and advocated for alternative diagnostic methods. In our work, we demonstrate that rank correlation is not a good fit for evaluating agreement and argue that Pearson-r is a better-suited alternative. We further show that regularization techniques that increase faithfulness of attention explanations also increase agreement between saliency methods. By connecting our findings to instance categories based on training dynamics, we show that the agreement of saliency method explanations is very low for easy-to-learn instances. Finally, we connect the improvement in agreement across instance categories to local representation space statistics of instances, paving the way for work on analyzing which intrinsic model properties improve their predisposition to interpretability methods.</abstract>
      <url hash="14c826e8">2023.findings-acl.582</url>
      <bibkey>jukic-etal-2023-easy</bibkey>
      <doi>10.18653/v1/2023.findings-acl.582</doi>
    </paper>
    <paper id="583">
      <title>Enhancing Cross-lingual Transfer via Phonemic Transcription Integration</title>
      <author><first>Hoang</first><last>Nguyen</last><affiliation>University of Illinois at Chicago</affiliation></author>
      <author><first>Chenwei</first><last>Zhang</last><affiliation>Amazon</affiliation></author>
      <author><first>Tao</first><last>Zhang</last><affiliation>University of Illinois at Chicago</affiliation></author>
      <author><first>Eugene</first><last>Rohrbaugh</last><affiliation>Harrisburg University of Science and Technology</affiliation></author>
      <author><first>Philip</first><last>Yu</last><affiliation>Universtiy of Illinois at Chicago</affiliation></author>
      <pages>9163-9175</pages>
      <abstract>Previous cross-lingual transfer methods are restricted to orthographic representation learning via textual scripts. This limitation hampers cross-lingual transfer and is biased towards languages sharing similar well-known scripts. To alleviate the gap between languages from different writing scripts, we propose PhoneXL, a framework incorporating phonemic transcriptions as an additional linguistic modality beyond the traditional orthographic transcriptions for cross-lingual transfer. Particularly, we propose unsupervised alignment objectives to capture (1) local one-to-one alignment between the two different modalities, (2) alignment via multi-modality contexts to leverage information from additional modalities, and (3) alignment via multilingual contexts where additional bilingual dictionaries are incorporated. We also release the first phonemic-orthographic alignment dataset on two token-level tasks (Named Entity Recognition and Part-of-Speech Tagging) among the understudied but interconnected Chinese-Japanese-Korean-Vietnamese (CJKV) languages. Our pilot study reveals phonemic transcription provides essential information beyond the orthography to enhance cross-lingual transfer and bridge the gap among CJKV languages, leading to consistent improvements on cross-lingual token-level tasks over orthographic-based multilingual PLMs.</abstract>
      <url hash="808afdad">2023.findings-acl.583</url>
      <bibkey>nguyen-etal-2023-enhancing</bibkey>
      <doi>10.18653/v1/2023.findings-acl.583</doi>
    </paper>
    <paper id="584">
      <title>Human-in-the-loop Abstractive Dialogue Summarization</title>
      <author><first>Jiaao</first><last>Chen</last><affiliation>Georgia Institute of Technology</affiliation></author>
      <author><first>Mohan</first><last>Dodda</last><affiliation>Research Student</affiliation></author>
      <author><first>Diyi</first><last>Yang</last><affiliation>Stanford University</affiliation></author>
      <pages>9176-9190</pages>
      <abstract>Abstractive dialogue summarization has received increasing attention recently. Despite the fact that most of the current dialogue summarization systems are trained to maximize the likelihood of human-written summaries and have achieved significant results, there is still a huge gap in generating high-quality summaries as determined by humans, such as coherence and faithfulness, partly due to the misalignment in maximizing a single human-written summary. To this end, we propose to incorporate different levels of human feedback into the training process. This will enable us to guide the models to capture the behaviors humans care about for summaries. Specifically, we ask humans to highlight the salient information to be included in summaries to provide the local feedback, and to make overall comparisons among summaries in terms of coherence, accuracy, coverage, concise and overall quality, as the global feedback. We then combine both local and global feedback to fine-tune the dialog summarization policy with Reinforcement Learning. Experiments conducted on multiple datasets demonstrate the effectiveness and generalization of our methods over the state-of-the-art supervised baselines, especially in terms of human judgments.</abstract>
      <url hash="70ec5885">2023.findings-acl.584</url>
      <bibkey>chen-etal-2023-human</bibkey>
      <doi>10.18653/v1/2023.findings-acl.584</doi>
    </paper>
    <paper id="585">
      <title>A Multi-task Learning Framework for Quality Estimation</title>
      <author><first>Sourabh</first><last>Deoghare</last><affiliation>IIT Bombay</affiliation></author>
      <author><first>Paramveer</first><last>Choudhary</last><affiliation>IIT Bombay</affiliation></author>
      <author><first>Diptesh</first><last>Kanojia</last><affiliation>University of Surrey</affiliation></author>
      <author><first>Tharindu</first><last>Ranasinghe</last><affiliation>Aston University</affiliation></author>
      <author><first>Pushpak</first><last>Bhattacharyya</last><affiliation>Indian Institute of Technology Bombay and Patna</affiliation></author>
      <author><first>Constantin</first><last>Orăsan</last><affiliation>University of Surrey</affiliation></author>
      <pages>9191-9205</pages>
      <abstract>Quality Estimation (QE) is the task of evaluating machine translation output in the absence of reference translation. Conventional approaches to QE involve training separate models at different levels of granularity viz., word-level, sentence-level, and document-level, which sometimes lead to inconsistent predictions for the same input. To overcome this limitation, we focus on jointly training a single model for sentence-level and word-level QE tasks in a multi-task learning framework. Using two multi-task learning-based QE approaches, we show that multi-task learning improves the performance of both tasks. We evaluate these approaches by performing experiments in different settings, viz., single-pair, multi-pair, and zero-shot. We compare the multi-task learning-based approach with baseline QE models trained on single tasks and observe an improvement of up to 4.28% in Pearson’s correlation (r) at sentence-level and 8.46% in F1-score at word-level, in the single-pair setting. In the multi-pair setting, we observe improvements of up to 3.04% at sentence-level and 13.74% at word-level; while in the zero-shot setting, we also observe improvements of up to 5.26% and 3.05%, respectively. We make the models proposed in this paper publically available.</abstract>
      <url hash="c9bf020e">2023.findings-acl.585</url>
      <bibkey>deoghare-etal-2023-multi</bibkey>
      <doi>10.18653/v1/2023.findings-acl.585</doi>
    </paper>
    <paper id="586">
      <title>The Devil is in the Details: On the Pitfalls of Event Extraction Evaluation</title>
      <author><first>Hao</first><last>Peng</last><affiliation>Tsinghua University</affiliation></author>
      <author><first>Xiaozhi</first><last>Wang</last><affiliation>Tsinghua University</affiliation></author>
      <author><first>Feng</first><last>Yao</last><affiliation>Tsinghua University</affiliation></author>
      <author><first>Kaisheng</first><last>Zeng</last><affiliation>Tsinghua University</affiliation></author>
      <author><first>Lei</first><last>Hou</last><affiliation>Tsinghua University</affiliation></author>
      <author><first>Juanzi</first><last>Li</last><affiliation>Tsinghua University</affiliation></author>
      <author><first>Zhiyuan</first><last>Liu</last><affiliation>Tsinghua University</affiliation></author>
      <author><first>Weixing</first><last>Shen</last><affiliation>Tsinghua University</affiliation></author>
      <pages>9206-9227</pages>
      <abstract>Event extraction (EE) is a crucial task aiming at extracting events from texts, which includes two subtasks: event detection (ED) and event argument extraction (EAE). In this paper, we check the reliability of EE evaluations and identify three major pitfalls: (1) The data preprocessing discrepancy makes the evaluation results on the same dataset not directly comparable, but the data preprocessing details are not widely noted and specified in papers. (2) The output space discrepancy of different model paradigms makes different-paradigm EE models lack grounds for comparison and also leads to unclear mapping issues between predictions and annotations. (3) The absence of pipeline evaluation of many EAE-only works makes them hard to be directly compared with EE works and may not well reflect the model performance in real-world pipeline scenarios. We demonstrate the significant influence of these pitfalls through comprehensive meta-analyses of recent papers and empirical experiments. To avoid these pitfalls, we suggest a series of remedies, including specifying data preprocessing, standardizing outputs, and providing pipeline evaluation results. To help implement these remedies, we develop a consistent evaluation framework OmniEvent, which can be obtained from <url>https://github.com/THU-KEG/OmniEvent</url>.</abstract>
      <url hash="a4a95287">2023.findings-acl.586</url>
      <bibkey>peng-etal-2023-devil</bibkey>
      <doi>10.18653/v1/2023.findings-acl.586</doi>
    </paper>
    <paper id="587">
      <title>Yes, this Way! Learning to Ground Referring Expressions into Actions with Intra-episodic Feedback from Supportive Teachers</title>
      <author><first>Philipp</first><last>Sadler</last><affiliation>University of Potsdam</affiliation></author>
      <author><first>Sherzod</first><last>Hakimov</last><affiliation>University of Potsdam</affiliation></author>
      <author><first>David</first><last>Schlangen</last><affiliation>University of Potsdam</affiliation></author>
      <pages>9228-9239</pages>
      <abstract>The ability to pick up on language signals in an ongoing interaction is crucial for future machine learning models to collaborate and interact with humans naturally. In this paper, we present an initial study that evaluates intra-episodic feedback given in a collaborative setting. We use a referential language game as a controllable example of a task-oriented collaborative joint activity. A teacher utters a referring expression generated by a well-known symbolic algorithm (the “Incremental Algorithm”) as an initial instruction and then monitors the follower’s actions to possibly intervene with intra-episodic feedback (which does not explicitly have to be requested). We frame this task as a reinforcement learning problem with sparse rewards and learn a follower policy for a heuristic teacher. Our results show that intra-episodic feedback allows the follower to generalize on aspects of scene complexity and performs better than providing only the initial statement.</abstract>
      <url hash="8d88912d">2023.findings-acl.587</url>
      <bibkey>sadler-etal-2023-yes</bibkey>
      <doi>10.18653/v1/2023.findings-acl.587</doi>
    </paper>
    <paper id="588">
      <title>Investigating Transformer-Guided Chaining for Interpretable Natural Logic Reasoning</title>
      <author><first>Kanagasabai</first><last>Rajaraman</last><affiliation>Institute for Infocomm Research, A*STAR</affiliation></author>
      <author><first>Saravanan</first><last>Rajamanickam</last><affiliation>A*STAR</affiliation></author>
      <author><first>Wei</first><last>Shi</last><affiliation>Institute for Infocomm Research, A*STAR</affiliation></author>
      <pages>9240-9253</pages>
      <abstract>Natural logic reasoning has received increasing attention lately, with several datasets and neural models proposed, though with limited success. More recently, a new class of works have emerged adopting a Neuro-Symbolic approach, called transformer guided chaining, whereby the idea is to iteratively perform 1-step neural inferences and chain together the results to generate a multi-step reasoning trace. Several works have adapted variants of this central idea and reported significantly high accuracies compared to vanilla LLM’s. In this paper, we perform a critical empirical investigation of the chaining approach on a multi-hop First-Order Logic (FOL) reasoning benchmark. In particular, we develop a reference implementation, called Chainformer, and conduct several experiments to analyze the accuracy, generalization, interpretability, and performance over FOLs. Our findings highlight key strengths and possible current limitations and suggest potential areas for future research in logic reasoning.</abstract>
      <url hash="a21bf355">2023.findings-acl.588</url>
      <bibkey>rajaraman-etal-2023-investigating</bibkey>
      <doi>10.18653/v1/2023.findings-acl.588</doi>
    </paper>
    <paper id="589">
      <title>Multilingual Multi-Figurative Language Detection</title>
      <author><first>Huiyuan</first><last>Lai</last><affiliation>University of Groningen</affiliation></author>
      <author><first>Antonio</first><last>Toral</last><affiliation>University of Groningen</affiliation></author>
      <author><first>Malvina</first><last>Nissim</last><affiliation>University of Groningen</affiliation></author>
      <pages>9254-9267</pages>
      <abstract>Figures of speech help people express abstract concepts and evoke stronger emotions than literal expressions, thereby making texts more creative and engaging. Due to its pervasive and fundamental character, figurative language understanding has been addressed in Natural Language Processing, but it’s highly understudied in a multilingual setting and when considering more than one figure of speech at the same time. To bridge this gap, we introduce multilingual multi-figurative language modelling, and provide a benchmark for sentence-level figurative language detection, covering three common figures of speech and seven languages. Specifically, we develop a framework for figurative language detection based on template-based prompt learning. In so doing, we unify multiple detection tasks that are interrelated across multiple figures of speech and languages, without requiring task- or language-specific modules. Experimental results show that our framework outperforms several strong baselines and may serve as a blueprint for the joint modelling of other interrelated tasks.</abstract>
      <url hash="15525a10">2023.findings-acl.589</url>
      <bibkey>lai-etal-2023-multilingual</bibkey>
      <doi>10.18653/v1/2023.findings-acl.589</doi>
    </paper>
    <paper id="590">
      <title>Zero-shot Visual Question Answering with Language Model Feedback</title>
      <author><first>Yifan</first><last>Du</last><affiliation>Gaoling School of Artificial Intelligence, Renmin University of China</affiliation></author>
      <author><first>Junyi</first><last>Li</last><affiliation>Gaoling School of Artificial Intelligence, Renmin University of China</affiliation></author>
      <author><first>Tianyi</first><last>Tang</last><affiliation>Renmin University of China</affiliation></author>
      <author><first>Wayne Xin</first><last>Zhao</last><affiliation>RUC</affiliation></author>
      <author><first>Ji-Rong</first><last>Wen</last><affiliation>Renmin University of China</affiliation></author>
      <pages>9268-9281</pages>
      <abstract>In this paper, we propose a novel language model guided captioning approach, LAMOC, for knowledge-based visual question answering (VQA). Our approach employs the generated captions by a captioning model as the context of an answer prediction model, which is a Pre-Trained Language model (PLM). As the major contribution, we leverage the guidance and feedback of the prediction model to improve the capability of the captioning model. In this way, the captioning model can become aware of the task goal and information need from the PLM. To develop our approach, we design two specific training stages, where the first stage adapts the captioning model to the prediction model (selecting more suitable caption propositions for training) and the second stage tunes the captioning model according to the task goal (learning from feedback of the PLM). Extensive experiments demonstrate the effectiveness of the proposed approach on the knowledge-based VQA task. Specifically, on the challenging A-OKVQA dataset, LAMOC outperforms several competitive zero-shot methods and even achieves comparable results to a fine-tuned VLP model. Our code is publicly available at <url>https://github.com/RUCAIBox/LAMOC</url>.</abstract>
      <url hash="df140e86">2023.findings-acl.590</url>
      <bibkey>du-etal-2023-zero</bibkey>
      <doi>10.18653/v1/2023.findings-acl.590</doi>
    </paper>
    <paper id="591">
      <title>Prompted Opinion Summarization with <fixed-case>GPT</fixed-case>-3.5</title>
      <author><first>Adithya</first><last>Bhaskar</last><affiliation>Indian Institute of Technology Bombay</affiliation></author>
      <author><first>Alex</first><last>Fabbri</last><affiliation>Salesforce AI Research</affiliation></author>
      <author><first>Greg</first><last>Durrett</last><affiliation>UT Austin</affiliation></author>
      <pages>9282-9300</pages>
      <abstract>Large language models have shown impressive performance across a wide variety of tasks, including text summarization. In this paper, we show that this strong performance extends to opinion summarization. We explore several pipeline methods for applying GPT-3.5 to summarize a large collection of user reviews in aprompted fashion. To handle arbitrarily large numbers of user reviews, we explore recursive summarization as well as methods for selecting salient content to summarize through supervised clustering or extraction. On two datasets, an aspect-oriented summarization dataset of hotel reviews (SPACE) and a generic summarization dataset of Amazon and Yelp reviews (FewSum), we show that GPT-3.5 models achieve very strong performance in human evaluation. We argue that standard evaluation metrics do not reflect this, and introduce three new metrics targeting faithfulness, factuality, and genericity to contrast these different methods.</abstract>
      <url hash="b9e0bd3a">2023.findings-acl.591</url>
      <bibkey>bhaskar-etal-2023-prompted</bibkey>
      <doi>10.18653/v1/2023.findings-acl.591</doi>
    </paper>
    <paper id="592">
      <title>Sentence Ordering with a Coherence Verifier</title>
      <author><first>Sainan</first><last>Jia</last><affiliation>Capital Normal University</affiliation></author>
      <author><first>Wei</first><last>Song</last><affiliation>Capital Normal University</affiliation></author>
      <author><first>Jiefu</first><last>Gong</last><affiliation>IFLYTEK</affiliation></author>
      <author><first>Shijin</first><last>Wang</last><affiliation>iFLYTEK Research</affiliation></author>
      <author><first>Ting</first><last>Liu</last><affiliation>Harbin Institute of Technology</affiliation></author>
      <pages>9301-9314</pages>
      <abstract>This paper presents a novel sentence ordering method by plugging a coherence verifier (CoVer) into pair-wise ranking-based and sequence generation-based methods. It does not change the model parameters of the baseline, and only verifies the coherence of candidate (partial) orders produced by the baseline and reranks them in beam search. We also propose a coherence model as CoVer with a novel graph formulation and a novel data construction strategy for contrastive pre-training independently of the sentence ordering task. Experimental results on four benchmarks demonstrate the effectiveness of our method with topological sorting-based and pointer network-based methods as the baselines. Detailed analyses illustrate how CoVer improves the baselines and confirm the importance of its graph formulation and training strategy. Our code is available at <url>https://github.com/SN-Jia/SO_with_CoVer</url>.</abstract>
      <url hash="7bf44a4e">2023.findings-acl.592</url>
      <bibkey>jia-etal-2023-sentence</bibkey>
      <doi>10.18653/v1/2023.findings-acl.592</doi>
    </paper>
    <paper id="593">
      <title><fixed-case>GUMS</fixed-case>um: Multi-Genre Data and Evaluation for <fixed-case>E</fixed-case>nglish Abstractive Summarization</title>
      <author><first>Yang Janet</first><last>Liu</last><affiliation>Georgetown University</affiliation></author>
      <author><first>Amir</first><last>Zeldes</last><affiliation>Georgetown University</affiliation></author>
      <pages>9315-9327</pages>
      <abstract>Automatic summarization with pre-trained language models has led to impressively fluent results, but is prone to ‘hallucinations’, low performance on non-news genres, and outputs which are not exactly summaries. Targeting ACL 2023’s ‘Reality Check’ theme, we present GUMSum, a small but carefully crafted dataset of English summaries in 12 written and spoken genres for evaluation of abstractive summarization. Summaries are highly constrained, focusing on substitutive potential, factuality, and faithfulness. We present guidelines and evaluate human agreement as well as subjective judgments on recent system outputs, comparing general-domain untuned approaches, a fine-tuned one, and a prompt-based approach, to human performance. Results show that while GPT3 achieves impressive scores, it still underperforms humans, with varying quality across genres. Human judgments reveal different types of errors in supervised, prompted, and human-generated summaries, shedding light on the challenges of producing a good summary.</abstract>
      <url hash="9089c257">2023.findings-acl.593</url>
      <bibkey>liu-zeldes-2023-gumsum</bibkey>
      <doi>10.18653/v1/2023.findings-acl.593</doi>
    </paper>
    <paper id="594">
      <title>Improving Grammatical Error Correction with Multimodal Feature Integration</title>
      <author><first>Tao</first><last>Fang</last><affiliation>University of Macau</affiliation></author>
      <author><first>Jinpeng</first><last>Hu</last><affiliation>CUHKSZ</affiliation></author>
      <author><first>Derek F.</first><last>Wong</last><affiliation>University of Macau</affiliation></author>
      <author><first>Xiang</first><last>Wan</last><affiliation>Shenzhen Research Institute of Big Data</affiliation></author>
      <author><first>Lidia S.</first><last>Chao</last><affiliation>University of Macau</affiliation></author>
      <author><first>Tsung-Hui</first><last>Chang</last><affiliation>The Chinese University of Hong Kong, Shenzhen</affiliation></author>
      <pages>9328-9344</pages>
      <abstract>Grammatical error correction (GEC) is a promising task aimed at correcting errors in a text. Many methods have been proposed to facilitate this task with remarkable results. However, most of them only focus on enhancing textual feature extraction without exploring the usage of other modalities’ information (e.g., speech), which can also provide valuable knowledge to help the model detect grammatical errors. To shore up this deficiency, we propose a novel framework that integrates both speech and text features to enhance GEC. In detail, we create new multimodal GEC datasets for English and German by generating audio from text using the advanced text-to-speech models. Subsequently, we extract acoustic and textual representations by a multimodal encoder that consists of a speech and a text encoder. A mixture-of-experts (MoE) layer is employed to selectively align representations from the two modalities, and then a dot attention mechanism is used to fuse them as final multimodal representations. Experimental results on CoNLL14, BEA19 English, and Falko-MERLIN German show that our multimodal GEC models achieve significant improvements over strong baselines and achieve a new state-of-the-art result on the Falko-MERLIN test set.</abstract>
      <url hash="ceeebc73">2023.findings-acl.594</url>
      <bibkey>fang-etal-2023-improving</bibkey>
      <doi>10.18653/v1/2023.findings-acl.594</doi>
    </paper>
    <paper id="595">
      <title>Teaching the Pre-trained Model to Generate Simple Texts for Text Simplification</title>
      <author><first>Renliang</first><last>Sun</last><affiliation>Peking University</affiliation></author>
      <author><first>Wei</first><last>Xu</last><affiliation>Georgia Institute of Technology</affiliation></author>
      <author><first>Xiaojun</first><last>Wan</last><affiliation>Peking University</affiliation></author>
      <pages>9345-9355</pages>
      <abstract>Randomly masking text spans in ordinary texts in the pre-training stage hardly allows models to acquire the ability to generate simple texts. It can hurt the performance of pre-trained models on text simplification tasks. In this paper, we propose a new continued pre-training strategy to teach the pre-trained model to generate simple texts. We continue pre-training BART, a representative model, to obtain SimpleBART. It consistently and significantly improves the results on lexical simplification, sentence simplification, and document-level simplification tasks over BART. At the end, we compare SimpleBART with several representative large language models (LLMs).</abstract>
      <url hash="150c7015">2023.findings-acl.595</url>
      <bibkey>sun-etal-2023-teaching</bibkey>
      <doi>10.18653/v1/2023.findings-acl.595</doi>
    </paper>
    <paper id="596">
      <title>Acquiring Frame Element Knowledge with Deep Metric Learning for Semantic Frame Induction</title>
      <author><first>Kosuke</first><last>Yamada</last><affiliation>Nagoya university</affiliation></author>
      <author><first>Ryohei</first><last>Sasano</last><affiliation>Nagoya University</affiliation></author>
      <author><first>Koichi</first><last>Takeda</last><affiliation>Nagoya University</affiliation></author>
      <pages>9356-9364</pages>
      <abstract>The semantic frame induction tasks are defined as a clustering of words into the frames that they evoke, and a clustering of their arguments according to the frame element roles that they should fill. In this paper, we address the latter task of argument clustering, which aims to acquire frame element knowledge, and propose a method that applies deep metric learning. In this method, a pre-trained language model is fine-tuned to be suitable for distinguishing frame element roles through the use of frame-annotated data, and argument clustering is performed with embeddings obtained from the fine-tuned model. Experimental results on FrameNet demonstrate that our method achieves substantially better performance than existing methods.</abstract>
      <url hash="1f540f63">2023.findings-acl.596</url>
      <bibkey>yamada-etal-2023-acquiring</bibkey>
      <doi>10.18653/v1/2023.findings-acl.596</doi>
    </paper>
    <paper id="597">
      <title>Leveraging Synthetic Targets for Machine Translation</title>
      <author><first>Sarthak</first><last>Mittal</last><affiliation>Mila</affiliation></author>
      <author><first>Oleksii</first><last>Hrinchuk</last><affiliation>NVIDIA</affiliation></author>
      <author><first>Oleksii</first><last>Kuchaiev</last><affiliation>NVIDIA</affiliation></author>
      <pages>9365-9379</pages>
      <abstract>In this work, we provide a recipe for training machine translation models in a limited resource setting by leveraging synthetic target data generated using a large pre-trained model. We show that consistently across different benchmarks in bilingual, multilingual, and speech translation setups, training models on synthetic targets outperforms training on the actual ground-truth data. This performance gap grows bigger with increasing limits on the amount of available resources in the form of the size of the dataset and the number of parameters in the model. We also provide preliminary analysis into whether this boost in performance is linked to ease of optimization or more deterministic nature of the predictions, and whether this paradigm leads to better out-of-distribution performance across different testing domains.</abstract>
      <url hash="86fcbb03">2023.findings-acl.597</url>
      <bibkey>mittal-etal-2023-leveraging</bibkey>
      <doi>10.18653/v1/2023.findings-acl.597</doi>
    </paper>
    <paper id="598">
      <title>Recipes for Sequential Pre-training of Multilingual Encoder and <fixed-case>S</fixed-case>eq2<fixed-case>S</fixed-case>eq Models</title>
      <author><first>Saleh</first><last>Soltan</last><affiliation>Amazon Alexa</affiliation></author>
      <author><first>Andy</first><last>Rosenbaum</last><affiliation>Amazon</affiliation></author>
      <author><first>Tobias</first><last>Falke</last><affiliation>Amazon Alexa AI</affiliation></author>
      <author><first>Qin</first><last>Lu</last><affiliation>Amazon.com Services LLC.</affiliation></author>
      <author><first>Anna</first><last>Rumshisky</last><affiliation>University of Massachusetts Lowell</affiliation></author>
      <author><first>Wael</first><last>Hamza</last><affiliation>Amazon</affiliation></author>
      <pages>9380-9394</pages>
      <abstract>Pre-trained encoder-only and sequence-to-sequence (seq2seq) models each have advantages, however training both model types from scratch is computationally expensive. We explore recipes to improve pre-training efficiency by initializing one model from the other. (1) Extracting the encoder from a seq2seq model, we show it under-performs a Masked Language Modeling (MLM) encoder, particularly on sequence labeling tasks. Variations of masking during seq2seq training, reducing the decoder size, and continuing with a small amount of MLM training do not close the gap. (2) Conversely, using an encoder to warm-start seq2seq training, we show that by unfreezing the encoder partway through training, we can match task performance of a from-scratch seq2seq model. Overall, this two-stage approach is an efficient recipe to obtain both a multilingual encoder and a seq2seq model, matching the performance of training each model from scratch while reducing the total compute cost by 27%.</abstract>
      <url hash="a38221bb">2023.findings-acl.598</url>
      <bibkey>soltan-etal-2023-recipes</bibkey>
      <doi>10.18653/v1/2023.findings-acl.598</doi>
    </paper>
    <paper id="599">
      <title>Constructing Code-mixed <fixed-case>U</fixed-case>niversal <fixed-case>D</fixed-case>ependency Forest for Unbiased Cross-lingual Relation Extraction</title>
      <author><first>Hao</first><last>Fei</last><affiliation>National University of Singapore</affiliation></author>
      <author><first>Meishan</first><last>Zhang</last><affiliation>Harbin Institute of Technology (Shenzhen), China</affiliation></author>
      <author><first>Min</first><last>Zhang</last><affiliation>Harbin Institute of Technology (Shenzhen)</affiliation></author>
      <author><first>Tat-Seng</first><last>Chua</last><affiliation>National University of Singapore</affiliation></author>
      <pages>9395-9408</pages>
      <abstract>Latest efforts on cross-lingual relation extraction (XRE) aggressively leverage the language-consistent structural features from the universal dependency (UD) resource, while they may largely suffer from biased transfer (e.g., either target-biased or source-biased) due to the inevitable linguistic disparity between languages. In this work, we investigate an unbiased UD- based XRE transfer by constructing a type of code-mixed UD forest. We first translate the sentence of the source language to the parallel target-side language, for both of which we parse the UD tree respectively. Then, we merge the source-/target-side UD structures as a unified code-mixed UD forest. With such forest features, the gaps of UD-based XRE between the training and predicting phases can be effectively closed. We conduct experiments on the ACE XRE benchmark datasets, where the results demonstrate that the proposed code-mixed UD forests help unbiased UD-based XRE transfer, with which we achieve significant XRE performance gains.</abstract>
      <url hash="bb64bddd">2023.findings-acl.599</url>
      <bibkey>fei-etal-2023-constructing</bibkey>
      <doi>10.18653/v1/2023.findings-acl.599</doi>
    </paper>
    <paper id="600">
      <title>Spontaneous gestures encoded by hand positions improve language models: An Information-Theoretic motivated study</title>
      <author><first>Yang</first><last>Xu</last><affiliation>Southern University of Science and Technology</affiliation></author>
      <author><first>Yang</first><last>Cheng</last><affiliation>University of Southern California</affiliation></author>
      <pages>9409-9424</pages>
      <abstract>The multi-modality nature of human communication has been utilized to enhance the performance of language modeling-related tasks. Driven by the development of large-scale end-to-end learning techniques and the availability of multi-modal data, it becomes possible to represent non-verbal communication behaviors through joint-learning, and directly study their interaction with verbal communication. However, there is still gaps in existing studies to better address the underlying mechanism of how non-verbal expression contributes to the overall communication purpose. Therefore, we explore two questions using mixed-modal language models trained against monologue video data: first, whether incorporating gesture representations can improve the language model’s performance (perplexity); second, whether spontaneous gestures demonstrate entropy rate constancy (ERC), which is an empirical pattern found in most verbal language data that supports the rational communication assumption from Information Theory. We have positive and interesting findings for both questions: speakers indeed use spontaneous gestures to convey “meaningful” information that enhances verbal communication, which can be captured with a simple spatial encoding scheme. More importantly, gestures are produced and organized rationally in a similar way as words, which optimizes the communication efficiency.</abstract>
      <url hash="4ea7671f">2023.findings-acl.600</url>
      <bibkey>xu-cheng-2023-spontaneous</bibkey>
      <doi>10.18653/v1/2023.findings-acl.600</doi>
    </paper>
    <paper id="601">
      <title>Progressive Translation: Improving Domain Robustness of Neural Machine Translation with Intermediate Sequences</title>
      <author><first>Chaojun</first><last>Wang</last><affiliation>The Chinese University of Hong Kong</affiliation></author>
      <author id="yang-liu-edinburgh"><first>Yang</first><last>Liu</last><affiliation>Microsoft</affiliation></author>
      <author><first>Wai</first><last>Lam</last><affiliation>The Chinese University of Hong Kong</affiliation></author>
      <pages>9425-9439</pages>
      <abstract>Previous studies show that intermediate supervision signals benefit various Natural Language Processing tasks. However, it is not clear whether there exist intermediate signals that benefit Neural Machine Translation (NMT). Borrowing techniques from Statistical Machine Translation, we propose intermediate signals which are intermediate sequences from the “source-like” structure to the “target-like” structure. Such intermediate sequences introduce an inductive bias that reflects a domain-agnostic principle of translation, which reduces spurious correlations that are harmful to out-of-domain generalisation. Furthermore, we introduce a full-permutation multi-task learning to alleviate the spurious causal relations from intermediate sequences to the target, which results from <i>exposure bias</i>. The Minimum Bayes Risk decoding algorithm is used to pick the best candidate translation from all permutations to further improve the performance. Experiments show that the introduced intermediate signals can effectively improve the domain robustness of NMT and reduces the amount of hallucinations on out-of-domain translation. Further analysis shows that our methods are especially promising in low-resource scenarios.</abstract>
      <url hash="e9750584">2023.findings-acl.601</url>
      <bibkey>wang-etal-2023-progressive</bibkey>
      <doi>10.18653/v1/2023.findings-acl.601</doi>
    </paper>
    <paper id="602">
      <title>Controlled Text Generation with Hidden Representation Transformations</title>
      <author><first>Vaibhav</first><last>Kumar</last><affiliation>University of California Los Angeles</affiliation></author>
      <author><first>Hana</first><last>Koorehdavoudi</last><affiliation>Amazon</affiliation></author>
      <author><first>Masud</first><last>Moshtaghi</last><affiliation>Amazon Alexa</affiliation></author>
      <author><first>Amita</first><last>Misra</last><affiliation>Amazon</affiliation></author>
      <author><first>Ankit</first><last>Chadha</last><affiliation>Amazon</affiliation></author>
      <author><first>Emilio</first><last>Ferrara</last><affiliation>USC</affiliation></author>
      <pages>9440-9455</pages>
      <abstract>We propose CHRT (Control HiddenRepresentation Transformation) – a con-trolled language generation framework thatsteers large language models to generatetext pertaining to certain attributes (such astoxicity). CHRT gains attribute control bymodifying the hidden representation of thebase model through learned transformations. We employ a contrastive-learning frameworkto learn these transformations that can becombined to gain multi-attribute control. Theeffectiveness of CHRT is experimentallyshown by comparing it with seven baselinesover three attributes. CHRT outperforms all thebaselines in the task of detoxification, positivesentiment steering, and text simplificationwhile minimizing the loss in linguistic qualities. Further, our approach has the lowest inferencelatency of only 0.01 seconds more than thebase model, making it the most suitable forhigh-performance production environments. We open-source our code and release two noveldatasets to further propel controlled languagegeneration research</abstract>
      <url hash="32fe6797">2023.findings-acl.602</url>
      <bibkey>kumar-etal-2023-controlled</bibkey>
      <doi>10.18653/v1/2023.findings-acl.602</doi>
    </paper>
    <paper id="603">
      <title>Visual Coherence Loss for Coherent and Visually Grounded Story Generation</title>
      <author><first>Xudong</first><last>Hong</last><affiliation>Saarland University / MPI Informatics</affiliation></author>
      <author><first>Vera</first><last>Demberg</last><affiliation>Saarland University</affiliation></author>
      <author><first>Asad</first><last>Sayeed</last><affiliation>University of Gothenburg</affiliation></author>
      <author><first>Qiankun</first><last>Zheng</last><affiliation>Saarland University</affiliation></author>
      <author><first>Bernt</first><last>Schiele</last><affiliation>MPI Informatics</affiliation></author>
      <pages>9456-9470</pages>
      <abstract>Local coherence is essential for long-form text generation models. We identify two important aspects of local coherence within the visual storytelling task: (1) the model needs to represent re-occurrences of characters within the image sequence in order to mention them correctly in the story; (2) character representations should enable us to find instances of the same characters and distinguish different characters. In this paper, we propose a loss function inspired by a linguistic theory of coherence for self-supervised learning for image sequence representations. We further propose combining features from an object and a face detector to construct stronger character features. To evaluate input-output relevance that current reference-based metrics don’t measure, we propose a character matching metric to check whether the models generate referring expressions correctly for characters in input image sequences. Experiments on a visual story generation dataset show that our proposed features and loss function are effective for generating more coherent and visually grounded stories.</abstract>
      <url hash="f3b2c899">2023.findings-acl.603</url>
      <bibkey>hong-etal-2023-visual</bibkey>
      <doi>10.18653/v1/2023.findings-acl.603</doi>
    </paper>
    <paper id="604">
      <title><fixed-case>A</fixed-case>na<fixed-case>M</fixed-case>eta: A Table Understanding Dataset of Field Metadata Knowledge Shared by Multi-dimensional Data Analysis Tasks</title>
      <author><first>Xinyi</first><last>He</last><affiliation>Xi’an Jiaotong University</affiliation></author>
      <author><first>Mengyu</first><last>Zhou</last><affiliation>Microsoft Research</affiliation></author>
      <author><first>Mingjie</first><last>Zhou</last><affiliation>University of Hong Kong</affiliation></author>
      <author><first>Jialiang</first><last>Xu</last><affiliation>University of Illinois at Urbana Champaign</affiliation></author>
      <author><first>Xiao</first><last>Lv</last><affiliation>Microsoft Research</affiliation></author>
      <author><first>Tianle</first><last>Li</last><affiliation>University of Waterloo</affiliation></author>
      <author><first>Yijia</first><last>Shao</last><affiliation>Peking University</affiliation></author>
      <author><first>Shi</first><last>Han</last><affiliation>Microsoft</affiliation></author>
      <author><first>Zejian</first><last>Yuan</last><affiliation>Xi’an Jiaotong University</affiliation></author>
      <author><first>Dongmei</first><last>Zhang</last><affiliation>Microsoft</affiliation></author>
      <pages>9471-9492</pages>
      <abstract>Tabular data analysis is performed everyday across various domains. It requires an accurate understanding of field semantics to correctly operate on table fields and find common patterns in daily analysis. In this paper, we introduce the AnaMeta dataset, a collection of 467k tables with derived supervision labels for four types of commonly used field metadata: measure/dimension dichotomy, common field roles, semantic field type, and default aggregation function. We evaluate a wide range of models for inferring metadata as the benchmark. We also propose a multi-encoder framework, called KDF, which improves the metadata understanding capability of tabular models by incorporating distribution and knowledge information. Furthermore, we propose four interfaces for incorporating field metadata into downstream analysis tasks.</abstract>
      <url hash="ddf96208">2023.findings-acl.604</url>
      <bibkey>he-etal-2023-anameta</bibkey>
      <doi>10.18653/v1/2023.findings-acl.604</doi>
    </paper>
    <paper id="605">
      <title>Large Language Models Are Partially Primed in Pronoun Interpretation</title>
      <author><first>Suet-Ying</first><last>Lam</last><affiliation>The University of Massachusetts Amherst</affiliation></author>
      <author><first>Qingcheng</first><last>Zeng</last><affiliation>Northwestern University</affiliation></author>
      <author><first>Kexun</first><last>Zhang</last><affiliation>UC Santa Barbara</affiliation></author>
      <author><first>Chenyu</first><last>You</last><affiliation>Yale University</affiliation></author>
      <author><first>Rob</first><last>Voigt</last><affiliation>Northwestern University</affiliation></author>
      <pages>9493-9506</pages>
      <abstract>While a large body of literature suggests that large language models (LLMs) acquire rich linguistic representations, little is known about whether they adapt to linguistic biases in a human-like way. The present study probes this question by asking whether LLMs display human-like referential biases using stimuli and procedures from real psycholinguistic experiments. Recent psycholinguistic studies suggest that humans adapt their referential biases with recent exposure to referential patterns; closely replicating three relevant psycholinguistic experiments from Johnson &amp; Arnold (2022) in an in-context learning (ICL) framework, we found that InstructGPT adapts its pronominal interpretations in response to the frequency of referential patterns in the local discourse, though in a limited fashion: adaptation was only observed relative to syntactic but not semantic biases. By contrast, FLAN-UL2 fails to generate meaningful patterns. Our results provide further evidence that contemporary LLMs discourse representations are sensitive to syntactic patterns in the local context but less so to semantic patterns. Our data and code are available at <url>https://github.com/zkx06111/llm_priming</url>.</abstract>
      <url hash="a367cea9">2023.findings-acl.605</url>
      <bibkey>lam-etal-2023-large</bibkey>
      <doi>10.18653/v1/2023.findings-acl.605</doi>
    </paper>
    <paper id="606">
      <title>Counterfactuals of Counterfactuals: a back-translation-inspired approach to analyse counterfactual editors</title>
      <author><first>George</first><last>Filandrianos</last><affiliation>National Technical University of Athens</affiliation></author>
      <author><first>Edmund</first><last>Dervakos</last><affiliation>National Technical University of Athens</affiliation></author>
      <author><first>Orfeas</first><last>Menis Mastromichalakis</last><affiliation>National Technical University of Athens</affiliation></author>
      <author><first>Chrysoula</first><last>Zerva</last><affiliation>Instituto de Instituto de Telecomunicações, Instituto Superior Técnico, University of Lisbon</affiliation></author>
      <author><first>Giorgos</first><last>Stamou</last><affiliation>National Technical University of Athens</affiliation></author>
      <pages>9507-9525</pages>
      <abstract>In the wake of responsible AI, interpretability methods, which attempt to provide an explanation for the predictions of neural models have seen rapid progress. In this work, we are concerned with explanations that are applicable to natural language processing (NLP) models and tasks, and we focus specifically on the analysis of counterfactual, contrastive explanations. We note that while there have been several explainers proposed to produce counterfactual explanations, their behaviour can vary significantly and the lack of a universal ground truth for the counterfactual edits imposes an insuperable barrier on their evaluation. We propose a new back translation-inspired evaluation methodology that utilises earlier outputs of the explainer as ground truth proxies to investigate the consistency of explainers. We show that by iteratively feeding the counterfactual to the explainer we can obtain valuable insights into the behaviour of both the predictor and the explainer models, and infer patterns that would be otherwise obscured. Using this methodology, we conduct a thorough analysis and propose a novel metric to evaluate the consistency of counterfactual generation approaches with different characteristics across available performance indicators.</abstract>
      <url hash="d9b459c8">2023.findings-acl.606</url>
      <bibkey>filandrianos-etal-2023-counterfactuals</bibkey>
      <doi>10.18653/v1/2023.findings-acl.606</doi>
    </paper>
    <paper id="607">
      <title>A Pilot Study on Dialogue-Level Dependency Parsing for <fixed-case>C</fixed-case>hinese</title>
      <author><first>Gongyao</first><last>Jiang</last><affiliation>Tianjin University</affiliation></author>
      <author><first>Shuang</first><last>Liu</last><affiliation>Tianjin University</affiliation></author>
      <author><first>Meishan</first><last>Zhang</last><affiliation>Harbin Institute of Technology (Shenzhen), China</affiliation></author>
      <author><first>Min</first><last>Zhang</last><affiliation>Harbin Institute of Technology (Shenzhen)</affiliation></author>
      <pages>9526-9541</pages>
      <abstract>Dialogue-level dependency parsing has received insufficient attention, especially for Chinese. To this end, we draw on ideas from syntactic dependency and rhetorical structure theory (RST), developing a high-quality human-annotated corpus, which contains 850 dialogues and 199,803 dependencies. Considering that such tasks suffer from high annotation costs, we investigate zero-shot and few-shot scenarios. Based on an existing syntactic treebank, we adopt a signal-based method to transform seen syntactic dependencies into unseen ones between elementary discourse units (EDUs), where the signals are detected by masked language modeling. Besides, we apply single-view and multi-view data selection to access reliable pseudo-labeled instances. Experimental results show the effectiveness of these baselines. Moreover, we discuss several crucial points about our dataset and approach.</abstract>
      <url hash="80197888">2023.findings-acl.607</url>
      <bibkey>jiang-etal-2023-pilot</bibkey>
      <doi>10.18653/v1/2023.findings-acl.607</doi>
    </paper>
    <paper id="608">
      <title>On the Off-Target Problem of Zero-Shot Multilingual Neural Machine Translation</title>
      <author><first>Liang</first><last>Chen</last><affiliation>Peking University</affiliation></author>
      <author><first>Shuming</first><last>Ma</last><affiliation>Microsoft Research Asia</affiliation></author>
      <author><first>Dongdong</first><last>Zhang</last><affiliation>Microsoft Research Asia</affiliation></author>
      <author><first>Furu</first><last>Wei</last><affiliation>Microsoft Research</affiliation></author>
      <author><first>Baobao</first><last>Chang</last><affiliation>Institute of Computational Linguistic, Peking University</affiliation></author>
      <pages>9542-9558</pages>
      <abstract>While multilingual neural machine translation has achieved great success, it suffers from the off-target issue, where the translation is in the wrong language. This problem is more pronounced on zero-shot translation tasks. In this work, we find that failing in encoding discriminative target language signal will lead to off-target and a closer lexical distance (i.e., KL-divergence) between two languages’ vocabularies is related with a higher off-target rate. We also find that solely isolating the vocab of different languages in the decoder can alleviate the problem. Motivated by the findings, we propose Language Aware Vocabulary Sharing (LAVS), a simple and effective algorithm to construct the multilingual vocabulary, that greatly alleviates the off-target problem of the translation model by increasing the KL-divergence between languages. We conduct experiments on a multilingual machine translation benchmark in 11 languages. Experiments show that the off-target rate for 90 translation tasks is reduced from 29% to 8%, while the overall BLEU score is improved by an average of 1.9 points without extra training cost or sacrificing the supervised directions’ performance. We release the code at <url>https://github.com/PKUnlp-icler/Off-Target-MNMT</url> for reproduction.</abstract>
      <url hash="7d1c14f3">2023.findings-acl.608</url>
      <bibkey>chen-etal-2023-target</bibkey>
      <doi>10.18653/v1/2023.findings-acl.608</doi>
    </paper>
    <paper id="609">
      <title><fixed-case>ORCA</fixed-case>: A Challenging Benchmark for <fixed-case>A</fixed-case>rabic Language Understanding</title>
      <author><first>AbdelRahim</first><last>Elmadany</last><affiliation>Natural Language Processing Lab, University of British Columbia (UBC)</affiliation></author>
      <author><first>ElMoatez Billah</first><last>Nagoudi</last><affiliation>The University of British Columbia</affiliation></author>
      <author><first>Muhammad</first><last>Abdul-Mageed</last><affiliation>The University of British Columbia</affiliation></author>
      <pages>9559-9586</pages>
      <abstract>Due to the crucial role pretrained language models play in modern NLP, several benchmarks have been proposed to evaluate their performance. In spite of these efforts, no public benchmark of diverse nature currently exists for evaluating Arabic NLU. This makes it challenging to measure progress for both Arabic and multilingual language models. This challenge is compounded by the fact that any benchmark targeting Arabic needs to take into account the fact that Arabic is not a single language but rather a collection of languages and language varieties. In this work, we introduce a publicly available benchmark for Arabic language understanding evaluation dubbed ORCA. It is carefully constructed to cover diverse Arabic varieties and a wide range of challenging Arabic understanding tasks exploiting 60 different datasets (across seven NLU task clusters). To measure current progress in Arabic NLU, we use ORCA to offer a comprehensive comparison between 18 multilingual and Arabic language models. We also provide a public leaderboard with a unified single-number evaluation metric (ORCA score) to facilitate future research.</abstract>
      <url hash="ef24c1e6">2023.findings-acl.609</url>
      <bibkey>elmadany-etal-2023-orca</bibkey>
      <doi>10.18653/v1/2023.findings-acl.609</doi>
    </paper>
    <paper id="610">
      <title>Delving into the Openness of <fixed-case>CLIP</fixed-case></title>
      <author><first>Shuhuai</first><last>Ren</last><affiliation>Peking University</affiliation></author>
      <author><first>Lei</first><last>Li</last><affiliation>Peking University</affiliation></author>
      <author><first>Xuancheng</first><last>Ren</last><affiliation>DAMO Academy, Alibaba Group</affiliation></author>
      <author><first>Guangxiang</first><last>Zhao</last><affiliation>Shanghai AI lab</affiliation></author>
      <author><first>Xu</first><last>Sun</last><affiliation>Peking University</affiliation></author>
      <pages>9587-9606</pages>
      <abstract>Contrastive Language-Image Pre-training (CLIP) formulates image classification as an image-to-text matching task, i.e., matching images to the corresponding natural language descriptions instead of discrete category IDs. This allows for open-vocabulary visual recognition, where the model can recognize images from an open class set (also known as an open vocabulary) in a zero-shot manner. However, evaluating the openness of CLIP-like models is challenging, as the models are open to arbitrary vocabulary in theory, but their accuracy varies in practice. To address this, we resort to an incremental perspective to assess the openness through vocabulary expansions, and define extensibility to measure a model’s ability to handle novel classes. Our evaluation shows that CLIP-like models are not truly open, and their performance deteriorates as the vocabulary expands. We further dissect the feature space of CLIP from the perspectives of representation alignment and uniformity. Our investigation reveals that the overestimation of openness is due to confusion among competing text features, rather than a failure to capture the similarity between image features and text features of novel classes. We hope that our investigation and analysis will facilitate future research on the CLIP openness issue.</abstract>
      <url hash="1e8d9e1e">2023.findings-acl.610</url>
      <bibkey>ren-etal-2023-delving</bibkey>
      <doi>10.18653/v1/2023.findings-acl.610</doi>
    </paper>
    <paper id="611">
      <title>From Adversarial Arms Race to Model-centric Evaluation: Motivating a Unified Automatic Robustness Evaluation Framework</title>
      <author><first>Yangyi</first><last>Chen</last><affiliation>UIUC</affiliation></author>
      <author><first>Hongcheng</first><last>Gao</last><affiliation>Chongqing University</affiliation></author>
      <author><first>Ganqu</first><last>Cui</last><affiliation>Tsinghua University</affiliation></author>
      <author><first>Lifan</first><last>Yuan</last><affiliation>Huazhong University of Science and Technology</affiliation></author>
      <author><first>Dehan</first><last>Kong</last><affiliation>Alibaba Group</affiliation></author>
      <author><first>Hanlu</first><last>Wu</last><affiliation>Zhejiang University</affiliation></author>
      <author><first>Ning</first><last>Shi</last><affiliation>The University of Alberta</affiliation></author>
      <author><first>Bo</first><last>Yuan</last><affiliation>Alibaba Group</affiliation></author>
      <author><first>Longtao</first><last>Huang</last><affiliation>Alibaba Group</affiliation></author>
      <author><first>Hui</first><last>Xue</last><affiliation>alibaba</affiliation></author>
      <author><first>Zhiyuan</first><last>Liu</last><affiliation>Tsinghua University</affiliation></author>
      <author><first>Maosong</first><last>Sun</last><affiliation>Tsinghua University</affiliation></author>
      <author><first>Heng</first><last>Ji</last><affiliation>University of Illinois at Urbana-Champaign and Amazon (Amazon Scholar)</affiliation></author>
      <pages>9607-9632</pages>
      <abstract>Textual adversarial attacks can discover models’ weaknesses by adding semantic-preserved but misleading perturbations to the inputs. The long-lasting adversarial attack-and-defense arms race in Natural Language Processing (NLP) is algorithm-centric, providing valuable techniques for automatic robustness evaluation. However, the existing practice of robustness evaluation may exhibit issues of incomprehensive evaluation, impractical evaluation protocol, and invalid adversarial samples. In this paper, we aim to set up a unified automatic robustness evaluation framework, shifting towards model-centric evaluation to further exploit the advantages of adversarial attacks. To address the above challenges, we first determine robustness evaluation dimensions based on model capabilities and specify the reasonable algorithm to generate adversarial samples for each dimension. Then we establish the evaluation protocol, including evaluation settings and metrics, under realistic demands. Finally, we use the perturbation degree of adversarial samples to control the sample validity. We implement a toolkit <b>RobTest</b> that realizes our automatic robustness evaluation framework. In our experiments, we conduct a robustness evaluation of RoBERTa models to demonstrate the effectiveness of our evaluation framework, and further show the rationality of each component in the framework.</abstract>
      <url hash="0664b9b2">2023.findings-acl.611</url>
      <bibkey>chen-etal-2023-adversarial</bibkey>
      <doi>10.18653/v1/2023.findings-acl.611</doi>
    </paper>
    <paper id="612">
      <title>An Empirical Study of Sentiment-Enhanced Pre-Training for Aspect-Based Sentiment Analysis</title>
      <author><first>Yice</first><last>Zhang</last><affiliation>Harbin Institute of Technology, Shenzhen</affiliation></author>
      <author><first>Yifan</first><last>Yang</last><affiliation>Harbin Institute of Technology, Shenzhen.</affiliation></author>
      <author><first>Bin</first><last>Liang</last><affiliation>Harbin Institute of Technology, Shenzhen</affiliation></author>
      <author><first>Shiwei</first><last>Chen</last><affiliation>Harbin Institute of Technology, Shenzhen</affiliation></author>
      <author><first>Bing</first><last>Qin</last><affiliation>Harbin Institute of Technology</affiliation></author>
      <author><first>Ruifeng</first><last>Xu</last><affiliation>Harbin Institute of Technology, Shenzhen</affiliation></author>
      <pages>9633-9651</pages>
      <abstract>Aspect-Based Sentiment Analysis (ABSA) aims to recognize fine-grained opinions and sentiments of users, which is an important problem in sentiment analysis. Recent work has shown that Sentiment-enhanced Pre-Training (SPT) can substantially improve the performance of various ABSA tasks. However, there is currently a lack of comprehensive evaluation and fair comparison of existing SPT approaches. Therefore, this paper performs an empirical study to investigate the effectiveness of different SPT approaches. First, we develop an effective knowledge-mining method and leverage it to build a large-scale knowledge-annotated SPT corpus. Second, we systematically analyze the impact of integrating sentiment knowledge and other linguistic knowledge in pre-training. For each type of sentiment knowledge, we also examine and compare multiple integration methods. Finally, we conduct extensive experiments on a wide range of ABSA tasks to see how much SPT can facilitate the understanding of aspect-level sentiments.</abstract>
      <url hash="d474944f">2023.findings-acl.612</url>
      <bibkey>zhang-etal-2023-empirical</bibkey>
      <doi>10.18653/v1/2023.findings-acl.612</doi>
    </paper>
    <paper id="613">
      <title><fixed-case>N</fixed-case>at<fixed-case>CS</fixed-case>: Eliciting Natural Customer Support Dialogues</title>
      <author><first>James</first><last>Gung</last><affiliation>Amazon</affiliation></author>
      <author><first>Emily</first><last>Moeng</last><affiliation>Amazon</affiliation></author>
      <author><first>Wesley</first><last>Rose</last><affiliation>Amazon</affiliation></author>
      <author><first>Arshit</first><last>Gupta</last><affiliation>Amazon AI</affiliation></author>
      <author><first>Yi</first><last>Zhang</last><affiliation>Amazon AI</affiliation></author>
      <author><first>Saab</first><last>Mansour</last><affiliation>Amazon</affiliation></author>
      <pages>9652-9677</pages>
      <abstract>Despite growing interest in applications based on natural customer support conversations,there exist remarkably few publicly available datasets that reflect the expected characteristics of conversations in these settings. Existing task-oriented dialogue datasets, which were collected to benchmark dialogue systems mainly in written human-to-bot settings, are not representative of real customer support conversations and do not provide realistic benchmarks for systems that are applied to natural data. To address this gap, we introduce NatCS, a multi-domain collection of spoken customer service conversations. We describe our process for collecting synthetic conversations between customers and agents based on natural language phenomena observed in real conversations. Compared to previous dialogue datasets, the conversations collected with our approach are more representative of real human-to-human conversations along multiple metrics. Finally, we demonstrate potential uses of NatCS, including dialogue act classification and intent induction from conversations as potential applications, showing that dialogue act annotations in NatCS provide more effective training data for modeling real conversations compared to existing synthetic written datasets. We publicly release NatCS to facilitate research in natural dialog systems</abstract>
      <url hash="ca870cd4">2023.findings-acl.613</url>
      <bibkey>gung-etal-2023-natcs</bibkey>
      <doi>10.18653/v1/2023.findings-acl.613</doi>
    </paper>
    <paper id="614">
      <title>Are Intermediate Layers and Labels Really Necessary? A General Language Model Distillation Method</title>
      <author><first>Shicheng</first><last>Tan</last><affiliation>Anhui University</affiliation></author>
      <author><first>Weng Lam</first><last>Tam</last><affiliation>Zhipu.AI</affiliation></author>
      <author><first>Yuanchun</first><last>Wang</last><affiliation>Renmin University of China</affiliation></author>
      <author><first>Wenwen</first><last>Gong</last><affiliation>Tsinghua University</affiliation></author>
      <author><first>Shu</first><last>Zhao</last><affiliation>Anhui University</affiliation></author>
      <author><first>Peng</first><last>Zhang</last><affiliation>Zhipu.AI</affiliation></author>
      <author><first>Jie</first><last>Tang</last><affiliation>Tsinghua University</affiliation></author>
      <pages>9678-9696</pages>
      <abstract>The large scale of pre-trained language models poses a challenge for their deployment on various devices, with a growing emphasis on methods to compress these models, particularly knowledge distillation. However, current knowledge distillation methods rely on the model’s intermediate layer features and the golden labels (also called hard labels), which usually require aligned model architecture and enough labeled data respectively. Moreover, the parameters of vocabulary are usually neglected in existing methods. To address these problems, we propose a general language model distillation (GLMD) method that performs two-stage word prediction distillation and vocabulary compression, which is simple and surprisingly shows extremely strong performance. Specifically, GLMD supports more general application scenarios by eliminating the constraints of dimension and structure between models and the need for labeled datasets through the absence of intermediate layers and golden labels. Meanwhile, based on the long-tailed distribution of word frequencies in the data, GLMD designs a strategy of vocabulary compression through decreasing vocabulary size instead of dimensionality. Experimental results show that our method outperforms 25 state-of-the-art methods on the SuperGLUE benchmark, achieving an average score that surpasses the best method by 3%.</abstract>
      <url hash="f7d41042">2023.findings-acl.614</url>
      <bibkey>tan-etal-2023-intermediate</bibkey>
      <doi>10.18653/v1/2023.findings-acl.614</doi>
    </paper>
    <paper id="615">
      <title>Diable: Efficient Dialogue State Tracking as Operations on Tables</title>
      <author><first>Pietro</first><last>Lesci</last><affiliation>University of Cambridge</affiliation></author>
      <author><first>Yoshinari</first><last>Fujinuma</last><affiliation>AWS AI Labs</affiliation></author>
      <author><first>Momchil</first><last>Hardalov</last><affiliation>AWS AI Labs</affiliation></author>
      <author><first>Chao</first><last>Shang</last><affiliation>Amazon AWS AI</affiliation></author>
      <author><first>Yassine</first><last>Benajiba</last><affiliation>Amazon AWS AI</affiliation></author>
      <author><first>Lluis</first><last>Marquez</last><affiliation>AWS AI Labs</affiliation></author>
      <pages>9697-9719</pages>
      <abstract>Sequence-to-sequence state-of-the-art systems for dialogue state tracking (DST) use the full dialogue history as input, represent the current state as a list with all the slots, and generate the entire state from scratch at each dialogue turn. This approach is inefficient, especially when the number of slots is large and the conversation is long. We propose Diable, a new task formalisation that simplifies the design and implementation of efficient DST systems and allows one to easily plug and play large language models. We represent the dialogue state as a table and formalise DST as a table manipulation task. At each turn, the system updates the previous state by generating table operations based on the dialogue context. Extensive experimentation on the MultiWoz datasets demonstrates that Diable (i) outperforms strong efficient DST baselines, (ii) is 2.4x more time efficient than current state-of-the-art methods while retaining competitive Joint Goal Accuracy, and (iii) is robust to noisy data annotations due to the table operations approach.</abstract>
      <url hash="54fb1ebb">2023.findings-acl.615</url>
      <bibkey>lesci-etal-2023-diable</bibkey>
      <revision id="1" href="2023.findings-acl.615v1" hash="cd2268c0"/>
      <revision id="2" href="2023.findings-acl.615v2" hash="1214c694" date="2023-08-02">Add link to code, optimise white space (i.e., promote paragraphs to subsections), and enhance table captions.</revision>
      <doi>10.18653/v1/2023.findings-acl.615</doi>
      <revision id="3" href="2023.findings-acl.615v3" hash="54fb1ebb" date="2023-09-17">Added an author.</revision>
    </paper>
    <paper id="616">
      <title>Neural Topic Modeling based on Cycle Adversarial Training and Contrastive Learning</title>
      <author><first>Boyu</first><last>Wang</last><affiliation>Southeast University</affiliation></author>
      <author><first>Linhai</first><last>Zhang</last><affiliation>Southeast University</affiliation></author>
      <author><first>Deyu</first><last>Zhou</last><affiliation>Southeast University</affiliation></author>
      <author><first>Yi</first><last>Cao</last><affiliation>Huawei Technologies Co., Ltd.</affiliation></author>
      <author><first>Jiandong</first><last>Ding</last><affiliation>Huawei Technologies Co., Ltd</affiliation></author>
      <pages>9720-9731</pages>
      <abstract>Neural topic models have been widely used to extract common topics across documents. Recently, contrastive learning has been applied to variational autoencoder-based neural topic models, achieving promising results. However, due to the limitation of the unidirectional structure of the variational autoencoder, the encoder is enhanced with the contrastive loss instead of the decoder, leading to a gap between model training and evaluation. To address the limitation, we propose a novel neural topic modeling framework based on cycle adversarial training and contrastive learning to apply contrastive learning on the generator directly. Specifically, a self-supervised contrastive loss is proposed to make the generator capture similar topic information, which leads to better topic-word distributions. Meanwhile, a discriminative contrastive loss is proposed to cooperate with the self-supervised contrastive loss to balance the generation and discrimination. Moreover, based on the reconstruction ability of the cycle generative adversarial network, a novel data augmentation strategy is designed and applied to the topic distribution directly. Experiments have been conducted on four benchmark datasets and results show that the proposed approach outperforms competitive baselines.</abstract>
      <url hash="280bd52d">2023.findings-acl.616</url>
      <bibkey>wang-etal-2023-neural</bibkey>
      <doi>10.18653/v1/2023.findings-acl.616</doi>
    </paper>
    <paper id="617">
      <title>Alleviating Exposure Bias via Multi-level Contrastive Learning and Deviation Simulation in Abstractive Summarization</title>
      <author><first>Jiawen</first><last>Xie</last><affiliation>Shanghai Jiao Tong University</affiliation></author>
      <author><first>Qi</first><last>Su</last><affiliation>Shanghai Jiaotong University</affiliation></author>
      <author><first>Shaoting</first><last>Zhang</last><affiliation>Shanghai AI Lab</affiliation></author>
      <author><first>Xiaofan</first><last>Zhang</last><affiliation>Shanghai Jiao Tong University</affiliation></author>
      <pages>9732-9747</pages>
      <abstract>Most Transformer based abstractive summarization systems have a severe mismatch between training and inference, i.e., exposure bias. From diverse perspectives, we introduce a simple multi-level contrastive learning framework for abstractive summarization (SimMCS) and a tailored sparse decoder self-attention pattern (SDSA) to bridge the gap between training and inference to improve model performance. Compared with previous contrastive objectives focusing only on the relative order of probability mass assigned to non-gold summaries, SimMCS additionally takes their absolute positions into account, which guarantees that the relatively high-quality (positive) summaries among them could be properly assigned high probability mass, and further enhances the capability of discriminating summary quality beyond exploiting potential artifacts of specific metrics. SDSA simulates the possible inference scenarios of deviation in the training phase to get closer to the ideal paradigm. Our approaches outperform the previous state-of-the-art results on two summarization datasets while just adding fairly low overhead. Further empirical analysis shows our model preserves the advantages of prior contrastive methods and possesses strong few-shot learning ability.</abstract>
      <url hash="32bf5a27">2023.findings-acl.617</url>
      <bibkey>xie-etal-2023-alleviating</bibkey>
      <doi>10.18653/v1/2023.findings-acl.617</doi>
    </paper>
    <paper id="618">
      <title>Mapping Brains with Language Models: A Survey</title>
      <author><first>Antonia</first><last>Karamolegkou</last><affiliation>Copenhagen University</affiliation></author>
      <author><first>Mostafa</first><last>Abdou</last><affiliation>Princeton University</affiliation></author>
      <author><first>Anders</first><last>Søgaard</last><affiliation>University of Copenhagen</affiliation></author>
      <pages>9748-9762</pages>
      <abstract>Over the years, many researchers have seemingly made the same observation: Brain and language model activations exhibit some structural similarities, enabling linear partial mappings between features extracted from neural recordings and computational language models. In an attempt to evaluate how much evidence has been accumulated for this observation, we survey over 30 studies spanning 10 datasets and 8 metrics. How much evidence has been accumulated, and what, if anything, is missing before we can draw conclusions? Our analysis of the evaluation methods used in the literature reveals that some of the metrics are less conservative. We also find that the accumulated evidence, for now, remains ambiguous, but correlations with model size and quality provide grounds for cautious optimism.</abstract>
      <url hash="c5ffa820">2023.findings-acl.618</url>
      <bibkey>karamolegkou-etal-2023-mapping</bibkey>
      <doi>10.18653/v1/2023.findings-acl.618</doi>
    </paper>
    <paper id="619">
      <title>Parameter-Efficient Finetuning for Robust Continual Multilingual Learning</title>
      <author><first>Kartikeya</first><last>Badola</last><affiliation>Google Research</affiliation></author>
      <author><first>Shachi</first><last>Dave</last><affiliation>Google Research</affiliation></author>
      <author><first>Partha</first><last>Talukdar</last><affiliation>Google Research and IISc</affiliation></author>
      <pages>9763-9780</pages>
      <abstract>We introduce and study the problem of Continual Multilingual Learning (CML) where a previously trained multilingual model is periodically updated using new data arriving in stages. If the new data is present only in a subset of languages, we find that the resulting model shows improved performance only on the languages included in the latest update (and a few closely related languages) while its performance on all the remaining languages degrade significantly. We address this challenge by proposing LAFT-URIEL, a parameter-efficient finetuning strategy which aims to increase the number of languages on which the model improves after an update, while reducing the magnitude of loss in performance for the remaining languages. LAFT-URIEL uses linguistic knowledge to balance overfitting and knowledge sharing across languages, allowing for an additional 25% of task languages to see an improvement in performance after an update, while also reducing the average magnitude of losses on the remaining languages by 78% relative.</abstract>
      <url hash="8089c100">2023.findings-acl.619</url>
      <bibkey>badola-etal-2023-parameter</bibkey>
      <doi>10.18653/v1/2023.findings-acl.619</doi>
    </paper>
    <paper id="620">
      <title>Interpretable Multimodal Misinformation Detection with Logic Reasoning</title>
      <author><first>Hui</first><last>Liu</last><affiliation>City University of Hong Kong</affiliation></author>
      <author><first>Wenya</first><last>Wang</last><affiliation>University of Washington</affiliation></author>
      <author><first>Haoliang</first><last>Li</last><affiliation>CityU</affiliation></author>
      <pages>9781-9796</pages>
      <abstract>Multimodal misinformation on online social platforms is becoming a critical concern due to increasing credibility and easier dissemination brought by multimedia content, compared to traditional text-only information. While existing multimodal detection approaches have achieved high performance, the lack of interpretability hinders these systems’ reliability and practical deployment. Inspired by Neural-Symbolic AI which combines the learning ability of neural networks with the explainability of symbolic learning, we propose a novel logic-based neural model for multimodal misinformation detection which integrates interpretable logic clauses to express the reasoning process of the target task. To make learning effective, we parameterize the symbolic logical elements using neural representations, which facilitate the automatic generation and evaluation of meaningful logic clauses. Additionally, to make our framework generalizable across diverse misinformation sources, we introduce five meta-predicates that can be instantiated with different correlations. Results on three public datasets (Twitter, Weibo, and Sarcasm) demonstrate the feasibility and versatility of our model.</abstract>
      <url hash="623815a4">2023.findings-acl.620</url>
      <bibkey>liu-etal-2023-interpretable</bibkey>
      <doi>10.18653/v1/2023.findings-acl.620</doi>
    </paper>
    <paper id="621">
      <title>Semantic-conditioned Dual Adaptation for Cross-domain Query-based Visual Segmentation</title>
      <author><first>Ye</first><last>Wang</last><affiliation>Zhejiang University</affiliation></author>
      <author><first>Tao</first><last>Jin</last><affiliation>Zhejiang University</affiliation></author>
      <author><first>Wang</first><last>Lin</last><affiliation>zhejiang university</affiliation></author>
      <author><first>Xize</first><last>Cheng</last><affiliation>Zhejiang University</affiliation></author>
      <author><first>Linjun</first><last>Li</last><affiliation>Zhejiang University</affiliation></author>
      <author><first>Zhou</first><last>Zhao</last><affiliation>zhejiang university</affiliation></author>
      <pages>9797-9815</pages>
      <abstract>Visual segmentation from language queries has attracted significant research interest. Despite the effectiveness, existing works require expensive labeling and suffer severe degradation when deployed to an unseen domain. In this paper, we investigate a novel task Cross-domain Query-based Visual Segmentation (CQVS), aiming to adapt the segmentation model from a labeled domain to a new unlabeled domain. The challenges of CQVS stem from three domain discrepancies: (1) multi-modal content shift, (2) uni-modal feature gap and (3) cross-modal relation bias. Existing domain adaptation methods fail to address them comprehensively and precisely (e.g. at pixel level), thus being suboptimal for CQVS. To overcome this limitation, we propose Semantic-conditioned Dual Adaptation (SDA), a novel framework to achieve precise feature- and relation-invariant across domains via a universal semantic structure. The SDA consists of two key components: Content-aware Semantic Modeling (CSM) and Dual Adaptive Branches (DAB). First, CSM introduces a common semantic space across domains to provide uniform guidance. Then, DAB seamlessly leverages this semantic information to develop a contrastive feature branch for category-wise pixel alignment, and design a reciprocal relation branch for relation enhancement via two complementary masks. Extensive experiments on three video benchmarks and three image benchmarks evidence the superiority of our approach over the state-of-the-arts.</abstract>
      <url hash="ed4e581b">2023.findings-acl.621</url>
      <bibkey>wang-etal-2023-semantic</bibkey>
      <doi>10.18653/v1/2023.findings-acl.621</doi>
    </paper>
    <paper id="622">
      <title>Figurative Language Processing: A Linguistically Informed Feature Analysis of the Behavior of Language Models and Humans</title>
      <author><first>Hyewon</first><last>Jang</last><affiliation>University of Konstanz</affiliation></author>
      <author><first>Qi</first><last>Yu</last><affiliation>University of Konstanz</affiliation></author>
      <author><first>Diego</first><last>Frassinelli</last><affiliation>University of Konstanz</affiliation></author>
      <pages>9816-9832</pages>
      <abstract>Recent years have witnessed a growing interest in investigating what Transformer-based language models (TLMs) actually learn from the training data. This is especially relevant for complex tasks such as the understanding of non-literal meaning. In this work, we probe the performance of three black-box TLMs and two intrinsically transparent white-box models on figurative language classification of sarcasm, similes, idioms, and metaphors. We conduct two studies on the classification results to provide insights into the inner workings of such models. With our first analysis on feature importance, we identify crucial differences in model behavior. With our second analysis using an online experiment with human participants, we inspect different linguistic characteristics of the four figurative language types.</abstract>
      <url hash="b8c23707">2023.findings-acl.622</url>
      <bibkey>jang-etal-2023-figurative</bibkey>
      <doi>10.18653/v1/2023.findings-acl.622</doi>
    </paper>
    <paper id="623">
      <title>Taxonomy of Problems in Lexical Semantics</title>
      <author><first>Bradley</first><last>Hauer</last><affiliation>University of Alberta</affiliation></author>
      <author><first>Grzegorz</first><last>Kondrak</last><affiliation>University of Alberta</affiliation></author>
      <pages>9833-9844</pages>
      <abstract>Semantic tasks are rarely formally defined, and the exact relationship between them is an open question. We introduce a taxonomy that elucidates the connection between several problems in lexical semantics, including monolingual and cross-lingual variants. Our theoretical framework is based on the hypothesis of the equivalence of concept and meaning distinctions. Using algorithmic problem reductions, we demonstrate that all problems in the taxonomy can be reduced to word sense disambiguation (WSD), and that WSD itself can be reduced to some problems, making them theoretically equivalent. In addition, we carry out experiments that strongly support the soundness of the concept-meaning hypothesis, and the correctness of our reductions.</abstract>
      <url hash="d8dd0b08">2023.findings-acl.623</url>
      <bibkey>hauer-kondrak-2023-taxonomy</bibkey>
      <doi>10.18653/v1/2023.findings-acl.623</doi>
    </paper>
    <paper id="624">
      <title>Making Pre-trained Language Models both Task-solvers and Self-calibrators</title>
      <author><first>Yangyi</first><last>Chen</last><affiliation>UIUC</affiliation></author>
      <author><first>Xingyao</first><last>Wang</last><affiliation>University of Illinois Urbana-Champaign</affiliation></author>
      <author><first>Heng</first><last>Ji</last><affiliation>University of Illinois at Urbana-Champaign and Amazon (Amazon Scholar)</affiliation></author>
      <pages>9845-9862</pages>
      <abstract>Pre-trained language models (PLMs) serve as backbones for various real-world systems. For high-stake applications, it’s equally essential to have reasonable confidence estimations in predictions. While the vanilla confidence scores of PLMs can already be effectively utilized, PLMs consistently become overconfident in their wrong predictions, which is not desirable in practice. Previous work shows that introducing an extra calibration task can mitigate this issue. The basic idea involves acquiring additional data to train models in predicting the confidence of their initial predictions. However, it only demonstrates the feasibility of this kind of method, assuming that there are abundant extra available samples for the introduced calibration task. In this work, we consider the practical scenario that we need to effectively utilize training samples to make PLMs both task-solvers and self-calibrators. Three challenges are presented, including limited training samples, data imbalance, and distribution shifts. We first conduct pilot experiments to quantify various decisive factors in the calibration task. Based on the empirical analysis results, we propose a training algorithm LM-TOAST to tackle the challenges. Experimental results show that LM-TOAST can effectively utilize the training data to make PLMs have reasonable confidence estimations while maintaining the original task performance. Further, we consider three downstream applications, namely selective classification, adversarial defense, and model cascading, to show the practical usefulness of LM-TOAST.</abstract>
      <url hash="bc3f882e">2023.findings-acl.624</url>
      <bibkey>chen-etal-2023-making</bibkey>
      <doi>10.18653/v1/2023.findings-acl.624</doi>
    </paper>
    <paper id="625">
      <title><fixed-case>E</fixed-case>mbed<fixed-case>T</fixed-case>ext<fixed-case>N</fixed-case>et: Dimension Reduction with Weighted Reconstruction and Correlation Losses for Efficient Text Embedding</title>
      <author><first>Dae Yon</first><last>Hwang</last><affiliation>Amazon</affiliation></author>
      <author><first>Bilal</first><last>Taha</last><affiliation>University of Toronto</affiliation></author>
      <author><first>Yaroslav</first><last>Nechaev</last><affiliation>Amazon.com</affiliation></author>
      <pages>9863-9879</pages>
      <abstract>The size of embeddings generated by large language models can negatively affect system latency and model size in certain downstream practical applications (e.g. KNN search). In this work, we propose EmbedTextNet, a light add-on network that can be appended to an arbitrary language model to generate a compact embedding without requiring any changes in its architecture or training procedure. Specifically, we use a correlation penalty added to the weighted reconstruction loss that better captures the informative features in the text embeddings, which improves the efficiency of the language models. We evaluated EmbedTextNet on three different downstream tasks: text similarity, language modelling, and text retrieval. Empirical results on diverse benchmark datasets demonstrate the effectiveness and superiority of EmbedTextNet compared to state-of-art methodologies in recent works, especially in extremely low dimensional embedding sizes. The developed code for reproducibility is included in the supplementary material.</abstract>
      <url hash="8fbff9b1">2023.findings-acl.625</url>
      <bibkey>hwang-etal-2023-embedtextnet</bibkey>
      <doi>10.18653/v1/2023.findings-acl.625</doi>
    </paper>
    <paper id="626">
      <title>Denoising Enhanced Distantly Supervised Ultrafine Entity Typing</title>
      <author><first>Yue</first><last>Zhang</last><affiliation>Baidu</affiliation></author>
      <author><first>Hongliang</first><last>Fei</last><affiliation>Google</affiliation></author>
      <author><first>Ping</first><last>Li</last><affiliation>LinkedIn</affiliation></author>
      <pages>9880-9892</pages>
      <abstract>Recently, the task of distantly supervised (DS) ultra-fine entity typing has received significant attention. However, DS data is noisy and often suffers from missing or wrong labeling issues resulting in low precision and low recall. This paper proposes a novel ultra-fine entity typing model with denoising capability. Specifically, we build a noise model to estimate the unknown labeling noise distribution over input contexts and noisy type labels. With the noise model, more trustworthy labels can be recovered by subtracting the estimated noise from the input. Furthermore, we propose an entity typing model, which adopts a bi-encoder architecture, is trained on the denoised data. Finally, the noise model and entity typing model are trained iteratively to enhance each other. We conduct extensive experiments on the Ultra-Fine entity typing dataset as well as OntoNotes dataset and demonstrate that our approach significantly outperforms other baseline methods.</abstract>
      <url hash="1c0ccf9a">2023.findings-acl.626</url>
      <bibkey>zhang-etal-2023-denoising</bibkey>
      <doi>10.18653/v1/2023.findings-acl.626</doi>
    </paper>
    <paper id="627">
      <title><fixed-case>INT</fixed-case>apt: Information-Theoretic Adversarial Prompt Tuning for Enhanced Non-Native Speech Recognition</title>
      <author><first>Eunseop</first><last>Yoon</last><affiliation>Korea Advanced Institute of Science and Technology</affiliation></author>
      <author><first>Hee Suk</first><last>Yoon</last><affiliation>Korea Advanced Institute of Science and Technology</affiliation></author>
      <author><first>John</first><last>Harvill</last><affiliation>University of Illinois at Urbana-Champaign</affiliation></author>
      <author><first>Mark</first><last>Hasegawa-Johnson</last><affiliation>University of Illinois</affiliation></author>
      <author><first>Chang</first><last>Yoo</last><affiliation>kaist</affiliation></author>
      <pages>9893-9902</pages>
      <abstract>Automatic Speech Recognition (ASR) systems have attained unprecedented performance with large speech models pre-trained based on self-supervised speech representation learning. However, these pre-trained speech models suffer from representational bias as they tend to better represent those prominent accents (i.e., native (L1) English accent) in the pre-training speech corpus than less represented accents, resulting in a deteriorated performance for non-native (L2) English accents. Although there have been some approaches to mitigate this issue, all of these methods require updating the pre-trained model weights. In this paper, we propose Information Theoretic Adversarial Prompt Tuning (INTapt), which introduces prompts concatenated to the original input that can re-modulate the attention of the pre-trained model such that the corresponding input resembles a native (L1) English speech without updating the backbone weights. INTapt is trained simultaneously in the following two manners: (1) adversarial training to reduce accent feature dependence between the original input and the prompt-concatenated input and (2) training to minimize CTC loss for improving ASR performance to a prompt-concatenated input. Experimental results show that INTapt improves the performance of L2 English and increases feature similarity between L2 and L1 accents.</abstract>
      <url hash="e337f615">2023.findings-acl.627</url>
      <bibkey>yoon-etal-2023-intapt</bibkey>
      <doi>10.18653/v1/2023.findings-acl.627</doi>
    </paper>
    <paper id="628">
      <title>Local Temperature Beam Search: Avoid Neural Text <fixed-case>D</fixed-case>e<fixed-case>G</fixed-case>eneration via Enhanced Calibration</title>
      <author><first>Dongkyu</first><last>Lee</last><affiliation>Hong Kong University of Science and Technology</affiliation></author>
      <author><first>Gyeonghun</first><last>Kim</last><affiliation>LG AI Research</affiliation></author>
      <author><first>Janghoon</first><last>Han</last><affiliation>LG AI Research</affiliation></author>
      <author><first>Taesuk</first><last>Hong</last><affiliation>Sogang University</affiliation></author>
      <author><first>Yi-Reun</first><last>Kim</last><affiliation>LG AI Research</affiliation></author>
      <author><first>Stanley Jungkyu</first><last>Choi</last><affiliation>LG AI Research</affiliation></author>
      <author><first>Nevin L.</first><last>Zhang</last><affiliation>Hong Kong University of Science and Technology</affiliation></author>
      <pages>9903-9915</pages>
      <abstract>Previous studies have constantly observed that a language model repeats itself, creating repetitions in an output sequence. To cope with the issue, stochastic decoding schemes have been the de facto approaches; the strategies add randomness in inference, hence avoiding the “self-loop”. However, the remedy comes at the cost of sacrificing output quality due to the randomness involved. In this work, we introduce a deterministic decoding scheme, local temperature beam search. This inference algorithm is an embarrassingly simple variant of beam search, yet it reduces repetition, whose level is superior to that of a sampling-based decoding algorithm, while maintaining the level of coherence as in beam search. Our idea is rooted in the concept of model calibration; we view a repetition as a casualty from overconfidence in a model. Therefore, our work mitigates the miscalibration present in the course of inference with a post-calibration approach applied in beam-specific manner. Our inference scheme is validated on text completion tasks, in which the repetition problem is seen most clearly, and is exhaustively compared with existing inference schemes.</abstract>
      <url hash="eb096be1">2023.findings-acl.628</url>
      <bibkey>lee-etal-2023-local</bibkey>
      <doi>10.18653/v1/2023.findings-acl.628</doi>
    </paper>
    <paper id="629">
      <title>Explanation Graph Generation via Generative Pre-training over Synthetic Graphs</title>
      <author><first>Han</first><last>Cui</last><affiliation>Harbin Institute of Technology</affiliation></author>
      <author><first>Shangzhan</first><last>Li</last><affiliation>Harbin Institute of Technology</affiliation></author>
      <author><first>Yu</first><last>Zhang</last><affiliation>Harbin Institute of Technology</affiliation></author>
      <author><first>Qi</first><last>Shi</last><affiliation>Harbin Institute of Technology</affiliation></author>
      <pages>9916-9934</pages>
      <abstract>The generation of explanation graphs is a significant task that aims to produce explanation graphs in response to user input, revealing the internal reasoning process. This task is challenging due to the significant discrepancy be- tween unstructured user queries and structured explanation graphs. Current research commonly fine-tunes a text-based pre-trained language model on a small downstream dataset that is annotated with labeled graphs. However, due to the limited scale of available datasets, this approach may prove to be insufficient in bridging the gap between natural language text and structured graphs. In this paper, to alleviate the above limitations, we propose a novel pre-trained framework EG3P(for Explanation Graph Generation via Generative Pre-training over synthetic graphs) for the explanation graph generation task. Specifically, we first propose a text-to-graph generative task to pre-train the model with the goal of bridging the text-graph gap. Additionally, we propose an automatic corpus synthesis strategy for synthesizing a large scale of high-quality corpus, reducing the reliance on costly manual annotation methods. Experimental results on ExplaGraphs show the effectiveness of EG3P that our model surpasses all baseline systems with remarkable margins. Besides, further analysis demonstrates that EG3P is able to generate better explanation graphs on actual reasoning tasks such as CommonsenseQA and OpenbookQA.</abstract>
      <url hash="3f5782c8">2023.findings-acl.629</url>
      <bibkey>cui-etal-2023-explanation</bibkey>
      <doi>10.18653/v1/2023.findings-acl.629</doi>
    </paper>
    <paper id="630">
      <title><fixed-case>N</fixed-case>a<fixed-case>SGEC</fixed-case>: a Multi-Domain <fixed-case>C</fixed-case>hinese Grammatical Error Correction Dataset from Native Speaker Texts</title>
      <author><first>Yue</first><last>Zhang</last><affiliation>Soochow University</affiliation></author>
      <author><first>Bo</first><last>Zhang</last><affiliation>alibaba-inc.com</affiliation></author>
      <author><first>Haochen</first><last>Jiang</last><affiliation>Soochow University</affiliation></author>
      <author><first>Zhenghua</first><last>Li</last><affiliation>Soochow University</affiliation></author>
      <author><first>Chen</first><last>Li</last><affiliation>Alibaba</affiliation></author>
      <author><first>Fei</first><last>Huang</last><affiliation>Alibaba DAMO Academy</affiliation></author>
      <author><first>Min</first><last>Zhang</last><affiliation>Harbin Institute of Technology (Shenzhen)</affiliation></author>
      <pages>9935-9951</pages>
      <abstract>We introduce NaSGEC, a new dataset to facilitate research on Chinese grammatical error correction (CGEC) for native speaker texts from multiple domains. Previous CGEC research primarily focuses on correcting texts from a single domain, especially learner essays. To broaden the target domain, we annotate multiple references for 12,500 sentences from three native domains, i.e., social media, scientific writing, and examination. We provide solid benchmark results for NaSGEC by employing cutting-edge CGEC models and different training data. We further perform detailed analyses of the connections and gaps between our domains from both empirical and statistical views. We hope this work can inspire future studies on an important but under-explored direction–cross-domain GEC.</abstract>
      <url hash="15127d77">2023.findings-acl.630</url>
      <bibkey>zhang-etal-2023-nasgec</bibkey>
      <doi>10.18653/v1/2023.findings-acl.630</doi>
    </paper>
    <paper id="631">
      <title><fixed-case>FORK</fixed-case>: A Bite-Sized Test Set for Probing Culinary Cultural Biases in Commonsense Reasoning Models</title>
      <author><first>Shramay</first><last>Palta</last><affiliation>Department of Computer Science, University of Maryland</affiliation></author>
      <author><first>Rachel</first><last>Rudinger</last><affiliation>University of Maryland</affiliation></author>
      <pages>9952-9962</pages>
      <abstract>It is common sense that one should prefer to eat a salad with a fork rather than with a chainsaw. However, for eating a bowl of rice, the choice between a fork and a pair of chopsticks is culturally relative. We introduce FORK, a small, manually-curated set of CommonsenseQA-style questions for probing cultural biases and assumptions present in commonsense reasoning systems, with a specific focus on food-related customs. We test several CommonsenseQA systems on FORK, and while we see high performance on questions about the US culture, the poor performance of these systems on questions about non-US cultures highlights systematic cultural assumptions aligned with US over non-US cultures.</abstract>
      <url hash="cd5418de">2023.findings-acl.631</url>
      <bibkey>palta-rudinger-2023-fork</bibkey>
      <doi>10.18653/v1/2023.findings-acl.631</doi>
    </paper>
    <paper id="632">
      <title><fixed-case>F</fixed-case>ed<fixed-case>PET</fixed-case>uning: When Federated Learning Meets the Parameter-Efficient Tuning Methods of Pre-trained Language Models</title>
      <author><first>Zhuo</first><last>Zhang</last><affiliation>Harbin Institute of Technology, Shenzhen</affiliation></author>
      <author><first>Yuanhang</first><last>Yang</last><affiliation>Harbin Institute of Technology, Shenzhen</affiliation></author>
      <author><first>Yong</first><last>Dai</last><affiliation>Tencent AI Lab</affiliation></author>
      <author><first>Qifan</first><last>Wang</last><affiliation>Meta AI</affiliation></author>
      <author><first>Yue</first><last>Yu</last><affiliation>Pengcheng lab</affiliation></author>
      <author><first>Lizhen</first><last>Qu</last><affiliation>Monash University</affiliation></author>
      <author><first>Zenglin</first><last>Xu</last><affiliation>Harbin Institute of Technology, Shenzhen</affiliation></author>
      <pages>9963-9977</pages>
      <abstract>With increasing concerns about data privacy, there is an increasing necessity of fine-tuning pre-trained language models (PLMs) for adapting to downstream tasks located in end-user devices or local clients without transmitting data to the central server. This urgent necessity therefore calls the research of investigating federated learning (FL) for PLMs. However, large PLMs bring the curse of prohibitive communication overhead and local model adaptation costs for the FL system. To this end, we investigate the parameter-efficient tuning (PETuning) of PLMs and develop a corresponding federated benchmark for four representative PETuning methods, dubbed FedPETuning. Specifically, FedPETuning provides the first holistic empirical study of representative PLMs tuning methods in FL, covering privacy attacks, performance comparisons, and resource-constrained analysis. Intensive experimental results have indicated that FedPETuning can efficiently defend against privacy attacks and maintains acceptable performance with reducing heavy resource consumption. The open-source code and data are available at <url>https://github.com/SMILELab-FL/FedPETuning</url>.</abstract>
      <url hash="7fcc2bb3">2023.findings-acl.632</url>
      <bibkey>zhang-etal-2023-fedpetuning</bibkey>
      <doi>10.18653/v1/2023.findings-acl.632</doi>
    </paper>
    <paper id="633">
      <title><fixed-case>M</fixed-case>ix<fixed-case>PAVE</fixed-case>: Mix-Prompt Tuning for Few-shot Product Attribute Value Extraction</title>
      <author><first>Li</first><last>Yang</last><affiliation>Google Research</affiliation></author>
      <author><first>Qifan</first><last>Wang</last><affiliation>Meta AI</affiliation></author>
      <author><first>Jingang</first><last>Wang</last><affiliation>Meituan</affiliation></author>
      <author><first>Xiaojun</first><last>Quan</last><affiliation>School of Computer Science and Engineering, Sun Yat-sen University</affiliation></author>
      <author><first>Fuli</first><last>Feng</last><affiliation>University of Science and Technology of China</affiliation></author>
      <author><first>Yu</first><last>Chen</last><affiliation>Meta</affiliation></author>
      <author><first>Madian</first><last>Khabsa</last><affiliation>Facebook</affiliation></author>
      <author><first>Sinong</first><last>Wang</last><affiliation>Facebook AI</affiliation></author>
      <author><first>Zenglin</first><last>Xu</last><affiliation>Harbin Institute of Technology, Shenzhen</affiliation></author>
      <author><first>Dongfang</first><last>Liu</last><affiliation>Rochester Institute of Technology</affiliation></author>
      <pages>9978-9991</pages>
      <abstract>The task of product attribute value extraction is to identify values of an attribute from product information. Product attributes are important features, which help improve online shopping experience of customers, such as product search, recommendation and comparison. Most existing works only focus on extracting values for a set of known attributes with sufficient training data. However, with the emerging nature of e-commerce, new products with their unique set of new attributes are constantly generated from different retailers and merchants. Collecting a large number of annotations for every new attribute is costly and time consuming. Therefore, it is an important research problem for product attribute value extraction with limited data. In this work, we propose a novel prompt tuning approach with <b>Mix</b>ed <b>P</b>rompts for few-shot <b>A</b>ttribute <b>V</b>alue <b>E</b>xtraction, namely MixPAVE. Specifically, MixPAVE introduces only a small amount (&lt; 1%) of trainable parameters, i.e., a mixture of two learnable prompts, while keeping the existing extraction model frozen. In this way, MixPAVE not only benefits from parameter-efficient training, but also avoids model overfitting on limited training examples. Experimental results on two product benchmarks demonstrate the superior performance of the proposed approach over several state-of-the-art baselines. A comprehensive set of ablation studies validate the effectiveness of the prompt design, as well as the efficiency of our approach.</abstract>
      <url hash="ebdc2540">2023.findings-acl.633</url>
      <bibkey>yang-etal-2023-mixpave</bibkey>
      <doi>10.18653/v1/2023.findings-acl.633</doi>
    </paper>
    <paper id="634">
      <title><fixed-case>S</fixed-case>low<fixed-case>BERT</fixed-case>: Slow-down Attacks on Input-adaptive Multi-exit <fixed-case>BERT</fixed-case></title>
      <author><first>Shengyao</first><last>Zhang</last><affiliation>Fudan University</affiliation></author>
      <author><first>Xudong</first><last>Pan</last><affiliation>Fudan University</affiliation></author>
      <author><first>Mi</first><last>Zhang</last><affiliation>Fudan University</affiliation></author>
      <author><first>Min</first><last>Yang</last><affiliation>Fudan University</affiliation></author>
      <pages>9992-10007</pages>
      <abstract>For pretrained language models such as Google’s BERT, recent research designs several input-adaptive inference mechanisms to improve the efficiency on cloud and edge devices. In this paper, we reveal a new attack surface on input-adaptive multi-exit BERT, where the adversary imperceptibly modifies the input texts to drastically increase the average inference cost. Our proposed slow-down attack called <i>SlowBERT</i> integrates a new rank-and-substitute adversarial text generation algorithm to efficiently search for the perturbation which maximally delays the exiting time. With no direct access to the model internals, we further devise a <i>time-based approximation algorithm</i> to infer the exit position as the loss oracle. Our extensive evaluation on two popular instances of multi-exit BERT for GLUE classification tasks validates the effectiveness of SlowBERT. In the worst case, SlowBERT increases the inference cost by <tex-math>4.57\times</tex-math>, which would strongly hurt the service quality of multi-exit BERT in practice, e.g., increasing the real-time cloud services’ response times for online users.</abstract>
      <url hash="c85759d6">2023.findings-acl.634</url>
      <bibkey>zhang-etal-2023-slowbert</bibkey>
      <doi>10.18653/v1/2023.findings-acl.634</doi>
    </paper>
    <paper id="635">
      <title>Compositional Mathematical Encoding for Math Word Problems</title>
      <author><first>Zhenwen</first><last>Liang</last><affiliation>University of Notre Dame</affiliation></author>
      <author><first>Jipeng</first><last>Zhang</last><affiliation>Hong Kong University of Science and Technology</affiliation></author>
      <author><first>Kehan</first><last>Guo</last><affiliation>University of Notre Dame</affiliation></author>
      <author><first>Xiaodong</first><last>Wu</last><affiliation>Queen’s University</affiliation></author>
      <author><first>Jie</first><last>Shao</last><affiliation>University of Electronic Science and Technology of China</affiliation></author>
      <author><first>Xiangliang</first><last>Zhang</last><affiliation>University of Notre Dame</affiliation></author>
      <pages>10008-10017</pages>
      <abstract>Solving math word problem (MWP) remains a challenging task, as it requires to understand both the semantic meanings of the text and the mathematical logic among quantities, i.e., for both semantics modal and quantity modal learning. Current MWP encoders work in a uni-modal setting and map the given problem description to a latent representation, then for decoding. The generalizability of these MWP encoders is thus limited because some problems are semantics-demanding and others are quantity-demanding. To address this problem, we propose a Compositional Math Word Problem Solver (C-MWP) which works in a bi-modal setting encoding in an interactive way. Extensive experiments validate the effectiveness of C-MWP and show its superiority over state-of-the-art models on public benchmarks.</abstract>
      <url hash="4619af87">2023.findings-acl.635</url>
      <bibkey>liang-etal-2023-compositional</bibkey>
      <doi>10.18653/v1/2023.findings-acl.635</doi>
    </paper>
    <paper id="636">
      <title><fixed-case>PREADD</fixed-case>: Prefix-Adaptive Decoding for Controlled Text Generation</title>
      <author><first>Jonathan</first><last>Pei</last><affiliation>University of California, Berkeley</affiliation></author>
      <author><first>Kevin</first><last>Yang</last><affiliation>UC Berkeley</affiliation></author>
      <author><first>Dan</first><last>Klein</last><affiliation>UC Berkeley / Microsoft</affiliation></author>
      <pages>10018-10037</pages>
      <abstract>We propose Prefix-Adaptive Decoding (PREADD), a flexible method for controlled text generation. Unlike existing methods that use auxiliary expert models to control for attributes, PREADD does not require an external model, instead relying on linearly combining output logits from multiple prompts. Specifically, PREADD contrasts the output logits generated using a raw prompt against those generated using a prefix-prepended prompt, enabling both positive and negative control with respect to any attribute encapsulated by the prefix. We evaluate PREADD on three tasks—toxic output mitigation, gender bias reduction, and sentiment control—and find that PREADD outperforms not only prompting baselines, but also an auxiliary-expert control method, by 12% or more in relative gain on our main metrics for each task.</abstract>
      <url hash="9d509dd9">2023.findings-acl.636</url>
      <bibkey>pei-etal-2023-preadd</bibkey>
      <doi>10.18653/v1/2023.findings-acl.636</doi>
    </paper>
    <paper id="637">
      <title><fixed-case>E</fixed-case>vent<fixed-case>OA</fixed-case>: An Event Ontology Alignment Benchmark Based on <fixed-case>F</fixed-case>rame<fixed-case>N</fixed-case>et and <fixed-case>W</fixed-case>ikidata</title>
      <author><first>Shaoru</first><last>Guo</last><affiliation>Institute of Automation,Chinese Academy of Sciences</affiliation></author>
      <author><first>Chenhao</first><last>Wang</last><affiliation>Institute of Automation, China Academy of Sciences</affiliation></author>
      <author><first>Yubo</first><last>Chen</last><affiliation>Institute of Automation, Chinese Academy of Sciences</affiliation></author>
      <author><first>Kang</first><last>Liu</last><affiliation>Institute of Automation, Chinese Academy of Sciences</affiliation></author>
      <author><first>Ru</first><last>Li</last><affiliation>School of Computer and Information Technology,Shanxi University</affiliation></author>
      <author><first>Jun</first><last>Zhao</last><affiliation>NLPR, Institute of Automation, Chinese Academy of Sciences</affiliation></author>
      <pages>10038-10052</pages>
      <abstract>Event ontology provides a shared and formal specification about what happens in the real world and can benefit many natural language understanding tasks. However, the independent development of event ontologies often results in heterogeneous representations that raise the need for establishing alignments between semantically related events. There exists a series of works about ontology alignment (OA), but they only focus on the entity-based OA, and neglect the event-based OA. To fill the gap, we construct an Event Ontology Alignment (EventOA) dataset based on FrameNet and Wikidata, which consists of 900+ event type alignments and 8,000+ event argument alignments. Furthermore, we propose a multi-view event ontology alignment (MEOA) method, which utilizes description information (i.e., name, alias and definition) and neighbor information (i.e., subclass and superclass) to obtain richer representation of the event ontologies. Extensive experiments show that our MEOA outperforms the existing entity-based OA methods and can serve as a strong baseline for EventOA research.</abstract>
      <url hash="7544ce9f">2023.findings-acl.637</url>
      <bibkey>guo-etal-2023-eventoa</bibkey>
      <doi>10.18653/v1/2023.findings-acl.637</doi>
    </paper>
    <paper id="638">
      <title>Enhancing Continual Relation Extraction via Classifier Decomposition</title>
      <author><first>Heming</first><last>Xia</last><affiliation>Peking University</affiliation></author>
      <author><first>Peiyi</first><last>Wang</last><affiliation>Peking University</affiliation></author>
      <author><first>Tianyu</first><last>Liu</last><affiliation>Peking University</affiliation></author>
      <author><first>Binghuai</first><last>Lin</last><affiliation>Tencent</affiliation></author>
      <author><first>Yunbo</first><last>Cao</last><affiliation>Tencent Corporation</affiliation></author>
      <author><first>Zhifang</first><last>Sui</last><affiliation>Peking University</affiliation></author>
      <pages>10053-10062</pages>
      <abstract>Continual relation extraction (CRE) models aim at handling emerging new relations while avoiding catastrophically forgetting old ones in the streaming data. Though improvements have been shown by previous CRE studies, most of them only adopt a vanilla strategy when models first learn representations of new relations. In this work, we point out that there exist two typical biases after training of this vanilla strategy: classifier bias and representation bias, which causes the previous knowledge that the model learned to be shaded. To alleviate those biases, we propose a simple yet effective classifier decomposition framework that splits the last FFN layer into separated previous and current classifiers, so as to maintain previous knowledge and encourage the model to learn more robust representations at this training stage. Experimental results on two standard benchmarks show that our proposed framework consistently outperforms the state-of-the-art CRE models, which indicates that the importance of the first training stage to CRE models may be underestimated. Our code will be released upon acceptance.</abstract>
      <url hash="10818add">2023.findings-acl.638</url>
      <bibkey>xia-etal-2023-enhancing</bibkey>
      <doi>10.18653/v1/2023.findings-acl.638</doi>
    </paper>
    <paper id="639">
      <title>A Comparative Analysis of the Effectiveness of Rare Tokens on Creative Expression using ram<fixed-case>BERT</fixed-case></title>
      <author><first>Youbin</first><last>Lee</last><affiliation>Department of Software Science and Engineering</affiliation></author>
      <author><first>Deokgi</first><last>Kim</last><affiliation>Department of Software Science and Engineering at Kunsan National University</affiliation></author>
      <author><first>Byung-Won</first><last>On</last><affiliation>Kunsan National University</affiliation></author>
      <author><first>Ingyu</first><last>Lee</last><affiliation>Yeungnam University</affiliation></author>
      <pages>10063-10077</pages>
      <abstract>Until now, few studies have been explored on Automated Creative Essay Scoring (ACES), in which a pre-trained model automatically labels an essay as a creative or a non-creative. Since the creativity evaluation of essays is very subjective, each evaluator often has his or her own criteria for creativity. For this reason, quantifying creativity in essays is very challenging. In this work, as one of preliminary studies in developing a novel model for ACES, we deeply investigate the correlation between creative essays and expressiveness. Specifically, we explore how rare tokens affect the evaluation of creativity for essays. For such a journey, we present five distinct methods to extract rare tokens, and conduct a comparative study on the correlation between rare tokens and creative essay evaluation results using BERT. Our experimental results showed clear correlation between rare tokens and creative essays. In all test sets, accuracies of our rare token masking-based BERT (ramBERT) model were improved over the existing BERT model up to 14%.</abstract>
      <url hash="0e31ca70">2023.findings-acl.639</url>
      <bibkey>lee-etal-2023-comparative</bibkey>
      <doi>10.18653/v1/2023.findings-acl.639</doi>
    </paper>
    <paper id="640">
      <title><fixed-case>MTR</fixed-case>: A Dataset Fusing Inductive, Deductive, and Defeasible Reasoning</title>
      <author><first>Yitian</first><last>Li</last><affiliation>Shanghai Jiao Tong University</affiliation></author>
      <author><first>Jidong</first><last>Tian</last><affiliation>State Key Lab of Advanced Optical Communication System and Network, Shanghai Jiao Tong University; Artificial Intelligence Institute, Shanghai Jiao Tong University</affiliation></author>
      <author><first>Caoyun</first><last>Fan</last><affiliation>Shanghai Jiaotong University</affiliation></author>
      <author><first>Wenqing</first><last>Chen</last><affiliation>Sun Yat-Sen University</affiliation></author>
      <author><first>Hao</first><last>He</last><affiliation>Shanghai Jiao Tong University</affiliation></author>
      <author><first>Yaohui</first><last>Jin</last><affiliation>Shanghai Jiao Tong University</affiliation></author>
      <pages>10078-10089</pages>
      <abstract>A long-standing difficulty in AI is the introduction of human-like reasoning in machine reading comprehension. Since algorithmic models can already perform as well as humans on simple quality assurance tasks thanks to the development of deep learning techniques, more difficult reasoning datasets have been presented. However, these datasets mainly focus on a single type of reasoning. There are still significant gaps in the studies when compared to the complex reasoning used in daily life. In this work, we introduce a brand-new dataset, named MTR. There are two parts to it: the first combines deductive and inductive reasoning, and the second does the same with inductive and defeasible reasoning. It consists of more than 30k QA instances, inferring relations between characters in short stories. Results show that state-of-the-art neural models do noticeably worse than expected. Our empirical results highlight the gap in the models’ ability to handle sophisticated inference.</abstract>
      <url hash="d624005e">2023.findings-acl.640</url>
      <bibkey>li-etal-2023-mtr</bibkey>
      <doi>10.18653/v1/2023.findings-acl.640</doi>
    </paper>
    <paper id="641">
      <title><fixed-case>N</fixed-case>ews<fixed-case>M</fixed-case>et : A ‘do it all’ Dataset of Contemporary Metaphors in News Headlines</title>
      <author><first>Rohan</first><last>Joseph</last><affiliation>Mahindra University</affiliation></author>
      <author><first>Timothy</first><last>Liu</last><affiliation>Singapore University of Technology and Design</affiliation></author>
      <author><first>Aik Beng</first><last>Ng</last><affiliation>NVIDIA AI Technology Centre</affiliation></author>
      <author><first>Simon</first><last>See</last><affiliation>nvidia</affiliation></author>
      <author><first>Sunny</first><last>Rai</last><affiliation>University of Pennsylvania</affiliation></author>
      <pages>10090-10104</pages>
      <abstract>Metaphors are highly creative constructs of human language that grow old and eventually die. Popular datasets used for metaphor processing tasks were constructed from dated source texts. In this paper, we propose NewsMet, a large high-quality contemporary dataset of news headlines hand-annotated with metaphorical verbs. The dataset comprises headlines from various sources including political, satirical, reliable and fake. Our dataset serves the purpose of evaluation for the tasks of metaphor interpretation and generation. The experiments reveal several insights and limitations of using LLMs to automate metaphor processing tasks as frequently seen in the recent literature. The dataset is publicly available for research purposes <url>https://github.com/AxleBlaze3/NewsMet_Metaphor_Dataset</url>.</abstract>
      <url hash="6abe629b">2023.findings-acl.641</url>
      <bibkey>joseph-etal-2023-newsmet</bibkey>
      <doi>10.18653/v1/2023.findings-acl.641</doi>
    </paper>
    <paper id="642">
      <title><fixed-case>C</fixed-case>oncept2<fixed-case>B</fixed-case>ox: Joint Geometric Embeddings for Learning Two-View Knowledge Graphs</title>
      <author><first>Zijie</first><last>Huang</last><affiliation>University of California, Los Angeles</affiliation></author>
      <author><first>Daheng</first><last>Wang</last><affiliation>Amazon</affiliation></author>
      <author><first>Binxuan</first><last>Huang</last><affiliation>Amazon</affiliation></author>
      <author><first>Chenwei</first><last>Zhang</last><affiliation>Amazon</affiliation></author>
      <author><first>Jingbo</first><last>Shang</last><affiliation>University of California, San Diego</affiliation></author>
      <author><first>Yan</first><last>Liang</last><affiliation>Amazon</affiliation></author>
      <author><first>Zhengyang</first><last>Wang</last><affiliation>Amazon.com</affiliation></author>
      <author><first>Xian</first><last>Li</last><affiliation>Amazon</affiliation></author>
      <author><first>Christos</first><last>Faloutsos</last><affiliation>CMU</affiliation></author>
      <author><first>Yizhou</first><last>Sun</last><affiliation>UCLA</affiliation></author>
      <author><first>Wei</first><last>Wang</last><affiliation>UCLA</affiliation></author>
      <pages>10105-10118</pages>
      <abstract>Knowledge graph embeddings (KGE) have been extensively studied to embed large-scale relational data for many real-world applications. Existing methods have long ignored the fact many KGs contain two fundamentally different views: high-level ontology-view concepts and fine-grained instance-view entities. They usually embed all nodes as vectors in one latent space. However, a single geometric representation fails to capture the structural differences between two views and lacks probabilistic semantics towards concepts’ granularity. We propose Concept2Box, a novel approach that jointly embeds the two views of a KG using dual geometric representations. We model concepts with box embeddings, which learn the hierarchy structure and complex relations such as overlap and disjoint among them. Box volumes can be interpreted as concepts’ granularity. Different from concepts, we model entities as vectors. To bridge the gap between concept box embeddings and entity vector embeddings, we propose a novel vector-to-box distance metric and learn both embeddings jointly. Experiments on both the public DBpedia KG and a newly-created industrial KG showed the effectiveness of Concept2Box.</abstract>
      <url hash="64f318ed">2023.findings-acl.642</url>
      <bibkey>huang-etal-2023-concept2box</bibkey>
      <doi>10.18653/v1/2023.findings-acl.642</doi>
    </paper>
    <paper id="643">
      <title>Noise-Robust Training with Dynamic Loss and Contrastive Learning for Distantly-Supervised Named Entity Recognition</title>
      <author><first>Zhiyuan</first><last>Ma</last><affiliation>Ant Group</affiliation></author>
      <author><first>Jintao</first><last>Du</last><affiliation>Ant Group</affiliation></author>
      <author><first>Shuheng</first><last>Zhou</last><affiliation>Ant Group</affiliation></author>
      <pages>10119-10128</pages>
      <abstract>Distantly-supervised named entity recognition (NER) aims at training networks with distantly-labeled data, which is automatically obtained by matching entity mentions in the raw text with entity types in a knowledge base. Distant supervision may induce incomplete and noisy labels, so recent state-of-the-art methods employ sample selection mechanism to separate clean data from noisy data based on the model’s prediction scores. However, they ignore the noise distribution change caused by data selection, and they simply excludes noisy data during training, resulting in information loss. We propose to (1) use a dynamic loss function to better adapt to the changing noise during the training process, and (2) incorporate token level contrastive learning to fully utilize the noisy data as well as facilitate feature learning without relying on labels. Our method achieves superior performance on three benchmark datasets, outperforming existing distantly supervised NER models by significant margins.</abstract>
      <url hash="fe69e2ae">2023.findings-acl.643</url>
      <bibkey>ma-etal-2023-noise</bibkey>
      <doi>10.18653/v1/2023.findings-acl.643</doi>
    </paper>
    <paper id="644">
      <title>Take a Break in the Middle: Investigating Subgoals towards Hierarchical Script Generation</title>
      <author><first>Xinze</first><last>Li</last><affiliation>Nanyang Technology University</affiliation></author>
      <author><first>Yixin</first><last>Cao</last><affiliation>Singapore Management University</affiliation></author>
      <author><first>Muhao</first><last>Chen</last><affiliation>USC</affiliation></author>
      <author><first>Aixin</first><last>Sun</last><affiliation>Nanyang Technological University</affiliation></author>
      <pages>10129-10147</pages>
      <abstract>Goal-oriented Script Generation is a new task of generating a list of steps that can fulfill the given goal. In this paper, we propose to extend the task from the perspective of cognitive theory. Instead of a simple flat structure, the steps are typically organized hierarchically — Human often decompose a complex task into subgoals, where each subgoal can be further decomposed into steps. To establish the benchmark, we contribute a new dataset, propose several baseline methods, and set up evaluation metrics. Both automatic and human evaluation verify the high-quality of dataset, as well as the effectiveness of incorporating subgoals into hierarchical script generation. Furthermore, We also design and evaluate the model to discover subgoal, and find that it is a bit more difficult to decompose the goals than summarizing from segmented steps.</abstract>
      <url hash="3c56051e">2023.findings-acl.644</url>
      <bibkey>li-etal-2023-take</bibkey>
      <doi>10.18653/v1/2023.findings-acl.644</doi>
    </paper>
    <paper id="645">
      <title>End-to-End Task-Oriented Dialogue Systems Based on Schema</title>
      <author><first>Wiradee</first><last>Imrattanatrai</last><affiliation>National Institute of Advanced Industrial Science and Technology</affiliation></author>
      <author><first>Ken</first><last>Fukuda</last><affiliation>AIRC/AIST</affiliation></author>
      <pages>10148-10161</pages>
      <abstract>This paper presents a schema-aware end-to-end neural network model for handling task-oriented dialogues based on a dynamic set of slots within a schema. Contrary to existing studies that proposed end-to-end approaches for task-oriented dialogue systems by relying on a unified schema across domains, we design our approach to support a domain covering multiple services where diverse schemas are available. To enable better generalizability among services and domains with different schemas, we supply the schema’s context information including slot descriptions and value constraints to the model. The experimental results on a well-known Schema-Guided Dialogue (SGD) dataset demonstrated the performance improvement by the proposed model compared to state-of-the-art baselines in terms of end-to-end modeling, dialogue state tracking task, and generalization on new services and domains using a limited number of dialogues.</abstract>
      <url hash="5edeae2d">2023.findings-acl.645</url>
      <bibkey>imrattanatrai-fukuda-2023-end</bibkey>
      <doi>10.18653/v1/2023.findings-acl.645</doi>
    </paper>
    <paper id="646">
      <title><fixed-case>H</fixed-case>a<fixed-case>VQA</fixed-case>: A Dataset for Visual Question Answering and Multimodal Research in <fixed-case>H</fixed-case>ausa Language</title>
      <author><first>Shantipriya</first><last>Parida</last><affiliation>Silo AI</affiliation></author>
      <author><first>Idris</first><last>Abdulmumin</last><affiliation>Ahmadu Bello University, Zaria</affiliation></author>
      <author><first>Shamsuddeen Hassan</first><last>Muhammad</last><affiliation>Bayero University, Kano</affiliation></author>
      <author><first>Aneesh</first><last>Bose</last><affiliation>Microsoft</affiliation></author>
      <author><first>Guneet Singh</first><last>Kohli</last><affiliation>Thapar University</affiliation></author>
      <author><first>Ibrahim Said</first><last>Ahmad</last><affiliation>Bayero University Kano</affiliation></author>
      <author><first>Ketan</first><last>Kotwal</last><affiliation>Idiap Research Institute</affiliation></author>
      <author><first>Sayan</first><last>Deb Sarkar</last><affiliation>ETH Zurich</affiliation></author>
      <author><first>Ondřej</first><last>Bojar</last><affiliation>Charles University, MFF UFAL</affiliation></author>
      <author><first>Habeebah</first><last>Kakudi</last><affiliation>Bayero University, Kano</affiliation></author>
      <pages>10162-10183</pages>
      <abstract>This paper presents “HaVQA”, the first multimodal dataset for visual question answering (VQA) tasks in the Hausa language. The dataset was created by manually translating 6,022 English question-answer pairs, which are associated with 1,555 unique images from the Visual Genome dataset. As a result, the dataset provides 12,044 gold standard English-Hausa parallel sentences that were translated in a fashion that guarantees their semantic match with the corresponding visual information. We conducted several baseline experiments on the dataset, including visual question answering, visual question elicitation, text-only and multimodal machine translation.</abstract>
      <url hash="a2103ba7">2023.findings-acl.646</url>
      <bibkey>parida-etal-2023-havqa</bibkey>
      <doi>10.18653/v1/2023.findings-acl.646</doi>
    </paper>
    <paper id="647">
      <title>Claim-Dissector: An Interpretable Fact-Checking System with Joint Re-ranking and Veracity Prediction</title>
      <author><first>Martin</first><last>Fajcik</last><affiliation>Brno University of Technology</affiliation></author>
      <author><first>Petr</first><last>Motlicek</last><affiliation>Idiap Research Institute</affiliation></author>
      <author><first>Pavel</first><last>Smrz</last><affiliation>Brno University of Technology</affiliation></author>
      <pages>10184-10205</pages>
      <abstract>We present Claim-Dissector: a novel latent variable model for fact-checking and analysis, which given a claim and a set of retrieved evidence jointly learns to identify: (i) the relevant evidences to the given claim (ii) the veracity of the claim. We propose to disentangle the per-evidence relevance probability and its contribution to the final veracity probability in an interpretable way — the final veracity probability is proportional to a linear ensemble of per-evidence relevance probabilities. In this way, the individual contributions of evidences towards the final predicted probability can be identified. In per-evidence relevance probability, our model can further distinguish whether each relevant evidence is supporting (S) or refuting (R) the claim. This allows to quantify how much the S/R probability contributes to final verdict or to detect disagreeing evidence. Despite its interpretable nature, our system achieves results competetive with state-of-the-art on the FEVER dataset, as compared to typical two-stage system pipelines, while using significantly fewer parameters. Furthermore, our analysis shows that our model can learn fine-grained relevance cues while using coarse-grained supervision and we demonstrate it in 2 ways. (i) We show that our model can achieve competitive sentence recall while using only paragraph-level relevance supervision. (ii) Traversing towards the finest granularity of relevance, we show that our model is capable of identifying relevance at the token level. To do this, we present a new benchmark TLR-FEVER focusing on token-level interpretability — humans annotate tokens in relevant evidences they considered essential when making their judgment. Then we measure how similar are these annotations to the tokens our model is focusing on.</abstract>
      <url hash="6470b876">2023.findings-acl.647</url>
      <bibkey>fajcik-etal-2023-claim</bibkey>
      <doi>10.18653/v1/2023.findings-acl.647</doi>
    </paper>
    <paper id="648">
      <title><fixed-case>S</fixed-case>truct<fixed-case>SP</fixed-case>: Efficient Fine-tuning of Task-Oriented Dialog System by Using Structure-aware Boosting and Grammar Constraints</title>
      <author><first>Truong</first><last>Do</last><affiliation>Japan Advanced Institute of Science and Technology (JAIST)</affiliation></author>
      <author><first>Phuong</first><last>Nguyen</last><affiliation>Japan Advanced Institute of Science and Technology</affiliation></author>
      <author><first>Minh</first><last>Nguyen</last><affiliation>JAIST</affiliation></author>
      <pages>10206-10220</pages>
      <abstract>We have investigated methods utilizing hierarchical structure information representation in the semantic parsing task and have devised a method that reinforces the semantic awareness of a pre-trained language model via a two-step fine-tuning mechanism: hierarchical structure information strengthening and a final specific task. The model used is better than existing ones at learning the contextual representations of utterances embedded within its hierarchical semantic structure and thereby improves system performance. In addition, we created a mechanism using inductive grammar to dynamically prune the unpromising directions in the semantic structure parsing process. Finally, through experimentsOur code will be published when this paper is accepted. on the TOP and TOPv2 (low-resource setting) datasets, we achieved state-of-the-art (SOTA) performance, confirming the effectiveness of our proposed model.</abstract>
      <url hash="790856c2">2023.findings-acl.648</url>
      <bibkey>do-etal-2023-structsp</bibkey>
      <doi>10.18653/v1/2023.findings-acl.648</doi>
    </paper>
    <paper id="649">
      <title><fixed-case>GDA</fixed-case>: Generative Data Augmentation Techniques for Relation Extraction Tasks</title>
      <author><first>Xuming</first><last>Hu</last><affiliation>School of Software, Tsinghua University</affiliation></author>
      <author><first>Aiwei</first><last>Liu</last><affiliation>School of Software, Tsinghua University</affiliation></author>
      <author><first>Zeqi</first><last>Tan</last><affiliation>Zhejiang University</affiliation></author>
      <author><first>Xin</first><last>Zhang</last><affiliation>Harbin Institute of Technology (Shenzhen)</affiliation></author>
      <author><first>Chenwei</first><last>Zhang</last><affiliation>Amazon</affiliation></author>
      <author><first>Irwin</first><last>King</last><affiliation>The Chinese University of Hong Kong</affiliation></author>
      <author><first>Philip S.</first><last>Yu</last><affiliation>University of Illinois at Chicago</affiliation></author>
      <pages>10221-10234</pages>
      <abstract>Relation extraction (RE) tasks show promising performance in extracting relations from two entities mentioned in sentences, given sufficient annotations available during training. Such annotations would be labor-intensive to obtain in practice. Existing work adopts data augmentation techniques to generate pseudo-annotated sentences beyond limited annotations. These techniques neither preserve the semantic consistency of the original sentences when rule-based augmentations are adopted, nor preserve the syntax structure of sentences when expressing relations using seq2seq models, resulting in less diverse augmentations. In this work, we propose a dedicated augmentation technique for relational texts, named GDA, which uses two complementary modules to preserve both semantic consistency and syntax structures. We adopt a generative formulation and design a multi-tasking solution to achieve synergies. Furthermore, GDA adopts entity hints as the prior knowledge of the generative model to augment diverse sentences. Experimental results in three datasets under a low-resource setting showed that GDA could bring <i>2.0%</i> F1 improvements compared with no augmentation technique.</abstract>
      <url hash="9956abbd">2023.findings-acl.649</url>
      <bibkey>hu-etal-2023-gda</bibkey>
      <doi>10.18653/v1/2023.findings-acl.649</doi>
    </paper>
    <paper id="650">
      <title><fixed-case>W</fixed-case>eb<fixed-case>DP</fixed-case>: Understanding Discourse Structures in Semi-Structured Web Documents</title>
      <author><first>Peilin</first><last>Liu</last><affiliation>Chinese Information Processing Laboratory, Institute of Software, Chinese Academy of Sciences</affiliation></author>
      <author><first>Hongyu</first><last>Lin</last><affiliation>Institute of Software, Chinese Academy of Sciences</affiliation></author>
      <author><first>Meng</first><last>Liao</last><affiliation>WeChat Search Team, WeChat, Tencent Inc., China</affiliation></author>
      <author><first>Hao</first><last>Xiang</last><affiliation>Chinese Information Processing Laboratory, Institute of Software, Chinese Academy of Sciences</affiliation></author>
      <author><first>Xianpei</first><last>Han</last><affiliation>Institute of Software, Chinese Academy of Sciences</affiliation></author>
      <author><first>Le</first><last>Sun</last><affiliation>ISCAS</affiliation></author>
      <pages>10235-10258</pages>
      <abstract>Web documents have become rich data resources in current era, and understanding their discourse structure will potentially benefit various downstream document processing applications. Unfortunately, current discourse analysis and document intelligence research mostly focus on either discourse structure of plain text or superficial visual structures in document, which cannot accurately describe discourse structure of highly free-styled and semi-structured web documents. To promote discourse studies on web documents, in this paper we introduced a benchmark – WebDP, orienting a new task named Web Document Discourse Parsing. Specifically, a web document discourse structure representation schema is proposed by extending classical discourse theories and adding special features to well represent discourse characteristics of web documents. Then, a manually annotated web document dataset – WEBDOCS is developed to facilitate the study of this parsing task. We compared current neural models on WEBDOCS and experimental results show that WebDP is feasible but also challenging for current models.</abstract>
      <url hash="783b931e">2023.findings-acl.650</url>
      <bibkey>liu-etal-2023-webdp</bibkey>
      <doi>10.18653/v1/2023.findings-acl.650</doi>
    </paper>
    <paper id="651">
      <title>Tab-<fixed-case>C</fixed-case>o<fixed-case>T</fixed-case>: Zero-shot Tabular Chain of Thought</title>
      <author><first>Jin</first><last>Ziqi</last><affiliation>Singapore University of Technology and Design</affiliation></author>
      <author><first>Wei</first><last>Lu</last><affiliation>Singapore University of Technology and Design</affiliation></author>
      <pages>10259-10277</pages>
      <abstract>The chain-of-though (CoT) prompting methods were successful in various natural language processing (NLP) tasks thanks to their ability to unveil the underlying complex reasoning processes. Such reasoning processes typically exhibit highly structured steps. Recent efforts also started investigating methods to encourage more structured reasoning procedures to be captured (cite least to most).In this work, we propose Tab-CoT, a novel tabular-format CoT prompting method, which allows the complex reasoning process to be explicitly modeled in a highly structured manner. Despite its simplicity, we show that our approach is capable of performing reasoning across multiple dimensions (i.e., both rows and columns).We demonstrate our approach’s strong zero-shot and few-shot capabilities through extensive experiments on a range of reasoning tasks.</abstract>
      <url hash="d0651860">2023.findings-acl.651</url>
      <bibkey>ziqi-lu-2023-tab</bibkey>
      <doi>10.18653/v1/2023.findings-acl.651</doi>
    </paper>
    <paper id="652">
      <title><fixed-case>KNSE</fixed-case>: A Knowledge-aware Natural Language Inference Framework for Dialogue Symptom Status Recognition</title>
      <author><first>Wei</first><last>Chen</last><affiliation>School of Data Science, Fudan University</affiliation></author>
      <author><first>Shiqi</first><last>Wei</last><affiliation>Fudan University</affiliation></author>
      <author><first>Zhongyu</first><last>Wei</last><affiliation>School of Data Science, Fudan University</affiliation></author>
      <author><first>Xuanjing</first><last>Huang</last><affiliation>Fudan University</affiliation></author>
      <pages>10278-10286</pages>
      <abstract>Symptom diagnosis in medical conversations aims to correctly extract both symptom entities and their status from the doctor-patient dialogue. In this paper, we propose a novel framework called KNSE for symptom status recognition (SSR), where the SSR is formulated as a natural language inference (NLI) task. For each mentioned symptom in a dialogue window, we first generate knowledge about the symptom and hypothesis about status of the symptom, to form a (premise, knowledge, hypothesis) triplet. The BERT model is then used to encode the triplet, which is further processed by modules including utterance aggregation, self-attention, cross-attention, and GRU to predict the symptom status. Benefiting from the NLI formalization, the proposed framework can encode more informative prior knowledge to better localize and track symptom status, which can effectively improve the performance of symptom status recognition. Preliminary experiments on Chinese medical dialogue datasets show that KNSE outperforms previous competitive baselines and has advantages in cross-disease and cross-symptom scenarios.</abstract>
      <url hash="d8a7f327">2023.findings-acl.652</url>
      <bibkey>chen-etal-2023-knse</bibkey>
      <doi>10.18653/v1/2023.findings-acl.652</doi>
    </paper>
    <paper id="653">
      <title>Augmenting Large Language Model Translators via Translation Memories</title>
      <author><first>Yongyu</first><last>Mu</last><affiliation>Northeastern University</affiliation></author>
      <author><first>Abudurexiti</first><last>Reheman</last><affiliation>Northeastern University</affiliation></author>
      <author><first>Zhiquan</first><last>Cao</last><affiliation>Northeastern University</affiliation></author>
      <author><first>Yuchun</first><last>Fan</last><affiliation>Northeastern University</affiliation></author>
      <author><first>Bei</first><last>Li</last><affiliation>Northeastern University</affiliation></author>
      <author><first>Yinqiao</first><last>Li</last><affiliation>Northeastern University</affiliation></author>
      <author><first>Tong</first><last>Xiao</last><affiliation>Northeastern University</affiliation></author>
      <author><first>Chunliang</first><last>Zhang</last><affiliation>NiuTrans Co., Ltd.</affiliation></author>
      <author><first>Jingbo</first><last>Zhu</last><affiliation>Northeastern University</affiliation></author>
      <pages>10287-10299</pages>
      <abstract>Using translation memories (TMs) as prompts is a promising approach to in-context learning of machine translation models. In this work, we take a step towards prompting large language models (LLMs) with TMs and making them better translators. We find that the ability of LLMs to “understand” prompts is indeed helpful for making better use of TMs. Experiments show that the results of a pre-trained LLM translator can be greatly improved by using high-quality TM-based prompts. These results are even comparable to those of the state-of-the-art NMT systems which have access to large-scale in-domain bilingual data and are well tuned on the downstream tasks.</abstract>
      <url hash="cd27b9d3">2023.findings-acl.653</url>
      <bibkey>mu-etal-2023-augmenting</bibkey>
      <doi>10.18653/v1/2023.findings-acl.653</doi>
    </paper>
    <paper id="654">
      <title>Character Coreference Resolution in Movie Screenplays</title>
      <author><first>Sabyasachee</first><last>Baruah</last><affiliation>University of Southern California</affiliation></author>
      <author><first>Shrikanth</first><last>Narayanan</last><affiliation>University of Southern California</affiliation></author>
      <pages>10300-10313</pages>
      <abstract>Movie screenplays have a distinct narrative structure. It segments the story into scenes containing interleaving descriptions of actions, locations, and character dialogues.A typical screenplay spans several scenes and can include long-range dependencies between characters and events.A holistic document-level understanding of the screenplay requires several natural language processing capabilities, such as parsing, character identification, coreference resolution, action recognition, summarization, and attribute discovery. In this work, we develop scalable and robust methods to extract the structural information and character coreference clusters from full-length movie screenplays. We curate two datasets for screenplay parsing and character coreference — <i>MovieParse</i> and <i>MovieCoref</i>, respectively.We build a robust screenplay parser to handle inconsistencies in screenplay formatting and leverage the parsed output to link co-referring character mentions.Our coreference models can scale to long screenplay documents without drastically increasing their memory footprints.</abstract>
      <url hash="02845ffc">2023.findings-acl.654</url>
      <bibkey>baruah-narayanan-2023-character</bibkey>
      <doi>10.18653/v1/2023.findings-acl.654</doi>
    </paper>
    <paper id="655">
      <title>Enhancing Event Causality Identification with Event Causal Label and Event Pair Interaction Graph</title>
      <author><first>Ruili</first><last>Pu</last><affiliation>School of Computer and Information Technology,Shanxi University</affiliation></author>
      <author><first>Yang</first><last>Li</last><affiliation>School of Finance, Shanxi University of Finance and Economics</affiliation></author>
      <author><first>Suge</first><last>Wang</last><affiliation>School of Computer &amp; Information Technology, Shanxi University</affiliation></author>
      <author><first>Deyu</first><last>Li</last><affiliation>School of Computer &amp; Information Technology, Shanxi University</affiliation></author>
      <author><first>Jianxing</first><last>Zheng</last><affiliation>School of Computer &amp; Information Technology, Shanxi University</affiliation></author>
      <author><first>Jian</first><last>Liao</last><affiliation>School of Computer &amp; Information Technology, Shanxi University</affiliation></author>
      <pages>10314-10322</pages>
      <abstract>Most existing event causality identification (ECI) methods rarely consider the event causal label information and the interaction information between event pairs. In this paper, we propose a framework to enrich the representation of event pairs by introducing the event causal label information and the event pair interaction information. In particular, 1) we design an event-causal-label-aware module to model the event causal label information, in which we design the event causal label prediction task as an auxiliary task of ECI, aiming to predict which events are involved in the causal relationship (we call them causality-related events) by mining the dependencies between events. 2) We further design an event pair interaction graph module to model the interaction information between event pairs, in which we construct the interaction graph with event pairs as nodes and leverage graph attention mechanism to model the degree of dependency between event pairs. The experimental results show that our approach outperforms previous state-of-the-art methods on two benchmark datasets EventStoryLine and Causal-TimeBank.</abstract>
      <url hash="7cece63c">2023.findings-acl.655</url>
      <bibkey>pu-etal-2023-enhancing</bibkey>
      <doi>10.18653/v1/2023.findings-acl.655</doi>
    </paper>
    <paper id="656">
      <title><fixed-case>L</fixed-case>ight<fixed-case>F</fixed-case>ormer: Light-weight Transformer Using <fixed-case>SVD</fixed-case>-based Weight Transfer and Parameter Sharing</title>
      <author><first>Xiuqing</first><last>Lv</last><affiliation>Tianjin University</affiliation></author>
      <author><first>Peng</first><last>Zhang</last><affiliation>Tianjin University</affiliation></author>
      <author><first>Sunzhu</first><last>Li</last><affiliation>Tianjin University</affiliation></author>
      <author><first>Guobing</first><last>Gan</last><affiliation>Tianjin University</affiliation></author>
      <author><first>Yueheng</first><last>Sun</last><affiliation>Tianjin University</affiliation></author>
      <pages>10323-10335</pages>
      <abstract>Transformer has become an important technique for natural language processing tasks with great success. However, it usually requires huge storage space and computational cost, making it difficult to be deployed on resource-constrained edge devices. To compress and accelerate Transformer, we propose LightFormer, which adopts a low-rank factorization initialized by SVD-based weight transfer and parameter sharing. The SVD-based weight transfer can effectively utilize the well-trained Transformer parameter knowledge to speed up the model convergence, and effectively alleviate the low-rank bottleneck problem combined with parameter sharing. We validate our method on machine translation, text summarization and text classification tasks. Experiments show that on IWSLT’14 De-En and WMT’14 En-De, LightFormer achieves similar performance to the baseline Transformer with 3.8 times and 1.8 times fewer parameters, and achieves 2.3 times speedup and 1.5 times speedup respectively, generally outperforming recent light-weight Transformers.</abstract>
      <url hash="0dd90e72">2023.findings-acl.656</url>
      <bibkey>lv-etal-2023-lightformer</bibkey>
      <doi>10.18653/v1/2023.findings-acl.656</doi>
    </paper>
    <paper id="657">
      <title>Multi-hop Evidence Retrieval for Cross-document Relation Extraction</title>
      <author><first>Keming</first><last>Lu</last><affiliation>University of Southern California</affiliation></author>
      <author><first>I-Hung</first><last>Hsu</last><affiliation>USC Information Sciences Institute</affiliation></author>
      <author><first>Wenxuan</first><last>Zhou</last><affiliation>University of Southern California</affiliation></author>
      <author><first>Mingyu Derek</first><last>Ma</last><affiliation>UCLA</affiliation></author>
      <author><first>Muhao</first><last>Chen</last><affiliation>USC</affiliation></author>
      <pages>10336-10351</pages>
      <abstract>Relation Extraction (RE) has been extended to cross-document scenarios because many relations are not simply described in a single document. This inevitably brings the challenge of efficient open-space evidence retrieval to support the inference of cross-document relations,along with the challenge of multi-hop reasoning on top of entities and evidence scattered in an open set of documents. To combat these challenges, we propose Mr.Cod (Multi-hop evidence retrieval for Cross-document relation extraction), which is a multi-hop evidence retrieval method based on evidence path mining and ranking. We explore multiple variants of retrievers to show evidence retrieval is essential in cross-document RE.We also propose a contextual dense retriever for this setting. Experiments on CodRED show that evidence retrieval with Mr.Cod effectively acquires cross-document evidence and boosts end-to-end RE performance in both closed and open settings.</abstract>
      <url hash="c8e1ec84">2023.findings-acl.657</url>
      <bibkey>lu-etal-2023-multi</bibkey>
      <doi>10.18653/v1/2023.findings-acl.657</doi>
    </paper>
    <paper id="658">
      <title>Which Examples Should be Multiply Annotated? Active Learning When Annotators May Disagree</title>
      <author><first>Connor</first><last>Baumler</last><affiliation>University of Maryland</affiliation></author>
      <author><first>Anna</first><last>Sotnikova</last><affiliation>University of Maryland</affiliation></author>
      <author><first>Hal</first><last>Daumé III</last><affiliation>UMD</affiliation></author>
      <pages>10352-10371</pages>
      <abstract>Linguistic annotations, especially for controversial topics like hate speech detection, are frequently contested due to annotator backgrounds and positionalities. In such situations, preserving this disagreement through the machine learning pipeline can be important for downstream use cases. However, capturing disagreement can increase annotation time and expense. Fortunately, for many tasks, not all examples are equally controversial; we develop an active learning approach, Disagreement Aware Active Learning (DAAL) that concentrates annotations on examples where model entropy and annotator entropy are the most different. Because we cannot know the true entropy of annotations on unlabeled examples, we estimate a model that predicts annotator entropy trained using very few multiply-labeled examples. We find that traditional uncertainty-based active learning underperforms simple passive learning on tasks with high levels of disagreement, but that our active learning approach is able to successfully improve on passive and active baselines, reducing the number of annotations required by at least 24% on average across several datasets.</abstract>
      <url hash="56fd0e85">2023.findings-acl.658</url>
      <bibkey>baumler-etal-2023-examples</bibkey>
      <doi>10.18653/v1/2023.findings-acl.658</doi>
    </paper>
    <paper id="659">
      <title><fixed-case>PIP</fixed-case>: Parse-Instructed Prefix for Syntactically Controlled Paraphrase Generation</title>
      <author><first>Yixin</first><last>Wan</last><affiliation>University of California, Los Angeles</affiliation></author>
      <author><first>Kuan-Hao</first><last>Huang</last><affiliation>University of California, Los Angeles</affiliation></author>
      <author><first>Kai-Wei</first><last>Chang</last><affiliation>UCLA</affiliation></author>
      <pages>10372-10380</pages>
      <abstract>Syntactically controlled paraphrase generation requires language models to generate paraphrases for sentences according to specific syntactic structures. Existing fine-tuning methods on this task is costly, as all parameters of the model need to be updated during the training process. Inspired by recent studies on parameter-efficient learning, we propose Parse-Instructed Prefix (PIP), a novel adaptation of prefix-tuning to tune large pre-trained language models on syntactically controlled paraphrase generation task in a low-data setting with significantly less training cost. We introduce two methods to instruct a model’s encoder prefix to capture syntax-related knowledge: direct initiation (PIP-Direct) and indirect optimization (PIP-Indirect). Comparing to traditional fine-tuning methods for this task, PIP is a compute-efficient alternative with 10 times less learnable parameters. Comparing to existing prefix-tuning methods, PIP excels at capturing syntax control information, achieving significantly higher performance at the same level of learnable parameter count.</abstract>
      <url hash="4f22a03b">2023.findings-acl.659</url>
      <bibkey>wan-etal-2023-pip</bibkey>
      <doi>10.18653/v1/2023.findings-acl.659</doi>
    </paper>
    <paper id="660">
      <title><fixed-case>D</fixed-case>e<fixed-case>P</fixed-case>lot: One-shot visual language reasoning by plot-to-table translation</title>
      <author><first>Fangyu</first><last>Liu</last><affiliation>University of Cambridge</affiliation></author>
      <author><first>Julian</first><last>Eisenschlos</last><affiliation>Google</affiliation></author>
      <author><first>Francesco</first><last>Piccinno</last><affiliation>Google</affiliation></author>
      <author><first>Syrine</first><last>Krichene</last><affiliation>Google</affiliation></author>
      <author><first>Chenxi</first><last>Pang</last><affiliation>Google</affiliation></author>
      <author><first>Kenton</first><last>Lee</last><affiliation>Google Research</affiliation></author>
      <author><first>Mandar</first><last>Joshi</last><affiliation>Google</affiliation></author>
      <author><first>Wenhu</first><last>Chen</last><affiliation>University of Waterloo &amp; Google Research</affiliation></author>
      <author><first>Nigel</first><last>Collier</last><affiliation>University of Cambridge</affiliation></author>
      <author><first>Yasemin</first><last>Altun</last><affiliation>Google Research</affiliation></author>
      <pages>10381-10399</pages>
      <abstract>Visual language such as charts and plots is ubiquitous in the human world. Comprehending plots and charts requires strong reasoning skills. Prior state-of-the-art (SOTA) models require at least tens of thousands of training examples and their reasoning capabilities are still much limited, especially on complex human-written queries. This paper presents the first one-shot solution to visual language reasoning. We decompose the challenge of visual language reasoning into two steps: (1) plot-to-text translation, and (2) reasoning over the translated text. The key in this method is a modality conversion module, named as DePlot, which translates the image of a plot or chart to a linearized table. The output of DePlot can then be directly used to prompt a pretrained large language model (LLM), exploiting the few-shot reasoning capabilities of LLMs. To obtain DePlot, we standardize the plot-to-table task by establishing unified task formats and metrics, and train DePlot end-to-end on this task. DePlot can then be used off-the-shelf together with LLMs in a plug-and-play fashion. Compared with a SOTA model finetuned on more than thousands of data points, DePlot+LLM with just one-shot prompting achieves a 29.4% improvement over finetuned SOTA on human-written queries from the task of chart QA.</abstract>
      <url hash="71d42841">2023.findings-acl.660</url>
      <bibkey>liu-etal-2023-deplot</bibkey>
      <doi>10.18653/v1/2023.findings-acl.660</doi>
    </paper>
    <paper id="661">
      <title>Stochastic Bridges as Effective Regularizers for Parameter-Efficient Tuning</title>
      <author><first>Weize</first><last>Chen</last><affiliation>Tsinghua University</affiliation></author>
      <author><first>Xu</first><last>Han</last><affiliation>Tsinghua University</affiliation></author>
      <author><first>Yankai</first><last>Lin</last><affiliation>Gaoling School of Artificial Intelligence, Renmin University of China</affiliation></author>
      <author><first>Zhiyuan</first><last>Liu</last><affiliation>Tsinghua University</affiliation></author>
      <author><first>Maosong</first><last>Sun</last><affiliation>Tsinghua University</affiliation></author>
      <author><first>Jie</first><last>Zhou</last><affiliation>Tencent Inc.</affiliation></author>
      <pages>10400-10420</pages>
      <abstract>Parameter-efficient tuning methods (PETs) have achieved promising results in tuning large pre-trained language models (PLMs). By formalizing frozen PLMs and additional tunable parameters as systems and controls respectively, PETs can be theoretically grounded to optimal control and further viewed as optimizing the terminal cost and running cost in the optimal control literature. Despite the elegance of this theoretical grounding, in practice, existing PETs often ignore the running cost and only optimize the terminal cost, i.e., focus on optimizing the loss function of the output state, regardless of the running cost that depends on the intermediate states. Since it is non-trivial to directly model the intermediate states and design a running cost function, we propose to use latent stochastic bridges to regularize the intermediate states and use the regularization as the running cost of PETs. As the first work to propose regularized PETs that use stochastic bridges as the regularizers (running costs) for the intermediate states, we show the effectiveness and generality of this regularization across different tasks, PLMs and PETs. In view of the great potential and capacity, we believe more sophisticated regularizers can be designed for PETs and better performance can be achieved in the future.</abstract>
      <url hash="76858e23">2023.findings-acl.661</url>
      <bibkey>chen-etal-2023-stochastic</bibkey>
      <doi>10.18653/v1/2023.findings-acl.661</doi>
    </paper>
    <paper id="662">
      <title>Learning from a Friend: Improving Event Extraction via Self-Training with Feedback from <fixed-case>A</fixed-case>bstract <fixed-case>M</fixed-case>eaning <fixed-case>R</fixed-case>epresentation</title>
      <author><first>Zhiyang</first><last>Xu</last><affiliation>Virginia Tech</affiliation></author>
      <author><first>Jay Yoon</first><last>Lee</last><affiliation>Seoul National University</affiliation></author>
      <author><first>Lifu</first><last>Huang</last><affiliation>Virginia Tech</affiliation></author>
      <pages>10421-10437</pages>
      <abstract>Data scarcity has been the main factor that hinders the progress of event extraction. To overcome this issue, we propose a Self-Training with Feedback (STF) framework that leverages the large-scale unlabeled data and acquires feedback for each new event prediction from the unlabeled data by comparing it to the Abstract Meaning Representation (AMR) graph of the same sentence. Specifically, STF consists of (1) a base event extraction model trained on existing event annotations and then applied to large-scale unlabeled corpora to predict new event mentions as pseudo training samples, and (2) a novel scoring model that takes in each new predicted event trigger, an argument, its argument role, as well as their paths in the AMR graph to estimate a compatibility score indicating the correctness of the pseudo label. The compatibility scores further act as feedback to encourage or discourage the model learning on the pseudo labels during self-training. Experimental results on three benchmark datasets, including ACE05-E, ACE05-E+, and ERE, demonstrate the effectiveness of the STF framework on event extraction, especially event argument extraction, with significant performance gain over the base event extraction models and strong baselines. Our experimental analysis further shows that STF is a generic framework as it can be applied to improve most, if not all, event extraction models by leveraging large-scale unlabeled data, even when high-quality AMR graph annotations are not available.</abstract>
      <url hash="059a3a62">2023.findings-acl.662</url>
      <bibkey>xu-etal-2023-learning-friend</bibkey>
      <doi>10.18653/v1/2023.findings-acl.662</doi>
    </paper>
    <paper id="663">
      <title>How Well Do Large Language Models Perform on Faux Pas Tests?</title>
      <author><first>Natalie</first><last>Shapira</last><affiliation>Bar-Ilan University</affiliation></author>
      <author><first>Guy</first><last>Zwirn</last><affiliation>Hadassah University Medical Center</affiliation></author>
      <author><first>Yoav</first><last>Goldberg</last><affiliation>Bar Ilan University</affiliation></author>
      <pages>10438-10451</pages>
      <abstract>Motivated by the question of the extent to which large language models “understand” social intelligence, we investigate the ability of such models to generate correct responses to questions involving descriptions of faux pas situations. The faux pas test is a test used in clinical psychology, which is known to be more challenging for children than individual tests of theory-of-mind or social intelligence. Our results demonstrate that, while the models seem to sometimes offer correct responses, they in fact struggle with this task, and that many of the seemingly correct responses can be attributed to over-interpretation by the human reader (“the ELIZA effect”). An additional phenomenon observed is the failure of most models to generate a correct response to presupposition questions. Finally, in an experiment in which the models are tasked with generating original faux pas stories, we find that while some models are capable of generating novel faux pas stories, the stories are all explicit, as the models are limited in their abilities to describe situations in an implicit manner.</abstract>
      <url hash="04179797">2023.findings-acl.663</url>
      <bibkey>shapira-etal-2023-well</bibkey>
      <doi>10.18653/v1/2023.findings-acl.663</doi>
    </paper>
    <paper id="664">
      <title>Modular Transformers: Compressing Transformers into Modularized Layers for Flexible Efficient Inference</title>
      <author><first>Wangchunshu</first><last>Zhou</last><affiliation>ETH Zurich</affiliation></author>
      <author><first>Ronan</first><last>Le Bras</last><affiliation>Allen Institute for AI</affiliation></author>
      <author><first>Yejin</first><last>Choi</last><affiliation>University of Washington</affiliation></author>
      <pages>10452-10465</pages>
      <abstract>Pre-trained Transformer models like T5 and BART have advanced the state of the art on a wide range of text generation tasks. Compressing these models into smaller ones has become critically important for practical use. Common neural network compression techniques such as knowledge distillation or quantization are limited to static compression where the compression ratio is fixed. In this paper, we introduce Modular Transformers, a modularized encoder-decoder framework for flexible sequence-to-sequence model compression. Modular Transformers trains modularized layers that have the same function of two or more consecutive layers in the original model via module replacing and knowledge distillation. After training, the modularized layers can be flexibly assembled into sequence-to-sequence models that meet different performance-efficiency trade-offs. Experimental results show that after a single training phase, by simply varying the assemble strategy, Modular Transformers can achieve flexible compression ratios from 1.1x to 6x with little to moderate relative performance drop.</abstract>
      <url hash="37f25713">2023.findings-acl.664</url>
      <bibkey>zhou-etal-2023-modular</bibkey>
      <doi>10.18653/v1/2023.findings-acl.664</doi>
    </paper>
    <paper id="665">
      <title><fixed-case>ISLT</fixed-case>ranslate: Dataset for Translating <fixed-case>I</fixed-case>ndian <fixed-case>S</fixed-case>ign <fixed-case>L</fixed-case>anguage</title>
      <author><first>Abhinav</first><last>Joshi</last><affiliation>Indian Institute of Technology Kanpur</affiliation></author>
      <author><first>Susmit</first><last>Agrawal</last><affiliation>IIT Hyderabad</affiliation></author>
      <author><first>Ashutosh</first><last>Modi</last><affiliation>Indian Institute of Technology Kanpur</affiliation></author>
      <pages>10466-10475</pages>
      <abstract>Sign languages are the primary means of communication for many hard-of-hearing people worldwide. Recently, to bridge the communication gap between the hard-of-hearing community and the rest of the population, several sign language translation datasets have been proposed to enable the development of statistical sign language translation systems. However, there is a dearth of sign language resources for the Indian sign language. This resource paper introduces ISLTranslate, a translation dataset for continuous Indian Sign Language (ISL) consisting of 31k ISL-English sentence/phrase pairs. To the best of our knowledge, it is the largest translation dataset for continuous Indian Sign Language. We provide a detailed analysis of the dataset. To validate the performance of existing end-to-end Sign language to spoken language translation systems, we benchmark the created dataset with a transformer-based model for ISL translation.</abstract>
      <url hash="0b406523">2023.findings-acl.665</url>
      <bibkey>joshi-etal-2023-isltranslate</bibkey>
      <doi>10.18653/v1/2023.findings-acl.665</doi>
    </paper>
    <paper id="666">
      <title><fixed-case>LM</fixed-case>entry: A Language Model Benchmark of Elementary Language Tasks</title>
      <author><first>Avia</first><last>Efrat</last><affiliation>Tel Aviv University</affiliation></author>
      <author><first>Or</first><last>Honovich</last><affiliation>Tel Aviv University</affiliation></author>
      <author><first>Omer</first><last>Levy</last><affiliation>Meta AI / Tel Aviv University</affiliation></author>
      <pages>10476-10501</pages>
      <abstract>As the performance of large language models rapidly improves, benchmarks are getting larger and more complex as well. We present LMentry, a benchmark that avoids this “arms race” by focusing on a compact set of tasks that are trivial to humans, e.g. writing a sentence containing a specific word, identifying which words in a list belong to a specific category, or choosing which of two words is longer.LMentry is specifically designed to provide quick and interpretable insights into the capabilities and robustness of large language models. Our experiments reveal a wide variety of failure cases that, while immediately obvious to humans, pose a considerable challenge for large language models, including OpenAI’s latest 175B-parameter instruction-tuned model, TextDavinci002.LMentry complements contemporary evaluation approaches of large language models, providing a quick, automatic, and easy-to-run “unit test”, without resorting to large benchmark suites of complex tasks.</abstract>
      <url hash="8f657355">2023.findings-acl.666</url>
      <bibkey>efrat-etal-2023-lmentry</bibkey>
      <doi>10.18653/v1/2023.findings-acl.666</doi>
    </paper>
    <paper id="667">
      <title>Differentiable Instruction Optimization for Cross-Task Generalization</title>
      <author><first>Masaru</first><last>Isonuma</last><affiliation>The University of Tokyo</affiliation></author>
      <author><first>Junichiro</first><last>Mori</last><affiliation>The University of Tokyo</affiliation></author>
      <author><first>Ichiro</first><last>Sakata</last><affiliation>The University of Tokyo</affiliation></author>
      <pages>10502-10517</pages>
      <abstract>Instruction tuning has been attracting much attention to achieve generalization ability across a wide variety of tasks. Although various types of instructions have been manually created for instruction tuning, it is still unclear what kind of instruction is optimal to obtain cross-task generalization ability. This work presents instruction optimization, which optimizes training instructions with respect to generalization ability. Rather than manually tuning instructions, we introduce learnable instructions and optimize them with gradient descent by leveraging bilevel optimization. Experimental results show that the learned instruction enhances the diversity of instructions and improves the generalization ability compared to using only manually created instructions.</abstract>
      <url hash="9b7322ef">2023.findings-acl.667</url>
      <bibkey>isonuma-etal-2023-differentiable</bibkey>
      <doi>10.18653/v1/2023.findings-acl.667</doi>
    </paper>
    <paper id="668">
      <title>Leveraging Training Data in Few-Shot Prompting for Numerical Reasoning</title>
      <author><first>Zhanming</first><last>Jie</last><affiliation>ByteDance AI Lab</affiliation></author>
      <author><first>Wei</first><last>Lu</last><affiliation>Singapore University of Technology and Design</affiliation></author>
      <pages>10518-10526</pages>
      <abstract>Chain-of-thought (CoT) prompting with large language models has proven effective in numerous natural language process tasks, but designing prompts that generalize well to diverse problem types can be challenging CITATION, especially in the context of math word problem solving. Additionally, it is common to have a large amount of training data that have a better diversity coverage but CoT annotations are not available, which limits the use of supervised learning techniques. To address these issues, we investigate two approaches to leverage the training data in few-shot prompting scenario: <i>dynamic program prompting</i> and <i>program distillation</i>.Our approach is largely inspired by CITATION where they proposed to replace the CoT with the programs as the intermediate reasoning step. Such a prompting strategy allows us to accurately verify the answer correctness through program execution in MWP solving.Our dynamic program prompting involves annotating the training data by sampling correct programs from a large language model, while program distillation involves adapting a smaller model to the program-annotated training data.Our experiments on three standard MWP datasets demonstrate the effectiveness of these approaches, yielding significant improvements over previous baselines for prompting and fine-tuning.Our results suggest that leveraging a large amount of training data can improve the generalization ability of prompts and boost the performance of fine-tuned smaller models in MWP solving.</abstract>
      <url hash="7ccbd4db">2023.findings-acl.668</url>
      <bibkey>jie-lu-2023-leveraging</bibkey>
      <doi>10.18653/v1/2023.findings-acl.668</doi>
    </paper>
    <paper id="669">
      <title>How does the task complexity of masked pretraining objectives affect downstream performance?</title>
      <author><first>Atsuki</first><last>Yamaguchi</last><affiliation>Hitachi, Ltd.</affiliation></author>
      <author><first>Hiroaki</first><last>Ozaki</last><affiliation>Hitachi Ltd.</affiliation></author>
      <author><first>Terufumi</first><last>Morishita</last><affiliation>Hitachi.ltd</affiliation></author>
      <author><first>Gaku</first><last>Morio</last><affiliation>Research &amp; Development Group, Hitachi America, Ltd.</affiliation></author>
      <author><first>Yasuhiro</first><last>Sogawa</last><affiliation>Hitachi, Ltd.</affiliation></author>
      <pages>10527-10537</pages>
      <abstract>Masked language modeling (MLM) is a widely used self-supervised pretraining objective, where a model needs to predict an original token that is replaced with a mask given contexts. Although simpler and computationally efficient pretraining objectives, e.g., predicting the first character of a masked token, have recently shown comparable results to MLM, no objectives with a masking scheme actually outperform it in downstream tasks. Motivated by the assumption that their lack of complexity plays a vital role in the degradation, we validate whether more complex masked objectives can achieve better results and investigate how much complexity they should have to perform comparably to MLM. Our results using GLUE, SQuAD, and Universal Dependencies benchmarks demonstrate that more complicated objectives tend to show better downstream results with at least half of the MLM complexity needed to perform comparably to MLM. Finally, we discuss how we should pretrain a model using a masked objective from the task complexity perspective.</abstract>
      <url hash="7976a836">2023.findings-acl.669</url>
      <bibkey>yamaguchi-etal-2023-task</bibkey>
      <doi>10.18653/v1/2023.findings-acl.669</doi>
    </paper>
    <paper id="670">
      <title><fixed-case>AUGUST</fixed-case>: an Automatic Generation Understudy for Synthesizing Conversational Recommendation Datasets</title>
      <author><first>Yu</first><last>Lu</last><affiliation>CUHK-SZ</affiliation></author>
      <author><first>Junwei</first><last>Bao</last><affiliation>JD AI Research</affiliation></author>
      <author><first>Zichen</first><last>Ma</last><affiliation>The Chinese University of Hong Kong, Shenzhen</affiliation></author>
      <author><first>Xiaoguang</first><last>Han</last><affiliation>The Chinese University of Hong Kong, Shenzhen</affiliation></author>
      <author><first>Youzheng</first><last>Wu</last><affiliation>JD AI Research</affiliation></author>
      <author><first>Shuguang</first><last>Cui</last><affiliation>The Chinese University of Hong Kong, Shenzhen</affiliation></author>
      <author><first>Xiaodong</first><last>He</last><affiliation>JD AI Research</affiliation></author>
      <pages>10538-10549</pages>
      <abstract>High-quality data is essential for conversational recommendation systems and serves as the cornerstone of the network architecture development and training strategy design. Existing works contribute heavy human efforts to manually labeling or designing and extending recommender dialogue templates. However, they suffer from: (i) the limited number of human annotators results in datasets can hardly capture rich and large-scale cases in the real world, (ii) the limited experience and knowledge of annotators accounts for the uninformative corpus and inappropriate recommendations. In this paper, we propose a novel automatic dataset synthesis approach that can generate large-scale and high-quality recommendation dialogues through a data2text generation process, where unstructured recommendation conversations are generated from structured graphs based on user-item information from the real world. In doing so, we comprehensively exploit: (i) rich personalized user profiles from traditional recommendation datasets, (ii) rich external knowledge from knowledge graphs, and (iii) the conversation ability contained in human-to-human conversational recommendation datasets. Extensive experiments validate the benefit brought by the automatically synthesized data under low-resource scenarios, and demonstrate the promising potential to facilitate developing a more effective conversational recommendation system.</abstract>
      <url hash="ce5ed5b5">2023.findings-acl.670</url>
      <bibkey>lu-etal-2023-august</bibkey>
      <doi>10.18653/v1/2023.findings-acl.670</doi>
    </paper>
    <paper id="671">
      <title>Knowing-how &amp; Knowing-that: A New Task for Machine Comprehension of User Manuals</title>
      <author><first>Hongru</first><last>Liang</last><affiliation>Sichuan University</affiliation></author>
      <author><first>Jia</first><last>Liu</last><affiliation>Ant Financial</affiliation></author>
      <author><first>Weihong</first><last>Du</last><affiliation>Sichuan University</affiliation></author>
      <author><first>Dingnan</first><last>Jin</last><affiliation>Ant Group</affiliation></author>
      <author><first>Wenqiang</first><last>Lei</last><affiliation>Sichuan University</affiliation></author>
      <author><first>Zujie</first><last>Wen</last><affiliation>Ant Financial Services Group</affiliation></author>
      <author><first>Jiancheng</first><last>Lv</last><affiliation>Sichuan University</affiliation></author>
      <pages>10550-10564</pages>
      <abstract>The machine reading comprehension (MRC) of user manuals has huge potential in customer service. However, current methods have trouble answering complex questions. Therefore, we introduce the knowing-how &amp; knowing-that task that requires the model to answer factoid-style, procedure-style, and inconsistent questions about user manuals. We resolve this task by jointly representing the sTeps and fActs in a gRAh (TARA), which supports a unified inference of various questions. Towards a systematical benchmarking study, we design a heuristic method to automatically parse user manuals into TARAs and build an annotated dataset to test the model’s ability in answering real-world questions. Empirical results demonstrate that representing user manuals as TARAs is a desired solution for the MRC of user manuals. An in-depth investigation of TARA further sheds light on the issues and broader impacts of future representations of user manuals. We hope our work can move the MRC of user manuals to a more complex and realistic stage.</abstract>
      <url hash="0c0345d7">2023.findings-acl.671</url>
      <bibkey>liang-etal-2023-knowing</bibkey>
      <doi>10.18653/v1/2023.findings-acl.671</doi>
    </paper>
    <paper id="672">
      <title>Deep Span Representations for Named Entity Recognition</title>
      <author><first>Enwei</first><last>Zhu</last><affiliation>University of Chinese Academy of Sciences</affiliation></author>
      <author><first>Yiyang</first><last>Liu</last><affiliation>Ningbo Institute of Life and Health Industry, University of Chinese Academy of Sciences</affiliation></author>
      <author><first>Jinpeng</first><last>Li</last><affiliation>HwaMei Hospital, University of Chinese Academy of Sciences</affiliation></author>
      <pages>10565-10582</pages>
      <abstract>Span-based models are one of the most straightforward methods for named entity recognition (NER). Existing span-based NER systems shallowly aggregate the token representations to span representations. However, this typically results in significant ineffectiveness for long entities, a coupling between the representations of overlapping spans, and ultimately a performance degradation. In this study, we propose DSpERT (Deep Span Encoder Representations from Transformers), which comprises a standard Transformer and a span Transformer. The latter uses low-layered span representations as queries, and aggregates the token representations as keys and values, layer by layer from bottom to top. Thus, DSpERT produces span representations of deep semantics. With weight initialization from pretrained language models, DSpERT achieves performance higher than or competitive with recent state-of-the-art systems on six NER benchmarks. Experimental results verify the importance of the depth for span representations, and show that DSpERT performs particularly well on long-span entities and nested structures. Further, the deep span representations are well structured and easily separable in the feature space.</abstract>
      <url hash="cc98fae2">2023.findings-acl.672</url>
      <bibkey>zhu-etal-2023-deep</bibkey>
      <doi>10.18653/v1/2023.findings-acl.672</doi>
    </paper>
    <paper id="673">
      <title>Disambiguated Lexically Constrained Neural Machine Translation</title>
      <author><first>Jinpeng</first><last>Zhang</last><affiliation>Soochow University</affiliation></author>
      <author><first>Nini</first><last>Xiao</last><affiliation>Soochow University</affiliation></author>
      <author><first>Ke</first><last>Wang</last><affiliation>Alibaba DAMO Academy</affiliation></author>
      <author><first>Chuanqi</first><last>Dong</last><affiliation>Soochow University</affiliation></author>
      <author><first>Xiangyu</first><last>Duan</last><affiliation>Soochow University</affiliation></author>
      <author><first>Yuqi</first><last>Zhang</last><affiliation>Alibaba inc.</affiliation></author>
      <author><first>Min</first><last>Zhang</last><affiliation>Harbin Institute of Technology (Shenzhen)</affiliation></author>
      <pages>10583-10596</pages>
      <abstract>Lexically constrained neural machine translation (LCNMT), which controls the translation generation with pre-specified constraints, is important in many practical applications. Current approaches to LCNMT typically assume that the pre-specified lexicon constraints are contextually appropriate. This assumption limits their application to real-world scenarios where a source lexicon may have multiple target constraints, and disambiguation is needed to select the most suitable one. In this paper, we propose disambiguated LCNMT (D-LCNMT) to solve the problem. D-LCNMT is a robust and effective two-stage framework that disambiguates the constraints based on contexts at first, then integrates the disambiguated constraints into LCNMT. Experimental results show that our approach outperforms strong baselines including existing data argumentation based approaches on benchmark datasets, and comprehensive experiments in scenarios where a source lexicon corresponds to multiple target constraints demonstrate the constraint disambiguation superiority of our approach.</abstract>
      <url hash="09dc192e">2023.findings-acl.673</url>
      <bibkey>zhang-etal-2023-disambiguated</bibkey>
      <doi>10.18653/v1/2023.findings-acl.673</doi>
    </paper>
    <paper id="674">
      <title>Curating Datasets for Better Performance with Example Training Dynamics</title>
      <author><first>Aviad</first><last>Sar-Shalom</last><affiliation>TAU</affiliation></author>
      <author><first>Roy</first><last>Schwartz</last><affiliation>The Hebrew University of Jerusalem</affiliation></author>
      <pages>10597-10608</pages>
      <abstract>The landscape of NLP research is dominated by large-scale models training on colossal datasets, relying on data quantity rather than quality. As an alternative to this landscape, we propose a method for weighing the relative importance of examples in a dataset based on their Example Training dynamics (swayamdipta et al., 2020) — a set of metrics computed during training. We propose a new way of computing the ETD of a dataset, and show that they can be used to improve performance in both in-distribution and out-of-distribution testing. We show that ETD can be transferable, i.e., they can be computed once and used for training different models, effectively reducing their computation cost. Finally, we suggest an active learning approach for computing ETD during training rather than as a preprocessing step — an approach that is not as effective, but dramatically reduces the extra computational costs.</abstract>
      <url hash="47014145">2023.findings-acl.674</url>
      <bibkey>sar-shalom-schwartz-2023-curating</bibkey>
      <doi>10.18653/v1/2023.findings-acl.674</doi>
    </paper>
    <paper id="675">
      <title>Multi-armed bandits for resource efficient, online optimization of language model pre-training: the use case of dynamic masking</title>
      <author><first>Inigo</first><last>Urteaga</last><affiliation>Columbia University</affiliation></author>
      <author><first>Moulay Zaidane</first><last>Draidia</last><affiliation>Columbia</affiliation></author>
      <author><first>Tomer</first><last>Lancewicki</last><affiliation>Walmart Global Tech</affiliation></author>
      <author><first>Shahram</first><last>Khadivi</last><affiliation>eBay</affiliation></author>
      <pages>10609-10627</pages>
      <abstract>We design and evaluate a Bayesian optimization framework for resource efficient pre-training of Transformer-based language models (TLMs). TLM pre-training requires high computational resources and introduces many unresolved design choices, such as selecting its pre-training hyperparameters.We propose a multi-armed bandit framework for the sequential selection of pre-training hyperparameters, aimed at optimizing language model performance, in a resource efficient manner. We design a Thompson sampling algorithm, with a surrogate Gaussian process reward model of the Masked Language Model (MLM) pre-training objective, for its sequential minimization. Instead of MLM pre-training with fixed masking probabilities, the proposed Gaussian process-based Thompson sampling (GP-TS) accelerates pre-training by sequentially selecting masking hyperparameters that improve performance. We empirically demonstrate how GP-TS pre-trains language models efficiently, i.e., it achieves lower MLM loss in fewer epochs, across a variety of settings. In addition, GP-TS pre-trained TLMs attain competitive downstream performance, while avoiding expensive hyperparameter grid search. GP-TS provides an interactive framework for efficient and optimized TLM pre-training that, by circumventing costly hyperparameter selection, enables substantial computational savings.</abstract>
      <url hash="2a16a7e3">2023.findings-acl.675</url>
      <bibkey>urteaga-etal-2023-multi</bibkey>
      <doi>10.18653/v1/2023.findings-acl.675</doi>
    </paper>
    <paper id="676">
      <title><fixed-case>ERNIE</fixed-case>-Code: Beyond <fixed-case>E</fixed-case>nglish-Centric Cross-lingual Pretraining for Programming Languages</title>
      <author><first>Yekun</first><last>Chai</last><affiliation>Baidu</affiliation></author>
      <author><first>Shuohuan</first><last>Wang</last><affiliation>Baidu</affiliation></author>
      <author><first>Chao</first><last>Pang</last><affiliation>baidu.com</affiliation></author>
      <author><first>Yu</first><last>Sun</last><affiliation>Baidu</affiliation></author>
      <author><first>Hao</first><last>Tian</last><affiliation>University of Science and Technology of China &amp; Baidu Inc</affiliation></author>
      <author><first>Hua</first><last>Wu</last><affiliation>Baidu</affiliation></author>
      <pages>10628-10650</pages>
      <abstract>Software engineers working with the same programming language (PL) may speak different natural languages (NLs) and vice versa, erecting huge barriers to communication and working efficiency. Recent studies have demonstrated the effectiveness of generative pre-training in computer programs, yet they are always English-centric. In this work, we step towards bridging the gap between multilingual NLs and multilingual PLs for large language models (LLMs). We release ERNIE-Code, a unified pre-trained language model for 116 NLs and 6 PLs. We employ two methods for universal cross-lingual pre-training: span-corruption language modeling that learns patterns from monolingual NL or PL; and pivot-based translation language modeling that relies on parallel data of many NLs and PLs. Extensive results show that ERNIE-Code outperforms previous multilingual LLMs for PL or NL across a wide range of end tasks of code intelligence, including multilingual code-to-text, text-to-code, code-to-code, and text-to-text generation. We further show its advantage of zero-shot prompting on multilingual code summarization and text-to-text translation. We release our code and pre-trained checkpoints.</abstract>
      <url hash="d6401044">2023.findings-acl.676</url>
      <bibkey>chai-etal-2023-ernie</bibkey>
      <doi>10.18653/v1/2023.findings-acl.676</doi>
    </paper>
    <paper id="677">
      <title><fixed-case>P</fixed-case>rompt<fixed-case>A</fixed-case>ttack: Probing Dialogue State Trackers with Adversarial Prompts</title>
      <author><first>Xiangjue</first><last>Dong</last><affiliation>Texas A&amp;M University</affiliation></author>
      <author><first>Yun</first><last>He</last><affiliation>Meta</affiliation></author>
      <author><first>Ziwei</first><last>Zhu</last><affiliation>George Mason University</affiliation></author>
      <author><first>James</first><last>Caverlee</last><affiliation>Texas A&amp;M University</affiliation></author>
      <pages>10651-10666</pages>
      <abstract>A key component of modern conversational systems is the Dialogue State Tracker (or DST), which models a user’s goals and needs. Toward building more robust and reliable DSTs, we introduce a prompt-based learning approach to automatically generate effective adversarial examples to probe DST models. Two key characteristics of this approach are: (i) it only needs the output of the DST with no need for model parameters, and (ii) it can learn to generate natural language utterances that can target any DST. Through experiments over state-of-the-art DSTs, the proposed framework leads to the greatest reduction in accuracy and the best attack success rate while maintaining good fluency and a low perturbation ratio. We also show how much the generated adversarial examples can bolster a DST through adversarial training. These results indicate the strength of prompt-based attacks on DSTs and leave open avenues for continued refinement.</abstract>
      <url hash="9e39fbb1">2023.findings-acl.677</url>
      <bibkey>dong-etal-2023-promptattack</bibkey>
      <doi>10.18653/v1/2023.findings-acl.677</doi>
    </paper>
    <paper id="678">
      <title>Understanding Programs by Exploiting (Fuzzing) Test Cases</title>
      <author><first>Jianyu</first><last>Zhao</last><affiliation>Tencent</affiliation></author>
      <author><first>Yuyang</first><last>Rong</last><affiliation>University of California, Davis</affiliation></author>
      <author><first>Yiwen</first><last>Guo</last><affiliation>Independent Researcher</affiliation></author>
      <author><first>Yifeng</first><last>He</last><affiliation>University of California, Davis</affiliation></author>
      <author><first>Hao</first><last>Chen</last><affiliation>UC Davis</affiliation></author>
      <pages>10667-10679</pages>
      <abstract>Semantic understanding of programs has attracted great attention in the community. Inspired by recent successes of large language models (LLMs) in natural language understanding, tremendous progress has been made by treating programming language as another sort of natural language and training LLMs on corpora of program code. However, programs are essentially different from texts after all, in a sense that they are normally heavily structured and syntax-strict. In particular, programs and their basic units (i.e., functions and subroutines) are designed to demonstrate a variety of behaviors and/or provide possible outputs, given different inputs. The relationship between inputs and possible outputs/behaviors represents the functions/subroutines and profiles the program as a whole. Hence, we propose to incorporate such a relationship into learning, for achieving a deeper semantic understanding of programs. To obtain inputs that are representative enough to trigger the execution of most part of the code, we resort to fuzz testing and propose fuzz tuning to boost the performance of program understanding and code representation learning, given a pre-trained LLM. The effectiveness of the proposed method is verified on two program understanding tasks including code clone detection and code classification, and it outperforms current state-of-the-arts by large margins. Code is available at <url>https://github.com/rabbitjy/FuzzTuning</url>.</abstract>
      <url hash="7e77873f">2023.findings-acl.678</url>
      <bibkey>zhao-etal-2023-understanding</bibkey>
      <doi>10.18653/v1/2023.findings-acl.678</doi>
    </paper>
    <paper id="679">
      <title>Hybrid Hierarchical Retrieval for Open-Domain Question Answering</title>
      <author><first>Manoj Ghuhan</first><last>Arivazhagan</last><affiliation>Amazon</affiliation></author>
      <author><first>Lan</first><last>Liu</last><affiliation>Amazon</affiliation></author>
      <author><first>Peng</first><last>Qi</last><affiliation>AWS AI Labs</affiliation></author>
      <author><first>Xinchi</first><last>Chen</last><affiliation>Amazon AWS</affiliation></author>
      <author><first>William Yang</first><last>Wang</last><affiliation>Unversity of California, Santa Barbara</affiliation></author>
      <author><first>Zhiheng</first><last>Huang</last><affiliation>Amazon AI</affiliation></author>
      <pages>10680-10689</pages>
      <abstract>Retrieval accuracy is crucial to the performance of open-domain question answering (ODQA) systems. Recent work has demonstrated that dense hierarchical retrieval (DHR), which retrieves document candidates first and then relevant passages from the refined document set, can significantly outperform the single stage dense passage retriever (DPR). While effective, this approach requires document structure information to learn document representation and is hard to adopt to other domains without this information. Additionally, the dense retrievers tend to generalize poorly on out-of-domain data comparing with sparse retrievers such as BM25. In this paper, we propose Hybrid Hierarchical Retrieval (HHR) to address the existing limitations. Instead of relying solely on dense retrievers, we can apply sparse retriever, dense retriever, and a combination of them in both stages of document and passage retrieval. We perform extensive experiments on ODQA benchmarks and observe that our framework not only brings in-domain gains, but also generalizes better to zero-shot TriviaQA and Web Questions datasets with an average of 4.69% improvement on recall@100 over DHR. We also offer practical insights to trade off between retrieval accuracy, latency, and storage cost. The code is available on github.</abstract>
      <url hash="86a4f8e4">2023.findings-acl.679</url>
      <bibkey>arivazhagan-etal-2023-hybrid</bibkey>
      <doi>10.18653/v1/2023.findings-acl.679</doi>
    </paper>
    <paper id="680">
      <title>Coherent or Not? Stressing a Neural Language Model for Discourse Coherence in Multiple Languages</title>
      <author><first>Dominique</first><last>Brunato</last><affiliation>Institute of Computational Linguistics “A. Zampolli” (ILC-CNR), Pisa</affiliation></author>
      <author><first>Felice</first><last>Dell’Orletta</last><affiliation>ItaliaNLP Lab @ Institute for Computational Linguistics “Antonio Zampolli”, ILC - CNR</affiliation></author>
      <author><first>Irene</first><last>Dini</last><affiliation>Istituto di Linguistica Computazionale “Antonio Zampolli” - CNR Pisa</affiliation></author>
      <author><first>Andrea Amelio</first><last>Ravelli</last><affiliation>Istituto di Linguistica Computazionale “A. Zampolli” ILC-CNR</affiliation></author>
      <pages>10690-10700</pages>
      <abstract>In this study, we investigate the capability of a Neural Language Model (NLM) to distinguish between coherent and incoherent text, where the latter has been artificially created to gradually undermine local coherence within text. While previous research on coherence assessment using NLMs has primarily focused on English, we extend our investigation to multiple languages. We employ a consistent evaluation framework to compare the performance of monolingual and multilingual models in both in-domain and out-domain settings. Additionally, we explore the model’s performance in a cross-language scenario.</abstract>
      <url hash="86d3ad1c">2023.findings-acl.680</url>
      <bibkey>brunato-etal-2023-coherent</bibkey>
      <doi>10.18653/v1/2023.findings-acl.680</doi>
    </paper>
    <paper id="681">
      <title>Understanding Differential Search Index for Text Retrieval</title>
      <author><first>Xiaoyang</first><last>Chen</last><affiliation>University of Chinese Academy of Sciences</affiliation></author>
      <author><first>Yanjiang</first><last>Liu</last><affiliation>University of Chinese Academy of Sciences</affiliation></author>
      <author><first>Ben</first><last>He</last><affiliation>University of Chinese Academy of Sciences</affiliation></author>
      <author><first>Le</first><last>Sun</last><affiliation>ISCAS</affiliation></author>
      <author><first>Yingfei</first><last>Sun</last><affiliation>University of Chinese Academy of Sciences</affiliation></author>
      <pages>10701-10717</pages>
      <abstract>The Differentiable Search Index (DSI) is a novel information retrieval (IR) framework that utilizes a differentiable function to generate a sorted list of document identifiers in response to a given query. However, due to the black-box nature of the end-to-end neural architecture, it remains to be understood to what extent DSI possesses the basic indexing and retrieval abilities. To mitigate this gap, in this study, we define and examine three important abilities that a functioning IR framework should possess, namely, exclusivity, completeness, and relevance ordering. Our analytical experimentation shows that while DSI demonstrates proficiency in memorizing the unidirectional mapping from pseudo queries to document identifiers, it falls short in distinguishing relevant documents from random ones, thereby negatively impacting its retrieval effectiveness. To address this issue, we propose a multi-task distillation approach to enhance the retrieval quality without altering the structure of the model and successfully endow it with improved indexing abilities. Through experiments conducted on various datasets, we demonstrate that our proposed method outperforms previous DSI baselinesThe code and data for this work can be found at <url>https://github.com/VerdureChen/Understang_DSI</url>.</abstract>
      <url hash="f471da1d">2023.findings-acl.681</url>
      <bibkey>chen-etal-2023-understanding</bibkey>
      <doi>10.18653/v1/2023.findings-acl.681</doi>
    </paper>
    <paper id="682">
      <title>Masked Audio Text Encoders are Effective Multi-Modal Rescorers</title>
      <author><first>Jinglun</first><last>Cai</last><affiliation>Amazon AWS AI</affiliation></author>
      <author><first>Monica</first><last>Sunkara</last><affiliation>Amazon</affiliation></author>
      <author><first>Xilai</first><last>Li</last><affiliation>Amazon</affiliation></author>
      <author><first>Anshu</first><last>Bhatia</last><affiliation>Amazon</affiliation></author>
      <author><first>Xiao</first><last>Pan</last><affiliation>Amazon</affiliation></author>
      <author><first>Sravan</first><last>Bodapati</last><affiliation>Amazon</affiliation></author>
      <pages>10718-10730</pages>
      <abstract>Masked Language Models (MLMs) have proven to be effective for second-pass rescoring in Automatic Speech Recognition (ASR) systems. In this work, we propose Masked Audio Text Encoder (MATE), a multi-modal masked language model rescorer which incorporates acoustic representations into the input space of MLM. We adopt contrastive learning for effectively aligning the modalities by learning shared representations. We show that using a multi-modal rescorer is beneficial for domain generalization of the ASR system when target domain data is unavailable. MATE reduces word error rate (WER) by 4%-16% on in-domain, and 3%-7% on out-of-domain datasets, over the text-only baseline. Additionally, with very limited amount of training data (0.8 hours) MATE achieves a WER reduction of 8%-23% over the first-pass baseline.</abstract>
      <url hash="b2089998">2023.findings-acl.682</url>
      <bibkey>cai-etal-2023-masked</bibkey>
      <doi>10.18653/v1/2023.findings-acl.682</doi>
    </paper>
    <paper id="683">
      <title>Replace and Report: <fixed-case>NLP</fixed-case> Assisted Radiology Report Generation</title>
      <author><first>Kaveri</first><last>Kale</last><affiliation>Indian Institute of Technology Bombay</affiliation></author>
      <author><first>Pushpak</first><last>Bhattacharyya</last><affiliation>Indian Institute of Technology Bombay and Patna</affiliation></author>
      <author><first>Kshitij</first><last>Jadhav</last><affiliation>Indian Institute of Technology Bombay</affiliation></author>
      <pages>10731-10742</pages>
      <abstract>Clinical practice frequently uses medical imaging for diagnosis and treatment. A significant challenge for automatic radiology report generation is that the radiology reports are long narratives consisting of multiple sentences for both abnormal and normal findings. Therefore, applying conventional image captioning approaches to generate the whole report proves to be insufficient, as these are designed to briefly describe images with short sentences. We propose a template-based approach to generate radiology reports from radiographs. Our approach involves the following: i) using a multilabel image classifier, produce the tags for the input radiograph; ii) using a transformer-based model, generate pathological descriptions (a description of abnormal findings seen on radiographs) from the tags generated in step (i); iii) using a BERT-based multi-label text classifier, find the spans in the normal report template to replace with the generated pathological descriptions; and iv) using a rule-based system, replace the identified span with the generated pathological description. We performed experiments with the two most popular radiology report datasets, IU Chest X-ray and MIMIC-CXR and demonstrated that the BLEU-1, ROUGE-L, METEOR, and CIDEr scores are better than the State-of-the-Art models by 25%, 36%, 44% and 48% respectively, on the IU X-RAY dataset. To the best of our knowledge, this is the first attempt to generate chest X-ray radiology reports by first creating small sentences for abnormal findings and then replacing them in the normal report template.</abstract>
      <url hash="5ea68662">2023.findings-acl.683</url>
      <bibkey>kale-etal-2023-replace</bibkey>
      <doi>10.18653/v1/2023.findings-acl.683</doi>
    </paper>
    <paper id="684">
      <title>Pre-trained Personalized Review Summarization with Effective Salience Estimation</title>
      <author><first>Hongyan</first><last>Xu</last><affiliation>hongyanxu@tju.edu.cn</affiliation></author>
      <author><first>Hongtao</first><last>Liu</last><affiliation>Du Xiaoman Financial</affiliation></author>
      <author><first>Zhepeng</first><last>Lv</last><affiliation>Duxiaoman</affiliation></author>
      <author><first>Qing</first><last>Yang</last><affiliation>Du Xiaoman Technology(Beijing)</affiliation></author>
      <author><first>Wenjun</first><last>Wang</last><affiliation>Tianjin University</affiliation></author>
      <pages>10743-10754</pages>
      <abstract>Personalized review summarization in recommender systems is a challenging task of generating condensed summaries for product reviews while preserving the salient content of reviews. Recently, Pretrained Language Models (PLMs) have become a new paradigm in text generation for the strong ability of natural language comprehension. However, it is nontrivial to apply PLMs in personalized review summarization directly since there are rich personalized information (e.g., user preferences and product characteristics) to be considered, which is crucial to the salience estimation of input review. In this paper, we propose a pre-trained personalized review summarization method, which aims to effectively incorporate the personalized information of users and products into the salience estimation of the input reviews. We design a personalized encoder that could identify the salient contents of the input sequence by jointly considering the semantic and personalized information respectively (i.e., ratings, user and product IDs, and linguistic features), yielding personalized representations for the input reviews and history summaries separately. Moreover, we design an interactive information selection mechanism that further identifies the salient contents of the input reviews and selects relative information from the history summaries. The results on real-world datasets show that our method performs better than the state-of-the-art baselines and could generate more readable summaries.</abstract>
      <url hash="69fdeb26">2023.findings-acl.684</url>
      <bibkey>xu-etal-2023-pre-trained</bibkey>
      <doi>10.18653/v1/2023.findings-acl.684</doi>
    </paper>
    <paper id="685">
      <title><fixed-case>C</fixed-case>a<fixed-case>PE</fixed-case>: Contrastive Parameter Ensembling for Reducing Hallucination in Abstractive Summarization</title>
      <author><first>Prafulla Kumar</first><last>Choubey</last><affiliation>Salesforce AI Research</affiliation></author>
      <author><first>Alex</first><last>Fabbri</last><affiliation>Salesforce AI Research</affiliation></author>
      <author><first>Jesse</first><last>Vig</last><affiliation>Salesforce Research</affiliation></author>
      <author><first>Chien-Sheng</first><last>Wu</last><affiliation>Salesforce</affiliation></author>
      <author><first>Wenhao</first><last>Liu</last><affiliation>Salesforce Research</affiliation></author>
      <author><first>Nazneen</first><last>Rajani</last><affiliation>Hugging Face</affiliation></author>
      <pages>10755-10773</pages>
      <abstract>Hallucination is a known issue for neural abstractive summarization models. Recent work suggests that the degree of hallucination may depend on factual errors in the training data. In this work, we propose a new method called Contrastive Parameter Ensembling (CaPE) to use training data more effectively, utilizing variations in noise in training samples to reduce hallucination. Starting with a base model fine-tuned on an entire dataset, we additionally train expert and anti-expert models on clean and noisy subsets of the data, respectively. We then adjust the parameters of the base model by adding (subtracting) the parameters of the expert (anti-expert), advancing the recent work on additive parameter ensembling approaches. Trained on a much smaller data subset, expert and anti-expert models only fractionally (&lt;14%) increases the total training time. Further, CaPE uses parameter ensembling and does not increase the inference time. Experimental results show that CaPE improves performance across different automatic factual metrics and human evaluation, with a maximum improvement of 16.69% and 15.38% on summary-level dependency-arc entailment accuracy for the XSUM and CNN/DM datasets. The CaPE model performs comparably to the base model on metrics of informativeness such as ROUGE.</abstract>
      <url hash="040d6e0a">2023.findings-acl.685</url>
      <bibkey>choubey-etal-2023-cape</bibkey>
      <doi>10.18653/v1/2023.findings-acl.685</doi>
    </paper>
    <paper id="686">
      <title><fixed-case>O</fixed-case>pine<fixed-case>S</fixed-case>um: Entailment-based self-training for abstractive opinion summarization</title>
      <author><first>Annie</first><last>Louis</last><affiliation>Google Research UK</affiliation></author>
      <author><first>Joshua</first><last>Maynez</last><affiliation>Google</affiliation></author>
      <pages>10774-10790</pages>
      <abstract>A typical product or place often has hundreds of reviews, and summarization of these texts is an important and challenging problem. Recent progress on abstractive summarization in domains such as news has been driven by supervised systems trained on hundreds of thousands of news articles paired with human-written summaries. However for opinion texts, such large scale datasets are rarely available. Unsupervised methods, self-training, and few-shot learning approaches bridge that gap. In this work, we present a novel self-training approach, OpineSum for abstractive opinion summarization. The self-training summaries in this approach are built automatically using a novel application of textual entailment and capture the consensus of opinions across the various reviews for an item. This method can be used to obtain silver-standard summaries on a large scale and train both unsupervised and few-shot abstractive summarization systems. OpineSum outperforms strong peer systems in both settings.</abstract>
      <url hash="cd67043a">2023.findings-acl.686</url>
      <bibkey>louis-maynez-2023-opinesum</bibkey>
      <doi>10.18653/v1/2023.findings-acl.686</doi>
    </paper>
    <paper id="687">
      <title>A Call for Standardization and Validation of Text Style Transfer Evaluation</title>
      <author><first>Phil</first><last>Ostheimer</last><affiliation>RPTU Kaiserslautern-Landau</affiliation></author>
      <author><first>Mayank Kumar</first><last>Nagda</last><affiliation>RPTU Kaiserslautern-Landau</affiliation></author>
      <author><first>Marius</first><last>Kloft</last><affiliation>RPTU Kaiserslautern-Landau</affiliation></author>
      <author><first>Sophie</first><last>Fellenz</last><affiliation>RPTU Kaiserslautern-Landau</affiliation></author>
      <pages>10791-10815</pages>
      <abstract>Text Style Transfer (TST) evaluation is, in practice, inconsistent. Therefore, we conduct a meta-analysis on human and automated TST evaluation and experimentation that thoroughly examines existing literature in the field. The meta-analysis reveals a substantial standardization gap in human and automated evaluation. In addition, we also find a validation gap: only few automated metrics have been validated using human experiments. To this end, we thoroughly scrutinize both the standardization and validation gap and reveal the resulting pitfalls. This work also paves the way to close the standardization and validation gap in TST evaluation by calling out requirements to be met by future research.</abstract>
      <url hash="6f550ef4">2023.findings-acl.687</url>
      <bibkey>ostheimer-etal-2023-call</bibkey>
      <doi>10.18653/v1/2023.findings-acl.687</doi>
    </paper>
    <paper id="688">
      <title>Bridging the Granularity Gap for Acoustic Modeling</title>
      <author><first>Chen</first><last>Xu</last><affiliation>Northeastern University</affiliation></author>
      <author><first>Yuhao</first><last>Zhang</last><affiliation>Northeastern University</affiliation></author>
      <author><first>Chengbo</first><last>Jiao</last><affiliation>University Of Electronic Science And Technology Of China</affiliation></author>
      <author><first>Xiaoqian</first><last>Liu</last><affiliation>Northeastern University</affiliation></author>
      <author><first>Chi</first><last>Hu</last><affiliation>Northeastern University</affiliation></author>
      <author><first>Xin</first><last>Zeng</last><affiliation>Northeastern University</affiliation></author>
      <author><first>Tong</first><last>Xiao</last><affiliation>Northeastern University</affiliation></author>
      <author><first>Anxiang</first><last>Ma</last><affiliation>Northeastern University</affiliation></author>
      <author><first>Huizhen</first><last>Wang</last><affiliation>Northeastern university</affiliation></author>
      <author><first>Jingbo</first><last>Zhu</last><affiliation>Northeastern University</affiliation></author>
      <pages>10816-10833</pages>
      <abstract>While Transformer has become the de-facto standard for speech, modeling upon the fine-grained frame-level features remains an open challenge of capturing long-distance dependencies and distributing the attention weights. We propose Progressive Down-Sampling (PDS) which gradually compresses the acoustic features into coarser-grained units containing more complete semantic information, like text-level representation. In addition, we develop a representation fusion method to alleviate information loss that occurs inevitably during high compression. In this way, we compress the acoustic features into 1/32 of the initial length while achieving better or comparable performances on the speech recognition task. And as a bonus, it yields inference speedups ranging from 1.20x to 1.47x.By reducing the modeling burden, we also achieve competitive results when training on the more challenging speech translation task.</abstract>
      <url hash="4ceba759">2023.findings-acl.688</url>
      <bibkey>xu-etal-2023-bridging</bibkey>
      <doi>10.18653/v1/2023.findings-acl.688</doi>
    </paper>
    <paper id="689">
      <title><fixed-case>MMSD</fixed-case>2.0: Towards a Reliable Multi-modal Sarcasm Detection System</title>
      <author><first>Libo</first><last>Qin</last><affiliation>Harbin Institute of Technology</affiliation></author>
      <author><first>Shijue</first><last>Huang</last><affiliation>Harbin Institute of Technology, Shenzhen</affiliation></author>
      <author><first>Qiguang</first><last>Chen</last><affiliation>Harbin Institute of Technology</affiliation></author>
      <author><first>Chenran</first><last>Cai</last><affiliation>Harbin Institute of Technology, Shenzhen</affiliation></author>
      <author><first>Yudi</first><last>Zhang</last><affiliation>Faculty of Computing, Harbin Institute of Technology</affiliation></author>
      <author><first>Bin</first><last>Liang</last><affiliation>Harbin Institute of Technology, Shenzhen</affiliation></author>
      <author><first>Wanxiang</first><last>Che</last><affiliation>Harbin Institute of Technology</affiliation></author>
      <author><first>Ruifeng</first><last>Xu</last><affiliation>Harbin Institute of Technology, Shenzhen</affiliation></author>
      <pages>10834-10845</pages>
      <abstract>Multi-modal sarcasm detection has attracted much recent attention. Nevertheless, the existing benchmark (MMSD) has some shortcomings that hinder the development of reliable multi-modal sarcasm detection system: (1) There are some spurious cues in MMSD, leading to the model bias learning; (2) The negative samples in MMSD are not always reasonable. To solve the aforementioned issues, we introduce MMSD2.0, a correction dataset that fixes the shortcomings of MMSD, by removing the spurious cues and re-annotating the unreasonable samples. Meanwhile, we present a novel framework called multi-view CLIP that is capable of leveraging multi-grained cues from multiple perspectives (i.e., text, image, and text-image interaction view) for multi-modal sarcasm detection. Extensive experiments show that MMSD2.0 is a valuable benchmark for building reliable multi-modal sarcasm detection systems and multi-view CLIP can significantly outperform the previous best baselines.</abstract>
      <url hash="30ec3129">2023.findings-acl.689</url>
      <bibkey>qin-etal-2023-mmsd2</bibkey>
      <doi>10.18653/v1/2023.findings-acl.689</doi>
    </paper>
    <paper id="690">
      <title>Learn to Not Link: Exploring <fixed-case>NIL</fixed-case> Prediction in Entity Linking</title>
      <author><first>Fangwei</first><last>Zhu</last><affiliation>Peking University</affiliation></author>
      <author><first>Jifan</first><last>Yu</last><affiliation>Tsinghua University</affiliation></author>
      <author><first>Hailong</first><last>Jin</last><affiliation>Tsinghua University</affiliation></author>
      <author><first>Lei</first><last>Hou</last><affiliation>Tsinghua University</affiliation></author>
      <author><first>Juanzi</first><last>Li</last><affiliation>Tsinghua University</affiliation></author>
      <author><first>Zhifang</first><last>Sui</last><affiliation>Peking University</affiliation></author>
      <pages>10846-10860</pages>
      <abstract>Entity linking models have achieved significant success via utilizing pretrained language models to capture semantic features. However, the NIL prediction problem, which aims to identify mentions without a corresponding entity in the knowledge base, has received insufficient attention. We categorize mentions linking to NIL into Missing Entity and Non-Entity Phrase, and propose an entity linking dataset NEL that focuses on the NIL prediction problem.NEL takes ambiguous entities as seeds, collects relevant mention context in the Wikipedia corpus, and ensures the presence of mentions linking to NIL by human annotation and entity masking. We conduct a series of experiments with the widely used bi-encoder and cross-encoder entity linking models, results show that both types of NIL mentions in training data have a significant influence on the accuracy of NIL prediction. Our code and dataset can be accessed at <url>https://github.com/solitaryzero/NIL_EL</url>.</abstract>
      <url hash="e44dd12b">2023.findings-acl.690</url>
      <bibkey>zhu-etal-2023-learn</bibkey>
      <doi>10.18653/v1/2023.findings-acl.690</doi>
    </paper>
    <paper id="691">
      <title>On Text-based Personality Computing: Challenges and Future Directions</title>
      <author><first>Qixiang</first><last>Fang</last><affiliation>Utrecht University</affiliation></author>
      <author><first>Anastasia</first><last>Giachanou</last><affiliation>Utrecht University</affiliation></author>
      <author><first>Ayoub</first><last>Bagheri</last><affiliation>Department of Methodology and Statistics, Utrecht University</affiliation></author>
      <author><first>Laura</first><last>Boeschoten</last><affiliation>Utrecht University</affiliation></author>
      <author><first>Erik-Jan</first><last>van Kesteren</last><affiliation>Utrecht University</affiliation></author>
      <author><first>Mahdi</first><last>Shafiee Kamalabad</last><affiliation>Utrecht University</affiliation></author>
      <author><first>Daniel</first><last>Oberski</last><affiliation>Utrecht University</affiliation></author>
      <pages>10861-10879</pages>
      <abstract>Text-based personality computing (TPC) has gained many research interests in NLP. In this paper, we describe 15 challenges that we consider deserving the attention of the NLP research community. These challenges are organized by the following topics: personality taxonomies, measurement quality, datasets, performance evaluation, modelling choices, as well as ethics and fairness. When addressing each challenge, not only do we combine perspectives from both NLP and social sciences, but also offer concrete suggestions. We hope to inspire more valid and reliable TPC research.</abstract>
      <url hash="8b7e3207">2023.findings-acl.691</url>
      <bibkey>fang-etal-2023-text</bibkey>
      <doi>10.18653/v1/2023.findings-acl.691</doi>
    </paper>
    <paper id="692">
      <title>Structured Pruning for Efficient Generative Pre-trained Language Models</title>
      <author><first>Chaofan</first><last>Tao</last><affiliation>University of Hong Kong</affiliation></author>
      <author><first>Lu</first><last>Hou</last><affiliation>Huawei Noah’s Ark Lab</affiliation></author>
      <author><first>Haoli</first><last>Bai</last><affiliation>Huawei Noah’s Ark Lab</affiliation></author>
      <author><first>Jiansheng</first><last>Wei</last><affiliation>Huawei</affiliation></author>
      <author><first>Xin</first><last>Jiang</last><affiliation>Huawei Noah’s Ark Lab</affiliation></author>
      <author><first>Qun</first><last>Liu</last><affiliation>Huawei Noah’s Ark Lab</affiliation></author>
      <author><first>Ping</first><last>Luo</last><affiliation>The University of Hong Kong</affiliation></author>
      <author><first>Ngai</first><last>Wong</last><affiliation>The University of Hong Kong</affiliation></author>
      <pages>10880-10895</pages>
      <abstract>The increasing sizes of large generative Pre-trained Language Models (PLMs) hinder their deploymentin real-world applications. To obtain efficient PLMs, previous studies mostly focus on pruning the attention heads and feed-forward networks (FFNs) of the Transformer. Nevertheless, we find that in generative PLMs, the hidden dimension shared by many other modules (e.g., embedding layer and layer normalization) contains persistent outliers regardless of the network input. This study comprehensively investigates the structured pruning of generative PLMs with all the above compressible components. To identify redundant network structures, we assign learnable masks over compressible components followed by sparse training. Various sizes of PLMs can be flexibly extracted via different thresholds, and are then task-specifically fine-tuned for further improvement. Extensive experiments on language modeling, summarization and machine translation validate the effectiveness of the proposed method. For example, the pruned BART brings 1.51x/6.96x inference speedup on GPU/CPU with 67% size reduction, and can be further combined with quantization for more than 25<tex-math>\times</tex-math> compression.</abstract>
      <url hash="9e367bdc">2023.findings-acl.692</url>
      <bibkey>tao-etal-2023-structured</bibkey>
      <doi>10.18653/v1/2023.findings-acl.692</doi>
    </paper>
    <paper id="693">
      <title>Prompt-Guided Retrieval Augmentation for Non-Knowledge-Intensive Tasks</title>
      <author><first>Zhicheng</first><last>Guo</last><affiliation>Tsinghua University</affiliation></author>
      <author><first>Sijie</first><last>Cheng</last><affiliation>Fudan University</affiliation></author>
      <author><first>Yile</first><last>Wang</last><affiliation>Tsinghua University</affiliation></author>
      <author><first>Peng</first><last>Li</last><affiliation>Institute for AI Industry Research (AIR), Tsinghua University, China</affiliation></author>
      <author id="yang-liu"><first>Yang</first><last>Liu</last><affiliation>Tsinghua University</affiliation></author>
      <pages>10896-10912</pages>
      <abstract>Retrieval-augmented methods have received increasing attention to support downstream tasks by leveraging useful information from external resources. Recent studies mainly focus on exploring retrieval to solve knowledge-intensive (KI) tasks. However, the potential of retrieval for most non-knowledge-intensive (NKI) tasks remains under-explored. There are two main challenges to leveraging retrieval-augmented methods for NKI tasks: 1) the demand for diverse relevance score functions and 2) the dilemma between training cost and task performance. To address these challenges, we propose a two-stage framework for NKI tasks, named PGRA. In the first stage, we adopt a task-agnostic retriever to build a shared static index and select candidate evidence efficiently. In the second stage, we design a prompt-guided reranker to rerank the nearest evidence according to task-specific relevance for the reader. Experimental results show that PGRA outperforms other state-of-the-art retrieval-augmented methods. Our analyses further investigate the influence factors to model performance and demonstrate the generality of PGRA. The code and model will be released for further research.</abstract>
      <url hash="ae2c53c2">2023.findings-acl.693</url>
      <bibkey>guo-etal-2023-prompt</bibkey>
      <doi>10.18653/v1/2023.findings-acl.693</doi>
    </paper>
    <paper id="694">
      <title>Contextualized Semantic Distance between Highly Overlapped Texts</title>
      <author><first>Letian</first><last>Peng</last><affiliation>UCSD</affiliation></author>
      <author><first>Zuchao</first><last>Li</last><affiliation>Wuhan University</affiliation></author>
      <author><first>Hai</first><last>Zhao</last><affiliation>Shanghai Jiao Tong University</affiliation></author>
      <pages>10913-10931</pages>
      <abstract>Overlapping frequently occurs in paired texts in natural language processing tasks like text editing and semantic similarity evaluation. Better evaluation of the semantic distance between the overlapped sentences benefits the language system’s understanding and guides the generation. Since conventional semantic metrics are based on word representations, they are vulnerable to the disturbance of overlapped components with similar representations. This paper aims to address the issue with a mask-and-predict strategy. We take the words in the longest common sequence (LCS) as neighboring words and use masked language modeling (MLM) from pre-trained language models (PLMs) to predict the distributions in their positions. Our metric, Neighboring Distribution Divergence (NDD), represents the semantic distance by calculating the divergence between distributions in the overlapped parts. Experiments on Semantic Textual Similarity show NDD to be more sensitive to various semantic differences, especially on highly overlapped paired texts. Based on the discovery, we further implement an unsupervised and training-free method for text compression, leading to a significant improvement on the previous perplexity-based method. The high compression rate controlling ability of our method even enables NDD to outperform the supervised state-of-the-art in domain adaption by a huge margin. Further experiments on syntax and semantics analyses verify the awareness of internal sentence structures, indicating the high potential of NDD for further studies.</abstract>
      <url hash="0db0235c">2023.findings-acl.694</url>
      <bibkey>peng-etal-2023-contextualized</bibkey>
      <doi>10.18653/v1/2023.findings-acl.694</doi>
    </paper>
    <paper id="695">
      <title>Unsupervised Dense Retrieval with Relevance-Aware Contrastive Pre-Training</title>
      <author><first>Yibin</first><last>Lei</last><affiliation>University of Amsterdam</affiliation></author>
      <author><first>Liang</first><last>Ding</last><affiliation>JD Explore Academy, JD.com Inc. &amp; The University of Sydney</affiliation></author>
      <author><first>Yu</first><last>Cao</last><affiliation>School of Computer Science, The University of Sydney</affiliation></author>
      <author><first>Changtong</first><last>Zan</last><affiliation>China University of Petroleum(East China)</affiliation></author>
      <author><first>Andrew</first><last>Yates</last><affiliation>University of Amsterdam</affiliation></author>
      <author><first>Dacheng</first><last>Tao</last><affiliation>School of Computer Science, The University of Sydney</affiliation></author>
      <pages>10932-10940</pages>
      <abstract>Dense retrievers have achieved impressive performance, but their demand for abundant training data limits their application scenarios. Contrastive pre-training, which constructs pseudo-positive examples from unlabeled data, has shown great potential to solve this problem. However, the pseudo-positive examples crafted by data augmentations can be irrelevant. To this end, we propose relevance-aware contrastive learning. It takes the intermediate-trained model itself as an imperfect oracle to estimate the relevance of positive pairs and adaptively weighs the contrastive loss of different pairs according to the estimated relevance. Our method consistently improves the SOTA unsupervised Contriever model on the BEIR and open-domain QA retrieval benchmarks. Further exploration shows that our method can not only beat BM25 after further pre-training on the target corpus but also serves as a good few-shot learner. Our code is publicly available at <url>https://github.com/Yibin-Lei/ReContriever</url>.</abstract>
      <url hash="2d88cd0e">2023.findings-acl.695</url>
      <bibkey>lei-etal-2023-unsupervised</bibkey>
      <doi>10.18653/v1/2023.findings-acl.695</doi>
    </paper>
    <paper id="696">
      <title>Verifying Annotation Agreement without Multiple Experts: A Case Study with <fixed-case>G</fixed-case>ujarati <fixed-case>SNACS</fixed-case></title>
      <author><first>Maitrey</first><last>Mehta</last><affiliation>University of Utah</affiliation></author>
      <author><first>Vivek</first><last>Srikumar</last><affiliation>University of Utah</affiliation></author>
      <pages>10941-10958</pages>
      <abstract>Good datasets are a foundation of NLP research, and form the basis for training and evaluating models of language use. While creating datasets, the standard practice is to verify the annotation consistency using a committee of human annotators. This norm assumes that multiple annotators are available, which is not the case for highly specialized tasks or low-resource languages. In this paper, we ask: Can we evaluate the quality of a dataset constructed by a single human annotator? To address this question, we propose four weak verifiers to help estimate dataset quality, and outline when each may be employed. We instantiate these strategies for the task of semantic analysis of adpositions in Gujarati, a low-resource language, and show that our weak verifiers concur with a double-annotation study. As an added contribution, we also release the first dataset with semantic annotations in Gujarati along with several model baselines.</abstract>
      <url hash="36202442">2023.findings-acl.696</url>
      <bibkey>mehta-srikumar-2023-verifying</bibkey>
      <doi>10.18653/v1/2023.findings-acl.696</doi>
    </paper>
    <paper id="697">
      <title>Reinforced Active Learning for Low-Resource, Domain-Specific, Multi-Label Text Classification</title>
      <author><first>Lukas</first><last>Wertz</last><affiliation>University of Stuttgart</affiliation></author>
      <author><first>Jasmina</first><last>Bogojeska</last><affiliation>ZHAW</affiliation></author>
      <author><first>Katsiaryna</first><last>Mirylenka</last><affiliation>IBM Research Europe</affiliation></author>
      <author><first>Jonas</first><last>Kuhn</last><affiliation>University of Stuttgart</affiliation></author>
      <pages>10959-10977</pages>
      <abstract>Text classification datasets from specialised or technical domains are in high demand, especially in industrial applications. However, due to the high cost of annotation such datasets are usually expensive to create. While Active Learning (AL) can reduce the labeling cost, required AL strategies are often only tested on general knowledge domains and tend to use information sources that are not consistent across tasks. We propose Reinforced Active Learning (RAL) to train a Reinforcement Learning policy that utilizes many different aspects of the data and the task in order to select the most informative unlabeled subset dynamically over the course of the AL procedure. We demonstrate the superior performance of the proposed RAL framework compared to strong AL baselines across four intricate multi-class, multi-label text classification datasets taken from specialised domains. In addition, we experiment with a unique data augmentation approach to further reduce the number of samples RAL needs to annotate.</abstract>
      <url hash="3d9c8c8b">2023.findings-acl.697</url>
      <bibkey>wertz-etal-2023-reinforced</bibkey>
      <doi>10.18653/v1/2023.findings-acl.697</doi>
    </paper>
    <paper id="698">
      <title>Improving Classroom Dialogue Act Recognition from Limited Labeled Data with Self-Supervised Contrastive Learning Classifiers</title>
      <author><first>Vikram</first><last>Kumaran</last><affiliation>North Carolina State University</affiliation></author>
      <author><first>Jonathan</first><last>Rowe</last><affiliation>North Carolina State University</affiliation></author>
      <author><first>Bradford</first><last>Mott</last><affiliation>North Carolina State University</affiliation></author>
      <author><first>Snigdha</first><last>Chaturvedi</last><affiliation>University of North Carolina, Chapel Hill</affiliation></author>
      <author><first>James</first><last>Lester</last><affiliation>North Carolina State University</affiliation></author>
      <pages>10978-10992</pages>
      <abstract>Recognizing classroom dialogue acts has significant promise for yielding insight into teaching, student learning, and classroom dynamics. However, obtaining K-12 classroom dialogue data with labels is a significant challenge, and therefore, developing data-efficient methods for classroom dialogue act recognition is essential. This work addresses the challenge of classroom dialogue act recognition from limited labeled data using a contrastive learning-based self-supervised approach (SSCon). SSCon uses two independent models that iteratively improve each other’s performance by increasing the accuracy of dialogue act recognition and minimizing the embedding distance between the same dialogue acts. We evaluate the approach on three complementary dialogue act recognition datasets: the TalkMoves dataset (annotated K-12 mathematics lesson transcripts), the DailyDialog dataset (multi-turn daily conversation dialogues), and the Dialogue State Tracking Challenge 2 (DSTC2) dataset (restaurant reservation dialogues). Results indicate that our self-supervised contrastive learning-based model outperforms competitive baseline models when trained with limited examples per dialogue act. Furthermore, SSCon outperforms other few-shot models that require considerably more labeled data.</abstract>
      <url hash="36cc4945">2023.findings-acl.698</url>
      <bibkey>kumaran-etal-2023-improving</bibkey>
      <doi>10.18653/v1/2023.findings-acl.698</doi>
    </paper>
    <paper id="699">
      <title>Contrastive Token-Wise Meta-Learning for Unseen Performer Visual Temporal-Aligned Translation</title>
      <author><first>Linjun</first><last>Li</last><affiliation>Zhejiang University</affiliation></author>
      <author><first>Tao</first><last>Jin</last><affiliation>Zhejiang University</affiliation></author>
      <author><first>Xize</first><last>Cheng</last><affiliation>Zhejiang University</affiliation></author>
      <author><first>Ye</first><last>Wang</last><affiliation>Zhejiang University</affiliation></author>
      <author><first>Wang</first><last>Lin</last><affiliation>zhejiang university</affiliation></author>
      <author><first>Rongjie</first><last>Huang</last><affiliation>Zhejiang University</affiliation></author>
      <author><first>Zhou</first><last>Zhao</last><affiliation>zhejiang university</affiliation></author>
      <pages>10993-11007</pages>
      <abstract>Visual temporal-aligned translation aims to transform the visual sequence into natural words, including important applicable tasks such as lipreading and fingerspelling recognition. However, various performance habits of specific words by different speakers or signers can lead to visual ambiguity, which has become a major obstacle to the development of current methods. Considering the constraints above, the generalization ability of the translation system is supposed to be further explored through the evaluation results on unseen performers. In this paper, we develop a novel generalizable framework named Contrastive Token-Wise Meta-learning (CtoML), which strives to transfer recognition skills to unseen performers. To the best of our knowledge, employing meta-learning methods directly in the image domain poses two main challenges, and we propose corresponding strategies. First, sequence prediction in visual temporal-aligned translation, which aims to generate multiple words autoregressively, is different from the vanilla classification. Thus, we devise the token-wise diversity-aware weights for the meta-train stage, which encourages the model to make efforts on those ambiguously recognized tokens. Second, considering the consistency of word-visual prototypes across different domains, we develop two complementary global and local contrastive losses to maintain inter-class relationships and promote domain-independent. We conduct extensive experiments on the widely-used lipreading dataset GRID and the fingerspelling dataset ChicagoFSWild, and the experimental results show the effectiveness of our proposed CtoML over existing state-of-the-art methods.</abstract>
      <url hash="6dd03525">2023.findings-acl.699</url>
      <bibkey>li-etal-2023-contrastive-token</bibkey>
      <doi>10.18653/v1/2023.findings-acl.699</doi>
    </paper>
    <paper id="700">
      <title>Enhancing Cross-lingual Prompting with Dual Prompt Augmentation</title>
      <author><first>Meng</first><last>Zhou</last><affiliation>Carnegie Mellon University</affiliation></author>
      <author><first>Xin</first><last>Li</last><affiliation>Alibaba Group</affiliation></author>
      <author><first>Yue</first><last>Jiang</last><affiliation>Carnegie Mellon University</affiliation></author>
      <author><first>Lidong</first><last>Bing</last><affiliation>Alibaba DAMO Academy</affiliation></author>
      <pages>11008-11020</pages>
      <abstract>Prompting shows promising results in few-shot scenarios. However, its strength for multilingual/cross-lingual problems has not been fully exploited. hao and Schütze (2021) made initial explorations in this direction by presenting that cross-lingual prompting outperforms cross-lingual finetuning. In this paper, we conduct an empirical exploration on the effect of each component in cross-lingual prompting and derive Universal Prompting, which helps alleviate the discrepancies between source-language training and target-language inference. Based on this, we propose DPA, a dual prompt augmentation framework, aiming at relieving the data scarcity issue in few-shot cross-lingual prompting. Notably, for XNLI, our method achieves 46.54% with only 16 English training examples per class, significantly better than 34.99% of fine-tuning. Our code is available at <url>https://github.com/DAMO-NLP-SG/DPA</url>.</abstract>
      <url hash="8fd589a8">2023.findings-acl.700</url>
      <bibkey>zhou-etal-2023-enhancing</bibkey>
      <doi>10.18653/v1/2023.findings-acl.700</doi>
    </paper>
    <paper id="701">
      <title>Foveate, Attribute, and Rationalize: Towards Physically Safe and Trustworthy <fixed-case>AI</fixed-case></title>
      <author><first>Alex</first><last>Mei</last><affiliation>University of California, Santa Barbara</affiliation></author>
      <author><first>Sharon</first><last>Levy</last><affiliation>UC Santa Barbara</affiliation></author>
      <author><first>William Yang</first><last>Wang</last><affiliation>Unversity of California, Santa Barbara</affiliation></author>
      <pages>11021-11036</pages>
      <abstract>Users’ physical safety is an increasing concern as the market for intelligent systems continues to grow, where unconstrained systems may recommend users dangerous actions that can lead to serious injury. Covertly unsafe text is an area of particular interest, as such text may arise from everyday scenarios and are challenging to detect as harmful. We propose FARM, a novel framework leveraging external knowledge for trustworthy rationale generation in the context of safety. In particular, FARM foveates on missing knowledge to qualify the information required to reason in specific scenarios and retrieves this information with attribution to trustworthy sources. This knowledge is used to both classify the safety of the original text and generate human-interpretable rationales, shedding light on the risk of systems to specific user groups and helping both stakeholders manage the risks of their systems and policymakers to provide concrete safeguards for consumer safety. Our experiments show that FARM obtains state-of-the-art results on the SafeText dataset, showing absolute improvement in safety classification accuracy by 5.9%.</abstract>
      <url hash="bb85268c">2023.findings-acl.701</url>
      <bibkey>mei-etal-2023-foveate</bibkey>
      <doi>10.18653/v1/2023.findings-acl.701</doi>
    </paper>
    <paper id="702">
      <title>Multijugate Dual Learning for Low-Resource Task-Oriented Dialogue System</title>
      <author><first>Shimin</first><last>Li</last><affiliation>Fudan University</affiliation></author>
      <author><first>Xiaotian</first><last>Zhang</last><affiliation>Fudan University</affiliation></author>
      <author><first>Yanjun</first><last>Zheng</last><affiliation>Fudan University</affiliation></author>
      <author><first>Linyang</first><last>Li</last><affiliation>Fudan University</affiliation></author>
      <author><first>Xipeng</first><last>Qiu</last><affiliation>Fudan University</affiliation></author>
      <pages>11037-11053</pages>
      <abstract>Dialogue data in real scenarios tend to be sparsely available, rendering data-starved end-to-end dialogue systems trained inadequately. We discover that data utilization efficiency in low-resource scenarios can be enhanced by mining alignment information uncertain utterance and deterministic dialogue state. Therefore, we innovatively implement dual learning in task-oriented dialogues to exploit the correlation of heterogeneous data. In addition, the one-to-one duality is converted into a multijugate duality to reduce the influence of spurious correlations in dual training for generalization. Without introducing additional parameters, our method could be implemented in arbitrary networks. Extensive empirical analyses demonstrate that our proposed method improves the effectiveness of end-to-end task-oriented dialogue systems under multiple benchmarks and obtains state-of-the-art results in low-resource scenarios.</abstract>
      <url hash="6cb4ab94">2023.findings-acl.702</url>
      <bibkey>li-etal-2023-multijugate</bibkey>
      <doi>10.18653/v1/2023.findings-acl.702</doi>
    </paper>
    <paper id="703">
      <title>A Class-Rebalancing Self-Training Framework for Distantly-Supervised Named Entity Recognition</title>
      <author><first>Qi</first><last>Li</last><affiliation>Zhejiang University</affiliation></author>
      <author><first>Tingyu</first><last>Xie</last><affiliation>Zhejiang University</affiliation></author>
      <author><first>Peng</first><last>Peng</last><affiliation>Zhejiang University</affiliation></author>
      <author><first>Hongwei</first><last>Wang</last><affiliation>Zhejiang University-University of Illinois at Urbana-Champaign Institute</affiliation></author>
      <author><first>Gaoang</first><last>Wang</last><affiliation>Zhejiang University</affiliation></author>
      <pages>11054-11068</pages>
      <abstract>Distant supervision reduces the reliance on human annotation in the named entity recognition tasks. The class-level imbalanced distant annotation is a realistic and unexplored problem, and the popular method of self-training can not handle class-level imbalanced learning. More importantly, self-training is dominated by the high-performance class in selecting candidates, and deteriorates the low-performance class with the bias of generated pseudo label. To address the class-level imbalance performance, we propose a class-rebalancing self-training framework for improving the distantly-supervised named entity recognition. In candidate selection, a class-wise flexible threshold is designed to fully explore other classes besides the high-performance class. In label generation, injecting the distant label, a hybrid pseudo label is adopted to provide straight semantic information for the low-performance class. Experiments on five flat and two nested datasets show that our model achieves state-of-the-art results. We also conduct extensive research to analyze the effectiveness of the flexible threshold and the hybrid pseudo label.</abstract>
      <url hash="334dd5fb">2023.findings-acl.703</url>
      <bibkey>li-etal-2023-class</bibkey>
      <doi>10.18653/v1/2023.findings-acl.703</doi>
    </paper>
    <paper id="704">
      <title><fixed-case>MURMUR</fixed-case>: Modular Multi-Step Reasoning for Semi-Structured Data-to-Text Generation</title>
      <author><first>Swarnadeep</first><last>Saha</last><affiliation>University of North Carolina at Chapel Hill</affiliation></author>
      <author><first>Xinyan</first><last>Yu</last><affiliation>University of Washington</affiliation></author>
      <author><first>Mohit</first><last>Bansal</last><affiliation>University of North Carolina at Chapel Hill</affiliation></author>
      <author><first>Ramakanth</first><last>Pasunuru</last><affiliation>Meta</affiliation></author>
      <author><first>Asli</first><last>Celikyilmaz</last><affiliation>FAIR @ Meta</affiliation></author>
      <pages>11069-11090</pages>
      <abstract>Prompting large language models has enabled significant recent progress in multi-step reasoning over text. However, when applied to text generation from semi-structured data (e.g., graphs or tables), these methods typically suffer from low semantic coverage, hallucination, and logical inconsistency. We propose MURMUR a neuro-symbolic modular approach to text generation from semi-structured data with multi-step reasoning. MURMUR is a best-first search method that generates reasoning paths using: (1) neural and symbolic modules with specific linguistic and logical skills, (2) a grammar whose production rules define valid compositions of modules, and (3) value functions that assess the quality of each reasoning step. We conduct experiments on two diverse data-to-text generation tasks like WebNLG and LogicNLG. The tasks differ in their data representations (graphs and tables) and span multiple linguistic and logical skills. MURMUR obtains significant improvements over recent few-shot baselines like direct prompting and chain-of-thought prompting, while also achieving comparable performance to fine-tuned GPT-2 on out-of-domain data. Moreover, human evaluation shows that MURMUR generates highly faithful and correct reasoning paths that lead to 26% more logically consistent summaries on LogicNLG, compared to direct prompting.</abstract>
      <url hash="18b19bd9">2023.findings-acl.704</url>
      <bibkey>saha-etal-2023-murmur</bibkey>
      <doi>10.18653/v1/2023.findings-acl.704</doi>
    </paper>
    <paper id="705">
      <title>Learning by Analogy: Diverse Questions Generation in Math Word Problem</title>
      <author><first>Zihao</first><last>Zhou</last><affiliation>Xi’an Jiaotong-liverpool University</affiliation></author>
      <author><first>Maizhen</first><last>Ning</last><affiliation>Xi’an Jiaotong-Liverpool University</affiliation></author>
      <author><first>Qiufeng</first><last>Wang</last><affiliation>Xi’anJiaoTong-Liverpool University</affiliation></author>
      <author><first>Jie</first><last>Yao</last><affiliation>Xi’an Jiaotong-Liverpool University</affiliation></author>
      <author><first>Wei</first><last>Wang</last><affiliation>Xi’an Jiaotong Liverpool University</affiliation></author>
      <author><first>Xiaowei</first><last>Huang</last><affiliation>university of liverpool</affiliation></author>
      <author><first>Kaizhu</first><last>Huang</last><affiliation>Duke Kunshan University</affiliation></author>
      <pages>11091-11104</pages>
      <abstract>Solving math word problem (MWP) with AI techniques has recently made great progress with the success of deep neural networks (DNN), but it is far from being solved. We argue that the ability of learning by analogy is essential for an MWP solver to better understand same problems which may typically be formulated in diverse ways. However most existing works exploit the shortcut learning to train MWP solvers simply based on samples with a single question. In lack of diverse questions, these methods merely learn shallow heuristics. In this paper, we make a first attempt to solve MWPs by generating diverse yet consistent questions/equations. Given a typical MWP including the scenario description, question, and equation (i.e., answer), we first generate multiple consistent equations via a group of heuristic rules. We then feed them to a question generator together with the scenario to obtain the corresponding diverse questions, forming a new MWP with a variety of questions and equations. Finally we engage a data filter to remove those unreasonable MWPs, keeping the high-quality augmented ones. To evaluate the ability of learning by analogy for an MWP solver, we generate a new MWP dataset (called DiverseMath23K) with diverse questions by extending the current benchmark Math23K. Extensive experimental results demonstrate that our proposed method can generate high-quality diverse questions with corresponding equations, further leading to performance improvement on Diverse-Math23K. The code and dataset is available at: <url>https://github.com/zhouzihao501/DiverseMWP</url>.</abstract>
      <url hash="7b386ae9">2023.findings-acl.705</url>
      <bibkey>zhou-etal-2023-learning-analogy</bibkey>
      <doi>10.18653/v1/2023.findings-acl.705</doi>
    </paper>
    <paper id="706">
      <title>Revisit Few-shot Intent Classification with <fixed-case>PLM</fixed-case>s: Direct Fine-tuning vs. Continual Pre-training</title>
      <author><first>Haode</first><last>Zhang</last><affiliation>The Hong Kong Polytechnic University</affiliation></author>
      <author><first>Haowen</first><last>Liang</last><affiliation>The Hong Kong Polytechnic University</affiliation></author>
      <author><first>Li-Ming</first><last>Zhan</last><affiliation>The Hong Kong Polytechnic University</affiliation></author>
      <author><first>Xiao-Ming</first><last>Wu</last><affiliation>Hong Kong Polytechnic University</affiliation></author>
      <author><first>Albert Y.S.</first><last>Lam</last><affiliation>Fano Labs</affiliation></author>
      <pages>11105-11121</pages>
      <abstract>We consider the task of few-shot intent detection, which involves training a deep learning model to classify utterances based on their underlying intents using only a small amount of labeled data. The current approach to address this problem is through continual pre-training, i.e., fine-tuning pre-trained language models (PLMs) on external resources (e.g., conversational corpora, public intent detection datasets, or natural language understanding datasets) before using them as utterance encoders for training an intent classifier. In this paper, we show that continual pre-training may not be essential, since the overfitting problem of PLMs on this task may not be as serious as expected. Specifically, we find that directly fine-tuning PLMs on only a handful of labeled examples already yields decent results compared to methods that employ continual pre-training, and the performance gap diminishes rapidly as the number of labeled data increases. To maximize the utilization of the limited available data, we propose a context augmentation method and leverage sequential self-distillation to boost performance. Comprehensive experiments on real-world benchmarks show that given only two or more labeled samples per class, direct fine-tuning outperforms many strong baselines that utilize external data sources for continual pre-training. The code can be found at <url>https://github.com/hdzhang-code/DFTPlus</url>.</abstract>
      <url hash="811ea19b">2023.findings-acl.706</url>
      <bibkey>zhang-etal-2023-revisit</bibkey>
      <doi>10.18653/v1/2023.findings-acl.706</doi>
    </paper>
    <paper id="707">
      <title>Improving Contrastive Learning of Sentence Embeddings from <fixed-case>AI</fixed-case> Feedback</title>
      <author><first>Qinyuan</first><last>Cheng</last><affiliation>Fudan University</affiliation></author>
      <author><first>Xiaogui</first><last>Yang</last><affiliation>Fudan University</affiliation></author>
      <author><first>Tianxiang</first><last>Sun</last><affiliation>Fudan University</affiliation></author>
      <author><first>Linyang</first><last>Li</last><affiliation>Fudan University</affiliation></author>
      <author><first>Xipeng</first><last>Qiu</last><affiliation>Fudan University</affiliation></author>
      <pages>11122-11138</pages>
      <abstract>Contrastive learning has become a popular approach in natural language processing, particularly for the learning of sentence embeddings.However, the discrete nature of natural language makes it difficult to ensure the quality of positive and negative sample pairs generated through data augmentation methods. Although supervised contrastive learning can produce more accurate sample pairs with human feedback labels, it still lacks fine-grained training signals. In this paper, we propose to improve Contrastive Learning of sentence embeddings from AI Feedback (CLAIF).Our method utilizes AI feedback from large pre-trained language models (LLMs) to construct sample pairs with fine-grained sample similarity scores to improve contrastive learning. Besides, we combine human feedback and AI feedback to provide better supervision signals for supervised contrastive learning of sentence embeddings.Experimental results show that our method achieves state-of-the-art performance on several semantic textual similarity (STS) and transfer learning tasks compared to other unsupervised and supervised contrastive learning methods.</abstract>
      <url hash="e3b454e1">2023.findings-acl.707</url>
      <bibkey>cheng-etal-2023-improving</bibkey>
      <doi>10.18653/v1/2023.findings-acl.707</doi>
    </paper>
    <paper id="708">
      <title><fixed-case>M</fixed-case>ars: Modeling Context &amp; State Representations with Contrastive Learning for End-to-End Task-Oriented Dialog</title>
      <author><first>Haipeng</first><last>Sun</last><affiliation>JD</affiliation></author>
      <author><first>Junwei</first><last>Bao</last><affiliation>JD AI Research</affiliation></author>
      <author><first>Youzheng</first><last>Wu</last><affiliation>JD AI Research</affiliation></author>
      <author><first>Xiaodong</first><last>He</last><affiliation>JD AI Research</affiliation></author>
      <pages>11139-11160</pages>
      <abstract>Traditional end-to-end task-oriented dialog systems first convert dialog context into belief state and action state before generating the system response. The system response performance is significantly affected by the quality of the belief state and action state. We first explore what dialog context representation is beneficial to improving the quality of the belief state and action state, which further enhances the generated response quality. To tackle our exploration, we propose Mars, an end-to-end task-oriented dialog system with two contrastive learning strategies to model the relationship between dialog context and belief/action state representations. Empirical results show dialog context representations, which are more different from semantic state representations, are more conducive to multi-turn task-oriented dialog. Moreover, our proposed Mars achieves state-of-the-art performance on the MultiWOZ 2.0, CamRest676, and CrossWOZ.</abstract>
      <url hash="b4f1a291">2023.findings-acl.708</url>
      <bibkey>sun-etal-2023-mars</bibkey>
      <doi>10.18653/v1/2023.findings-acl.708</doi>
    </paper>
    <paper id="709">
      <title>Text Augmented Open Knowledge Graph Completion via Pre-Trained Language Models</title>
      <author><first>Pengcheng</first><last>Jiang</last><affiliation>Dept of Computer Science, University of Illinois at Urbana-Champaign</affiliation></author>
      <author><first>Shivam</first><last>Agarwal</last><affiliation>University of Illinois at Urbana Champaign</affiliation></author>
      <author><first>Bowen</first><last>Jin</last><affiliation>UIUC</affiliation></author>
      <author><first>Xuan</first><last>Wang</last><affiliation>Virginia Tech</affiliation></author>
      <author><first>Jimeng</first><last>Sun</last><affiliation>UIUC</affiliation></author>
      <author><first>Jiawei</first><last>Han</last><affiliation>UIUC</affiliation></author>
      <pages>11161-11180</pages>
      <abstract>The mission of open knowledge graph (KG) completion is to draw new findings from known facts. Existing works that augment KG completion require either (1) factual triples to enlarge the graph reasoning space or (2) manually designed prompts to extract knowledge from a pre-trained language model (PLM), exhibiting limited performance and requiring expensive efforts from experts. To this end, we propose TagReal that automatically generates quality query prompts and retrieves support information from large text corpora to probe knowledge from PLM for KG completion. The results show that TagReal achieves state-of-the-art performance on two benchmark datasets. We find that TagReal has superb performance even with limited training data, outperforming existing embedding-based, graph-based, and PLM-based methods.</abstract>
      <url hash="10f94cdd">2023.findings-acl.709</url>
      <bibkey>jiang-etal-2023-text</bibkey>
      <doi>10.18653/v1/2023.findings-acl.709</doi>
    </paper>
    <paper id="710">
      <title>Discourse Analysis via Questions and Answers: Parsing Dependency Structures of Questions Under Discussion</title>
      <author><first>Wei-Jen</first><last>Ko</last><affiliation>University of Texas at Austin</affiliation></author>
      <author><first>Yating</first><last>Wu</last><affiliation>The University of Texas at Austin</affiliation></author>
      <author><first>Cutter</first><last>Dalton</last><affiliation>University of Colorado, Boulder</affiliation></author>
      <author><first>Dananjay</first><last>Srinivas</last><affiliation>University of Colorado at Boulder</affiliation></author>
      <author><first>Greg</first><last>Durrett</last><affiliation>UT Austin</affiliation></author>
      <author><first>Junyi Jessy</first><last>Li</last><affiliation>University of Texas at Austin</affiliation></author>
      <pages>11181-11195</pages>
      <abstract>Automatic discourse processing is bottlenecked by data: current discourse formalisms pose highly demanding annotation tasks involving large taxonomies of discourse relations, making them inaccessible to lay annotators. This work instead adopts the linguistic framework of Questions Under Discussion (QUD) for discourse analysis and seeks to derive QUD structures automatically. QUD views each sentence as an answer to a question triggered in prior context; thus, we characterize relationships between sentences as free-form questions, in contrast to exhaustive fine-grained taxonomies. We develop the first-of-its-kind QUD parser that derives a dependency structure of questions over full documents, trained using a large, crowdsourced question-answering dataset DCQA (Ko et al., 2022). Human evaluation results show that QUD dependency parsing is possible for language models trained with this crowdsourced, generalizable annotation scheme. We illustrate how our QUD structure is distinct from RST trees, and demonstrate the utility of QUD analysis in the context of document simplification. Our findings show that QUD parsing is an appealing alternative for automatic discourse processing.</abstract>
      <url hash="264629a1">2023.findings-acl.710</url>
      <bibkey>ko-etal-2023-discourse</bibkey>
      <doi>10.18653/v1/2023.findings-acl.710</doi>
    </paper>
    <paper id="711">
      <title>An Integrated Approach for Political Bias Prediction and Explanation Based on Discursive Structure</title>
      <author><first>Nicolas</first><last>Devatine</last><affiliation>IRIT</affiliation></author>
      <author><first>Philippe</first><last>Muller</last><affiliation>IRIT, University of Toulouse</affiliation></author>
      <author><first>Chloé</first><last>Braud</last><affiliation>IRIT, CNRS</affiliation></author>
      <pages>11196-11211</pages>
      <abstract>One crucial aspect of democracy is fair information sharing. While it is hard to prevent biases in news, they should be identified for better transparency. We propose an approach to automatically characterize biases that takes into account structural differences and that is efficient for long texts. This yields new ways to provide explanations for a textual classifier, going beyond mere lexical cues. We show that: (i) the use of discourse-based structure-aware document representations compare well to local, computationally heavy, or domain-specific models on classification tasks that deal with textual bias (ii) our approach based on different levels of granularity allows for the generation of better explanations of model decisions, both at the lexical and structural level, while addressing the challenge posed by long texts.</abstract>
      <url hash="b7229578">2023.findings-acl.711</url>
      <bibkey>devatine-etal-2023-integrated</bibkey>
      <doi>10.18653/v1/2023.findings-acl.711</doi>
    </paper>
    <paper id="712">
      <title>Smart Word Suggestions for Writing Assistance</title>
      <author><first>Chenshuo</first><last>Wang</last><affiliation>Peking University</affiliation></author>
      <author><first>Shaoguang</first><last>Mao</last><affiliation>Microsoft Research Asia</affiliation></author>
      <author><first>Tao</first><last>Ge</last><affiliation>Microsoft</affiliation></author>
      <author><first>Wenshan</first><last>Wu</last><affiliation>Microsoft Research Asia</affiliation></author>
      <author><first>Xun</first><last>Wang</last><affiliation>Microsoft</affiliation></author>
      <author><first>Yan</first><last>Xia</last><affiliation>Microsoft Research Asia</affiliation></author>
      <author><first>Jonathan</first><last>Tien</last><affiliation>Microsoft Research</affiliation></author>
      <author><first>Dongyan</first><last>Zhao</last><affiliation>pku.edu.cn</affiliation></author>
      <pages>11212-11225</pages>
      <abstract>Enhancing word usage is a desired feature for writing assistance. To further advance research in this area, this paper introduces “Smart Word Suggestions” (SWS) task and benchmark. Unlike other works, SWS emphasizes end-to-end evaluation and presents a more realistic writing assistance scenario. This task involves identifying words or phrases that require improvement and providing substitution suggestions. The benchmark includes human-labeled data for testing, a large distantly supervised dataset for training, and the framework for evaluation. The test data includes 1,000 sentences written by English learners, accompanied by over 16,000 substitution suggestions annotated by 10 native speakers. The training dataset comprises over 3.7 million sentences and 12.7 million suggestions generated through rules. Our experiments with seven baselines demonstrate that SWS is a challenging task. Based on experimental analysis, we suggest potential directions for future research on SWS. The dataset and related codes will be available for research purposes.</abstract>
      <url hash="a43b3b35">2023.findings-acl.712</url>
      <bibkey>wang-etal-2023-smart</bibkey>
      <doi>10.18653/v1/2023.findings-acl.712</doi>
    </paper>
    <paper id="713">
      <title><fixed-case>JECC</fixed-case>: Commonsense Reasoning Tasks Derived from Interactive Fictions</title>
      <author><first>Mo</first><last>Yu</last><affiliation>Tencent Inc.</affiliation></author>
      <author><first>Yi</first><last>Gu</last><affiliation>UC San Diego</affiliation></author>
      <author><first>Xiaoxiao</first><last>Guo</last><affiliation>IBM Research</affiliation></author>
      <author><first>Yufei</first><last>Feng</last><affiliation>Queen’s University</affiliation></author>
      <author><first>Xiaodan</first><last>Zhu</last><affiliation>Queen’s University</affiliation></author>
      <author><first>Michael</first><last>Greenspan</last><affiliation>Queen’s University</affiliation></author>
      <author><first>Murray</first><last>Campbell</last><affiliation>IBM Research</affiliation></author>
      <author><first>Chuang</first><last>Gan</last><affiliation>MIT-IBM Watson AI Lab</affiliation></author>
      <pages>11226-11238</pages>
      <abstract>Commonsense reasoning simulates the human ability to make presumptions about our physical world, and it is an essential cornerstone in building general AI systems. We proposea new commonsense reasoning dataset based on human’s Interactive Fiction (IF) gameplaywalkthroughs as human players demonstrate plentiful and diverse commonsense reasoning. The new dataset provides a natural mixture of various reasoning types and requires multi-hopreasoning. Moreover, the IF game-based construction procedure requires much less humaninterventions than previous ones. Different from existing benchmarks, our dataset focuseson the assessment of functional commonsense knowledge rules rather than factual knowledge. Hence, in order to achieve higher performance on our tasks, models need to effectively uti-lize such functional knowledge to infer the outcomes of actions, rather than relying solely onmemorizing facts. Experiments show that the introduced dataset is challenging to previousmachine reading models as well as the new large language models with a significant 20%performance gap compared to human experts.</abstract>
      <url hash="2109417b">2023.findings-acl.713</url>
      <bibkey>yu-etal-2023-jecc</bibkey>
      <doi>10.18653/v1/2023.findings-acl.713</doi>
    </paper>
    <paper id="714">
      <title>A Study on Knowledge Distillation from Weak Teacher for Scaling Up Pre-trained Language Models</title>
      <author><first>Hayeon</first><last>Lee</last><affiliation>Student</affiliation></author>
      <author><first>Rui</first><last>Hou</last><affiliation>Meta</affiliation></author>
      <author><first>Jongpil</first><last>Kim</last><affiliation>Meta</affiliation></author>
      <author><first>Davis</first><last>Liang</last><affiliation>Amazon</affiliation></author>
      <author><first>Sung Ju</first><last>Hwang</last><affiliation>KAIST</affiliation></author>
      <author><first>Alexander</first><last>Min</last><affiliation>Meta</affiliation></author>
      <pages>11239-11246</pages>
      <abstract>Distillation from Weak Teacher (DWT) is a method of transferring knowledge from a smaller, weaker teacher model to a larger student model to improve its performance. Previous studies have shown that DWT can be effective in the vision domain and natural language processing (NLP) pre-training stage. Specifically, DWT shows promise in practical scenarios, such as enhancing new generation or larger models using pre-trained yet older or smaller models and lacking a resource budget. However, the optimal conditions for using DWT have yet to be fully investigated in NLP pre-training. Therefore, this study examines three key factors to optimize DWT, distinct from those used in the vision domain or traditional knowledge distillation. These factors are:(i) the impact of teacher model quality on DWT effectiveness, (ii) guidelines for adjusting the weighting value for DWT loss, and (iii) the impact of parameter remapping as a student model initialization technique for DWT.</abstract>
      <url hash="d630ebb2">2023.findings-acl.714</url>
      <bibkey>lee-etal-2023-study</bibkey>
      <doi>10.18653/v1/2023.findings-acl.714</doi>
    </paper>
    <paper id="715">
      <title><fixed-case>SORTIE</fixed-case>: Dependency-Aware Symbolic Reasoning for Logical Data-to-text Generation</title>
      <author><first>Xueliang</first><last>Zhao</last><affiliation>The University of Hong Kong</affiliation></author>
      <author><first>Tingchen</first><last>Fu</last><affiliation>Renmin University of China</affiliation></author>
      <author><first>Lemao</first><last>Liu</last><affiliation>Tencent AI Lab</affiliation></author>
      <author><first>Lingpeng</first><last>Kong</last><affiliation>The University of Hong Kong</affiliation></author>
      <author><first>Shuming</first><last>Shi</last><affiliation>Tencent AI Lab</affiliation></author>
      <author><first>Rui</first><last>Yan</last><affiliation>Renmin University of China</affiliation></author>
      <pages>11247-11266</pages>
      <abstract>Logical data-to-text generation is a representative task in measuring the capabilities of both language generation and complex reasoning. Despite the introduction of reasoning skills in generation, existing works still rely on neural language models to output the final table description. However, due to the inefficacy of neural language models in complex reasoning, these methods inevitably have difficulty working out key entities in the description and might produce unfaithful descriptions. To alleviate these issues, we propose a dependency-aware symbolic reasoning framework that reasons out each entity in the table description with our designed table-compatible programming language. To figure out the dependency relationship among entities, we devise an entity scheduling mechanism to determine the order of programme synthesis such that the reasoning of an entity only relies on other “resolved” entities. Experiments on three datasets and three backbones show that ours outperforms previous methods not only in surface-level fidelity but also in logical fidelity. Notably, the proposed framework enhances GPT-2, BART and T5 with an absolute improvement of 5.7%~11.5% on SP-Acc.</abstract>
      <url hash="f72dd460">2023.findings-acl.715</url>
      <bibkey>zhao-etal-2023-sortie</bibkey>
      <doi>10.18653/v1/2023.findings-acl.715</doi>
    </paper>
    <paper id="716">
      <title>Boosting Event Extraction with Denoised Structure-to-Text Augmentation</title>
      <author><first>Bo</first><last>Wang</last><affiliation>School of Computer Science and Technology, Beijing Institute of Technology</affiliation></author>
      <author><first>Heyan</first><last>Huang</last><affiliation>Beijing Institute of Technology</affiliation></author>
      <author><first>Xiaochi</first><last>Wei</last><affiliation>Baidu Inc.</affiliation></author>
      <author><first>Ge</first><last>Shi</last><affiliation>Beijing University of Technology</affiliation></author>
      <author><first>Xiao</first><last>Liu</last><affiliation>Microsoft Research Asia</affiliation></author>
      <author><first>Chong</first><last>Feng</last><affiliation>Beijing Institute of Technology</affiliation></author>
      <author><first>Tong</first><last>Zhou</last><affiliation>Beijing University of Technology</affiliation></author>
      <author><first>Shuaiqiang</first><last>Wang</last><affiliation>Baidu Inc.</affiliation></author>
      <author><first>Dawei</first><last>Yin</last><affiliation>Baidu</affiliation></author>
      <pages>11267-11281</pages>
      <abstract>Event extraction aims to recognize pre-defined event triggers and arguments from texts, which suffer from the lack of high-quality annotations. In most NLP applications, involving a large scale of synthetic training data is a practical and effective approach to alleviate the problem of data scarcity. However, when applying to the task of event extraction, recent data augmentation methods often neglect the problem of grammatical incorrectness, structure misalignment, and semantic drifting, leading to unsatisfactory performances. In order to solve these problems, we propose a denoised structure-to-text augmentation framework for event extraction (DAEE), which generates additional training data through the knowledge-based structure-to-text generation model and selects the effective subset from the generated data iteratively with a deep reinforcement learning agent. Experimental results on several datasets demonstrate that the proposed method generates more diverse text representations for event extraction and achieves comparable results with the state-of-the-art.</abstract>
      <url hash="4aac5088">2023.findings-acl.716</url>
      <bibkey>wang-etal-2023-boosting</bibkey>
      <doi>10.18653/v1/2023.findings-acl.716</doi>
    </paper>
    <paper id="717">
      <title>Detecting Adversarial Samples through Sharpness of Loss Landscape</title>
      <author><first>Rui</first><last>Zheng</last><affiliation>Fudan University</affiliation></author>
      <author><first>Shihan</first><last>Dou</last><affiliation>Fudan University</affiliation></author>
      <author><first>Yuhao</first><last>Zhou</last><affiliation>Fudan University</affiliation></author>
      <author><first>Qin</first><last>Liu</last><affiliation>University of Southern California</affiliation></author>
      <author><first>Tao</first><last>Gui</last><affiliation>fudan university</affiliation></author>
      <author><first>Qi</first><last>Zhang</last><affiliation>Fudan University</affiliation></author>
      <author><first>Zhongyu</first><last>Wei</last><affiliation>School of Data Science, Fudan University</affiliation></author>
      <author><first>Xuanjing</first><last>Huang</last><affiliation>Fudan University</affiliation></author>
      <author><first>Menghan</first><last>Zhang</last><affiliation>Institute of Modern Languages and Linguistics, Fudan University</affiliation></author>
      <pages>11282-11298</pages>
      <abstract>Deep neural networks (DNNs) have been proven to be sensitive towards perturbations on input samples, and previous works highlight that adversarial samples are even more vulnerable than normal ones. In this work, this phenomenon is illustrated frWe first show that adversarial samples locate in steep and narrow local minima of the loss landscape (high sharpness) while normal samples, which differs distinctly from adversarial ones, reside in the loss surface that is more flatter (low sharpness).om the perspective of sharpness via visualizing the input loss landscape of models. Based on this, we propose a simple and effective sharpness-based detector to distinct adversarial samples by maximizing the loss increment within the region where the inference sample is located. Considering that the notion of sharpness of a loss landscape is relative, we further propose an adaptive optimization strategy in an attempt to fairly compare the relative sharpness among different samples. Experimental results show that our approach can outperform previous detection methods by large margins (average +6.6 F1 score) for four advanced attack strategies considered in this paper across three text classification tasks.</abstract>
      <url hash="c6663c79">2023.findings-acl.717</url>
      <bibkey>zheng-etal-2023-detecting</bibkey>
      <doi>10.18653/v1/2023.findings-acl.717</doi>
    </paper>
    <paper id="718">
      <title>A Simple, Yet Effective Approach to Finding Biases in Code Generation</title>
      <author><first>Spyridon</first><last>Mouselinos</last><affiliation>University of Warsaw</affiliation></author>
      <author><first>Mateusz</first><last>Malinowski</last><affiliation>DeepMind</affiliation></author>
      <author><first>Henryk</first><last>Michalewski</last><affiliation>Google, University of Warsaw</affiliation></author>
      <pages>11299-11329</pages>
      <abstract>Recently, high-performing code generation systems based on large language models have surfaced. They are trained on massive corpora containing much more natural text than actual executable computer code. This work shows that current code generation systems exhibit undesired biases inherited from their large language model backbones, which can reduce the quality of the generated code under specific circumstances. To investigate the effect, we propose the “block of influence” concept, which enables a modular decomposition and analysis of the coding challenges. We introduce an automated intervention mechanism reminiscent of adversarial testing that exposes undesired biases through the failure modes of the models under test. Finally, we demonstrate how our framework can be used as a data transformation technique during fine-tuning, acting as a mitigation strategy for these biases.</abstract>
      <url hash="deed2fec">2023.findings-acl.718</url>
      <bibkey>mouselinos-etal-2023-simple</bibkey>
      <doi>10.18653/v1/2023.findings-acl.718</doi>
    </paper>
    <paper id="719">
      <title>Membership Inference Attacks against Language Models via Neighbourhood Comparison</title>
      <author><first>Justus</first><last>Mattern</last><affiliation>RWTH Aachen</affiliation></author>
      <author><first>Fatemehsadat</first><last>Mireshghallah</last><affiliation>UC San Diego</affiliation></author>
      <author><first>Zhijing</first><last>Jin</last><affiliation>Max Planck Institute &amp; ETH Zurich</affiliation></author>
      <author><first>Bernhard</first><last>Schoelkopf</last><affiliation>Max-Planck Institute for Intelligent Systems</affiliation></author>
      <author><first>Mrinmaya</first><last>Sachan</last><affiliation>ETH Zurich</affiliation></author>
      <author><first>Taylor</first><last>Berg-Kirkpatrick</last><affiliation>University of California San Diego</affiliation></author>
      <pages>11330-11343</pages>
      <abstract>Membership Inference attacks (MIAs) aim to predict whether a data sample was present in the training data of a machine learning model or not, and are widely used for assessing the privacy risks of language models. Most existing attacks rely on the observation that models tend toassign higher probabilities to their training samples than non-training points. However, simple thresholding of the model score in isolation tends to lead to high false-positive rates as it does not account for the intrinsic complexity of a sample. Recent work has demonstrated that reference-based attacks which compare model scores to those obtained from a reference model trained on similar data can substantially improve the performance of MIAs.However, in order to train reference models, attacks of this kind make the strong and arguably unrealistic assumption that an adversary has access to samples closely resembling the original training data. Therefore, we investigate their performance in more realistic scenarios and find that they are highly fragile in relation to the data distribution used to train reference models. To investigate whether this fragility provides a layer of safety, we propose and evaluate neighbourhood attacks, which compare model scores for a given sample to scores of synthetically generated neighbour texts and therefore eliminate the need for access to the training data distribution. We show that, in addition to being competitive with reference-based attacks that have perfect knowledge about the training data distribution, our attack clearly outperforms existing reference-free attacks as well as reference-based attacks with imperfect knowledge, which demonstrates the need for a reevaluation of the threat model of adversarial attacks.</abstract>
      <url hash="399a256d">2023.findings-acl.719</url>
      <bibkey>mattern-etal-2023-membership</bibkey>
      <doi>10.18653/v1/2023.findings-acl.719</doi>
    </paper>
    <paper id="720">
      <title><fixed-case>CFL</fixed-case>: Causally Fair Language Models Through Token-level Attribute Controlled Generation</title>
      <author><first>Rahul</first><last>Madhavan</last><affiliation>Indian Institute of Science, Bangalore</affiliation></author>
      <author><first>Rishabh</first><last>Garg</last><affiliation>IBM</affiliation></author>
      <author><first>Kahini</first><last>Wadhawan</last><affiliation>IBM</affiliation></author>
      <author><first>Sameep</first><last>Mehta</last><affiliation>IBM Research - India</affiliation></author>
      <pages>11344-11358</pages>
      <abstract>We propose a method to control the attributes of Language Models (LMs) for the text generation task using Causal Average Treatment Effect (ATE) scores and counterfactual augmentation. We explore this method, in the context of LM detoxification, and propose the Causally Fair Language (CFL) architecture for detoxifying pre-trained LMs in a plug-and-play manner. Our architecture is based on a Structural Causal Model (SCM) that is mathematically transparent and computationally efficient as compared with many existing detoxification techniques. We also propose several new metrics that aim to better understand the behaviour of LMs in the context of toxic text generation. Further, we achieve state of the art performance for toxic degeneration, which are computed using Real Toxicity Prompts. Our experiments show that CFL achieves such a detoxification without much impact on the model perplexity. We also show that CFL mitigates the unintended bias problem through experiments on the BOLD dataset.</abstract>
      <url hash="796cf0c9">2023.findings-acl.720</url>
      <bibkey>madhavan-etal-2023-cfl</bibkey>
      <doi>10.18653/v1/2023.findings-acl.720</doi>
    </paper>
    <paper id="721">
      <title>Can Diffusion Model Achieve Better Performance in Text Generation ? Bridging the Gap between Training and Inference !</title>
      <author><first>Zecheng</first><last>Tang</last><affiliation>Soochow University</affiliation></author>
      <author><first>Pinzheng</first><last>Wang</last><affiliation>Soochow University</affiliation></author>
      <author><first>Keyan</first><last>Zhou</last><affiliation>Soochow University</affiliation></author>
      <author><first>Juntao</first><last>Li</last><affiliation>Soochow University</affiliation></author>
      <author><first>Ziqiang</first><last>Cao</last><affiliation>Soochow University</affiliation></author>
      <author><first>Min</first><last>Zhang</last><affiliation>Harbin Institute of Technology (Shenzhen)</affiliation></author>
      <pages>11359-11386</pages>
      <abstract>Diffusion models have been successfully adapted to text generation tasks by mapping the discrete text into the continuous space. However, there exist nonnegligible gaps between training and inference, owing to the absence of the forward process during inference. Thus, the model only predicts based on the previously generated reverse noise rather than the noise computed by the forward process. Besides, the widely-used downsampling strategy in speeding up the inference will cause the mismatch of diffusion trajectories between training and inference. To understand and mitigate the above two types of training-inference discrepancies, we launch a thorough preliminary study. Based on our observations, we propose two simple yet effective methods to bridge the gaps mentioned above, named Distance Penalty and Adaptive Decay Sampling. Extensive experiments on <b>6</b> generation tasks confirm the superiority of our methods, which can achieve <tex-math>\mathbf{100}\times \rightarrow \mathbf{200}\times</tex-math> speedup with better performance. Our code will be released at <url>https://github.com/CODINNLG/Bridge_Gap_Diffusion</url>.</abstract>
      <url hash="10b18887">2023.findings-acl.721</url>
      <bibkey>tang-etal-2023-diffusion</bibkey>
      <doi>10.18653/v1/2023.findings-acl.721</doi>
    </paper>
    <paper id="722">
      <title>Topic-Guided Self-Introduction Generation for Social Media Users</title>
      <author><first>Chunpu</first><last>Xu</last><affiliation>Department of Computing, The Hong Kong Polytechnic University</affiliation></author>
      <author><first>Jing</first><last>Li</last><affiliation>Department of Computing, The Hong Kong Polytechnic University</affiliation></author>
      <author><first>Piji</first><last>Li</last><affiliation>Nanjing University of Aeronautics and Astronautics</affiliation></author>
      <author><first>Min</first><last>Yang</last><affiliation>Chinese Academy of Sciences</affiliation></author>
      <pages>11387-11402</pages>
      <abstract>Millions of users are active on social media. To allow users to better showcase themselves and network with others, we explore the auto-generation of social media self-introduction, a short sentence outlining a user’s personal interests. While most prior work profiling users with tags (e.g., ages), we investigate sentence-level self-introductions to provide a more natural and engaging way for users to know each other. Here we exploit a user’s tweeting history to generate their self-introduction. The task is non-trivial because the history content may be lengthy, noisy, and exhibit various personal interests. To address this challenge, we propose a novel unified topic-guided encoder-decoder (UTGED) framework; it models latent topics to reflect salient user interest, whose topic mixture then guides encoding a user’s history and topic words control decoding their self-introduction. For experiments, we collect a large-scale Twitter dataset, and extensive results show the superiority of our UTGED to the advanced encoder-decoder models without topic modeling.</abstract>
      <url hash="eea26964">2023.findings-acl.722</url>
      <bibkey>xu-etal-2023-topic</bibkey>
      <doi>10.18653/v1/2023.findings-acl.722</doi>
    </paper>
    <paper id="723">
      <title>Recyclable Tuning for Continual Pre-training</title>
      <author><first>Yujia</first><last>Qin</last><affiliation>Tsinghua University</affiliation></author>
      <author><first>Cheng</first><last>Qian</last><affiliation>Tsinghua University</affiliation></author>
      <author><first>Xu</first><last>Han</last><affiliation>Tsinghua University</affiliation></author>
      <author><first>Yankai</first><last>Lin</last><affiliation>Gaoling School of Artificial Intelligence, Renmin University of China</affiliation></author>
      <author><first>Huadong</first><last>Wang</last><affiliation>Tsinghua University</affiliation></author>
      <author><first>Ruobing</first><last>Xie</last><affiliation>WeChat, Tencent</affiliation></author>
      <author><first>Zhiyuan</first><last>Liu</last><affiliation>Tsinghua University</affiliation></author>
      <author><first>Maosong</first><last>Sun</last><affiliation>Tsinghua University</affiliation></author>
      <author><first>Jie</first><last>Zhou</last><affiliation>Tencent Inc.</affiliation></author>
      <pages>11403-11426</pages>
      <abstract>Continual pre-training is the paradigm where pre-trained language models (PLMs) continually acquire fresh knowledge from growing data and gradually get upgraded. Before an upgraded PLM is released, we may have tuned the original PLM for various tasks and stored the adapted weights. However, when tuning the upgraded PLM, these outdated adapted weights will typically be ignored and discarded, causing a potential waste of resources. We bring this issue to the forefront and contend that proper algorithms for recycling outdated adapted weights should be developed. To this end, we formulate the task of recyclable tuning for continual pre-training. In pilot studies, we find that after continual pre-training, the upgraded PLM remains compatible with the outdated adapted weights to some extent. Motivated by this finding, we analyze the connection between continually pre-trained PLMs from two novel aspects, i.e., mode connectivity, and functional similarity. Based on the corresponding findings, we propose both an initialization-based method and a distillation-based method for our task. We demonstrate their feasibility in improving the convergence and performance for tuning the upgraded PLM. We also show that both methods can be combined to achieve better performance.</abstract>
      <url hash="c7c77cf2">2023.findings-acl.723</url>
      <bibkey>qin-etal-2023-recyclable</bibkey>
      <doi>10.18653/v1/2023.findings-acl.723</doi>
    </paper>
    <paper id="724">
      <title><fixed-case>BLOCSUM</fixed-case>: Block Scope-based Source Code Summarization via Shared Block Representation</title>
      <author><first>YunSeok</first><last>Choi</last><affiliation>Sungkyunkwan University</affiliation></author>
      <author><first>Hyojun</first><last>Kim</last><affiliation>SungKyunKwan university</affiliation></author>
      <author><first>Jee-Hyong</first><last>Lee</last><affiliation>Sungkyunkwan Univ</affiliation></author>
      <pages>11427-11441</pages>
      <abstract>Code summarization, which aims to automatically generate natural language descriptions from source code, has become an essential task in software development for better program understanding. Abstract Syntax Tree (AST), which represents the syntax structure of the source code, is helpful when utilized together with the sequence of code tokens to improve the quality of code summaries. Recent works on code summarization attempted to capture the sequential and structural information of the source code, but they considered less the property that source code consists of multiple code blocks. In this paper, we propose BLOCSUM, BLOck scope-based source Code SUMmarization via shared block representation that utilizes block-scope information by representing various structures of the code block. We propose a shared block position embedding to effectively represent the structure of code blocks and merge both code and AST.Furthermore, we develop variant ASTs to learn rich information such as block and global dependencies of the source code. To prove our approach, we perform experiments on two real-world datasets, the Java dataset and the Python dataset. We demonstrate the effectiveness of BLOCSUM through various experiments, including ablation studies and a human evaluation.</abstract>
      <url hash="feca9703">2023.findings-acl.724</url>
      <bibkey>choi-etal-2023-blocsum</bibkey>
      <doi>10.18653/v1/2023.findings-acl.724</doi>
    </paper>
    <paper id="725">
      <title><fixed-case>H</fixed-case>yper<fixed-case>PELT</fixed-case>: Unified Parameter-Efficient Language Model Tuning for Both Language and Vision-and-Language Tasks</title>
      <author><first>Zhengkun</first><last>Zhang</last><affiliation>Nankai University</affiliation></author>
      <author><first>Wenya</first><last>Guo</last><affiliation>Nankai University</affiliation></author>
      <author><first>Xiaojun</first><last>Meng</last><affiliation>Noah’s Ark Lab, Huawei Technologies</affiliation></author>
      <author><first>Yasheng</first><last>Wang</last><affiliation>Huawei Noah’s Ark Lab</affiliation></author>
      <author><first>Yadao</first><last>Wang</last><affiliation>Huawei Technologies Co., Ltd.</affiliation></author>
      <author><first>Xin</first><last>Jiang</last><affiliation>Huawei Noah’s Ark Lab</affiliation></author>
      <author><first>Qun</first><last>Liu</last><affiliation>Huawei Noah’s Ark Lab</affiliation></author>
      <author><first>Zhenglu</first><last>Yang</last><affiliation>Nankai University</affiliation></author>
      <pages>11442-11453</pages>
      <abstract>With the scale and capacity of pretrained models growing rapidly, parameter-efficient language model tuning has emerged as a popular paradigm for solving various NLP and Vision-and-Language (V&amp;L) tasks. In this paper, we design a unified parameter-efficient multitask learning framework that works effectively on both NLP and V&amp;L tasks. In particular, we use a shared hypernetwork that takes trainable hyper-embeddings and visual modality as input, and outputs weights for different modules in a pretrained language model, such as the parameters inserted into multi-head attention blocks (i.e., prefix-tuning) and feed-forward blocks (i.e., adapter-tuning.). Our proposed framework adds fewer trainable parameters in multi-task learning while achieving superior performances and transfer ability compared to state-of-the-art methods. Empirical results on the GLUE benchmark and multiple V&amp;L tasks confirm the effectiveness of our framework.</abstract>
      <url hash="e60d56ea">2023.findings-acl.725</url>
      <bibkey>zhang-etal-2023-hyperpelt</bibkey>
      <doi>10.18653/v1/2023.findings-acl.725</doi>
    </paper>
    <paper id="726">
      <title>Enhancing Unsupervised Semantic Parsing with Distributed Contextual Representations</title>
      <author><first>Zixuan</first><last>Ling</last><affiliation>Fudan University</affiliation></author>
      <author><first>Xiaoqing</first><last>Zheng</last><affiliation>Fudan University</affiliation></author>
      <author><first>Jianhan</first><last>Xu</last><affiliation>Fudan University</affiliation></author>
      <author><first>Jinshu</first><last>Lin</last><affiliation>Hundsun</affiliation></author>
      <author><first>Kai-Wei</first><last>Chang</last><affiliation>UCLA</affiliation></author>
      <author><first>Cho-Jui</first><last>Hsieh</last><affiliation>University of California, Los Angeles</affiliation></author>
      <author><first>Xuanjing</first><last>Huang</last><affiliation>Fudan University</affiliation></author>
      <pages>11454-11465</pages>
      <abstract>We extend a non-parametric Bayesian model of (Titov and Klementiev, 2011) to deal with homonymy and polysemy by leveraging distributed contextual word and phrase representations pre-trained on a large collection of unlabelled texts. Then, unsupervised semantic parsing is performed by decomposing sentences into fragments, clustering the fragments to abstract away syntactic variations of the same meaning, and predicting predicate-argument relations between the fragments. To better model the statistical dependencies between predicates and their arguments, we further conduct a hierarchical Pitman-Yor process. An improved Metropolis-Hastings merge-split sampler is proposed to speed up the mixing and convergence of Markov chains by leveraging pre-trained distributed representations. The experimental results show that the models achieve better accuracy on both question-answering and relation extraction tasks.</abstract>
      <url hash="891ae8dc">2023.findings-acl.726</url>
      <bibkey>ling-etal-2023-enhancing</bibkey>
      <doi>10.18653/v1/2023.findings-acl.726</doi>
    </paper>
    <paper id="727">
      <title>Generating Labeled Data for Relation Extraction: A Meta Learning Approach with Joint <fixed-case>GPT</fixed-case>-2 Training</title>
      <author><first>Amir</first><last>Pouran Ben Veyseh</last><affiliation>University of Oregon</affiliation></author>
      <author><first>Franck</first><last>Dernoncourt</last><affiliation>Adobe Research</affiliation></author>
      <author><first>Bonan</first><last>Min</last><affiliation>Amazon AWS AI Labs</affiliation></author>
      <author><first>Thien</first><last>Nguyen</last><affiliation>University of Oregon</affiliation></author>
      <pages>11466-11478</pages>
      <abstract>Relation Extraction (RE) is the task of identifying semantic relation between real-world entities mentioned in text. Despite significant progress in RE research, a remaining challenge for RE concerns the lack of training data for data-hungry deep learning models. Cost of annotation and difficulty of the task are among hindrance to collect a large-scale RE dataset in different domains. To address this limitation, we propose a novel framework to automatically generate labeled data for RE. Our framework presents the pre-trained language model GPT-2 for data generation. In addition, to optimize the generated samples for an RE model, we introduce a meta learning approach to allow the GPT-2 model to be updated during the training process for RE. In particular, to leverage the feedback from the RE model to improve the data generation from GPT-2, we propose a novel reward function to update the GPT-2 model with REINFORCE, seeking to promote the similarity of the RE loss function’s gradients computed for generated data and a meta development set. We conduct extensive experiments on two benchmark datasets to produce state-of-the-art performance for RE.</abstract>
      <url hash="4f218ea0">2023.findings-acl.727</url>
      <bibkey>pouran-ben-veyseh-etal-2023-generating</bibkey>
      <doi>10.18653/v1/2023.findings-acl.727</doi>
    </paper>
    <paper id="728">
      <title>Disfluency Generation for More Robust Dialogue Systems</title>
      <author><first>Benjamin</first><last>Marie</last><affiliation>4i</affiliation></author>
      <pages>11479-11488</pages>
      <abstract>Disfluencies in user utterances can trigger a chain of errors impacting all the modules of a dialogue system: natural language understanding, dialogue state tracking, and response generation. In this work, we first analyze existing dialogue datasets commonly used in research and show that they only contain a marginal number of disfluent utterances. Due to this relative absence of disfluencies in their training data, dialogue systems may then critically fail when exposed to disfluent utterances. Following this observation, we propose to augment existing datasets with disfluent user utterances by paraphrasing fluent utterances into disfluent ones. Relying on a pre-trained language model, our few-shot disfluent paraphraser guided by a disfluency classifier can generate useful disfluent utterances for training better dialogue systems. We report on improvements for both dialogue state tracking and response generation when the dialogue systems are trained on datasets augmented with our disfluent utterances.</abstract>
      <url hash="31087fa8">2023.findings-acl.728</url>
      <bibkey>marie-2023-disfluency</bibkey>
      <doi>10.18653/v1/2023.findings-acl.728</doi>
    </paper>
    <paper id="729">
      <title>Dipping <fixed-case>PLM</fixed-case>s Sauce: Bridging Structure and Text for Effective Knowledge Graph Completion via Conditional Soft Prompting</title>
      <author><first>Chen</first><last>Chen</last><affiliation>Nanyang Technological University</affiliation></author>
      <author><first>Yufei</first><last>Wang</last><affiliation>Macquaire University</affiliation></author>
      <author><first>Aixin</first><last>Sun</last><affiliation>Nanyang Technological University</affiliation></author>
      <author><first>Bing</first><last>Li</last><affiliation>The Agency for Science, Technology and Research (A*STAR), Singapore</affiliation></author>
      <author><first>Kwok-Yan</first><last>Lam</last><affiliation>Nanyang Technological University</affiliation></author>
      <pages>11489-11503</pages>
      <abstract>Knowledge Graph Completion (KGC) often requires both KG structural and textual information to be effective. Pre-trained Language Models (PLMs) have been used to learn the textual information, usually under the fine-tune paradigm for the KGC task. However, the fine-tuned PLMs often overwhelmingly focus on the textual information and overlook structural knowledge. To tackle this issue, this paper proposes CSProm-KG (Conditional Soft Prompts for KGC) which maintains a balance between structural information and textual knowledge. CSProm-KG only tunes the parameters of Conditional Soft Prompts that are generated by the entities and relations representations. We verify the effectiveness of CSProm-KG on three popular static KGC benchmarks WN18RR, FB15K-237 and Wikidata5M, and two temporal KGC benchmarks ICEWS14 and ICEWS05-15. CSProm-KG outperforms competitive baseline models and sets new state-of-the-art on these benchmarks. We conduct further analysis to show (i) the effectiveness of our proposed components, (ii) the efficiency of CSProm-KG, and (iii) the flexibility of CSProm-KG.</abstract>
      <url hash="3374fc23">2023.findings-acl.729</url>
      <bibkey>chen-etal-2023-dipping</bibkey>
      <doi>10.18653/v1/2023.findings-acl.729</doi>
    </paper>
    <paper id="730">
      <title>Revisiting Pathologies of Neural Models under Input Reduction</title>
      <author><first>Canasai</first><last>Kruengkrai</last><affiliation>National Institute of Informatics</affiliation></author>
      <author><first>Junichi</first><last>Yamagishi</last><affiliation>National Institute of Informatics</affiliation></author>
      <pages>11504-11517</pages>
      <abstract>We revisit the question of why neural models tend to produce high-confidence predictions on inputs that appear nonsensical to humans. Previous work has suggested that the models fail to assign low probabilities to such inputs due to model overconfidence. We evaluate various regularization methods on fact verification benchmarks and find that this problem persists even with well-calibrated or underconfident models, suggesting that overconfidence is not the only underlying cause. We also find that regularizing the models with reduced examples helps improve interpretability but comes with the cost of miscalibration. We show that although these reduced examples are incomprehensible to humans, they can contain valid statistical patterns in the dataset utilized by the model.</abstract>
      <url hash="8089833f">2023.findings-acl.730</url>
      <bibkey>kruengkrai-yamagishi-2023-revisiting</bibkey>
      <doi>10.18653/v1/2023.findings-acl.730</doi>
    </paper>
    <paper id="731">
      <title><fixed-case>L</fixed-case>ego-<fixed-case>MT</fixed-case>: Learning Detachable Models for Massively Multilingual Machine Translation</title>
      <author><first>Fei</first><last>Yuan</last><affiliation>Shanghai AI Laboratory</affiliation></author>
      <author><first>Yinquan</first><last>Lu</last><affiliation>Shanghai AI Laboratory</affiliation></author>
      <author><first>Wenhao</first><last>Zhu</last><affiliation>National Key Laboratory for Novel Software Technology, Nanjing University</affiliation></author>
      <author><first>Lingpeng</first><last>Kong</last><affiliation>The University of Hong Kong</affiliation></author>
      <author><first>Lei</first><last>Li</last><affiliation>University of California Santa Barbara</affiliation></author>
      <author><first>Yu</first><last>Qiao</last><affiliation>Shanghai AI Lab</affiliation></author>
      <author><first>Jingjing</first><last>Xu</last><affiliation>Shanghai AI Lab</affiliation></author>
      <pages>11518-11533</pages>
      <abstract>Multilingual neural machine translation (MNMT) aims to build a unified model for many language directions. Existing monolithic models for MNMT encounter two challenges: parameter interference among languages and inefficient inference for large models. In this paper, we revisit the classic multi-way structures and develop a detachable model by assigning each language (or group of languages) to an individual branch that supports plug-and-play training and inference. To address the needs of learning representations for all languages in a unified space, we propose a novel efficient training recipe, upon which we build an effective detachable model, Lego-MT.For a fair comparison, we collect data from OPUS and build a translation benchmark covering 433 languages and 1.3B parallel data. Experiments show that Lego-MT with 1.2B parameters brings an average gain of 3.2 spBLEU. It even outperforms M2M-100 with 12B parameters. The proposed training recipe brings a 28.2<tex-math>\times</tex-math> speedup over the conventional multi-way training method.code and data repo: <url>https://github.com/CONE-MT/Lego-MT.git</url>.</abstract>
      <url hash="8200908c">2023.findings-acl.731</url>
      <bibkey>yuan-etal-2023-lego</bibkey>
      <doi>10.18653/v1/2023.findings-acl.731</doi>
    </paper>
    <paper id="732">
      <title><fixed-case>F</fixed-case>i<fixed-case>DO</fixed-case>: Fusion-in-Decoder optimized for stronger performance and faster inference</title>
      <author><first>Michiel</first><last>de Jong</last><affiliation>University of Southern California</affiliation></author>
      <author><first>Yury</first><last>Zemlyanskiy</last><affiliation>USC</affiliation></author>
      <author><first>Joshua</first><last>Ainslie</last><affiliation>Google</affiliation></author>
      <author><first>Nicholas</first><last>FitzGerald</last><affiliation>Google</affiliation></author>
      <author><first>Sumit</first><last>Sanghai</last><affiliation>Google</affiliation></author>
      <author><first>Fei</first><last>Sha</last><affiliation>Google</affiliation></author>
      <author><first>William</first><last>Cohen</last><affiliation>Google AI</affiliation></author>
      <pages>11534-11547</pages>
      <abstract>Fusion-in-Decoder (FiD) is a powerful retrieval-augmented language model that sets the state-of-the-art on many knowledge-intensive NLP tasks. However, the architecture used for FiD was chosen by making minimal modifications to a standard T5 model, which our analysis shows to be highly suboptimal for a retrieval-augmented model. In particular, FiD allocates the bulk of FLOPs to the encoder, while the majority of inference time results from memory bandwidth constraints in the decoder. We propose two simple changes to the FiD architecture to alleviate memory bandwidth constraints, and speed up inference by 7x. This allows us to use a much larger decoder at modest cost. We denote FiD with the above modifications as FiDO, and show that it strongly improves performance over existing FiD models for a wide range of inference budgets. For example, FiDO-Large-XXL performs faster inference than FiD-Base and achieves better performance than FiD-Large.</abstract>
      <url hash="83a871a8">2023.findings-acl.732</url>
      <bibkey>de-jong-etal-2023-fido</bibkey>
      <doi>10.18653/v1/2023.findings-acl.732</doi>
    </paper>
    <paper id="733">
      <title>Detecting Edit Failures In Large Language Models: An Improved Specificity Benchmark</title>
      <author><first>Jason</first><last>Hoelscher-Obermaier</last><affiliation>Apart Research</affiliation></author>
      <author><first>Julia</first><last>Persson</last><affiliation>KTH Royal Institute of Technology</affiliation></author>
      <author><first>Esben</first><last>Kran</last><affiliation>Apart Research</affiliation></author>
      <author><first>Ioannis</first><last>Konstas</last><affiliation>Heriot-Watt University</affiliation></author>
      <author><first>Fazl</first><last>Barez</last><affiliation>The University of Edinburgh</affiliation></author>
      <pages>11548-11559</pages>
      <abstract>Recent model editing techniques promise to mitigate the problem of memorizing false or outdated associations during LLM training. However, we show that these techniques can introduce large unwanted side effects which are not detected by existing specificity benchmarks. We extend the existing CounterFact benchmark to include a dynamic component and dub our benchmark CounterFact+. Additionally, we extend the metrics used for measuring specificity by a principled KL divergence-based metric. We use this improved benchmark to evaluate recent model editing techniques and find that they suffer from low specificity. Our findings highlight the need for improved specificity benchmarks that identify and prevent unwanted side effects.</abstract>
      <url hash="34908ab2">2023.findings-acl.733</url>
      <bibkey>hoelscher-obermaier-etal-2023-detecting</bibkey>
      <doi>10.18653/v1/2023.findings-acl.733</doi>
    </paper>
    <paper id="734">
      <title>Structure-Aware Language Model Pretraining Improves Dense Retrieval on Structured Data</title>
      <author><first>Xinze</first><last>Li</last><affiliation>Northeastern University</affiliation></author>
      <author><first>Zhenghao</first><last>Liu</last><affiliation>Northeastern University</affiliation></author>
      <author><first>Chenyan</first><last>Xiong</last><affiliation>Microsoft Research</affiliation></author>
      <author><first>Shi</first><last>Yu</last><affiliation>Tsinghua University</affiliation></author>
      <author><first>Yu</first><last>Gu</last><affiliation>Northeastern University</affiliation></author>
      <author><first>Zhiyuan</first><last>Liu</last><affiliation>Tsinghua University</affiliation></author>
      <author><first>Ge</first><last>Yu</last><affiliation>Northeastern University</affiliation></author>
      <pages>11560-11574</pages>
      <abstract>This paper presents Structure Aware Dense Retrieval (SANTA) model, which encodes user queries and structured data in one universal embedding space for retrieving structured data. SANTA proposes two pretraining methods to make language models structure-aware and learn effective representations for structured data: 1) Structured Data Alignment, which utilizes the natural alignment relations between structured data and unstructured data for structure-aware pretraining. It contrastively trains language models to represent multi-modal text data and teaches models to distinguish matched structured data for unstructured texts. 2) Masked Entity Prediction, which designs an entity-oriented mask strategy and asks language models to fill in the masked entities. Our experiments show that SANTA achieves state-of-the-art on code search and product search and conducts convincing results in the zero-shot setting. SANTA learns tailored representations for multi-modal text data by aligning structured and unstructured data pairs and capturing structural semantics by masking and predicting entities in the structured data. All codes are available at <url>https://github.com/OpenMatch/OpenMatch</url>.</abstract>
      <url hash="4a8fad1c">2023.findings-acl.734</url>
      <bibkey>li-etal-2023-structure</bibkey>
      <doi>10.18653/v1/2023.findings-acl.734</doi>
    </paper>
    <paper id="735">
      <title>Few-shot Joint Multimodal Aspect-Sentiment Analysis Based on Generative Multimodal Prompt</title>
      <author><first>Xiaocui</first><last>Yang</last><affiliation>School of Computer Science and Engineering, Northeastern University,</affiliation></author>
      <author><first>Shi</first><last>Feng</last><affiliation>Northeastern University</affiliation></author>
      <author><first>Daling</first><last>Wang</last><affiliation>Northeastern University</affiliation></author>
      <author><first>Qi</first><last>Sun</last><affiliation>Nanjing University of Science and Technology</affiliation></author>
      <author><first>Wenfang</first><last>Wu</last><affiliation>Northeastern University</affiliation></author>
      <author><first>Yifei</first><last>Zhang</last><affiliation>Northeastern University</affiliation></author>
      <author><first>Pengfei</first><last>Hong</last><affiliation>Singapore University of Technology and Design</affiliation></author>
      <author><first>Soujanya</first><last>Poria</last><affiliation>Singapore University of Technology and Design</affiliation></author>
      <pages>11575-11589</pages>
      <abstract>We have witnessed the rapid proliferation of multimodal data on numerous social media platforms. Conventional studies typically require massive labeled data to train models for Multimodal Aspect-Based Sentiment Analysis (MABSA). However, collecting and annotating fine-grained multimodal data for MABSA is tough. To alleviate the above issue, we perform three MABSA-related tasks with quite a small number of labeled multimodal samples. We first build diverse and comprehensive multimodal few-shot datasets according to the data distribution. To capture the specific prompt for each aspect term in a few-shot scenario, we propose a novel Generative Multimodal Prompt (GMP) model for MABSA, which includes the Multimodal Encoder module and the N-Stream Decoders module. We further introduce a subtask to predict the number of aspect terms in each instance to construct the multimodal prompt. Extensive experiments on two datasets demonstrate that our approach outperforms strong baselines on two MABSA-related tasks in the few-shot setting.</abstract>
      <url hash="a5d9fd21">2023.findings-acl.735</url>
      <bibkey>yang-etal-2023-shot-joint</bibkey>
      <doi>10.18653/v1/2023.findings-acl.735</doi>
    </paper>
    <paper id="736">
      <title>Predicting Human Translation Difficulty Using Automatic Word Alignment</title>
      <author><first>Zheng Wei</first><last>Lim</last><affiliation>University of Melbourne</affiliation></author>
      <author><first>Trevor</first><last>Cohn</last><affiliation>University of Melbourne</affiliation></author>
      <author><first>Charles</first><last>Kemp</last><affiliation>University of Melbourne</affiliation></author>
      <author><first>Ekaterina</first><last>Vylomova</last><affiliation>University of Melbourne</affiliation></author>
      <pages>11590-11601</pages>
      <abstract>Translation difficulty arises when translators are required to resolve translation ambiguity from multiple possible translations. Translation difficulty can be measured by recording the diversity of responses provided by human translators and the time taken to provide these responses, but these behavioral measures are costly and do not scale. In this work, we use word alignments computed over large scale bilingual corpora to develop predictors of lexical translation difficulty. We evaluate our approach using behavioural data from translations provided both in and out of context, and report results that improve on a previous embedding-based approach (Thompson et al., 2020). Our work can therefore contribute to a deeper understanding of cross-lingual differences and of causes of translation difficulty.</abstract>
      <url hash="00364c2d">2023.findings-acl.736</url>
      <bibkey>lim-etal-2023-predicting</bibkey>
      <doi>10.18653/v1/2023.findings-acl.736</doi>
    </paper>
    <paper id="737">
      <title>Know Where You’re Going: Meta-Learning for Parameter-Efficient Fine-Tuning</title>
      <author><first>Mozhdeh</first><last>Gheini</last><affiliation>University of Southern California</affiliation></author>
      <author><first>Xuezhe</first><last>Ma</last><affiliation>Information Sciences Institute</affiliation></author>
      <author><first>Jonathan</first><last>May</last><affiliation>USC Information Sciences Institute</affiliation></author>
      <pages>11602-11612</pages>
      <abstract>A recent family of techniques, dubbed lightweight fine-tuning methods, facilitates parameter-efficient transfer by updating only a small set of additional parameters while keeping the parameters of the original model frozen. While proven to be an effective approach, there are no existing studies on if and how such knowledge of the downstream fine-tuning approach calls for complementary measures after pre-training and before fine-tuning. In this work, we show that taking the ultimate choice of fine-tuning into consideration boosts the performance of parameter-efficient fine-tuning. By relying on optimization-based meta-learning using MAML with certain modifications for our distinct purpose, we prime the pre-trained model specifically for parameter-efficient fine-tuning, resulting in gains of up to 4.96 points on cross-lingual NER fine-tuning. Our ablation settings and analyses further reveal that the specific approach we take to meta-learning is crucial for the attained gains.</abstract>
      <url hash="adee2a23">2023.findings-acl.737</url>
      <bibkey>gheini-etal-2023-know</bibkey>
      <doi>10.18653/v1/2023.findings-acl.737</doi>
    </paper>
    <paper id="738">
      <title>Moving Beyond Downstream Task Accuracy for Information Retrieval Benchmarking</title>
      <author><first>Keshav</first><last>Santhanam</last><affiliation>Stanford University</affiliation></author>
      <author><first>Jon</first><last>Saad-Falcon</last><affiliation>Stanford University</affiliation></author>
      <author><first>Martin</first><last>Franz</last><affiliation>IBM T.J. Watson Research Center</affiliation></author>
      <author><first>Omar</first><last>Khattab</last><affiliation>Stanford University</affiliation></author>
      <author><first>Avi</first><last>Sil</last><affiliation>IBM Research AI</affiliation></author>
      <author><first>Radu</first><last>Florian</last><affiliation>IBM Research</affiliation></author>
      <author><first>Md Arafat</first><last>Sultan</last><affiliation>IBM Research AI</affiliation></author>
      <author><first>Salim</first><last>Roukos</last><affiliation>IBM Research AI</affiliation></author>
      <author><first>Matei</first><last>Zaharia</last><affiliation>Stanford</affiliation></author>
      <author><first>Christopher</first><last>Potts</last><affiliation>Stanford University</affiliation></author>
      <pages>11613-11628</pages>
      <abstract>Neural information retrieval (IR) systems have progressed rapidly in recent years, in large part due to the release of publicly available benchmarking tasks. Unfortunately, some dimensions of this progress are illusory: the majority of the popular IR benchmarks today focus exclusively on downstream task accuracy and thus conceal the costs incurred by systems that trade away efficiency for quality. Latency, hardware cost, and other efficiency considerations are paramount to the deployment of IR systems in user-facing settings. We propose that IR benchmarks structure their evaluation methodology to include not only metrics of accuracy, but also efficiency considerations such as a query latency and the corresponding cost budget for a reproducible hardware setting. For the popular IR benchmarks MS MARCO and XOR-TyDi, we show how the best choice of IR system varies according to how these efficiency considerations are chosen and weighed. We hope that future benchmarks will adopt these guidelines toward more holistic IR evaluation.</abstract>
      <url hash="ab3e4e89">2023.findings-acl.738</url>
      <bibkey>santhanam-etal-2023-moving</bibkey>
      <doi>10.18653/v1/2023.findings-acl.738</doi>
    </paper>
    <paper id="739">
      <title><fixed-case>A</fixed-case>xomiya<fixed-case>BERT</fixed-case>a: A Phonologically-aware Transformer Model for <fixed-case>A</fixed-case>ssamese</title>
      <author><first>Abhijnan</first><last>Nath</last><affiliation>Colorado State University</affiliation></author>
      <author><first>Sheikh</first><last>Mannan</last><affiliation>Colorado State University</affiliation></author>
      <author><first>Nikhil</first><last>Krishnaswamy</last><affiliation>Colorado State University</affiliation></author>
      <pages>11629-11646</pages>
      <abstract>Despite their successes in NLP, Transformer-based language models still require extensive computing resources and suffer in low-resource or low-compute settings. In this paper, we present AxomiyaBERTa, a novel BERT model for Assamese, a morphologically-rich low-resource language (LRL) of Eastern India. AxomiyaBERTa is trained only on the masked language modeling (MLM) task, without the typical additional next sentence prediction (NSP) objective, and our results show that in resource-scarce settings for very low-resource languages like Assamese, MLM alone can be successfully leveraged for a range of tasks. AxomiyaBERTa achieves SOTA on token-level tasks like Named Entity Recognition and also performs well on “longer-context” tasks like Cloze-style QA and Wiki Title Prediction, with the assistance of a novel embedding disperser and phonological signals respectively. Moreover, we show that AxomiyaBERTa can leverage phonological signals for even more challenging tasks, such as a novel cross-document coreference task on a translated version of the ECB+ corpus, where we present a new SOTA result for an LRL. Our source code and evaluation scripts may be found at <url>https://github.com/csu-signal/axomiyaberta</url>.</abstract>
      <url hash="e1de5bd1">2023.findings-acl.739</url>
      <bibkey>nath-etal-2023-axomiyaberta</bibkey>
      <doi>10.18653/v1/2023.findings-acl.739</doi>
    </paper>
    <paper id="740">
      <title>An Exploratory Study on Model Compression for Text-to-<fixed-case>SQL</fixed-case></title>
      <author><first>Shuo</first><last>Sun</last><affiliation>Institute for Infocomm Research, A*STAR</affiliation></author>
      <author><first>Yuze</first><last>Gao</last><affiliation>Researcher</affiliation></author>
      <author><first>Yuchen</first><last>Zhang</last><affiliation>Agency for Science, Technology and Research</affiliation></author>
      <author><first>Jian</first><last>Su</last><affiliation>Institute for Infocomm Research</affiliation></author>
      <author><first>Bin</first><last>Chen</last><affiliation>Institute for Infocomm Research, Singapore</affiliation></author>
      <author><first>Yingzhan</first><last>Lin</last><affiliation>Baidu Inc., China</affiliation></author>
      <author><first>Shuqi</first><last>Sun</last><affiliation>Baidu</affiliation></author>
      <pages>11647-11654</pages>
      <abstract>Text-to-SQL translates user queries into SQL statements that can retrieve relevant answers from relational databases. Recent approaches to Text-to-SQL rely on pre-trained language models that are computationally expensive and technically challenging to deploy in real-world applications that require real-time or on-device processing capabilities. In this paper, we perform a focused study on the feasibility of applying recent model compression techniques to sketch-based and sequence-to-sequence Text-to-SQL models. Our results reveal that sketch-based Text-to-SQL models generally have higher inference efficiency and respond better to model compression than sequence-to-sequence models, making them ideal for real-world deployments, especially in use cases with simple SQL statements.</abstract>
      <url hash="6b3e3494">2023.findings-acl.740</url>
      <bibkey>sun-etal-2023-exploratory</bibkey>
      <doi>10.18653/v1/2023.findings-acl.740</doi>
    </paper>
    <paper id="741">
      <title><fixed-case>F</fixed-case>luent<fixed-case>S</fixed-case>peech: Stutter-Oriented Automatic Speech Editing with Context-Aware Diffusion Models</title>
      <author><first>Ziyue</first><last>Jiang</last><affiliation>Zhejiang university</affiliation></author>
      <author><first>Qian</first><last>Yang</last><affiliation>ZheJiang University</affiliation></author>
      <author><first>Jialong</first><last>Zuo</last><affiliation>University of Whuhan at Asian</affiliation></author>
      <author><first>Zhenhui</first><last>Ye</last><affiliation>Zhejiang University</affiliation></author>
      <author><first>Rongjie</first><last>Huang</last><affiliation>Zhejiang University</affiliation></author>
      <author><first>Yi</first><last>Ren</last><affiliation>Bytedance</affiliation></author>
      <author><first>Zhou</first><last>Zhao</last><affiliation>zhejiang university</affiliation></author>
      <pages>11655-11671</pages>
      <abstract>Stutter removal is an essential scenario in the field of speech editing. However, when the speech recording contains stutters, the existing text-based speech editing approaches still suffer from: 1) the over-smoothing problem in the edited speech; 2) lack of robustness due to the noise introduced by stutter; 3) to remove the stutters, users are required to determine the edited region manually. To tackle the challenges in stutter removal, we propose FluentSpeech, a stutter-oriented automatic speech editing model. Specifically, 1) we propose a context-aware diffusion model that iteratively refines the modified mel-spectrogram with the guidance of context features; 2) we introduce a stutter predictor module to inject the stutter information into the hidden sequence; 3) we also propose a stutter-oriented automatic speech editing (SASE) dataset that contains spontaneous speech recordings with time-aligned stutter labels to train the automatic stutter localization model. Experimental results on VCTK and LibriTTS datasets demonstrate that our model achieves state-of-the-art performance on speech editing. Further experiments on our SASE dataset show that FluentSpeech can effectively improve the fluency of stuttering speech in terms of objective and subjective metrics. Code and audio samples can be found at <url>https://github.com/Zain-Jiang/Speech-Editing-Toolkit</url>.</abstract>
      <url hash="a92932b0">2023.findings-acl.741</url>
      <bibkey>jiang-etal-2023-fluentspeech</bibkey>
      <doi>10.18653/v1/2023.findings-acl.741</doi>
    </paper>
    <paper id="742">
      <title><fixed-case>H</fixed-case>y<fixed-case>HTM</fixed-case>: Hyperbolic Geometry-based Hierarchical Topic Model</title>
      <author><first>Simra</first><last>Shahid</last><affiliation>Adobe</affiliation></author>
      <author><first>Tanay</first><last>Anand</last><affiliation>Adobe</affiliation></author>
      <author><first>Nikitha</first><last>Srikanth</last><affiliation>Adobe Systems India Pvt Ltd</affiliation></author>
      <author><first>Sumit</first><last>Bhatia</last><affiliation>Adobe</affiliation></author>
      <author><first>Balaji</first><last>Krishnamurthy</last><affiliation>Adobe Inc</affiliation></author>
      <author><first>Nikaash</first><last>Puri</last><affiliation>Machine Learning Research Scientist</affiliation></author>
      <pages>11672-11688</pages>
      <abstract>Hierarchical Topic Models (HTMs) are useful for discovering topic hierarchies in a collection of documents. However, traditional HTMs often produce hierarchies where lower-level topics are unrelated and not specific enough to their higher-level topics. Additionally, these methods can be computationally expensive. We present HyHTM - a Hyperbolic geometry-based Hierarchical Topic Model - that addresses these limitations by incorporating hierarchical information from hyperbolic geometry to explicitly model hierarchies in topic models. Experimental results with four baselines show that HyHTM can better attend to parent-child relationships among topics. HyHTM produces coherent topic hierarchies that specialize in granularity from generic higher-level topics to specific lower-level topics. Further, our model is significantly faster and leaves a much smaller memory footprint than our best-performing baseline. We have made the source code for our algorithm publicly accessible.</abstract>
      <url hash="8f3436b9">2023.findings-acl.742</url>
      <bibkey>shahid-etal-2023-hyhtm</bibkey>
      <doi>10.18653/v1/2023.findings-acl.742</doi>
    </paper>
    <paper id="743">
      <title><fixed-case>K</fixed-case>o<fixed-case>RC</fixed-case>: Knowledge Oriented Reading Comprehension Benchmark for Deep Text Understanding</title>
      <author><first>Zijun</first><last>Yao</last><affiliation>Tsinghua University</affiliation></author>
      <author><first>Yantao</first><last>Liu</last><affiliation>ict</affiliation></author>
      <author><first>Xin</first><last>Lv</last><affiliation>Tsinghua University</affiliation></author>
      <author><first>Shulin</first><last>Cao</last><affiliation>Tsinghua University</affiliation></author>
      <author><first>Jifan</first><last>Yu</last><affiliation>Tsinghua University</affiliation></author>
      <author><first>Juanzi</first><last>Li</last><affiliation>Tsinghua University</affiliation></author>
      <author><first>Lei</first><last>Hou</last><affiliation>Tsinghua University</affiliation></author>
      <pages>11689-11707</pages>
      <abstract>Deep text understanding, which requires the connections between a given document and prior knowledge beyond its text, has been highlighted by many benchmarks in recent years. However, these benchmarks have encountered two major limitations. On the one hand, most of them require human annotation of knowledge, which leads to limited knowledge coverage. On the other hand, they usually use choices or spans in the texts as the answers, which results in narrow answer space. To overcome these limitations, we build a new challenging benchmark named KoRC in this paper. Compared with previous benchmarks, KoRC has two advantages, i.e., broad knowledge coverage and flexible answer format. Specifically, we utilize massive knowledge bases to guide annotators or large language models (LLMs) to construct knowledgable questions. Moreover, we use labels in knowledge bases rather than spans or choices as the final answers. We test state-of-the-art models on KoRC and the experimental results show that the strongest baseline only achieves 68.3% and 30.0% F1 measure in the IID and OOD test set, respectively. These results indicate that deep text understanding is still an unsolved challenge. We will release our dataset and baseline methods upon acceptance.</abstract>
      <url hash="7d170feb">2023.findings-acl.743</url>
      <bibkey>yao-etal-2023-korc</bibkey>
      <doi>10.18653/v1/2023.findings-acl.743</doi>
    </paper>
    <paper id="744">
      <title><fixed-case>DKAF</fixed-case>: <fixed-case>KB</fixed-case> Arbitration for Learning Task-Oriented Dialog Systems with Dialog-<fixed-case>KB</fixed-case> Inconsistencies</title>
      <author><first>Vishal</first><last>Saley</last><affiliation>Indian Institute of Technology Delhi</affiliation></author>
      <author><first>Rocktim</first><last>Das</last><affiliation>Indian Institute of Technology, Delhi.</affiliation></author>
      <author><first>Dinesh</first><last>Raghu</last><affiliation>IBM Research</affiliation></author>
      <author><first/><last>Mausam</last><affiliation>Indian Institute of Technology, Delhi</affiliation></author>
      <pages>11708-11730</pages>
      <abstract>Task-oriented dialog (TOD) agents often ground their responses on external knowledge bases (KBs). These KBs can be dynamic and may be updated frequently. Existing approaches for learning TOD agents assume the KB snapshot contemporary to each individual dialog is available during training. However, in real-world scenarios, only the latest KB snapshot is available during training and as a result, the train dialogs may contain facts conflicting with the latest KB. These dialog-KB inconsistencies in the training data may potentially confuse the TOD agent learning algorithm. In this work, we define the novel problem of learning a TOD agent with dialog-KB inconsistencies in the training data. We propose a Dialog-KB Arbitration Framework (DKAF) which reduces the dialog-KB inconsistencies by predicting the contemporary KB snapshot for each train dialog. These predicted KB snapshots are then used for training downstream TOD agents. As there are no existing datasets with dialog-KB inconsistencies, we systematically introduce inconsistencies in two publicly available dialog datasets. We show that TOD agents trained with DKAF perform better than existing baselines on both these datasets.</abstract>
      <url hash="41d53941">2023.findings-acl.744</url>
      <bibkey>saley-etal-2023-dkaf</bibkey>
      <doi>10.18653/v1/2023.findings-acl.744</doi>
    </paper>
    <paper id="745">
      <title>Scale-Invariant Infinite Hierarchical Topic Model</title>
      <author><first>Shusei</first><last>Eshima</last><affiliation>Harvard University</affiliation></author>
      <author><first>Daichi</first><last>Mochihashi</last><affiliation>The Institute of Statistical Mathematics</affiliation></author>
      <pages>11731-11746</pages>
      <abstract>Hierarchical topic models have been employed to organize a large number of diverse topics from corpora into a latent tree structure. However, existing models yield fragmented topics with overlapping themes whose expected probability becomes exponentially smaller along the depth of the tree. To solve this intrinsic problem, we propose a scale-invariant infinite hierarchical topic model (ihLDA). The ihLDA adaptively adjusts the topic creation to make the expected topic probability decay considerably slower than that in existing models. Thus, it facilitates the estimation of deeper topic structures encompassing diverse topics in a corpus. Furthermore, the ihLDA extends a widely used tree-structured prior (Adams et al., 2010) in a hierarchical Bayesian way, which enables drawing an infinite topic tree from the base tree while efficiently sampling the topic assignments for the words. Experiments demonstrate that the ihLDA has better topic uniqueness and hierarchical diversity thanexisting approaches, including state-of-the-art neural models.</abstract>
      <url hash="7999cfc8">2023.findings-acl.745</url>
      <bibkey>eshima-mochihashi-2023-scale</bibkey>
      <doi>10.18653/v1/2023.findings-acl.745</doi>
    </paper>
    <paper id="746">
      <title><fixed-case>RC</fixed-case>3: Regularized Contrastive Cross-lingual Cross-modal Pre-training</title>
      <author><first>Chulun</first><last>Zhou</last><affiliation>Tencent</affiliation></author>
      <author><first>Yunlong</first><last>Liang</last><affiliation>Beijing Jiaotong University</affiliation></author>
      <author><first>Fandong</first><last>Meng</last><affiliation>WeChat AI, Tencent</affiliation></author>
      <author><first>Jinan</first><last>Xu</last><affiliation>Beijing Jiaotong University</affiliation></author>
      <author><first>Jinsong</first><last>Su</last><affiliation>Xiamen university</affiliation></author>
      <author><first>Jie</first><last>Zhou</last><affiliation>Tencent Inc.</affiliation></author>
      <pages>11747-11762</pages>
      <abstract>Multilingual vision-language (V&amp;L) pre-training has achieved remarkable progress in learning universal representations across different modalities and languages. In spite of recent success, there still remain challenges limiting further improvements of V&amp;L pre-trained models in multilingual settings. Particularly, current V&amp;L pre-training methods rely heavily on strictly-aligned multilingual image-text pairs generated from English-centric datasets through machine translation. However, the cost of collecting and translating such strictly-aligned datasets is usually unbearable. In this paper, we propose Regularized Contrastive Cross-lingual Cross-modal (RC3) pre-training, which further exploits more abundant weakly-aligned multilingual image-text pairs. Specifically, we design a regularized cross-lingual visio-textual contrastive learning objective that constrains the representation proximity of weakly-aligned visio-textual inputs according to textual relevance. Besides, existing V&amp;L pre-training approaches mainly deal with visual inputs by either region-of-interest (ROI) features or patch embeddings. We flexibly integrate the two forms of visual features into our model for pre-training and downstream multi-modal tasks. Extensive experiments on 5 downstream multi-modal tasks across 6 languages demonstrate the effectiveness of our proposed method over competitive contrast models with strong zero-shot capability.</abstract>
      <url hash="6d15d742">2023.findings-acl.746</url>
      <bibkey>zhou-etal-2023-rc3</bibkey>
      <doi>10.18653/v1/2023.findings-acl.746</doi>
    </paper>
    <paper id="747">
      <title>Deep Equilibrium Non-Autoregressive Sequence Learning</title>
      <author><first>Zaixiang</first><last>Zheng</last><affiliation>ByteDance AI Lab</affiliation></author>
      <author><first>Yi</first><last>Zhou</last><affiliation>Bytedance AI Lab</affiliation></author>
      <author><first>Hao</first><last>Zhou</last><affiliation>Institute for AI Industry Research (AIR), Tsinghua University</affiliation></author>
      <pages>11763-11781</pages>
      <abstract>In this work, we argue that non-autoregressive (NAR) sequence generative models can equivalently be regarded as an iterative refinement process towards the target sequence, implying an underlying dynamical system of NAR model: z = f (z, x) → y. In such a way, the optimal prediction of a NAR model should be the equilibrium state of its dynamics if given infinitely many iterations. However, this is infeasible in practice due to limited computational and memory budgets. To this end, we propose DEQNAR to directly solve for the equilibrium state of NAR models based on deep equilibrium networks (Bai et al., 2019) with black-box root-finding solvers and back-propagate through the equilibrium point via implicit differentiation with constant memory. We conduct extensive experiments on four WMT machine translation benchmarks. Our main findings show that DEQNAR can indeed converge to a more accurate prediction and is a general-purpose framework that consistently helps yield substantial improvement for several strong NAR backbones.</abstract>
      <url hash="04d85bc7">2023.findings-acl.747</url>
      <bibkey>zheng-etal-2023-deep</bibkey>
      <doi>10.18653/v1/2023.findings-acl.747</doi>
    </paper>
    <paper id="748">
      <title><fixed-case>R</fixed-case>e<fixed-case>G</fixed-case>en: Zero-Shot Text Classification via Training Data Generation with Progressive Dense Retrieval</title>
      <author><first>Yue</first><last>Yu</last><affiliation>Georgia Institute of Technology</affiliation></author>
      <author><first>Yuchen</first><last>Zhuang</last><affiliation>Georgia Institute of Technology</affiliation></author>
      <author><first>Rongzhi</first><last>Zhang</last><affiliation>Georgia Institute of Technology</affiliation></author>
      <author><first>Yu</first><last>Meng</last><affiliation>University of Illinois at Urbana-Champaign</affiliation></author>
      <author><first>Jiaming</first><last>Shen</last><affiliation>Google Research</affiliation></author>
      <author><first>Chao</first><last>Zhang</last><affiliation>Georgia Tech</affiliation></author>
      <pages>11782-11805</pages>
      <abstract>With the development of large language models (LLMs), zero-shot learning has attracted much attention for various NLP tasks. Different from prior works that generate training data with billion-scale natural language generation (NLG) models, we propose a retrieval-enhanced framework to create training data from a general-domain unlabeled corpus. To realize this, we first conduct contrastive pretraining to learn an unsupervised dense retriever for extracting the most relevant documents using class-descriptive verbalizers. We then further pro- pose two simple strategies, namely Verbalizer Augmentation with Demonstrations and Self- consistency Guided Filtering to improve the topic coverage of the dataset while removing noisy examples. Experiments on nine datasets demonstrate that ReGen achieves 4.3% gain over the strongest baselines and saves around 70% of the time when compared with baselines using large NLG models. Besides, REGEN can be naturally integrated with recently proposed large language models to boost performance.</abstract>
      <url hash="2c4cd992">2023.findings-acl.748</url>
      <bibkey>yu-etal-2023-regen</bibkey>
      <doi>10.18653/v1/2023.findings-acl.748</doi>
    </paper>
    <paper id="749">
      <title>Race, Gender, and Age Biases in Biomedical Masked Language Models</title>
      <author><first>Michelle</first><last>Kim</last><affiliation>Michigan State University</affiliation></author>
      <author><first>Junghwan</first><last>Kim</last><affiliation>University of Michigan</affiliation></author>
      <author><first>Kristen</first><last>Johnson</last><affiliation>Michigan State University</affiliation></author>
      <pages>11806-11815</pages>
      <abstract>Biases cause discrepancies in healthcare services. Race, gender, and age of a patient affect interactions with physicians and the medical treatments one receives. These biases in clinical practices can be amplified following the release of pre-trained language models trained on biomedical corpora. To bring awareness to such repercussions, we examine social biases present in the biomedical masked language models. We curate prompts based on evidence-based practice and compare generated diagnoses based on biases. For a case study, we measure bias in diagnosing coronary artery disease and using cardiovascular procedures based on bias. Our study demonstrates that biomedical models are less biased than BERT in gender, while the opposite is true for race and age.</abstract>
      <url hash="29a746da">2023.findings-acl.749</url>
      <bibkey>kim-etal-2023-race</bibkey>
      <doi>10.18653/v1/2023.findings-acl.749</doi>
    </paper>
    <paper id="750">
      <title>Neighboring Words Affect Human Interpretation of Saliency Explanations</title>
      <author><first>Alon</first><last>Jacovi</last><affiliation>Bar Ilan University</affiliation></author>
      <author><first>Hendrik</first><last>Schuff</last><affiliation>Bosch Center for Artificial Intelligence</affiliation></author>
      <author><first>Heike</first><last>Adel</last><affiliation>Bosch Center for Artificial Intelligence</affiliation></author>
      <author><first>Ngoc Thang</first><last>Vu</last><affiliation>University of Stuttgart</affiliation></author>
      <author><first>Yoav</first><last>Goldberg</last><affiliation>Bar Ilan University</affiliation></author>
      <pages>11816-11833</pages>
      <abstract>Word-level saliency explanations (“heat maps over words”) are often used to communicate feature-attribution in text-based models. Recent studies found that superficial factors such as word length can distort human interpretation of the communicated saliency scores. We conduct a user study to investigate how the marking of a word’s *neighboring words* affect the explainee’s perception of the word’s importance in the context of a saliency explanation. We find that neighboring words have significant effects on the word’s importance rating. Concretely, we identify that the influence changes based on neighboring direction (left vs. right) and a-priori linguistic and computational measures of phrases and collocations (vs. unrelated neighboring words).Our results question whether text-based saliency explanations should be continued to be communicated at word level, and inform future research on alternative saliency explanation methods.</abstract>
      <url hash="205f30e4">2023.findings-acl.750</url>
      <bibkey>jacovi-etal-2023-neighboring</bibkey>
      <doi>10.18653/v1/2023.findings-acl.750</doi>
    </paper>
    <paper id="751">
      <title><fixed-case>HELP</fixed-case> <fixed-case>ME</fixed-case> <fixed-case>THINK</fixed-case>: A Simple Prompting Strategy for Non-experts to Create Customized Content with Models</title>
      <author><first>Swaroop</first><last>Mishra</last><affiliation>Arizona State University</affiliation></author>
      <author><first>Elnaz</first><last>Nouri</last><affiliation>Microsoft Research</affiliation></author>
      <pages>11834-11890</pages>
      <abstract>Controlling the text generated by language models and customizing the content has been a long-standing challenge. Existing prompting techniques proposed in pursuit of providing control are task-specific and lack generality; this provides overwhelming choices for non-expert users to find a suitable method for their task. The effort associated with those techniques, such as in writing examples, explanations, instructions, etc. further limits their adoption among non-expert users. In this paper, we propose a simple prompting strategy Help Me Think where we encourage largelanguage models (such as GPT3 and ChatGPT) to help non-expert users by asking a set of relevant questions and leveraging user answers to execute the task. We demonstrate the efficacy of our technique Help Me Think on a variety of tasks. Specifically, we focus on tasks that are hard for average humans and require significant thinking to perform. We hope our work will encourage the development of unconventional ways to harness the power of large language models.</abstract>
      <url hash="937a9224">2023.findings-acl.751</url>
      <bibkey>mishra-nouri-2023-help</bibkey>
      <doi>10.18653/v1/2023.findings-acl.751</doi>
    </paper>
    <paper id="752">
      <title>Decker: Double Check with Heterogeneous Knowledge for Commonsense Fact Verification</title>
      <author><first>Anni</first><last>Zou</last><affiliation>Shanghai Jiao Tong University</affiliation></author>
      <author><first>Zhuosheng</first><last>Zhang</last><affiliation>Shanghai Jiao Tong University</affiliation></author>
      <author><first>Hai</first><last>Zhao</last><affiliation>Shanghai Jiao Tong University</affiliation></author>
      <pages>11891-11904</pages>
      <abstract>Commonsense fact verification, as a challenging branch of commonsense question-answering (QA), aims to verify through facts whether a given commonsense claim is correct or not. Answering commonsense questions necessitates a combination of knowledge from various levels. However, existing studies primarily rest on grasping either unstructured evidence or potential reasoning paths from structured knowledge bases, yet failing to exploit the benefits of heterogeneous knowledge simultaneously. In light of this, we propose Decker, a commonsense fact verification model that is capable of bridging heterogeneous knowledge by uncovering latent relationships between structured and unstructured knowledge. Experimental results on two commonsense fact verification benchmark datasets, CSQA2.0 and CREAK demonstrate the effectiveness of our Decker and further analysis verifies its capability to seize more precious information through reasoning. The official implementation of Decker is available at <url>https://github.com/Anni-Zou/Decker</url>.</abstract>
      <url hash="0469a6da">2023.findings-acl.752</url>
      <bibkey>zou-etal-2023-decker</bibkey>
      <doi>10.18653/v1/2023.findings-acl.752</doi>
    </paper>
    <paper id="753">
      <title><fixed-case>D</fixed-case>oppler<fixed-case>BAS</fixed-case>: Binaural Audio Synthesis Addressing Doppler Effect</title>
      <author><first>Jinglin</first><last>Liu</last><affiliation>ByteDance</affiliation></author>
      <author><first>Zhenhui</first><last>Ye</last><affiliation>Zhejiang University</affiliation></author>
      <author><first>Qian</first><last>Chen</last><affiliation>Alibaba Group</affiliation></author>
      <author><first>Siqi</first><last>Zheng</last><affiliation>Alibaba</affiliation></author>
      <author><first>Wen</first><last>Wang</last><affiliation>Alibaba Group</affiliation></author>
      <author><first>Zhang</first><last>Qinglin</last><affiliation>Alibaba Group</affiliation></author>
      <author><first>Zhou</first><last>Zhao</last><affiliation>zhejiang university</affiliation></author>
      <pages>11905-11912</pages>
      <abstract>Recently, binaural audio synthesis (BAS) has emerged as a promising research field for its applications in augmented and virtual realities. Binaural audio helps ususers orient themselves and establish immersion by providing the brain with interaural time differences reflecting spatial information. However, existing BAS methods are limited in terms of phase estimation, which is crucial for spatial hearing. In this paper, we propose the DopplerBAS method to explicitly address the Doppler effect of the moving sound source. Specifically, we calculate the radial relative velocity of the moving speaker in spherical coordinates, which further guides the synthesis of binaural audio. This simple method introduces no additional hyper-parameters and does not modify the loss functions, and is plug-and-play: it scales well to different types of backbones. DopperBAS distinctly improves the representative WarpNet and BinauralGrad backbones in the phase error metric and reaches a new state of the art (SOTA): 0.780 (versus the current SOTA 0.807). Experiments and ablation studies demonstrate the effectiveness of our method.</abstract>
      <url hash="38a98f8b">2023.findings-acl.753</url>
      <bibkey>liu-etal-2023-dopplerbas</bibkey>
      <doi>10.18653/v1/2023.findings-acl.753</doi>
    </paper>
    <paper id="754">
      <title>Easy-to-Hard Learning for Information Extraction</title>
      <author><first>Chang</first><last>Gao</last><affiliation>The Chinese University of Hong Kong</affiliation></author>
      <author><first>Wenxuan</first><last>Zhang</last><affiliation>DAMO Academy, Alibaba Group</affiliation></author>
      <author><first>Wai</first><last>Lam</last><affiliation>The Chinese University of Hong Kong</affiliation></author>
      <author><first>Lidong</first><last>Bing</last><affiliation>Alibaba DAMO Academy</affiliation></author>
      <pages>11913-11930</pages>
      <abstract>Information extraction (IE) systems aim to automatically extract structured information, such as named entities, relations between entities, and events, from unstructured texts. While most existing work addresses a particular IE task, universally modeling various IE tasks with one model has achieved great success recently. Despite their success, they employ a one-stage learning strategy, i.e., directly learning to extract the target structure given the input text, which contradicts the human learning process. In this paper, we propose a unified easy-to-hard learning framework consisting of three stages, i.e., the easy stage, the hard stage, and the main stage, for IE by mimicking the human learning process. By breaking down the learning process into multiple stages, our framework facilitates the model to acquire general IE task knowledge and improve its generalization ability. Extensive experiments across four IE tasks demonstrate the effectiveness of our framework. We achieve new state-of-the-art results on 13 out of 17 datasets.</abstract>
      <url hash="607b73cc">2023.findings-acl.754</url>
      <bibkey>gao-etal-2023-easy</bibkey>
      <doi>10.18653/v1/2023.findings-acl.754</doi>
    </paper>
    <paper id="755">
      <title><fixed-case>SC</fixed-case>on<fixed-case>E</fixed-case>: Simplified Cone Embeddings with Symbolic Operators for Complex Logical Queries</title>
      <author><first>Chau</first><last>Nguyen</last><affiliation>The University of Western Australia</affiliation></author>
      <author><first>Tim</first><last>French</last><affiliation>The University of Western Australia</affiliation></author>
      <author><first>Wei</first><last>Liu</last><affiliation>The University of Western Austarlia</affiliation></author>
      <author><first>Michael</first><last>Stewart</last><affiliation>The University of Western Australia</affiliation></author>
      <pages>11931-11946</pages>
      <abstract>Geometric representation of query embeddings (using points, particles, rectangles and cones) can effectively achieve the task of answering complex logical queries expressed in first-order logic (FOL) form over knowledge graphs, allowing intuitive encodings. However, current geometric-based methods depend on the neural approach to model FOL operators (conjunction, disjunction and negation), which are not easily explainable with considerable computation cost. We overcome this challenge by introducing a symbolic modeling approach for the FOL operators, emphasizing the direct calculation of the intersection between geometric shapes, particularly sector-cones in the embedding space, to model the conjunction operator. This approach reduces the computation cost as a non-neural approach is involved in the core logic operators. Moreover, we propose to accelerate the learning in the relation projection operator using the neural approach to emphasize the essential role of this operator in all query structures. Although empirical evidence for explainability is challenging, our approach demonstrates a significant improvement in answering complex logical queries (both non-negative and negative FOL forms) over previous geometric-based models.</abstract>
      <url hash="eb570bfb">2023.findings-acl.755</url>
      <bibkey>nguyen-etal-2023-scone</bibkey>
      <doi>10.18653/v1/2023.findings-acl.755</doi>
    </paper>
    <paper id="756">
      <title>Two Heads Are Better Than One: Improving Fake News Video Detection by Correlating with Neighbors</title>
      <author><first>Peng</first><last>Qi</last><affiliation>Institute of Computing Technology, Chinese Academy of Sciences; University of Chinese Academy of Sciences</affiliation></author>
      <author><first>Yuyang</first><last>Zhao</last><affiliation>National University of Singapore</affiliation></author>
      <author><first>Yufeng</first><last>Shen</last><affiliation>University of Chinese Academy of Sciences</affiliation></author>
      <author><first>Wei</first><last>Ji</last><affiliation>National University of Singapore</affiliation></author>
      <author><first>Juan</first><last>Cao</last><affiliation>Institute of Computing Technology, Chinese Academy of Sciences; University of Chinese Academy of Sciences</affiliation></author>
      <author><first>Tat-Seng</first><last>Chua</last><affiliation>National University of Singapore</affiliation></author>
      <pages>11947-11959</pages>
      <abstract>The prevalence of short video platforms has spawned a lot of fake news videos, which have stronger propagation ability than textual fake news. Thus, automatically detecting fake news videos has been an important countermeasure in practice. Previous works commonly verify each news video individually with multimodal information. Nevertheless, news videos from different perspectives regarding the same event are commonly posted together, which contain complementary or contradictory information and thus can be used to evaluate each other mutually. To this end, we introduce a new and practical paradigm, i.e., cross-sample fake news video detection, and propose a novel framework, Neighbor-Enhanced fakE news video Detection (NEED), which integrates the neighborhood relationship of new videos belonging to the same event. NEED can be readily combined with existing single-sample detectors and further enhance their performances with the proposed graph aggregation (GA) and debunking rectification (DR) modules. Specifically, given the feature representations obtained from single-sample detectors, GA aggregates the neighborhood information with the dynamic graph to enrich the features of independent samples. After that, DR explicitly leverages the relationship between debunking videos and fake news videos to refute the candidate videos via textual and visual consistency. Extensive experiments on the public benchmark demonstrate that NEED greatly improves the performance of both single-modal (up to 8.34% in accuracy) and multimodal (up to 4.97% in accuracy) base detectors.</abstract>
      <url hash="426b54df">2023.findings-acl.756</url>
      <bibkey>qi-etal-2023-two</bibkey>
      <doi>10.18653/v1/2023.findings-acl.756</doi>
    </paper>
    <paper id="757">
      <title>An Annotated Dataset for Explainable Interpersonal Risk Factors of Mental Disturbance in Social Media Posts</title>
      <author><first>Muskan</first><last>Garg</last><affiliation>Mayo Clinic</affiliation></author>
      <author><first>Amirmohammad</first><last>Shahbandegan</last><affiliation>Lakehead University</affiliation></author>
      <author><first>Amrit</first><last>Chadha</last><affiliation>Thapar Institute of Engineering and technology</affiliation></author>
      <author><first>Vijay</first><last>Mago</last><affiliation>Lakehead University</affiliation></author>
      <pages>11960-11969</pages>
      <abstract>With a surge in identifying suicidal risk and its severity in social media posts, we argue that a more consequential and explainable research is required for optimal impact on clinical psychology practice and personalized mental healthcare. The success of computational intelligence techniques for inferring mental illness from social media resources, points to natural language processing as a lens for determining Interpersonal Risk Factors (IRF) in human writings. Motivated with limited availability of datasets for social NLP research community, we construct and release a new annotated dataset with human-labelled explanations and classification of IRF affecting mental disturbance on social media: (i) Thwarted Belongingness (TBe), and (ii) Perceived Burdensomeness (PBu). We establish baseline models on our dataset facilitating future research directions to develop real-time personalized AI models by detecting patterns of TBe and PBu in emotional spectrum of user’s historical social media profile.</abstract>
      <url hash="51e1a9bb">2023.findings-acl.757</url>
      <bibkey>garg-etal-2023-annotated</bibkey>
      <doi>10.18653/v1/2023.findings-acl.757</doi>
    </paper>
    <paper id="758">
      <title>Nano: Nested Human-in-the-Loop Reward Learning for Few-shot Language Model Control</title>
      <author><first>Xiang</first><last>Fan</last><affiliation>Carnegie Mellon University</affiliation></author>
      <author><first>Yiwei</first><last>Lyu</last><affiliation>University of Michigan</affiliation></author>
      <author><first>Paul Pu</first><last>Liang</last><affiliation>Carnegie Mellon University</affiliation></author>
      <author><first>Ruslan</first><last>Salakhutdinov</last><affiliation>CMU</affiliation></author>
      <author><first>Louis-Philippe</first><last>Morency</last><affiliation>Carnegie Mellon University</affiliation></author>
      <pages>11970-11992</pages>
      <abstract>Pretrained language models have demonstrated extraordinary capabilities in language generation. However, real-world tasks often require controlling the distribution of generated text in order to mitigate bias, promote fairness, and achieve personalization. Existing techniques for controlling the distribution of generated text only work with quantified distributions, which require pre-defined categories, proportions of the distribution, or an existing corpus following the desired distributions. However, many important distributions, such as personal preferences, are unquantified. In this work, we tackle the problem of generating text following arbitrary distributions (quantified and unquantified) by proposing NANO, a few-shot human-in-the-loop training algorithm that continuously learns from human feedback. NANO achieves state-of-the-art results on single topic/attribute as well as quantified distribution control compared to previous works. We also show that NANO is able to learn unquantified distributions, achieves personalization, and captures differences between different individuals’ personal preferences with high sample efficiency.</abstract>
      <url hash="4d80a8c1">2023.findings-acl.758</url>
      <bibkey>fan-etal-2023-nano</bibkey>
      <doi>10.18653/v1/2023.findings-acl.758</doi>
    </paper>
    <paper id="759">
      <title>Connectivity Patterns are Task Embeddings</title>
      <author><first>Zhiheng</first><last>Xi</last><affiliation>Fudan University</affiliation></author>
      <author><first>Rui</first><last>Zheng</last><affiliation>Fudan University</affiliation></author>
      <author><first>Yuansen</first><last>Zhang</last><affiliation>Fudan University</affiliation></author>
      <author><first>Xuanjing</first><last>Huang</last><affiliation>Fudan University</affiliation></author>
      <author><first>Zhongyu</first><last>Wei</last><affiliation>School of Data Science, Fudan University</affiliation></author>
      <author><first>Minlong</first><last>Peng</last><affiliation>Baidu Inc.</affiliation></author>
      <author><first>Mingming</first><last>Sun</last><affiliation>Baidu Research</affiliation></author>
      <author><first>Qi</first><last>Zhang</last><affiliation>Fudan University</affiliation></author>
      <author><first>Tao</first><last>Gui</last><affiliation>fudan university</affiliation></author>
      <pages>11993-12013</pages>
      <abstract>Task embeddings are task-specific vectors designed to construct a semantic space of tasks, which can be used to predict the most transferable source task for a given target task via the similarity between task embeddings. However, existing methods use optimized parameters and representations as task embeddings, resulting in substantial computational complexity and storage requirements. In this work, we draw inspiration from the operating mechanism of deep neural networks (DNNs) and biological brains, where neuronal activations are sparse and task-specific, and we use the connectivity patterns of neurons as a unique identifier associated with the task. The proposed method learns to assign importance masks for sub-structures of DNNs, and accordingly indicate the task-specific connectivity patterns. In addition to the storage advantages brought by the binary masking mechanism and structured sparsity, the early-bird nature of the sparse optimization process can deliver an efficient computation advantage. Experiments show that our method consistently outperforms other baselines in predicting inter-task transferability across data regimes and transfer settings, while keeping high efficiency in computation and storage.</abstract>
      <url hash="5f4e9d00">2023.findings-acl.759</url>
      <bibkey>xi-etal-2023-connectivity</bibkey>
      <doi>10.18653/v1/2023.findings-acl.759</doi>
    </paper>
    <paper id="760">
      <title>Improving Autoregressive Grammatical Error Correction with Non-autoregressive Models</title>
      <author><first>Hang</first><last>Cao</last><affiliation>Northeastern University</affiliation></author>
      <author><first>Zhiquan</first><last>Cao</last><affiliation>Northeastern University</affiliation></author>
      <author><first>Chi</first><last>Hu</last><affiliation>Northeastern University</affiliation></author>
      <author><first>Baoyu</first><last>Hou</last><affiliation>NEU</affiliation></author>
      <author><first>Tong</first><last>Xiao</last><affiliation>Northeastern University</affiliation></author>
      <author><first>Jingbo</first><last>Zhu</last><affiliation>Northeastern University</affiliation></author>
      <pages>12014-12027</pages>
      <abstract>Grammatical Error Correction (GEC) aims to correct grammatical errors in sentences. We find that autoregressive models tend to assign low probabilities to tokens that need corrections. Here we introduce additional signals to the training of GEC models so that these systems can learn to better predict at ambiguous positions. To do this, we use a non-autoregressive model as an auxiliary model, and develop a new regularization term of training by considering the difference in predictions between the autoregressive and non-autoregressive models. We experiment with this method on both English and Chinese GEC tasks. Experimental results show that our GEC system outperforms the baselines on all the data sets significantly.</abstract>
      <url hash="cf754bec">2023.findings-acl.760</url>
      <bibkey>cao-etal-2023-improving</bibkey>
      <doi>10.18653/v1/2023.findings-acl.760</doi>
    </paper>
    <paper id="761">
      <title><fixed-case>S</fixed-case>am<fixed-case>T</fixed-case>o<fixed-case>N</fixed-case>e: Improving Contrastive Loss for Dual Encoder Retrieval Models with Same Tower Negatives</title>
      <author><first>Fedor</first><last>Moiseev</last><affiliation>Google</affiliation></author>
      <author><first>Gustavo</first><last>Hernandez Abrego</last><affiliation>Google</affiliation></author>
      <author><first>Peter</first><last>Dornbach</last><affiliation>Google</affiliation></author>
      <author><first>Imed</first><last>Zitouni</last><affiliation>Google</affiliation></author>
      <author><first>Enrique</first><last>Alfonseca</last><affiliation>Google</affiliation></author>
      <author><first>Zhe</first><last>Dong</last><affiliation>Google Inc</affiliation></author>
      <pages>12028-12037</pages>
      <abstract>Dual encoders have been used for retrieval tasks and representation learning with good results. A standard way to train dual encoders is using a contrastive loss with in-batch negatives. In this work, we propose an improved contrastive learning objective by adding queries or documents from the same encoder towers to the negatives, for which we name it as “contrastive loss with SAMe TOwer NEgatives” (SamToNe). By evaluating on question answering retrieval benchmarks from MS MARCO and MultiReQA, and heterogenous zero-shot information retrieval benchmarks (BEIR), we demonstrate that SamToNe can effectively improve the retrieval quality for both symmetric and asymmetric dual encoders. By directly probing the embedding spaces of the two encoding towers via the t-SNE algorithm (van der Maaten and Hinton, 2008), we observe that SamToNe ensures the alignment between the embedding spaces from the two encoder towers. Based on the analysis of the embedding distance distributions of the top-1 retrieved results, we further explain the efficacy of the method from the perspective of regularisation.</abstract>
      <url hash="2733999b">2023.findings-acl.761</url>
      <bibkey>moiseev-etal-2023-samtone</bibkey>
      <doi>10.18653/v1/2023.findings-acl.761</doi>
    </paper>
    <paper id="762">
      <title>On the Strength of Sequence Labeling and Generative Models for Aspect Sentiment Triplet Extraction</title>
      <author><first>Shen</first><last>Zhou</last><affiliation>Wuhan University</affiliation></author>
      <author><first>Tieyun</first><last>Qian</last><affiliation>Wuhan University</affiliation></author>
      <pages>12038-12050</pages>
      <abstract>Generative models have achieved great success in aspect sentiment triplet extraction tasks. However, existing methods ignore the mutual informative clues between aspect and opinion terms and may generate false paired triplets. Furthermore, the inherent limitations of generative models, i.e., the token-by-token decoding and the simple structured prompt, prevent models from handling complex structures especially multi-word terms and multi-triplet sentences. To address these issues, we propose a sequence labeling enhanced generative model. Firstly, we encode the dependency between aspect and opinion into two bidirectional templates to avoid false paired triplets. Secondly, we introduce a marker-oriented sequence labeling module to improve generative models’ ability of tackling complex structures. Specifically, this module enables the generative model to capture the boundary information of aspect/opinion spans and provides hints to decode multiple triplets with the shared marker. Experimental results on four datasets prove that our model yields a new state-of-art performance. Our code and data are available at <url>https://github.com/NLPWM-WHU/SLGM</url>.</abstract>
      <url hash="a33b64f7">2023.findings-acl.762</url>
      <bibkey>zhou-qian-2023-strength</bibkey>
      <doi>10.18653/v1/2023.findings-acl.762</doi>
    </paper>
    <paper id="763">
      <title>Revisiting Non-Autoregressive Translation at Scale</title>
      <author><first>Zhihao</first><last>Wang</last><affiliation>Xiamen University</affiliation></author>
      <author><first>Longyue</first><last>Wang</last><affiliation>Tencent AI Lab</affiliation></author>
      <author><first>Jinsong</first><last>Su</last><affiliation>Xiamen university</affiliation></author>
      <author><first>Junfeng</first><last>Yao</last><affiliation>Xiamen University</affiliation></author>
      <author><first>Zhaopeng</first><last>Tu</last><affiliation>Tencent AI Lab</affiliation></author>
      <pages>12051-12065</pages>
      <abstract>In real-world systems, scaling has been critical for improving the translation quality in autoregressive translation (AT), which however has not been well studied for non-autoregressive translation (NAT). In this work, we bridge the gap by systematically studying the impact of scaling on NAT behaviors. Extensive experiments on six WMT benchmarks over two advanced NAT models show that scaling can alleviate the commonly-cited weaknesses of NAT models, resulting in better translation performance. To reduce the side-effect of scaling on decoding speed, we empirically investigate the impact of NAT encoder and decoder on the translation performance. Experimental results on the large-scale WMT20 En-De show that the asymmetric architecture (e.g. bigger encoder and smaller decoder) can achieve comparable performance with the scaling model, while maintaining the superiority of decoding speed with standard NAT models. To this end, we establish a new benchmark by validating scaled NAT models on the scaled dataset, which can be regarded as a strong baseline for future works. We release code and system outputs at <url>https://github.com/DeepLearnXMU/Scaling4NAT</url>.</abstract>
      <url hash="bd11f240">2023.findings-acl.763</url>
      <bibkey>wang-etal-2023-revisiting</bibkey>
      <doi>10.18653/v1/2023.findings-acl.763</doi>
    </paper>
    <paper id="764">
      <title>Improving Radiology Summarization with Radiograph and Anatomy Prompts</title>
      <author><first>Jinpeng</first><last>Hu</last><affiliation>CUHKSZ</affiliation></author>
      <author><first>Zhihong</first><last>Chen</last><affiliation>Shenzhen Research Institute of Big Data, The Chinese University of Hong Kong, Shenzhen</affiliation></author>
      <author id="yang-liu"><first>Yang</first><last>Liu</last><affiliation>The Chinese University of Hong Kong, Shenzhen</affiliation></author>
      <author><first>Xiang</first><last>Wan</last><affiliation>Shenzhen Research Institute of Big Data</affiliation></author>
      <author><first>Tsung-Hui</first><last>Chang</last><affiliation>The Chinese University of Hong Kong, Shenzhen</affiliation></author>
      <pages>12066-12080</pages>
      <abstract>The impression is crucial for the referring physicians to grasp key information since it is concluded from the findings and reasoning of radiologists. To alleviate the workload of radiologists and reduce repetitive human labor in impression writing, many researchers have focused on automatic impression generation. However, recent works on this task mainly summarize the corresponding findings and pay less attention to the radiology images. In clinical, radiographs can provide more detailed valuable observations to enhance radiologists’ impression writing, especially for complicated cases. Besides, each sentence in findings usually focuses on single anatomy, such that they only need to be matched to corresponding anatomical regions instead of the whole image, which is beneficial for textual and visual features alignment. Therefore, we propose a novel anatomy-enhanced multimodal model to promote impression generation. In detail, we first construct a set of rules to extract anatomies and put these prompts into each sentence to highlight anatomy characteristics. Then, two separate encoders are applied to extract features from the radiograph and findings. Afterward, we utilize a contrastive learning module to align these two representations at the overall level and use a co-attention to fuse them at the sentence level with the help of anatomy-enhanced sentence representation. The experimental results on two benchmark datasets confirm the effectiveness of the proposed method, which achieves state-of-the-art results.</abstract>
      <url hash="67352671">2023.findings-acl.764</url>
      <bibkey>hu-etal-2023-improving-radiology</bibkey>
      <doi>10.18653/v1/2023.findings-acl.764</doi>
    </paper>
    <paper id="765">
      <title>Explanation Regeneration via Information Bottleneck</title>
      <author><first>Qintong</first><last>Li</last><affiliation>The University of Hong Kong</affiliation></author>
      <author><first>Zhiyong</first><last>Wu</last><affiliation>Shanghai AI Lab</affiliation></author>
      <author><first>Lingpeng</first><last>Kong</last><affiliation>The University of Hong Kong</affiliation></author>
      <author><first>Wei</first><last>Bi</last><affiliation>Tencent AI Lab</affiliation></author>
      <pages>12081-12102</pages>
      <abstract>Explaining the black-box predictions of NLP models naturally and accurately is an important open problem in natural language generation. These free-text explanations are expected to contain sufficient and carefully-selected evidence to form supportive arguments for predictions. Thanks to the superior generative capacity of large pretrained language models (PLM), recent work built on prompt engineering enables explanations generated without specific training. However, explanations generated through single-pass prompting often lack sufficiency and conciseness, due to the prompt complexity and hallucination issues. To discard the dross and take the essence of current PLM’s results, we propose to produce sufficient and concise explanations via the information bottleneck (EIB) theory. EIB regenerates explanations by polishing the single-pass output of PLM but retaining the information that supports the contents being explained by balancing two information bottleneck objectives. Experiments on two different tasks verify the effectiveness of EIB through automatic evaluation and thoroughly-conducted human evaluation.</abstract>
      <url hash="25bef441">2023.findings-acl.765</url>
      <bibkey>li-etal-2023-explanation</bibkey>
      <doi>10.18653/v1/2023.findings-acl.765</doi>
    </paper>
    <paper id="766">
      <title>Improving Zero-shot Multilingual Neural Machine Translation by Leveraging Cross-lingual Consistency Regularization</title>
      <author><first>Pengzhi</first><last>Gao</last><affiliation>Baidu, Inc.</affiliation></author>
      <author><first>Liwen</first><last>Zhang</last><affiliation>Baidu. Inc.</affiliation></author>
      <author><first>Zhongjun</first><last>He</last><affiliation>Baidu, Inc.</affiliation></author>
      <author><first>Hua</first><last>Wu</last><affiliation>Baidu</affiliation></author>
      <author><first>Haifeng</first><last>Wang</last><affiliation>Baidu</affiliation></author>
      <pages>12103-12119</pages>
      <abstract>The multilingual neural machine translation (NMT) model has a promising capability of zero-shot translation, where it could directly translate between language pairs unseen during training. For good transfer performance from supervised directions to zero-shot directions, the multilingual NMT model is expected to learn universal representations across different languages. This paper introduces a cross-lingual consistency regularization, CrossConST, to bridge the representation gap among different languages and boost zero-shot translation performance. The theoretical analysis shows that CrossConST implicitly maximizes the probability distribution for zero-shot translation, and the experimental results on both low-resource and high-resource benchmarks show that CrossConST consistently improves the translation performance. The experimental analysis also proves that CrossConST could close the sentence representation gap and better align the representation space. Given the universality and simplicity of CrossConST, we believe it can serve as a strong baseline for future multilingual NMT research.</abstract>
      <url hash="8028d370">2023.findings-acl.766</url>
      <bibkey>gao-etal-2023-improving</bibkey>
      <doi>10.18653/v1/2023.findings-acl.766</doi>
    </paper>
    <paper id="767">
      <title><fixed-case>R</fixed-case>eact<fixed-case>IE</fixed-case>: Enhancing Chemical Reaction Extraction with Weak Supervision</title>
      <author><first>Ming</first><last>Zhong</last><affiliation>University of Illinois Urbana-Champaign</affiliation></author>
      <author><first>Siru</first><last>Ouyang</last><affiliation>University of Illinois Urbana-Champaign</affiliation></author>
      <author><first>Minhao</first><last>Jiang</last><affiliation>University of Illinois at Urbana Champaign</affiliation></author>
      <author><first>Vivian</first><last>Hu</last><affiliation>UIUC</affiliation></author>
      <author><first>Yizhu</first><last>Jiao</last><affiliation>University of Illinois Urbana-Champaign</affiliation></author>
      <author><first>Xuan</first><last>Wang</last><affiliation>Virginia Tech</affiliation></author>
      <author><first>Jiawei</first><last>Han</last><affiliation>UIUC</affiliation></author>
      <pages>12120-12130</pages>
      <abstract>Structured chemical reaction information plays a vital role for chemists engaged in laboratory work and advanced endeavors such as computer-aided drug design. Despite the importance of extracting structured reactions from scientific literature, data annotation for this purpose is cost-prohibitive due to the significant labor required from domain experts. Consequently, the scarcity of sufficient training data poses an obstacle to the progress of related models in this domain. In this paper, we propose ReactIE, which combines two weakly supervised approaches for pre-training. Our method utilizes frequent patterns within the text as linguistic cues to identify specific characteristics of chemical reactions. Additionally, we adopt synthetic data from patent records as distant supervision to incorporate domain knowledge into the model. Experiments demonstrate that ReactIE achieves substantial improvements and outperforms all existing baselines.</abstract>
      <url hash="31bcb8a6">2023.findings-acl.767</url>
      <bibkey>zhong-etal-2023-reactie</bibkey>
      <doi>10.18653/v1/2023.findings-acl.767</doi>
    </paper>
    <paper id="768">
      <title>Expand, Rerank, and Retrieve: Query Reranking for Open-Domain Question Answering</title>
      <author><first>Yung-Sung</first><last>Chuang</last><affiliation>Massachusetts Institute of Technology</affiliation></author>
      <author><first>Wei</first><last>Fang</last><affiliation>Massachusetts Institute of Technology</affiliation></author>
      <author><first>Shang-Wen</first><last>Li</last><affiliation>Facebook AI Research (FAIR)</affiliation></author>
      <author><first>Wen-tau</first><last>Yih</last><affiliation>Meta AI - FAIR</affiliation></author>
      <author><first>James</first><last>Glass</last><affiliation>Massachusetts Institute of Technology</affiliation></author>
      <pages>12131-12147</pages>
      <abstract>We propose EAR, a query Expansion And Reranking approach for improving passage retrieval, with the application to open-domain question answering. EAR first applies a query expansion model to generate a diverse set of queries, and then uses a query reranker to select the ones that could lead to better retrieval results. Motivated by the observation that the best query expansion often is not picked by greedy decoding, EAR trains its reranker to predict the rank orders of the gold passages when issuing the expanded queries to a given retriever. By connecting better the query expansion model and retriever, EAR significantly enhances a traditional sparse retrieval method, BM25. Empirically, EAR improves top-5/20 accuracy by 3-8 and 5-10 points in in-domain and out-of-domain settings, respectively, when compared to a vanilla query expansion model, GAR, and a dense retrieval model, DPR.</abstract>
      <url hash="9ecac413">2023.findings-acl.768</url>
      <bibkey>chuang-etal-2023-expand</bibkey>
      <doi>10.18653/v1/2023.findings-acl.768</doi>
    </paper>
    <paper id="769">
      <title>Neural Networks Against (and For) Self-Training: Classification with Small Labeled and Large Unlabeled Sets</title>
      <author><first>Payam</first><last>Karisani</last><affiliation>UIUC</affiliation></author>
      <pages>12148-12162</pages>
      <abstract>We propose a semi-supervised text classifier based on self-training using one positive and one negative property of neural networks. One of the weaknesses of self-training is the semantic drift problem, where noisy pseudo-labels accumulate over iterations and consequently the error rate soars. In order to tackle this challenge, we reshape the role of pseudo-labels and create a hierarchical order of information. In addition, a crucial step in self-training is to use the classifier confidence prediction to select the best candidate pseudo-labels. This step cannot be efficiently done by neural networks, because it is known that their output is poorly calibrated. To overcome this challenge, we propose a hybrid metric to replace the plain confidence measurement. Our metric takes into account the prediction uncertainty via a subsampling technique. We evaluate our model in a set of five standard benchmarks, and show that it significantly outperforms a set of ten diverse baseline models. Furthermore, we show that the improvement achieved by our model is additive to language model pretraining, which is a widely used technique for using unlabeled documents.</abstract>
      <url hash="3026a8bd">2023.findings-acl.769</url>
      <bibkey>karisani-2023-neural</bibkey>
      <doi>10.18653/v1/2023.findings-acl.769</doi>
    </paper>
    <paper id="770">
      <title>Inducing Character-level Structure in Subword-based Language Models with Type-level Interchange Intervention Training</title>
      <author><first>Jing</first><last>Huang</last><affiliation>Stanford University</affiliation></author>
      <author><first>Zhengxuan</first><last>Wu</last><affiliation>Stanford University</affiliation></author>
      <author><first>Kyle</first><last>Mahowald</last><affiliation>University of Texas at Austin</affiliation></author>
      <author><first>Christopher</first><last>Potts</last><affiliation>Stanford University</affiliation></author>
      <pages>12163-12180</pages>
      <abstract>Language tasks involving character-level manipulations (e.g., spelling corrections, arithmetic operations, word games) are challenging for models operating on subword units. To address this, we develop a causal intervention framework to learn robust and interpretable character representations inside subword-based language models. Our method treats each character as a typed variable in a causal model and learns such causal structures by adapting the interchange intervention training method of Geiger et al. (2021). We additionally introduce a suite of character-level tasks that systematically vary in their dependence on meaning and sequence-level context. While character-level models still perform best on purely form-based tasks like string reversal, our method outperforms character-level models on more complex tasks that blend form, meaning, and context, such as spelling correction in context and word search games. Compared with standard subword-based models, our approach also significantly improves robustness on unseen token sequences and leads to human-interpretable internal representations of characters.</abstract>
      <url hash="b6cb8f65">2023.findings-acl.770</url>
      <bibkey>huang-etal-2023-inducing</bibkey>
      <doi>10.18653/v1/2023.findings-acl.770</doi>
    </paper>
    <paper id="771">
      <title>Efficient Document Embeddings via Self-Contrastive Bregman Divergence Learning</title>
      <author><first>Daniel</first><last>Saggau</last><affiliation>LMU Munich</affiliation></author>
      <author><first>Mina</first><last>Rezaei</last><affiliation>LMU Munich</affiliation></author>
      <author><first>Bernd</first><last>Bischl</last><affiliation>LMU</affiliation></author>
      <author><first>Ilias</first><last>Chalkidis</last><affiliation>University of Copenhagen</affiliation></author>
      <pages>12181-12190</pages>
      <abstract>Learning quality document embeddings is a fundamental problem in natural language processing (NLP), information retrieval (IR), recommendation systems, and search engines. Despite recent advances in the development of transformer-based models that produce sentence embeddings with self-contrastive learning, the encoding of long documents (Ks of words) is still challenging with respect to both efficiency and quality considerations. Therefore, we train Longfomer-based document encoders using a state-of-the-art unsupervised contrastive learning method (SimCSE). Further on, we complement the baseline method -siamese neural network- with additional convex neural networks based on functional Bregman divergence aiming to enhance the quality of the output document representations. We show that overall the combination of a self-contrastive siamese network and our proposed neural Bregman network outperforms the baselines in two linear classification settings on three long document topic classification tasks from the legal and biomedical domains.</abstract>
      <url hash="574678bb">2023.findings-acl.771</url>
      <bibkey>saggau-etal-2023-efficient</bibkey>
      <doi>10.18653/v1/2023.findings-acl.771</doi>
    </paper>
    <paper id="772">
      <title><fixed-case>QAP</fixed-case>: A Quantum-Inspired Adaptive-Priority-Learning Model for Multimodal Emotion Recognition</title>
      <author><first>Ziming</first><last>Li</last><affiliation>Institute of Information Engineering, Chinese Academy of Sciences; University of Chinese Academy of Sciences</affiliation></author>
      <author><first>Yan</first><last>Zhou</last><affiliation>Institute of Information Engineering,Chinese Academy of Sciences</affiliation></author>
      <author><first>Yaxin</first><last>Liu</last><affiliation>Institute of Information Engineering,Chinese Academy of Sciences</affiliation></author>
      <author><first>Fuqing</first><last>Zhu</last><affiliation>Institute of Information Engineering, Chinese Academy of Sciences</affiliation></author>
      <author><first>Chuanpeng</first><last>Yang</last><affiliation>Institute of Information Engineering,Chinese Academy of Sciences</affiliation></author>
      <author><first>Songlin</first><last>Hu</last><affiliation>Institute of Information Engineering, CAS</affiliation></author>
      <pages>12191-12204</pages>
      <abstract>Multimodal emotion recognition for video has gained considerable attention in recent years, in which three modalities (<i>i.e.,</i> textual, visual and acoustic) are involved. Due to the diverse levels of informational content related to emotion, three modalities typically possess varying degrees of contribution to emotion recognition. More seriously, there might be inconsistencies between the emotion of individual modality and the video. The challenges mentioned above are caused by the inherent uncertainty of emotion. Inspired by the recent advances of quantum theory in modeling uncertainty, we make an initial attempt to design a quantum-inspired adaptive-priority-learning model (QAP) to address the challenges. Specifically, the quantum state is introduced to model modal features, which allows each modality to retain all emotional tendencies until the final classification. Additionally, we design Q-attention to orderly integrate three modalities, and then QAP learns modal priority adaptively so that modalities can provide different amounts of information based on priority. Experimental results on the IEMOCAP and MOSEI datasets show that QAP establishes new state-of-the-art results.</abstract>
      <url hash="af1b35f8">2023.findings-acl.772</url>
      <bibkey>li-etal-2023-qap</bibkey>
      <doi>10.18653/v1/2023.findings-acl.772</doi>
    </paper>
    <paper id="773">
      <title>Language acquisition: do children and language models follow similar learning stages?</title>
      <author><first>Linnea</first><last>Evanson</last><affiliation>Meta AI; Ecole normale superieure</affiliation></author>
      <author><first>Yair</first><last>Lakretz</last><affiliation>Neurospin</affiliation></author>
      <author><first>Jean Rémi</first><last>King</last><affiliation>CNRS</affiliation></author>
      <pages>12205-12218</pages>
      <abstract>During language acquisition, children follow a typical sequence of learning stages, whereby they first learn to categorize phonemes before they develop their lexicon and eventually master increasingly complex syntactic structures. However, the computational principles that lead to this learning trajectory remain largely unknown. To investigate this, we here compare the learning trajectories of deep language models to those of human children. Specifically, we test whether, during its training, GPT-2 exhibits stages of language acquisition comparable to those observed in children aged between 18 months and 6 years. For this, we train 48 GPT-2 models from scratch and evaluate their syntactic and semantic abilities at each training step, using 96 probes curated from the BLiMP, Zorro and BIG-Bench benchmarks. We then compare these evaluations with the behavior of 54 children during language production. Our analyses reveal three main findings. First, similarly to children, the language models tend to learn linguistic skills in a systematic order. Second, this learning scheme is parallel: the language tasks that are learned last improve from the very first training steps. Third, some – but not all – learning stages are shared between children and these language models. Overall, these results shed new light on the principles of language acquisition, and highlight important divergences in how humans and modern algorithms learn to process natural language.</abstract>
      <url hash="d7d7faab">2023.findings-acl.773</url>
      <bibkey>evanson-etal-2023-language</bibkey>
      <doi>10.18653/v1/2023.findings-acl.773</doi>
    </paper>
    <paper id="774">
      <title>The Role of Output Vocabulary in <fixed-case>T</fixed-case>2<fixed-case>T</fixed-case> <fixed-case>LM</fixed-case>s for <fixed-case>SPARQL</fixed-case> Semantic Parsing</title>
      <author><first>Debayan</first><last>Banerjee</last><affiliation>Language Technology Group, University of Hamburg</affiliation></author>
      <author><first>Pranav</first><last>Nair</last><affiliation>Indian Institute of Technology (BHU), Varanasi</affiliation></author>
      <author><first>Ricardo</first><last>Usbeck</last><affiliation>Hamburg University</affiliation></author>
      <author><first>Chris</first><last>Biemann</last><affiliation>Universität Hamburg</affiliation></author>
      <pages>12219-12228</pages>
      <abstract>In this work, we analyse the role of output vocabulary for text-to-text (T2T) models on the task of SPARQL semantic parsing. We perform experiments within the the context of knowledge graph question answering (KGQA), where the task is to convert questions in natural language to the SPARQL query language. We observe that the query vocabulary is distinct from human vocabulary. Language Models (LMs) are pre-dominantly trained for human language tasks, and hence, if the query vocabulary is replaced with a vocabulary more attuned to the LM tokenizer, the performance of models may improve. We carry out carefully selected vocabulary substitutions on the queries and find absolute gains in the range of 17% on the GrailQA dataset.</abstract>
      <url hash="afc1f9ec">2023.findings-acl.774</url>
      <bibkey>banerjee-etal-2023-role</bibkey>
      <doi>10.18653/v1/2023.findings-acl.774</doi>
    </paper>
    <paper id="775">
      <title><fixed-case>U</fixed-case>ni<fixed-case>COQE</fixed-case>: Unified Comparative Opinion Quintuple Extraction As A Set</title>
      <author><first>Zinong</first><last>Yang</last><affiliation>Nanjing University of Science and Technology</affiliation></author>
      <author><first>Feng</first><last>Xu</last><affiliation>Nanjing University of Finance and Economics</affiliation></author>
      <author><first>Jianfei</first><last>Yu</last><affiliation>Nanjing University of Science and Technology</affiliation></author>
      <author><first>Rui</first><last>Xia</last><affiliation>Nanjing University of Science and Technology</affiliation></author>
      <pages>12229-12240</pages>
      <abstract>Comparative Opinion Quintuple Extraction (COQE) aims to identify comparative opinion sentences in product reviews, extract comparative opinion elements in the sentences, and then incorporate them into quintuples. Existing methods decompose the COQE task into multiple primary subtasks and then solve them in a pipeline manner. However, these approaches ignore the intrinsic connection between subtasks and the error propagation among stages. This paper proposes a unified generative model, UniCOQE, to solve the COQE task in one shot. We design a generative template where all the comparative tuples are concatenated as the target output sequence. However, the multiple tuples are inherently not an ordered sequence but an unordered set. The pre-defined order will force the generative model to learn a false order bias and hinge the model’s training. To alleviate this bias, we introduce a new “predict-and-assign” training paradigm that models the golden tuples as a set. Specifically, we utilize a set-matching strategy to find the optimal order of tuples. The experimental results on multiple benchmarks show that our unified generative model significantly outperforms the SOTA method, and ablation experiments prove the effectiveness of the set-matching strategy.</abstract>
      <url hash="ca18eadc">2023.findings-acl.775</url>
      <bibkey>yang-etal-2023-unicoqe</bibkey>
      <doi>10.18653/v1/2023.findings-acl.775</doi>
    </paper>
    <paper id="776">
      <title>Response-conditioned Turn-taking Prediction</title>
      <author><first>Bing’er</first><last>Jiang</last><affiliation>KTH</affiliation></author>
      <author><first>Erik</first><last>Ekstedt</last><affiliation>KTH Royal Institute of Technology</affiliation></author>
      <author><first>Gabriel</first><last>Skantze</last><affiliation>KTH Speech Music and Hearing</affiliation></author>
      <pages>12241-12248</pages>
      <abstract>Previous approaches to turn-taking and response generation in conversational systems have treated it as a two-stage process: First, the end of a turn is detected (based on conversation history), then the system generates an appropriate response. Humans, however, do not take the turn just because it is likely, but also consider whether what they want to say fits the position. In this paper, we present a model (an extension of TurnGPT) that conditions the end-of-turn prediction on both conversation history and what the next speaker wants to say. We found that our model consistently outperforms the baseline model in a variety of metrics. The improvement is most prominent in two scenarios where turn predictions can be ambiguous solely from the conversation history: 1) when the current utterance contains a statement followed by a question; 2) when the end of the current utterance semantically matches the response. Treating the turn-prediction and response-ranking as a one-stage process, our findings suggest that our model can be used as an incremental response ranker, which can be applied in various settings.</abstract>
      <url hash="e59055dd">2023.findings-acl.776</url>
      <bibkey>jiang-etal-2023-response</bibkey>
      <doi>10.18653/v1/2023.findings-acl.776</doi>
    </paper>
    <paper id="777">
      <title>A Unified One-Step Solution for Aspect Sentiment Quad Prediction</title>
      <author><first>Junxian</first><last>Zhou</last><affiliation>DataStory</affiliation></author>
      <author><first>Haiqin</first><last>Yang</last><affiliation>International Digital Economy Academy</affiliation></author>
      <author><first>Yuxuan</first><last>He</last><affiliation>Datastory</affiliation></author>
      <author><first>Hao</first><last>Mou</last><affiliation>DataStory</affiliation></author>
      <author><first>JunBo</first><last>Yang</last><affiliation>DataStory</affiliation></author>
      <pages>12249-12265</pages>
      <abstract>Aspect sentiment quad prediction (ASQP) is a challenging yet significant subtask in aspectbased sentiment analysis as it provides a complete aspect-level sentiment structure. However, existing ASQP datasets are usually small and low-density, hindering technical advancement. To expand the capacity, in this paper, we release two new datasets for ASQP, which contain the following characteristics: larger size, more words per sample, and higher density. With such datasets, we unveil the shortcomings of existing strong ASQP baselines and therefore propose a unified one-step solution for ASQP, namely One-ASQP, to detect the aspect categories and to identify the aspectopinion-sentiment (AOS) triplets simultaneously. Our One-ASQP holds several unique advantages: (1) by separating ASQP into two subtasks and solving them independently and simultaneously, we can avoid error propagation in pipeline-based methods and overcome slow training and inference in generation-based methods; (2) by introducing sentiment-specific horns tagging schema in a token-pair-based two-dimensional matrix, we can exploit deeper interactions between sentiment elements and efficiently decode the AOS triplets; (3) we design "[NULL]” token can help us effectively identify the implicit aspects or opinions. Experiments on two benchmark datasets and our released two datasets demonstrate the advantages of our One-ASQP. The two new datasets are publicly released at <url>https://www.github.com/Datastory-CN/ASQP-Datasets</url>.</abstract>
      <url hash="df36c066">2023.findings-acl.777</url>
      <bibkey>zhou-etal-2023-unified-one</bibkey>
      <doi>10.18653/v1/2023.findings-acl.777</doi>
    </paper>
    <paper id="778">
      <title>On Isotropy, Contextualization and Learning Dynamics of Contrastive-based Sentence Representation Learning</title>
      <author><first>Chenghao</first><last>Xiao</last><affiliation>Durham University</affiliation></author>
      <author><first>Yang</first><last>Long</last><affiliation>Durham University</affiliation></author>
      <author><first>Noura</first><last>Al Moubayed</last><affiliation>Durham University</affiliation></author>
      <pages>12266-12283</pages>
      <abstract>Incorporating contrastive learning objectives in sentence representation learning (SRL) has yielded significant improvements on many sentence-level NLP tasks. However, it is not well understood why contrastive learning works for learning sentence-level semantics. In this paper, we aim to help guide future designs of sentence representation learning methods by taking a closer look at contrastive SRL through the lens of isotropy, contextualization and learning dynamics. We interpret its successes through the geometry of the representation shifts and show that contrastive learning brings isotropy, and drives high intra-sentence similarity: when in the same sentence, tokens converge to similar positions in the semantic space. We also find that what we formalize as “spurious contextualization” is mitigated for semantically meaningful tokens, while augmented for functional ones. We find that the embedding space is directed towards the origin during training, with more areas now better defined. We ablate these findings by observing the learning dynamics with different training temperatures, batch sizes and pooling methods.</abstract>
      <url hash="92844fdb">2023.findings-acl.778</url>
      <bibkey>xiao-etal-2023-isotropy</bibkey>
      <doi>10.18653/v1/2023.findings-acl.778</doi>
    </paper>
    <paper id="779">
      <title>Few-shot Fine-tuning vs. In-context Learning: A Fair Comparison and Evaluation</title>
      <author><first>Marius</first><last>Mosbach</last><affiliation>Saarland University</affiliation></author>
      <author><first>Tiago</first><last>Pimentel</last><affiliation>University of Cambridge</affiliation></author>
      <author><first>Shauli</first><last>Ravfogel</last><affiliation>Bar Ilan University</affiliation></author>
      <author><first>Dietrich</first><last>Klakow</last><affiliation>Saarland University</affiliation></author>
      <author><first>Yanai</first><last>Elazar</last><affiliation>AI2, UW</affiliation></author>
      <pages>12284-12314</pages>
      <abstract>Few-shot fine-tuning and in-context learning are two alternative strategies for task adaptation of pre-trained language models. Recently, in-context learning has gained popularity over fine-tuning due to its simplicity and improved out-of-domain generalization, and because extensive evidence shows that fine-tuned models pick up on spurious correlations. Unfortunately, previous comparisons of the two approaches were done using models of different sizes. This raises the question of whether the observed weaker out-of-domain generalization of fine-tuned models is an inherent property of fine-tuning or a limitation of the experimental setup. In this paper, we compare the generalization of few-shot fine-tuning and in-context learning to challenge datasets, while controlling for the models used, the number of examples, and the number of parameters, ranging from 125M to 30B. Our results show that fine-tuned language models can in fact generalize well out-of-domain. We find that both approaches generalize similarly; they exhibit large variation and depend on properties such as model size and the number of examples, highlighting that robust task adaptation remains a challenge.</abstract>
      <url hash="75a39bfa">2023.findings-acl.779</url>
      <bibkey>mosbach-etal-2023-shot</bibkey>
      <doi>10.18653/v1/2023.findings-acl.779</doi>
    </paper>
    <paper id="780">
      <title>Common Law Annotations: Investigating the Stability of Dialog System Output Annotations</title>
      <author><first>Seunggun</first><last>Lee</last><affiliation>New York University</affiliation></author>
      <author><first>Alexandra</first><last>DeLucia</last><affiliation>Johns Hopkins University</affiliation></author>
      <author><first>Nikita</first><last>Nangia</last><affiliation>New York University</affiliation></author>
      <author><first>Praneeth</first><last>Ganedi</last><affiliation>New York University</affiliation></author>
      <author><first>Ryan</first><last>Guan</last><affiliation>University of Pennsylvania</affiliation></author>
      <author><first>Rubing</first><last>Li</last><affiliation>New York University</affiliation></author>
      <author><first>Britney</first><last>Ngaw</last><affiliation>New York University</affiliation></author>
      <author><first>Aditya</first><last>Singhal</last><affiliation>New York University</affiliation></author>
      <author><first>Shalaka</first><last>Vaidya</last><affiliation>NYU Courant</affiliation></author>
      <author><first>Zijun</first><last>Yuan</last><affiliation>New York University</affiliation></author>
      <author><first>Lining</first><last>Zhang</last><affiliation>New York University</affiliation></author>
      <author><first>João</first><last>Sedoc</last><affiliation>New York University</affiliation></author>
      <pages>12315-12349</pages>
      <abstract>Metrics for Inter-Annotator Agreement (IAA), like Cohen’s Kappa, are crucial for validating annotated datasets. Although high agreement is often used to show the reliability of annotation procedures, it is insufficient to ensure or reproducibility. While researchers are encouraged to increase annotator agreement, this can lead to specific and tailored annotation guidelines. We hypothesize that this may result in diverging annotations from different groups. To study this, we first propose the Lee et al. Protocol (LEAP), a standardized and codified annotation protocol. LEAP strictly enforces transparency in the annotation process, which ensures reproducibility of annotation guidelines. Using LEAP to annotate a dialog dataset, we empirically show that while research groups may create reliable guidelines by raising agreement, this can cause divergent annotations across different research groups, thus questioning the validity of the annotations. Therefore, we caution NLP researchers against using reliability as a proxy for reproducibility and validity.</abstract>
      <url hash="fb7a0d41">2023.findings-acl.780</url>
      <bibkey>lee-etal-2023-common</bibkey>
      <doi>10.18653/v1/2023.findings-acl.780</doi>
    </paper>
    <paper id="781">
      <title><fixed-case>H</fixed-case>ua<fixed-case>SLIM</fixed-case>: Human Attention Motivated Shortcut Learning Identification and Mitigation for Large Language models</title>
      <author><first>Yuqi</first><last>Ren</last><affiliation>Tianjin University</affiliation></author>
      <author><first>Deyi</first><last>Xiong</last><affiliation>Tianjin University</affiliation></author>
      <pages>12350-12365</pages>
      <abstract>Large language models have made remarkable progress on a variety of NLP tasks. However, it has been found that they tend to rely on shortcut features that spuriously correlate with labels for prediction, which weakens their generalization on out-of-distribution samples. In this paper, we propose a human attention guided approach to identifying and mitigating shortcut learning, which encourages the LLM-based target model to learn relevant features. We define an attention-based measurement to capture both model and data bias and identify shortcut tokens by exploring both human and neural attention. In a self-distillation framework, we mitigate shortcut learning by dynamically adjusting the distillation temperature according to the detected shortcut tokens and estimated shortcut degree. Additionally, we utilize human attention as a supervisory signal to constrain large language models to pay more attention to relevant tokens. Experimental results on multiple NLP tasks show that our proposed method can effectively identify shortcut tokens, and significantly improve the robustness of large language models on OOD samples, while not undermining the performance on IID data.</abstract>
      <url hash="3ab0bfaf">2023.findings-acl.781</url>
      <bibkey>ren-xiong-2023-huaslim</bibkey>
      <doi>10.18653/v1/2023.findings-acl.781</doi>
    </paper>
    <paper id="782">
      <title><fixed-case>PMI</fixed-case>-Align: Word Alignment With Point-Wise Mutual Information Without Requiring Parallel Training Data</title>
      <author><first>Fatemeh</first><last>Azadi</last><affiliation>University of Tehran</affiliation></author>
      <author><first>Heshaam</first><last>Faili</last><affiliation>University of Tehran</affiliation></author>
      <author><first>Mohammad Javad</first><last>Dousti</last><affiliation>University of Tehran</affiliation></author>
      <pages>12366-12377</pages>
      <abstract>Word alignment has many applications including cross-lingual annotation projection, bilingual lexicon extraction, and the evaluation or analysis of translation outputs. Recent studies show that using contextualized embeddings from pre-trained multilingual language models could give us high quality word alignments without the need of parallel training data. In this work, we propose PMI-Align which computes and uses the point-wise mutual information between source and target tokens to extract word alignments, instead of the cosine similarity or dot product which is mostly used in recent approaches. Our experiments show that our proposed PMI-Align approach could outperform the rival methods on five out of six language pairs. Although our approach requires no parallel training data, we show that this method could also benefit the approaches using parallel data to fine-tune pre-trained language models on word alignments. Our code and data are publicly available.</abstract>
      <url hash="9c470aa8">2023.findings-acl.782</url>
      <bibkey>azadi-etal-2023-pmi</bibkey>
      <doi>10.18653/v1/2023.findings-acl.782</doi>
    </paper>
    <paper id="783">
      <title>Exploring Non-Verbal Predicates in Semantic Role Labeling: Challenges and Opportunities</title>
      <author><first>Riccardo</first><last>Orlando</last><affiliation>Sapienza University of Rome</affiliation></author>
      <author><first>Simone</first><last>Conia</last><affiliation>Sapienza University of Rome</affiliation></author>
      <author><first>Roberto</first><last>Navigli</last><affiliation>Sapienza University of Rome</affiliation></author>
      <pages>12378-12388</pages>
      <abstract>Although we have witnessed impressive progress in Semantic Role Labeling (SRL), most of the research in the area is carried out assuming that the majority of predicates are verbs. Conversely, predicates can also be expressed using other parts of speech, e.g., nouns and adjectives. However, non-verbal predicates appear in the benchmarks we commonly use to measure progress in SRL less frequently than in some real-world settings – newspaper headlines, dialogues, and tweets, among others. In this paper, we put forward a new PropBank dataset which boasts wide coverage of multiple predicate types. Thanks to it, we demonstrate empirically that standard benchmarks do not provide an accurate picture of the current situation in SRL and that state-of-the-art systems are still incapable of transferring knowledge across different predicate types. Having observed these issues, we also present a novel, manually-annotated challenge set designed to give equal importance to verbal, nominal, and adjectival predicate-argument structures. We use such dataset to investigate whether we can leverage different linguistic resources to promote knowledge transfer. In conclusion, we claim that SRL is far from “solved”, and its integration with other semantic tasks might enable significant improvements in the future, especially for the long tail of non-verbal predicates, thereby facilitating further research on SRL for non-verbal predicates. We release our software and datasets at <url>https://github.com/sapienzanlp/exploring-srl</url>.</abstract>
      <url hash="662830f5">2023.findings-acl.783</url>
      <bibkey>orlando-etal-2023-exploring</bibkey>
      <doi>10.18653/v1/2023.findings-acl.783</doi>
    </paper>
    <paper id="784">
      <title><fixed-case>DSPM</fixed-case>-<fixed-case>NLG</fixed-case>: A Dual Supervised Pre-trained Model for Few-shot Natural Language Generation in Task-oriented Dialogue System</title>
      <author><first>Yufan</first><last>Wang</last><affiliation>Central China Normal University,National Engineering Research Center for E-Learning</affiliation></author>
      <author><first>Bowei</first><last>Zou</last><affiliation>Institute for Infocomm Research</affiliation></author>
      <author><first>Rui</first><last>Fan</last><affiliation>Faculty of Artificial Intelligence in Education, Central China Normal University</affiliation></author>
      <author><first>Ai Ti</first><last>Aw</last><affiliation>Institute for Infocomm Research</affiliation></author>
      <author><first>Tingting</first><last>He</last><affiliation>School of Computer, Central China Normal University</affiliation></author>
      <pages>12389-12402</pages>
      <abstract>In few-shot settings, fully conveying the semantic information of the dialogue act is a crucial challenge for Natural Language Generation (NLG) in the task-oriented dialogue system. An interesting fact is that NLG and Spoken Language Understanding (SLU) are a natural dual problem pair. Suppose the response generated by the NLG module can be restored to the corresponding dialogue act by the SLU module, which reflects that the generated response fully conveys the semantic information of the dialogue act. Based on this idea, a novel Dual Supervised Pre-trained Model for a few-shot Natural Language Generation (DSPM-NLG) is proposed to regularize the pre-training process. We adopt a joint model with a dual supervised framework to learn the dual correlation between NLG and SLU from the perspective of probability. In addition, a slot-masked strategy is designed to enable the model to focus better on the key slot-value pairs. DSPM-NLG is continuously trained on existing public large-scale annotated data, which thoroughly learns the duality between two tasks to enhance the semantically controlling and generalization abilities of the pre-trained model. Experiments demonstrate that our proposed model performs outstandingly on the few-shot benchmark dataset and outperforms the previous SOTA results.</abstract>
      <url hash="fa01e8c2">2023.findings-acl.784</url>
      <bibkey>wang-etal-2023-dspm</bibkey>
      <doi>10.18653/v1/2023.findings-acl.784</doi>
    </paper>
    <paper id="785">
      <title><fixed-case>TEP</fixed-case>rompt: Task Enlightenment Prompt Learning for Implicit Discourse Relation Recognition</title>
      <author><first>Wei</first><last>Xiang</last><affiliation>Huazhong University of Science and Technology (HUST)</affiliation></author>
      <author><first>Chao</first><last>Liang</last><affiliation>Huazhong University of Science and Technology(HUST)</affiliation></author>
      <author><first>Bang</first><last>Wang</last><affiliation>Huazhong University of Science and Technology (HUST)</affiliation></author>
      <pages>12403-12414</pages>
      <abstract>Implicit Discourse Relation Recognition (IDRR) aims at classifying the relation sense between two arguments without an explicit connective. Recently, the ConnPrompt (Xiang et al., 2022) has leveraged the powerful prompt learning for IDRR based on the fusion of multi-prompt decisions from three different yet much similar connective prediction templates. Instead of multi-prompt ensembling, we propose to design auxiliary tasks with enlightened prompt learning for the IDRR task. Although an auxiliary task is not used to directly output final prediction, we argue that during the joint training some of its learned features can be useful to boost the main task. In light of such motivations, we propose a task enlightenment prompt learning model, called TEPrompt, to fuse learned features from three related tasks for IDRR. In particular, the TEPrompt contains three tasks, viz., Discourse Relation Recognition (DRR), Sense Semantics Classification (SSC) and Annotated Connective Prediction (ACP), each with a unique prompt template and an answer space. In the training phase, we jointly train three prompt learning tasks with shared argument representation. In the testing phase, we only take the DRR output with fused features as the final IDRR decision. Experiments with the same conditions have shown that the proposed TEPrompt outperforms the ConnPrompt. This can be attributed to the promoted decision features and language models benefited from joint-training of auxiliary tasks.</abstract>
      <url hash="43fd58e7">2023.findings-acl.785</url>
      <bibkey>xiang-etal-2023-teprompt</bibkey>
      <doi>10.18653/v1/2023.findings-acl.785</doi>
    </paper>
    <paper id="786">
      <title>Evaluating Factuality in Cross-lingual Summarization</title>
      <author><first>Mingqi</first><last>Gao</last><affiliation>Peking University</affiliation></author>
      <author><first>Wenqing</first><last>Wang</last><affiliation>Beijing Foreign Studies University</affiliation></author>
      <author><first>Xiaojun</first><last>Wan</last><affiliation>Peking University</affiliation></author>
      <author><first>Yuemei</first><last>Xu</last><affiliation>School of Information Science and Technology, Beijing Foreign Studies University</affiliation></author>
      <pages>12415-12431</pages>
      <abstract>Cross-lingual summarization aims to help people efficiently grasp the core idea of the document written in a foreign language. Modern text summarization models generate highly fluent but often factually inconsistent outputs, which has received heightened attention in recent research. However, the factual consistency of cross-lingual summarization has not been investigated yet. In this paper, we propose a cross-lingual factuality dataset by collecting human annotations of reference summaries as well as generated summaries from models at both summary level and sentence level. Furthermore, we perform the fine-grained analysis and observe that over 50% of generated summaries and over 27% of reference summaries contain factual errors with characteristics different from monolingual summarization. Existing evaluation metrics for monolingual summarization require translation to evaluate the factuality of cross-lingual summarization and perform differently at different tasks and levels. Finally, we adapt the monolingual factuality metrics as an initial step towards the automatic evaluation of summarization factuality in cross-lingual settings. Our dataset and code are available at <url>https://github.com/kite99520/Fact_CLS</url>.</abstract>
      <url hash="e20df8ea">2023.findings-acl.786</url>
      <bibkey>gao-etal-2023-evaluating</bibkey>
      <doi>10.18653/v1/2023.findings-acl.786</doi>
    </paper>
    <paper id="787">
      <title>On the Correspondence between Compositionality and Imitation in Emergent Neural Communication</title>
      <author><first>Emily</first><last>Cheng</last><affiliation>Universitat de Pompeu Fabra</affiliation></author>
      <author><first>Mathieu</first><last>Rita</last><affiliation>INRIA</affiliation></author>
      <author><first>Thierry</first><last>Poibeau</last><affiliation>LATTICE (CNRS &amp; ENS/PSL)</affiliation></author>
      <pages>12432-12447</pages>
      <abstract>Compositionality is a hallmark of human language that not only enables linguistic generalization, but also potentially facilitates acquisition. When simulating language emergence with neural networks, compositionality has been shown to improve communication performance; however, its impact on imitation learning has yet to be investigated. Our work explores the link between compositionality and imitation in a Lewis game played by deep neural agents. Our contributions are twofold: first, we show that the learning algorithm used to imitate is crucial: supervised learning tends to produce more average languages, while reinforcement learning introduces a selection pressure toward more compositional languages. Second, our study reveals that compositional languages are easier to imitate, which may induce the pressure toward compositional languages in RL imitation settings.</abstract>
      <url hash="f6304ced">2023.findings-acl.787</url>
      <bibkey>cheng-etal-2023-correspondence</bibkey>
      <doi>10.18653/v1/2023.findings-acl.787</doi>
    </paper>
    <paper id="788">
      <title>The Coreference under Transformation Labeling Dataset: Entity Tracking in Procedural Texts Using Event Models</title>
      <author><first>Kyeongmin</first><last>Rim</last><affiliation>Department of Computer Science, Brandeis University</affiliation></author>
      <author><first>Jingxuan</first><last>Tu</last><affiliation>Brandeis University</affiliation></author>
      <author><first>Bingyang</first><last>Ye</last><affiliation>Brandeis University</affiliation></author>
      <author><first>Marc</first><last>Verhagen</last><affiliation>Brandeis University</affiliation></author>
      <author><first>Eben</first><last>Holderness</last><affiliation>Brandeis University</affiliation></author>
      <author><first>James</first><last>Pustejovsky</last><affiliation>Brandeis University</affiliation></author>
      <pages>12448-12460</pages>
      <abstract>We demonstrate that coreference resolution in procedural texts is significantly improved when performing transformation-based entity linking prior to coreference relation identification. When events in the text introduce changes to the state of participating entities, it is often impossible to accurately link entities in anaphoric and coreference relations without an understanding of the transformations those entities undergo. We show how adding event semantics helps to better model entity coreference. We argue that all transformation predicates, not just creation verbs, introduce a new entity into the discourse, as a kind of generalized Result Role, which is typically not textually mentioned. This allows us to model procedural texts as process graphs and to compute the coreference type for any two entities in the recipe. We present our annotation methodology and the corpus generated as well as describe experiments on coreference resolution of entity mentions under a process-oriented model of events.</abstract>
      <url hash="d5d0a684">2023.findings-acl.788</url>
      <bibkey>rim-etal-2023-coreference</bibkey>
      <doi>10.18653/v1/2023.findings-acl.788</doi>
    </paper>
    <paper id="789">
      <title>Why Does Zero-Shot Cross-Lingual Generation Fail? An Explanation and a Solution</title>
      <author><first>Tianjian</first><last>Li</last><affiliation>Johns Hopkins University</affiliation></author>
      <author><first>Kenton</first><last>Murray</last><affiliation>Johns Hopkins University</affiliation></author>
      <pages>12461-12476</pages>
      <abstract>Zero-shot cross-lingual transfer is when a multilingual model is trained to perform a task in one language and then is applied to another language. Although the zero-shot cross-lingual transfer approach has achieved success in various classification tasks, its performance on natural language generation tasks falls short in quality and sometimes outputs an incorrect language. In our study, we show that the fine-tuning process learns language invariant representations, which is beneficial for classification tasks but harmful for generation tasks. Motivated by this, we propose a simple method to regularize the model from learning language invariant representations and a method to select model checkpoints without a development set in the target language, both resulting in better generation quality. Experiments on three semantically diverse generation tasks show that our method reduces the accidental translation problem by 68% and improves the ROUGE-L score by 1.5 on average.</abstract>
      <url hash="9aa002b0">2023.findings-acl.789</url>
      <bibkey>li-murray-2023-zero</bibkey>
      <doi>10.18653/v1/2023.findings-acl.789</doi>
    </paper>
    <paper id="790">
      <title>Distractor Generation based on <fixed-case>T</fixed-case>ext2<fixed-case>T</fixed-case>ext Language Models with Pseudo <fixed-case>K</fixed-case>ullback-<fixed-case>L</fixed-case>eibler Divergence Regulation</title>
      <author><first>Hui-Juan</first><last>Wang</last><affiliation>NCHU</affiliation></author>
      <author><first>Kai-Yu</first><last>Hsieh</last><affiliation>NCHU</affiliation></author>
      <author><first>Han-Cheng</first><last>Yu</last><affiliation>NCHU</affiliation></author>
      <author><first>Jui-Ching</first><last>Tsou</last><affiliation>+886909883218</affiliation></author>
      <author><first>Yu An</first><last>Shih</last><affiliation>+886905128863</affiliation></author>
      <author><first>Chen-Hua</first><last>Huang</last><affiliation>winnie25814315@gmail.com</affiliation></author>
      <author><first>Yao-Chung</first><last>Fan</last><affiliation>National Chung Hsing University</affiliation></author>
      <pages>12477-12491</pages>
      <abstract>In this paper, we address the task of cloze-style multiple choice question (MCQs) distractor generation. Our study is featured by the following designs. First, we propose to formulate the cloze distractor generation as a Text2Text task. Second, we propose pseudo Kullback-Leibler Divergence for regulating the generation to consider the item discrimination index in education evaluation. Third, we explore the candidate augmentation strategy and multi-tasking training with cloze-related tasks to further boost the generation performance. Through experiments with benchmarking datasets, our best perfomring model advances the state-of-the-art result from 10.81 to 22.00 (p@1 score).</abstract>
      <url hash="b233e967">2023.findings-acl.790</url>
      <bibkey>wang-etal-2023-distractor</bibkey>
      <doi>10.18653/v1/2023.findings-acl.790</doi>
    </paper>
    <paper id="791">
      <title>Lexical Translation Inconsistency-Aware Document-Level Translation Repair</title>
      <author><first>Zhen</first><last>Zhang</last><affiliation>Soochow University</affiliation></author>
      <author><first>Junhui</first><last>Li</last><affiliation>Soochow University, Suzhou</affiliation></author>
      <author><first>Shimin</first><last>Tao</last><affiliation>huawei</affiliation></author>
      <author><first>Hao</first><last>Yang</last><affiliation>Huawei Co. Ltd</affiliation></author>
      <pages>12492-12505</pages>
      <abstract>Following the idea of “one translation per discourse”, in this paper we aim to improve translation consistency via document-level translation repair (DocRepair), i.e., automatic post-editing on translations of documents. To this end, we propose a lexical translation inconsistency-aware DocRepair to explicitly model translation inconsistency. First we locate the inconsistency in automatic translation. Then we provide translation candidates for those inconsistency. Finally, we propose lattice-like input to properly model inconsistent tokens and phrases and their candidates. Experimental results on three document-level translation datasets show that based on G-Transformer, a state-of-the-art document-to-document (Doc2Doc) translation model, our Doc2Doc DocRepair achieves significant improvement on translation quality in BLEU scores, but also greatly improves lexical translation consistency.</abstract>
      <url hash="d1ff6d8d">2023.findings-acl.791</url>
      <bibkey>zhang-etal-2023-lexical</bibkey>
      <doi>10.18653/v1/2023.findings-acl.791</doi>
    </paper>
    <paper id="792">
      <title><fixed-case>C</fixed-case>ausal<fixed-case>D</fixed-case>ialogue: Modeling Utterance-level Causality in Conversations</title>
      <author><first>Yi-Lin</first><last>Tuan</last><affiliation>University of California, Santa Barbara</affiliation></author>
      <author><first>Alon</first><last>Albalak</last><affiliation>University of California, Santa Barbara</affiliation></author>
      <author><first>Wenda</first><last>Xu</last><affiliation>University of California at Santa Barbara</affiliation></author>
      <author><first>Michael</first><last>Saxon</last><affiliation>University of California, Santa Barbara</affiliation></author>
      <author><first>Connor</first><last>Pryor</last><affiliation>University of California Santa Cruz</affiliation></author>
      <author><first>Lise</first><last>Getoor</last><affiliation>UC Santa Cruz</affiliation></author>
      <author><first>William Yang</first><last>Wang</last><affiliation>Unversity of California, Santa Barbara</affiliation></author>
      <pages>12506-12522</pages>
      <abstract>Despite their widespread adoption, neural conversation models have yet to exhibit natural chat capabilities with humans. In this research, we examine user utterances as causes and generated responses as effects, recognizing that changes in a cause should produce a different effect. To further explore this concept, we have compiled and expanded upon a new dataset called CausalDialogue through crowd-sourcing. This dataset includes multiple cause-effect pairs within a directed acyclic graph (DAG) structure. Our analysis reveals that traditional loss functions struggle to effectively incorporate the DAG structure, leading us to propose a causality-enhanced method called Exponential Maximum Average Treatment Effect (ExMATE) to enhance the impact of causality at the utterance level in training neural conversation models. To evaluate the needs of considering causality in dialogue generation, we built a comprehensive benchmark on CausalDialogue dataset using different models, inference, and training methods. Through experiments, we find that a causality-inspired loss like ExMATE can improve the diversity and agility of conventional loss function and there is still room for improvement to reach human-level quality on this new dataset.</abstract>
      <url hash="bd3753b5">2023.findings-acl.792</url>
      <bibkey>tuan-etal-2023-causaldialogue</bibkey>
      <doi>10.18653/v1/2023.findings-acl.792</doi>
    </paper>
    <paper id="793">
      <title>Towards Unified Spoken Language Understanding Decoding via Label-aware Compact Linguistics Representations</title>
      <author><first>Zhihong</first><last>Zhu</last><affiliation>Peking University</affiliation></author>
      <author><first>Xuxin</first><last>Cheng</last><affiliation>Peking University</affiliation></author>
      <author><first>Zhiqi</first><last>Huang</last><affiliation>Tencent AI Lab</affiliation></author>
      <author><first>Dongsheng</first><last>Chen</last><affiliation>Peking University</affiliation></author>
      <author><first>Yuexian</first><last>Zou</last><affiliation>Peking University</affiliation></author>
      <pages>12523-12531</pages>
      <abstract>Joint intent detection and slot filling models have shown promising success in recent years due to the high correlations between the two tasks. However, previous works independently decode the two tasks, which could result in misaligned predictions for both tasks. To address this shortcoming, we propose a novel method named Label-aware Compact Linguistics Representation (LCLR), which leverages label embeddings to jointly guide the decoding process. Concretely, LCLR projects both task-specific hidden states into a joint label latent space, where both task-specific hidden states could be concisely represented as linear combinations of label embeddings. Such feature decomposition of task-specific hidden states increases the representing power for the linguistics of utterance. Extensive experiments on two single- and multi-intent SLU benchmarks prove that LCLR can learn more discriminative label information than previous separate decoders, and consistently outperform previous state-of-the-art methods across all metrics. More encouragingly, LCLR can be applied to boost the performance of existing approaches, making it easy to be incorporated into any existing SLU models.</abstract>
      <url hash="d4533fa6">2023.findings-acl.793</url>
      <bibkey>zhu-etal-2023-towards</bibkey>
      <doi>10.18653/v1/2023.findings-acl.793</doi>
    </paper>
    <paper id="794">
      <title>Less Likely Brainstorming: Using Language Models to Generate Alternative Hypotheses</title>
      <author><first>Liyan</first><last>Tang</last><affiliation>University of Texas at Austin</affiliation></author>
      <author><first>Yifan</first><last>Peng</last><affiliation>Weill Cornell Medicine</affiliation></author>
      <author><first>Yanshan</first><last>Wang</last><affiliation>University of Pittsburgh</affiliation></author>
      <author><first>Ying</first><last>Ding</last><affiliation>University of Texas at Austin</affiliation></author>
      <author><first>Greg</first><last>Durrett</last><affiliation>UT Austin</affiliation></author>
      <author><first>Justin</first><last>Rousseau</last><affiliation>University of Texas at Austin</affiliation></author>
      <pages>12532-12555</pages>
      <abstract>A human decision-maker benefits the most from an AI assistant that corrects for their biases. For problems such as generating interpretation of a radiology report given findings, a system predicting only highly likely outcomes may be less useful, where such outcomes are already obvious to the user. To alleviate biases in human decision-making, it is worth considering a broad differential diagnosis, going beyond the most likely options. We introduce a new task, “less likely brainstorming,” that asks a model to generate outputs that humans think are relevant but less likely to happen. We explore the task in two settings: a brain MRI interpretation generation setting and an everyday commonsense reasoning setting. We found that a baseline approach of training with less likely hypotheses as targets generates outputs that humans evaluate as either likely or irrelevant nearly half of the time; standard MLE training is not effective. To tackle this problem, we propose a controlled text generation method that uses a novel contrastive learning strategy to encourage models to differentiate between generating likely and less likely outputs according to humans. We compare our method with several state-of-the-art controlled text generation models via automatic and human evaluations and show that our models’ capability of generating less likely outputs is improved.</abstract>
      <url hash="b315db8c">2023.findings-acl.794</url>
      <bibkey>tang-etal-2023-less</bibkey>
      <doi>10.18653/v1/2023.findings-acl.794</doi>
    </paper>
    <paper id="795">
      <title>Language Modeling with Latent Situations</title>
      <author><first>Belinda Z.</first><last>Li</last><affiliation>MIT</affiliation></author>
      <author><first>Maxwell</first><last>Nye</last><affiliation>MIT</affiliation></author>
      <author><first>Jacob</first><last>Andreas</last><affiliation>MIT</affiliation></author>
      <pages>12556-12571</pages>
      <abstract>Language models (LMs) often generate incoherent outputs: they refer to events and entity states that are incompatible with the state of the world described in inputs. We introduce SITUATIONSUPERVISION, a family of approaches for improving coherence in LMs by training them to construct and condition on explicit representations of entities and their states. SITUATIONSUPERVISION has two components: an *auxiliary situation modeling* task that trains models to predict entity state representations in context, and a *latent state inference* procedure that imputes these states from partially annotated training data. SITUATIONSUPERVISION can be applied via fine-tuning (by supervising LMs to encode state variables in their hidden representations) and prompting (by inducing LMs to interleave textual descriptions of entity states with output text). In both cases, it requires only a small number of state annotations to produce substantial coherence improvements (up to an 16% reduction in errors), showing that standard LMs can be efficiently adapted to explicitly model language and aspects of its meaning.</abstract>
      <url hash="87afa411">2023.findings-acl.795</url>
      <bibkey>li-etal-2023-language-modeling</bibkey>
      <doi>10.18653/v1/2023.findings-acl.795</doi>
    </paper>
    <paper id="796">
      <title>Can Cross-Lingual Transferability of Multilingual Transformers Be Activated Without End-Task Data?</title>
      <author><first>Zewen</first><last>Chi</last><affiliation>Beijing Institute of Technology</affiliation></author>
      <author><first>Heyan</first><last>Huang</last><affiliation>Beijing Institute of Technology</affiliation></author>
      <author><first>Xian-Ling</first><last>Mao</last><affiliation>Beijing Institute of Technology</affiliation></author>
      <pages>12572-12584</pages>
      <abstract>Pretrained multilingual Transformers have achieved great success in cross-lingual transfer learning. Current methods typically activate the cross-lingual transferability of multilingual Transformers by fine-tuning them on end-task data. However, the methods cannot perform cross-lingual transfer when end-task data are unavailable. In this work, we explore whether the cross-lingual transferability can be activated without end-task data. We propose a cross-lingual transfer method, named PlugIn-X. PlugIn-X disassembles monolingual and multilingual Transformers into sub-modules, and reassembles them to be the multilingual end-task model. After representation adaptation, PlugIn-X finally performs cross-lingual transfer in a plug-and-play style. Experimental results show that PlugIn-X successfully activates the cross-lingual transferability of multilingual Transformers without accessing end-task data. Moreover, we analyze how the cross-model representation alignment affects the cross-lingual transferability.</abstract>
      <url hash="247823c1">2023.findings-acl.796</url>
      <bibkey>chi-etal-2023-cross</bibkey>
      <doi>10.18653/v1/2023.findings-acl.796</doi>
    </paper>
    <paper id="797">
      <title>Focus-aware Response Generation in Inquiry Conversation</title>
      <author><first>Yiquan</first><last>Wu</last><affiliation>Zhejiang University</affiliation></author>
      <author><first>Weiming</first><last>Lu</last><affiliation>Zhejiang University</affiliation></author>
      <author><first>Yating</first><last>Zhang</last><affiliation>Alibaba Group</affiliation></author>
      <author><first>Adam</first><last>Jatowt</last><affiliation>University of Innsbruck</affiliation></author>
      <author><first>Jun</first><last>Feng</last><affiliation>State Grid</affiliation></author>
      <author><first>Changlong</first><last>Sun</last><affiliation>Alibaba</affiliation></author>
      <author><first>Fei</first><last>Wu</last><affiliation>Zhejiang University</affiliation></author>
      <author><first>Kun</first><last>Kuang</last><affiliation>Zhejiang University</affiliation></author>
      <pages>12585-12599</pages>
      <abstract>Inquiry conversation is a common form of conversation that aims to complete the investigation (e.g., court hearing, medical consultation and police interrogation) during which a series of focus shifts occurs. While many models have been proposed to generate a smooth response to a given conversation history, neglecting the focus can limit performance in inquiry conversation where the order of the focuses plays there a key role. In this paper, we investigate the problem of response generation in inquiry conversation by taking the focus into consideration. We propose a novel Focus-aware Response Generation (FRG) method by jointly optimizing a multi-level encoder and a set of focal decoders to generate several candidate responses that correspond to different focuses. Additionally, a focus ranking module is proposed to predict the next focus and rank the candidate responses. Experiments on two orthogonal inquiry conversation datasets (judicial, medical domain) demonstrate that our method generates results significantly better in automatic metrics and human evaluation compared to the state-of-the-art approaches.</abstract>
      <url hash="7fd13303">2023.findings-acl.797</url>
      <bibkey>wu-etal-2023-focus</bibkey>
      <doi>10.18653/v1/2023.findings-acl.797</doi>
    </paper>
    <paper id="798">
      <title>A Hierarchical Explanation Generation Method Based on Feature Interaction Detection</title>
      <author><first>Yiming</first><last>Ju</last><affiliation>Institute of Automation, Chinese Academy of Sciences</affiliation></author>
      <author><first>Yuanzhe</first><last>Zhang</last><affiliation>Institute of Automation, Chinese Academy of Sciences</affiliation></author>
      <author><first>Kang</first><last>Liu</last><affiliation>Institute of Automation, Chinese Academy of Sciences</affiliation></author>
      <author><first>Jun</first><last>Zhao</last><affiliation>Chinese Academy of Sciences</affiliation></author>
      <pages>12600-12611</pages>
      <abstract>The opaqueness of deep NLP models has motivated efforts to explain how deep models predict. Recently, work has introduced hierarchical attribution explanations, which calculate attribution scores for compositional text hierarchically to capture compositional semantics. Existing work on hierarchical attributions tends to limit the text groups to a continuous text span, which we call the connecting rule. While easy for humans to read, limiting the attribution unit to a continuous span might lose important long-distance feature interactions for reflecting model predictions. In this work, we introduce a novel strategy for capturing feature interactions and employ it to build hierarchical explanations without the connecting rule. The proposed method can convert ubiquitous non-hierarchical explanations (e.g., LIME) into their corresponding hierarchical versions. Experimental results show the effectiveness of our approach in building high-quality hierarchical explanations.</abstract>
      <url hash="452bc02b">2023.findings-acl.798</url>
      <bibkey>ju-etal-2023-hierarchical</bibkey>
      <doi>10.18653/v1/2023.findings-acl.798</doi>
    </paper>
    <paper id="799">
      <title>Jointly Reparametrized Multi-Layer Adaptation for Efficient and Private Tuning</title>
      <author><first>Umang</first><last>Gupta</last><affiliation>University of Southern California</affiliation></author>
      <author><first>Aram</first><last>Galstyan</last><affiliation>USC Information Sciences Institute</affiliation></author>
      <author><first>Greg</first><last>Ver Steeg</last><affiliation>University of California Riverside</affiliation></author>
      <pages>12612-12629</pages>
      <abstract>Efficient finetuning of pretrained language transformers is becoming increasingly prevalent for solving natural language processing tasks. While effective, it can still require a large number of tunable parameters. This can be a drawback for low-resource applications and training with differential-privacy constraints, where excessive noise may be introduced during finetuning. To this end, we propose a novel language transformer finetuning strategy that introduces task-specific parameters in multiple transformer layers. These parameters are derived from fixed random projections of a single trainable vector, enabling finetuning with significantly fewer parameters while maintaining performance. We achieve within 5% of full finetuning performance on GLUE tasks with as few as 4,100 parameters per task, outperforming other parameter-efficient finetuning approaches that use a similar number of per-task parameters. Besides, the random projections can be precomputed at inference, avoiding additional computational latency. All these make our method particularly appealing for low-resource applications. Finally, our method achieves the best or comparable utility compared to several recent finetuning methods when training with the same privacy constraints, underscoring its effectiveness and potential real-world impact.</abstract>
      <url hash="55ce4ec4">2023.findings-acl.799</url>
      <bibkey>gupta-etal-2023-jointly</bibkey>
      <doi>10.18653/v1/2023.findings-acl.799</doi>
    </paper>
    <paper id="800">
      <title>A Diffusion Model for Event Skeleton Generation</title>
      <author><first>Fangqi</first><last>Zhu</last><affiliation>Harbin Institute of Technology (Shenzhen)</affiliation></author>
      <author><first>Lin</first><last>Zhang</last><affiliation>International Digital Economy Academy</affiliation></author>
      <author><first>Jun</first><last>Gao</last><affiliation>Harbin Institute of Technology, Shenzhen</affiliation></author>
      <author><first>Bing</first><last>Qin</last><affiliation>Harbin Institute of Technology</affiliation></author>
      <author><first>Ruifeng</first><last>Xu</last><affiliation>Harbin Institute of Technology, Shenzhen</affiliation></author>
      <author><first>Haiqin</first><last>Yang</last><affiliation>International Digital Economy Academy</affiliation></author>
      <pages>12630-12641</pages>
      <abstract>Event skeleton generation, aiming to induce an event schema skeleton graph with abstracted event nodes and their temporal relations from a set of event instance graphs, is a critical step in the temporal complex event schema induction task. Existing methods effectively address this task from a graph generation perspective but suffer from noise-sensitive and error accumulation, e.g., the inability to correct errors while generating schema. We, therefore, propose a novel Diffusion Event Graph Model (DEGM) to address these issues. Our DEGM is the first workable diffusion model for event skeleton generation, where the embedding and rounding techniques with a custom edge-based loss are introduced to transform a discrete event graph into learnable latent representations. Furthermore, we propose a denoising training process to maintain the model’s robustness. Consequently, DEGM derives the final schema, where error correction is guaranteed by iteratively refining the latent representations during the schema generation process. Experimental results on three IED bombing datasets demonstrate that our DEGM achieves better results than other state-of-the-art baselines. Our code and data are available at <url>https://github.com/zhufq00/EventSkeletonGeneration</url>.</abstract>
      <url hash="ed347a46">2023.findings-acl.800</url>
      <bibkey>zhu-etal-2023-diffusion</bibkey>
      <doi>10.18653/v1/2023.findings-acl.800</doi>
    </paper>
    <paper id="801">
      <title>Nonparametric Decoding for Generative Retrieval</title>
      <author><first>Hyunji</first><last>Lee</last><affiliation>Korea Advanced Institute of Science and Technology</affiliation></author>
      <author><first>JaeYoung</first><last>Kim</last><affiliation>Kakao</affiliation></author>
      <author><first>Hoyeon</first><last>Chang</last><affiliation>KAIST</affiliation></author>
      <author><first>Hanseok</first><last>Oh</last><affiliation>Korea Advanced Institute of Science and Technology</affiliation></author>
      <author><first>Sohee</first><last>Yang</last><affiliation>Graduate School of AI, KAIST</affiliation></author>
      <author><first>Vladimir</first><last>Karpukhin</last><affiliation>Forethought Technologies</affiliation></author>
      <author><first>Yi</first><last>Lu</last><affiliation>Forethought AI</affiliation></author>
      <author><first>Minjoon</first><last>Seo</last><affiliation>KAIST</affiliation></author>
      <pages>12642-12661</pages>
      <abstract>The generative retrieval model depends solely on the information encoded in its model parameters without external memory, its information capacity is limited and fixed. To overcome the limitation, we propose Nonparametric Decoding (Np Decoding) which can be applied to existing generative retrieval models. Np Decoding uses nonparametric contextualized vocab embeddings (external memory) rather than vanilla vocab embeddings as decoder vocab embeddings. By leveraging the contextualized vocab embeddings, the generative retrieval model is able to utilize both the parametric and nonparametric space. Evaluation over 9 datasets (8 single-hop and 1 multi-hop) in the document retrieval task shows that applying Np Decoding to generative retrieval models significantly improves the performance. We also show that Np Decoding is data- and parameter-efficient, and shows high performance in the zero-shot setting.</abstract>
      <url hash="42167790">2023.findings-acl.801</url>
      <bibkey>lee-etal-2023-nonparametric</bibkey>
      <doi>10.18653/v1/2023.findings-acl.801</doi>
    </paper>
    <paper id="802">
      <title>Aspect-aware Unsupervised Extractive Opinion Summarization</title>
      <author><first>Haoyuan</first><last>Li</last><affiliation>University of North Carolina at Chapel Hill</affiliation></author>
      <author><first>Somnath</first><last>Basu Roy Chowdhury</last><affiliation>University of North Carolina at Chapel Hill</affiliation></author>
      <author><first>Snigdha</first><last>Chaturvedi</last><affiliation>University of North Carolina, Chapel Hill</affiliation></author>
      <pages>12662-12678</pages>
      <abstract>Extractive opinion summarization extracts sentences from users’ reviews to represent the prevalent opinions about a product or service. However, the extracted sentences can be redundant and may miss some important aspects, especially for centroid-based extractive summarization models (Radev et al., 2004). To alleviate these issues, we introduce TokenCluster– a method for unsupervised extractive opinion summarization that automatically identifies the aspects described in the review sentences and then extracts sentences based on their aspects. It identifies the underlying aspects of the review sentences using roots of noun phrases and adjectives appearing in them. Empirical evaluation shows that TokenCluster improves aspect coverage in summaries and achieves strong performance on multiple opinion summarization datasets, for both general and aspect-specific summarization. We also perform extensive ablation and human evaluation studies to validate the design choices of our method. The implementation of our work is available at <url>https://github.com/leehaoyuan/TokenCluster</url></abstract>
      <url hash="7bfe02b6">2023.findings-acl.802</url>
      <bibkey>li-etal-2023-aspect</bibkey>
      <doi>10.18653/v1/2023.findings-acl.802</doi>
    </paper>
    <paper id="803">
      <title><fixed-case>GNN</fixed-case>-<fixed-case>SL</fixed-case>: Sequence Labeling Based on Nearest Examples via <fixed-case>GNN</fixed-case></title>
      <author><first>Shuhe</first><last>Wang</last><affiliation>Peking University</affiliation></author>
      <author><first>Yuxian</first><last>Meng</last><affiliation>Shannon.AI</affiliation></author>
      <author><first>Rongbin</first><last>Ouyang</last><affiliation>Peking University</affiliation></author>
      <author><first>Jiwei</first><last>Li</last><affiliation>Shannon.AI</affiliation></author>
      <author><first>Tianwei</first><last>Zhang</last><affiliation>Nanyang Technological University</affiliation></author>
      <author><first>Lingjuan</first><last>Lyu</last><affiliation>Sony AI</affiliation></author>
      <author><first>Guoyin</first><last>Wang</last><affiliation>Amazon Search Science and AI</affiliation></author>
      <pages>12679-12692</pages>
      <abstract>To better handle long-tail cases in the sequence labeling (SL) task, in this work, we introduce graph neural networks sequence labeling (GNN-SL), which augments the vanilla SL model output with similar tagging examples retrieved from the whole training set. Since not all the retrieved tagging examples benefit the model prediction, we construct a heterogeneous graph, and leverage graph neural networks (GNNs) to transfer information between the retrieved tagging examples and the input word sequence. The augmented node which aggregates information from neighbors is used to do prediction. This strategy enables the model to directly acquire similar tagging examples and improves the general quality of predictions. We conduct a variety of experiments on three typical sequence labeling tasks: Named Entity Recognition (NER), Part of Speech Tagging (POS), and Chinese Word Segmentation (CWS) to show the significant performance of our GNN-SL. Notably, GNN-SL achieves SOTA results of 96.9 (+0.2) on PKU, 98.3 (+0.4) on CITYU, 98.5 (+0.2) on MSR, and 96.9 (+0.2) on AS for the CWS task, and resultscomparable to SOTA performances on NER datasets, and POS datasets.</abstract>
      <url hash="f024f94b">2023.findings-acl.803</url>
      <bibkey>wang-etal-2023-gnn</bibkey>
      <doi>10.18653/v1/2023.findings-acl.803</doi>
    </paper>
    <paper id="804">
      <title>Serial Contrastive Knowledge Distillation for Continual Few-shot Relation Extraction</title>
      <author><first>Xinyi</first><last>Wang</last><affiliation>Nanjing University</affiliation></author>
      <author><first>Zitao</first><last>Wang</last><affiliation>Nanjing University</affiliation></author>
      <author><first>Wei</first><last>Hu</last><affiliation>Nanjing University</affiliation></author>
      <pages>12693-12706</pages>
      <abstract>Continual few-shot relation extraction (RE) aims to continuously train a model for new relations with few labeled training data, of which the major challenges are the catastrophic forgetting of old relations and the overfitting caused by data sparsity. In this paper, we propose a new model, namely SCKD, to accomplish the continual few-shot RE task. Specifically, we design serial knowledge distillation to preserve the prior knowledge from previous models and conduct contrastive learning with pseudo samples to keep the representations of samples in different relations sufficiently distinguishable. Our experiments on two benchmark datasets validate the effectiveness of SCKD for continual few-shot RE and its superiority in knowledge transfer and memory utilization over state-of-the-art models.</abstract>
      <url hash="08e16d34">2023.findings-acl.804</url>
      <bibkey>wang-etal-2023-serial</bibkey>
      <doi>10.18653/v1/2023.findings-acl.804</doi>
    </paper>
    <paper id="805">
      <title>Revisiting the Architectures like Pointer Networks to Efficiently Improve the Next Word Distribution, Summarization Factuality, and Beyond</title>
      <author><first>Haw-Shiuan</first><last>Chang</last><affiliation>Amazon.com</affiliation></author>
      <author><first>Zonghai</first><last>Yao</last><affiliation>University of Massachusetts Amherst</affiliation></author>
      <author><first>Alolika</first><last>Gon</last><affiliation>Fidelity Investments</affiliation></author>
      <author><first>Hong</first><last>Yu</last><affiliation>University of Massachusetts, Lowell</affiliation></author>
      <author><first>Andrew</first><last>McCallum</last><affiliation>UMass Amherst</affiliation></author>
      <pages>12707-12730</pages>
      <abstract>Is the output softmax layer, which is adopted by most language models (LMs), always the best way to compute the next word probability? Given so many attention layers in a modern transformer-based LM, are the pointer networks redundant nowadays? In this study, we discover that the answers to both questions are no. This is because the softmax bottleneck sometimes prevents the LMs from predicting the desired distribution and the pointer networks can be used to break the bottleneck efficiently. Based on the finding, we propose several softmax alternatives by simplifying the pointer networks and accelerating the word-by-word rerankers. In GPT-2, our proposals are significantly better and more efficient than mixture of softmax, a state-of-the-art softmax alternative. In summarization experiments, without very significantly decreasing its training/testing speed, our best method based on T5-Small improves factCC score by 2 points in CNN/DM and XSUM dataset, and improves MAUVE scores by 30% in BookSum paragraph-level dataset.</abstract>
      <url hash="d584715f">2023.findings-acl.805</url>
      <bibkey>chang-etal-2023-revisiting-architectures</bibkey>
      <doi>10.18653/v1/2023.findings-acl.805</doi>
    </paper>
    <paper id="806">
      <title><fixed-case>GLUE</fixed-case>-<fixed-case>X</fixed-case>: Evaluating Natural Language Understanding Models from an Out-of-Distribution Generalization Perspective</title>
      <author><first>Linyi</first><last>Yang</last><affiliation>Westlake University</affiliation></author>
      <author><first>Shuibai</first><last>Zhang</last><affiliation>Singapore University of Technology and Design</affiliation></author>
      <author><first>Libo</first><last>Qin</last><affiliation>Harbin Institute of Technology</affiliation></author>
      <author><first>Yafu</first><last>Li</last><affiliation>Westlake University</affiliation></author>
      <author><first>Yidong</first><last>Wang</last><affiliation>Tokyo Institute of Technology</affiliation></author>
      <author><first>Hanmeng</first><last>Liu</last><affiliation>Zhejiang University</affiliation></author>
      <author><first>Jindong</first><last>Wang</last><affiliation>Microsoft Research</affiliation></author>
      <author><first>Xing</first><last>Xie</last><affiliation>Microsoft Research Asia</affiliation></author>
      <author><first>Yue</first><last>Zhang</last><affiliation>Westlake University</affiliation></author>
      <pages>12731-12750</pages>
      <abstract>Pre-trained language models (PLMs) are known to improve the generalization performance of natural language understanding models by leveraging large amounts of data during the pre-training phase. However, the out-of-distribution (OOD) generalization problem remains a challenge in many NLP tasks, limiting the real-world deployment of these methods. This paper presents the first attempt at creating a unified benchmark named GLUE-X for evaluating OOD robustness in NLP models, highlighting the importance of OOD robustness and providing insights on how to measure the robustness of a model and how to improve it. The benchmark includes 13 publicly available datasets for OOD testing, and evaluations are conducted on 8 classic NLP tasks over 21 popularly used PLMs. Our findings confirm the need for improved OOD accuracy in NLP tasks, as significant performance degradation was observed in all settings compared to in-distribution (ID) accuracy.</abstract>
      <url hash="46eb1cdc">2023.findings-acl.806</url>
      <bibkey>yang-etal-2023-glue</bibkey>
      <doi>10.18653/v1/2023.findings-acl.806</doi>
    </paper>
    <paper id="807">
      <title>Investigating the Saliency of Sentiment Expressions in Aspect-Based Sentiment Analysis</title>
      <author><first>Joachim</first><last>Wagner</last><affiliation>ADAPT Centre, Dublin City University</affiliation></author>
      <author><first>Jennifer</first><last>Foster</last><affiliation>Dublin City University</affiliation></author>
      <pages>12751-12769</pages>
      <abstract>We examine the behaviour of an aspect-based sentiment classifier built by fine-tuning the BERT BASE model on the SemEval 2016 English dataset. In a set of masking experiments, we examine the extent to which the tokens identified as salient by LIME and a gradient-based method are being used by the classifier. We find that both methods are able to produce faithful rationales, with LIME outperforming the gradient-based method. We also identify a set of manually annotated sentiment expressions for this dataset, and carry out more masking experiments with these as human rationales. The enhanced performance of a classifier that only sees the relevant sentiment expressions suggests that they are not being used to their full potential. A comparison of the LIME and gradient rationales with the sentiment expressions reveals only a moderate level of agreement. Some disagreements are related to the fixed length of the rationales and the tendency of the rationales to contain content words related to the aspect itself.</abstract>
      <url hash="8987e55e">2023.findings-acl.807</url>
      <bibkey>wagner-foster-2023-investigating</bibkey>
      <doi>10.18653/v1/2023.findings-acl.807</doi>
    </paper>
    <paper id="808">
      <title><fixed-case>DMLM</fixed-case>: Descriptive Masked Language Modeling</title>
      <author><first>Edoardo</first><last>Barba</last><affiliation>Sapienza University of Rome</affiliation></author>
      <author><first>Niccolò</first><last>Campolungo</last><affiliation>La Sapienza University</affiliation></author>
      <author><first>Roberto</first><last>Navigli</last><affiliation>Sapienza University of Rome</affiliation></author>
      <pages>12770-12788</pages>
      <abstract>Over the last few years, Masked Language Modeling (MLM) pre-training has resulted in remarkable advancements in many Natural Language Understanding (NLU) tasks, which sparked an interest in researching alternatives and extensions to the MLM objective. In this paper, we tackle the absence of explicit semantic grounding in MLM and propose Descriptive Masked Language Modeling (DMLM), a knowledge-enhanced reading comprehension objective, where the model is required to predict the most likely word in a context, being provided with the word’s definition. For instance, given the sentence “I was going to the _”, if we provided as definition “financial institution”, the model would have to predict the word “bank”; if, instead, we provided “sandy seashore”, the model should predict “beach”. Our evaluation highlights the effectiveness of DMLM in comparison with standard MLM, showing improvements on a number of well-established NLU benchmarks, as well as other semantics-focused tasks, e.g., Semantic Role Labeling. Furthermore, we demonstrate how it is possible to take full advantage of DMLM to embed explicit semantics in downstream tasks, explore several properties of DMLM-based contextual representations and suggest a number of future directions to investigate.</abstract>
      <url hash="a2ff64a6">2023.findings-acl.808</url>
      <bibkey>barba-etal-2023-dmlm</bibkey>
      <doi>10.18653/v1/2023.findings-acl.808</doi>
    </paper>
    <paper id="809">
      <title>Reproducibility in <fixed-case>NLP</fixed-case>: What Have We Learned from the Checklist?</title>
      <author><first>Ian</first><last>Magnusson</last><affiliation>Allen Institute for AI</affiliation></author>
      <author><first>Noah A.</first><last>Smith</last><affiliation>University of Washington</affiliation></author>
      <author><first>Jesse</first><last>Dodge</last><affiliation>Allen Institute for AI</affiliation></author>
      <pages>12789-12811</pages>
      <abstract>Scientific progress in NLP rests on the reproducibility of researchers’ claims. The *CL conferences created the NLP Reproducibility Checklist in 2020 to be completed by authors at submission to remind them of key information to include. We provide the first analysis of the Checklist by examining 10,405 anonymous responses to it. First, we find evidence of an increase in reporting of information on efficiency, validation performance, summary statistics, and hyperparameters after the Checklist’s introduction. Further, we show acceptance rate grows for submissions with more Yes responses. We find that the 44% of submissions that gather new data are 5% less likely to be accepted than those that did not; the average reviewer-rated reproducibility of these submissions is also 2% lower relative to the rest. We find that only 46% of submissions claim to open-source their code, though submissions that do have 8% higher reproducibility score relative to those that do not, the most for any item. We discuss what can be inferred about the state of reproducibility in NLP, and provide a set of recommendations for future conferences, including: a) allowing submitting code and appendices one week after the deadline, and b) measuring dataset reproducibility by a checklist of data collection practices.</abstract>
      <url hash="7fa73b71">2023.findings-acl.809</url>
      <bibkey>magnusson-etal-2023-reproducibility</bibkey>
      <doi>10.18653/v1/2023.findings-acl.809</doi>
    </paper>
    <paper id="810">
      <title>Domain Generalization via Switch Knowledge Distillation for Robust Review Representation</title>
      <author><first>You</first><last>Zhang</last><affiliation>Yunnan University</affiliation></author>
      <author><first>Jin</first><last>Wang</last><affiliation>Yunnan University</affiliation></author>
      <author><first>Liang-Chih</first><last>Yu</last><affiliation>Yuan Ze University</affiliation></author>
      <author><first>Dan</first><last>Xu</last><affiliation>Yunnan University</affiliation></author>
      <author><first>Xuejie</first><last>Zhang</last><affiliation>Yunnan University</affiliation></author>
      <pages>12812-12826</pages>
      <abstract>Applying neural models injected with in-domain user and product information to learn review representations of unseen or anonymous users incurs an obvious obstacle in content-based recommender systems. For the generalization of the in-domain classifier, most existing models train an extra plain-text model for the unseen domain. Without incorporating historical user and product information, such a schema makes unseen and anonymous users dissociate from the recommender system. To simultaneously learn the review representation of both existing and unseen users, this study proposed a switch knowledge distillation for domain generalization. A generalization-switch (GSwitch) model was initially applied to inject user and product information by flexibly encoding both domain-invariant and domain-specific features. By turning the status ON or OFF, the model introduced a switch knowledge distillation to learn a robust review representation that performed well for either existing or anonymous unseen users. The empirical experiments were conducted on IMDB, Yelp-2013, and Yelp-2014 by masking out users in test data as unseen and anonymous users. The comparative results indicate that the proposed method enhances the generalization capability of several existing baseline models. For reproducibility, the code for this paper is available at: <url>https://github.com/yoyo-yun/DG_RRR</url>.</abstract>
      <url hash="d21b56d7">2023.findings-acl.810</url>
      <bibkey>zhang-etal-2023-domain</bibkey>
      <doi>10.18653/v1/2023.findings-acl.810</doi>
    </paper>
    <paper id="811">
      <title>On Search Strategies for Document-Level Neural Machine Translation</title>
      <author><first>Christian</first><last>Herold</last><affiliation>RWTH Aachen University</affiliation></author>
      <author><first>Hermann</first><last>Ney</last><affiliation>RWTH Aachen University</affiliation></author>
      <pages>12827-12836</pages>
      <abstract>Compared to sentence-level systems, document-level neural machine translation (NMT) models produce a more consistent output across a document and are able to better resolve ambiguities within the input. There are many works on document-level NMT, mostly focusing on modifying the model architecture or training strategy to better accommodate the additional context-input. On the other hand, in most works, the question on how to perform search with the trained model is scarcely discussed, sometimes not mentioned at all. In this work, we aim to answer the question how to best utilize a context-aware translation model in decoding. We start with the most popular document-level NMT approach and compare different decoding schemes, some from the literature and others proposed by us. In the comparison, we are using both, standard automatic metrics, as well as specific linguistic phenomena on three standard document-level translation benchmarks. We find that most commonly used decoding strategies perform similar to each other and that higher quality context information has the potential to further improve the translation.</abstract>
      <url hash="d104aefa">2023.findings-acl.811</url>
      <bibkey>herold-ney-2023-search</bibkey>
      <doi>10.18653/v1/2023.findings-acl.811</doi>
    </paper>
    <paper id="812">
      <title>Causal Intervention for Mitigating Name Bias in Machine Reading Comprehension</title>
      <author><first>Jiazheng</first><last>Zhu</last><affiliation>Tianjin University</affiliation></author>
      <author><first>Shaojuan</first><last>Wu</last><affiliation>Tianjin university</affiliation></author>
      <author><first>Xiaowang</first><last>Zhang</last><affiliation>Tianjin University</affiliation></author>
      <author><first>Yuexian</first><last>Hou</last><affiliation>Tianjin University</affiliation></author>
      <author><first>Zhiyong</first><last>Feng</last><affiliation>Tianjin university</affiliation></author>
      <pages>12837-12852</pages>
      <abstract>Machine Reading Comprehension (MRC) is to answer questions based on a given passage, which has made great achievements using pre-trained Language Models (LMs). We study the robustness of MRC models to names which is flexible and repeatability. MRC models based on LMs may overuse the name information to make predictions, which causes the representation of names to be non-interchangeable, called name bias. In this paper, we propose a novel Causal Interventional paradigm for MRC (CI4MRC) to mitigate name bias. Specifically, we uncover that the pre-trained knowledge concerning names is indeed a confounder by analyzing the causalities among the pre-trained knowledge, context representation and answers based on a Structural Causal Model (SCM). We develop effective CI4MRC algorithmic implementations to constrain the confounder based on the neuron-wise and token-wise adjustments. Experiments demonstrate that our proposed CI4MRC effectively mitigates the name bias and achieves competitive performance on the original SQuAD. Moreover, our method is general to various pre-trained LMs and performs robustly on the adversarial datasets.</abstract>
      <url hash="e881ccbe">2023.findings-acl.812</url>
      <bibkey>zhu-etal-2023-causal</bibkey>
      <doi>10.18653/v1/2023.findings-acl.812</doi>
    </paper>
    <paper id="813">
      <title>Counterfactual Probing for the Influence of Affect and Specificity on Intergroup Bias</title>
      <author><first>Venkata Subrahmanyan</first><last>Govindarajan</last><affiliation>University of Texas at Austin</affiliation></author>
      <author><first>David</first><last>Beaver</last><affiliation>UT Austin</affiliation></author>
      <author><first>Kyle</first><last>Mahowald</last><affiliation>University of Texas at Austin</affiliation></author>
      <author><first>Junyi Jessy</first><last>Li</last><affiliation>University of Texas at Austin</affiliation></author>
      <pages>12853-12862</pages>
      <abstract>While existing work on studying bias in NLP focues on negative or pejorative language use, Govindarajan et al. (2023) offer a revised framing of bias in terms of intergroup social context, and its effects on language behavior. In this paper, we investigate if two pragmatic features (specificity and affect) systematically vary in different intergroup contexts — thus connecting this new framing of bias to language output. Preliminary analysis finds modest correlations between specificity and affect of tweets with supervised intergroup relationship (IGR) labels. Counterfactual probing further reveals that while neural models finetuned for predicting IGR reliably use affect in classification, the model’s usage of specificity is inconclusive.</abstract>
      <url hash="09a4ca6c">2023.findings-acl.813</url>
      <bibkey>govindarajan-etal-2023-counterfactual</bibkey>
      <doi>10.18653/v1/2023.findings-acl.813</doi>
    </paper>
    <paper id="814">
      <title><fixed-case>S</fixed-case>ong<fixed-case>R</fixed-case>ewriter: A <fixed-case>C</fixed-case>hinese Song Rewriting System with Controllable Content and Rhyme Scheme</title>
      <author><first>Yusen</first><last>Sun</last><affiliation>Huawei Noah’s Ark Lab</affiliation></author>
      <author><first>Liangyou</first><last>Li</last><affiliation>Huawei Noah’s Ark Lab</affiliation></author>
      <author><first>Qun</first><last>Liu</last><affiliation>Huawei Noah’s Ark Lab</affiliation></author>
      <author><first>Dit-Yan</first><last>Yeung</last><affiliation>Hong Kong University of Science and Technology</affiliation></author>
      <pages>12863-12880</pages>
      <abstract>Although lyrics generation has achieved significant progress in recent years, it has limited practical applications because the generated lyrics cannot be performed without composing compatible melodies. In this work, we bridge this practical gap by proposing a song rewriting system which rewrites the lyrics of an existing song such that the generated lyrics are compatible with the rhythm of the existing melody and thus singable. In particular, we propose SongRewriter, a controllable Chinese lyric generation and editing system which assists users without prior knowledge of melody composition. The system is trained by a randomized multi-level masking strategy which produces a unified model for generating entirely new lyrics or editing a few fragments. To improve the controllabiliy of the generation process, we further incorporate a keyword prompt to control the lexical choices of the content and propose novel decoding constraints and a vowel modeling task to enable flexible end and internal rhyme schemes. While prior rhyming metrics are mainly for rap lyrics, we propose three novel rhyming evaluation metrics for song lyrics. Both automatic and human evaluations show that the proposed model performs better than the state-of-the-art models in both contents and rhyming quality.</abstract>
      <url hash="594cd411">2023.findings-acl.814</url>
      <bibkey>sun-etal-2023-songrewriter</bibkey>
      <doi>10.18653/v1/2023.findings-acl.814</doi>
    </paper>
    <paper id="815">
      <title>Triplet-Free Knowledge-Guided Response Generation</title>
      <author><first>Dongming</first><last>Li</last><affiliation>The Chinese University of Hong Kong, Shenzhen</affiliation></author>
      <author><first>Jianfeng</first><last>Liu</last><affiliation>Xiaobing.ai</affiliation></author>
      <author><first>Baoyuan</first><last>Wang</last><affiliation>Xiaobing.ai</affiliation></author>
      <pages>12881-12899</pages>
      <abstract>Generating vivid and informative responses (e.g., comments for social posts and utterances for dialogues) is challenging without giving relevant knowledge. Prior works focus on constructing the ”latent” knowledge first and then learning how to ”ground” it based on pseudo (context, knowledge, response) triplets. However, the retrieval between real responses and their latent knowledge is difficult in nature. In this paper, instead of focusing on how to ground knowledge given the responses, we take a different perspective to optimize the final responses for given guided knowledge directly. This allows us to re-formulate the entire problem in a simplified yet more scalable way. Specifically, we pretrain a response language model (LM) to measure the relevance and consistency between any context and response, then use search engines to collect the top-ranked passages to serve as the guiding knowledge without explicitly optimizing the ‘‘best” latent knowledge that corresponds to a given response. The final response generation model is trained through reinforcement learning by taking both the response LM prior and knowledge-injection rate as rewards. For better evaluations, we construct a new Chinese benchmark, ”IceKC”, using fresh multimodal online social posts. Both automatic evaluations and human evaluations show our zero-resource approach performs significantly better than prior works.</abstract>
      <url hash="bdc588fe">2023.findings-acl.815</url>
      <bibkey>li-etal-2023-triplet</bibkey>
      <doi>10.18653/v1/2023.findings-acl.815</doi>
    </paper>
    <paper id="816">
      <title>Implicit Memory Transformer for Computationally Efficient Simultaneous Speech Translation</title>
      <author><first>Matthew</first><last>Raffel</last><affiliation>Oregon State University</affiliation></author>
      <author><first>Lizhong</first><last>Chen</last><affiliation>Oregon State University</affiliation></author>
      <pages>12900-12907</pages>
      <abstract>Simultaneous speech translation is an essential communication task difficult for humans whereby a translation is generated concurrently with oncoming speech inputs. For such a streaming task, transformers using block processing to break an input sequence into segments have achieved state-of-the-art performance at a reduced cost. Current methods to allow information to propagate across segments, including left context and memory banks, have faltered as they are both insufficient representations and unnecessarily expensive to compute. In this paper, we propose an Implicit Memory Transformer that implicitly retains memory through a new left context method, removing the need to explicitly represent memory with memory banks. We generate the left context from the attention output of the previous segment and include it in the keys and values of the current segment’s attention calculation. Experiments on the MuST-C dataset show that the Implicit Memory Transformer provides a substantial speedup on the encoder forward pass with nearly identical translation quality when compared with the state-of-the-art approach that employs both left context and memory banks.</abstract>
      <url hash="24c830ea">2023.findings-acl.816</url>
      <bibkey>raffel-chen-2023-implicit</bibkey>
      <doi>10.18653/v1/2023.findings-acl.816</doi>
    </paper>
    <paper id="817">
      <title>Enhancing Document-level Event Argument Extraction with Contextual Clues and Role Relevance</title>
      <author><first>Wanlong</first><last>Liu</last><affiliation>University of Electronic Science and Technology of China</affiliation></author>
      <author><first>Shaohuan</first><last>Cheng</last><affiliation>University of Electronic Science and Technology of China</affiliation></author>
      <author><first>Dingyi</first><last>Zeng</last><affiliation>University of Electronic Science and Technology of China</affiliation></author>
      <author><first>Qu</first><last>Hong</last><affiliation>School of Computer Science and Engineering, University of Electronic Science and Technology of China</affiliation></author>
      <pages>12908-12922</pages>
      <abstract>Document-level event argument extraction poses new challenges of long input and cross-sentence inference compared to its sentence-level counterpart. However, most prior works focus on capturing the relations between candidate arguments and the event trigger in each event, ignoring two crucial points: a) non-argument contextual clue information; b) the relevance among argument roles. In this paper, we propose a SCPRG (Span-trigger-based Contextual Pooling and latent Role Guidance) model, which contains two novel and effective modules for the above problem. The Span-Trigger-based Contextual Pooling (STCP) adaptively selects and aggregates the information of non-argument clue words based on the context attention weights of specific argument-trigger pairs from pre-trained model. The Role-based Latent Information Guidance (RLIG) module constructs latent role representations, makes them interact through role-interactive encoding to capture semantic relevance, and merges them into candidate arguments. Both STCP and RLIG introduce no more than 1% new parameters compared with the base model and can be easily applied to other event extraction models, which are compact and transplantable. Experiments on two public datasets show that our SCPRG outperforms previous state-of-the-art methods, with 1.13 F1 and 2.64 F1 improvements on RAMS and WikiEvents respectively. Further analyses illustrate the interpretability of our model.</abstract>
      <url hash="880fdb5b">2023.findings-acl.817</url>
      <bibkey>liu-etal-2023-enhancing-document</bibkey>
      <doi>10.18653/v1/2023.findings-acl.817</doi>
      <pwccode url="https://github.com/LWL-cpu/SCPRG-master" additional="false">LWL-cpu/SCPRG-master</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/wikievents">WikiEvents</pwcdataset>
    </paper>
    <paper id="818">
      <title>Exploring the Impact of Vision Features in News Image Captioning</title>
      <author><first>Junzhe</first><last>Zhang</last><affiliation>Peking University</affiliation></author>
      <author><first>Xiaojun</first><last>Wan</last><affiliation>Peking University</affiliation></author>
      <pages>12923-12936</pages>
      <abstract>The task of news image captioning aims to generate a detailed caption which describes the specific information of an image in a news article. However, we find that recent state-of-art models can achieve competitive performance even without vision features. To resolve the impact of vision features in the news image captioning task, we conduct extensive experiments with mainstream models based on encoder-decoder framework. From our exploration, we find 1) vision features do contribute to the generation of news image captions; 2) vision features can assist models to better generate entities of captions when the entity information is sufficient in the input textual context of the given article; 3) Regions of specific objects in images contribute to the generation of related entities in captions.</abstract>
      <url hash="add76cb5">2023.findings-acl.818</url>
      <bibkey>zhang-wan-2023-exploring</bibkey>
      <doi>10.18653/v1/2023.findings-acl.818</doi>
    </paper>
    <paper id="819">
      <title>Using Collostructional Analysis to evaluate <fixed-case>BERT</fixed-case>’s representation of linguistic constructions</title>
      <author><first>Tim</first><last>Veenboer</last><affiliation>University of Amsterdam</affiliation></author>
      <author><first>Jelke</first><last>Bloem</last><affiliation>University of Amsterdam</affiliation></author>
      <pages>12937-12951</pages>
      <abstract>Collostructional analysis is a technique devised to find correlations between particular words and linguistic constructions in order to analyse meaning associations of these constructions. Contrasting collostructional analysis results with output from BERT might provide insights into the way BERT represents the meaning of linguistic constructions. This study tests to what extent English BERT’s meaning representations correspond to known constructions from the linguistics literature by means of two tasks that we propose. Firstly, by predicting the words that can be used in open slots of constructions, the meaning associations of more lexicalized constructions can be observed. Secondly, by finding similar sequences using BERT’s output embeddings and manually reviewing the resulting sentences, we can observe whether instances of less lexicalized constructions are clustered together in semantic space. These two methods show that BERT represents constructional meaning to a certain extent, but does not separate instances of a construction from a near-synonymous construction that has a different form.</abstract>
      <url hash="3b5d9e3a">2023.findings-acl.819</url>
      <bibkey>veenboer-bloem-2023-using</bibkey>
      <doi>10.18653/v1/2023.findings-acl.819</doi>
    </paper>
    <paper id="820">
      <title>Selecting Better Samples from Pre-trained <fixed-case>LLM</fixed-case>s: A Case Study on Question Generation</title>
      <author><first>Xingdi</first><last>Yuan</last><affiliation>Microsoft Research</affiliation></author>
      <author><first>Tong</first><last>Wang</last><affiliation>Microsoft Research</affiliation></author>
      <author><first>Yen-Hsiang</first><last>Wang</last><affiliation>National Chung Hsing University</affiliation></author>
      <author><first>Emery</first><last>Fine</last><affiliation>MSR Montreal</affiliation></author>
      <author><first>Rania</first><last>Abdelghani</last><affiliation>INRIA BSO, Flowers teams &amp; EvidenceB</affiliation></author>
      <author><first>Hélène</first><last>Sauzéon</last><affiliation>Flowers Team - Inria Bordeaux</affiliation></author>
      <author><first>Pierre-Yves</first><last>Oudeyer</last><affiliation>Inria, France and Microsoft Research, Canada</affiliation></author>
      <pages>12952-12965</pages>
      <abstract>Large Language Models (LLMs) have in recent years demonstrated impressive prowess in natural language generation. A common practice to improve generation diversity is to sample multiple outputs from the model. However, partly due to the inaccessibility of LLMs, there lacks a simple and robust way of selecting the best output from these stochastic samples. As a case study framed in the context of question generation, we propose two prompt-based approaches, namely round-trip and prompt-based score, to selecting high-quality questions from a set of LLM-generated candidates. Our method works without the need to modify the underlying model, nor does it rely on human-annotated references — both of which are realistic constraints for real-world deployment of LLMs. With automatic as well as human evaluations, we empirically demonstrate that our approach can effectively select questions of higher qualities than greedy generation.</abstract>
      <url hash="c3143bf8">2023.findings-acl.820</url>
      <bibkey>yuan-etal-2023-selecting</bibkey>
      <doi>10.18653/v1/2023.findings-acl.820</doi>
    </paper>
    <paper id="821">
      <title>Sentiment Knowledge Enhanced Self-supervised Learning for Multimodal Sentiment Analysis</title>
      <author><first>Fan</first><last>Qian</last><affiliation>Harbin Institute of Technology</affiliation></author>
      <author><first>Jiqing</first><last>Han</last><affiliation>Harbin Institute of Technology</affiliation></author>
      <author><first>Yongjun</first><last>He</last><affiliation>Harbin Institute of Technology</affiliation></author>
      <author><first>Tieran</first><last>Zheng</last><affiliation>School of Computer Science and Technology, Harbin Institute of Technology</affiliation></author>
      <author><first>Guibin</first><last>Zheng</last><affiliation>Harbin Institute of Technology</affiliation></author>
      <pages>12966-12978</pages>
      <abstract>Multimodal Sentiment Analysis (MSA) has made great progress that benefits from extraordinary fusion scheme. However, there is a lack of labeled data, resulting in severe overfitting and poor generalization for supervised models applied in this field. In this paper, we propose Sentiment Knowledge Enhanced Self-supervised Learning (SKESL) to capture common sentimental patterns in unlabeled videos, which facilitates further learning on limited labeled data. Specifically, with the help of sentiment knowledge and non-verbal behavior, SKESL conducts sentiment word masking and predicts fine-grained word sentiment intensity, so as to embed sentiment information at the word level into pre-trained multimodal representation. In addition, a non-verbal injection method is also proposed to integrate non-verbal information into the word semantics. Experiments on two standard benchmarks of MSA clearly show that SKESL significantly outperforms the baseline, and achieves new State-Of-The-Art (SOTA) results.</abstract>
      <url hash="52835afc">2023.findings-acl.821</url>
      <bibkey>qian-etal-2023-sentiment</bibkey>
      <doi>10.18653/v1/2023.findings-acl.821</doi>
    </paper>
    <paper id="822">
      <title>Theory of Mind in Freely-Told Children’s Narratives: A Classification Approach</title>
      <author><first>Bram</first><last>van Dijk</last><affiliation>Leiden University</affiliation></author>
      <author><first>Marco</first><last>Spruit</last><affiliation>Leiden University</affiliation></author>
      <author><first>Max</first><last>van Duijn</last><affiliation>Leiden University</affiliation></author>
      <pages>12979-12993</pages>
      <abstract>Children are the focal point for studying the link between language and Theory of Mind (ToM) competence. Language and ToM are often studied with younger children and standardized tests, but as both are social competences, data and methods with higher ecological validity are critical. We leverage a corpus of 442 freely-told stories by Dutch children aged 4-12, recorded in their everyday classroom environments, to study language and ToM with NLP-tools. We labelled stories according to the mental depth of story characters children create, as a proxy for their ToM competence ‘in action’, and built a classifier with features encoding linguistic competences identified in existing work as predictive of ToM.We obtain good and fairly robust results (F1-macro = .71), relative to the complexity of the task for humans. Our results are explainable in that we link specific linguistic features such as lexical complexity and sentential complementation, that are relatively independent of children’s ages, to higher levels of character depth. This confirms and extends earlier work, as our study includes older children and socially embedded data from a different domain. Overall, our results support the idea that language and ToM are strongly interlinked, and that in narratives the former can scaffold the latter.</abstract>
      <url hash="d5e58240">2023.findings-acl.822</url>
      <bibkey>van-dijk-etal-2023-theory</bibkey>
      <doi>10.18653/v1/2023.findings-acl.822</doi>
    </paper>
    <paper id="823">
      <title>Better Language Models of Code through Self-Improvement</title>
      <author><first>Hung</first><last>To</last><affiliation>FPT Software AI Center</affiliation></author>
      <author><first>Nghi</first><last>Bui</last><affiliation>Salesforce Research Asia</affiliation></author>
      <author><first>Jin L.C.</first><last>Guo</last><affiliation>McGill University</affiliation></author>
      <author><first>Tien</first><last>Nguyen</last><affiliation>University of Texas at Dallas</affiliation></author>
      <pages>12994-13002</pages>
      <abstract>Pre-trained language models for code (PLMCs) have gained attention in recent research. These models are pre-trained on large-scale datasets using multi-modal objectives. However, fine-tuning them requires extensive supervision and is limited by the size of the dataset provided. We aim to improve this issue by proposing a data augmentation framework using knowledge distillation. Our framework utilizes knowledge gained during the pre-training and fine-tuning stage to augment training data, which is then used for the next step. We incorporate this framework into the state-of-the-art language models, such as CodeT5, CodeBERT, and UnixCoder. The results show that our framework significantly improves PLMCs’ performance in sequence-generation tasks, such as code summarization and code generation in the CodeXGLUE benchmark.</abstract>
      <url hash="9303935a">2023.findings-acl.823</url>
      <bibkey>to-etal-2023-better</bibkey>
      <doi>10.18653/v1/2023.findings-acl.823</doi>
    </paper>
    <paper id="824">
      <title>Challenging <fixed-case>BIG</fixed-case>-Bench Tasks and Whether Chain-of-Thought Can Solve Them</title>
      <author><first>Mirac</first><last>Suzgun</last><affiliation>Stanford University</affiliation></author>
      <author><first>Nathan</first><last>Scales</last><affiliation>Google Research</affiliation></author>
      <author><first>Nathanael</first><last>Schärli</last><affiliation>Google Research</affiliation></author>
      <author><first>Sebastian</first><last>Gehrmann</last><affiliation>Bloomberg LP</affiliation></author>
      <author><first>Yi</first><last>Tay</last><affiliation>Google Research</affiliation></author>
      <author><first>Hyung Won</first><last>Chung</last><affiliation>Google Research</affiliation></author>
      <author><first>Aakanksha</first><last>Chowdhery</last><affiliation>Google Research</affiliation></author>
      <author><first>Quoc</first><last>Le</last><affiliation>Google Inc</affiliation></author>
      <author><first>Ed</first><last>Chi</last><affiliation>Google Research</affiliation></author>
      <author><first>Denny</first><last>Zhou</last><affiliation>Google</affiliation></author>
      <author><first>Jason</first><last>Wei</last><affiliation>OpenAI</affiliation></author>
      <pages>13003-13051</pages>
      <abstract>BIG-Bench (Srivastava et al., 2022) is a diverse evaluation suite that focuses on tasks believed to be beyond the capabilities of current language models. Language models have already made good progress on this benchmark, with the best model in the BIG-Bench paper outperforming average reported human-rater results on 65% of the BIG-Bench tasks via few-shot prompting. But on what tasks do language models fall short of average human-rater performance, and are those tasks actually unsolvable by current language models? In this work, we focus on a suite of 23 challenging BIG-Bench tasks which we call BIG-Bench Hard (BBH). These are the tasks for which prior language model evaluations did not outperform the average human-rater. We find that applying chain-of-thought (CoT) prompting to BBH tasks enables PaLM to surpass the average human-rater performance on 10 of the 23 tasks, and Codex (code-davinci-002) to surpass the average human-rater performance on 17 of the 23 tasks. Since many tasks in BBH require multi-step reasoning, few-shot prompting without CoT, as done in the BIG-Bench evaluations (Srivastava et al., 2022), substantially underestimates the best performance and capabilities of language models, which is better captured via CoT prompting. As further analysis, we explore the interaction between CoT and model scale on BBH, finding that CoT enables emergent task performance on several BBH tasks with otherwise flat scaling curves.</abstract>
      <url hash="dbaccd20">2023.findings-acl.824</url>
      <bibkey>suzgun-etal-2023-challenging</bibkey>
      <doi>10.18653/v1/2023.findings-acl.824</doi>
    </paper>
    <paper id="825">
      <title>Score It All Together: A Multi-Task Learning Study on Automatic Scoring of Argumentative Essays</title>
      <author><first>Yuning</first><last>Ding</last><affiliation>FernUniversität in Hagen</affiliation></author>
      <author><first>Marie</first><last>Bexte</last><affiliation>FernUniversität in Hagen</affiliation></author>
      <author><first>Andrea</first><last>Horbach</last><affiliation>Universität Hildesheim</affiliation></author>
      <pages>13052-13063</pages>
      <abstract>When scoring argumentative essays in an educational context, not only the presence or absence of certain argumentative elements but also their quality is important. On the recently published student essay dataset PERSUADE, we first show that the automatic scoring of argument quality benefits from additional information about context, writing prompt and argument type. We then explore the different combinations of three tasks: automated span detection, type and quality prediction. Results show that a multi-task learning approach combining the three tasks outperforms sequential approaches that first learn to segment and then predict the quality/type of a segment.</abstract>
      <url hash="246c2b1e">2023.findings-acl.825</url>
      <bibkey>ding-etal-2023-score</bibkey>
      <doi>10.18653/v1/2023.findings-acl.825</doi>
    </paper>
    <paper id="826">
      <title>Data Sampling and (In)stability in Machine Translation Evaluation</title>
      <author><first>Chi-kiu</first><last>Lo</last><affiliation>National Research Council of Canada</affiliation></author>
      <author><first>Rebecca</first><last>Knowles</last><affiliation>National Research Council Canada</affiliation></author>
      <pages>13064-13074</pages>
      <abstract>We analyze the different data sampling approaches used in selecting data for human evaluation and ranking of machine translation systems at the highly influential Conference on Machine Translation (WMT). By using automatic evaluation metrics, we are able to focus on the impact of the data sampling procedure as separate from questions about human annotator consistency. We provide evidence that the latest data sampling approach used at WMT skews the annotated data toward shorter documents, not necessarily representative of the full test set. Lastly, we examine a new data sampling method that uses the available labour budget to sample data in a more representative manner, with the goals of improving representation of various document lengths in the sample and producing more stable rankings of system translation quality.</abstract>
      <url hash="531b573b">2023.findings-acl.826</url>
      <bibkey>lo-knowles-2023-data</bibkey>
      <doi>10.18653/v1/2023.findings-acl.826</doi>
    </paper>
    <paper id="827">
      <title>Probing Graph Decomposition for Argument Pair Extraction</title>
      <author><first>Yang</first><last>Sun</last><affiliation>Harbin Institute of Technology, Shenzhen</affiliation></author>
      <author><first>Bin</first><last>Liang</last><affiliation>Harbin Institute of Technology, Shenzhen</affiliation></author>
      <author><first>Jianzhu</first><last>Bao</last><affiliation>Harbin Institute of Technology, Shenzhen</affiliation></author>
      <author><first>Yice</first><last>Zhang</last><affiliation>Harbin Institute of Technology, Shenzhen</affiliation></author>
      <author><first>Geng</first><last>Tu</last><affiliation>Harbin Institute of Technology, Shenzhen</affiliation></author>
      <author><first>Min</first><last>Yang</last><affiliation>Chinese Academy of Sciences</affiliation></author>
      <author><first>Ruifeng</first><last>Xu</last><affiliation>Harbin Institute of Technology, Shenzhen</affiliation></author>
      <pages>13075-13088</pages>
      <abstract>Argument pair extraction (APE) aims to extract interactive argument pairs from two passages within a discussion. The key challenge of APE is to effectively capture the complex context-aware interactive relations of arguments between the two passages. In this paper, we elicit relational semantic knowledge from large-scale pre-trained language models (PLMs) via a probing technique. The induced sentence-level relational probing graph can help capture rich explicit interactive relations between argument pairs effectively. Since the relevance score of a sentence pair within a passage is generally larger than that of the sentence pair from different passages, each sentence would prefer to propagate information within the same passage and under-explore the interactive relations between two passages. To tackle this issue, we propose a graph decomposition method to decompose the probing graph into four sub-graphs from intra- and inter-passage perspectives, where the intra-passage graphs can help detect argument spans within each passage and the inter-passage graphs can help identify the argument pairs between the review and rebuttal passages. Experimental results on two benchmark datasets show that our method achieves substantial improvements over strong baselines for APE.</abstract>
      <url hash="e5ea2412">2023.findings-acl.827</url>
      <bibkey>sun-etal-2023-probing</bibkey>
      <doi>10.18653/v1/2023.findings-acl.827</doi>
    </paper>
    <paper id="828">
      <title><fixed-case>D</fixed-case>iffu<fixed-case>S</fixed-case>um: Generation Enhanced Extractive Summarization with Diffusion</title>
      <author><first>Haopeng</first><last>Zhang</last><affiliation>University of California, Davis</affiliation></author>
      <author><first>Xiao</first><last>Liu</last><affiliation>Univeristy of California, Davis</affiliation></author>
      <author><first>Jiawei</first><last>Zhang</last><affiliation>UC Davis</affiliation></author>
      <pages>13089-13100</pages>
      <abstract>Extractive summarization aims to form a summary by directly extracting sentences from the source document. Existing works mostly formulate it as a sequence labeling problem by making individual sentence label predictions. This paper proposes DiffuSum, a novel paradigm for extractive summarization, by directly generating the desired summary sentence representations with diffusion models and extracting sentences based on sentence representation matching. In addition, DiffuSum jointly optimizes a contrastive sentence encoder with a matching loss for sentence representation alignment and a multi-class contrastive loss for representation diversity. Experimental results show that DiffuSum achieves the new state-of-the-art extractive results on CNN/DailyMail with ROUGE scores of 44.83/22.56/40.56. Experiments on the other two datasets with different summary lengths and cross-dataset evaluation also demonstrate the effectiveness of DiffuSum. The strong performance of our framework shows the great potential of adapting generative models for extractive summarization.</abstract>
      <url hash="155678d4">2023.findings-acl.828</url>
      <bibkey>zhang-etal-2023-diffusum</bibkey>
      <doi>10.18653/v1/2023.findings-acl.828</doi>
    </paper>
    <paper id="829">
      <title>Towards Parameter-Efficient Integration of Pre-Trained Language Models In Temporal Video Grounding</title>
      <author><first>Erica</first><last>Kido Shimomoto</last><affiliation>National Institute of Advanced Industrial Science and Technology</affiliation></author>
      <author><first>Edison</first><last>Marrese-Taylor</last><affiliation>National Institute of Advanced Industrial Science and Technology (AIST)</affiliation></author>
      <author><first>Hiroya</first><last>Takamura</last><affiliation>The National Institute of Advanced Industrial Science and Technology (AIST)</affiliation></author>
      <author><first>Ichiro</first><last>Kobayashi</last><affiliation>Ochanomizu University</affiliation></author>
      <author><first>Hideki</first><last>Nakayama</last><affiliation>The University of Tokyo</affiliation></author>
      <author><first>Yusuke</first><last>Miyao</last><affiliation>University of Tokyo</affiliation></author>
      <pages>13101-13123</pages>
      <abstract>This paper explores the task of Temporal Video Grounding (TVG) where, given an untrimmed video and a query sentence, the goal is to recognize and determine temporal boundaries of action instances in the video described by natural language queries. Recent works tackled this task by improving query inputs with large pre-trained language models (PLM), at the cost of more expensive training. However, the effects of this integration are unclear, as these works also propose improvements in the visual inputs. Therefore, this paper studies the role of query sentence representation with PLMs in TVG and assesses the applicability of parameter-efficient training with NLP adapters. We couple popular PLMs with a selection of existing approaches and test different adapters to reduce the impact of the additional parameters. Our results on three challenging datasets show that, with the same visual inputs, TVG models greatly benefited from the PLM integration and fine-tuning, stressing the importance of the text query representation in this task. Furthermore, adapters were an effective alternative to full fine-tuning, even though they are not tailored to our task, allowing PLM integration in larger TVG models and delivering results comparable to SOTA models. Finally, our results shed light on which adapters work best in different scenarios.</abstract>
      <url hash="cf2ea117">2023.findings-acl.829</url>
      <bibkey>kido-shimomoto-etal-2023-towards</bibkey>
      <doi>10.18653/v1/2023.findings-acl.829</doi>
    </paper>
    <paper id="830">
      <title>A Memory Model for Question Answering from Streaming Data Supported by Rehearsal and Anticipation of Coreference Information</title>
      <author><first>Vladimir</first><last>Araujo</last><affiliation>KU Leuven</affiliation></author>
      <author><first>Alvaro</first><last>Soto</last><affiliation>PUC</affiliation></author>
      <author><first>Marie-Francine</first><last>Moens</last><affiliation>KU Leuven</affiliation></author>
      <pages>13124-13138</pages>
      <abstract>Existing question answering methods often assume that the input content (e.g., documents or videos) is always accessible to solve the task. Alternatively, memory networks were introduced to mimic the human process of incremental comprehension and compression of the information in a fixed-capacity memory. However, these models only learn how to maintain memory by backpropagating errors in the answers through the entire network. Instead, it has been suggested that humans have effective mechanisms to boost their memorization capacities, such as rehearsal and anticipation. Drawing inspiration from these, we propose a memory model that performs rehearsal and anticipation while processing inputs to memorize important information for solving question answering tasks from streaming data. The proposed mechanisms are applied self-supervised during training through masked modeling tasks focused on coreference information. We validate our model on a short-sequence (bAbI) dataset as well as large-sequence textual (NarrativeQA) and video (ActivityNet-QA) question answering datasets, where it achieves substantial improvements over previous memory network approaches. Furthermore, our ablation study confirms the proposed mechanisms’ importance for memory models.</abstract>
      <url hash="ffad9faf">2023.findings-acl.830</url>
      <bibkey>araujo-etal-2023-memory</bibkey>
      <doi>10.18653/v1/2023.findings-acl.830</doi>
    </paper>
    <paper id="831">
      <title>Pay Attention to Implicit Attribute Values: A Multi-modal Generative Framework for <fixed-case>AVE</fixed-case> Task</title>
      <author><first>Yupeng</first><last>Zhang</last><affiliation>Beihang University</affiliation></author>
      <author><first>Shensi</first><last>Wang</last><affiliation>Meituan</affiliation></author>
      <author><first>Peiguang</first><last>Li</last><affiliation>Meituan Group</affiliation></author>
      <author><first>Guanting</first><last>Dong</last><affiliation>Beijing University of Posts and Telecommunications</affiliation></author>
      <author><first>Sirui</first><last>Wang</last><affiliation>Tsinghua University</affiliation></author>
      <author><first>Yunsen</first><last>Xian</last><affiliation>Meituan</affiliation></author>
      <author><first>Zhoujun</first><last>Li</last><affiliation>Beihang University</affiliation></author>
      <author><first>Hongzhi</first><last>Zhang</last><affiliation>Meituan Inc.</affiliation></author>
      <pages>13139-13151</pages>
      <abstract>Attribute Value Extraction (AVE) boosts many e-commerce platform services such as targeted recommendation, product retrieval and question answering. Most previous studies adopt an extractive framework such as named entity recognition (NER) to capture subtokens in the product descriptions as the corresponding values of target attributes. However, in the real world scenario, there also exist implicit attribute values that are not mentioned explicitly but embedded in the image information and implied text meaning of products, for which the power of extractive methods is severely constrained. To address the above issues, we exploit a unified multi-modal AVE framework named DEFLATE (a multi-modal unifieD framEwork For impLicit And expliciT AVE) to acquire implicit attribute values in addition to the explicit ones. DEFLATE consists of a QA-based generation model to produce candidate attribute values from the product information of different modalities, and a discriminative model to ensure the credibility of the generated answers. Meanwhile, to provide a testbed that close to the real world, we collect and annotate a multi-modal dataset with parts of implicit attribute values. Extensive experiments conducted on multiple datasets demonstrate that DEFLATE significantly outperforms previous methods on the extraction of implicit attribute values, while achieving comparable performance for the explicit ones.</abstract>
      <url hash="68e2a7f7">2023.findings-acl.831</url>
      <bibkey>zhang-etal-2023-pay</bibkey>
      <doi>10.18653/v1/2023.findings-acl.831</doi>
    </paper>
    <paper id="832">
      <title><fixed-case>C</fixed-case>o<fixed-case>RRPUS</fixed-case>: Code-based Structured Prompting for Neurosymbolic Story Understanding</title>
      <author><first>Yijiang</first><last>Dong</last><affiliation>University of Pennsylvania</affiliation></author>
      <author><first>Lara</first><last>Martin</last><affiliation>University of Maryland, Baltimore County</affiliation></author>
      <author><first>Chris</first><last>Callison-Burch</last><affiliation>University of Pennsylvania</affiliation></author>
      <pages>13152-13168</pages>
      <abstract>Story generation and understanding—as with all NLG/NLU tasks—has seen a surge in neurosymbolic work. Researchers have recognized that, while large language models (LLMs) have tremendous utility, they can be augmented with symbolic means to be even better and to make up for many flaws that neural networks have. However, symbolic methods are extremely costly in terms of the amount of time and expertise needed to create them. In this work, we capitalize on state-of-the-art Code-LLMs, such as Codex, to bootstrap the use of symbolic methods for tracking the state of stories and aiding in story understanding. We show that our CoRRPUS system and abstracted prompting procedures can beat current state-of-the-art structured LLM techniques on pre-existing story understanding tasks (bAbI Task 2 and Re³) with minimal hand engineering. This work highlights the usefulness of code-based symbolic representations for enabling LLMs to better perform story reasoning tasks.</abstract>
      <url hash="3d1b5473">2023.findings-acl.832</url>
      <bibkey>dong-etal-2023-corrpus</bibkey>
      <doi>10.18653/v1/2023.findings-acl.832</doi>
    </paper>
    <paper id="833">
      <title>Fighting Bias With Bias: Promoting Model Robustness by Amplifying Dataset Biases</title>
      <author><first>Yuval</first><last>Reif</last><affiliation>Hebrew University of Jerusalem</affiliation></author>
      <author><first>Roy</first><last>Schwartz</last><affiliation>The Hebrew University of Jerusalem</affiliation></author>
      <pages>13169-13189</pages>
      <abstract>NLP models often rely on superficial cues known as dataset biases to achieve impressive performance, and can fail on examples where these biases do not hold. Recent work sought to develop robust, unbiased models by filtering biased examples from training sets. In this work, we argue that such filtering can obscure the true capabilities of models to overcome biases, which might never be removed in full from the dataset. We suggest that in order to drive the development of models robust to subtle biases, dataset biases should be amplified in the training set. We introduce an evaluation framework defined by a bias-amplified training set and an anti-biased test set, both automatically extracted from existing datasets. Experiments across three notions of bias, four datasets and two models show that our framework is substantially more challenging for models than the original data splits, and even more challenging than hand-crafted challenge sets. Our evaluation framework can use any existing dataset, even those considered obsolete, to test model robustness. We hope our work will guide the development of robust models that do not rely on superficial biases and correlations. To this end, we publicly release our code and data.</abstract>
      <url hash="90fac130">2023.findings-acl.833</url>
      <bibkey>reif-schwartz-2023-fighting</bibkey>
      <doi>10.18653/v1/2023.findings-acl.833</doi>
    </paper>
    <paper id="834">
      <title>Context-Aware Document Simplification</title>
      <author><first>Liam</first><last>Cripwell</last><affiliation>CNRS/LORIA and Université de Lorraine</affiliation></author>
      <author><first>Joël</first><last>Legrand</last><affiliation>INRIA - CNRS - Université de Lorraine - CentraleSupélec</affiliation></author>
      <author><first>Claire</first><last>Gardent</last><affiliation>CNRS/LORIA</affiliation></author>
      <pages>13190-13206</pages>
      <abstract>To date, most work on text simplification has focused on sentence-level inputs. Early attempts at document simplification merely applied these approaches iteratively over the sentences of a document. However, this fails to coherently preserve the discourse structure, leading to suboptimal output quality. Recently, strategies from controllable simplification have been leveraged to achieve state-of-the-art results on document simplification by first generating a document-level plan (a sequence of sentence-level simplification operations) and using this plan to guide sentence-level simplification downstream. However, this is still limited in that the simplification model has no direct access to the local inter-sentence document context, likely having a negative impact on surface realisation. We explore various systems that use document context within the simplification process itself, either by iterating over larger text units or by extending the system architecture to attend over a high-level representation of document context. In doing so, we achieve state-of-the-art performance on the document simplification task, even when not relying on plan-guidance. Further, we investigate the performance and efficiency tradeoffs of system variants and make suggestions of when each should be preferred.</abstract>
      <url hash="c7261d6e">2023.findings-acl.834</url>
      <bibkey>cripwell-etal-2023-context</bibkey>
      <doi>10.18653/v1/2023.findings-acl.834</doi>
    </paper>
    <paper id="835">
      <title>Distinguish Before Answer: Generating Contrastive Explanation as Knowledge for Commonsense Question Answering</title>
      <author><first>Qianglong</first><last>Chen</last><affiliation>Zhejiang University</affiliation></author>
      <author><first>Guohai</first><last>Xu</last><affiliation>Alibaba Group</affiliation></author>
      <author><first>Ming</first><last>Yan</last><affiliation>Alibaba Group</affiliation></author>
      <author><first>Ji</first><last>Zhang</last><affiliation>Alibaba Group</affiliation></author>
      <author><first>Fei</first><last>Huang</last><affiliation>Alibaba DAMO Academy</affiliation></author>
      <author><first>Luo</first><last>Si</last><affiliation>Alibaba Group Inc</affiliation></author>
      <author><first>Yin</first><last>Zhang</last><affiliation>Zhejiang University</affiliation></author>
      <pages>13207-13224</pages>
      <abstract>Existing knowledge-enhanced methods have achieved remarkable results in certain Q&amp;A tasks via obtaining diverse knowledge from different knowledge bases. However, limited by the properties of retrieved knowledge, they still have trouble benefiting from both the knowledge relevance and distinguishment simultaneously. To address the challenge, we propose <b>CPACE</b>, a <b>C</b>oncept-centric <b>P</b>rompt-b<b>A</b>sed <b>C</b>ontrastive <b>E</b>xplanation Generation model, which aims to convert obtained symbolic knowledge into the contrastive explanation for better distinguishing the differences among given candidates. Firstly, following previous works, we retrieve different types of symbolic knowledge with a concept-centric knowledge extraction module. After that, we generate corresponding contrastive explanation using acquired symbolic knowledge and prompt as guidance for better modeling the knowledge distinguishment and interpretability. Finally, we regard the generated contrastive explanation as external knowledge for downstream task enhancement. We conduct a series of experiments on three widely-used question-answering datasets: CSQA, QASC, and OBQA. Experimental results demonstrate that with the help of generated contrastive explanation, our CPACE model achieves new SOTA on CSQA (89.8% on the testing set, 0.9% higher than human performance), and gains impressive improvement on QASC and OBQA (4.2% and 3.5%, respectively).</abstract>
      <url hash="30408f2b">2023.findings-acl.835</url>
      <bibkey>chen-etal-2023-distinguish</bibkey>
      <doi>10.18653/v1/2023.findings-acl.835</doi>
    </paper>
    <paper id="836">
      <title>Abstract then Play: A Skill-centric Reinforcement Learning Framework for Text-based Games</title>
      <author><first>Anjie</first><last>Zhu</last><affiliation>University of Electronic Science and Technology of China</affiliation></author>
      <author><first>Peng-Fei</first><last>Zhang</last><affiliation>University of Queensland</affiliation></author>
      <author><first>Yi</first><last>Zhang</last><affiliation>The University of Queensland</affiliation></author>
      <author><first>Zi</first><last>Huang</last><affiliation>University of Queensland</affiliation></author>
      <author><first>Jie</first><last>Shao</last><affiliation>University of Electronic Science and Technology of China</affiliation></author>
      <pages>13225-13236</pages>
      <abstract>Text-based games present an exciting test-bed for reinforcement learning algorithms in the natural language environment. In these adventure games, an agent must learn to interact with the environment through text in order to accomplish tasks, facing large and combinational action space as well as partial observability issues. However, existing solutions fail to decompose the task and abstract the action autonomously, which either pre-specify the subtasks or pre-train on the human gameplay dataset. In this work, we introduce a novel skill-centric reinforcement learning framework, which is capable of abstracting the action in an end-to-end manner. To learn a more disentangled skill, we focus on the informativeness and distinguishability of the skill in accordance with the information bottleneck principle. Specifically, we introduce a discriminator to enable the skill to reflect the trajectory and push their representations onto the unit hypersphere to distribute uniformly. Moreover, a self-predictive mechanism is employed to learn inverse and forward dynamics, and a self-recovery mechanism is leveraged to refine the action representation, thus resulting in a more comprehensive perception of dynamics and more effective representations of textual state and action. Empirical experiments are carried out on the Jericho environment and the results validate the superiority against state-of-the-art baselines.</abstract>
      <url hash="f52d6313">2023.findings-acl.836</url>
      <bibkey>zhu-etal-2023-abstract</bibkey>
      <doi>10.18653/v1/2023.findings-acl.836</doi>
    </paper>
    <paper id="837">
      <title><fixed-case>SSP</fixed-case>: Self-Supervised Post-training for Conversational Search</title>
      <author><first>Quan</first><last>Tu</last><affiliation>Renmin University of China</affiliation></author>
      <author><first>Shen</first><last>Gao</last><affiliation>Shandong University</affiliation></author>
      <author><first>Xiaolong</first><last>Wu</last><affiliation>Huawei Poisson Lab</affiliation></author>
      <author><first>Zhao</first><last>Cao</last><affiliation>Huawei</affiliation></author>
      <author><first>Ji-Rong</first><last>Wen</last><affiliation>Renmin University of China</affiliation></author>
      <author><first>Rui</first><last>Yan</last><affiliation>Renmin University of China</affiliation></author>
      <pages>13237-13249</pages>
      <abstract>Conversational search has been regarded as the next-generation search paradigm. Constrained by data scarcity, most existing methods distill the well-trained ad-hoc retriever to the conversational retriever. However, these methods, which usually initialize parameters by query reformulation to discover contextualized dependency, have trouble in understanding the dialogue structure information and struggle with contextual semantic vanishing. In this paper, we propose {pasted macro ‘FULLMODEL’} ({pasted macro ‘MODEL’}) which is a new post-training paradigm with three self-supervised tasks to efficiently initialize the conversational search model to enhance the dialogue structure and contextual semantic understanding. Furthermore, the {pasted macro ‘MODEL’} can be plugged into most of the existing conversational models to boost their performance. To verify the effectiveness of our proposed method, we apply the conversational encoder post-trained by {pasted macro ‘MODEL’} on the conversational search task using two benchmark datasets: CAsT-19 and CAsT-20.Extensive experiments that our {pasted macro ‘MODEL’} can boost the performance of several existing conversational search methods. Our source code is available at <url>https://github.com/morecry/SSP</url>.</abstract>
      <url hash="6e525d03">2023.findings-acl.837</url>
      <bibkey>tu-etal-2023-ssp</bibkey>
      <doi>10.18653/v1/2023.findings-acl.837</doi>
    </paper>
    <paper id="838">
      <title>Towards Reference-free Text Simplification Evaluation with a <fixed-case>BERT</fixed-case> <fixed-case>S</fixed-case>iamese Network Architecture</title>
      <author><first>Xinran</first><last>Zhao</last><affiliation>Stanford University</affiliation></author>
      <author><first>Esin</first><last>Durmus</last><affiliation>Stanford University</affiliation></author>
      <author><first>Dit-Yan</first><last>Yeung</last><affiliation>Hong Kong University of Science and Technology</affiliation></author>
      <pages>13250-13264</pages>
      <abstract>Text simplification (TS) aims to modify sentences to make their both content and structure easier to understand. Traditional n-gram matching-based TS evaluation metrics heavily rely on the exact token match and human-annotated simplified sentences. In this paper, we present a novel neural-network-based reference-free TS metric BETS that leverages pre-trained contextualized language representation models and large-scale paraphrasing datasets to evaluate simplicity and meaning preservation. We show that our metric, without collecting any costly human simplification reference, correlates better than existing metrics with human judgments for the quality of both overall simplification (+7.7%) and its key aspects, i.e., comparative simplicity (+11.2%) and meaning preservation (+9.2%).</abstract>
      <url hash="f20faf7b">2023.findings-acl.838</url>
      <bibkey>zhao-etal-2023-towards</bibkey>
      <doi>10.18653/v1/2023.findings-acl.838</doi>
    </paper>
    <paper id="839">
      <title>Causal interventions expose implicit situation models for commonsense language understanding</title>
      <author><first>Takateru</first><last>Yamakoshi</last><affiliation>University of Tokyo</affiliation></author>
      <author><first>James</first><last>McClelland</last><affiliation>Stanford University</affiliation></author>
      <author><first>Adele</first><last>Goldberg</last><affiliation>Princeton University</affiliation></author>
      <author><first>Robert</first><last>Hawkins</last><affiliation>Princeton University</affiliation></author>
      <pages>13265-13293</pages>
      <abstract>Accounts of human language processing have long appealed to implicit “situation models” that enrich comprehension with relevant but unstated world knowledge. Here, we apply causal intervention techniques to recent transformer models to analyze performance on the Winograd Schema Challenge (WSC), where a single context cue shifts interpretation of an ambiguous pronoun. We identify a relatively small circuit of attention heads that are responsible for propagating information from the context word that guides which of the candidate noun phrases the pronoun ultimately attends to. We then compare how this circuit behaves in a closely matched “syntactic” control where the situation model is not strictly necessary. These analyses suggest a distinct pathway through which implicit situation models may be constructed to guide pronoun resolution</abstract>
      <url hash="2e842383">2023.findings-acl.839</url>
      <bibkey>yamakoshi-etal-2023-causal</bibkey>
      <doi>10.18653/v1/2023.findings-acl.839</doi>
    </paper>
    <paper id="840">
      <title>Iterative Nearest Neighbour Machine Translation for Unsupervised Domain Adaptation</title>
      <author><first>Hui</first><last>Huang</last><affiliation>Harbin Institute of Technology</affiliation></author>
      <author><first>Shuangzhi</first><last>Wu</last><affiliation>Bytedance</affiliation></author>
      <author><first>Xinnian</first><last>Liang</last><affiliation>Beihang University</affiliation></author>
      <author><first>Zefan</first><last>Zhou</last><affiliation>Northeastern University</affiliation></author>
      <author><first>Muyun</first><last>Yang</last><affiliation>Harbin Institute of Technology</affiliation></author>
      <author><first>Tiejun</first><last>Zhao</last><affiliation>Harbin Institute of Technology</affiliation></author>
      <pages>13294-13301</pages>
      <abstract>Unsupervised domain adaptation of machine translation, which adapts a pre-trained translation model to a specific domain without in-domain parallel data, has drawn extensive attention in recent years. However, most existing methods focus on the fine-tuning based techniques, which is non-extensible. In this paper, we propose a new method to perform unsupervised domain adaptation in a non-parametric manner. Our method only resorts to in-domain monolingual data, and we jointly perform nearest neighbour inference on both forward and backward translation directions. The forward translation model creates nearest neighbour datastore for the backward direction, and vice versa, strengthening each other in an iterative style. Experiments on multi-domain datasets demonstrate that our method significantly improves the in-domain translation performance and achieves state-of-the-art results among non-parametric methods.</abstract>
      <url hash="43f9dbe9">2023.findings-acl.840</url>
      <bibkey>huang-etal-2023-iterative</bibkey>
      <doi>10.18653/v1/2023.findings-acl.840</doi>
    </paper>
    <paper id="841">
      <title><fixed-case>P</fixed-case>ru<fixed-case>MUX</fixed-case>: Augmenting Data Multiplexing with Model Compression</title>
      <author><first>Yushan</first><last>Su</last><affiliation>Princeton University</affiliation></author>
      <author><first>Vishvak</first><last>Murahari</last><affiliation>Princeton University</affiliation></author>
      <author><first>Karthik</first><last>Narasimhan</last><affiliation>Princeton University</affiliation></author>
      <author><first>Kai</first><last>Li</last><affiliation>Princeton University</affiliation></author>
      <pages>13302-13315</pages>
      <abstract>As language models increase in size by the day, methods for efficient inference are critical to leveraging their capabilities for various applications. Prior work has investigated techniques like model pruning, knowledge distillation, and data multiplexing to increase model throughput without sacrificing accuracy. In this paper, we combine two such methods – structured pruning and data multiplexing – to compound the speedup gains obtained by either method. Our approach, PruMUX, obtains up to 7.5-29.5X throughput improvement over BERT-base model with accuracy threshold from 80% to 74%. We further study various combinations of parameters (such as sparsity and multiplexing factor) in the two techniques to provide a comprehensive analysis of the tradeoff between accuracy and throughput in the resulting models. We then propose Auto-PruMUX, a meta-level model that can predict the high-performance parameters for pruning and multiplexing given a desired accuracy loss budget, providing a practical method to leverage the combination effectively.</abstract>
      <url hash="8b546dc1">2023.findings-acl.841</url>
      <bibkey>su-etal-2023-prumux</bibkey>
      <doi>10.18653/v1/2023.findings-acl.841</doi>
    </paper>
    <paper id="842">
      <title>With Prejudice to None: A Few-Shot, Multilingual Transfer Learning Approach to Detect Social Bias in Low Resource Languages</title>
      <author><first>Nihar</first><last>Sahoo</last><affiliation>Indian Institute of Technology, Bombay</affiliation></author>
      <author><first>Niteesh</first><last>Mallela</last><affiliation>Indian Institute of Technology Bombay</affiliation></author>
      <author><first>Pushpak</first><last>Bhattacharyya</last><affiliation>Indian Institute of Technology Bombay and Patna</affiliation></author>
      <pages>13316-13330</pages>
      <abstract>In this paper, we describe our work on social bias detection in a low-resource multilingual setting in which the languages are from two very divergent families- Indo-European (English, Hindi, and Italian) and Altaic (Korean). Currently, the majority of the social bias datasets available are in English and this inhibits progress on social bias detection in low-resource languages. To address this problem, we introduce a new dataset for social bias detection in Hindi and investigate multilingual transfer learning using publicly available English, Italian, and Korean datasets. The Hindi dataset contains 9k social media posts annotated for (i) binary bias labels (bias/neutral), (ii) binary labels for sentiment (positive/negative), (iii) target groups for each bias category, and (iv) rationale for annotated bias labels (a short piece of text). We benchmark our Hindi dataset using different multilingual models, with XLM-R achieving the best performance of 80.8 macro-F1 score. Our results show that the detection of social biases in resource-constrained languages such as Hindi and Korean may be improved with the use of a similar dataset in English. We also show that translating all datasets into English does not work effectively for detecting social bias, since the nuances of source language are lost in translation. All the scripts and datasets utilized in this study will be publicly available.</abstract>
      <url hash="247dd861">2023.findings-acl.842</url>
      <bibkey>sahoo-etal-2023-prejudice</bibkey>
      <doi>10.18653/v1/2023.findings-acl.842</doi>
    </paper>
    <paper id="843">
      <title>Don’t Lose Yourself! Empathetic Response Generation via Explicit Self-Other Awareness</title>
      <author><first>Weixiang</first><last>Zhao</last><affiliation>Harbin Institute of Technology</affiliation></author>
      <author><first>Yanyan</first><last>Zhao</last><affiliation>Harbin Institute of Technology</affiliation></author>
      <author><first>Xin</first><last>Lu</last><affiliation>Harbin Institute of Technology</affiliation></author>
      <author><first>Bing</first><last>Qin</last><affiliation>Harbin Institute of Technology</affiliation></author>
      <pages>13331-13344</pages>
      <abstract>As a critical step to achieve human-like chatbots, empathetic response generation has attained increasing interests. Previous attempts are incomplete and not sufficient enough to elicit empathy because they only stay on the initial stage of empathy to automatically sense and simulate the feelings and thoughts of others via other-awareness. However, they ignore to include self-awareness to consider the own views of the self in their responses, which is a crucial process to achieve the empathy. To this end, we propose to generate Empathetic response with explicit Self-Other Awareness (EmpSOA). Specifically, three stages, self-other differentiation, self-other modulation and self-other generation, are devised to clearly maintain, regulate and inject the self-other aware information into the process of empathetic response generation. Both automatic and human evaluations on the benchmark dataset demonstrate the superiority of EmpSOA to generate more empathetic responses. Our source code will be publicly available.</abstract>
      <url hash="20b69d53">2023.findings-acl.843</url>
      <bibkey>zhao-etal-2023-dont</bibkey>
      <doi>10.18653/v1/2023.findings-acl.843</doi>
    </paper>
    <paper id="844">
      <title>Are Layout-Infused Language Models Robust to Layout Distribution Shifts? A Case Study with Scientific Documents</title>
      <author><first>Catherine</first><last>Chen</last><affiliation>University of California at Berkeley</affiliation></author>
      <author><first>Zejiang</first><last>Shen</last><affiliation>MIT</affiliation></author>
      <author><first>Dan</first><last>Klein</last><affiliation>UC Berkeley / Microsoft</affiliation></author>
      <author><first>Gabriel</first><last>Stanovsky</last><affiliation>The Hebrew University of Jerusalem</affiliation></author>
      <author><first>Doug</first><last>Downey</last><affiliation>Allen Institute for AI, Northwestern University</affiliation></author>
      <author><first>Kyle</first><last>Lo</last><affiliation>Allen Institute for Artificial Intelligence</affiliation></author>
      <pages>13345-13360</pages>
      <abstract>Recent work has shown that infusing layout features into language models (LMs) improves processing of visually-rich documents such as scientific papers. Layout-infused LMs are often evaluated on documents with familiar layout features (e.g., papers from the same publisher), but in practice models encounter documents with unfamiliar distributions of layout features, such as new combinations of text sizes and styles, or new spatial configurations of textual elements. In this work we test whether layout-infused LMs are robust to layout distribution shifts. As a case study we use the task of scientific document structure recovery, segmenting a scientific paper into its structural categories (e.g., “title”, “caption”, “reference”). To emulate distribution shifts that occur in practice we re-partition the GROTOAP2 dataset. We find that under layout distribution shifts model performance degrades by up to 20 F1. Simple training strategies, such as increasing training diversity, can reduce this degradation by over 35% relative F1; however, models fail to reach in-distribution performance in any tested out-of-distribution conditions. This work highlights the need to consider layout distribution shifts during model evaluation, and presents a methodology for conducting such evaluations.</abstract>
      <url hash="af0635aa">2023.findings-acl.844</url>
      <bibkey>chen-etal-2023-layout</bibkey>
      <doi>10.18653/v1/2023.findings-acl.844</doi>
    </paper>
    <paper id="845">
      <title>Enhancing Neural Topic Model with Multi-Level Supervisions from Seed Words</title>
      <author><first>Yang</first><last>Lin</last><affiliation>Peking University</affiliation></author>
      <author><first>Xin</first><last>Gao</last><affiliation>Peking University</affiliation></author>
      <author><first>Xu</first><last>Chu</last><affiliation>Tsinghua University</affiliation></author>
      <author><first>Yasha</first><last>Wang</last><affiliation>Peking University</affiliation></author>
      <author><first>Junfeng</first><last>Zhao</last><affiliation>School of Electronics Engineering and Computer Science,Peking University</affiliation></author>
      <author><first>Chao</first><last>Chen</last><affiliation>Chongqing University</affiliation></author>
      <pages>13361-13377</pages>
      <abstract>Efforts have been made to apply topic seed words to improve the topic interpretability of topic models. However, due to the semantic diversity of natural language, supervisions from seed words could be ambiguous, making it hard to be incorporated into the current neural topic models. In this paper, we propose SeededNTM, a neural topic model enhanced with supervisions from seed words on both word and document levels. We introduce a context-dependency assumption to alleviate the ambiguities with context document information, and an auto-adaptation mechanism to automatically balance between multi-level information. Moreover, an intra-sample consistency regularizer is proposed to deal with noisy supervisions via encouraging perturbation and semantic consistency. Extensive experiments on multiple datasets show that SeededNTM can derive semantically meaningful topics and outperforms the state-of-the-art seeded topic models in terms of topic quality and classification accuracy.</abstract>
      <url hash="110ff802">2023.findings-acl.845</url>
      <bibkey>lin-etal-2023-enhancing</bibkey>
      <doi>10.18653/v1/2023.findings-acl.845</doi>
    </paper>
    <paper id="846">
      <title>Learning from Children: Improving Image-Caption Pretraining via Curriculum</title>
      <author><first>Hammad</first><last>Ayyubi</last><affiliation>Columbia University</affiliation></author>
      <author><first>Rahul</first><last>Lokesh</last><affiliation>Samsung Research America</affiliation></author>
      <author><first>Alireza</first><last>Zareian</last><affiliation>Columbia University</affiliation></author>
      <author><first>Bo</first><last>Wu</last><affiliation>MIT-IBM Watson AI Lab</affiliation></author>
      <author><first>Shih-Fu</first><last>Chang</last><affiliation>Columbia University</affiliation></author>
      <pages>13378-13386</pages>
      <abstract>Image-caption pretraining has been quite successfully used for downstream vision tasks like zero-shot image classification and object detection. However, image-caption pretraining is still a hard problem – it requires multiple concepts (nouns) from captions to be aligned to several objects in images. To tackle this problem, we go to the roots – the best learner, children. We take inspiration from cognitive science studies dealing with children’s language learning to propose a curriculum learning framework. The learning begins with easy-to-align image caption pairs containing one concept per caption. The difficulty is progressively increased with each new phase by adding one more concept per caption. Correspondingly, the knowledge acquired in each learning phase is utilized in subsequent phases to effectively constrain the learning problem to aligning one new concept-object pair in each phase. We show that this learning strategy improves over vanilla image-caption training in various settings – pretraining from scratch, using a pretrained image or/and pretrained text encoder, low data regime etc.</abstract>
      <url hash="ce75e4ac">2023.findings-acl.846</url>
      <bibkey>ayyubi-etal-2023-learning</bibkey>
      <doi>10.18653/v1/2023.findings-acl.846</doi>
    </paper>
    <paper id="847">
      <title>Discovering Language Model Behaviors with Model-Written Evaluations</title>
      <author><first>Ethan</first><last>Perez</last><affiliation>Anthropic</affiliation></author>
      <author><first>Sam</first><last>Ringer</last><affiliation>Anthropic</affiliation></author>
      <author><first>Kamile</first><last>Lukosiute</last><affiliation>Anthropic</affiliation></author>
      <author><first>Karina</first><last>Nguyen</last><affiliation>Anthropic</affiliation></author>
      <author><first>Edwin</first><last>Chen</last><affiliation>Surge AI</affiliation></author>
      <author><first>Scott</first><last>Heiner</last><affiliation>Surge AI</affiliation></author>
      <author><first>Craig</first><last>Pettit</last><affiliation>Surge AI</affiliation></author>
      <author><first>Catherine</first><last>Olsson</last><affiliation>Anthropic</affiliation></author>
      <author><first>Sandipan</first><last>Kundu</last><affiliation>Anthropic</affiliation></author>
      <author><first>Saurav</first><last>Kadavath</last><affiliation>Anthropic</affiliation></author>
      <author><first>Andy</first><last>Jones</last><affiliation>Anthropic PBC</affiliation></author>
      <author><first>Anna</first><last>Chen</last><affiliation>Anthropic AI</affiliation></author>
      <author><first>Benjamin</first><last>Mann</last><affiliation>OpenAI</affiliation></author>
      <author><first>Brian</first><last>Israel</last><affiliation>Anthropic</affiliation></author>
      <author><first>Bryan</first><last>Seethor</last><affiliation>Anthropic</affiliation></author>
      <author><first>Cameron</first><last>McKinnon</last><affiliation>Anthropic</affiliation></author>
      <author><first>Christopher</first><last>Olah</last><affiliation>Anthropic</affiliation></author>
      <author><first>Da</first><last>Yan</last><affiliation>Anthropic</affiliation></author>
      <author><first>Daniela</first><last>Amodei</last><affiliation>Anthropic</affiliation></author>
      <author><first>Dario</first><last>Amodei</last><affiliation>Anthropic</affiliation></author>
      <author><first>Dawn</first><last>Drain</last><affiliation>Anthropic</affiliation></author>
      <author><first>Dustin</first><last>Li</last><affiliation>Anthropic</affiliation></author>
      <author><first>Eli</first><last>Tran-Johnson</last><affiliation>Anthropic</affiliation></author>
      <author><first>Guro</first><last>Khundadze</last><affiliation>Anthropic</affiliation></author>
      <author><first>Jackson</first><last>Kernion</last><affiliation>Anthropic</affiliation></author>
      <author><first>James</first><last>Landis</last><affiliation>Anthropic</affiliation></author>
      <author><first>Jamie</first><last>Kerr</last><affiliation>Anthropic</affiliation></author>
      <author><first>Jared</first><last>Mueller</last><affiliation>Anthropic PBC</affiliation></author>
      <author><first>Jeeyoon</first><last>Hyun</last><affiliation>Anthropic</affiliation></author>
      <author><first>Joshua</first><last>Landau</last><affiliation>Anthropic</affiliation></author>
      <author><first>Kamal</first><last>Ndousse</last><affiliation>Anthropic</affiliation></author>
      <author><first>Landon</first><last>Goldberg</last><affiliation>Anthropic</affiliation></author>
      <author><first>Liane</first><last>Lovitt</last><affiliation>Anthropic</affiliation></author>
      <author><first>Martin</first><last>Lucas</last><affiliation>Anthropic</affiliation></author>
      <author><first>Michael</first><last>Sellitto</last><affiliation>Anthropic</affiliation></author>
      <author><first>Miranda</first><last>Zhang</last><affiliation>Anthropic</affiliation></author>
      <author><first>Neerav</first><last>Kingsland</last><affiliation>Anthropic</affiliation></author>
      <author><first>Nelson</first><last>Elhage</last><affiliation>Anthropic</affiliation></author>
      <author><first>Nicholas</first><last>Joseph</last><affiliation>Anthropic</affiliation></author>
      <author><first>Noemi</first><last>Mercado</last><affiliation>Anthropic</affiliation></author>
      <author><first>Nova</first><last>DasSarma</last><affiliation>Anthropic, PBC</affiliation></author>
      <author><first>Oliver</first><last>Rausch</last><affiliation>Anthropic</affiliation></author>
      <author><first>Robin</first><last>Larson</last><affiliation>Anthropic</affiliation></author>
      <author><first>Sam</first><last>McCandlish</last><affiliation>Anthropic</affiliation></author>
      <author><first>Scott</first><last>Johnston</last><affiliation>Anthropic</affiliation></author>
      <author><first>Shauna</first><last>Kravec</last><affiliation>Anthropic</affiliation></author>
      <author><first>Sheer</first><last>El Showk</last><affiliation>Anthropic PBC</affiliation></author>
      <author><first>Tamera</first><last>Lanham</last><affiliation>Anthropic</affiliation></author>
      <author><first>Timothy</first><last>Telleen-Lawton</last><affiliation>Anthropic</affiliation></author>
      <author><first>Tom</first><last>Brown</last><affiliation>Anthropic</affiliation></author>
      <author><first>Tom</first><last>Henighan</last><affiliation>Anthropic</affiliation></author>
      <author><first>Tristan</first><last>Hume</last><affiliation>Anthropic</affiliation></author>
      <author><first>Yuntao</first><last>Bai</last><affiliation>Anthropic, PBC</affiliation></author>
      <author><first>Zac</first><last>Hatfield-Dodds</last><affiliation>Anthropic</affiliation></author>
      <author><first>Jack</first><last>Clark</last><affiliation>Anthropic</affiliation></author>
      <author><first>Samuel R.</first><last>Bowman</last><affiliation>New York University</affiliation></author>
      <author><first>Amanda</first><last>Askell</last><affiliation>Anthropic</affiliation></author>
      <author><first>Roger</first><last>Grosse</last><affiliation>University of Toronto</affiliation></author>
      <author><first>Danny</first><last>Hernandez</last><affiliation>Anthropic</affiliation></author>
      <author><first>Deep</first><last>Ganguli</last><affiliation>Anthropic</affiliation></author>
      <author><first>Evan</first><last>Hubinger</last><affiliation>Anthropic</affiliation></author>
      <author><first>Nicholas</first><last>Schiefer</last><affiliation>Anthropic</affiliation></author>
      <author><first>Jared</first><last>Kaplan</last><affiliation>Anthropic</affiliation></author>
      <pages>13387-13434</pages>
      <abstract>As language models (LMs) scale, they develop many novel behaviors, good and bad, exacerbating the need to evaluate how they behave. Prior work creates evaluations with crowdwork (which is time-consuming and expensive) or existing data sources (which are not always available). Here, we automatically generate evaluations with LMs. We explore approaches with varying amounts of human effort, from instructing LMs to write yes/no questions to making complex Winogender schemas with multiple stages of LM-based generation and filtering. Crowdworkers rate the examples as highly relevant and agree with 90-100% of labels, sometimes more so than corresponding human-written datasets. We generate 154 datasets and discover new cases of inverse scaling where LMs get worse with size. Larger LMs repeat back a dialog user’s preferred answer (“sycophancy”) and express greater desire to pursue concerning goals like resource acquisition and goal preservation. We also find some of the first examples of inverse scaling in RL from Human Feedback (RLHF), where more RLHF makes LMs worse. For example, RLHF makes LMs express stronger political views (on gun rights and immigration) and a greater desire to avoid shut down. Overall, LM-written evaluations are high-quality and let us quickly discover many novel LM behaviors.</abstract>
      <url hash="1f9d7c59">2023.findings-acl.847</url>
      <bibkey>perez-etal-2023-discovering</bibkey>
      <doi>10.18653/v1/2023.findings-acl.847</doi>
    </paper>
    <paper id="848">
      <title>Cross-Domain Argument Quality Estimation</title>
      <author><first>Michael</first><last>Fromm</last><affiliation>Fraunhofer IAIS</affiliation></author>
      <author><first>Max</first><last>Berrendorf</last><affiliation>LMU Munich</affiliation></author>
      <author><first>Evgeniy</first><last>Faerman</last><affiliation>LMU</affiliation></author>
      <author><first>Thomas</first><last>Seidl</last><affiliation>LMU Munich</affiliation></author>
      <pages>13435-13448</pages>
      <abstract>Argumentation is one of society’s foundational pillars, and, sparked by advances in NLP, and the vast availability of text data, automated mining of arguments receives increasing attention. A decisive property of arguments is their strength or quality. While there are works on the automated estimation of argument strength, their scope is narrow:They focus on isolated datasets and neglect the interactions with related argument-mining tasks, such as argument identification and evidence detection. In this work, we close this gap by approaching argument quality estimation from multiple different angles:Grounded on rich results from thorough empirical evaluations, we assess the generalization capabilities of argument quality estimation across diverse domains and the interplay with related argument mining tasks. We find that generalization depends on a sufficient representation of different domains in the training part. In zero-shot transfer and multi-task experiments, we reveal that argument quality is among the more challenging tasks but can improve others. We publish our code at <url>https://github.com/fromm-m/acl-cross-domain-aq</url>.</abstract>
      <url hash="2466833f">2023.findings-acl.848</url>
      <bibkey>fromm-etal-2023-cross</bibkey>
      <doi>10.18653/v1/2023.findings-acl.848</doi>
    </paper>
    <paper id="849">
      <title><fixed-case>D</fixed-case>ia<fixed-case>ASQ</fixed-case>: A Benchmark of Conversational Aspect-based Sentiment Quadruple Analysis</title>
      <author><first>Bobo</first><last>Li</last><affiliation>Wuhan University</affiliation></author>
      <author><first>Hao</first><last>Fei</last><affiliation>National University of Singapore</affiliation></author>
      <author><first>Fei</first><last>Li</last><affiliation>Wuhan University</affiliation></author>
      <author><first>Yuhan</first><last>Wu</last><affiliation>Wuhan University</affiliation></author>
      <author><first>Jinsong</first><last>Zhang</last><affiliation>Wuhan University</affiliation></author>
      <author><first>Shengqiong</first><last>Wu</last><affiliation>National University of Singapore</affiliation></author>
      <author><first>Jingye</first><last>Li</last><affiliation>ByteDance Inc.</affiliation></author>
      <author><first>Yijiang</first><last>Liu</last><affiliation>Wuhan University</affiliation></author>
      <author><first>Lizi</first><last>Liao</last><affiliation>Singapore Management University</affiliation></author>
      <author><first>Tat-Seng</first><last>Chua</last><affiliation>National University of Singapore</affiliation></author>
      <author><first>Donghong</first><last>Ji</last><affiliation>Wuhan University</affiliation></author>
      <pages>13449-13467</pages>
      <abstract>The rapid development of aspect-based sentiment analysis (ABSA) within recent decades shows great potential for real-world society. The current ABSA works, however, are mostly limited to the scenario of a single text piece, leaving the study in dialogue contexts unexplored. To bridge the gap between fine-grained sentiment analysis and conversational opinion mining, in this work, we introduce a novel task of conversational aspect-based sentiment quadruple analysis, namely DiaASQ, aiming to detect the quadruple of target-aspect-opinion-sentiment in a dialogue. We manually construct a large-scale high-quality DiaASQ dataset in both Chinese and English languages. We deliberately develop a neural model to benchmark the task, which advances in effectively performing end-to-end quadruple prediction, and manages to incorporate rich dialogue-specific and discourse feature representations for better cross-utterance quadruple extraction. We hope the new benchmark will spur more advancements in the sentiment analysis community.</abstract>
      <url hash="579e6015">2023.findings-acl.849</url>
      <bibkey>li-etal-2023-diaasq</bibkey>
      <doi>10.18653/v1/2023.findings-acl.849</doi>
    </paper>
    <paper id="850">
      <title><fixed-case>G</fixed-case>eo<fixed-case>DRL</fixed-case>: A Self-Learning Framework for Geometry Problem Solving using Reinforcement Learning in Deductive Reasoning</title>
      <author><first>Shuai</first><last>Peng</last><affiliation>Peking University</affiliation></author>
      <author><first>Di</first><last>Fu</last><affiliation>ByteDance</affiliation></author>
      <author><first>Yijun</first><last>Liang</last><affiliation>ByteDance</affiliation></author>
      <author><first>Liangcai</first><last>Gao</last><affiliation>Peking University</affiliation></author>
      <author><first>Zhi</first><last>Tang</last><affiliation>Wangxuan Institute of Computer Technology, Peking University</affiliation></author>
      <pages>13468-13480</pages>
      <abstract>Ensuring both interpretability and correctness is a great challenge in automated geometry problem solving (GPS), and the scarcity of labeled data hinders learning mathematical reasoning from samples. Therefore, we present GeoDRL, a self-learning geometry problem solving framework that integrates logic graph deduction and Deep Reinforcement Learning (DRL) to optimize geometry reasoning as a Markov Decision Process. GeoDRL employs a Graph Neural Network on a Geometry Logic Graph, updating the problem state using a symbolic system. Incorporating DRL into deductive reasoning enables GeoDRL to achieve unsupervised self-learning while maintaining correctness. GeoDRL, through unsupervised learning, exhibits enhanced accuracy in the Geometry3K dataset, improving by 11.1% over previous SOTA methods, and simultaneously boosts efficiency and interpretability.</abstract>
      <url hash="10cb441b">2023.findings-acl.850</url>
      <bibkey>peng-etal-2023-geodrl</bibkey>
      <doi>10.18653/v1/2023.findings-acl.850</doi>
    </paper>
    <paper id="851">
      <title>Uncertainty-Aware Unlikelihood Learning Improves Generative Aspect Sentiment Quad Prediction</title>
      <author><first>Mengting</first><last>Hu</last><affiliation>Nankai University</affiliation></author>
      <author><first>Yinhao</first><last>Bai</last><affiliation>Nankai University</affiliation></author>
      <author><first>Yike</first><last>Wu</last><affiliation>Nankai University</affiliation></author>
      <author><first>Zhen</first><last>Zhang</last><affiliation>Nankai University</affiliation></author>
      <author><first>Liqi</first><last>Zhang</last><affiliation>Tiangong University</affiliation></author>
      <author><first>Hang</first><last>Gao</last><affiliation>Tsinghua University</affiliation></author>
      <author><first>Shiwan</first><last>Zhao</last><affiliation>Independent Researcher</affiliation></author>
      <author><first>Minlie</first><last>Huang</last><affiliation>Tsinghua University</affiliation></author>
      <pages>13481-13494</pages>
      <abstract>Recently, aspect sentiment quad prediction has received widespread attention in the field of aspect-based sentiment analysis. Existing studies extract quadruplets via pre-trained generative language models to paraphrase the original sentence into a templated target sequence. However, previous works only focus on what to generate but ignore what not to generate. We argue that considering the negative samples also leads to potential benefits. In this work, we propose a template-agnostic method to control the token-level generation, which boosts original learning and reduces mistakes simultaneously. Specifically, we introduce Monte Carlo dropout to understand the built-in uncertainty of pre-trained language models, acquiring the noises and errors. We further propose marginalized unlikelihood learning to suppress the uncertainty-aware mistake tokens. Finally, we introduce minimization entropy to balance the effects of marginalized unlikelihood learning. Extensive experiments on four public datasets demonstrate the effectiveness of our approach on various generation templates.</abstract>
      <url hash="dc3015a2">2023.findings-acl.851</url>
      <bibkey>hu-etal-2023-uncertainty</bibkey>
      <doi>10.18653/v1/2023.findings-acl.851</doi>
    </paper>
    <paper id="852">
      <title>Adversarial Knowledge Stimulated Contrastive Prompting for Few-shot Language Learners</title>
      <author><first>Kai</first><last>Zheng</last><affiliation>Microsoft</affiliation></author>
      <author><first>Qingfeng</first><last>Sun</last><affiliation>Microsoft Corporation</affiliation></author>
      <author><first>Yaming</first><last>Yang</last><affiliation>Microsoft</affiliation></author>
      <author><first>Tengchao</first><last>Lv</last><affiliation>Microsoft Research Asia</affiliation></author>
      <author><first>Yeyong</first><last>Pi</last><affiliation>Microsoft</affiliation></author>
      <author><first>Changlin</first><last>Zhao</last><affiliation>Microsoft.com</affiliation></author>
      <author><first>Fei</first><last>Xu</last><affiliation>Microsoft</affiliation></author>
      <author><first>Qi</first><last>Zhang</last><affiliation>Microsoft</affiliation></author>
      <pages>13495-13507</pages>
      <abstract>Prompt-based fine-tuning has boosted the performance of Pre-trained Language Models(PLMs) on few-shot Natural Language Understanding (NLU) tasks by employing task-specific prompts. Yet, PLMsare unfamiliar with prompt-style expressionsduring pre-training, which limits the few-shotlearning performance on downstream tasks. It would be desirable if the models can stimulate prompting knowledge while adaptation to specific NLU tasks. We present the Adversarial Knowledge Stimulated Contrastive Prompting (AKSCP) framework, leading to better few-shot NLU tasks for language models by implicitly stimulate knowledge from pretrained language model. In AKSCP, a novel paradigm Cloze-driven prompt is proposed for joint prompt tuning across word cloze task and prompt-based learning, forcing PLMs to stimulate prompting knowledge. We further design an Adversarial Contrastive learning method to improve the generalization ability of PLM for different downstream tasks. Experiments over a variety of NLU tasks show that AKSCP consistently outperforms state-of-the-arts for prompt-based fine-tuning.</abstract>
      <url hash="a7305aae">2023.findings-acl.852</url>
      <bibkey>zheng-etal-2023-adversarial</bibkey>
      <doi>10.18653/v1/2023.findings-acl.852</doi>
    </paper>
    <paper id="853">
      <title>Making Pre-trained Language Models Better Learn Few-Shot Spoken Language Understanding in More Practical Scenarios</title>
      <author><first>Yufan</first><last>Wang</last><affiliation>Central China Normal University,National Engineering Research Center for E-Learning</affiliation></author>
      <author><first>Jie</first><last>Mei</last><affiliation>Central China Normal University</affiliation></author>
      <author><first>Bowei</first><last>Zou</last><affiliation>Institute for Infocomm Research</affiliation></author>
      <author><first>Rui</first><last>Fan</last><affiliation>Faculty of Artificial Intelligence in Education, Central China Normal University</affiliation></author>
      <author><first>Tingting</first><last>He</last><affiliation>School of Computer, Central China Normal University</affiliation></author>
      <author><first>Ai Ti</first><last>Aw</last><affiliation>Institute for Infocomm Research</affiliation></author>
      <pages>13508-13523</pages>
      <abstract>Most previous few-shot Spoken Language Understanding (SLU) models typically need to be trained on a set of data-rich source domains and adapt to the target domain with a few examples. In this paper, we explore a more practical scenario for few-shot SLU, in which we only assume access to a pre-trained language model and a few labeled examples without any other source domain data. We concentrate on understanding how far the few-shot SLU could be pushed in this setting. To this end, we develop a prompt-based intent detection model in few-shot settings, which leverages the BERT original pre-training next sentence prediction task and the prompt template to detect the user’s intent. For slot filling, we propose an approach of reconstructing slot labels, which reduces the training complexity by reducing the number of slot labels in few-shot settings. To evaluate the few-shot SLU for a more practical scenario, we present two benchmarks, FewShotATIS and FewShotSNIPS. And a dynamic sampling strategy is designed to construct the two datasets according to the learning difficulty of each intent and slot. Experiments on FewShotATIS and FewShotSNIPS demonstrate that our proposed model achieves state-of-the-art performance.</abstract>
      <url hash="317c3c01">2023.findings-acl.853</url>
      <bibkey>wang-etal-2023-making</bibkey>
      <doi>10.18653/v1/2023.findings-acl.853</doi>
    </paper>
    <paper id="854">
      <title>Typology Guided Multilingual Position Representations: Case on Dependency Parsing</title>
      <author><first>Tao</first><last>Ji</last><affiliation>Department of Computer Science and Technology at East China Normal University</affiliation></author>
      <author><first>Yuanbin</first><last>Wu</last><affiliation>East China Normal University</affiliation></author>
      <author><first>Xiaoling</first><last>Wang</last><affiliation>East China Normal University</affiliation></author>
      <pages>13524-13541</pages>
      <abstract>Recent multilingual models benefit from strong unified semantic representation models. However, due to conflict linguistic regularities, ignoring language-specific features during multilingual learning may suffer from negative transfer. In this work, we analyze the relationbetween a language’s position space and its typological characterization, and suggest deploying different position spaces for different languages. We develop a position generation network which combines prior knowledge from typology features and existing position vectors. Experiments on the multilingual dependency parsing task show that the learned position vectors exhibit meaningful hidden structures, and they can help achieving the best multilingual parsing results.</abstract>
      <url hash="09553daa">2023.findings-acl.854</url>
      <bibkey>ji-etal-2023-typology</bibkey>
      <doi>10.18653/v1/2023.findings-acl.854</doi>
    </paper>
    <paper id="855">
      <title>Learning Event-aware Measures for Event Coreference Resolution</title>
      <author id="yao-yao"><first>Yao</first><last>Yao</last><affiliation>Shanghai Jiao Tong University</affiliation></author>
      <author><first>Zuchao</first><last>Li</last><affiliation>Wuhan University</affiliation></author>
      <author><first>Hai</first><last>Zhao</last><affiliation>Shanghai Jiao Tong University</affiliation></author>
      <pages>13542-13556</pages>
      <abstract>Researchers are witnessing knowledge-inspired natural language processing shifts the focus from entity-level to event-level, whereas event coreference resolution is one of the core challenges. This paper proposes a novel model for within-document event coreference resolution. On the basis of event but not entity as before, our model learns and integrates multiple representations from both event alone and event pair. For the former, we introduce multiple linguistics-motivated event alone features for more discriminative event representations. For the latter, we consider multiple similarity measures to capture the distinction of event pair. Our proposed model achieves new state-of-the-art on the ACE 2005 benchmark, demonstrating the effectiveness of our proposed framework.</abstract>
      <url hash="1fd54048">2023.findings-acl.855</url>
      <bibkey>yao-etal-2023-learning</bibkey>
      <doi>10.18653/v1/2023.findings-acl.855</doi>
    </paper>
    <paper id="856">
      <title>Second Language Acquisition of Neural Language Models</title>
      <author><first>Miyu</first><last>Oba</last><affiliation>Nara Institute of Science and Technology</affiliation></author>
      <author><first>Tatsuki</first><last>Kuribayashi</last><affiliation>MBZUAI</affiliation></author>
      <author><first>Hiroki</first><last>Ouchi</last><affiliation>Nara Institute of Science and Technology</affiliation></author>
      <author><first>Taro</first><last>Watanabe</last><affiliation>Nara Institute of Science and Technology</affiliation></author>
      <pages>13557-13572</pages>
      <abstract>With the success of neural language models (LMs), their language acquisition has gained much attention. This work sheds light on the second language (L2) acquisition of LMs, while previous work has typically explored their first language (L1) acquisition. Specifically, we trained bilingual LMs with a scenario similar to human L2 acquisition and analyzed their cross-lingual transfer from linguistic perspectives. Our exploratory experiments demonstrated that the L1 pretraining accelerated their linguistic generalization in L2, and language transfer configurations (e.g., the L1 choice, and presence of parallel texts) substantially affected their generalizations. These clarify their (non-)human-like L2 acquisition in particular aspects.</abstract>
      <url hash="d95e900d">2023.findings-acl.856</url>
      <bibkey>oba-etal-2023-second</bibkey>
      <doi>10.18653/v1/2023.findings-acl.856</doi>
    </paper>
    <paper id="857">
      <title>On the Universal Adversarial Perturbations for Efficient Data-free Adversarial Detection</title>
      <author><first>SongYang</first><last>Gao</last><affiliation>Fudan University</affiliation></author>
      <author><first>Shihan</first><last>Dou</last><affiliation>Fudan University</affiliation></author>
      <author><first>Qi</first><last>Zhang</last><affiliation>Fudan University</affiliation></author>
      <author><first>Xuanjing</first><last>Huang</last><affiliation>Fudan University</affiliation></author>
      <author><first>Jin</first><last>Ma</last><affiliation>ustc</affiliation></author>
      <author><first>Ying</first><last>Shan</last><affiliation>Tencent</affiliation></author>
      <pages>13573-13581</pages>
      <abstract>Detecting adversarial samples that are carefully crafted to fool the model is a critical step to socially-secure applications. However, existing adversarial detection methods require access to sufficient training data, which brings noteworthy concerns regarding privacy leakage and generalizability. In this work, we validate that the adversarial sample generated by attack algorithms is strongly related to a specific vector in the high-dimensional inputs. Such vectors, namely UAPs (Universal Adversarial Perturbations), can be calculated without original training data. Based on this discovery, we propose a data-agnostic adversarial detection framework, which induces different responses between normal and adversarial samples to UAPs. Experimental results show that our method achieves competitive detection performance on various text classification tasks, and maintains an equivalent time consumption to normal inference.</abstract>
      <url hash="29ef2ed1">2023.findings-acl.857</url>
      <bibkey>gao-etal-2023-universal</bibkey>
      <doi>10.18653/v1/2023.findings-acl.857</doi>
    </paper>
    <paper id="858">
      <title>Exploring the Effectiveness of Prompt Engineering for Legal Reasoning Tasks</title>
      <author><first>Fangyi</first><last>Yu</last><affiliation>Ontario Tech University</affiliation></author>
      <author><first>Lee</first><last>Quartey</last><affiliation>Thomson Reuters</affiliation></author>
      <author><first>Frank</first><last>Schilder</last><affiliation>Thomson Reuters</affiliation></author>
      <pages>13582-13596</pages>
      <abstract>The use of large language models (LLMs) for zero- or few-shot prompting in natural language processing has given rise to a new research area known as prompt engineering. Recent studies have demonstrated that Chain-of-Thought (CoT) prompts can lead to significant improvements in tasks such as arithmetic and common-sense reasoning. This paper explores the use of such approaches in legal reasoning tasks by conducting experiments on the COLIEE entailment task, which is based on the Japanese Bar exam. We evaluate zero-shot/few-shot and fine-tuning approaches with and without explanations, as well as various prompting strategies. Our results indicate that while CoT prompting and fine-tuning with explanations can improve performance, the best results are achieved with prompts derived from specific legal reasoning techniques, such as IRAC (Issue, Rule, Application, Conclusion). In addition, we observe that few-shot learning where the demonstrations are derived from clustering past training data consistently yields high performance on the COLIEE entailment task for both the years of the data that we tested. Through our experiments, we improve the previous best result on the 2021 COLIEE task from 0.7037 to 0.8025 and surpass the best system from 2022 with an accuracy of 0.789.</abstract>
      <url hash="c0b10fe0">2023.findings-acl.858</url>
      <bibkey>yu-etal-2023-exploring</bibkey>
      <doi>10.18653/v1/2023.findings-acl.858</doi>
    </paper>
    <paper id="859">
      <title>End-to-end Aspect-based Sentiment Analysis with <fixed-case>C</fixed-case>ombinatory <fixed-case>C</fixed-case>ategorial <fixed-case>G</fixed-case>rammar</title>
      <author><first>Yuanhe</first><last>Tian</last><affiliation>Department of Linguistics, University of Washington</affiliation></author>
      <author><first>Weidong</first><last>Chen</last><affiliation>University of Science and Technology of China</affiliation></author>
      <author><first>Bo</first><last>Hu</last><affiliation>University of Science and Technology of China</affiliation></author>
      <author><first>Yan</first><last>Song</last><affiliation>USTC</affiliation></author>
      <author><first>Fei</first><last>Xia</last><affiliation>University of Washington</affiliation></author>
      <pages>13597-13609</pages>
      <abstract>End-to-end Aspect-based Sentiment Analysis (EASA) is a natural language processing (NLP) task that involves extracting aspect terms and identifying the sentiments for them, which provides a fine-grained level of text analysis and thus requires a deep understanding of the running text. Many previous studies leverage advanced text encoders to extract context information and use syntactic information, e.g., the dependency structure of the input sentence, to improve the model performance. However, such models may reach a bottleneck since the dependency structure is not designed to provide semantic information of the text, which is also important for identifying the sentiment and thus leave room for further improvement. Considering that combinatory categorial grammar (CCG) is a formalism that expresses both syntactic and semantic information of a sentence, it has the potential to be beneficial to EASA. In this paper, we propose a novel approach to improve EASA with CCG supertags, which carry the syntactic and semantic information of the associated words and serve as the most important part of the CCG derivation. Specifically, our approach proposes a CCG supertag decoding process to learn the syntactic and semantic information carried by CCG supertags and use the information to guide the attention over the input words so as to identify important contextual information for EASA. Furthermore, a gate mechanism is used in incorporating the weighted contextual information into the backbone EASA decoding process. We evaluate our approach on three publicly available English datasets for EASA, and show that it outperforms strong baselines and achieves state-of-the-art results on all datasets.</abstract>
      <url hash="abf03aca">2023.findings-acl.859</url>
      <bibkey>tian-etal-2023-end</bibkey>
      <doi>10.18653/v1/2023.findings-acl.859</doi>
    </paper>
    <paper id="860">
      <title><fixed-case>C</fixed-case>on<fixed-case>KI</fixed-case>: Contrastive Knowledge Injection for Multimodal Sentiment Analysis</title>
      <author><first>Yakun</first><last>Yu</last><affiliation>University of Alberta</affiliation></author>
      <author><first>Mingjun</first><last>Zhao</last><affiliation>University of Alberta</affiliation></author>
      <author><first>Shi-ang</first><last>Qi</last><affiliation>University of Alberta</affiliation></author>
      <author><first>Feiran</first><last>Sun</last><affiliation>Tencent</affiliation></author>
      <author><first>Baoxun</first><last>Wang</last><affiliation>Tencent</affiliation></author>
      <author><first>Weidong</first><last>Guo</last><affiliation>Tencent</affiliation></author>
      <author><first>Xiaoli</first><last>Wang</last><affiliation>Tencent</affiliation></author>
      <author><first>Lei</first><last>Yang</last><affiliation>Tencent</affiliation></author>
      <author><first>Di</first><last>Niu</last><affiliation>University of Alberta</affiliation></author>
      <pages>13610-13624</pages>
      <abstract>Multimodal Sentiment Analysis leverages multimodal signals to detect the sentiment of a speaker. Previous approaches concentrate on performing multimodal fusion and representation learning based on general knowledge obtained from pretrained models, which neglects the effect of domain-specific knowledge. In this paper, we propose Contrastive Knowledge Injection (ConKI) for multimodal sentiment analysis, where specific-knowledge representations for each modality can be learned together with general knowledge representations via knowledge injection based on an adapter architecture. In addition, ConKI uses a hierarchical contrastive learning procedure performed between knowledge types within every single modality, across modalities within each sample, and across samples to facilitate the effective learning of the proposed representations, hence improving multimodal sentiment predictions. The experiments on three popular multimodal sentiment analysis benchmarks show that ConKI outperforms all prior methods on a variety of performance metrics.</abstract>
      <url hash="bffc3874">2023.findings-acl.860</url>
      <bibkey>yu-etal-2023-conki</bibkey>
      <doi>10.18653/v1/2023.findings-acl.860</doi>
    </paper>
    <paper id="861">
      <title>On Degrees of Freedom in Defining and Testing Natural Language Understanding</title>
      <author><first>Saku</first><last>Sugawara</last><affiliation>National Institute of Informatics</affiliation></author>
      <author><first>Shun</first><last>Tsugita</last><affiliation>Nagoya University</affiliation></author>
      <pages>13625-13649</pages>
      <abstract>Natural language understanding (NLU) studies often exaggerate or underestimate the capabilities of systems, thereby limiting the reproducibility of their findings. These erroneous evaluations can be attributed to the difficulty of defining and testing NLU adequately. In this position paper, we reconsider this challenge by identifying two types of researcher degrees of freedom. We revisit Turing’s original interpretation of the Turing test and reveal that an effective test of NLU does not provide an operational definition; it merely provides inductive evidence that the test subject understands the language sufficiently well to meet stakeholder objectives. In other words, stakeholders are free to arbitrarily define NLU through their objectives. To use the test results as inductive evidence, stakeholders must carefully assess if the interpretation of test scores is valid or not. However, designing and using NLU tests involve other degrees of freedom, such as specifying target skills and defining evaluation metrics. As a result, achieving consensus among stakeholders becomes difficult. To resolve this issue, we propose a validity argument, which is a framework comprising a series of validation criteria across test components. By demonstrating that current practices in NLU studies can be associated with those criteria and organizing them into a comprehensive checklist, we prove that the validity argument can serve as a coherent guideline for designing credible test sets and facilitating scientific communication.</abstract>
      <url hash="85c301c6">2023.findings-acl.861</url>
      <bibkey>sugawara-tsugita-2023-degrees</bibkey>
      <doi>10.18653/v1/2023.findings-acl.861</doi>
    </paper>
    <paper id="862">
      <title><fixed-case>A</fixed-case>tten<fixed-case>W</fixed-case>alker: Unsupervised Long-Document Question Answering via Attention-based Graph Walking</title>
      <author><first>Yuxiang</first><last>Nie</last><affiliation>Beijing Institute of Technology</affiliation></author>
      <author><first>Heyan</first><last>Huang</last><affiliation>Beijing Institute of Technology</affiliation></author>
      <author><first>Wei</first><last>Wei</last><affiliation>Huazhong University of Science and Technology</affiliation></author>
      <author><first>Xian-Ling</first><last>Mao</last><affiliation>Beijing Institute of Technology</affiliation></author>
      <pages>13650-13663</pages>
      <abstract>Annotating long-document question answering (long-document QA) pairs is time-consuming and expensive. To alleviate the problem, it might be possible to generate long-document QA pairs via unsupervised question answering (UQA) methods. However, existing UQA tasks are based on short documents, and can hardly incorporate long-range information. To tackle the problem, we propose a new task, named unsupervised long-document question answering (ULQA), aiming to generate high-quality long-document QA instances in an unsupervised manner. Besides, we propose AttenWalker, a novel unsupervised method to aggregate and generate answers with long-range dependency so as to construct long-document QA pairs. Specifically, AttenWalker is composed of three modules, i.e. span collector, span linker and answer aggregator. Firstly, the span collector takes advantage of constituent parsing and reconstruction loss to select informative candidate spans for constructing answers. Secondly, with the help of the attention graph of a pre-trained long-document model, potentially interrelated text spans (that might be far apart) could be linked together via an attention-walking algorithm. Thirdly, in the answer aggregator, linked spans are aggregated into the final answer via the mask-filling ability of a pre-trained model. Extensive experiments show that AttenWalker outperforms previous methods on NarrativeQA and Qasper. In addition, AttenWalker also shows strong performance in the few-shot learning setting.</abstract>
      <url hash="5640a5f0">2023.findings-acl.862</url>
      <bibkey>nie-etal-2023-attenwalker</bibkey>
      <doi>10.18653/v1/2023.findings-acl.862</doi>
    </paper>
    <paper id="863">
      <title>Adaptive Ordered Information Extraction with Deep Reinforcement Learning</title>
      <author><first>Wenhao</first><last>Huang</last><affiliation>Fudan University</affiliation></author>
      <author><first>Jiaqing</first><last>Liang</last><affiliation>Fudan University</affiliation></author>
      <author><first>Zhixu</first><last>Li</last><affiliation>Fudan University</affiliation></author>
      <author><first>Yanghua</first><last>Xiao</last><affiliation>Fudan University</affiliation></author>
      <author><first>Chuanjun</first><last>Ji</last><affiliation>DataGrand Inc.</affiliation></author>
      <pages>13664-13678</pages>
      <abstract>Information extraction (IE) has been studied extensively. The existing methods always follow a fixed extraction order for complex IE tasks with multiple elements to be extracted in one instance such as event extraction. However, we conduct experiments on several complex IE datasets and observe that different extraction orders can significantly affect the extraction results for a great portion of instances, and the ratio of sentences that are sensitive to extraction orders increases dramatically with the complexity of the IE task. Therefore, this paper proposes a novel adaptive ordered IE paradigm to find the optimal element extraction order for different instances, so as to achieve the best extraction results. We also propose an reinforcement learning (RL) based framework to generate optimal extraction order for each instance dynamically. Additionally, we propose a co-training framework adapted to RL to mitigate the exposure bias during the extractor training phase. Extensive experiments conducted on several public datasets demonstrate that our proposed method can beat previous methods and effectively improve the performance of various IE tasks, especially for complex ones.</abstract>
      <url hash="1354d4ce">2023.findings-acl.863</url>
      <bibkey>huang-etal-2023-adaptive</bibkey>
      <doi>10.18653/v1/2023.findings-acl.863</doi>
    </paper>
    <paper id="864">
      <title><fixed-case>W</fixed-case>asserstein-Fisher-<fixed-case>R</fixed-case>ao Embedding: Logical Query Embeddings with Local Comparison and Global Transport</title>
      <author><first>Zihao</first><last>Wang</last><affiliation>HKUST</affiliation></author>
      <author><first>Weizhi</first><last>Fei</last><affiliation>Tsinghua University</affiliation></author>
      <author><first>Hang</first><last>Yin</last><affiliation>Tsinghua University</affiliation></author>
      <author><first>Yangqiu</first><last>Song</last><affiliation>HKUST</affiliation></author>
      <author><first>Ginny</first><last>Wong</last><affiliation>NVIDIA AI Technology Center</affiliation></author>
      <author><first>Simon</first><last>See</last><affiliation>nvidia</affiliation></author>
      <pages>13679-13696</pages>
      <abstract>Answering complex queries on knowledge graphs is important but particularly challenging because of the data incompleteness. Query embedding methods address this issue by learningbased models and simulating logical reasoning with set operators. Previous works focus on specific forms of embeddings, but scoring functions between embeddings are underexplored. In contrast to existing scorning functions motivated by local comparison or global transport, this work investigates the local and global trade-off with unbalanced optimal transport theory. Specifically, we embed sets as bounded measures in R endowed with a scoring function motivated by the Wasserstein-Fisher-Rao metric. Such a design also facilitates closed-form set operators in the embedding space. Moreover, we introduce a convolution-based algorithm for linear time computation and a block diagonal kernel to enforce the trade-off. Results show that WFRE is capable of outperforming existing query embedding methods on standard datasets, evaluation sets with combinatorially complex queries, and hierarchical knowledge graphs. Ablation study shows that finding a better local and global trade-off is essential for performance improvement.</abstract>
      <url hash="dfb7d043">2023.findings-acl.864</url>
      <bibkey>wang-etal-2023-wasserstein</bibkey>
      <doi>10.18653/v1/2023.findings-acl.864</doi>
    </paper>
    <paper id="865">
      <title><fixed-case>RISE</fixed-case>: Leveraging Retrieval Techniques for Summarization Evaluation</title>
      <author><first>David</first><last>Uthus</last><affiliation>Google Research</affiliation></author>
      <author><first>Jianmo</first><last>Ni</last><affiliation>Google</affiliation></author>
      <pages>13697-13709</pages>
      <abstract>Evaluating automatically-generated text summaries is a challenging task. While there have been many interesting approaches, they still fall short of human evaluations. We present RISE, a new approach for evaluating summaries by leveraging techniques from information retrieval. RISE is first trained as a retrieval task using a dual-encoder retrieval setup, and can then be subsequently utilized for evaluating a generated summary given an input document, without gold reference summaries. RISE is especially well suited when working on new datasets where one may not have reference summaries available for evaluation. We conduct comprehensive experiments on the SummEval benchmark (Fabbri et al., 2021) and a long document summarization benchmark. The results show that RISE consistently achieves higher correlation with human evaluations compared to many past approaches to summarization evaluation. Furthermore, RISE also demonstrates data-efficiency and generalizability across languages.</abstract>
      <url hash="97a47cb6">2023.findings-acl.865</url>
      <bibkey>uthus-ni-2023-rise</bibkey>
      <doi>10.18653/v1/2023.findings-acl.865</doi>
    </paper>
    <paper id="866">
      <title>On the Difference of <fixed-case>BERT</fixed-case>-style and <fixed-case>CLIP</fixed-case>-style Text Encoders</title>
      <author><first>Zhihong</first><last>Chen</last><affiliation>Shenzhen Research Institute of Big Data, The Chinese University of Hong Kong, Shenzhen</affiliation></author>
      <author><first>Guiming</first><last>Chen</last><affiliation>The Chinese University of Hong Kong, Shenzhen</affiliation></author>
      <author><first>Shizhe</first><last>Diao</last><affiliation>The Hong Kong University of Science and Technology</affiliation></author>
      <author><first>Xiang</first><last>Wan</last><affiliation>Shenzhen Research Institute of Big Data</affiliation></author>
      <author><first>Benyou</first><last>Wang</last><affiliation>The Chinese University of Hong Kong, Shenzhen</affiliation></author>
      <pages>13710-13721</pages>
      <abstract>Masked language modeling (MLM) has been one of the most popular pretraining recipes in natural language processing, <i>e.g.</i>, BERT, one of the representative models. Recently, contrastive language-image pretraining (CLIP) has also attracted attention, especially its vision models that achieve excellent performance on a broad range of vision tasks. However, few studies are dedicated to studying the text encoders learned by CLIP. In this paper, we analyze the difference between <i>BERT-style</i> and <i>CLIP-style</i> text encoders from three experiments: (i) general text understanding, (ii) vision-centric text understanding, and (iii) text-to-image generation. Experimental analyses show that although CLIP-style text encoders underperform BERT-style ones for general text understanding tasks, they are equipped with a unique ability, <i>i.e.</i>, <i>synesthesia</i>, for the cross-modal association, which is more similar to the senses of humans.</abstract>
      <url hash="3f9283d9">2023.findings-acl.866</url>
      <bibkey>chen-etal-2023-difference</bibkey>
      <doi>10.18653/v1/2023.findings-acl.866</doi>
    </paper>
    <paper id="867">
      <title>Model Interpretability and Rationale Extraction by Input Mask Optimization</title>
      <author><first>Marc</first><last>Brinner</last><affiliation>Bielefeld University</affiliation></author>
      <author><first>Sina</first><last>Zarrieß</last><affiliation>University of Bielefeld</affiliation></author>
      <pages>13722-13744</pages>
      <abstract>Concurrent with the rapid progress in neural network-based models in NLP, the need for creating explanations for the predictions of these black-box models has risen steadily. Yet, especially for complex inputs like texts or images, existing interpretability methods still struggle with deriving easily interpretable explanations that also accurately represent the basis for the model’s decision. To this end, we propose a new, model-agnostic method to generate extractive explanations for predictions made by neural networks, that is based on masking parts of the input which the model does not consider to be indicative of the respective class. The masking is done using gradient-based optimization combined with a new regularization scheme that enforces sufficiency, comprehensiveness, and compactness of the generated explanation. Our method achieves state-of-the-art results in a challenging paragraph-level rationale extraction task, showing that this task can be performed without training a specialized model. We further apply our method to image inputs and obtain high-quality explanations for image classifications, which indicates that the objectives for optimizing explanation masks in text generalize to inputs of other modalities.</abstract>
      <url hash="f5e08bde">2023.findings-acl.867</url>
      <bibkey>brinner-zarriess-2023-model</bibkey>
      <doi>10.18653/v1/2023.findings-acl.867</doi>
    </paper>
    <paper id="868">
      <title><fixed-case>N</fixed-case>usa<fixed-case>C</fixed-case>rowd: Open Source Initiative for <fixed-case>I</fixed-case>ndonesian <fixed-case>NLP</fixed-case> Resources</title>
      <author><first>Samuel</first><last>Cahyawijaya</last><affiliation>HKUST</affiliation></author>
      <author><first>Holy</first><last>Lovenia</last><affiliation>The Hong Kong University of Science and Technology</affiliation></author>
      <author><first>Alham Fikri</first><last>Aji</last><affiliation>MBZUAI</affiliation></author>
      <author><first>Genta</first><last>Winata</last><affiliation>Bloomberg</affiliation></author>
      <author><first>Bryan</first><last>Wilie</last><affiliation>The Hong Kong University of Science and Technology</affiliation></author>
      <author><first>Fajri</first><last>Koto</last><affiliation>MBZUAI</affiliation></author>
      <author><first>Rahmad</first><last>Mahendra</last><affiliation>Universitas Indonesia</affiliation></author>
      <author><first>Christian</first><last>Wibisono</last><affiliation>Institut Teknologi Bandung</affiliation></author>
      <author><first>Ade</first><last>Romadhony</last><affiliation>Telkom University</affiliation></author>
      <author><first>Karissa</first><last>Vincentio</last><affiliation>Universitas Multimedia Nusantara (Comp.Eng.)</affiliation></author>
      <author><first>Jennifer</first><last>Santoso</last><affiliation>University of Tsukuba</affiliation></author>
      <author><first>David</first><last>Moeljadi</last><affiliation>Kanda University of International Studies</affiliation></author>
      <author><first>Cahya</first><last>Wirawan</last><affiliation>AI-Research.id</affiliation></author>
      <author><first>Frederikus</first><last>Hudi</last><affiliation>Nara Institute of Science and Technology, WAP Tokushima Lab. of AI&amp;NLP</affiliation></author>
      <author><first>Muhammad Satrio</first><last>Wicaksono</last><affiliation>Independent</affiliation></author>
      <author><first>Ivan</first><last>Parmonangan</last><affiliation>Bina Nusantara University</affiliation></author>
      <author><first>Ika</first><last>Alfina</last><affiliation>Faculty of Computer Science, Universitas Indonesia</affiliation></author>
      <author><first>Ilham Firdausi</first><last>Putra</last><affiliation>Independent</affiliation></author>
      <author><first>Samsul</first><last>Rahmadani</last><affiliation>Bahasa.ai</affiliation></author>
      <author><first>Yulianti</first><last>Oenang</last><affiliation>ITB</affiliation></author>
      <author><first>Ali</first><last>Septiandri</last><affiliation>Nokia Bell Labs</affiliation></author>
      <author><first>James</first><last>Jaya</last><affiliation/></author>
      <author><first>Kaustubh</first><last>Dhole</last><affiliation>Emory University</affiliation></author>
      <author><first>Arie</first><last>Suryani</last><affiliation>STEI ITB</affiliation></author>
      <author><first>Rifki Afina</first><last>Putri</last><affiliation>KAIST</affiliation></author>
      <author><first>Dan</first><last>Su</last><affiliation>The Hong Kong University of Science and Technology</affiliation></author>
      <author><first>Keith</first><last>Stevens</last><affiliation>Surface Data</affiliation></author>
      <author><first>Made Nindyatama</first><last>Nityasya</last><affiliation>Independent</affiliation></author>
      <author><first>Muhammad</first><last>Adilazuarda</last><affiliation>Institut Teknologi Bandung</affiliation></author>
      <author><first>Ryan</first><last>Hadiwijaya</last><affiliation>Independent</affiliation></author>
      <author><first>Ryandito</first><last>Diandaru</last><affiliation>Institut Teknologi Bandung</affiliation></author>
      <author><first>Tiezheng</first><last>Yu</last><affiliation>The Hong Kong University of Science and Technology</affiliation></author>
      <author><first>Vito</first><last>Ghifari</last><affiliation>Institut Teknologi bandung</affiliation></author>
      <author><first>Wenliang</first><last>Dai</last><affiliation>Hong Kong University of Science and Technology</affiliation></author>
      <author><first>Yan</first><last>Xu</last><affiliation>Hong Kong University of Science and Technology</affiliation></author>
      <author><first>Dyah</first><last>Damapuspita</last><affiliation>Universitas Indonesia</affiliation></author>
      <author><first>Haryo</first><last>Wibowo</last><affiliation>Independent</affiliation></author>
      <author><first>Cuk</first><last>Tho</last><affiliation>Bina Nusantara University</affiliation></author>
      <author><first>Ichwanul</first><last>Karo Karo</last><affiliation>State University of Medan</affiliation></author>
      <author><first>Tirana</first><last>Fatyanosa</last><affiliation>Kumamoto University</affiliation></author>
      <author><first>Ziwei</first><last>Ji</last><affiliation>The Hong Kong University of Science and Technology</affiliation></author>
      <author><first>Graham</first><last>Neubig</last><affiliation>Carnegie Mellon University</affiliation></author>
      <author><first>Timothy</first><last>Baldwin</last><affiliation>MBZUAI</affiliation></author>
      <author><first>Sebastian</first><last>Ruder</last><affiliation>Google</affiliation></author>
      <author><first>Pascale</first><last>Fung</last><affiliation>Hong Kong University of Science and Technology</affiliation></author>
      <author><first>Herry</first><last>Sujaini</last><affiliation>Tanjungpura University</affiliation></author>
      <author><first>Sakriani</first><last>Sakti</last><affiliation>Japan Advanced Institute of Science and Technology / Nara Institute of Science and Technology (JAIST/NAIST)</affiliation></author>
      <author><first>Ayu</first><last>Purwarianti</last><affiliation>Bandung Institute of Technology</affiliation></author>
      <pages>13745-13818</pages>
      <abstract>We present NusaCrowd, a collaborative initiative to collect and unify existing resources for Indonesian languages, including opening access to previously non-public resources. Through this initiative, we have brought together 137 datasets and 118 standardized data loaders. The quality of the datasets has been assessed manually and automatically, and their value is demonstrated through multiple experiments.NusaCrowd’s data collection enables the creation of the first zero-shot benchmarks for natural language understanding and generation in Indonesian and the local languages of Indonesia. Furthermore, NusaCrowd brings the creation of the first multilingual automatic speech recognition benchmark in Indonesian and the local languages of Indonesia. Our work strives to advance natural language processing (NLP) research for languages that are under-represented despite being widely spoken.</abstract>
      <url hash="cb0b0bfe">2023.findings-acl.868</url>
      <bibkey>cahyawijaya-etal-2023-nusacrowd</bibkey>
      <revision id="1" href="2023.findings-acl.868v1" hash="c73cf784"/>
      <revision id="2" href="2023.findings-acl.868v2" hash="cb0b0bfe" date="2023-07-31">Fix incorrect affiliation in the author list.</revision>
      <doi>10.18653/v1/2023.findings-acl.868</doi>
    </paper>
    <paper id="869">
      <title>Transcribing Vocal Communications of Domestic Shiba lnu Dogs</title>
      <author><first>Jieyi</first><last>Huang</last><affiliation>Shanghai Jiao Tong University</affiliation></author>
      <author><first>Chunhao</first><last>Zhang</last><affiliation>Shanghai Jiao Tong University</affiliation></author>
      <author><first>Mengyue</first><last>Wu</last><affiliation>Shanghai Jiao Tong University</affiliation></author>
      <author><first>Kenny</first><last>Zhu</last><affiliation>Shanghai Jiao Tong University</affiliation></author>
      <pages>13819-13832</pages>
      <abstract>How animals communicate and whether they have languages is a persistent curiosity of human beings. However, the study of animal communications has been largely restricted to data from field recordings or in a controlled environment, which is expensive and limited in scale and variety. In this paper, we take domestic Shiba Inu dogs as an example, and extract their vocal communications from large amount of YouTube videos of Shiba Inu dogs. We classify these clips into different scenarios and locations, and further transcribe the audio into phonetically symbolic scripts through a systematic process. We discover consistent phonetic symbols among their expressions, which indicates that Shiba Inu dogs can have systematic verbal communication patterns. This reusable framework produces the first-of-its-kind Shiba Inu vocal communication dataset that will be valuable to future research in both zoology and linguistics.</abstract>
      <url hash="5682b24a">2023.findings-acl.869</url>
      <bibkey>huang-etal-2023-transcribing</bibkey>
      <doi>10.18653/v1/2023.findings-acl.869</doi>
    </paper>
    <paper id="870">
      <title><fixed-case>S</fixed-case>kill<fixed-case>QG</fixed-case>: Learning to Generate Question for Reading Comprehension Assessment</title>
      <author><first>Xiaoqiang</first><last>Wang</last><affiliation>Zhejiang University</affiliation></author>
      <author><first>Bang</first><last>Liu</last><affiliation>University of Montreal</affiliation></author>
      <author><first>Siliang</first><last>Tang</last><affiliation>Zhejiang University</affiliation></author>
      <author><first>Lingfei</first><last>Wu</last><affiliation>Pinterest</affiliation></author>
      <pages>13833-13850</pages>
      <abstract>We present SkillQG: a question generation framework with controllable comprehension types for assessing and improving machine reading comprehension models. Existing question generation systems widely differentiate questions by literal information such as question words and answer types to generate semantically relevant questions for a given context. However, they rarely consider the comprehension nature of questions, i.e., the different comprehension capabilities embodied by different questions. In comparison, our SkillQG is able to tailor a fine-grained assessment and improvement to the capabilities of questions answering models built on it. Specifically, we first frame the comprehension type of questions based on a hierarchical skill-based schema. We then formulate SkillQG as a skill-conditioned question generator. Furthermore, to improve the controllability of generation, we augment the input text with skill-specific question focus and knowledge, which are constructed by iteratively prompting the pre-trained language models. Empirical results demonstrate that SkillQG outperforms baselines in terms of quality, relevance, and skill-controllability while showing a promising performance boost in downstream question answering task.</abstract>
      <url hash="cedf3f3c">2023.findings-acl.870</url>
      <bibkey>wang-etal-2023-skillqg</bibkey>
      <doi>10.18653/v1/2023.findings-acl.870</doi>
    </paper>
    <paper id="871">
      <title>Improving Long Dialogue Summarization with Semantic Graph Representation</title>
      <author><first>Yilun</first><last>Hua</last><affiliation>Columbia University</affiliation></author>
      <author><first>Zhaoyuan</first><last>Deng</last><affiliation>Columbia University</affiliation></author>
      <author><first>Kathleen</first><last>McKeown</last><affiliation>Columbia University and Amazon (Amazon Scholar)</affiliation></author>
      <pages>13851-13883</pages>
      <abstract>Although Large Language Models (LLMs) are successful in abstractive summarization of short dialogues, summarization of long dialogues remains challenging. To address this challenge, we propose a novel algorithm that processes complete dialogues comprising thousands of tokens into topic-segment-level Abstract Meaning Representation (AMR) graphs, which explicitly capture the dialogue structure, highlight salient semantics, and preserve high-level information. We also develop a new text-graph attention to leverage both graph semantics and a pretrained LLM that exploits the text. Finally, we propose an AMR node selection loss used jointly with conventional cross-entropy loss, to create additional training signals that facilitate graph feature encoding and content selection. Experiments show that our system outperforms the state-of-the-art models on multiple long dialogue summarization datasets, especially in low-resource settings, and generalizes well to out-of-domain data.</abstract>
      <url hash="6025b100">2023.findings-acl.871</url>
      <bibkey>hua-etal-2023-improving</bibkey>
      <doi>10.18653/v1/2023.findings-acl.871</doi>
    </paper>
    <paper id="872">
      <title>Model Intrinsic Features of Fine-tuning based Text Summarization Models for Factual Consistency</title>
      <author><first>Jongyoon</first><last>Song</last><affiliation>Seoul National University</affiliation></author>
      <author><first>Nohil</first><last>Park</last><affiliation>Seoul National University</affiliation></author>
      <author><first>Bongkyu</first><last>Hwang</last><affiliation>SAMSUNG SDS Research</affiliation></author>
      <author><first>Jaewoong</first><last>Yun</last><affiliation>Samsung SDS</affiliation></author>
      <author><first>Seongho</first><last>Joe</last><affiliation>Samsung SDS</affiliation></author>
      <author><first>Youngjune</first><last>Gwon</last><affiliation>Samsung SDS</affiliation></author>
      <author><first>Sungroh</first><last>Yoon</last><affiliation>Seoul National University</affiliation></author>
      <pages>13884-13898</pages>
      <abstract>In this study, we analyze the model intrinsic features of a summarization model by varying the fine-tuning objectives and datasets. We fine-tune BART models combining three fine-tuning objectives (negative log-likelihood, unlikelihood, and contrastive loss) and two datasets (CNN/DailyMail and XSum) and provide shuffled or aligned documents to observe changes in the model predictions and intrinsic features. We find that (i) the inductive bias for factual consistency during the fine-tuning procedure depends on both the objectives and datasets, and (ii) summarization models with relatively low factual consistency are more likely to model summaries that are not conditional to the documents. We demonstrate that splitting data based on the unconditional and conditional summary modeling difficulty affects the factual consistency and intrinsic features of the summarization models. Our experimental results highlight the importance of studying the inductive bias during fine-tuning for factual consistency.</abstract>
      <url hash="05a9b294">2023.findings-acl.872</url>
      <bibkey>song-etal-2023-model</bibkey>
      <doi>10.18653/v1/2023.findings-acl.872</doi>
    </paper>
    <paper id="873">
      <title><fixed-case>E</fixed-case>fficient<fixed-case>VLM</fixed-case>: Fast and Accurate Vision-Language Models via Knowledge Distillation and Modal-adaptive Pruning</title>
      <author><first>Tiannan</first><last>Wang</last><affiliation>Beihang University</affiliation></author>
      <author><first>Wangchunshu</first><last>Zhou</last><affiliation>ETH Zurich</affiliation></author>
      <author><first>Yan</first><last>Zeng</last><affiliation>Bytedance AI Lab</affiliation></author>
      <author><first>Xinsong</first><last>Zhang</last><affiliation>Bytedance AI Lab</affiliation></author>
      <pages>13899-13913</pages>
      <abstract>Pre-trained vision-language models (VLMs) have achieved impressive results in a range of vision-language tasks. However, popular VLMs usually consist of hundreds of millions of parameters which brings challenges for fine-tuning and deployment in real-world applications due to space, memory, and latency constraints. In this work, we introduce a distilling then pruning framework to compress large vision-language models into smaller, faster, and more accurate ones. We first shrink the size ofa pre-trained large VLM and apply knowledge distillation in the vision-language pre-training stage to obtain a task-agnostic compact VLM. Then we propose a modal-adaptive pruning algorithm to automatically infer the importance of vision and language modalities for different downstream tasks and adaptively remove redundant structures and neurons in different encoders with controllable target sparsity. We apply our framework to train EfficientVLM, a fast and accurate vision-language model consisting of 6 vision layers, 3 text layers, and 3 cross-modal fusion layers, accounting for only 93 million parameters in total, which is 44.3% of the teacher model. EfficientVLM retains 98.4% performance of the teacher model and accelerates its inference speed by 2.2×. EfficientVLM achieves a large absolute improvement over previous SoTA efficient VLMs of similar sizes by a large margin on various vision-language tasks, including VQAv2 (+4.9%), NLVR2 (+5.6%), ITR (R@1 on TR +17.2%, on IR + 15.6% ) and COCO caption generation (CIDEr +6.5), demonstrating a large potential on training lightweight VLMs.</abstract>
      <url hash="1ef784cb">2023.findings-acl.873</url>
      <bibkey>wang-etal-2023-efficientvlm</bibkey>
      <doi>10.18653/v1/2023.findings-acl.873</doi>
    </paper>
    <paper id="874">
      <title><fixed-case>DP</fixed-case>-<fixed-case>BART</fixed-case> for Privatized Text Rewriting under Local Differential Privacy</title>
      <author><first>Timour</first><last>Igamberdiev</last><affiliation>Technical University of Darmstadt</affiliation></author>
      <author><first>Ivan</first><last>Habernal</last><affiliation>Technical University of Darmstadt</affiliation></author>
      <pages>13914-13934</pages>
      <abstract>Privatized text rewriting with local differential privacy (LDP) is a recent approach that enables sharing of sensitive textual documents while formally guaranteeing privacy protection to individuals. However, existing systems face several issues, such as formal mathematical flaws, unrealistic privacy guarantees, privatization of only individual words, as well as a lack of transparency and reproducibility. In this paper, we propose a new system ‘DP-BART’ that largely outperforms existing LDP systems. Our approach uses a novel clipping method, iterative pruning, and further training of internal representations which drastically reduces the amount of noise required for DP guarantees. We run experiments on five textual datasets of varying sizes, rewriting them at different privacy guarantees and evaluating the rewritten texts on downstream text classification tasks. Finally, we thoroughly discuss the privatized text rewriting approach and its limitations, including the problem of the strict text adjacency constraint in the LDP paradigm that leads to the high noise requirement.</abstract>
      <url hash="6b8364c1">2023.findings-acl.874</url>
      <bibkey>igamberdiev-habernal-2023-dp</bibkey>
      <doi>10.18653/v1/2023.findings-acl.874</doi>
    </paper>
    <paper id="875">
      <title>Robustness of Learning from Task Instructions</title>
      <author><first>Jiasheng</first><last>Gu</last><affiliation>University of Southern California</affiliation></author>
      <author><first>Hongyu</first><last>Zhao</last><affiliation>The University of Chicago</affiliation></author>
      <author><first>Hanzi</first><last>Xu</last><affiliation>Temple University</affiliation></author>
      <author><first>Liangyu</first><last>Nie</last><affiliation>University of Texas at Dallas</affiliation></author>
      <author><first>Hongyuan</first><last>Mei</last><affiliation>Toyota Technological Institute at Chicago</affiliation></author>
      <author><first>Wenpeng</first><last>Yin</last><affiliation>Pennsylvania State University</affiliation></author>
      <pages>13935-13948</pages>
      <abstract>Traditional supervised learning mostly works on individual tasks and requires training on a large set of task-specific examples. This paradigm seriously hinders the development of task generalization since preparing a task-specific example set is costly. To build a system that can quickly and easily generalize to new tasks, task instructions have been adopted as an emerging trend of supervision recently. These instructions give the model the definition of the task and allow the model to output the appropriate answer based on the instructions and inputs. However, task instructions are often expressed in different forms, which can be interpreted from two threads: first, some instructions are short sentences and are pretrained language model (PLM) oriented, such as prompts, while other instructions are paragraphs and are human-oriented, such as those in Amazon MTurk; second, different end-users very likely explain the same task with instructions of different textual expressions. A robust system for task generalization should be able to handle any new tasks regardless of the variability of instructions. However, the system robustness in dealing with instruction-driven task generalization is still unexplored. This work investigates the system robustness when the instructions of new tasks are (i) manipulated, (ii) paraphrased, or (iii) from different levels of conciseness. To our knowledge, this is the first work that systematically studies how robust a PLM is when it is supervised by instructions with different factors of variability.</abstract>
      <url hash="2200ab06">2023.findings-acl.875</url>
      <bibkey>gu-etal-2023-robustness</bibkey>
      <doi>10.18653/v1/2023.findings-acl.875</doi>
    </paper>
    <paper id="876">
      <title>Masked Latent Semantic Modeling: an Efficient Pre-training Alternative to Masked Language Modeling</title>
      <author><first>Gábor</first><last>Berend</last><affiliation>University Of Szeged</affiliation></author>
      <pages>13949-13962</pages>
      <abstract>In this paper, we propose an alternative to the classic masked language modeling (MLM) pre-training paradigm, where the objective is altered from the reconstruction of the exact identity of randomly selected masked subwords to the prediction of their latent semantic properties. We coin the proposed pre-training technique masked latent semantic modeling (MLSM for short). In order to make the contextualized determination of the latent semantic properties of the masked subwords possible, we rely on an unsupervised technique which uses sparse coding. Our experimental results reveal that the fine-tuned performance of those models that we pre-trained via MLSM is consistently and significantly better compared to the use of vanilla MLM pretraining and other strong baselines.</abstract>
      <url hash="5adf1cd5">2023.findings-acl.876</url>
      <bibkey>berend-2023-masked</bibkey>
      <doi>10.18653/v1/2023.findings-acl.876</doi>
    </paper>
    <paper id="877">
      <title>Detection and Mitigation of the Negative Impact of Dataset Extractivity on Abstractive Summarization</title>
      <author><first>Yubin</first><last>Ge</last><affiliation>University of Illinois, Urbana Champaign</affiliation></author>
      <author><first>Sullam</first><last>Jeoung</last><affiliation>UIUC</affiliation></author>
      <author><first>Ly</first><last>Dinh</last><affiliation>University of South Florida</affiliation></author>
      <author><first>Jana</first><last>Diesner</last><affiliation>UIUC</affiliation></author>
      <pages>13963-13976</pages>
      <abstract>In text summarization, extractivity is defined as a measurement of the degree of overlap between a source document and its summary. Previous research has shown that the extractivity level of training data can influence both output extractivity and the amount of factual information (i.e. faithfulness) in outputs for abstractive summarization. However, it remains unclear if and how extractivity impacts the performance of abstractive models. In this work, we investigate the relationship between dataset extractivity and model performance by comparing the performance of trained models under different degrees of extractivity. We find that while low levels of extractivity can improve performance, as extractivity increases, performance is negatively impacted. Furthermore, through an analysis of the model’s copy continuity of content, we discover that higher extractivity leads to a greater tendency for the model to copy text continuously from the source document rather than identifying and summarizing important content that should be covered in the target summary. To address these issues, we propose a simple and effective method to design copy labels for fixing the model’s copying behaviors and train the model with a copy mechanism. The experimental results illustrate the effectiveness of our strategy in alleviating the negative impact on model performance resulting from high dataset extractivity, and that our method outperforms several competitive baselines.</abstract>
      <url hash="92b4036c">2023.findings-acl.877</url>
      <bibkey>ge-etal-2023-detection</bibkey>
      <doi>10.18653/v1/2023.findings-acl.877</doi>
    </paper>
    <paper id="878">
      <title>Commonsense Knowledge Graph Completion Via Contrastive Pretraining and Node Clustering</title>
      <author><first>Siwei</first><last>Wu</last><affiliation>NanJing University of Science &amp; Technology</affiliation></author>
      <author><first>Xiangqing</first><last>Shen</last><affiliation>Nanjing University of Science and Technology</affiliation></author>
      <author><first>Rui</first><last>Xia</last><affiliation>Nanjing University of Science and Technology</affiliation></author>
      <pages>13977-13989</pages>
      <abstract>The nodes in the commonsense knowledge graph (CSKG) are normally represented by free-form short text (e.g., word or phrase). Different nodes may represent the same concept. This leads to the problems of edge sparsity and node redundancy, which challenges CSKG representation and completion. On the one hand, edge sparsity limits the performance of graph representation learning; On the other hand, node redundancy makes different nodes corresponding to the same concept have inconsistent relations with other nodes. To address the two problems, we propose a new CSKG completion framework based on Contrastive Pretraining and Node Clustering (CPNC). Contrastive Pretraining constructs positive and negative head-tail node pairs on CSKG and utilizes contrastive learning to obtain better semantic node representation. Node Clustering aggregates nodes with the same concept into a latent concept, assisting the task of CSKG completion. We evaluate our CPNC approach on two CSKG completion benchmarks (CN-100K and ATOMIC), where CPNC outperforms the state-of-the-art methods. Extensive experiments demonstrate that both Contrastive Pretraining and Node Clustering can significantly improve the performance of CSKG completion. The source code of CPNC is publicly available on <url>https://github.com/NUSTM/CPNC</url>.</abstract>
      <url hash="432df3d4">2023.findings-acl.878</url>
      <bibkey>wu-etal-2023-commonsense</bibkey>
      <doi>10.18653/v1/2023.findings-acl.878</doi>
    </paper>
    <paper id="879">
      <title>Incorporating Factuality Inference to Identify Document-level Event Factuality</title>
      <author><first>Heng</first><last>Zhang</last><affiliation>Soochow University</affiliation></author>
      <author><first>Peifeng</first><last>Li</last><affiliation>Soochow University</affiliation></author>
      <author><first>Zhong</first><last>Qian</last><affiliation>Soochow University</affiliation></author>
      <author><first>Xiaoxu</first><last>Zhu</last><affiliation>Soochow Univerisity</affiliation></author>
      <pages>13990-14002</pages>
      <abstract>Document-level Event Factuality Identification (DEFI) refers to identifying the degree of certainty that a specific event occurs in a document. Previous studies on DEFI failed to link the document-level event factuality with various sentence-level factuality values in the same document. In this paper, we innovatively propose an event factuality inference task to bridge the sentence-level and the document-level event factuality semantically. Specifically, we present a Sentence-to-Document Inference Network (SDIN) that contains a multi-layer interaction module and a gated aggregation module to integrate the above two tasks, and employ a multi-task learning framework to improve the performance of DEFI. The experimental results on the public English and Chinese DLEF datasets show that our model outperforms the SOTA baselines significantly.</abstract>
      <url hash="0492b299">2023.findings-acl.879</url>
      <bibkey>zhang-etal-2023-incorporating</bibkey>
      <doi>10.18653/v1/2023.findings-acl.879</doi>
    </paper>
    <paper id="880">
      <title>Hybrid and Collaborative Passage Reranking</title>
      <author><first>Zongmeng</first><last>Zhang</last><affiliation>University of Science and Technology of China</affiliation></author>
      <author><first>Wengang</first><last>Zhou</last><affiliation>University of Science and Technology of China</affiliation></author>
      <author><first>Jiaxin</first><last>Shi</last><affiliation>Huawei Cloud Computing Technologies</affiliation></author>
      <author><first>Houqiang</first><last>Li</last><affiliation>University of Science and Technology of China</affiliation></author>
      <pages>14003-14021</pages>
      <abstract>In passage retrieval system, the initial passage retrieval results may be unsatisfactory, which can be refined by a reranking scheme. Existing solutions to passage reranking focus on enriching the interaction between query and each passage separately, neglecting the context among the top-ranked passages in the initial retrieval list. To tackle this problem, we propose a Hybrid and Collaborative Passage Reranking (HybRank) method, which leverages the substantial similarity measurements of upstream retrievers for passage collaboration and incorporates the lexical and semantic properties of sparse and dense retrievers for reranking. Besides, built on off-the-shelf retriever features, HybRank is a plug-in reranker capable of enhancing arbitrary passage lists including previously reranked ones. Extensive experiments demonstrate the stable improvements of performance over prevalent retrieval and reranking methods, and verify the effectiveness of the core components of HybRank.</abstract>
      <url hash="a132b9ba">2023.findings-acl.880</url>
      <bibkey>zhang-etal-2023-hybrid</bibkey>
      <doi>10.18653/v1/2023.findings-acl.880</doi>
    </paper>
    <paper id="881">
      <title>Sentence Embedding Leaks More Information than You Expect: Generative Embedding Inversion Attack to Recover the Whole Sentence</title>
      <author><first>Haoran</first><last>Li</last><affiliation>Hong Kong University of Science and Technology</affiliation></author>
      <author><first>Mingshi</first><last>Xu</last><affiliation>Hong Kong University of Science and Technology</affiliation></author>
      <author><first>Yangqiu</first><last>Song</last><affiliation>HKUST</affiliation></author>
      <pages>14022-14040</pages>
      <abstract>Sentence-level representations are beneficial for various natural language processing tasks. It is commonly believed that vector representations can capture rich linguistic properties. Currently, large language models (LMs) achieve state-of-the-art performance on sentence embedding. However, some recent works suggest that vector representations from LMs can cause information leakage. In this work, we further investigate the information leakage issue and propose a generative embedding inversion attack (GEIA) that aims to reconstruct input sequences based only on their sentence embeddings. Given the black-box access to a language model, we treat sentence embeddings as initial tokens’ representations and train or fine-tune a powerful decoder model to decode the whole sequences directly. We conduct extensive experiments to demonstrate that our generative inversion attack outperforms previous embedding inversion attacks in classification metrics and generates coherent and contextually similar sentences as the original inputs.</abstract>
      <url hash="eeaf644d">2023.findings-acl.881</url>
      <bibkey>li-etal-2023-sentence</bibkey>
      <doi>10.18653/v1/2023.findings-acl.881</doi>
    </paper>
    <paper id="882">
      <title>Learning Query Adaptive Anchor Representation for Inductive Relation Prediction</title>
      <author><first>Zhiwen</first><last>Xie</last><affiliation>School of Computer Science, Wuhan University</affiliation></author>
      <author><first>Yi</first><last>Zhang</last><affiliation>+86 13296663168</affiliation></author>
      <author><first>Jin</first><last>Liu</last><affiliation>School of Computer Science, Wuhan University</affiliation></author>
      <author><first>Guangyou</first><last>Zhou</last><affiliation>School of Computer Science, Central China Normal University</affiliation></author>
      <author><first>Jimmy</first><last>Huang</last><affiliation>School of Information Technology, York University</affiliation></author>
      <pages>14041-14053</pages>
      <abstract>Relation prediction on knowledge graphs (KGs) attempts to infer the missing links between entities. Most previous studies are limited to the transductive setting where all entities must be seen during the training, making them unable to perform reasoning on emerging entities. Recently, the inductive setting is proposed to handle the entities in the test phase to be unseen during training, However, it suffers from the inefficient reasoning under the enclosing subgraph extraction issue and the lack of effective entity-independent feature modeling. To this end, we propose a novel Query Adaptive Anchor Representation (QAAR) model for inductive relation prediction. First, we extract one opening subgraph and perform reasoning by one time for all candidate triples, which is more efficient when the number of candidate triples is large. Second, we define some query adaptive anchors which are independent on any specific entity. Based on these anchors, we take advantage of the transferable entity-independent features (relation-aware, structure-aware and distance features) that can be used to produce entity embeddings for emerging unseen entities. Such entity-independent features is modeled by a query-aware graph attention network on the opening subgraph. Experimental results demonstrate that our proposed QAAR outperforms state-of-the-art baselines in inductive relation prediction task.</abstract>
      <url hash="d64b2fbf">2023.findings-acl.882</url>
      <bibkey>xie-etal-2023-learning</bibkey>
      <doi>10.18653/v1/2023.findings-acl.882</doi>
    </paper>
    <paper id="883">
      <title>Context or Knowledge is Not Always Necessary: A Contrastive Learning Framework for Emotion Recognition in Conversations</title>
      <author><first>Geng</first><last>Tu</last><affiliation>Harbin Institute of Technology (Shenzhen)</affiliation></author>
      <author><first>Bin</first><last>Liang</last><affiliation>Harbin Institute of Technology, Shenzhen</affiliation></author>
      <author><first>Ruibin</first><last>Mao</last><affiliation>Shenzhen Securities Information Co., Ltd.</affiliation></author>
      <author><first>Min</first><last>Yang</last><affiliation>Chinese Academy of Sciences</affiliation></author>
      <author><first>Ruifeng</first><last>Xu</last><affiliation>Harbin Institute of Technology, Shenzhen</affiliation></author>
      <pages>14054-14067</pages>
      <abstract>Emotion recognition in conversations (ERC) aims to detect the emotion of utterances in conversations. Existing efforts generally focus on modeling context- and knowledge-sensitive dependencies. However, it is observed that the emotions of many utterances can be correctly detected without context or external knowledge. In such cases, blindly leveraging the context and external knowledge may impede model training. Based on this, we propose a novel framework based on contrastive learning (CL), called CKCL (including the contrastive learning scenarios among Context and Knowledge), to distinguish the above utterances for better vector representations. The CKCL framework defines context- and knowledge-independent utterances, as the positive sample, whose predicted results are unchanged even masking context and knowledge representations, otherwise, the negative sample. This can obtain a latent feature reflecting the impact degree of context and external knowledge on predicted results, thus effectively denoising irrelevant context and knowledge during training. Experimental results on four datasets show the performance of CKCL-based models is significantly boosted and outperforms state-of-the-art methods.</abstract>
      <url hash="d3ea550b">2023.findings-acl.883</url>
      <bibkey>tu-etal-2023-context</bibkey>
      <doi>10.18653/v1/2023.findings-acl.883</doi>
    </paper>
    <paper id="884">
      <title>Exploring Speaker-Related Information in Spoken Language Understanding for Better Speaker Diarization</title>
      <author><first>Luyao</first><last>Cheng</last><affiliation>Alibaba Group</affiliation></author>
      <author><first>Siqi</first><last>Zheng</last><affiliation>Alibaba</affiliation></author>
      <author><first>Zhang</first><last>Qinglin</last><affiliation>Alibaba Group</affiliation></author>
      <author><first>Hui</first><last>Wang</last><affiliation>Speech Lab, Alibaba Group</affiliation></author>
      <author><first>Yafeng</first><last>Chen</last><affiliation>Alibaba Group</affiliation></author>
      <author><first>Qian</first><last>Chen</last><affiliation>Alibaba Group</affiliation></author>
      <pages>14068-14077</pages>
      <abstract>Speaker diarization is a classic task in speech processing and is crucial in multi-party scenarios such as meetings and conversations. Current mainstream speaker diarization approaches consider acoustic information only, which result in performance degradation when encountering adverse acoustic environment. In this paper, we propose methods to extract speaker-related information from semantic content in multi-party meetings, which, as we will show, can further benefit speaker diarization. We introduce two sub-tasks, Dialogue Detection and Speaker-Turn Detection, in which we effectively extract speaker information from conversational semantics. We also propose a simple yet effective algorithm to jointly model acoustic and semantic information and obtain speaker-identified texts. Experiments on both AISHELL-4 and AliMeeting datasets show that our method achieves consistent improvements over acoustic-only speaker diarization systems.</abstract>
      <url hash="ca1c9c39">2023.findings-acl.884</url>
      <bibkey>cheng-etal-2023-exploring</bibkey>
      <doi>10.18653/v1/2023.findings-acl.884</doi>
    </paper>
    <paper id="885">
      <title>Cross-Lingual Knowledge Distillation for Answer Sentence Selection in Low-Resource Languages</title>
      <author><first>Shivanshu</first><last>Gupta</last><affiliation>University of California Irvine</affiliation></author>
      <author><first>Yoshitomo</first><last>Matsubara</last><affiliation>Amazon Alexa AI</affiliation></author>
      <author><first>Ankit</first><last>Chadha</last><affiliation>Amazon</affiliation></author>
      <author><first>Alessandro</first><last>Moschitti</last><affiliation>Amazon</affiliation></author>
      <pages>14078-14092</pages>
      <abstract>While impressive performance has been achieved on the task of Answer Sentence Selection (AS2) for English, the same does not hold for languages that lack large labeled datasets. In this work, we propose Cross-Lingual Knowledge Distillation (CLKD) from a strong English AS2 teacher as a method to train AS2 models for low-resource languages in the tasks without the need of labeled data for the target language. To evaluate our method, we introduce 1) Xtr-WikiQA, a translation-based WikiQA dataset for 9 additional languages, and 2) TyDi-AS2, a multilingual AS2 dataset with over 70K questions spanning 8 typologically diverse languages. We conduct extensive experiments on Xtr-WikiQA and TyDi-AS2 with multiple teachers, diverse monolingual and multilingual pretrained language models (PLMs) as students, and both monolingual and multilingual training. The results demonstrate that CLKD either outperforms or rivals even supervised fine-tuning with the same amount of labeled data and a combination of machine translation and the teacher model. Our method can potentially enable stronger AS2 models for low-resource languages, while TyDi-AS2 can serve as the largest multilingual AS2 dataset for further studies in the research community.</abstract>
      <url hash="3f74048b">2023.findings-acl.885</url>
      <bibkey>gupta-etal-2023-cross</bibkey>
      <doi>10.18653/v1/2023.findings-acl.885</doi>
    </paper>
    <paper id="886">
      <title>Run Like a Girl! Sport-Related Gender Bias in Language and Vision</title>
      <author><first>Sophia</first><last>Harrison</last><affiliation>Universitat Pompeu Fabra</affiliation></author>
      <author><first>Eleonora</first><last>Gualdoni</last><affiliation>Universitat Pompeu Fabra</affiliation></author>
      <author><first>Gemma</first><last>Boleda</last><affiliation>Universitat Pompeu Fabra / ICREA</affiliation></author>
      <pages>14093-14103</pages>
      <abstract>Gender bias in Language and Vision datasets and models has the potential to perpetuate harmful stereotypes and discrimination. We analyze gender bias in two Language and Vision datasets. Consistent with prior work, we find that both datasets underrepresent women, which promotes their invisibilization. Moreover, we hypothesize and find that a bias affects human naming choices for people playing sports: speakers produce names indicating the sport (e.g. “tennis player” or “surfer”) more often when it is a man or a boy participating in the sport than when it is a woman or a girl, with an average of 46% vs. 35% of sports-related names for each gender. A computational model trained on these naming data reproduces thebias. We argue that both the data and the model result in representational harm against women.</abstract>
      <url hash="0f7685b2">2023.findings-acl.886</url>
      <bibkey>harrison-etal-2023-run</bibkey>
      <doi>10.18653/v1/2023.findings-acl.886</doi>
    </paper>
    <paper id="887">
      <title>People and Places of Historical <fixed-case>E</fixed-case>urope: Bootstrapping Annotation Pipeline and a New Corpus of Named Entities in Late Medieval Texts</title>
      <author><first>Vit</first><last>Novotny</last><affiliation>Faculty of Informatics, Masaryk University</affiliation></author>
      <author><first>Kristina</first><last>Luger</last><affiliation>Masaryk University</affiliation></author>
      <author><first>Michal</first><last>Štefánik</last><affiliation>Masaryk University</affiliation></author>
      <author><first>Tereza</first><last>Vrabcova</last><affiliation>Masaryk University, Faculty of Informatics</affiliation></author>
      <author><first>Ales</first><last>Horak</last><affiliation>Masaryk University</affiliation></author>
      <pages>14104-14113</pages>
      <abstract>Although pre-trained named entity recognition (NER) models are highly accurate on modern corpora, they underperform on historical texts due to differences in language OCR errors. In this work, we develop a new NER corpus of 3.6M sentences from late medieval charters written mainly in Czech, Latin, and German.We show that we can start with a list of known historical figures and locations and an unannotated corpus of historical texts, and use information retrieval techniques to automatically bootstrap a NER-annotated corpus. Using our corpus, we train a NER model that achieves entity-level Precision of 72.81–93.98% with 58.14–81.77% Recall on a manually-annotated test dataset. Furthermore, we show that using a weighted loss function helps to combat class imbalance in token classification tasks. To make it easy for others to reproduce and build upon our work, we publicly release our corpus, models, and experimental code.</abstract>
      <url hash="499115b9">2023.findings-acl.887</url>
      <bibkey>novotny-etal-2023-people</bibkey>
      <doi>10.18653/v1/2023.findings-acl.887</doi>
    </paper>
    <paper id="888">
      <title>Check-<fixed-case>COVID</fixed-case>: Fact-Checking <fixed-case>COVID</fixed-case>-19 News Claims with Scientific Evidence</title>
      <author><first>Gengyu</first><last>Wang</last><affiliation>Columbia University</affiliation></author>
      <author><first>Kate</first><last>Harwood</last><affiliation>Columbia University</affiliation></author>
      <author><first>Lawrence</first><last>Chillrud</last><affiliation>Northwestern University</affiliation></author>
      <author><first>Amith</first><last>Ananthram</last><affiliation>Columbia University</affiliation></author>
      <author><first>Melanie</first><last>Subbiah</last><affiliation>Columbia University</affiliation></author>
      <author><first>Kathleen</first><last>McKeown</last><affiliation>Columbia University and Amazon (Amazon Scholar)</affiliation></author>
      <pages>14114-14127</pages>
      <abstract>We present a new fact-checking benchmark, Check-COVID, that requires systems to verify claims about COVID-19 from news using evidence from scientific articles. This approach to fact-checking is particularly challenging as it requires checking internet text written in everyday language against evidence from journal articles written in formal academic language. Check-COVID contains 1, 504 expert-annotated news claims about the coronavirus paired with sentence-level evidence from scientific journal articles and veracity labels. It includes both extracted (journalist-written) and composed (annotator-written) claims. Experiments using both a fact-checking specific system and GPT-3.5, which respectively achieve F1 scores of 76.99 and 69.90 on this task, reveal the difficulty of automatically fact-checking both claim types and the importance of in-domain data for good performance. Our data and models are released publicly at <url>https://github.com/posuer/Check-COVID</url>.</abstract>
      <url hash="cd69710d">2023.findings-acl.888</url>
      <bibkey>wang-etal-2023-check-covid</bibkey>
      <doi>10.18653/v1/2023.findings-acl.888</doi>
    </paper>
    <paper id="889">
      <title>Early Exit with Disentangled Representation and Equiangular Tight Frame</title>
      <author><first>Yixin</first><last>Ji</last><affiliation>Soochow University</affiliation></author>
      <author><first>Jikai</first><last>Wang</last><affiliation>Soochow University</affiliation></author>
      <author><first>Juntao</first><last>Li</last><affiliation>Soochow University</affiliation></author>
      <author><first>Qiang</first><last>Chen</last><affiliation>alibaba group</affiliation></author>
      <author><first>Wenliang</first><last>Chen</last><affiliation>Soochow University</affiliation></author>
      <author><first>Min</first><last>Zhang</last><affiliation>Harbin Institute of Technology (Shenzhen)</affiliation></author>
      <pages>14128-14142</pages>
      <abstract>Dynamic early exit has demonstrated great potential in coping with the sharply increasing number of pre-trained language model parameters, which can achieve a good trade-off between performance and efficiency. The existing early exit paradigm relies on training parametrical internal classifiers at each intermediate layer to complete specific tasks. Based on the predictions of these internal classifiers, different methods are designed to decide when to exit. Under this circumstance, each intermediate layer takes on both generic language representation learning and task-specific feature extraction, which makes each intermediate layer struggle to balance two types of backward loss signals during training. To break this dilemma, we propose an adapter method to decouple the two distinct types of representation and further introduce a non-parametric simplex equiangular tight frame classifier (ETF) for improvement. Extensive experiments on monolingual and multilingual tasks demonstrate that our method gains significant improvements over strong PLM backbones and early exit methods.</abstract>
      <url hash="bf3efbc5">2023.findings-acl.889</url>
      <bibkey>ji-etal-2023-early</bibkey>
      <doi>10.18653/v1/2023.findings-acl.889</doi>
    </paper>
    <paper id="890">
      <title>Tokenization with Factorized Subword Encoding</title>
      <author><first>David</first><last>Samuel</last><affiliation>University of Oslo, Language Technology Group</affiliation></author>
      <author><first>Lilja</first><last>Øvrelid</last><affiliation>Dept of Informatics, University of Oslo</affiliation></author>
      <pages>14143-14161</pages>
      <abstract>In recent years, language models have become increasingly larger and more complex. However, the input representations for these models continue to rely on simple and greedy subword tokenization methods. In this paper, we propose a novel tokenization method that factorizes subwords onto discrete triplets using a VQ-VAE model. The effectiveness of the proposed tokenization method, referred to as the Factorizer, is evaluated on language modeling and morpho-syntactic tasks for 7 diverse languages. Results indicate that this method is more appropriate and robust for morphological tasks than the commonly used byte-pair encoding (BPE) tokenization algorithm.</abstract>
      <url hash="0b75f237">2023.findings-acl.890</url>
      <bibkey>samuel-ovrelid-2023-tokenization</bibkey>
      <doi>10.18653/v1/2023.findings-acl.890</doi>
    </paper>
    <paper id="891">
      <title>Rarely a problem? Language models exhibit inverse scaling in their predictions following few-type quantifiers</title>
      <author><first>James</first><last>Michaelov</last><affiliation>Department of Cognitive Science, University of California San Diego</affiliation></author>
      <author><first>Benjamin</first><last>Bergen</last><affiliation>UC San Diego</affiliation></author>
      <pages>14162-14174</pages>
      <abstract>How well do language models deal with quantification? In this study, we focus on ‘few’-type quantifiers, as in ‘few children like toys’, which might pose a particular challenge for language models because the sentence components with out the quantifier are likely to co-occur, and ‘few’-type quantifiers are rare. We present 960 English sentence stimuli from two human neurolinguistic experiments to 22 autoregressive transformer models of differing sizes. Not only do all the models perform poorly on ‘few’-type quantifiers, but overall the larger the model, the worse its performance. This inverse scaling is consistent with previous work suggesting that larger models increasingly reflect online rather than offline human processing, and we argue that the decreasing performance of larger models may challenge uses of language models as the basis for natural language systems.</abstract>
      <url hash="ff900f45">2023.findings-acl.891</url>
      <bibkey>michaelov-bergen-2023-rarely</bibkey>
      <doi>10.18653/v1/2023.findings-acl.891</doi>
    </paper>
    <paper id="892">
      <title>“A Little is Enough”: Few-Shot Quality Estimation based Corpus Filtering improves Machine Translation</title>
      <author><first>Akshay</first><last>Batheja</last><affiliation>Indian Institute of Technology Bombay</affiliation></author>
      <author><first>Pushpak</first><last>Bhattacharyya</last><affiliation>Indian Institute of Technology Bombay and Patna</affiliation></author>
      <pages>14175-14185</pages>
      <abstract>Quality Estimation (QE) is the task of evaluating the quality of a translation when reference translation is not available. The goal of QE aligns with the task of corpus filtering, where we assign the quality score to the sentence pairs present in the pseudo-parallel corpus. We propose a Quality Estimation based Filtering approach to extract high-quality parallel data from the pseudo-parallel corpus. To the best of our knowledge, this is a novel adaptation of QE framework to extracting quality parallel corpus from the pseudo-parallel corpus.. By training with this filtered corpus, we observe an improvement in the Machine Translation (MT) system’s performance by up to 1.8 BLEU points, for English-Marathi, Chinese-English, and Hindi-Bengali language pairs, over the baseline model. The baseline model is the one that is trained on the whole pseudo-parallel corpus. Our Few-shot QE model transfer learned from the English-Marathi QE model and fine-tuned on only 500 Hindi-Bengali training instances, shows an improvement of up to 0.6 BLEU points for Hindi-Bengali language pair, compared to the baseline model. This demonstrates the promise of transfer learning in the setting under discussion. QE systems typically require in the order of (7K-25K) of training data. Our Hindi-Bengali QE is trained on only 500 instances of training that is 1/40th of the normal requirement and achieves comparable performance. All the scripts and datasets utilized in this study will be publicly available.</abstract>
      <url hash="2991f306">2023.findings-acl.892</url>
      <bibkey>batheja-bhattacharyya-2023-little</bibkey>
      <doi>10.18653/v1/2023.findings-acl.892</doi>
    </paper>
    <paper id="893">
      <title>How effective is machine translation on low-resource code-switching? A case study comparing human and automatic metrics</title>
      <author><first>Li</first><last>Nguyen</last><affiliation>University of Cambridge</affiliation></author>
      <author><first>Christopher</first><last>Bryant</last><affiliation>University of Cambridge</affiliation></author>
      <author><first>Oliver</first><last>Mayeux</last><affiliation>University of Cambridge</affiliation></author>
      <author><first>Zheng</first><last>Yuan</last><affiliation>King’s College London</affiliation></author>
      <pages>14186-14195</pages>
      <abstract>This paper presents an investigation into the differences between processing monolingual input and code-switching (CSW) input in the context of machine translation (MT). Specifically, we compare the performance of three MT systems (Google, mBART-50 and M2M-100-big) in terms of their ability to translate monolingual Vietnamese, a low-resource language, and Vietnamese-English CSW respectively. To our knowledge, this is the first study to systematically analyse what might happen when multilingual MT systems are exposed to CSW data using both automatic and human metrics. We find that state-of-the-art neural translation systems not only achieve higher scores on automatic metrics when processing CSW input (compared to monolingual input), but also produce translations that are consistently rated as more semantically faithful by humans. We further suggest that automatic evaluation alone is insufficient for evaluating the translation of CSW input. Our findings establish a new benchmark that offers insights into the relationship between MT and CSW.</abstract>
      <url hash="5139bf60">2023.findings-acl.893</url>
      <bibkey>nguyen-etal-2023-effective</bibkey>
      <doi>10.18653/v1/2023.findings-acl.893</doi>
    </paper>
    <paper id="894">
      <title>Images in Language Space: Exploring the Suitability of Large Language Models for Vision &amp; Language Tasks</title>
      <author><first>Sherzod</first><last>Hakimov</last><affiliation>University of Potsdam</affiliation></author>
      <author><first>David</first><last>Schlangen</last><affiliation>University of Potsdam</affiliation></author>
      <pages>14196-14210</pages>
      <abstract>Large language models have demonstrated robust performance on various language tasks using zero-shot or few-shot learning paradigms. While being actively researched, multimodal models that can additionally handle images as input have yet to catch up in size and generality with language-only models. In this work, we ask whether language-only models can be utilised for tasks that require visual input – but also, as we argue, often require a strong reasoning component. Similar to some recent related work, we make visual information accessible to the language model using separate verbalisation models. Specifically, we investigate the performance of open-source, open-access language models against GPT-3 on five vision-language tasks when given textually-encoded visual information. Our results suggest that language models are effective for solving vision-language tasks even with limited samples. This approach also enhances the interpretability of a model’s output by providing a means of tracing the output back through the verbalised image content.</abstract>
      <url hash="ed7f9667">2023.findings-acl.894</url>
      <bibkey>hakimov-schlangen-2023-images</bibkey>
      <doi>10.18653/v1/2023.findings-acl.894</doi>
    </paper>
    <paper id="895">
      <title>On the Expressivity Role of <fixed-case>L</fixed-case>ayer<fixed-case>N</fixed-case>orm in Transformers’ Attention</title>
      <author><first>Shaked</first><last>Brody</last><affiliation>Technion</affiliation></author>
      <author><first>Uri</first><last>Alon</last><affiliation>Carnegie Mellon University</affiliation></author>
      <author><first>Eran</first><last>Yahav</last><affiliation>Technion</affiliation></author>
      <pages>14211-14221</pages>
      <abstract>Layer Normalization (LayerNorm) is an inherent component in all Transformer-based models. In this paper, we show that LayerNorm is crucial to the expressivity of the multi-head attention layer that follows it. This is in contrast to the common belief that LayerNorm’s only role is to normalize the activations during the forward pass, and their gradients during the backward pass. We consider a geometric interpretation of LayerNorm and show that it consists of two components: (a) projection of the input vectors to a d-1 space that is orthogonal to the [1,1,...,1] vector, and(b) scaling of all vectors to the same norm of d. We show that each of these components is important for the attention layer that follows it in Transformers:(a) projection allows the attention mechanism to create an attention query that attends to all keys equally, offloading the need to learn this operation in the attention; and(b) scaling allows each key to potentially receive the highest attention, and prevents keys from being “un-select-able”.We show empirically that Transformers do indeed benefit from these properties of LayeNorm in general language modeling and even in computing simple functions such as “majority”. Our code is available at <url>https://github.com/tech-srl/layer_norm_expressivity_role</url> .</abstract>
      <url hash="4ae18798">2023.findings-acl.895</url>
      <bibkey>brody-etal-2023-expressivity</bibkey>
      <doi>10.18653/v1/2023.findings-acl.895</doi>
    </paper>
    <paper id="896">
      <title><fixed-case>DE</fixed-case>nsity: Open-domain Dialogue Evaluation Metric using Density Estimation</title>
      <author><first>ChaeHun</first><last>Park</last><affiliation>KAIST</affiliation></author>
      <author><first>Seungil</first><last>Lee</last><affiliation>KAIST</affiliation></author>
      <author><first>Daniel</first><last>Rim</last><affiliation>KAIST</affiliation></author>
      <author><first>Jaegul</first><last>Choo</last><affiliation>KAIST</affiliation></author>
      <pages>14222-14236</pages>
      <abstract>Despite the recent advances in open-domain dialogue systems, building a reliable evaluation metric is still a challenging problem. Recent studies proposed learnable metrics based on classification models trained to distinguish the correct response. However, neural classifiers are known to make overly confident predictions for examples from unseen distributions. We propose DENSITY, which evaluates a response by utilizing density estimation on the feature space derived from a neural classifier. Our metric measures how likely a response would appear in the distribution of human conversations. Moreover, to improve the performance of DENSITY, we utilize contrastive learning to further compress the feature space. Experiments on multiple response evaluation datasets show that DENSITY correlates better with human evaluations than the existing metrics.</abstract>
      <url hash="20ed36a8">2023.findings-acl.896</url>
      <bibkey>park-etal-2023-density</bibkey>
      <doi>10.18653/v1/2023.findings-acl.896</doi>
    </paper>
    <paper id="897">
      <title>Fixing <fixed-case>M</fixed-case>o<fixed-case>E</fixed-case> Over-Fitting on Low-Resource Languages in Multilingual Machine Translation</title>
      <author><first>Maha</first><last>Elbayad</last><affiliation>Meta AI</affiliation></author>
      <author><first>Anna</first><last>Sun</last><affiliation>Meta AI</affiliation></author>
      <author><first>Shruti</first><last>Bhosale</last><affiliation>Facebook AI Research</affiliation></author>
      <pages>14237-14253</pages>
      <abstract>Sparsely gated Mixture of Experts (MoE) models have been shown to be a compute-efficient method to scale model capacity for multilingual machine translation. However, for low-resource tasks, MoE models severely over-fit. We show effective regularization strategies, namely dropout techniques for MoE layers in EOM and FOM, Conditional MoE Routing and Curriculum Learning methods that prevent over-fitting and improve the performance of MoE models on low-resource tasks without adversely affecting high-resource tasks. On a massively multilingual machine translation benchmark, our strategies result in about +1 chrF++ improvement in very low resource language pairs. We perform an extensive analysis of the learned MoE routing to better understand the impact of our regularization methods and how we can improve them.</abstract>
      <url hash="075bd286">2023.findings-acl.897</url>
      <bibkey>elbayad-etal-2023-fixing</bibkey>
      <doi>10.18653/v1/2023.findings-acl.897</doi>
    </paper>
    <paper id="898">
      <title>Intent Discovery with Frame-guided Semantic Regularization and Augmentation</title>
      <author><first>Yajing</first><last>Sun</last><affiliation>huawei</affiliation></author>
      <author><first>Rui</first><last>Zhang</last><affiliation>Artificial Intelligence Application Research Center, Huawei Technologies</affiliation></author>
      <author><first>Jingyuan</first><last>Yang</last><affiliation>Artificial Intelligence Application Research Center, Huawei Technologies</affiliation></author>
      <author><first>Wei</first><last>Peng</last><affiliation>Artificial Intelligence Application Research Center, Huawei Technologies</affiliation></author>
      <pages>14254-14261</pages>
      <abstract>Most existing intent discovery methods leverage representation learning and clustering to transfer the prior knowledge of known intents to unknown ones. The learned representations are limited to the syntactic forms of sentences, therefore, fall short of recognizing adequate variations under the same meaning of unknown intents. This paper proposes an approach utilizing frame knowledge as conceptual semantic guidance to bridge the gap between known intents representation learning and unknown intents clustering. Specifically, we employ semantic regularization to minimize the bidirectional KL divergence between model predictions for frame-based and sentence-based samples. Moreover, we construct a frame-guided data augmenter to capture intent-friendly semantic information and implement contrastive clustering learning for unsupervised sentence embedding. Extensive experiments on two benchmark datasets show that our method achieves substantial improvements in accuracy (5%+) compared to solid baselines.</abstract>
      <url hash="9c2705c9">2023.findings-acl.898</url>
      <bibkey>sun-etal-2023-intent</bibkey>
      <doi>10.18653/v1/2023.findings-acl.898</doi>
    </paper>
    <paper id="899">
      <title>An Empirical Comparison of <fixed-case>LM</fixed-case>-based Question and Answer Generation Methods</title>
      <author><first>Asahi</first><last>Ushio</last><affiliation>Cardiff University</affiliation></author>
      <author><first>Fernando</first><last>Alva-Manchego</last><affiliation>Cardiff University</affiliation></author>
      <author><first>Jose</first><last>Camacho-Collados</last><affiliation>Cardiff University</affiliation></author>
      <pages>14262-14272</pages>
      <abstract>Question and answer generation (QAG) consists of generating a set of question-answer pairs given a context (e.g. a paragraph). This task has a variety of applications, such as data augmentation for question answering (QA) models, information retrieval and education. In this paper, we establish baselines with three different QAG methodologies that leverage sequence-to-sequence language model (LM) fine-tuning. Experiments show that an end-to-end QAG model, which is computationally light at both training and inference times, is generally robust and outperforms other more convoluted approaches. However, there are differences depending on the underlying generative LM. Finally, our analysis shows that QA models fine-tuned solely on generated question-answer pairs can be competitive when compared to supervised QA models trained on human-labeled data.</abstract>
      <url hash="65046546">2023.findings-acl.899</url>
      <bibkey>ushio-etal-2023-empirical</bibkey>
      <doi>10.18653/v1/2023.findings-acl.899</doi>
    </paper>
    <paper id="900">
      <title>Contrastive Learning with Generated Representations for Inductive Knowledge Graph Embedding</title>
      <author><first>Qian</first><last>Li</last><affiliation>Northeastern University</affiliation></author>
      <author><first>Shafiq</first><last>Joty</last><affiliation>Nanyang Technological University; Salesforce AI Research</affiliation></author>
      <author><first>Daling</first><last>Wang</last><affiliation>Northeastern University</affiliation></author>
      <author><first>Shi</first><last>Feng</last><affiliation>Northeastern University</affiliation></author>
      <author><first>Yifei</first><last>Zhang</last><affiliation>Northeastern University</affiliation></author>
      <author><first>Chengwei</first><last>Qin</last><affiliation>Nanyang Technological University</affiliation></author>
      <pages>14273-14287</pages>
      <abstract>With the evolution of Knowledge Graphs (KGs), new entities emerge which are not seen before. Representation learning of KGs in such an inductive setting aims to capture and transfer the structural patterns from existing entities to new entities. However, the performance of existing methods in inductive KGs are limited by sparsity and implicit transfer. In this paper, we propose VMCL, a Contrastive Learning (CL) framework with graph guided Variational autoencoder on Meta-KGs in the inductive setting. We first propose representation generation to capture the encoded and generated representations of entities, where the generated variations can densify representations with complementary features. Then, we design two CL objectives that work across entities and meta-KGs to simulate the transfer mode. With extensive experiments we demonstrate that our proposed VMCL can significantly outperform previous state-of-the-art baselines.</abstract>
      <url hash="514a9cda">2023.findings-acl.900</url>
      <bibkey>li-etal-2023-contrastive-learning</bibkey>
      <doi>10.18653/v1/2023.findings-acl.900</doi>
    </paper>
    <paper id="901">
      <title>Decouple knowledge from paramters for plug-and-play language modeling</title>
      <author><first>Xin</first><last>Cheng</last><affiliation>Peking University</affiliation></author>
      <author><first>Yankai</first><last>Lin</last><affiliation>Gaoling School of Artificial Intelligence, Renmin University of China</affiliation></author>
      <author><first>Xiuying</first><last>Chen</last><affiliation>KAUST</affiliation></author>
      <author><first>Dongyan</first><last>Zhao</last><affiliation>pku.edu.cn</affiliation></author>
      <author><first>Rui</first><last>Yan</last><affiliation>Renmin University of China</affiliation></author>
      <pages>14288-14308</pages>
      <abstract>Pre-trained language models (PLM) have made impressive results in a wide range of NLP tasks and it has been revealed that one of the key factors to their success is the parameters of these models implicitly learn various types of knowledge in the pre-training corpus. However, encoding knowledge implicitly in the model parameters has two fundamental drawbacks. First, the knowledge is neither editable nor scalable once the model is trained, which is especially problematic in that knowledge is consistently evolving. Second, it lacks interpretability and prevents us from understanding what kind of knowledge PLM needs to solve a certain task. In this paper, we introduce {pasted macro ‘MODEL’}, a pre-training model with differentiable plug-in memory (DPM). The key intuition behind is to decouple the knowledge storage from model parameters with an editable and scalable key-value memory and leverage knowledge in an explainable manner by knowledge retrieval in the {pasted macro ‘MEMORY’}. We conduct extensive experiments under various settings to justify this design choice. In domain adaptation setting, {pasted macro ‘MODEL’} could be easily adapted to different domains with pluggable in-domain memory—obtaining 3.95 F1 improvements across four domains, without any in-domain training. {pasted macro ‘MODEL’} could also keep absorbing new knowledge after pre-training is done by knowledge updating operation in the {pasted macro ‘MEMORY’} without re-training. Finally, we show that by incorporating training samples into {pasted macro ‘MEMORY’} with knowledge prompting, {pasted macro ‘MODEL’} could further be improved by the instruction of in-task knowledge.</abstract>
      <url hash="9f47f62f">2023.findings-acl.901</url>
      <bibkey>cheng-etal-2023-decouple</bibkey>
      <doi>10.18653/v1/2023.findings-acl.901</doi>
    </paper>
  </volume>
  <volume id="emnlp" ingest-date="2023-12-07" type="proceedings">
    <meta>
      <booktitle>Findings of the Association for Computational Linguistics: EMNLP 2023</booktitle>
      <editor><first>Houda</first><last>Bouamor</last></editor>
      <editor><first>Juan</first><last>Pino</last></editor>
      <editor><first>Kalika</first><last>Bali</last></editor>
      <publisher>Association for Computational Linguistics</publisher>
      <address>Singapore</address>
      <month>December</month>
      <year>2023</year>
      <venue>findings</venue>
    </meta>
    <frontmatter>
      <url hash="f05b36cc">2023.findings-emnlp.0</url>
      <bibkey>findings-2023</bibkey>
    </frontmatter>
    <paper id="1">
      <title>Multi Document Summarization Evaluation in the Presence of Damaging Content</title>
      <author><first>Avshalom</first><last>Manevich</last></author>
      <author><first>David</first><last>Carmel</last></author>
      <author><first>Nachshon</first><last>Cohen</last></author>
      <author><first>Elad</first><last>Kravi</last></author>
      <author><first>Ori</first><last>Shapira</last></author>
      <pages>1-12</pages>
      <abstract>In the Multi-document summarization (MDS) task, a summary is produced for a given set of documents. A recent line of research introduced the concept of damaging documents, denoting documents that should not be exposed to readers due to various reasons. In the presence of damaging documents, a summarizer is ideally expected to exclude damaging content in its output. Existing metrics evaluate a summary based on aspects such as relevance and consistency with the source documents. We propose to additionally measure the ability of MDS systems to properly handle damaging documents in their input set. To that end, we offer two novel metrics based on lexical similarity and language model likelihood. A set of experiments demonstrates the effectiveness of our metrics in measuring the ability of MDS systems to summarize a set of documents while eliminating damaging content from their summaries.</abstract>
      <url hash="33715106">2023.findings-emnlp.1</url>
      <bibkey>manevich-etal-2023-multi</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.1</doi>
    </paper>
    <paper id="2">
      <title>Guiding <fixed-case>AMR</fixed-case> Parsing with Reverse Graph Linearization</title>
      <author><first>Bofei</first><last>Gao</last></author>
      <author><first>Liang</first><last>Chen</last></author>
      <author><first>Peiyi</first><last>Wang</last></author>
      <author><first>Zhifang</first><last>Sui</last></author>
      <author><first>Baobao</first><last>Chang</last></author>
      <pages>13-26</pages>
      <abstract>Abstract Meaning Representation (AMR) parsing aims to extract an abstract semantic graph from a given sentence. The sequence-to-sequence approaches, which linearize the semantic graph into a sequence of nodes and edges and generate the linearized graph directly, have achieved good performance. However, we observed that these approaches suffer from structure loss accumulation during the decoding process, leading to a much lower F1-score for nodes and edges decoded later compared to those decoded earlier. To address this issue, we propose a novel Reverse Graph Linearization (RGL) enhanced framework. RGL defines both default and reverse linearization orders of an AMR graph, where most structures at the back part of the default order appear at the front part of the reversed order and vice versa. RGL incorporates the reversed linearization to the original AMR parser through a two-pass self-distillation mechanism, which guides the model when generating the default linearizations. Our analysis shows that our proposed method significantly mitigates the problem of structure loss accumulation, outperforming the previously best AMR parsing model by 0.8 and 0.5 Smatch scores on the AMR 2.0 and AMR 3.0 dataset, respectively. The code are available at <url>https://github.com/pkunlp-icler/AMR_reverse_graph_linearization</url>.</abstract>
      <url hash="3420d7c4">2023.findings-emnlp.2</url>
      <bibkey>gao-etal-2023-guiding</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.2</doi>
    </paper>
    <paper id="3">
      <title>Translate the Beauty in Songs: Jointly Learning to Align Melody and Translate Lyrics</title>
      <author><first>Chengxi</first><last>Li</last></author>
      <author><first>Kai</first><last>Fan</last></author>
      <author><first>Jiajun</first><last>Bu</last></author>
      <author><first>Boxing</first><last>Chen</last></author>
      <author><first>Zhongqiang</first><last>Huang</last></author>
      <author><first>Zhi</first><last>Yu</last></author>
      <pages>27-39</pages>
      <abstract>Song translation requires both translation of lyrics and alignment of music notes so that the resulting verse can be sung to the accompanying melody, which is a challenging problem that has attracted some interests in different aspects of the translation process. In this paper, we propose Lyrics-Melody Translation with Adaptive Grouping (LTAG), a holistic solution to automatic song translation by jointly modeling lyric translation and lyrics-melody alignment. It is a novel encoder-decoder framework that can simultaneously translate the source lyrics and determine the number of aligned notes at each decoding step through an adaptive note grouping module. To address data scarcity, we commissioned a small amount of training data annotated specifically for this task and used large amounts of automatic training data through back-translation. Experiments conducted on an English-Chinese song translation data set show the effectiveness of our model in both automatic and human evaluations.</abstract>
      <url hash="125204c1">2023.findings-emnlp.3</url>
      <bibkey>li-etal-2023-translate</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.3</doi>
    </paper>
    <paper id="4">
      <title>Aksharantar: Open <fixed-case>I</fixed-case>ndic-language Transliteration datasets and models for the Next Billion Users</title>
      <author><first>Yash</first><last>Madhani</last></author>
      <author><first>Sushane</first><last>Parthan</last></author>
      <author><first>Priyanka</first><last>Bedekar</last></author>
      <author><first>Gokul</first><last>Nc</last></author>
      <author><first>Ruchi</first><last>Khapra</last></author>
      <author><first>Anoop</first><last>Kunchukuttan</last></author>
      <author><first>Pratyush</first><last>Kumar</last></author>
      <author><first>Mitesh</first><last>Khapra</last></author>
      <pages>40-57</pages>
      <abstract>Transliteration is very important in the Indian language context due to the usage of multiple scripts and the widespread use of romanized inputs. However, few training and evaluation sets are publicly available. We introduce Aksharantar, the largest publicly available transliteration dataset for Indian languages created by mining from monolingual and parallel corpora, as well as collecting data from human annotators. The dataset contains 26 million transliteration pairs for 21 Indic languages from 3 language families using 12 scripts. Aksharantar is 21 times larger than existing datasets and is the first publicly available dataset for 7 languages and 1 language family. We also introduce a test set of 103k word pairs for 19 languages that enables a fine-grained analysis of transliteration models on native origin words, foreign words, frequent words, and rare words. Using the training set, we trained IndicXlit, a multilingual transliteration model that improves accuracy by 15% on the Dakshina test set, and establishes strong baselines on the Aksharantar testset introduced in this work. The models, mining scripts, transliteration guidelines, and datasets are available at https://github.com/AI4Bharat/IndicXlit under open-source licenses.</abstract>
      <url hash="a2690146">2023.findings-emnlp.4</url>
      <bibkey>madhani-etal-2023-aksharantar</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.4</doi>
    </paper>
    <paper id="5">
      <title>Pretraining Without Attention</title>
      <author><first>Junxiong</first><last>Wang</last></author>
      <author><first>Jing</first><last>Yan</last></author>
      <author><first>Albert</first><last>Gu</last></author>
      <author><first>Alexander</first><last>Rush</last></author>
      <pages>58-69</pages>
      <abstract>Transformers have been essential to pretraining success in NLP. While other architectures have been used, downstream accuracy is either significantly worse, or requires attention layers to match standard benchmarks such as GLUE. This work explores pretraining without attention by using recent advances in sequence routing based on state-space models (SSMs). Our proposed model, Bidirectional Gated SSM (BiGS), combines SSM layers with a multiplicative gating architecture that has been effective in simplified sequence modeling architectures. The model learns static layers that do not consider pair-wise interactions. Even so, BiGS is able to match BERT pretraining accuracy on GLUE and can be extended to long-form pretraining of 4096 tokens without approximation. Analysis shows that while the models have similar average accuracy, the approach has different inductive biases than BERT and scales more efficiently to longer sequences.</abstract>
      <url hash="034771f9">2023.findings-emnlp.5</url>
      <bibkey>wang-etal-2023-pretraining</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.5</doi>
    </paper>
    <paper id="6">
      <title>Time-Aware Representation Learning for Time-Sensitive Question Answering</title>
      <author><first>Jungbin</first><last>Son</last></author>
      <author><first>Alice</first><last>Oh</last></author>
      <pages>70-77</pages>
      <abstract>Time is one of the crucial factors in real-world question answering (QA) problems. However, language models have difficulty understanding the relationships between time specifiers, such as ‘after’ and ‘before’, and numbers, since existing QA datasets do not include sufficient time expressions. To address this issue, we propose a Time-Context aware Question Answering (TCQA) framework. We suggest a Time-Context dependent Span Extraction (TCSE) task, and build a time-context dependent data generation framework for model training. Moreover, we present a metric to evaluate the time awareness of the QA model using TCSE. The TCSE task consists of a question and four sentence candidates classified as correct or incorrect based on time and context. The model is trained to extract the answer span from the sentence that is both correct in time and context. The model trained with TCQA outperforms baseline models up to 8.5 of the F1-score in the TimeQA dataset. Our dataset and code are available at https://github.com/sonjbin/TCQA</abstract>
      <url hash="59a16b66">2023.findings-emnlp.6</url>
      <bibkey>son-oh-2023-time</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.6</doi>
    </paper>
    <paper id="7">
      <title><fixed-case>E</fixed-case>ff<fixed-case>E</fixed-case>val: A Comprehensive Evaluation of Efficiency for <fixed-case>MT</fixed-case> Evaluation Metrics</title>
      <author><first>Daniil</first><last>Larionov</last></author>
      <author><first>Jens</first><last>Grünwald</last></author>
      <author><first>Christoph</first><last>Leiter</last></author>
      <author><first>Steffen</first><last>Eger</last></author>
      <pages>78-96</pages>
      <abstract>Efficiency is a key property to foster inclusiveness and reduce environmental costs, especially in an era of LLMs. In this work, we provide a comprehensive evaluation of efficiency for MT evaluation metrics. Our approach involves replacing computation-intensive transformers with lighter alternatives and employing linear and quadratic approximations for alignment algorithms on top of LLM representations. We evaluate six (reference-free and reference-based) metrics across three MT datasets and examine 16 lightweight transformers. In addition, we look into the training efficiency of metrics like COMET by utilizing adapters. Our results indicate that (a) TinyBERT provides the optimal balance between quality and efficiency, (b) CPU speed-ups are more substantial than those on GPU; (c) WMD approximations yield no efficiency gains while reducing quality and (d) adapters enhance training efficiency (regarding backward pass speed and memory requirements) as well as, in some cases, metric quality. These findings can help to strike a balance between evaluation speed and quality, which is essential for effective NLG systems. Furthermore, our research contributes to the ongoing efforts to optimize NLG evaluation metrics with minimal impact on performance. To our knowledge, ours is the most comprehensive analysis of different aspects of efficiency for MT metrics conducted so far.</abstract>
      <url hash="207babd9">2023.findings-emnlp.7</url>
      <bibkey>larionov-etal-2023-effeval</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.7</doi>
    </paper>
    <paper id="8">
      <title>Unsupervised Opinion Summarization Using Approximate Geodesics</title>
      <author><first>Somnath</first><last>Basu Roy Chowdhury</last></author>
      <author><first>Nicholas</first><last>Monath</last></author>
      <author><first>Kumar</first><last>Dubey</last></author>
      <author><first>Amr</first><last>Ahmed</last></author>
      <author><first>Snigdha</first><last>Chaturvedi</last></author>
      <pages>97-112</pages>
      <abstract>Opinion summarization is the task of creating summaries capturing popular opinions from user reviews. In this paper, we introduce Geodesic Summarizer (GeoSumm), a novel system to perform unsupervised extractive opinion summarization. GeoSumm consists of an encoder-decoder based representation learning model that generates topical representations of texts. These representations capture the underlying semantics of the text as a distribution over learnable latent units. GeoSumm generates these topical representations by performing dictionary learning over pre-trained text representations at multiple layers of the decoder. We then use these topical representations to quantify the importance of review sentences using a novel approximate geodesic distance-based scoring mechanism. We use the importance scores to identify popular opinions in order to compose general and aspect-specific summaries. Our proposed model, GeoSumm, achieves strong performance on three opinion summarization datasets. We perform additional experiments to analyze the functioning of our model and showcase the generalization ability of GeoSumm across different domains.</abstract>
      <url hash="d9d0450f">2023.findings-emnlp.8</url>
      <bibkey>basu-roy-chowdhury-etal-2023-unsupervised-opinion</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.8</doi>
    </paper>
    <paper id="9">
      <title>Investigating the Frequency Distortion of Word Embeddings and Its Impact on Bias Metrics</title>
      <author><first>Francisco</first><last>Valentini</last></author>
      <author><first>Juan</first><last>Sosa</last></author>
      <author><first>Diego</first><last>Slezak</last></author>
      <author><first>Edgar</first><last>Altszyler</last></author>
      <pages>113-126</pages>
      <abstract>Recent research has shown that static word embeddings can encode words’ frequencies. However, little has been studied about this behavior. In the present work, we study how frequency and semantic similarity relate to one another in static word embeddings, and we assess the impact of this relationship on embedding-based bias metrics. We find that Skip-gram, GloVe and FastText embeddings tend to produce higher similarity between high-frequency words than between other frequency combinations. We show that the association between frequency and similarity also appears when words are randomly shuffled, and holds for different hyperparameter settings. This proves that the patterns we find are neither due to real semantic associations nor to specific parameters choices, and are an artifact produced by the word embeddings. To illustrate how frequencies can affect the measurement of biases related to gender, ethnicity, and affluence, we carry out a controlled experiment that shows that biases can even change sign or reverse their order when word frequencies change.</abstract>
      <url hash="2bc88af2">2023.findings-emnlp.9</url>
      <bibkey>valentini-etal-2023-investigating</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.9</doi>
    </paper>
    <paper id="10">
      <title>Improving Classifier Robustness through Active Generative Counterfactual Data Augmentation</title>
      <author><first>Ananth</first><last>Balashankar</last></author>
      <author><first>Xuezhi</first><last>Wang</last></author>
      <author><first>Yao</first><last>Qin</last></author>
      <author><first>Ben</first><last>Packer</last></author>
      <author><first>Nithum</first><last>Thain</last></author>
      <author><first>Ed</first><last>Chi</last></author>
      <author><first>Jilin</first><last>Chen</last></author>
      <author><first>Alex</first><last>Beutel</last></author>
      <pages>127-139</pages>
      <abstract>Counterfactual Data Augmentation (CDA) is a commonly used technique for improving robustness in natural language classifiers. However, one fundamental challenge is how to discover meaningful counterfactuals and efficiently label them, with minimal human labeling cost. Most existing methods either completely rely on human-annotated labels, an expensive process which limits the scale of counterfactual data, or implicitly assume label invariance, which may mislead the model with incorrect labels. In this paper, we present a novel framework that utilizes counterfactual generative models to generate a large number of diverse counterfactuals by actively sampling from regions of uncertainty, and then automatically label them with a learned auxiliary classifier. Our key insight is that we can more correctly label the generated counterfactuals by training a pairwise classifier that interpolates the relationship between the original example and the counterfactual. We demonstrate that with a small amount of human-annotated counterfactual data (10%), we can generate a counterfactual augmentation dataset with learned labels, that provides an 18-20% improvement in robustness and a 14-21% reduction in errors on 6 out-of-domain datasets, comparable to that of a fully human-annotated counterfactual dataset for both sentiment classification and question paraphrase tasks.</abstract>
      <url hash="bfa9af5f">2023.findings-emnlp.10</url>
      <bibkey>balashankar-etal-2023-improving</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.10</doi>
    </paper>
    <paper id="11">
      <title>Data Augmentation Techniques for Machine Translation of Code-Switched Texts: A Comparative Study</title>
      <author><first>Injy</first><last>Hamed</last></author>
      <author><first>Nizar</first><last>Habash</last></author>
      <author><first>Thang</first><last>Vu</last></author>
      <pages>140-154</pages>
      <abstract>Code-switching (CSW) text generation has been receiving increasing attention as a solution to address data scarcity. In light of this growing interest, we need more comprehensive studies comparing different augmentation approaches. In this work, we compare three popular approaches: lexical replacements, linguistic theories, and back-translation (BT), in the context of Egyptian Arabic-English CSW. We assess the effectiveness of the approaches on machine translation and the quality of augmentations through human evaluation. We show that BT and CSW predictive-based lexical replacement, being trained on CSW parallel data, perform best on both tasks. Linguistic theories and random lexical replacement prove to be effective in the lack of CSW parallel data, where both approaches achieve similar results.</abstract>
      <url hash="bba994ed">2023.findings-emnlp.11</url>
      <bibkey>hamed-etal-2023-data</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.11</doi>
    </paper>
    <paper id="12">
      <title>On the Relation between Sensitivity and Accuracy in In-Context Learning</title>
      <author><first>Yanda</first><last>Chen</last></author>
      <author><first>Chen</first><last>Zhao</last></author>
      <author><first>Zhou</first><last>Yu</last></author>
      <author><first>Kathleen</first><last>McKeown</last></author>
      <author><first>He</first><last>He</last></author>
      <pages>155-167</pages>
      <abstract>In-context learning (ICL) suffers from oversensitivity to the prompt, making it unreliable in real-world scenarios. We study the sensitivity of ICL with respect to multiple perturbation types. First, we find that label bias obscures the true sensitivity, and therefore prior work may have significantly underestimated ICL sensitivity. Second, we observe a strong negative correlation between ICL sensitivity and accuracy: predictions sensitive to perturbations are less likely to be correct. Motivated by these findings, we propose <tex-math>SenSel</tex-math>, a few-shot selective prediction method that abstains from sensitive predictions. Experiments on ten classification datasets show that <tex-math>SenSel</tex-math> consistently outperforms two commonly used confidence-based and entropy-based baselines on abstention decisions.</abstract>
      <url hash="bd3c9037">2023.findings-emnlp.12</url>
      <bibkey>chen-etal-2023-relation</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.12</doi>
    </paper>
    <paper id="13">
      <title>Self-distilled Transitive Instance Weighting for Denoised Distantly Supervised Relation Extraction</title>
      <author><first>Xiangyu</first><last>Lin</last></author>
      <author><first>Weijia</first><last>Jia</last></author>
      <author><first>Zhiguo</first><last>Gong</last></author>
      <pages>168-180</pages>
      <abstract>The widespread existence of wrongly labeled instances is a challenge to distantly supervised relation extraction. Most of the previous works are trained in a bag-level setting to alleviate such noise. However, sentence-level training better utilizes the information than bag-level training, as long as combined with effective noise alleviation. In this work, we propose a novel Transitive Instance Weighting mechanism integrated with the self-distilled BERT backbone, utilizing information in the intermediate outputs to generate dynamic instance weights for denoised sentence-level training. By down-weighting wrongly labeled instances and discounting the weights of easy-to-fit ones, our method can effectively tackle wrongly labeled instances and prevent overfitting. Experiments on both held-out and manual datasets indicate that our method achieves state-of-the-art performance and consistent improvements over the baselines.</abstract>
      <url hash="8af128df">2023.findings-emnlp.13</url>
      <bibkey>lin-etal-2023-self</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.13</doi>
    </paper>
    <paper id="14">
      <title><fixed-case>MWE</fixed-case> as <fixed-case>WSD</fixed-case>: Solving Multiword Expression Identification with Word Sense Disambiguation</title>
      <author><first>Joshua</first><last>Tanner</last></author>
      <author><first>Jacob</first><last>Hoffman</last></author>
      <pages>181-193</pages>
      <abstract>Recent approaches to word sense disambiguation (WSD) utilize encodings of the sense gloss (definition), in addition to the input context, to improve performance. In this work we demonstrate that this approach can be adapted for use in multiword expression (MWE) identification by training models which use gloss and context information to filter MWE candidates produced by a rule-based extraction pipeline. Our approach substantially improves precision, outperforming the state-of-the-art in MWE identification on the DiMSUM dataset by up to 1.9 F1 points and achieving competitive results on the PARSEME 1.1 English dataset. Our models also retain most of their WSD performance, showing that a single model can be used for both tasks. Finally, building on similar approaches using Bi-encoders for WSD, we introduce a novel Poly-encoder architecture which improves MWE identification performance.</abstract>
      <url hash="9927a8c9">2023.findings-emnlp.14</url>
      <bibkey>tanner-hoffman-2023-mwe</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.14</doi>
    </paper>
    <paper id="15">
      <title>Dual Contrastive Learning Framework for Incremental Text Classification</title>
      <author><first>Yigong</first><last>Wang</last></author>
      <author><first>Zhuoyi</first><last>Wang</last></author>
      <author><first>Yu</first><last>Lin</last></author>
      <author><first>Jinghui</first><last>Guo</last></author>
      <author><first>Sadaf</first><last>Halim</last></author>
      <author><first>Latifur</first><last>Khan</last></author>
      <pages>194-206</pages>
      <abstract>Incremental learning plays a pivotal role in the context of online knowledge discovery, as it encourages large models (LM) to learn and refresh knowledge continuously. Many approaches have been proposed to simultaneously preserve knowledge from previous tasks while learning new concepts in online NLP applications. In this paper, we primarily focus on learning a more generalized embedding space that could be better transferred to various downstream sequence tasks. The key idea is to learn from both task-agnostic and task-specific embedding aspects so that the inherent challenge of catastrophic forgetting that arises in incremental learning scenarios can be addressed with a more generalized solution. We propose a dual contrastive learning (DCL) based framework to foster the transferability of representations across different tasks, it consists of two key components: firstly, we utilize global contrastive learning that intertwines a task-agnostic strategy for promoting a generalized embedding space; secondly, considering the domain shift from unseen distributions can compromise the quality of learned embeddings. We further incorporate a task-specific attention mechanism to enhance the adaptability of task-specific weight for various emerging tasks and ultimately reduce errors in generic representations. Experiments over various text datasets demonstrate that our work achieves superior performance and outperforms the current state-of-the-art methods.</abstract>
      <url hash="8a72b769">2023.findings-emnlp.15</url>
      <bibkey>wang-etal-2023-dual</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.15</doi>
    </paper>
    <paper id="16">
      <title>Reference Free Domain Adaptation for Translation of Noisy Questions with Question Specific Rewards</title>
      <author><first>Baban</first><last>Gain</last></author>
      <author><first>Ramakrishna</first><last>Appicharla</last></author>
      <author><first>Soumya</first><last>Chennabasavaraj</last></author>
      <author><first>Nikesh</first><last>Garera</last></author>
      <author><first>Asif</first><last>Ekbal</last></author>
      <author><first>Muthusamy</first><last>Chelliah</last></author>
      <pages>207-221</pages>
      <abstract>Community Question-Answering (CQA) portals serve as a valuable tool for helping users within an organization. However, making them accessible to non-English-speaking users continues to be a challenge. Translating questions can broaden the community’s reach, benefiting individuals with similar inquiries in various languages. Translating questions using Neural Machine Translation (NMT) poses more challenges, especially in noisy environments, where the grammatical correctness of the questions is not monitored. These questions may be phrased as statements by non-native speakers, with incorrect subject-verb order and sometimes even missing question marks. Creating a synthetic parallel corpus from such data is also difficult due to its noisy nature. To address this issue, we propose a training methodology that fine-tunes the NMT system only using source-side data. Our approach balances adequacy and fluency by utilizing a loss function that combines BERTScore and Masked Language Model (MLM) Score. Our method surpasses the conventional Maximum Likelihood Estimation (MLE) based fine-tuning approach, which relies on synthetic target data, by achieving a 1.9 BLEU score improvement. Our model exhibits robustness while we add noise to our baseline, and still achieve 1.1 BLEU improvement and large improvements on TER and BLEURT metrics. Our proposed methodology is model-agnostic and is only necessary during the training phase. We make the codes and datasets publicly available at <url>https://www.iitp.ac.in/~ai-nlp-ml/resources.html#DomainAdapt</url> for facilitating further research.</abstract>
      <url hash="f5ea5891">2023.findings-emnlp.16</url>
      <bibkey>gain-etal-2023-reference</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.16</doi>
    </paper>
    <paper id="17">
      <title>Filtered Semi-<fixed-case>M</fixed-case>arkov <fixed-case>CRF</fixed-case></title>
      <author><first>Urchade</first><last>Zaratiana</last></author>
      <author><first>Nadi</first><last>Tomeh</last></author>
      <author><first>Niama</first><last>El Khbir</last></author>
      <author><first>Pierre</first><last>Holat</last></author>
      <author><first>Thierry</first><last>Charnois</last></author>
      <pages>222-235</pages>
      <abstract>Semi-Markov CRF has been proposed as an alternative to the traditional Linear Chain CRF for text segmentation tasks such as Named Entity Recognition (NER). Unlike CRF, which treats text segmentation as token-level prediction, Semi-CRF considers segments as the basic unit, making it more expressive. However, Semi-CRF suffers from two major drawbacks: (1) quadratic complexity over sequence length, as it operates on every span of the input sequence, and (2) inferior performance compared to CRF for sequence labeling tasks like NER. In this paper, we introduce Filtered Semi-Markov CRF, a variant of Semi-CRF that addresses these issues by incorporating a filtering step to eliminate irrelevant segments, reducing complexity and search space. Our approach is evaluated on several NER benchmarks, where it outperforms both CRF and Semi-CRF while being significantly faster. The implementation of our method is available on Github.</abstract>
      <url hash="8082070e">2023.findings-emnlp.17</url>
      <bibkey>zaratiana-etal-2023-filtered</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.17</doi>
    </paper>
    <paper id="18">
      <title>Data Pruning for Efficient Model Pruning in Neural Machine Translation</title>
      <author><first>Abdul</first><last>Azeemi</last></author>
      <author><first>Ihsan</first><last>Qazi</last></author>
      <author><first>Agha</first><last>Raza</last></author>
      <pages>236-246</pages>
      <abstract>Model pruning methods reduce memory requirements and inference time of large-scale pre-trained language models after deployment. However, the actual pruning procedure is computationally intensive, involving repeated training and pruning until the required sparsity is achieved. This paper combines data pruning with movement pruning for Neural Machine Translation (NMT) to enable efficient fine-pruning. We design a dataset pruning strategy by leveraging cross-entropy scores of individual training instances. We conduct pruning experiments on the task of machine translation from Romanian-to-English and Turkish-to-English, and demonstrate that selecting hard-to-learn examples (top-k) based on training cross-entropy scores outperforms other dataset pruning methods. We empirically demonstrate that data pruning reduces the overall steps required for convergence and the training time of movement pruning. Finally, we perform a series of experiments to tease apart the role of training data during movement pruning and uncover new insights to understand the interplay between data and model pruning in the context of NMT.</abstract>
      <url hash="4d6ee223">2023.findings-emnlp.18</url>
      <bibkey>azeemi-etal-2023-data</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.18</doi>
    </paper>
    <paper id="19">
      <title>Long-Form Speech Translation through Segmentation with Finite-State Decoding Constraints on Large Language Models</title>
      <author><first>Arya</first><last>McCarthy</last></author>
      <author><first>Hao</first><last>Zhang</last></author>
      <author><first>Shankar</first><last>Kumar</last></author>
      <author><first>Felix</first><last>Stahlberg</last></author>
      <author><first>Ke</first><last>Wu</last></author>
      <pages>247-257</pages>
      <abstract>One challenge in speech translation is that plenty of spoken content is long-form, but short units are necessary for obtaining high-quality translations. To address this mismatch, we adapt large language models (LLMs) to split long ASR transcripts into segments that can be independently translated so as to maximize the overall translation quality. We overcome the tendency of hallucination in LLMs by incorporating finite-state constraints during decoding; these eliminate invalid outputs without requiring additional training. We discover that LLMs are adaptable to transcripts containing ASR errors through prompt-tuning or fine-tuning. Relative to a state-of-the-art automatic punctuation baseline, our best LLM improves the average BLEU by 2.9 points for English–German, English–Spanish, and English–Arabic TED talk translation in 9 test sets, just by improving segmentation.</abstract>
      <url hash="4cfb8905">2023.findings-emnlp.19</url>
      <bibkey>mccarthy-etal-2023-long</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.19</doi>
    </paper>
    <paper id="20">
      <title>Re-Temp: Relation-Aware Temporal Representation Learning for Temporal Knowledge Graph Completion</title>
      <author><first>Kunze</first><last>Wang</last></author>
      <author><first>Caren</first><last>Han</last></author>
      <author><first>Josiah</first><last>Poon</last></author>
      <pages>258-269</pages>
      <abstract>Temporal Knowledge Graph Completion (TKGC) under the extrapolation setting aims to predict the missing entity from a fact in the future, posing a challenge that aligns more closely with real-world prediction problems. Existing research mostly encodes entities and relations using sequential graph neural networks applied to recent snapshots. However, these approaches tend to overlook the ability to skip irrelevant snapshots according to entity-related relations in the query and disregard the importance of explicit temporal information. To address this, we propose our model, Re-Temp (Relation-Aware Temporal Representation Learning), which leverages explicit temporal embedding as input and incorporates skip information flow after each timestamp to skip unnecessary information for prediction. Additionally, we introduce a two-phase forward propagation method to prevent information leakage. Through the evaluation on six TKGC (extrapolation) datasets, we demonstrate that our model outperforms all eight recent state-of-the-art models by a significant margin.</abstract>
      <url hash="3dd04728">2023.findings-emnlp.20</url>
      <bibkey>wang-etal-2023-temp</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.20</doi>
    </paper>
    <paper id="21">
      <title><fixed-case>R</fixed-case>ethinking<fixed-case>TMSC</fixed-case>: An Empirical Study for Target-Oriented Multimodal Sentiment Classification</title>
      <author><first>Junjie</first><last>Ye</last></author>
      <author><first>Jie</first><last>Zhou</last></author>
      <author><first>Junfeng</first><last>Tian</last></author>
      <author><first>Rui</first><last>Wang</last></author>
      <author><first>Qi</first><last>Zhang</last></author>
      <author><first>Tao</first><last>Gui</last></author>
      <author><first>Xuanjing</first><last>Huang</last></author>
      <pages>270-277</pages>
      <abstract>Recently, Target-oriented Multimodal Sentiment Classification (TMSC) has gained significant attention among scholars. However, current multimodal models have reached a performance bottleneck. To investigate the causes of this problem, we perform extensive empirical evaluation and in-depth analysis of the datasets to answer the following questions: **Q1**: Are the modalities equally important for TMSC? **Q2**: Which multimodal fusion modules are more effective? **Q3**: Do existing datasets adequately support the research? Our experiments and analyses reveal that the current TMSC systems primarily rely on the textual modality, as most of targets’ sentiments can be determined *solely* by text. Consequently, we point out several directions to work on for the TMSC task in terms of model design and dataset construction. The code and data can be found in https://github.com/Junjie-Ye/RethinkingTMSC.</abstract>
      <url hash="c083c536">2023.findings-emnlp.21</url>
      <bibkey>ye-etal-2023-rethinkingtmsc</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.21</doi>
    </paper>
    <paper id="22">
      <title>Lexical Entrainment for Conversational Systems</title>
      <author><first>Zhengxiang</first><last>Shi</last></author>
      <author><first>Procheta</first><last>Sen</last></author>
      <author><first>Aldo</first><last>Lipani</last></author>
      <pages>278-293</pages>
      <abstract>Conversational agents have become ubiquitous in assisting with daily tasks, and are expected to possess human-like features. One such feature is lexical entrainment (LE), a phenomenon in which speakers in human-human conversations tend to naturally and subconsciously align their lexical choices with those of their interlocutors, leading to more successful and engaging conversations. As an example, if a digital assistant replies “Your appointment for Jinling Noodle Pub is at 7 pm” to the question “When is my reservation for Jinling Noodle Bar today?”, it may feel as though the assistant is trying to correct the speaker, whereas a response of “Your reservation for Jinling Noodle Baris at 7 pm” would likely be perceived as more positive. This highlights the importance of LE in establishing a shared terminology for maximum clarity and reducing ambiguity in conversations. However, we demonstrate in this work that current response generation models do not adequately address this crucial human-like phenomenon. To address this, we propose a new dataset, named MultiWOZ-ENTR, and a measure for LE for conversational systems. Additionally, we suggest a way to explicitly integrate LE into conversational systems with two new tasks, a LE extraction task and a LE generation task. We also present two baseline approaches for the LE extraction task, which aim to detect LE expressions from dialogue contexts</abstract>
      <url hash="5430a1a9">2023.findings-emnlp.22</url>
      <bibkey>shi-etal-2023-lexical</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.22</doi>
    </paper>
    <paper id="23">
      <title><fixed-case>A</fixed-case>uto<fixed-case>R</fixed-case>eply: Detecting Nonsense in Dialogue with Discriminative Replies</title>
      <author><first>Weiyan</first><last>Shi</last></author>
      <author><first>Emily</first><last>Dinan</last></author>
      <author><first>Adi</first><last>Renduchintala</last></author>
      <author><first>Daniel</first><last>Fried</last></author>
      <author><first>Athul</first><last>Jacob</last></author>
      <author><first>Zhou</first><last>Yu</last></author>
      <author><first>Mike</first><last>Lewis</last></author>
      <pages>294-309</pages>
      <abstract>We show that dialogue models can detect errors in their own messages, by calculating the likelihood of replies that are indicative of poor messages. For example, if an agent believes its partner is likely to respond “I don’t understand” to a candidate message, that message may not make sense, so an alternative message should be chosen. We evaluate our approach on a dataset from the game Diplomacy, which contains long dialogues richly grounded in the game state, on which existing models make many errors. We first show that hand-crafted replies can be effective for the task of detecting nonsense in applications as complex as Diplomacy. We then design AutoReply, an algorithm to search for such discriminative replies automatically, given a small number of annotated dialogue examples. We find that AutoReply-generated replies outperform handcrafted replies and perform on par with supervised learning approaches.</abstract>
      <url hash="5bbe4b1a">2023.findings-emnlp.23</url>
      <bibkey>shi-etal-2023-autoreply</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.23</doi>
    </paper>
    <paper id="24">
      <title>Follow-on Question Suggestion via Voice Hints for Voice Assistants</title>
      <author><first>Besnik</first><last>Fetahu</last></author>
      <author><first>Pedro</first><last>Faustini</last></author>
      <author><first>Anjie</first><last>Fang</last></author>
      <author><first>Giuseppe</first><last>Castellucci</last></author>
      <author><first>Oleg</first><last>Rokhlenko</last></author>
      <author><first>Shervin</first><last>Malmasi</last></author>
      <pages>310-325</pages>
      <abstract>The adoption of voice assistants like Alexa or Siri has grown rapidly, allowing users to instantly access information via voice search. Query suggestion is a standard feature of screen-based search experiences, allowing users to explore additional topics. However, this is not trivial to implement in voice-based settings. To enable this, we tackle the novel task of suggesting questions with compact and natural voice hints to allow users to ask follow-up questions. We define the task, ground it in syntactic theory and outline linguistic desiderata for spoken hints. We propose baselines and an approach using sequence-to-sequence Transformers to generate spoken hints from a list of questions. Using a new dataset of 6681 input questions and human written hints, we evaluated the models with automatic metrics and human evaluation. Results show that a naive approach of concatenating suggested questions creates poor voice hints. Our approach, which applies a linguistically-motivated pretraining task was strongly preferred by humans for producing the most natural hints.</abstract>
      <url hash="a65de61c">2023.findings-emnlp.24</url>
      <bibkey>fetahu-etal-2023-follow</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.24</doi>
    </paper>
    <paper id="25">
      <title>Bidirectional Masked Self-attention and N-gram Span Attention for Constituency Parsing</title>
      <author><first>Soohyeong</first><last>Kim</last></author>
      <author><first>Whanhee</first><last>Cho</last></author>
      <author><first>Minji</first><last>Kim</last></author>
      <author><first>Yong</first><last>Choi</last></author>
      <pages>326-338</pages>
      <abstract>Attention mechanisms have become a crucial aspect of deep learning, particularly in natural language processing (NLP) tasks. However, in tasks such as constituency parsing, attention mechanisms can lack the directional information needed to form sentence spans. To address this issue, we propose a Bidirectional masked and N-gram span Attention (BNA) model, which is designed by modifying the attention mechanisms to capture the explicit dependencies between each word and enhance the representation of the output span vectors. The proposed model achieves state-of-the-art performance on the Penn Treebank and Chinese Penn Treebank datasets, with F1 scores of 96.47 and 94.15, respectively. Ablation studies and analysis show that our proposed BNA model effectively captures sentence structure by contextualizing each word in a sentence through bidirectional dependencies and enhancing span representation.</abstract>
      <url hash="5eb66c5e">2023.findings-emnlp.25</url>
      <bibkey>kim-etal-2023-bidirectional</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.25</doi>
    </paper>
    <paper id="26">
      <title><fixed-case>CR</fixed-case>-<fixed-case>COPEC</fixed-case>: Causal Rationale of Corporate Performance Changes to learn from Financial Reports</title>
      <author><first>Ye</first><last>Chun</last></author>
      <author><first>Sunjae</first><last>Kwon</last></author>
      <author><first>Kyunghwan</first><last>Sohn</last></author>
      <author><first>Nakwon</first><last>Sung</last></author>
      <author><first>Junyoup</first><last>Lee</last></author>
      <author><first>Byoung</first><last>Seo</last></author>
      <author><first>Kevin</first><last>Compher</last></author>
      <author><first>Seung-won</first><last>Hwang</last></author>
      <author><first>Jaesik</first><last>Choi</last></author>
      <pages>339-355</pages>
      <abstract>In this paper, we introduce CR-COPEC called Causal Rationale of Corporate Performance Changes from financial reports. This is a comprehensive large-scale domain-adaptation causal sentence dataset to detect financial performance changes of corporate. CR-COPEC contributes to two major achievements. First, it detects causal rationale from 10-K annual reports of the U.S. companies, which contain experts’ causal analysis following accounting standards in a formal manner. This dataset can be widely used by both individual investors and analysts as material information resources for investing and decision-making without tremendous effort to read through all the documents. Second, it carefully considers different characteristics which affect the financial performance of companies in twelve industries. As a result, CR-COPEC can distinguish causal sentences in various industries by taking unique narratives in each industry into consideration. We also provide an extensive analysis of how well CR-COPEC dataset is constructed and suited for classifying target sentences as causal ones with respect to industry characteristics.</abstract>
      <url hash="f308ebb6">2023.findings-emnlp.26</url>
      <bibkey>chun-etal-2023-cr</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.26</doi>
    </paper>
    <paper id="27">
      <title>Plausibility Processing in Transformer Language Models: Focusing on the Role of Attention Heads in <fixed-case>GPT</fixed-case></title>
      <author><first>Soo</first><last>Ryu</last></author>
      <pages>356-369</pages>
      <abstract>The goal of this paper is to explore how Transformer language models process semantic knowledge, especially regarding the plausibility of noun-verb relations. First, I demonstrate GPT2 exhibits a higher degree of similarity with humans in plausibility processing compared to other Transformer language models. Next, I delve into how knowledge of plausibility is contained within attention heads of GPT2 and how these heads causally contribute to GPT2’s plausibility processing ability. Through several experiments, it was found that: i) GPT2 has a number of attention heads that detect plausible noun-verb relationships; ii) these heads collectively contribute to the Transformer’s ability to process plausibility, albeit to varying degrees; and iii) attention heads’ individual performance in detecting plausibility does not necessarily correlate with how much they contribute to GPT2’s plausibility processing ability.</abstract>
      <url hash="bfc670d6">2023.findings-emnlp.27</url>
      <bibkey>ryu-2023-plausibility</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.27</doi>
    </paper>
    <paper id="28">
      <title>Automatic Unit Test Data Generation and Actor-Critic Reinforcement Learning for Code Synthesis</title>
      <author><first>Philip</first><last>Gorinski</last></author>
      <author><first>Matthieu</first><last>Zimmer</last></author>
      <author><first>Gerasimos</first><last>Lampouras</last></author>
      <author><first>Derrick Goh Xin</first><last>Deik</last></author>
      <author><first>Ignacio</first><last>Iacobacci</last></author>
      <pages>370-384</pages>
      <abstract>The advent of large pre-trained language models in the domain of Code Synthesis has shown remarkable performance on various benchmarks, treating the problem of Code Generation in a fashion similar to Natural Language Generation, trained with a Language Modelling (LM) objective. In addition, the property of programming language code being precisely evaluable with respect to its semantics – through the use of Unit Tests to check its functional correctness – lends itself to using Reinforcement Learning (RL) as a further training paradigm. Previous work has shown that RL can be applied as such to improve models’ coding capabilities; however, such RL-based methods rely on a reward signal based on defined Unit Tests, which are much harder to obtain compared to the huge crawled code datasets used in LM objectives. In this work, we present a novel approach to automatically obtain data consisting of function signatures and associated Unit Tests, suitable for RL training of Code Synthesis models. We also introduce a straightforward, simple yet effective Actor-Critic RL training scheme and show that it, in conjunction with automatically generated training data, leads to improvement of a pre-trained code language model’s performance by up to 9.9% improvement over the original underlying code synthesis LM, and up to 4.3% over RL-based models trained with standard PPO or CodeRL.</abstract>
      <url hash="16648873">2023.findings-emnlp.28</url>
      <bibkey>gorinski-etal-2023-automatic</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.28</doi>
    </paper>
    <paper id="29">
      <title>Unlocking the Heterogeneous Landscape of Big Data <fixed-case>NLP</fixed-case> with <fixed-case>DUUI</fixed-case></title>
      <author><first>Alexander</first><last>Leonhardt</last></author>
      <author><first>Giuseppe</first><last>Abrami</last></author>
      <author><first>Daniel</first><last>Baumartz</last></author>
      <author><first>Alexander</first><last>Mehler</last></author>
      <pages>385-399</pages>
      <abstract>Automatic analysis of large corpora is a complex task, especially in terms of time efficiency. This complexity is increased by the fact that flexible, extensible text analysis requires the continuous integration of ever new tools. Since there are no adequate frameworks for these purposes in the field of NLP, and especially in the context of UIMA, that are not outdated or unusable for security reasons, we present a new approach to address the latter task: Docker Unified UIMA Interface (DUUI), a scalable, flexible, lightweight, and feature-rich framework for automatic distributed analysis of text corpora that leverages Big Data experience and virtualization with Docker. We evaluate DUUI’s communication approach against a state-of-the-art approach and demonstrate its outstanding behavior in terms of time efficiency, enabling the analysis of big text data.</abstract>
      <url hash="29ed77b8">2023.findings-emnlp.29</url>
      <bibkey>leonhardt-etal-2023-unlocking</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.29</doi>
    </paper>
    <paper id="30">
      <title>Towards Agile Text Classifiers for Everyone</title>
      <author><first>Maximilian</first><last>Mozes</last></author>
      <author><first>Jessica</first><last>Hoffmann</last></author>
      <author><first>Katrin</first><last>Tomanek</last></author>
      <author><first>Muhamed</first><last>Kouate</last></author>
      <author><first>Nithum</first><last>Thain</last></author>
      <author><first>Ann</first><last>Yuan</last></author>
      <author><first>Tolga</first><last>Bolukbasi</last></author>
      <author><first>Lucas</first><last>Dixon</last></author>
      <pages>400-414</pages>
      <abstract>Text-based safety classifiers are widely used for content moderation and increasingly to tune generative language model behavior - a topic of growing concern for the safety of digital assistants and chatbots. However, different policies require different classifiers, and safety policies themselves improve from iteration and adaptation. This paper introduces and evaluates methods for agile text classification, whereby classifiers are trained using small, targeted datasets that can be quickly developed for a particular policy. Experimenting with 7 datasets from three safety-related domains, comprising 15 annotation schemes, led to our key finding: prompt-tuning large language models, like PaLM 62B, with a labeled dataset of as few as 80 examples can achieve state-of-the-art performance. We argue that this enables a paradigm shift for text classification, especially for models supporting safer online discourse. Instead of collecting millions of examples to attempt to create universal safety classifiers over months or years, classifiers could be tuned using small datasets, created by individuals or small organizations, tailored for specific use cases, and iterated on and adapted in the time-span of a day.</abstract>
      <url hash="a3968d38">2023.findings-emnlp.30</url>
      <bibkey>mozes-etal-2023-towards</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.30</doi>
    </paper>
    <paper id="31">
      <title>Beyond Good Intentions: Reporting the Research Landscape of <fixed-case>NLP</fixed-case> for Social Good</title>
      <author><first>Fernando</first><last>Adauto</last></author>
      <author><first>Zhijing</first><last>Jin</last></author>
      <author><first>Bernhard</first><last>Schölkopf</last></author>
      <author><first>Tom</first><last>Hope</last></author>
      <author><first>Mrinmaya</first><last>Sachan</last></author>
      <author><first>Rada</first><last>Mihalcea</last></author>
      <pages>415-438</pages>
      <abstract>With the recent advances in natural language processing (NLP), a vast number of applications have emerged across various use cases. Among the plethora of NLP applications, many academic researchers are motivated to do work that has a positive social impact, in line with the recent initiatives of NLP for Social Good (NLP4SG). However, it is not always obvious to researchers how their research efforts are tackling today’s big social problems. Thus, in this paper, we introduce NLP4SGPapers, a scientific dataset with three associated tasks that can help identify NLP4SG papers and characterize the NLP4SG landscape by: (1) identifying the papers that address a social problem, (2) mapping them to the corresponding UN Sustainable Development Goals (SDGs), and (3) identifying the task they are solving and the methods they are using. Using state-of-the-art NLP models, we address each of these tasks and use them on the entire ACL Anthology, resulting in a visualization workspace that gives researchers a comprehensive overview of the field of NLP4SG. Our website is available at https://nlp4sg.vercel.app . We released our data at https://huggingface.co/datasets/feradauto/NLP4SGPapers and code at https://github.com/feradauto/nlp4sg</abstract>
      <url hash="44571950">2023.findings-emnlp.31</url>
      <bibkey>adauto-etal-2023-beyond</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.31</doi>
    </paper>
    <paper id="32">
      <title><fixed-case>PAXQA</fixed-case>: Generating Cross-lingual Question Answering Examples at Training Scale</title>
      <author><first>Bryan</first><last>Li</last></author>
      <author><first>Chris</first><last>Callison-Burch</last></author>
      <pages>439-454</pages>
      <abstract>Existing question answering (QA) systems owe much of their success to large, high-quality training data. Such annotation efforts are costly, and the difficulty compounds in the cross-lingual setting. Therefore, prior cross-lingual QA work has focused on releasing evaluation datasets, and then applying zero-shot methods as baselines. This work proposes a synthetic data generation method for cross-lingual QA which leverages indirect supervision from existing parallel corpora. Our method termed PAXQA (Projecting annotations for cross-lingual (x) QA) decomposes cross-lingual QA into two stages. First, we apply a question generation (QG) model to the English side. Second, we apply annotation projection to translate both the questions and answers. To better translate questions, we propose a novel use of lexically-constrained machine translation, in which constrained entities are extracted from the parallel bitexts. We apply PAXQA to generate cross-lingual QA examples in 4 languages (662K examples total), and perform human evaluation on a subset to create validation and test splits. We then show that models fine-tuned on these datasets outperform prior synthetic data generation models over several extractive QA datasets. The largest performance gains are for directions with non-English questions and English contexts. Ablation studies show that our dataset generation method is relatively robust to noise from automatic word alignments, showing the sufficient quality of our generations. To facilitate follow-up work, we release our code and datasets at https://github.com/manestay/paxqa.</abstract>
      <url hash="d654b747">2023.findings-emnlp.32</url>
      <bibkey>li-callison-burch-2023-paxqa</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.32</doi>
    </paper>
    <paper id="33">
      <title>Sharing, Teaching and Aligning: Knowledgeable Transfer Learning for Cross-Lingual Machine Reading Comprehension</title>
      <author><first>Tingfeng</first><last>Cao</last></author>
      <author><first>Chengyu</first><last>Wang</last></author>
      <author><first>Chuanqi</first><last>Tan</last></author>
      <author><first>Jun</first><last>Huang</last></author>
      <author><first>Jinhui</first><last>Zhu</last></author>
      <pages>455-467</pages>
      <abstract>In cross-lingual language understanding, machine translation is often utilized to enhance the transferability of models across languages, either by translating the training data from the source language to the target, or from the target to the source to aid inference. However, in cross-lingual machine reading comprehension (MRC), it is difficult to perform a deep level of assistance to enhance cross-lingual transfer because of the variation of answer span positions in different languages. In this paper, we propose X-STA, a new approach for cross-lingual MRC. Specifically, we leverage an attentive teacher to subtly transfer the answer spans of the source language to the answer output space of the target. A Gradient-Disentangled Knowledge Sharing technique is proposed as an improved cross-attention block. In addition, we force the model to learn semantic alignments from multiple granularities and calibrate the model outputs with teacher guidance to enhance cross-lingual transferability. Experiments on three multi-lingual MRC datasets show the effectiveness of our method, outperforming state-of-the-art approaches.</abstract>
      <url hash="912fcfa7">2023.findings-emnlp.33</url>
      <bibkey>cao-etal-2023-sharing</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.33</doi>
    </paper>
    <paper id="34">
      <title><fixed-case>BERT</fixed-case> Goes Off-Topic: Investigating the Domain Transfer Challenge using Genre Classification</title>
      <author><first>Dmitri</first><last>Roussinov</last></author>
      <author><first>Serge</first><last>Sharoff</last></author>
      <pages>468-483</pages>
      <abstract>While performance of many text classification tasks has been recently improved due to Pretrained Language Models (PLMs), in this paper we show that they still suffer from a performance gap when the underlying distribution of topics changes. For example, a genre classifier trained on political topics often fails when tested on documents in the same genre, but about sport or medicine. In this work, we quantify this phenomenon empirically with a large corpus and a large set of topics. Thus, we verify that domain transfer remains challenging both for classic PLMs, such as BERT, and for modern large models (LLMs), such as GPT. We develop a data augmentation approach by generating texts in any desired genre and on any desired topic, even when there are no documents in the training corpus that are both in that particular genre and on that particular topic. When we augment the training dataset with the topically-controlled synthetic texts, F1 improves up to 50% for some topics, approaching on-topic training, while showing no or next to no improvement for other topics. While our empirical results focus on genre classification, our methodology is applicable to other classification tasks such as gender, authorship, or sentiment classification.</abstract>
      <url hash="d54e35dc">2023.findings-emnlp.34</url>
      <bibkey>roussinov-sharoff-2023-bert</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.34</doi>
    </paper>
    <paper id="35">
      <title>Toward Stronger Textual Attack Detectors</title>
      <author><first>Pierre</first><last>Colombo</last></author>
      <author><first>Marine</first><last>Picot</last></author>
      <author><first>Nathan</first><last>Noiry</last></author>
      <author><first>Guillaume</first><last>Staerman</last></author>
      <author><first>Pablo</first><last>Piantanida</last></author>
      <pages>484-505</pages>
      <abstract>The landscape of available textual adversarial attacks keeps growing, posing severe threats and raising concerns regarding deep NLP systems integrity. However, the crucial problem of defending against malicious attacks has only drawn few attention in the NLP community. The latter is nonetheless instrumental to develop robust and trustworthy systems. This paper makes two important contributions in this line of search: <i>(i)</i> we introduce LAROUSSE, a new framework to detect textual adversarial attacks and <i>(ii)</i> we introduce STAKEOUT, an extended benchmark composed of nine popular attack methods, three datasets and two pre-trained models. LAROUSSE is ready-to-use in production as it is unsupervised, hyperparameter free and non-differentiable, protecting it against gradient-based methods. Our new benchmark STAKEOUT allows for a robust evaluation framework: we conduct extensive numerical experiments which demonstrate that LAROUSSE outperforms previous methods, and which allows to identify interesting factor of detection rate variations.</abstract>
      <url hash="a012641d">2023.findings-emnlp.35</url>
      <bibkey>colombo-etal-2023-toward</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.35</doi>
    </paper>
    <paper id="36">
      <title><fixed-case>MEAL</fixed-case>: Stable and Active Learning for Few-Shot Prompting</title>
      <author><first>Abdullatif</first><last>Köksal</last></author>
      <author><first>Timo</first><last>Schick</last></author>
      <author><first>Hinrich</first><last>Schuetze</last></author>
      <pages>506-517</pages>
      <abstract>Few-shot classification has made great strides due to foundation models that, through priming and prompting, are highly effective few-shot learners. However, this approach has high variance both across different sets of few shots (*data selection*) and across different finetuning runs (*run variability*). This is problematic not only because it impedes the fair comparison of different approaches, but especially because it makes few-shot learning too unreliable for many real-world applications. To alleviate these issues, we make two contributions for more stable and effective few-shot learning: First, we propose novel ensembling methods and show that they substantially reduce *run variability*. Second, we introduce a new active learning (AL) criterion for *data selection* and present the first AL-based approach specifically tailored towards prompt-based learning. In our experiments, we show that our combined method, MEAL (**M**ultiprompt finetuning and prediction **E**nsembling with **A**ctive **L**earning), improves overall performance of prompt-based finetuning by 2.3 points on five diverse tasks. We publicly share our code and data splits in https://github.com/akoksal/MEAL.</abstract>
      <url hash="0986127d">2023.findings-emnlp.36</url>
      <bibkey>koksal-etal-2023-meal</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.36</doi>
    </paper>
    <paper id="37">
      <title>Structure and Label Constrained Data Augmentation for Cross-domain Few-shot <fixed-case>NER</fixed-case></title>
      <author><first>Jingyi</first><last>Zhang</last></author>
      <author><first>Ying</first><last>Zhang</last></author>
      <author><first>Yufeng</first><last>Chen</last></author>
      <author><first>Jinan</first><last>Xu</last></author>
      <pages>518-530</pages>
      <abstract>Cross-domain few-shot named entity recognition (NER) is a challenging task that aims to recognize entities in target domains with limited labeled data by leveraging relevant knowledge from source domains. However, domain gaps limit the effect of knowledge transfer and harm the performance of NER models. In this paper, we analyze those domain gaps from two new perspectives, i.e., entity annotations and entity structures and leverage word-to-tag and word-to-word relations to model them, respectively. Moreover, we propose a novel method called Structure and Label Constrained Data Augmentation (SLC-DA) for Cross-domain Few-shot NER, which novelly design a label constrained pre-train task and a structure constrained optimization objectives in the data augmentation process to generate domain-specific augmented data to help NER models smoothly transition from source to target domains. We evaluate our approach on several standard datasets and achieve state-of-the-art or competitive results, demonstrating the effectiveness of our method in cross-domain few-shot NER.</abstract>
      <url hash="3db349ea">2023.findings-emnlp.37</url>
      <bibkey>zhang-etal-2023-structure</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.37</doi>
    </paper>
    <paper id="38">
      <title>Weakly-supervised Deep Cognate Detection Framework for Low-Resourced Languages Using Morphological Knowledge of Closely-Related Languages</title>
      <author><first>Koustava</first><last>Goswami</last></author>
      <author><first>Priya</first><last>Rani</last></author>
      <author><first>Theodorus</first><last>Fransen</last></author>
      <author><first>John</first><last>McCrae</last></author>
      <pages>531-541</pages>
      <abstract>Exploiting cognates for transfer learning in under-resourced languages is an exciting opportunity for language understanding tasks, including unsupervised machine translation, named entity recognition and information retrieval. Previous approaches mainly focused on supervised cognate detection tasks based on orthographic, phonetic or state-of-the-art contextual language models, which under-perform for most under-resourced languages. This paper proposes a novel language-agnostic weakly-supervised deep cognate detection framework for under-resourced languages using morphological knowledge from closely related languages. We train an encoder to gain morphological knowledge of a language and transfer the knowledge to perform unsupervised and weakly-supervised cognate detection tasks with and without the pivot language for the closely-related languages. While unsupervised, it overcomes the need for hand-crafted annotation of cognates. We performed experiments on different published cognate detection datasets across language families and observed not only significant improvement over the state-of-the-art but also our method outperformed the state-of-the-art supervised and unsupervised methods. Our model can be extended to a wide range of languages from any language family as it overcomes the requirement of the annotation of the cognate pairs for training.</abstract>
      <url hash="8bc0e331">2023.findings-emnlp.38</url>
      <bibkey>goswami-etal-2023-weakly</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.38</doi>
    </paper>
    <paper id="39">
      <title><fixed-case>SQLP</fixed-case>rompt: In-Context Text-to-<fixed-case>SQL</fixed-case> with Minimal Labeled Data</title>
      <author><first>Ruoxi</first><last>Sun</last></author>
      <author><first>Sercan</first><last>Arik</last></author>
      <author><first>Rajarishi</first><last>Sinha</last></author>
      <author><first>Hootan</first><last>Nakhost</last></author>
      <author><first>Hanjun</first><last>Dai</last></author>
      <author><first>Pengcheng</first><last>Yin</last></author>
      <author><first>Tomas</first><last>Pfister</last></author>
      <pages>542-550</pages>
      <abstract>Text-to-SQL aims to automate the process of generating SQL queries on a database from natural language text. In this work, we propose “SQLPrompt”, tailored to improve the few-shot prompting capabilities of Text-to-SQL for Large Language Models (LLMs). Our methods include innovative prompt design, execution-based consistency decoding strategy which selects the SQL with the most consistent execution outcome among other SQL proposals, and a method that aims to improve performance by diversifying the SQL proposals during consistency selection with different prompt designs (“MixPrompt”) and foundation models (“MixLLMs”). We show that <i>SQLPrompt</i> outperforms previous approaches for in-context learning with zero labeled data by a large margin, closing the gap with finetuning state-of-the-art with thousands of labeled data.</abstract>
      <url hash="205d38e3">2023.findings-emnlp.39</url>
      <bibkey>sun-etal-2023-sqlprompt</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.39</doi>
    </paper>
    <paper id="40">
      <title>Toward Building General Foundation Models for Language, Vision, and Vision-Language Understanding Tasks</title>
      <author><first>Xinsong</first><last>Zhang</last></author>
      <author><first>Yan</first><last>Zeng</last></author>
      <author><first>Jipeng</first><last>Zhang</last></author>
      <author><first>Hang</first><last>Li</last></author>
      <pages>551-568</pages>
      <abstract>Foundation models or pre-trained models have substantially improved the performance of various language, vision, and vision-language understanding tasks. However, existing foundation models can only perform the best in one type of tasks, namely language, vision, or vision-language. It is still an open question whether it is possible to construct a general foundation model performing the best for all the understanding tasks. In this paper, we propose a new method for training the general foundation model, X-FM (the X-Foundation Model). X-FM has one language encoder, one vision encoder, and one fusion encoder, as well as a new training method. The training method includes two new techniques for learning X-FM from text, image, and image-text pair data. One is to stop gradients from the vision-language training when learning the language encoder. The other is to leverage the vision-language training to guide the learning of the vision encoder. Extensive experiments on benchmark datasets show that X-FM can significantly outperform existing general foundation models and perform better than or comparable to existing foundation models specifically for language, vision, or vision-language understanding. Code and pre-trained models are released at https://github.com/zhangxinsong-nlp/XFM.</abstract>
      <url hash="09055a69">2023.findings-emnlp.40</url>
      <bibkey>zhang-etal-2023-toward</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.40</doi>
    </paper>
    <paper id="41">
      <title>Trigger Warnings: Bootstrapping a Violence Detector for Fan Fiction</title>
      <author><first>Magdalena</first><last>Wolska</last></author>
      <author><first>Matti</first><last>Wiegmann</last></author>
      <author><first>Christopher</first><last>Schröder</last></author>
      <author><first>Ole</first><last>Borchardt</last></author>
      <author><first>Benno</first><last>Stein</last></author>
      <author><first>Martin</first><last>Potthast</last></author>
      <pages>569-576</pages>
      <abstract>We present the first dataset and evaluation results on a newly defined task: assigning trigger warnings. We introduce a labeled corpus of narrative fiction from Archive of Our Own (AO3), a popular fan fiction site, and define a document-level classification task to determine whether or not to assign a trigger warning to an English story. We focus on the most commonly assigned trigger type “violence’ using the warning labels provided by AO3 authors as ground-truth labels. We trained SVM, BERT, and Longfomer models on three datasets sampled from the corpus and achieve F1 scores between 0.8 and 0.9, indicating that assigning trigger warnings for violence is feasible.</abstract>
      <url hash="4de5653c">2023.findings-emnlp.41</url>
      <bibkey>wolska-etal-2023-trigger</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.41</doi>
    </paper>
    <paper id="42">
      <title>Pass-Tuning: Towards Structure-Aware Parameter-Efficient Tuning for Code Representation Learning</title>
      <author><first>Nuo</first><last>Chen</last></author>
      <author><first>Qiushi</first><last>Sun</last></author>
      <author><first>Jianing</first><last>Wang</last></author>
      <author><first>Xiang</first><last>Li</last></author>
      <author><first>Ming</first><last>Gao</last></author>
      <pages>577-591</pages>
      <abstract>Code pre-trained models (CodePTMs) have recently become the de-facto paradigm for various tasks in the domain of code intelligence. To achieve excellent performance, the widely used strategy is to fine-tune all the parameters of CodePTMs. However, as the model size increases along with the number of downstream tasks, this strategy becomes excessively expensive. There are also some prior works that utilize Parameter-Efficient Learning (PEL) methods for model tuning in natural language processing to mitigate similar problems, but applying them directly to CodePTMs fails to capture the inherent structural characteristics of codes. To address the problem, in this paper, we propose Pass-Tuning for structure-aware Parameter-Efficient code representation learning. Specifically, a plug-and-play graph neural network module that can learn from Abstract Syntax Tree (AST) is employed as a tunable prefix. On the one hand, Pass-Tuning can further exploit the structural information of source code. On the other hand, it could serve as a replacement for full fine-tuning. We evaluate our method on multiple tasks across eight programming languages, including code understanding and generation. These results demonstrate the effectiveness, robustness, and universality of our method.</abstract>
      <url hash="8e9528a2">2023.findings-emnlp.42</url>
      <bibkey>chen-etal-2023-pass</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.42</doi>
    </paper>
    <paper id="43">
      <title>Counterfactual Augmentation for Multimodal Learning Under Presentation Bias</title>
      <author><first>Victoria</first><last>Lin</last></author>
      <author><first>Louis-Philippe</first><last>Morency</last></author>
      <author><first>Dimitrios</first><last>Dimitriadis</last></author>
      <author><first>Srinagesh</first><last>Sharma</last></author>
      <pages>592-606</pages>
      <abstract>In real-world machine learning systems, labels are often derived from user behaviors that the system wishes to encourage. Over time, new models must be trained as new training examples and features become available. However, feedback loops between users and models can bias future user behavior, inducing a *presentation bias* in the labels that compromises the ability to train new models. In this paper, we propose *counterfactual augmentation*, a novel causal method for correcting presentation bias using generated counterfactual labels. Our empirical evaluations demonstrate that counterfactual augmentation yields better downstream performance compared to both uncorrected models and existing bias-correction methods. Model analyses further indicate that the generated counterfactuals align closely with true counterfactuals in an oracle setting.</abstract>
      <url hash="414182e8">2023.findings-emnlp.43</url>
      <bibkey>lin-etal-2023-counterfactual</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.43</doi>
    </paper>
    <paper id="44">
      <title>A Table-to-Text Framework with Heterogeneous Multidominance Attention and Self-Evaluated Multi-Pass Deliberation</title>
      <author><first>Xi</first><last>Chen</last></author>
      <author><first>Xinjiang</first><last>Lu</last></author>
      <author><first>Haoran</first><last>Xin</last></author>
      <author><first>Wenjun</first><last>Peng</last></author>
      <author><first>Haoyang</first><last>Duan</last></author>
      <author><first>Feihu</first><last>Jiang</last></author>
      <author><first>Jingbo</first><last>Zhou</last></author>
      <author><first>Hui</first><last>Xiong</last></author>
      <pages>607-620</pages>
      <abstract>Though big progress in table-to-text works, effectively leveraging table structure signals, e.g., hierarchical structure, remains challenging. Besides, deliberating generated descriptions proves to be effective for table-to-text. However, determining the appropriate outcome when encountering multi-pass candidates is another challenge. To this end, we propose a novel table-to-text approach on top of Self-evaluated multi-pass Generation and Heterogenous Multidominance Attention, namely SG-HMA. Specifically, we formulate the table structure into a multidominance (MD) structure and devise a heterogenous multidominance attention (HMA) to comprehensively explore the complex interactions encoded in the hierarchical structure, which can further deliver rich signals for text generation with the help of pre-trained language models (PLMs). Afterward, a contrastive loss is introduced to align the generation objective with evaluation metrics, so the more faithful generated descriptions can be guaranteed. We conduct extensive experiments on three public datasets, demonstrating that SG-HMA outperforms several SOTA methods quantitatively and qualitatively.</abstract>
      <url hash="cd0ce6d9">2023.findings-emnlp.44</url>
      <bibkey>chen-etal-2023-table</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.44</doi>
    </paper>
    <paper id="45">
      <title>Crossing the Aisle: Unveiling Partisan and Counter-Partisan Events in News Reporting</title>
      <author><first>Kaijian</first><last>Zou</last></author>
      <author><first>Xinliang</first><last>Zhang</last></author>
      <author><first>Winston</first><last>Wu</last></author>
      <author><first>Nicholas</first><last>Beauchamp</last></author>
      <author><first>Lu</first><last>Wang</last></author>
      <pages>621-632</pages>
      <abstract>News media is expected to uphold unbiased reporting. Yet they may still affect public opinion by selectively including or omitting events that support or contradict their ideological positions. Prior work in NLP has only studied media bias via linguistic style and word usage. In this paper, we study to which degree media balances news reporting and affects consumers through event inclusion or omission. We first introduce the task of detecting both partisan and counter-partisan events: events that support or oppose the author’s political ideology. To conduct our study, we annotate a high-quality dataset, PAC, containing 8,511 (counter-)partisan event annotations in 304 news articles from ideologically diverse media outlets. We benchmark PAC to highlight the challenges of this task. Our findings highlight both the ways in which the news subtly shapes opinion and the need for large language models that better understand events within a broader context. Our dataset can be found at https://github.com/launchnlp/Partisan-Event-Dataset.</abstract>
      <url hash="75551837">2023.findings-emnlp.45</url>
      <bibkey>zou-etal-2023-crossing</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.45</doi>
    </paper>
    <paper id="46">
      <title>Video-Text Retrieval by Supervised Sparse Multi-Grained Learning</title>
      <author><first>Yimu</first><last>Wang</last></author>
      <author><first>Peng</first><last>Shi</last></author>
      <pages>633-649</pages>
      <abstract>While recent progress in video-text retrieval has been advanced by the exploration of better representation learning, in this paper, we present a novel multi-grained sparse learning framework, S3MA, to learn an aligned sparse space shared between the video and the text for video-text retrieval. The shared sparse space is initialized with a finite number of sparse concepts, each of which refers to a number of words. With the text data at hand, we learn and update the shared sparse space in a supervised manner using the proposed similarity and alignment losses. Moreover, to enable multi-grained alignment, we incorporate frame representations for better modeling the video modality and calculating fine-grained and coarse-grained similarities. Benefiting from the learned shared sparse space and multi-grained similarities, extensive experiments on several video-text retrieval benchmarks demonstrate the superiority of S3MA over existing methods.</abstract>
      <url hash="4462ea67">2023.findings-emnlp.46</url>
      <bibkey>wang-shi-2023-video</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.46</doi>
    </paper>
    <paper id="47">
      <title>Zero-Shot-<fixed-case>BERT</fixed-case>-Adapters: a Zero-Shot Pipeline for Unknown Intent Detection</title>
      <author><first>Daniele</first><last>Comi</last></author>
      <author><first>Dimitrios</first><last>Christofidellis</last></author>
      <author><first>Pier</first><last>Piazza</last></author>
      <author><first>Matteo</first><last>Manica</last></author>
      <pages>650-663</pages>
      <abstract>Intent discovery is a crucial task in natural language processing, and it is increasingly relevant for various of industrial applications. Identifying novel, unseen intents from user inputs remains one of the biggest challenges in this field. Herein, we propose Zero-Shot-BERT-Adapters, a two-stage method for multilingual intent discovery relying on a Transformer architecture, fine-tuned with Adapters. We train the model for Natural Language Inference (NLI) and later perform unknown intent classification in a zero-shot setting for multiple languages. In our evaluation, we first analyze the quality of the model after adaptive fine-tuning on known classes. Secondly, we evaluate its performance in casting intent classification as an NLI task. Lastly, we test the zero-shot performance of the model on unseen classes, showing how Zero-Shot-BERT-Adapters can effectively perform intent discovery by generating semantically similar intents, if not equal, to the ground-truth ones. Our experiments show how Zero-Shot-BERT-Adapters outperforms various baselines in two zero-shot settings: known intent classification and unseen intent discovery. The proposed pipeline holds the potential for broad application in customer care. It enables automated dynamic triage using a lightweight model that can be easily deployed and scaled in various business scenarios, unlike large language models. Zero-Shot-BERT-Adapters represents an innovative multi-language approach for intent discovery, enabling the online generation of novel intents. A Python package implementing the pipeline and the new datasets we compiled are available at the following link: https://github.com/GT4SD/zero-shot-bert-adapters.</abstract>
      <url hash="bf4a833d">2023.findings-emnlp.47</url>
      <bibkey>comi-etal-2023-zero</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.47</doi>
    </paper>
    <paper id="48">
      <title><fixed-case>R</fixed-case>e<fixed-case>FSQL</fixed-case>: A Retrieval-Augmentation Framework for Text-to-<fixed-case>SQL</fixed-case> Generation</title>
      <author><first>Kun</first><last>Zhang</last></author>
      <author><first>Xiexiong</first><last>Lin</last></author>
      <author><first>Yuanzhuo</first><last>Wang</last></author>
      <author><first>Xin</first><last>Zhang</last></author>
      <author><first>Fei</first><last>Sun</last></author>
      <author><first>Cen</first><last>Jianhe</last></author>
      <author><first>Hexiang</first><last>Tan</last></author>
      <author><first>Xuhui</first><last>Jiang</last></author>
      <author><first>Huawei</first><last>Shen</last></author>
      <pages>664-673</pages>
      <abstract>Text-to-SQL is the task that aims at translating natural language questions into SQL queries. Existing methods directly align the natural language with SQL Language and train one encoder-decoder-based model to fit all questions. However, they underestimate the inherent structural characteristics of SQL, as well as the gap between specific structure knowledge and general knowledge. This leads to structure errors in the generated SQL. To address the above challenges, we propose a retrieval-argument framework, namely ReFSQL. It contains two parts, structure-enhanced retriever and the generator. Structure-enhanced retriever is designed to identify samples with comparable specific knowledge in an unsupervised way. Subsequently, we incorporate the retrieved samples’ SQL into the input, enabling the model to acquire prior knowledge of similar SQL grammar. To further bridge the gap between specific and general knowledge, we present a mahalanobis contrastive learning method, which facilitates the transfer of the sample toward the specific knowledge distribution constructed by the retrieved samples. Experimental results on five datasets verify the effectiveness of our approach in improving the accuracy and robustness of Text-to-SQL generation. Our framework has achieved improved performance when combined with many other backbone models (including the 11B flan-T5) and also achieved state-of-the-art performance when compared to existing methods that employ the fine-tuning approach.</abstract>
      <url hash="3f6f35f5">2023.findings-emnlp.48</url>
      <bibkey>zhang-etal-2023-refsql</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.48</doi>
    </paper>
    <paper id="49">
      <title>Approximating Two-Layer Feedforward Networks for Efficient Transformers</title>
      <author><first>Róbert</first><last>Csordás</last></author>
      <author><first>Kazuki</first><last>Irie</last></author>
      <author><first>Jürgen</first><last>Schmidhuber</last></author>
      <pages>674-692</pages>
      <abstract>How to reduce compute and memory requirements of neural networks (NNs) without sacrificing performance? Many recent works use sparse Mixtures of Experts (MoEs) to build resource-efficient large language models (LMs). Here we introduce several novel perspectives on MoEs, presenting a general framework that *unifies* various methods to *approximate two-layer NNs* (e.g., feedforward blocks of Transformers), including product-key memories (PKMs). Leveraging insights from this framework, we propose methods to improve both MoEs and PKMs. Unlike prior work that compares MoEs with dense baselines under the *compute-equal* condition, our evaluation condition is *parameter-equal*, which is crucial to properly evaluate LMs. We show that our MoEs are competitive with the *dense* Transformer-XL on both the WikiText-103 and enwiki8 datasets at two different scales, while being much more resource efficient. This demonstrates that MoEs are relevant not only to extremely large LMs but also to any-scale resource-efficient LMs. Our code is public.</abstract>
      <url hash="5e445b98">2023.findings-emnlp.49</url>
      <bibkey>csordas-etal-2023-approximating</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.49</doi>
    </paper>
    <paper id="50">
      <title>Adapter-<fixed-case>TST</fixed-case>: A Parameter Efficient Method for Multiple-Attribute Text Style Transfer</title>
      <author><first>Zhiqiang</first><last>Hu</last></author>
      <author><first>Nancy</first><last>Chen</last></author>
      <author><first>Roy</first><last>Lee</last></author>
      <pages>693-703</pages>
      <abstract>Adapting a large language model for multiple-attribute text style transfer via fine-tuning can be challenging due to the substantial amount of computational resources and labeled data required for the specific downstream task. In this paper, we address this challenge by introducing Adapter-TST, a framework that freezes the pre-trained model’s original parameters and enables the development of a multiple-attribute text style transfer model. Using BART as the backbone model, Adapter-TST utilizes different neural adapters to model different types of attribute information, similar to a plug-in connected to BART. Our method allows control over multiple attributes (e.g. sentiment, tense, active or passive voice) and configures the adapters’ architecture to generate multiple outputs in respect to attributes or compositional editing on the same sentence. We evaluate the proposed model on both traditional sentiment transfer and multiple-attribute transfer tasks. The experiment results demonstrate that Adapter-TST outperforms all the state-of-the-art baselines with significantly less computational resources. We have also empirically shown that each adapter is able to characterize specific stylistic attributes effectively and can be configured to perform compositional editing.</abstract>
      <url hash="2bb02503">2023.findings-emnlp.50</url>
      <bibkey>hu-etal-2023-adapter</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.50</doi>
    </paper>
    <paper id="51">
      <title>Solving the Right Problem is Key for Translational <fixed-case>NLP</fixed-case>: A Case Study in <fixed-case>UMLS</fixed-case> Vocabulary Insertion</title>
      <author><first>Bernal</first><last>Gutierrez</last></author>
      <author><first>Yuqing</first><last>Mao</last></author>
      <author><first>Vinh</first><last>Nguyen</last></author>
      <author><first>Kin</first><last>Fung</last></author>
      <author><first>Yu</first><last>Su</last></author>
      <author><first>Olivier</first><last>Bodenreider</last></author>
      <pages>704-717</pages>
      <abstract>As the immense opportunities enabled by large language models become more apparent, NLP systems will be increasingly expected to excel in real-world settings. However, in many instances, powerful models alone will not yield translational NLP solutions, especially if the formulated problem is not well aligned with the real-world task. In this work, we study the case of UMLS vocabulary insertion, an important real-world task in which hundreds of thousands of new terms, referred to as atoms, are added to the UMLS, one of the most comprehensive open-source biomedical knowledge bases. Previous work aimed to develop an automated NLP system to make this time-consuming, costly, and error-prone task more efficient. Nevertheless, practical progress in this direction has been difficult to achieve due to a problem formulation and evaluation gap between research output and the real-world task. In order to address this gap, we introduce a new formulation for UMLS vocabulary insertion which mirrors the real-world task, datasets which faithfully represent it and several strong baselines we developed through re-purposing existing solutions. Additionally, we propose an effective rule-enhanced biomedical language model which enables important new model behavior, outperforms all strong baselines and provides measurable qualitative improvements to editors who carry out the UVI task. We hope this case study provides insight into the considerable importance of problem formulation for the success of translational NLP solutions.</abstract>
      <url hash="8f153a94">2023.findings-emnlp.51</url>
      <bibkey>gutierrez-etal-2023-solving</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.51</doi>
    </paper>
    <paper id="52">
      <title>Improving Cross-lingual Transfer through Subtree-aware Word Reordering</title>
      <author><first>Ofir</first><last>Arviv</last></author>
      <author><first>Dmitry</first><last>Nikolaev</last></author>
      <author><first>Taelin</first><last>Karidi</last></author>
      <author><first>Omri</first><last>Abend</last></author>
      <pages>718-736</pages>
      <abstract>Despite the impressive growth of the abilities of multilingual language models, such as XLM-R and mT5, it has been shown that they still face difficulties when tackling typologically-distant languages, particularly in the low-resource setting. One obstacle for effective cross-lingual transfer is variability in word-order patterns. It can be potentially mitigated via source- or target-side word reordering, and numerous approaches to reordering have been proposed. However, they rely on language-specific rules, work on the level of POS tags, or only target the main clause, leaving subordinate clauses intact. To address these limitations, we present a new powerful reordering method, defined in terms of Universal Dependencies, that is able to learn fine-grained word-order patterns conditioned on the syntactic context from a small amount of annotated data and can be applied at all levels of the syntactic tree. We conduct experiments on a diverse set of tasks and show that our method consistently outperforms strong baselines over different language pairs and model architectures. This performance advantage holds true in both zero-shot and few-shot scenarios.</abstract>
      <url hash="5b7d1aeb">2023.findings-emnlp.52</url>
      <bibkey>arviv-etal-2023-improving</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.52</doi>
    </paper>
    <paper id="53">
      <title>Novel Slot Detection With an Incremental Setting</title>
      <author><first>Chen</first><last>Liang</last></author>
      <author><first>Hongliang</first><last>Li</last></author>
      <author><first>Changhao</first><last>Guan</last></author>
      <author><first>Qingbin</first><last>Liu</last></author>
      <author><first>Jian</first><last>Liu</last></author>
      <author><first>Jinan</first><last>Xu</last></author>
      <author><first>Zhe</first><last>Zhao</last></author>
      <pages>737-746</pages>
      <abstract>Current dialogue systems face diverse user requests and rapid change domains, making quickly adapt to scenarios with previous unseen slot types become a major challenge. Recently, researchers have introduced novel slot detection (NSD) to discover potential new types. However, dialogue system with NSD does not bring practical improvements due to the system still cannot handle novel slots in subsequent interactions. In this paper, we define incremental novel slot detection (INSD), which separates the dialogue system to deal with novel types as two major phrases: 1) model discovers unknown slots, 2) training model to possess the capability to handle new classes. We provide an effective model to extract novel slots with set prediction strategy and propose a query-enhanced approach to overcome catastrophic forgetting during the process of INSD. We construct two INSD datasets to evaluate our method and experimental results show that our approach exhibits superior performance.</abstract>
      <url hash="e679fbc1">2023.findings-emnlp.53</url>
      <bibkey>liang-etal-2023-novel</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.53</doi>
    </paper>
    <paper id="54">
      <title>Self-supervised Post-processing Method to Enrich Pretrained Word Vectors</title>
      <author><first>Hwiyeol</first><last>Jo</last></author>
      <pages>747-757</pages>
      <abstract>Retrofitting techniques, which inject external resources into word representations, have compensated for the weakness of distributed representations in semantic and relational knowledge between words. However, the previous methods require additional external resources and strongly depend on the lexicon. To address the issues, we propose a simple extension of extrofitting, self-supervised extrofitting: extrofitting by its own word vector distribution. Our methods improve the vanilla embeddings on all of word similarity tasks without any external resources. Moreover, the method is also effective in various languages, which implies that our method will be useful in lexicon-scarce languages. As downstream tasks, we show its benefits in dialogue state tracking and text classification tasks, reporting better and generalized results compared to other word vector specialization methods.</abstract>
      <url hash="cbd79ab1">2023.findings-emnlp.54</url>
      <bibkey>jo-2023-self-supervised</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.54</doi>
    </paper>
    <paper id="55">
      <title>Automatic Model Selection with Large Language Models for Reasoning</title>
      <author><first>James</first><last>Zhao</last></author>
      <author><first>Yuxi</first><last>Xie</last></author>
      <author><first>Kenji</first><last>Kawaguchi</last></author>
      <author><first>Junxian</first><last>He</last></author>
      <author><first>Michael</first><last>Xie</last></author>
      <pages>758-783</pages>
      <abstract>Chain-of-Thought (CoT) and Program-Aided Language Models (PAL) represent two distinct reasoning methods, each with its own strengths. CoT employs natural language, offering flexibility and interpretability, while PAL utilizes programming language, yielding more structured and rigorous logic. We introduce a model selection method to combine the best of both worlds by employing a large language model (LLM) to dynamically select between them. Our theoretical analysis underscores the feasibility of this method, which is further corroborated by empirical results. Our proposed method demonstrates significant performance improvements across eight reasoning datasets with Codex, ChatGPT, and GPT-4. Additionally, our method is complementary to self-consistency; when integrated, it can further enhance performance while significantly reducing computation costs. Moreover, we achieve new state-of-the-art results on GSM8K and SVAMP, with respective accuracies of 96.8% and 93.7%.</abstract>
      <url hash="384a8fc4">2023.findings-emnlp.55</url>
      <bibkey>zhao-etal-2023-automatic</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.55</doi>
    </paper>
    <paper id="56">
      <title><fixed-case>ARK</fixed-case>it<fixed-case>S</fixed-case>cene<fixed-case>R</fixed-case>efer: Text-based Localization of Small Objects in Diverse Real-World 3<fixed-case>D</fixed-case> Indoor Scenes</title>
      <author><first>Shunya</first><last>Kato</last></author>
      <author><first>Shuhei</first><last>Kurita</last></author>
      <author><first>Chenhui</first><last>Chu</last></author>
      <author><first>Sadao</first><last>Kurohashi</last></author>
      <pages>784-799</pages>
      <abstract>3D referring expression comprehension is a task to ground text representations onto objects in 3D scenes. It is a crucial task for indoor household robots or augmented reality devices to localize objects referred to in user instructions. However, existing indoor 3D referring expression comprehension datasets typically cover larger object classes that are easy to localize, such as chairs, tables, or doors, and often overlook small objects, such as cooking tools or office supplies. Based on the recently proposed diverse and high-resolution 3D scene dataset of ARKitScenes, we construct the ARKitSceneRefer dataset focusing on small daily-use objects that frequently appear in real-world indoor scenes. ARKitSceneRefer contains 15k objects of 1,605 indoor scenes, which are significantly larger than those of the existing 3D referring datasets, and covers diverse object classes of 583 from the LVIS dataset. In empirical experiments with both 2D and 3D state-of-the-art referring expression comprehension models, we observed the task difficulty of the localization in the diverse small object classes.</abstract>
      <url hash="92dfa6ce">2023.findings-emnlp.56</url>
      <bibkey>kato-etal-2023-arkitscenerefer</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.56</doi>
    </paper>
    <paper id="57">
      <title>Improving Question Generation with Multi-level Content Planning</title>
      <author><first>Zehua</first><last>Xia</last></author>
      <author><first>Qi</first><last>Gou</last></author>
      <author><first>Bowen</first><last>Yu</last></author>
      <author><first>Haiyang</first><last>Yu</last></author>
      <author><first>Fei</first><last>Huang</last></author>
      <author><first>Yongbin</first><last>Li</last></author>
      <author><first>Nguyen</first><last>Cam-Tu</last></author>
      <pages>800-814</pages>
      <abstract>This paper addresses the problem of generating questions from a given context and an answer, specifically focusing on questions that require multi-hop reasoning across an extended context. Previous studies have suggested that key phrase selection is essential for question generation (QG), yet it is still challenging to connect such disjointed phrases into meaningful questions, particularly for long context. To mitigate this issue, we propose MultiFactor, a novel QG framework based on multi-level content planning. Specifically, MultiFactor includes two components: FA-Model, which simultaneously selects key phrases and generates full answers, and Q-Model which takes the generated full answer as an additional input to generate questions. Here, full answer generation is introduced to connect the short answer with the selected key phrases, thus forming an answer-aware summary to facilitate QG. Both FA-Model and Q-Model are formalized as simple-yet-effective Phrase-Enhanced Transformers, our joint model for phrase selection and text generation. Experimental results show that our method outperforms strong baselines on two popular QG datasets. Our code is available at https://github.com/zeaver/MultiFactor.</abstract>
      <url hash="647673f8">2023.findings-emnlp.57</url>
      <bibkey>xia-etal-2023-improving</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.57</doi>
    </paper>
    <paper id="58">
      <title>Is <fixed-case>C</fixed-case>hat<fixed-case>GPT</fixed-case> a Financial Expert? Evaluating Language Models on Financial Natural Language Processing</title>
      <author><first>Yue</first><last>Guo</last></author>
      <author><first>Zian</first><last>Xu</last></author>
      <author><first>Yi</first><last>Yang</last></author>
      <pages>815-821</pages>
      <abstract>The emergence of Large Language Models (LLMs), such as ChatGPT, has revolutionized general natural language preprocessing (NLP) tasks. However, their expertise in the financial domain lacks a comprehensive evaluation. To assess the ability of LLMs to solve financial NLP tasks, we present FinLMEval, a framework for Financial Language Model Evaluation, comprising nine datasets designed to evaluate the performance of language models. This study compares the performance of fine-tuned auto-encoding language models (BERT, RoBERTa, FinBERT) and the LLM ChatGPT. Our findings reveal that while ChatGPT demonstrates notable performance across most financial tasks, it generally lags behind the fine-tuned expert models, especially when dealing with proprietary datasets. We hope this study builds foundation evaluation benchmarks for continuing efforts to build more advanced LLMs in the financial domain.</abstract>
      <url hash="df4cf9ec">2023.findings-emnlp.58</url>
      <bibkey>guo-etal-2023-chatgpt</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.58</doi>
    </paper>
    <paper id="59">
      <title><fixed-case>D</fixed-case>elucion<fixed-case>QA</fixed-case>: Detecting Hallucinations in Domain-specific Question Answering</title>
      <author><first>Mobashir</first><last>Sadat</last></author>
      <author><first>Zhengyu</first><last>Zhou</last></author>
      <author><first>Lukas</first><last>Lange</last></author>
      <author><first>Jun</first><last>Araki</last></author>
      <author><first>Arsalan</first><last>Gundroo</last></author>
      <author><first>Bingqing</first><last>Wang</last></author>
      <author><first>Rakesh</first><last>Menon</last></author>
      <author><first>Md</first><last>Parvez</last></author>
      <author><first>Zhe</first><last>Feng</last></author>
      <pages>822-835</pages>
      <abstract>Hallucination is a well-known phenomenon in text generated by large language models (LLMs). The existence of hallucinatory responses is found in almost all application scenarios e.g., summarization, question-answering (QA) etc. For applications requiring high reliability (e.g., customer-facing assistants), the potential existence of hallucination in LLM-generated text is a critical problem. The amount of hallucination can be reduced by leveraging information retrieval to provide relevant background information to the LLM. However, LLMs can still generate hallucinatory content for various reasons (e.g., prioritizing its parametric knowledge over the context, failure to capture the relevant information from the context, etc.). Detecting hallucinations through automated methods is thus paramount. To facilitate research in this direction, we introduce a sophisticated dataset, DelucionQA, that captures hallucinations made by retrieval-augmented LLMs for a domain-specific QA task. Furthermore, we propose a set of hallucination detection methods to serve as baselines for future works from the research community. Analysis and case study are also provided to share valuable insights on hallucination phenomena in the target scenario.</abstract>
      <url hash="0ddee72c">2023.findings-emnlp.59</url>
      <bibkey>sadat-etal-2023-delucionqa</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.59</doi>
    </paper>
    <paper id="60">
      <title><fixed-case>I</fixed-case>nv<fixed-case>GC</fixed-case>: Robust Cross-Modal Retrieval by Inverse Graph Convolution</title>
      <author><first>Xiangru</first><last>Jian</last></author>
      <author><first>Yimu</first><last>Wang</last></author>
      <pages>836-865</pages>
      <abstract>Over recent decades, significant advancements in cross-modal retrieval is mainly driven by breakthroughs in visual and linguistic modeling. However, a recent study shows that multi-modal data representations tend to cluster within a limited convex cone (as representation degeneration problem), which hinders retrieval performance due to the inseparability of these representations. In our study, we first empirically validate the presence of the representation degeneration problem across multiple cross-modal benchmarks and methods. Next, to address it, we introduce a novel method, called InvGC, a post-processing technique inspired by graph convolution and average pooling. Specifically, InvGC defines the graph topology within the datasets and then applies graph convolution in a subtractive manner. This method effectively separates representations by increasing the distances between data points. To improve the efficiency and effectiveness of InvGC, we propose an advanced graph topology, LocalAdj, which only aims to increase the distances between each data point and its nearest neighbors. To understand why InvGC works, we present a detailed theoretical analysis, proving that the lower bound of recall will be improved after deploying InvGC. Extensive empirical results show that InvGC and InvGC w/LocalAdj significantly mitigate the representation degeneration problem, thereby enhancing retrieval performance.</abstract>
      <url hash="6b201ff3">2023.findings-emnlp.60</url>
      <bibkey>jian-wang-2023-invgc</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.60</doi>
    </paper>
    <paper id="61">
      <title>Dissecting In-Context Learning of Translations in <fixed-case>GPT</fixed-case>-3</title>
      <author><first>Vikas</first><last>Raunak</last></author>
      <author><first>Arul</first><last>Menezes</last></author>
      <author><first>Hany</first><last>Awadalla</last></author>
      <pages>866-872</pages>
      <abstract>Most of the recent work in leveraging Large Language Models (LLMs) such as GPT-3 for Machine Translation (MT) has focused on selecting the few-shot samples for prompting. In this work, we try to better understand the role of demonstration attributes for the in-context learning of translations through perturbations of high-quality, in-domain demonstrations. We find that asymmetric perturbation of the source-target mappings yield vastly different results. We show that the perturbation of the source side has surprisingly little impact, while target perturbation can drastically reduce translation quality, suggesting that it is the output text distribution that provides the most important learning signal during in-context learning of translations. We propose a method named Zero-Shot-Context to add this signal automatically in Zero-Shot prompting. We demonstrate that it improves upon the zero-shot translation performance of GPT-3, even making it competitive with few-shot prompted translations.</abstract>
      <url hash="5cb4ba02">2023.findings-emnlp.61</url>
      <bibkey>raunak-etal-2023-dissecting</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.61</doi>
    </paper>
    <paper id="62">
      <title>Social Commonsense-Guided Search Query Generation for Open-Domain Knowledge-Powered Conversations</title>
      <author><first>Revanth</first><last>Reddy</last></author>
      <author><first>Hao</first><last>Bai</last></author>
      <author><first>Wentao</first><last>Yao</last></author>
      <author><first>Sharath Chandra Etagi</first><last>Suresh</last></author>
      <author><first>Heng</first><last>Ji</last></author>
      <author><first>ChengXiang</first><last>Zhai</last></author>
      <pages>873-885</pages>
      <abstract>Open-domain dialog involves generating search queries that help obtain relevant knowledge for holding informative conversations. However, it can be challenging to determine what information to retrieve when the user is passive and does not express a clear need or request. To tackle this issue, we present a novel approach that focuses on generating internet search queries that are guided by social commonsense. Specifically, we leverage a commonsense dialog system to establish connections related to the conversation topic, which subsequently guides our query generation. Our proposed framework addresses passive user interactions by integrating topic tracking, commonsense response generation and instruction-driven query generation. Through extensive evaluations, we show that our approach overcomes limitations of existing query generation techniques that rely solely on explicit dialog information, and produces search queries that are more relevant, specific, and compelling, ultimately resulting in more engaging responses.</abstract>
      <url hash="cbf92c09">2023.findings-emnlp.62</url>
      <bibkey>reddy-etal-2023-social</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.62</doi>
    </paper>
    <paper id="63">
      <title><fixed-case>M</fixed-case>ix<fixed-case>TEA</fixed-case>: Semi-supervised Entity Alignment with Mixture Teaching</title>
      <author><first>Feng</first><last>Xie</last></author>
      <author><first>Xin</first><last>Song</last></author>
      <author><first>Xiang</first><last>Zeng</last></author>
      <author><first>Xuechen</first><last>Zhao</last></author>
      <author><first>Lei</first><last>Tian</last></author>
      <author><first>Bin</first><last>Zhou</last></author>
      <author><first>Yusong</first><last>Tan</last></author>
      <pages>886-896</pages>
      <abstract>Semi-supervised entity alignment (EA) is a practical and challenging task because of the lack of adequate labeled mappings as training data. Most works address this problem by generating pseudo mappings for unlabeled entities. However, they either suffer from the erroneous (noisy) pseudo mappings or largely ignore the uncertainty of pseudo mappings. In this paper, we propose a novel semi-supervised EA method, termed as MixTEA, which guides the model learning with an end-to-end mixture teaching of manually labeled mappings and probabilistic pseudo mappings. We firstly train a student model using few labeled mappings as standard. More importantly, in pseudo mapping learning, we propose a bi-directional voting (BDV) strategy that fuses the alignment decisions in different directions to estimate the uncertainty via the joint matching confidence score. Meanwhile, we also design a matching diversity-based rectification (MDR) module to adjust the pseudo mapping learning, thus reducing the negative influence of noisy mappings. Extensive results on benchmark datasets as well as further analyses demonstrate the superiority and the effectiveness of our proposed method.</abstract>
      <url hash="09bd58ed">2023.findings-emnlp.63</url>
      <bibkey>xie-etal-2023-mixtea</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.63</doi>
    </paper>
    <paper id="64">
      <title><fixed-case>EZ</fixed-case>-<fixed-case>STANCE</fixed-case>: A Large Dataset for Zero-Shot Stance Detection</title>
      <author><first>Chenye</first><last>Zhao</last></author>
      <author><first>Cornelia</first><last>Caragea</last></author>
      <pages>897-911</pages>
      <abstract>Zero-shot stance detection (ZSSD) aims to determine whether the author of a text is in favor of, against, or neutral toward a target that is unseen during training. In this paper, we present EZ-STANCE, a large English ZSSD dataset with 30,606 annotated text-target pairs. In contrast to VAST, the only other existing ZSSD dataset, EZ-STANCE includes both noun-phrase targets and claim targets, covering a wide range of domains. In addition, we introduce two challenging subtasks for ZSSD: target-based ZSSD and domain-based ZSSD. We provide an in-depth description and analysis of our dataset. We evaluate EZ-STANCE using state-of-the-art deep learning models. Furthermore, we propose to transform ZSSD into the NLI task by applying two simple yet effective prompts to noun-phrase targets. Our experimental results show that EZ-STANCE is a challenging new benchmark, which provides significant research opportunities on ZSSD. We will make our dataset and code available on GitHub.</abstract>
      <url hash="c64be5b5">2023.findings-emnlp.64</url>
      <bibkey>zhao-caragea-2023-ez</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.64</doi>
    </paper>
    <paper id="65">
      <title>Boot and Switch: Alternating Distillation for Zero-Shot Dense Retrieval</title>
      <author><first>Fan</first><last>Jiang</last></author>
      <author><first>Qiongkai</first><last>Xu</last></author>
      <author><first>Tom</first><last>Drummond</last></author>
      <author><first>Trevor</first><last>Cohn</last></author>
      <pages>912-931</pages>
      <abstract>Neural ‘dense’ retrieval models are state of the art for many datasets, however these models often exhibit limited domain transfer ability. Existing approaches to adaptation are unwieldy, such as requiring explicit supervision, complex model architectures, or massive external models. We present <tex-math>\texttt{ABEL}</tex-math>, a simple but effective unsupervised method to enhance passage retrieval in zero-shot settings. Our technique follows a straightforward loop: a dense retriever learns from supervision signals provided by a reranker, and subsequently, the reranker is updated based on feedback from the improved retriever. By iterating this loop, the two components mutually enhance one another’s performance. Experimental results demonstrate that our unsupervised <tex-math>\texttt{ABEL}</tex-math> model outperforms both leading supervised and unsupervised retrievers on the BEIR benchmark. Meanwhile, it exhibits strong adaptation abilities to tasks and domains that were unseen during training. By either fine-tuning <tex-math>\texttt{ABEL}</tex-math> on labelled data or integrating it with existing supervised dense retrievers, we achieve state-of-the-art results.</abstract>
      <url hash="cffa23d2">2023.findings-emnlp.65</url>
      <bibkey>jiang-etal-2023-boot</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.65</doi>
    </paper>
    <paper id="66">
      <title><fixed-case>TESTA</fixed-case>: Temporal-Spatial Token Aggregation for Long-form Video-Language Understanding</title>
      <author><first>Shuhuai</first><last>Ren</last></author>
      <author><first>Sishuo</first><last>Chen</last></author>
      <author><first>Shicheng</first><last>Li</last></author>
      <author><first>Xu</first><last>Sun</last></author>
      <author><first>Lu</first><last>Hou</last></author>
      <pages>932-947</pages>
      <abstract>Large-scale video-language pre-training has made remarkable strides in advancing video-language understanding tasks. However, the heavy computational burden of video encoding remains a formidable efficiency bottleneck, particularly for long-form videos. These videos contain massive visual tokens due to their inherent 3D properties and spatiotemporal redundancy, making it challenging to capture complex temporal and spatial relationships. To tackle this issue, we propose an efficient method called TEmporal-Spatial Token Aggregation (TESTA). TESTA condenses video semantics by adaptively aggregating similar frames, as well as similar patches within each frame. TESTA can reduce the number of visual tokens by 75% and thus accelerate video encoding. Building upon TESTA, we introduce a pre-trained video-language model equipped with a divided space-time token aggregation module in each video encoder block. We evaluate our model on five datasets for paragraph-to-video retrieval and long-form VideoQA tasks. Experimental results show that TESTA improves computing efficiency by 1.7 times, and achieves significant performance gains from its scalability in processing longer input frames, e.g., +13.7 R@1 on QuerYD and +6.5 R@1 on Condensed Movie.</abstract>
      <url hash="bc2c7d87">2023.findings-emnlp.66</url>
      <bibkey>ren-etal-2023-testa</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.66</doi>
    </paper>
    <paper id="67">
      <title>Fusing Temporal Graphs into Transformers for Time-Sensitive Question Answering</title>
      <author><first>Xin</first><last>Su</last></author>
      <author><first>Phillip</first><last>Howard</last></author>
      <author><first>Nagib</first><last>Hakim</last></author>
      <author><first>Steven</first><last>Bethard</last></author>
      <pages>948-966</pages>
      <abstract>Answering time-sensitive questions from long documents requires temporal reasoning over the times in questions and documents. An important open question is whether large language models can perform such reasoning solely using a provided text document, or whether they can benefit from additional temporal information extracted using other systems. We address this research question by applying existing temporal information extraction systems to construct temporal graphs of events, times, and temporal relations in questions and documents. We then investigate different approaches for fusing these graphs into Transformer models. Experimental results show that our proposed approach for fusing temporal graphs into input text substantially enhances the temporal reasoning capabilities of Transformer models with or without fine-tuning. Additionally, our proposed method outperforms various graph convolution-based approaches and establishes a new state-of-the-art performance on SituatedQA and three splits of TimeQA.</abstract>
      <url hash="83e073ea">2023.findings-emnlp.67</url>
      <bibkey>su-etal-2023-fusing</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.67</doi>
    </paper>
    <paper id="68">
      <title>The Internal State of an <fixed-case>LLM</fixed-case> Knows When It’s Lying</title>
      <author><first>Amos</first><last>Azaria</last></author>
      <author><first>Tom</first><last>Mitchell</last></author>
      <pages>967-976</pages>
      <abstract>While Large Language Models (LLMs) have shown exceptional performance in various tasks, one of their most prominent drawbacks is generating inaccurate or false information with a confident tone. In this paper, we provide evidence that the LLM’s internal state can be used to reveal the truthfulness of statements. This includes both statements provided to the LLM, and statements that the LLM itself generates. Our approach is to train a classifier that outputs the probability that a statement is truthful, based on the hidden layer activations of the LLM as it reads or generates the statement. Experiments demonstrate that given a set of test sentences, of which half are true and half false, our trained classifier achieves an average of 71% to 83% accuracy labeling which sentences are true versus false, depending on the LLM base model. Furthermore, we explore the relationship between our classifier’s performance and approaches based on the probability assigned to the sentence by the LLM. We show that while LLM-assigned sentence probability is related to sentence truthfulness, this probability is also dependent on sentence length and the frequencies of words in the sentence, resulting in our trained classifier providing a more reliable approach to detecting truthfulness, highlighting its potential to enhance the reliability of LLM-generated content and its practical applicability in real-world scenarios.</abstract>
      <url hash="2a971ddc">2023.findings-emnlp.68</url>
      <bibkey>azaria-mitchell-2023-internal</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.68</doi>
    </paper>
    <paper id="69">
      <title>Factual Relation Discrimination for Factuality-oriented Abstractive Summarization</title>
      <author><first>Zhiguang</first><last>Gao</last></author>
      <author><first>Peifeng</first><last>Li</last></author>
      <author><first>Feng</first><last>Jiang</last></author>
      <author><first>Xiaomin</first><last>Chu</last></author>
      <author><first>Qiaoming</first><last>Zhu</last></author>
      <pages>977-986</pages>
      <abstract>Most neural abstractive summarization models are capable of producing high-quality summaries. However, they still frequently contain factual errors. Existing factuality-oriented abstractive summarization models only consider the integration of factual information and ignore the causes of factual errors. To address this issue, we propose a factuality-oriented abstractive summarization model DASum, which is based on a new task factual relation discrimination that is able to identify the causes of factual errors. First, we use data augmentation methods to construct counterfactual summaries (i. e., negative samples), and build a factual summarization dataset. Then, we propose the factual relation discrimination task, which determines the factuality of the dependency relations in summaries during summary generation and guides our DASum to generate factual relations, thereby improving the factuality of summaries. Experimental results on the CNN/DM and XSUM datasets show that our DASum outperforms several state-of-the-art benchmarks in terms of the factual metrics.</abstract>
      <url hash="bd9dc776">2023.findings-emnlp.69</url>
      <bibkey>gao-etal-2023-factual</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.69</doi>
    </paper>
    <paper id="70">
      <title>Multi-Modal Knowledge Graph Transformer Framework for Multi-Modal Entity Alignment</title>
      <author><first>Qian</first><last>Li</last></author>
      <author><first>Cheng</first><last>Ji</last></author>
      <author><first>Shu</first><last>Guo</last></author>
      <author><first>Zhaoji</first><last>Liang</last></author>
      <author><first>Lihong</first><last>Wang</last></author>
      <author><first>Jianxin</first><last>Li</last></author>
      <pages>987-999</pages>
      <abstract>Multi-Modal Entity Alignment (MMEA) is a critical task that aims to identify equivalent entity pairs across multi-modal knowledge graphs (MMKGs). However, this task faces challenges due to the presence of different types of information, including neighboring entities, multi-modal attributes, and entity types. Directly incorporating the above information (e.g., concatenation or attention) can lead to an unaligned information space. To address these challenges, we propose a novel MMEA transformer, called Meaformer, that hierarchically introduces neighbor features, multi-modal attributes, and entity types to enhance the alignment task. Taking advantage of the transformer’s ability to better integrate multiple information, we design a hierarchical modifiable self-attention block in a transformer encoder to preserve the unique semantics of different information. Furthermore, we design two entity-type prefix injection methods to redintegrate entity-type information using type prefixes, which help to restrict the global information of entities not present in the MMKGs.</abstract>
      <url hash="5b6d8938">2023.findings-emnlp.70</url>
      <bibkey>li-etal-2023-multi-modal-knowledge</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.70</doi>
    </paper>
    <paper id="71">
      <title>Is a Prestigious Job the same as a Prestigious Country? A Case Study on Multilingual Sentence Embeddings and <fixed-case>E</fixed-case>uropean Countries</title>
      <author><first>Jindřich</first><last>Libovický</last></author>
      <pages>1000-1010</pages>
      <abstract>We study how multilingual sentence representations capture European countries and occupations and how this differs across European languages. We prompt the models with templated sentences that we machine-translate into 12 European languages and analyze the most prominent dimensions in the embeddings. Our analysis reveals that the most prominent feature in the embedding is the political distinction between Eastern and Western Europe and the country’s economic strength in terms of GDP. When prompted specifically for job prestige, the embedding space clearly distinguishes high and low-prestige jobs. The occupational dimension is uncorrelated with the most dominant country dimensions in three out of four studied models. The exception is a small distilled model that exhibits a connection between occupational prestige and country of origin, which is a potential source of nationality-based discrimination. Our findings are consistent across languages.</abstract>
      <url hash="4b3c440b">2023.findings-emnlp.71</url>
      <bibkey>libovicky-2023-prestigious</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.71</doi>
    </paper>
    <paper id="72">
      <title>Towards A Holistic Landscape of Situated Theory of Mind in Large Language Models</title>
      <author><first>Ziqiao</first><last>Ma</last></author>
      <author><first>Jacob</first><last>Sansom</last></author>
      <author><first>Run</first><last>Peng</last></author>
      <author><first>Joyce</first><last>Chai</last></author>
      <pages>1011-1031</pages>
      <abstract>Large Language Models (LLMs) have generated considerable interest and debate regarding their potential emergence of Theory of Mind (ToM). Several recent inquiries reveal a lack of robust ToM in these models and pose a pressing demand to develop new benchmarks, as current ones primarily focus on different aspects of ToM and are prone to shortcuts and data leakage. In this position paper, we seek to answer two road-blocking questions: (1) How can we taxonomize a holistic landscape of machine ToM? (2) What is a more effective evaluation protocol for machine ToM? Following psychological studies, we taxonomize machine ToM into 7 mental state categories and delineate existing benchmarks to identify under-explored aspects of ToM. We argue for a holistic and situated evaluation of ToM to break ToM into individual components and treat LLMs as an agent who is physically situated in environments and socially situated in interactions with humans. Such situated evaluation provides a more comprehensive assessment of mental states and potentially mitigates the risk of shortcuts and data leakage. We further present a pilot study in a grid world setup as a proof of concept. We hope this position paper can facilitate future research to integrate ToM with LLMs and offer an intuitive means for researchers to better position their work in the landscape of ToM.</abstract>
      <url hash="59156af8">2023.findings-emnlp.72</url>
      <bibkey>ma-etal-2023-towards-holistic</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.72</doi>
    </paper>
    <paper id="73">
      <title>Text Augmented Spatial Aware Zero-shot Referring Image Segmentation</title>
      <author><first>Yucheng</first><last>Suo</last></author>
      <author><first>Linchao</first><last>Zhu</last></author>
      <author><first>Yi</first><last>Yang</last></author>
      <pages>1032-1043</pages>
      <abstract>In this paper, we study a challenging task of zero-shot referring image segmentation. This task aims to identify the instance mask that is most related to a referring expression <b>without</b> training on pixel-level annotations. Previous research takes advantage of pre-trained cross-modal models, e.g., CLIP, to align instance-level masks with referring expressions. Yet, CLIP only considers the global-level alignment of image-text pairs, neglecting fine-grained matching between the referring sentence and local image regions. To address this challenge, we introduce a Text Augmented Spatial-aware (TAS) zero-shot referring image segmentation framework that is training-free and robust to various visual encoders. TAS incorporates a mask proposal network for instance-level mask extraction, a text-augmented visual-text matching score for mining the image-text correlation, and a spatial rectifier for mask post-processing. Notably, the text-augmented visual-text matching score leverages a <tex-math>P</tex-math>-score and an <tex-math>N</tex-math>-score in addition to the typical visual-text matching score. The <tex-math>P</tex-math>-score is utilized to close the visual-text domain gap through a surrogate captioning model, where the score is computed between the surrogate model-generated texts and the referring expression. The <tex-math>N</tex-math>-score considers the fine-grained alignment of region-text pairs via negative phrase mining, encouraging the masked image to be repelled from the mined distracting phrases. Extensive experiments are conducted on various datasets, including RefCOCO, RefCOCO+, and RefCOCOg. The proposed method clearly outperforms state-of-the-art zero-shot referring image segmentation methods.</abstract>
      <url hash="f62ee129">2023.findings-emnlp.73</url>
      <bibkey>suo-etal-2023-text</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.73</doi>
    </paper>
    <paper id="74">
      <title><fixed-case>IRFL</fixed-case>: Image Recognition of Figurative Language</title>
      <author><first>Ron</first><last>Yosef</last></author>
      <author><first>Yonatan</first><last>Bitton</last></author>
      <author><first>Dafna</first><last>Shahaf</last></author>
      <pages>1044-1058</pages>
      <abstract>Figures of speech such as metaphors, similes, and idioms are integral parts of human communication. They are ubiquitous in many forms of discourse, allowing people to convey complex, abstract ideas and evoke emotion. As figurative forms are often conveyed through multiple modalities (e.g., both text and images), understanding multimodal figurative language is an important AI challenge, weaving together profound vision, language, commonsense and cultural knowledge. In this work, we develop the Image Recognition of Figurative Language (IRFL) dataset. We leverage human annotation and an automatic pipeline we created to generate a multimodal dataset, and introduce two novel tasks as a benchmark for multimodal figurative language understanding. We experimented with state-of-the-art vision and language models and found that the best (22%) performed substantially worse than humans (97%). We release our dataset, benchmark, and code in hopes of driving the development of models that can better understand figurative language.</abstract>
      <url hash="19e36170">2023.findings-emnlp.74</url>
      <bibkey>yosef-etal-2023-irfl</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.74</doi>
    </paper>
    <paper id="75">
      <title>Self-supervised Meta-Prompt Learning with Meta-Gradient Regularization for Few-shot Generalization</title>
      <author><first>Kaihang</first><last>Pan</last></author>
      <author><first>Juncheng</first><last>Li</last></author>
      <author><first>Hongye</first><last>Song</last></author>
      <author><first>Jun</first><last>Lin</last></author>
      <author><first>Xiaozhong</first><last>Liu</last></author>
      <author><first>Siliang</first><last>Tang</last></author>
      <pages>1059-1077</pages>
      <abstract>Prompt tuning is a parameter-efficient method, which learns soft prompts and conditions frozen language models to perform specific downstream tasks. Though effective, prompt tuning under few-shot settings on the one hand heavily relies on a good initialization of soft prompts. On the other hand, it can easily overfit to few-shot training samples, thereby undermining generalizability. Existing works leverage pre-training or supervised meta-learning to initialize soft prompts but they fail to data-efficiently generalize to unseen downstream tasks. To address the above problems, this paper proposes a novel Self-sUpervised meta-Prompt learning framework with MEta-gradient Regularization for few-shot generalization (SUPMER). SUPMER leverages self-supervised meta-learning with a diverse set of well-designed meta-tasks to learn a universal prompt initialization for efficient adaptation using only unlabeled data. Additionally, it jointly meta-learns a gradient regularization function to transform raw gradients into a domain-generalizable direction, thus alleviating the problem of overfitting. Extensive experiments show that SUPMER achieves better performance for different few-shot downstream tasks, and also exhibits a stronger domain generalization ability. The code for SUPMER will be available at https://github.com/beepkh/SUPMER.</abstract>
      <url hash="23944d91">2023.findings-emnlp.75</url>
      <bibkey>pan-etal-2023-self</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.75</doi>
    </paper>
    <paper id="76">
      <title>An Adaptive Prompt Generation Framework for Task-oriented Dialogue System</title>
      <author><first>Jun</first><last>Gao</last></author>
      <author><first>Liuyu</first><last>Xiang</last></author>
      <author><first>Huijia</first><last>Wu</last></author>
      <author><first>Han</first><last>Zhao</last></author>
      <author><first>Yiqi</first><last>Tong</last></author>
      <author><first>Zhaofeng</first><last>He</last></author>
      <pages>1078-1089</pages>
      <abstract>The de facto way of utilizing black-box large language models (LLMs) to perform various downstream tasks is prompting. However, obtaining suitable prompts for specific tasks is still a challenging problem. While existing LLM-based methods demonstrate promising performance in task-oriented dialogue (TOD) task, they often require manual adjustment in prompt selection, or focus solely on dialogue understanding or generation. To address these issues, we propose an adaptive prompt generation framework to fully unleash the potential of LLMs for the comprehensive TOD system. Firstly, we design a trainable slot generator (TSG) that can generate domain and slot information in the belief state, which serves as prior knowledge for subsequent prompt generation. Next, we propose an adaptive prompt generator (APG) that utilizes the prior knowledge to generate prompts for the LLM, deriving the belief state and system response of the dialogue for evaluation. Finally, we evaluate our framework on the MultiWOZ 2.0 dataset. Extensive experiments demonstrate that our method outperforms existing methods. Our code and data will be released.</abstract>
      <url hash="fca3a63a">2023.findings-emnlp.76</url>
      <bibkey>gao-etal-2023-adaptive</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.76</doi>
    </paper>
    <paper id="77">
      <title>Temporal Knowledge Graph Reasoning Based on N-tuple Modeling</title>
      <author><first>Zhongni</first><last>Hou</last></author>
      <author><first>Xiaolong</first><last>Jin</last></author>
      <author><first>Zixuan</first><last>Li</last></author>
      <author><first>Long</first><last>Bai</last></author>
      <author><first>Saiping</first><last>Guan</last></author>
      <author><first>Yutao</first><last>Zeng</last></author>
      <author><first>Jiafeng</first><last>Guo</last></author>
      <author><first>Xueqi</first><last>Cheng</last></author>
      <pages>1090-1100</pages>
      <abstract>Reasoning over Temporal Knowledge Graphs (TKGs) that predicts temporal facts (e.g., events) in the future is crucial for many applications. The temporal facts in existing TKGs only contain their core entities (i.e., the entities playing core roles therein) and formulate them as quadruples, i.e., (subject entity, predicate, object entity, timestamp). This formulation oversimplifies temporal facts and inevitably causes information loss. Therefore, we propose to describe a temporal fact more accurately as an n-tuple, containing not only its predicate and core entities, but also its auxiliary entities, as well as the roles of all entities. By so doing, TKGs are augmented to N-tuple Temporal Knowledge Graphs (N-TKGs). To conduct reasoning over N-TKGs, we further propose N-tuple Evolutional Network (NE-Net). It recurrently learns the evolutional representations of entities and predicates in temporal facts at different timestamps in the history via modeling the relations among those entities and predicates. Based on the learned representations, reasoning tasks at future timestamps can be realized via task-specific decoders. Experiment results on two newly built datasets demonstrate the superiority of N-TKG and the effectiveness of NE-Net.</abstract>
      <url hash="76e07a62">2023.findings-emnlp.77</url>
      <bibkey>hou-etal-2023-temporal</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.77</doi>
    </paper>
    <paper id="78">
      <title>Make Your Decision Convincing! A Unified Two-Stage Framework: Self-Attribution and Decision-Making</title>
      <author><first>Yanrui</first><last>Du</last></author>
      <author><first>Sendong</first><last>Zhao</last></author>
      <author><first>Haochun</first><last>Wang</last></author>
      <author><first>Yuhan</first><last>Chen</last></author>
      <author><first>Rui</first><last>Bai</last></author>
      <author><first>Zewen</first><last>Qiang</last></author>
      <author><first>Muzhen</first><last>Cai</last></author>
      <author><first>Bing</first><last>Qin</last></author>
      <pages>1101-1112</pages>
      <abstract>Explaining black-box model behavior with natural language has achieved impressive results in various NLP tasks. Recent research has explored the utilization of subsequences from the input text as a rationale, providing users with evidence to support the model decision. Although existing frameworks excel in generating high-quality rationales while achieving high task performance, they neglect to account for the unreliable link between the generated rationale and model decision. In simpler terms, a model may make correct decisions while attributing wrong rationales, or make poor decisions while attributing correct rationales. To mitigate this issue, we propose a unified two-stage framework known as Self-Attribution and Decision-Making (SADM). Through extensive experiments on five reasoning datasets from the ERASER benchmark, we demonstrate that our framework not only establishes a more reliable link between the generated rationale and model decision but also achieves competitive results in task performance and the quality of rationale. Furthermore, we explore the potential of our framework in semi-supervised scenarios.</abstract>
      <url hash="d380ebc3">2023.findings-emnlp.78</url>
      <bibkey>du-etal-2023-make</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.78</doi>
    </paper>
    <paper id="79">
      <title>Adaptive Structure Induction for Aspect-based Sentiment Analysis with Spectral Perspective</title>
      <author><first>Hao</first><last>Niu</last></author>
      <author><first>Yun</first><last>Xiong</last></author>
      <author><first>Xiaosu</first><last>Wang</last></author>
      <author><first>Wenjing</first><last>Yu</last></author>
      <author><first>Yao</first><last>Zhang</last></author>
      <author><first>Zhonglei</first><last>Guo</last></author>
      <pages>1113-1126</pages>
      <abstract>Recently, incorporating structure information (e.g. dependency syntactic tree) can enhance the performance of aspect-based sentiment analysis (ABSA). However, this structure information is obtained from off-the-shelf parsers, which is often sub-optimal and cumbersome. Thus, automatically learning adaptive structures is conducive to solving this problem. In this work, we concentrate on structure induction from pre-trained language models (PLMs) and throw the structure induction into a spectrum perspective to explore the impact of scale information in language representation on structure induction ability. Concretely, the main architecture of our model is composed of commonly used PLMs (e.g. RoBERTa, etc), and a simple yet effective graph structure learning (GSL) module (graph learner + GNNs). Subsequently, we plug in spectral filters with different bands respectively after the PLMs to produce filtered language representations and feed them into the GSL module to induce latent structures. We conduct extensive experiments on three public benchmarks for ABSA. The results and further analyses demonstrate that introducing this spectral approach can shorten Aspects-sentiment Distance (AsD) and be beneficial to structure induction. Even based on such a simple framework, the effects on three datasets can reach SOTA (state of the art) or near SOTA performance. Additionally, our exploration also has the potential to be generalized to other tasks or to bring inspiration to other similar domains.</abstract>
      <url hash="7d47f72d">2023.findings-emnlp.79</url>
      <bibkey>niu-etal-2023-adaptive</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.79</doi>
    </paper>
    <paper id="80">
      <title><fixed-case>N</fixed-case>ova<fixed-case>COMET</fixed-case>: Open Commonsense Foundation Models with Symbolic Knowledge Distillation</title>
      <author><first>Peter</first><last>West</last></author>
      <author><first>Ronan</first><last>Bras</last></author>
      <author><first>Taylor</first><last>Sorensen</last></author>
      <author><first>Bill</first><last>Lin</last></author>
      <author><first>Liwei</first><last>Jiang</last></author>
      <author><first>Ximing</first><last>Lu</last></author>
      <author><first>Khyathi</first><last>Chandu</last></author>
      <author><first>Jack</first><last>Hessel</last></author>
      <author><first>Ashutosh</first><last>Baheti</last></author>
      <author><first>Chandra</first><last>Bhagavatula</last></author>
      <author><first>Yejin</first><last>Choi</last></author>
      <pages>1127-1149</pages>
      <abstract>We present NovaCOMET, an open commonsense knowledge model, that combines the best aspects of knowledge and general task models. Compared to previous knowledge models, NovaCOMET allows open-format relations enabling direct application to reasoning tasks; compared to general task models like Flan-T5, it explicitly centers knowledge, enabling superior performance for commonsense reasoning. NovaCOMET leverages the knowledge of opaque proprietary models to create an open knowledge pipeline. First, knowledge is symbolically distilled into NovATOMIC, a publicly-releaseddiscrete knowledge graph which can be audited, critiqued, and filtered. Next, we train NovaCOMET on NovATOMIC by fine-tuning an open-source pretrained model. NovaCOMET uses an open-format training objective, replacing the fixed relation sets of past knowledge models, enabling arbitrary structures within the data to serve as inputs or outputs. The resulting generation model, optionally augmented with human annotation, matches or exceeds comparable open task models like Flan-T5 on a range of commonsense generation tasks. NovaCOMET serves as a counterexample to the contemporary focus on instruction tuning only, demonstrating a distinct advantage to explicitly modeling commonsense knowledge as well.</abstract>
      <url hash="315b2c81">2023.findings-emnlp.80</url>
      <bibkey>west-etal-2023-novacomet</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.80</doi>
    </paper>
    <paper id="81">
      <title>In-Context Demonstration Selection with Cross Entropy Difference</title>
      <author><first>Dan</first><last>Iter</last></author>
      <author><first>Reid</first><last>Pryzant</last></author>
      <author><first>Ruochen</first><last>Xu</last></author>
      <author><first>Shuohang</first><last>Wang</last></author>
      <author id="yang-liu-edinburgh"><first>Yang</first><last>Liu</last></author>
      <author><first>Yichong</first><last>Xu</last></author>
      <author><first>Chenguang</first><last>Zhu</last></author>
      <pages>1150-1162</pages>
      <abstract>Large language models (LLMs) can use in-context demonstrations to improve performance on zero-shot tasks. However, selecting the best in-context examples is challenging because model performance can vary widely depending on the selected examples. We present a cross-entropy difference (CED) method for selecting in-context demonstrations. Our method is based on the observation that the effectiveness of in-context demonstrations negatively correlates with the perplexity of the test example by a language model that was finetuned on that demonstration. We utilize parameter efficient finetuning to train small models on training data that are used for computing the cross-entropy difference between a test example and every candidate in-context demonstration. This metric is used to rank and select in-context demonstrations independently for each test input. We evaluate our method on a mix-domain dataset that combines 8 benchmarks, representing 4 text generation tasks, showing that CED for in-context demonstration selection can improve performance for a variety of LLMs over baseline selection methods.</abstract>
      <url hash="2c0f30eb">2023.findings-emnlp.81</url>
      <bibkey>iter-etal-2023-context</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.81</doi>
    </paper>
    <paper id="82">
      <title>The Past, Present, and Future of Typological Databases in <fixed-case>NLP</fixed-case></title>
      <author><first>Emi</first><last>Baylor</last></author>
      <author><first>Esther</first><last>Ploeger</last></author>
      <author><first>Johannes</first><last>Bjerva</last></author>
      <pages>1163-1169</pages>
      <abstract>Typological information has the potential to be beneficial in the development of NLP models, particularly for low-resource languages. Unfortunately, current large-scale typological databases, notably WALS and Grambank, are inconsistent both with each other and with other sources of typological information, such as linguistic grammars. Some of these inconsistencies stem from coding errors or linguistic variation, but many of the disagreements are due to the discrete categorical nature of these databases. We shed light on this issue by systematically exploring disagreements across typological databases and resources, and their uses in NLP, covering the past and present. We next investigate the future of such work, offering an argument that a continuous view of typological features is clearly beneficial, echoing recommendations from linguistics. We propose that such a view of typology has significant potential in the future, including in language modeling in low-resource scenarios.</abstract>
      <url hash="71aa674a">2023.findings-emnlp.82</url>
      <bibkey>baylor-etal-2023-past</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.82</doi>
    </paper>
    <paper id="83">
      <title><fixed-case>S</fixed-case>oul<fixed-case>C</fixed-case>hat: Improving <fixed-case>LLM</fixed-case>s’ Empathy, Listening, and Comfort Abilities through Fine-tuning with Multi-turn Empathy Conversations</title>
      <author><first>Yirong</first><last>Chen</last></author>
      <author><first>Xiaofen</first><last>Xing</last></author>
      <author><first>Jingkai</first><last>Lin</last></author>
      <author><first>Huimin</first><last>Zheng</last></author>
      <author><first>Zhenyu</first><last>Wang</last></author>
      <author><first>Qi</first><last>Liu</last></author>
      <author><first>Xiangmin</first><last>Xu</last></author>
      <pages>1170-1183</pages>
      <abstract>Large language models (LLMs) have been widely applied in various fields due to their excellent capability for memorizing knowledge and chain of thought (CoT). When these language models are applied in the field of psychological counseling, they often rush to provide universal advice. However, when users seek psychological support, they need to gain empathy, trust, understanding and comfort, rather than just reasonable advice. To this end, we constructed a multi-turn empathetic conversation dataset of more than 2 million samples, in which the input is the multi-turn conversation context, and the target is empathetic responses that cover expressions such as questioning, comfort, recognition, listening, trust, emotional support, etc. Experiments have shown that the empathy ability of LLMs can be significantly enhanced when finetuning by using multi-turn dialogue history and responses that are closer to the expression of a psychological consultant.</abstract>
      <url hash="ae978c9a">2023.findings-emnlp.83</url>
      <bibkey>chen-etal-2023-soulchat</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.83</doi>
    </paper>
    <paper id="84">
      <title>Can <fixed-case>C</fixed-case>hat<fixed-case>GPT</fixed-case> Assess Human Personalities? A General Evaluation Framework</title>
      <author><first>Haocong</first><last>Rao</last></author>
      <author><first>Cyril</first><last>Leung</last></author>
      <author><first>Chunyan</first><last>Miao</last></author>
      <pages>1184-1194</pages>
      <abstract>Large Language Models (LLMs) especially ChatGPT have produced impressive results in various areas, but their potential human-like psychology is still largely unexplored. Existing works study the virtual personalities of LLMs but rarely explore the possibility of analyzing human personalities via LLMs. This paper presents a generic evaluation framework for LLMs to assess human personalities based on Myers–Briggs Type Indicator (MBTI) tests. Specifically, we first devise unbiased prompts by randomly permuting options in MBTI questions and adopt the average testing result to encourage more impartial answer generation. Then, we propose to replace the subject in question statements to enable flexible queries and assessments on different subjects from LLMs. Finally, we re-formulate the question instructions in a manner of correctness evaluation to facilitate LLMs to generate clearer responses. The proposed framework enables LLMs to flexibly assess personalities of different groups of people. We further propose three evaluation metrics to measure the consistency, robustness, and fairness of assessment results from state-of-the-art LLMs including ChatGPT and GPT-4. Our experiments reveal ChatGPT’s ability to assess human personalities, and the average results demonstrate that it can achieve more consistent and fairer assessments in spite of lower robustness against prompt biases compared with InstructGPT.</abstract>
      <url hash="9b4dfc67">2023.findings-emnlp.84</url>
      <bibkey>rao-etal-2023-chatgpt</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.84</doi>
    </paper>
    <paper id="85">
      <title><fixed-case>M</fixed-case>oqa<fixed-case>GPT</fixed-case> : Zero-Shot Multi-modal Open-domain Question Answering with Large Language Model</title>
      <author><first>Le</first><last>Zhang</last></author>
      <author><first>Yihong</first><last>Wu</last></author>
      <author><first>Fengran</first><last>Mo</last></author>
      <author><first>Jian-Yun</first><last>Nie</last></author>
      <author><first>Aishwarya</first><last>Agrawal</last></author>
      <pages>1195-1210</pages>
      <abstract>Multi-modal open-domain question answering typically requires evidence retrieval from databases across diverse modalities, such as images, tables, passages, etc. Even Large Language Models (LLMs) like GPT-4 fall short in this task. To enable LLMs to tackle the task in a zero-shot manner, we introduce MoqaGPT, a straightforward and flexible framework. Using a divide-and-conquer strategy that bypasses intricate multi-modality ranking, our framework can accommodate new modalities and seamlessly transition to new models for the task. Built upon LLMs, MoqaGPT retrieves and extracts answers from each modality separately, then fuses this multi-modal information using LLMs to produce a final answer. Our methodology boosts performance on the MMCoQA dataset, improving F1 by +37.91 points and EM by +34.07 points over the supervised baseline. On the MultiModalQA dataset, MoqaGPT surpasses the zero-shot baseline, improving F1 by 9.5 points and EM by 10.1 points, and significantly closes the gap with supervised methods. Our codebase is available at https://github.com/lezhang7/MOQAGPT.</abstract>
      <url hash="62b4b411">2023.findings-emnlp.85</url>
      <bibkey>zhang-etal-2023-moqagpt</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.85</doi>
    </paper>
    <paper id="86">
      <title>Large Language Models Know Your Contextual Search Intent: A Prompting Framework for Conversational Search</title>
      <author><first>Kelong</first><last>Mao</last></author>
      <author><first>Zhicheng</first><last>Dou</last></author>
      <author><first>Fengran</first><last>Mo</last></author>
      <author><first>Jiewen</first><last>Hou</last></author>
      <author><first>Haonan</first><last>Chen</last></author>
      <author><first>Hongjin</first><last>Qian</last></author>
      <pages>1211-1225</pages>
      <abstract>Precisely understanding users’ contextual search intent has been an important challenge for conversational search. As conversational search sessions are much more diverse and long-tailed, existing methods trained on limited data still show unsatisfactory effectiveness and robustness to handle real conversational search scenarios. Recently, large language models (LLMs) have demonstrated amazing capabilities for text generation and conversation understanding. In this work, we present a simple yet effective prompting framework, called LLM4CS, to leverage LLMs as a text-based search intent interpreter to help conversational search. Under this framework, we explore three prompting methods to generate multiple query rewrites and hypothetical responses, and propose to aggregate them into an integrated representation that can robustly represent the user’s real contextual search intent. Extensive automatic evaluations and human evaluations on three widely used conversational search benchmarks, including CAsT-19, CAsT-20, and CAsT-21, demonstrate the remarkable performance of our simple LLM4CS framework compared with existing methods and even using human rewrites. Our findings provide important evidence to better understand and leverage LLMs for conversational search.</abstract>
      <url hash="6ea914b3">2023.findings-emnlp.86</url>
      <bibkey>mao-etal-2023-large</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.86</doi>
    </paper>
    <paper id="87">
      <title><fixed-case>D</fixed-case>oc<fixed-case>A</fixed-case>s<fixed-case>R</fixed-case>ef: An Empirical Study on Repurposing Reference-based Summary Quality Metrics as Reference-free Metrics</title>
      <author><first>Forrest</first><last>Bao</last></author>
      <author><first>Ruixuan</first><last>Tu</last></author>
      <author><first>Ge</first><last>Luo</last></author>
      <author><first>Yinfei</first><last>Yang</last></author>
      <author><first>Hebi</first><last>Li</last></author>
      <author><first>Minghui</first><last>Qiu</last></author>
      <author><first>Youbiao</first><last>He</last></author>
      <author><first>Cen</first><last>Chen</last></author>
      <pages>1226-1235</pages>
      <abstract>Automated summary quality assessment falls into two categories: reference-based and reference-free. Reference-based metrics, historically deemed more accurate due to the additional information provided by human-written references, are limited by their reliance on human input. In this paper, we hypothesize that the comparison methodologies used by some reference-based metrics to evaluate a system summary against its corresponding reference can be effectively adapted to assess it against its source document, thereby transforming these metrics into reference-free ones. Experimental results support this hypothesis. After being repurposed reference-freely, the zero-shot BERTScore using the pretrained DeBERTa-large-MNLI model of <tex-math>&lt;</tex-math>0.5B parameters consistently outperforms its original reference-based version across various aspects on the SummEval and Newsroom datasets. It also excels in comparison to most existing reference-free metrics and closely competes with zero-shot summary evaluators based on GPT-3.5.</abstract>
      <url hash="1bd595cb">2023.findings-emnlp.87</url>
      <bibkey>bao-etal-2023-docasref</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.87</doi>
    </paper>
    <paper id="88">
      <title>Toxicity in chatgpt: Analyzing persona-assigned language models</title>
      <author><first>Ameet</first><last>Deshpande</last></author>
      <author><first>Vishvak</first><last>Murahari</last></author>
      <author><first>Tanmay</first><last>Rajpurohit</last></author>
      <author><first>Ashwin</first><last>Kalyan</last></author>
      <author><first>Karthik</first><last>Narasimhan</last></author>
      <pages>1236-1270</pages>
      <abstract>Large language models (LLMs) have shown incredible capabilities and transcended the natural language processing (NLP) community, with adoption throughout many services like healthcare, therapy, education, and customer service. Since users include people with critical information needs like students or patients engaging with chatbots, the safety of these systems is of prime importance. Legislation has recognized its significance and recently drafted a “Blueprint For An AI Bill Of Rights” which calls for domain experts to identify risks and potential impact of AI systems. To this end, we systematically evaluate toxicity in over half a million generations of ChatGPT, a popular dialogue-based LLM. We find that setting the system parameter of ChatGPT by assigning it a persona, say that of the boxer Muhammad Ali, significantly increases the toxicity of generations. Depending on the persona assigned to ChatGPT, its toxicity can increase up to <tex-math>6\times</tex-math>, with outputs engaging in incorrect stereotypes, harmful dialogue, and hurtful opinions. Furthermore, we find concerning patterns where specific entities (e.g., certain races) are targeted more than others (<tex-math>3\times</tex-math> more) irrespective of the assigned persona, reflecting discriminatory biases in the model. Our findings show that multiple provisions in the legislative blueprint are being violated, and we hope that the broader AI community rethinks the efficacy of current safety guardrails and develops better techniques that lead to robust, safe, and trustworthy AI.</abstract>
      <url hash="a577e4cb">2023.findings-emnlp.88</url>
      <bibkey>deshpande-etal-2023-toxicity</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.88</doi>
    </paper>
    <paper id="89">
      <title>Execution-Based Evaluation for Open-Domain Code Generation</title>
      <author><first>Zhiruo</first><last>Wang</last></author>
      <author><first>Shuyan</first><last>Zhou</last></author>
      <author><first>Daniel</first><last>Fried</last></author>
      <author><first>Graham</first><last>Neubig</last></author>
      <pages>1271-1290</pages>
      <abstract>To extend the scope of coding queries to more realistic settings, we propose ODEX, the first Open-Domain EXecution-based natural language (NL) to Python code generation dataset. ODEX has 945 NL-Code pairs spanning 79 diverse libraries, along with 1,707 human-written test cases for execution. Our NL-Code pairs are harvested from StackOverflow forums to encourage natural and practical coding queries. Moreover, ODEX supports four natural languages as intents, in English, Spanish, Japanese, and Russian. ODEX unveils intriguing behavioral differences among top-performing code language models (LM). While CODEX achieves better overall results, CODEGEN improves effectively via scaling – CODEGEN 6.1B performs comparably with CODEX 12B. Both models show substantial gaps between open and closed domains, but CODEGEN gaps tend to decrease with model size while CODEX gaps increase. We release ODEX to facilitate research into open-domain problems for the code generation community.</abstract>
      <url hash="595f3677">2023.findings-emnlp.89</url>
      <bibkey>wang-etal-2023-execution</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.89</doi>
    </paper>
    <paper id="90">
      <title>Syntax-Aware Retrieval Augmented Code Generation</title>
      <author><first>Xiangyu</first><last>Zhang</last></author>
      <author><first>Yu</first><last>Zhou</last></author>
      <author><first>Guang</first><last>Yang</last></author>
      <author><first>Taolue</first><last>Chen</last></author>
      <pages>1291-1302</pages>
      <abstract>Neural code generation models are nowadays widely adopted to generate code from natural language descriptions automatically. Recently, pre-trained neural models equipped with token-level retrieval capabilities have exhibited great potentials in neural machine translation. However, applying them directly to code generation experience challenges: the use of the retrieval-based mechanism inevitably introduces extraneous noise to the generation process, resulting in even syntactically incorrect code. Computationally, such models necessitate frequent searches of the cached datastore, which turns out to be time-consuming. To address these issues, we propose <tex-math>k</tex-math>NN-TRANX, a token-level retrieval augmented code generation method. <tex-math>k</tex-math>NN-TRANX allows for searches in smaller datastores tailored for the code generation task. It leverages syntax constraints for the retrieval of datastores, which reduces the impact of retrieve noise. We evaluate <tex-math>k</tex-math>NN-TRANX on two public datasets and the experimental results confirm the effectiveness of our approach.</abstract>
      <url hash="19ea34b0">2023.findings-emnlp.90</url>
      <bibkey>zhang-etal-2023-syntax</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.90</doi>
    </paper>
    <paper id="91">
      <title>Selecting Key Views for Zero-Shot Entity Linking</title>
      <author><first>Xuhui</first><last>Sui</last></author>
      <author><first>Ying</first><last>Zhang</last></author>
      <author><first>Kehui</first><last>Song</last></author>
      <author><first>Baohang</first><last>Zhou</last></author>
      <author><first>Xiaojie</first><last>Yuan</last></author>
      <author><first>Wensheng</first><last>Zhang</last></author>
      <pages>1303-1312</pages>
      <abstract>Entity linking, which aligns mentions in the text to entities in knowledge bases, is essential for many natural language processing tasks. Considering the real-world scenarios, recent research hotspot of entity linking has focused on the zero-shot setting, where mentions need to link to unseen entities and only the description of each entity is provided. This task challenges the language understanding ability of models to capture the coherence evidence between the mention context and entity description. However, entity descriptions often contain rich information from multiple views, and a mention with context only relates to a small part of the information. Other irrelevant information will introduce noise, which interferes with models to make the right judgments. Furthermore, the existence of these information also makes it difficult to synthesize key information. To solve these problems, we select key views from descriptions and propose a KVZEL framework for zero-shot entity linking. Specifically, our KVZEL first adopts unsupervised clustering to form sub views. Then, it employs a mention-aware key views selection module to iteratively accumulate mention-focused views. This puts emphasis on capturing mention-related information and allows long-range key information integration. Finally, we aggregate key views to make the final decision. Experimental results show the effectiveness of our KVZEL and it achieves the new state-of-the-art on the zero-shot entity linking dataset.</abstract>
      <url hash="b6aa5f15">2023.findings-emnlp.91</url>
      <bibkey>sui-etal-2023-selecting</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.91</doi>
    </paper>
    <paper id="92">
      <title>Is Explanation the Cure? Misinformation Mitigation in the Short Term and Long Term</title>
      <author><first>Yi-Li</first><last>Hsu</last></author>
      <author><first>Shih-Chieh</first><last>Dai</last></author>
      <author><first>Aiping</first><last>Xiong</last></author>
      <author><first>Lun-Wei</first><last>Ku</last></author>
      <pages>1313-1323</pages>
      <abstract>With advancements in natural language processing (NLP) models, automatic explanation generation has been proposed to mitigate misinformation on social media platforms in addition to adding warning labels to identified fake news. While many researchers have focused on generating good explanations, how these explanations can really help humans combat fake news is under-explored. In this study, we compare the effectiveness of a warning label and the state-of- the-art counterfactual explanations generated by GPT-4 in debunking misinformation. In a two-wave, online human-subject study, participants (N = 215) were randomly assigned to a control group in which false contents are shown without any intervention, a warning tag group in which the false claims were labeled, or an explanation group in which the false contents were accompanied by GPT-4 generated explanations. Our results show that both interventions significantly decrease participants’ self-reported belief in fake claims in an equivalent manner for the short-term and long-term. We discuss the implications of our findings and directions for future NLP-based misinformation debunking strategies.</abstract>
      <url hash="54d13b85">2023.findings-emnlp.92</url>
      <bibkey>hsu-etal-2023-explanation</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.92</doi>
    </paper>
    <paper id="93">
      <title>Improving the Robustness of Summarization Models by Detecting and Removing Input Noise</title>
      <author><first>Kundan</first><last>Krishna</last></author>
      <author><first>Yao</first><last>Zhao</last></author>
      <author><first>Jie</first><last>Ren</last></author>
      <author><first>Balaji</first><last>Lakshminarayanan</last></author>
      <author><first>Jiaming</first><last>Luo</last></author>
      <author><first>Mohammad</first><last>Saleh</last></author>
      <author><first>Peter</first><last>Liu</last></author>
      <pages>1324-1336</pages>
      <abstract>The evaluation of abstractive summarization models typically uses test data that is identically distributed as training data. In real-world practice, documents to be summarized may contain input noise caused by text extraction artifacts or data pipeline bugs. The robustness of model performance under distribution shift caused by such noise is relatively under studied. We present a large empirical study quantifying the sometimes severe loss in performance – up to 12 ROUGE-1 points – from different types of input noise for a range of datasets and model sizes. We then propose a light-weight method for detecting and removing such noise in the input during model inference without requiring any extra training, auxiliary models, or even prior knowledge of the type of noise. Our proposed approach effectively mitigates the loss in performance, recovering a large fraction of the performance drop, sometimes as large as 11 ROUGE-1 points.</abstract>
      <url hash="44a8a513">2023.findings-emnlp.93</url>
      <bibkey>krishna-etal-2023-improving</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.93</doi>
    </paper>
    <paper id="94">
      <title>How Reliable Are <fixed-case>AI</fixed-case>-Generated-Text Detectors? An Assessment Framework Using Evasive Soft Prompts</title>
      <author><first>Tharindu</first><last>Kumarage</last></author>
      <author><first>Paras</first><last>Sheth</last></author>
      <author><first>Raha</first><last>Moraffah</last></author>
      <author><first>Joshua</first><last>Garland</last></author>
      <author><first>Huan</first><last>Liu</last></author>
      <pages>1337-1349</pages>
      <abstract>In recent years, there has been a rapid proliferation of AI-generated text, primarily driven by the release of powerful pre-trained language models (PLMs). To address the issue of misuse associated with AI-generated text, various high-performing detectors have been developed, including the OpenAI detector and the Stanford DetectGPT. In our study, we ask how reliable these detectors are. We answer the question by designing a novel approach that can prompt any PLM to generate text that evades these high-performing detectors. The proposed approach suggests a universal evasive prompt, a novel type of soft prompt, which guides PLMs in producing “human-like” text that can mislead the detectors. The novel universal evasive prompt is achieved in two steps: First, we create an evasive soft prompt tailored to a specific PLM through prompt tuning; and then, we leverage the transferability of soft prompts to transfer the learned evasive soft prompt from one PLM to another. Employing multiple PLMs in various writing tasks, we conduct extensive experiments to evaluate the efficacy of the evasive soft prompts in their evasion of state-of-the-art detectors.</abstract>
      <url hash="5531bd4b">2023.findings-emnlp.94</url>
      <bibkey>kumarage-etal-2023-reliable</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.94</doi>
    </paper>
    <paper id="95">
      <title>Knowledge is a Region in Weight Space for Fine-tuned Language Models</title>
      <author><first>Almog</first><last>Gueta</last></author>
      <author><first>Elad</first><last>Venezian</last></author>
      <author><first>Colin</first><last>Raffel</last></author>
      <author><first>Noam</first><last>Slonim</last></author>
      <author><first>Yoav</first><last>Katz</last></author>
      <author><first>Leshem</first><last>Choshen</last></author>
      <pages>1350-1370</pages>
      <abstract>Research on neural networks has focused on understanding a single model trained on a single dataset. However, relatively little is known about the relationships between different models, particularly those trained or tested on different datasets. We address this by studying how the weight space and the underlying loss landscape of different models are interconnected. Specifically, we demonstrate that finetuned models that were optimized for high performance, reside in well-defined regions in weight space, and vice versa – that any model that resides anywhere in those regions also exhibits high performance. Notably, we show that language models that have been finetuned on the same dataset form a tight cluster in the weight space, while models finetuned on different datasets from the same underlying task form a looser cluster. Moreover, traversing around the region between the models leads to new models that perform comparably or even better than models obtained via finetuning, even on tasks that the original models were not finetuned on. Our findings provide insight into the relationships between models, demonstrating that a model positioned between two similar models can acquire the knowledge of both. We leverage this and design a method for selecting a better model for efficient finetuning. Specifically, we show that starting from the center of the region is as effective, if not more, than using the pretrained model in 11 out of 12 datasets, resulting in an average accuracy improvement of 3.06.</abstract>
      <url hash="05f5f9de">2023.findings-emnlp.95</url>
      <bibkey>gueta-etal-2023-knowledge</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.95</doi>
    </paper>
    <paper id="96">
      <title>Unveiling the Multi-Annotation Process: Examining the Influence of Annotation Quantity and Instance Difficulty on Model Performance</title>
      <author><first>Pritam</first><last>Kadasi</last></author>
      <author><first>Mayank</first><last>Singh</last></author>
      <pages>1371-1388</pages>
      <abstract>The NLP community has long advocated for the construction of multi-annotator datasets to better capture the nuances of language interpretation, subjectivity, and ambiguity. This paper conducts a retrospective study to show how performance scores can vary when a dataset expands from a single annotation per instance to multiple annotations. We propose a novel multi-annotator simulation process to generate datasets with varying annotation budgets. We show that similar datasets with the same annotation budget can lead to varying performance gains. Our findings challenge the popular belief that models trained on multi-annotation examples always lead to better performance than models trained on single or few-annotation examples.</abstract>
      <url hash="74f2cd91">2023.findings-emnlp.96</url>
      <bibkey>kadasi-singh-2023-unveiling</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.96</doi>
    </paper>
    <paper id="97">
      <title>On the Risk of Misinformation Pollution with Large Language Models</title>
      <author><first>Yikang</first><last>Pan</last></author>
      <author><first>Liangming</first><last>Pan</last></author>
      <author><first>Wenhu</first><last>Chen</last></author>
      <author><first>Preslav</first><last>Nakov</last></author>
      <author><first>Min-Yen</first><last>Kan</last></author>
      <author><first>William</first><last>Wang</last></author>
      <pages>1389-1403</pages>
      <abstract>We investigate the potential misuse of modern Large Language Models (LLMs) for generating credible-sounding misinformation and its subsequent impact on information-intensive applications, particularly Open-Domain Question Answering (ODQA) systems. We establish a threat model and simulate potential misuse scenarios, both unintentional and intentional, to assess the extent to which LLMs can be utilized to produce misinformation. Our study reveals that LLMs can act as effective misinformation generators, leading to a significant degradation (up to 87%) in the performance of ODQA systems. Moreover, we uncover disparities in the attributes associated with persuading humans and machines, presenting an obstacle to current human-centric approaches to combat misinformation. To mitigate the harm caused by LLM-generated misinformation, we propose three defense strategies: misinformation detection, vigilant prompting, and reader ensemble. These approaches have demonstrated promising results, albeit with certain associated costs. Lastly, we discuss the practicality of utilizing LLMs as automatic misinformation generators and provide relevant resources and code to facilitate future research in this area.</abstract>
      <url hash="709a5275">2023.findings-emnlp.97</url>
      <bibkey>pan-etal-2023-risk</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.97</doi>
    </paper>
    <paper id="98">
      <title>Dolphin: A Challenging and Diverse Benchmark for <fixed-case>A</fixed-case>rabic <fixed-case>NLG</fixed-case></title>
      <author><first>El Moatez Billah</first><last>Nagoudi</last></author>
      <author><first>AbdelRahim</first><last>Elmadany</last></author>
      <author><first>Ahmed</first><last>El-Shangiti</last></author>
      <author><first>Muhammad</first><last>Abdul-Mageed</last></author>
      <pages>1404-1422</pages>
      <abstract>We present Dolphin, a novel benchmark that addresses the need for a natural language generation (NLG) evaluation framework dedicated to the wide collection of Arabic languages and varieties. The proposed benchmark encompasses a broad range of 13 different NLG tasks, including dialogue generation, question answering, machine translation, summarization, among others. Dolphin comprises a substantial corpus of 40 diverse and representative public datasets across 50 test splits, carefully curated to reflect real-world scenarios and the linguistic richness of Arabic. It sets a new standard for evaluating the performance and generalization capabilities of Arabic and multilingual models, promising to enable researchers to push the boundaries of current methodologies. We provide an extensive analysis of Dolphin, highlighting its diversity and identifying gaps in current Arabic NLG research. We also offer a public leaderboard that is both interactive and modular and evaluate several Arabic and multilingual models on our benchmark, allowing us to set strong baselines against which researchers can compare.</abstract>
      <url hash="63e5ae51">2023.findings-emnlp.98</url>
      <bibkey>nagoudi-etal-2023-dolphin</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.98</doi>
    </paper>
    <paper id="99">
      <title>Hierarchical Enhancement Framework for Aspect-based Argument Mining</title>
      <author><first>Yujie</first><last>Fu</last></author>
      <author><first>Yang</first><last>Li</last></author>
      <author><first>Suge</first><last>Wang</last></author>
      <author><first>Xiaoli</first><last>Li</last></author>
      <author><first>Deyu</first><last>Li</last></author>
      <author><first>Jian</first><last>Liao</last></author>
      <author><first>JianXing</first><last>Zheng</last></author>
      <pages>1423-1433</pages>
      <abstract>Aspect-Based Argument Mining (ABAM) is a critical task in computational argumentation. Existing methods have primarily treated ABAM as a nested named entity recognition problem, overlooking the need for tailored strategies to effectively address the specific challenges of ABAM tasks. To this end, we propose a layer-based Hierarchical Enhancement Framework (HEF) for ABAM, and introduce three novel components: the Semantic and Syntactic Fusion (SSF) component, the Batch-level Heterogeneous Graph Attention Network (BHGAT) component, and the Span Mask Interactive Attention (SMIA) component. These components serve the purposes of optimizing underlying representations, detecting argument unit stances, and constraining aspect term recognition boundaries, respectively. By incorporating these components, our framework enables better handling of the challenges and improves the performance and accuracy in argument unit and aspect term recognition. Experiments on multiple datasets and various tasks verify the effectiveness of the proposed framework and components.</abstract>
      <url hash="84849990">2023.findings-emnlp.99</url>
      <bibkey>fu-etal-2023-hierarchical</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.99</doi>
    </paper>
    <paper id="100">
      <title><fixed-case>M</fixed-case>enat<fixed-case>QA</fixed-case>: A New Dataset for Testing the Temporal Comprehension and Reasoning Abilities of Large Language Models</title>
      <author><first>Yifan</first><last>Wei</last></author>
      <author><first>Yisong</first><last>Su</last></author>
      <author><first>Huanhuan</first><last>Ma</last></author>
      <author><first>Xiaoyan</first><last>Yu</last></author>
      <author><first>Fangyu</first><last>Lei</last></author>
      <author><first>Yuanzhe</first><last>Zhang</last></author>
      <author><first>Jun</first><last>Zhao</last></author>
      <author><first>Kang</first><last>Liu</last></author>
      <pages>1434-1447</pages>
      <abstract>Large language models (LLMs) have shown nearly saturated performance on many natural language processing (NLP) tasks. As a result, it is natural for people to believe that LLMs have also mastered abilities such as time understanding and reasoning. However, research on the temporal sensitivity of LLMs has been insufficiently emphasized. To fill this gap, this paper constructs Multiple Sensitive Factors Time QA (MenatQA), which encompasses three temporal factors (scope factor, order factor, counterfactual factor) with total 2,853 samples for evaluating the time comprehension and reasoning abilities of LLMs. This paper tests current mainstream LLMs with different parameter sizes, ranging from billions to hundreds of billions. The results show most LLMs fall behind smaller temporal reasoning models with different degree on these factors. In specific, LLMs show a significant vulnerability to temporal biases and depend heavily on the temporal information provided in questions. Furthermore, this paper undertakes a preliminary investigation into potential improvement strategies by devising specific prompts and leveraging external tools. These approaches serve as valuable baselines or references for future research endeavors.</abstract>
      <url hash="07468f85">2023.findings-emnlp.100</url>
      <bibkey>wei-etal-2023-menatqa</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.100</doi>
    </paper>
    <paper id="101">
      <title>What Makes Chain-of-Thought Prompting Effective? A Counterfactual Study</title>
      <author><first>Aman</first><last>Madaan</last></author>
      <author><first>Katherine</first><last>Hermann</last></author>
      <author><first>Amir</first><last>Yazdanbakhsh</last></author>
      <pages>1448-1535</pages>
      <abstract>The effectiveness of Chain-of-thought prompting (CoT) has been widely recognized, but the underlying mechanisms behind its success, the reason why it just works for a wide range of tasks, remains an open question. To investigate this, we employ a counterfactual prompting approach, systematically manipulating elements of examples used in a few-shot prompt, and testing the consequences on model behavior. This allows us to understand the relative contributions of prompt elements such as symbols (digits, entities) and patterns (equations, sentence structure) on in-context learning. Our experiments with three different large language models (LLMs) reveal several key findings. First, the specific symbols used in the prompt do not significantly impact the model’s performance. However, consistent patterns in examples and specifying text in style frequently found on the web are crucial. Second, our findings suggest that the necessity of accurate few-shot examples depends on their role in communicating task understanding. We identify tasks where inaccurate few-shot examples hurt and, surprisingly, tasks where they improve performance. Additionally, we find that the intermediate steps in CoT may not necessarily facilitate learning how to solve a task, but instead efficiently convey task understanding (what) to the model. Furthermore, CoT leverages LLMs to fill in missing commonsense information, particularly helping difficult reasoning problems and long-tail questions.</abstract>
      <url hash="85b1f578">2023.findings-emnlp.101</url>
      <bibkey>madaan-etal-2023-makes</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.101</doi>
    </paper>
    <paper id="102">
      <title>Perceptual Structure in the absence of grounding: the impact of abstractedness and subjectivity in color language for <fixed-case>LLM</fixed-case>s</title>
      <author><first>Pablo</first><last>Loyola</last></author>
      <author><first>Edison</first><last>Marrese-Taylor</last></author>
      <author><first>Andres</first><last>Hoyos-Idrobo</last></author>
      <pages>1536-1542</pages>
      <abstract>The need for grounding in language understanding is an active research topic. Previous work has suggested that color perception and color language appear as a suitable test bed to empirically study the problem, given its cognitive significance and showing that there is considerable alignment between a defined color space and the feature space defined by a language model. To further study this issue, we collect a large scale source of colors and their descriptions, containing almost a 1 million examples , and perform an empirical analysis to compare two kinds of alignments: (i) inter-space, by learning a mapping between embedding space and color space, and (ii) intra-space, by means of prompting comparatives between color descriptions. Our results show that while color space alignment holds for monolexemic, highly pragmatic color descriptions, this alignment drops considerably in the presence of examples that exhibit elements of real linguistic usage such as subjectivity and abstractedness, suggesting that grounding may be required in such cases.</abstract>
      <url hash="8479e2de">2023.findings-emnlp.102</url>
      <bibkey>loyola-etal-2023-perceptual</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.102</doi>
    </paper>
    <paper id="103">
      <title>A Dataset for Investigating the Impact of Context for Offensive Language Detection in Tweets</title>
      <author><first>Musa</first><last>İhtiyar</last></author>
      <author><first>Ömer</first><last>Özdemir</last></author>
      <author><first>Mustafa</first><last>Erengül</last></author>
      <author><first>Arzucan</first><last>Özgür</last></author>
      <pages>1543-1549</pages>
      <abstract>Offensive language detection is crucial in natural language processing (NLP). We investigated the importance of context for detecting such language in reply tweets on Twitter, where the use of offensive language is widespread. We collected a Turkish tweet dataset where the target group was unvaccinated people during the Covid period. Tweets in the dataset were enriched with contextual information by adding the original tweet to which a particular tweet was posted as a reply. The dataset, which includes over 28,000 tweet-reply pairs, was manually labeled by human annotators and made publicly available. In addition, we compared the performance of different machine learning models with and without contextual information. Our results show that this type of contextual information was not very useful in improving the performance of the models in general, although it slightly increased the macro-averaged F1-score of certain models.</abstract>
      <url hash="f4ab687e">2023.findings-emnlp.103</url>
      <bibkey>ihtiyar-etal-2023-dataset</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.103</doi>
    </paper>
    <paper id="104">
      <title>Remember what you did so you know what to do next</title>
      <author><first>Manuel</first><last>Ciosici</last></author>
      <author><first>Alex</first><last>Hedges</last></author>
      <author><first>Yash</first><last>Kankanampati</last></author>
      <author><first>Justin</first><last>Martin</last></author>
      <author><first>Marjorie</first><last>Freedman</last></author>
      <author><first>Ralph</first><last>Weischedel</last></author>
      <pages>1550-1562</pages>
      <abstract>We explore using the 6B parameter GPT-J language model to create a plan for a simulated robot to achieve 30 classes of goals in ScienceWorld, a text game simulator for elementary science experiments and for which previously published empirical work has shown large language models (LLM)s to be a poor fit (Wang et al., 2022). Using the Markov assumption, the LLM outperforms the state-of-the-art based on reinforcement learning by a factor of 1.4. When we fill the LLM’s input buffer with as many prior steps as will fit, improvement rises to 3.3x. Even when training on only 6.5% of the training data, we observe a 2.3x improvement over the state-of-the-art. Our experiments show that performance varies widely across the 30 classes of actions, indicating that averaging over tasks can hide significant performance issues.</abstract>
      <url hash="93912b5c">2023.findings-emnlp.104</url>
      <bibkey>ciosici-etal-2023-remember</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.104</doi>
    </paper>
    <paper id="105">
      <title>An Empirical Study of Multimodal Model Merging</title>
      <author><first>Yi-Lin</first><last>Sung</last></author>
      <author><first>Linjie</first><last>Li</last></author>
      <author><first>Kevin</first><last>Lin</last></author>
      <author><first>Zhe</first><last>Gan</last></author>
      <author><first>Mohit</first><last>Bansal</last></author>
      <author><first>Lijuan</first><last>Wang</last></author>
      <pages>1563-1575</pages>
      <abstract>Model merging (e.g., via interpolation or task arithmetic) fuses multiple models trained on different tasks to generate a multi-task solution. The technique has been proven successful in previous studies, where the models are trained on similar tasks and with the same initialization. In this paper, we expand on this concept to a multimodal setup by merging transformers trained on different modalities. Furthermore, we conduct our study for a novel goal where we can merge vision, language, and cross-modal transformers of a modality-specific architecture to create a parameter-efficient modality-agnostic architecture. Through comprehensive experiments, we systematically investigate the key factors impacting model performance after merging, including initialization, merging mechanisms, and model architectures. We also propose two metrics that assess the distance between weights to be merged and can serve as an indicator of the merging outcomes. Our analysis leads to an effective training recipe for matching the performance of the modality-agnostic baseline (i.e., pre-trained from scratch) via model merging. Our method also outperforms naive merging significantly on various tasks, with improvements of 3% on VQA, 7% on COCO retrieval, 25% on NLVR2, 14% on Flickr30k and 3% on ADE20k.</abstract>
      <url hash="06f5fbda">2023.findings-emnlp.105</url>
      <bibkey>sung-etal-2023-empirical</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.105</doi>
    </paper>
    <paper id="106">
      <title>Learning to Abstract with Nonparametric Variational Information Bottleneck</title>
      <author><first>Melika</first><last>Behjati</last></author>
      <author><first>Fabio</first><last>Fehr</last></author>
      <author><first>James</first><last>Henderson</last></author>
      <pages>1576-1586</pages>
      <abstract>Learned representations at the level of characters, sub-words, words, and sentences, have each contributed to advances in understanding different NLP tasks and linguistic phenomena. However, learning textual embeddings is costly as they are tokenization specific and require different models to be trained for each level of abstraction. We introduce a novel language representation model which can learn to compress to different levels of abstraction at different layers of the same model. We apply Nonparametric Variational Information Bottleneck (NVIB) to stacked Transformer self-attention layers in the encoder, which encourages an information-theoretic compression of the representations through the model. We find that the layers within the model correspond to increasing levels of abstraction and that their representations are more linguistically informed. Finally, we show that NVIB compression results in a model which is more robust to adversarial perturbations.</abstract>
      <url hash="fd84f6f2">2023.findings-emnlp.106</url>
      <bibkey>behjati-etal-2023-learning</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.106</doi>
    </paper>
    <paper id="107">
      <title>Global Structure Knowledge-Guided Relation Extraction Method for Visually-Rich Document</title>
      <author><first>Xiangnan</first><last>Chen</last></author>
      <author><first>Qian</first><last>Xiao</last></author>
      <author><first>Juncheng</first><last>Li</last></author>
      <author><first>Duo</first><last>Dong</last></author>
      <author><first>Jun</first><last>Lin</last></author>
      <author><first>Xiaozhong</first><last>Liu</last></author>
      <author><first>Siliang</first><last>Tang</last></author>
      <pages>1587-1598</pages>
      <abstract>Visual Relation Extraction (VRE) is a powerful means of discovering relationships between entities within visually-rich documents. Existing methods often focus on manipulating entity features to find pairwise relations, yet neglect the more fundamental structural information that links disparate entity pairs together. The absence of global structure information may make the model struggle to learn long-range relations and easily predict conflicted results. To alleviate such limitations, we propose a GlObal Structure knowledge-guided relation Extraction (GOSE) framework. GOSE initiates by generating preliminary relation predictions on entity pairs extracted from a scanned image of the document. Subsequently, global structural knowledge is captured from the preceding iterative predictions, which are then incorporated into the representations of the entities. This “generate-capture-incorporate” cycle is repeated multiple times, allowing entity representations and global structure knowledge to be mutually reinforced. Extensive experiments validate that GOSE not only outperforms existing methods in the standard fine-tuning setting but also reveals superior cross-lingual learning capabilities; indeed, even yields stronger data-efficient performance in the low-resource setting.</abstract>
      <url hash="c9d5ecda">2023.findings-emnlp.107</url>
      <bibkey>chen-etal-2023-global</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.107</doi>
    </paper>
    <paper id="108">
      <title>Learning to Compose Representations of Different Encoder Layers towards Improving Compositional Generalization</title>
      <author><first>Lei</first><last>Lin</last></author>
      <author><first>Shuangtao</first><last>Li</last></author>
      <author><first>Yafang</first><last>Zheng</last></author>
      <author><first>Biao</first><last>Fu</last></author>
      <author><first>Shan</first><last>Liu</last></author>
      <author><first>Yidong</first><last>Chen</last></author>
      <author><first>Xiaodong</first><last>Shi</last></author>
      <pages>1599-1614</pages>
      <abstract>Recent studies have shown that sequence-to-sequence (seq2seq) models struggle with compositional generalization (CG), i.e., the ability to systematically generalize to unseen compositions of seen components. There is mounting evidence that one of the reasons hindering CG is the representation of the encoder uppermost layer is entangled, i.e., the syntactic and semantic representations of sequences are entangled. However, we consider that the previously identified representation entanglement problem is not comprehensive enough. Additionally, we hypothesize that the source keys and values representations passing into different decoder layers are also entangled. Starting from this intuition, we propose CompoSition (<b>Compo</b>se <b>S</b>yntactic and Semant<b>i</b>c Representa<b>tion</b>s), an extension to seq2seq models which learns to compose representations of different encoder layers dynamically for different tasks, since recent studies reveal that the bottom layers of the Transformer encoder contain more syntactic information and the top ones contain more semantic information. Specifically, we introduce a <i>composed layer</i> between the encoder and decoder to compose different encoder layers’ representations to generate specific keys and values passing into different decoder layers. CompoSition achieves competitive results on two comprehensive and realistic benchmarks, which empirically demonstrates the effectiveness of our proposal. Codes are available at <url>https://github.com/thinkaboutzero/COMPOSITION</url>.</abstract>
      <url hash="2971cfb4">2023.findings-emnlp.108</url>
      <bibkey>lin-etal-2023-learning</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.108</doi>
    </paper>
    <paper id="109">
      <title><fixed-case>S</fixed-case>elect<fixed-case>N</fixed-case>oise: Unsupervised Noise Injection to Enable Zero-Shot Machine Translation for Extremely Low-resource Languages</title>
      <author><first>Maharaj</first><last>Brahma</last></author>
      <author><first>Kaushal</first><last>Maurya</last></author>
      <author><first>Maunendra</first><last>Desarkar</last></author>
      <pages>1615-1629</pages>
      <abstract>In this work, we focus on the task of machine translation (MT) from extremely low-resource language (ELRLs) to English. The unavailability of parallel data, lack of representation from large multilingual pre-trained models, and limited monolingual data hinder the development of MT systems for ELRLs. However, many ELRLs often share lexical similarities with high-resource languages (HRLs) due to factors such as dialectical variations, geographical proximity, and language structure. We utilize this property to improve cross-lingual signals from closely related HRL to enable MT for ELRLs. Specifically, we propose a novel unsupervised approach, <tex-math>\textit{SelectNoise}</tex-math>, based on <tex-math>\textit{selective candidate extraction}</tex-math> and <tex-math>\textit{noise injection}</tex-math> to generate noisy HRLs training data. The noise injection acts as a regularizer, and the model trained with noisy data learns to handle lexical variations such as spelling, grammar, and vocabulary changes, leading to improved cross-lingual transfer to ELRLs. The selective candidates are extracted using BPE merge operations and edit operations, and noise injection is performed using greedy, top-p, and top-k sampling strategies. We evaluate the proposed model on 12 ELRLs from the FLORES-200 benchmark in a zero-shot setting across two language families. The proposed model outperformed all the strong baselines, demonstrating its efficacy. It has comparable performance with the supervised noise injection model. Our code and model are publicly available.</abstract>
      <url hash="96e13fb2">2023.findings-emnlp.109</url>
      <bibkey>brahma-etal-2023-selectnoise</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.109</doi>
    </paper>
    <paper id="110">
      <title>Breaking Boundaries in Retrieval Systems: Unsupervised Domain Adaptation with Denoise-Finetuning</title>
      <author><first>Che</first><last>Chen</last></author>
      <author><first>Ching</first><last>Yang</last></author>
      <author><first>Chun-Yi</first><last>Lin</last></author>
      <author><first>Hung-Yu</first><last>Kao</last></author>
      <pages>1630-1642</pages>
      <abstract>Dense retrieval models have exhibited remarkable effectiveness, but they rely on abundant labeled data and face challenges when applied to different domains. Previous domain adaptation methods have employed generative models to generate pseudo queries, creating pseudo datasets to enhance the performance of dense retrieval models. However, these approaches typically use unadapted rerank models, leading to potentially imprecise labels. In this paper, we demonstrate the significance of adapting the rerank model to the target domain prior to utilizing it for label generation. This adaptation process enables us to obtain more accurate labels, thereby improving the overall performance of the dense retrieval model. Additionally, by combining the adapted retrieval model with the adapted rerank model, we achieve significantly better domain adaptation results across three retrieval datasets. We release our code for future research.</abstract>
      <url hash="91d6fdac">2023.findings-emnlp.110</url>
      <bibkey>chen-etal-2023-breaking</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.110</doi>
    </paper>
    <paper id="111">
      <title>Exploring the Cognitive Knowledge Structure of Large Language Models: An Educational Diagnostic Assessment Approach</title>
      <author><first>Zheyuan</first><last>Zhang</last></author>
      <author><first>Jifan</first><last>Yu</last></author>
      <author><first>Juanzi</first><last>Li</last></author>
      <author><first>Lei</first><last>Hou</last></author>
      <pages>1643-1650</pages>
      <abstract>Large Language Models (LLMs) have not only exhibited exceptional performance across various tasks, but also demonstrated sparks of intelligence. Recent studies have focused on assessing their capabilities on human exams and revealed their impressive competence in different domains. However, cognitive research on the overall knowledge structure of LLMs is still lacking. In this paper, based on educational diagnostic assessment method, we conduct an evaluation using MoocRadar, a meticulously annotated human test dataset based on Bloom Taxonomy. We aim to reveal the knowledge structures of LLMs and gain insights of their cognitive capabilities. This research emphasizes the significance of investigating LLMs’ knowledge and understanding the disparate cognitive patterns of LLMs. By shedding light on models’ knowledge, researchers can advance development and utilization of LLMs in a more informed and effective manner.</abstract>
      <url hash="764f2a33">2023.findings-emnlp.111</url>
      <bibkey>zhang-etal-2023-exploring-cognitive</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.111</doi>
    </paper>
    <paper id="112">
      <title>Simpler neural networks prefer subregular languages</title>
      <author><first>Charles</first><last>Torres</last></author>
      <author><first>Richard</first><last>Futrell</last></author>
      <pages>1651-1661</pages>
      <abstract>We apply a continuous relaxation of <tex-math>L_0</tex-math> regularization (Louizos et al., 2017), which induces sparsity, to study the inductive biases of LSTMs. In particular, we are interested in the patterns of formal languages which are readily learned and expressed by LSTMs. Across a wide range of tests we find sparse LSTMs prefer subregular languages over regular languages and the strength of this preference increases as we increase the pressure for sparsity. Furthermore LSTMs which are trained on subregular languages have fewer non-zero parameters. We conjecture that this subregular bias in LSTMs is related to the cognitive bias for subregular language observed in human phonology which are both downstream of a simplicity bias in a suitable description language.</abstract>
      <url hash="21e3afbe">2023.findings-emnlp.112</url>
      <bibkey>torres-futrell-2023-simpler</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.112</doi>
    </paper>
    <paper id="113">
      <title>Simple Hardware-Efficient <fixed-case>PCFG</fixed-case>s with Independent Left and Right Productions</title>
      <author><first>Wei</first><last>Liu</last></author>
      <author><first>Songlin</first><last>Yang</last></author>
      <author><first>Yoon</first><last>Kim</last></author>
      <author><first>Kewei</first><last>Tu</last></author>
      <pages>1662-1669</pages>
      <abstract>Scaling dense PCFGs to thousands of nonterminals via low-rank parameterizations of the rule probability tensor has been shown to be beneficial for unsupervised parsing. However, PCFGs scaled this way still perform poorly as a language model, and even underperform similarly-sized HMMs. This work introduces <tex-math>\emph{SimplePCFG}</tex-math>, a simple PCFG formalism with independent left and right productions. Despite imposing a stronger independence assumption than the low-rank approach, we find that this formalism scales more effectively both as a language model and as an unsupervised parser. We further introduce <tex-math>\emph{FlashInside}</tex-math>, a hardware IO-aware implementation of the inside algorithm for efficiently scaling simple PCFGs. Through extensive experiments on multiple grammar induction benchmarks, we validate the effectiveness of simple PCFGs over low-rank baselines.</abstract>
      <url hash="c9cca1ac">2023.findings-emnlp.113</url>
      <bibkey>liu-etal-2023-simple</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.113</doi>
    </paper>
    <paper id="114">
      <title>R<tex-math>^3</tex-math> Prompting: Review, Rephrase and Resolve for Chain-of-Thought Reasoning in Large Language Models under Noisy Context</title>
      <author><first>Qingyuan</first><last>Tian</last></author>
      <author><first>Hanlun</first><last>Zhu</last></author>
      <author><first>Lei</first><last>Wang</last></author>
      <author><first>Yang</first><last>Li</last></author>
      <author><first>Yunshi</first><last>Lan</last></author>
      <pages>1670-1685</pages>
      <abstract>With the help of Chain-of-Thought (CoT) prompting, Large Language Models (LLMs) have achieved remarkable performance on various reasoning tasks. However, most of them have been evaluated under noise-free context and the dilemma for LLMs to produce inaccurate results under the noisy context has not been fully investigated. Existing studies utilize trigger sentences to encourage LLMs to concentrate on the relevant information but the trigger has limited effect on final answer prediction. Inspired by interactive CoT method, where intermediate reasoning steps are promoted by multiple rounds of interaction between users and LLMs, we propose a novel prompting method, namely R<tex-math>^3</tex-math> prompting, for CoT reasoning under noisy context. Specifically, R<tex-math>^3</tex-math> prompting interacts with LLMs to perform key sentence extraction, variable declaration and answer prediction, which corresponds to a thought process of reviewing, rephrasing and resolving. The responses generated at the last interaction will perform as hints to guide toward the responses of the next interaction. Our experiments show that R<tex-math>^3</tex-math> prompting significantly outperforms existing CoT prompting methods on five reasoning tasks under noisy context. With GPT-3.5-turbo, we observe 3.7% accuracy improvement on average on the reasoning tasks under noisy context compared to the most competitive prompting baseline. More analyses and ablation studies show the robustness and generalization of R<tex-math>^3</tex-math> prompting method in solving reasoning tasks in LLMs under noisy context.</abstract>
      <url hash="074c99b8">2023.findings-emnlp.114</url>
      <bibkey>tian-etal-2023-r3</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.114</doi>
    </paper>
    <paper id="115">
      <title>Quality Estimation-Assisted Automatic Post-Editing</title>
      <author><first>Sourabh</first><last>Deoghare</last></author>
      <author><first>Diptesh</first><last>Kanojia</last></author>
      <author><first>Fred</first><last>Blain</last></author>
      <author><first>Tharindu</first><last>Ranasinghe</last></author>
      <author><first>Pushpak</first><last>Bhattacharyya</last></author>
      <pages>1686-1698</pages>
      <abstract>Automatic Post-Editing (APE) systems are prone to over-correction of the Machine Translation (MT) outputs. While Word-level Quality Estimation (QE) system can provide a way to curtail the over-correction, a significant performance gain has not been observed thus far by utilizing existing APE and QE combination strategies. In this paper, we propose joint training of a model on APE and QE tasks to improve the APE. Our proposed approach utilizes a multi-task learning (MTL) methodology, which shows significant improvement while treating both tasks as a ‘bargaining game’ during training. Moreover, we investigate various existing combination strategies and show that our approach achieves state-of-the-art performance for a ‘distant’ language pair, viz., English-Marathi. We observe an improvement of 1.09 TER and 1.37 BLEU points over a baseline QE-Unassisted APE system for English-Marathi, while also observing 0.46 TER and 0.62 BLEU points for English-German. Further, we discuss the results qualitatively and show how our approach helps reduce over-correction, thereby improving the APE performance. We also observe that the degree of integration between QE and APE directly correlates with the APE performance gain. We release our code and models publicly.</abstract>
      <url hash="63fe8baa">2023.findings-emnlp.115</url>
      <bibkey>deoghare-etal-2023-quality</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.115</doi>
    </paper>
    <paper id="116">
      <title>Adapter Pruning using Tropical Characterization</title>
      <author><first>Rishabh</first><last>Bhardwaj</last></author>
      <author><first>Tushar</first><last>Vaidya</last></author>
      <author><first>Soujanya</first><last>Poria</last></author>
      <pages>1699-1706</pages>
      <abstract>Adapters are widely popular parameter-efficient transfer learning approaches in natural language processing that insert trainable modules in between layers of a pre-trained language model. Apart from several heuristics, however, there has been a lack of studies analyzing the optimal number of adapter parameters needed for downstream applications. Thus, we propose an adapter pruning approach by studying the tropical characteristics of trainable modules. We cast it as an optimization problem that aims to prune parameters from the adapter layers without changing the orientation of underlying tropical hypersurfaces. Our experiments on five NLP datasets show that tropical geometry tends to identify more relevant parameters to prune when compared with the magnitude-based baseline, while a combined approach works best across the tasks.</abstract>
      <url hash="152d830d">2023.findings-emnlp.116</url>
      <bibkey>bhardwaj-etal-2023-adapter</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.116</doi>
    </paper>
    <paper id="117">
      <title>Self-Supervised Rule Learning to Link Text Segments to Relational Elements of Structured Knowledge</title>
      <author><first>Shajith</first><last>Ikbal</last></author>
      <author><first>Udit</first><last>Sharma</last></author>
      <author><first>Hima</first><last>Karanam</last></author>
      <author><first>Sumit</first><last>Neelam</last></author>
      <author><first>Ronny</first><last>Luss</last></author>
      <author><first>Dheeraj</first><last>Sreedhar</last></author>
      <author><first>Pavan</first><last>Kapanipathi</last></author>
      <author><first>Naweed</first><last>Khan</last></author>
      <author><first>Kyle</first><last>Erwin</last></author>
      <author><first>Ndivhuwo</first><last>Makondo</last></author>
      <author><first>Ibrahim</first><last>Abdelaziz</last></author>
      <author><first>Achille</first><last>Fokoue</last></author>
      <author><first>Alexander</first><last>Gray</last></author>
      <author><first>Maxwell</first><last>Crouse</last></author>
      <author><first>Subhajit</first><last>Chaudhury</last></author>
      <author><first>Chitra</first><last>Subramanian</last></author>
      <pages>1707-1718</pages>
      <abstract>We present a neuro-symbolic approach to self-learn rules that serve as interpretable knowledge to perform relation linking in knowledge base question answering systems. These rules define natural language text predicates as a weighted mixture of knowledge base paths. The weights learned during training effectively serve the mapping needed to perform relation linking. We use popular masked training strategy to self-learn the rules. A key distinguishing aspect of our work is that the masked training operate over logical forms of the sentence instead of their natural language text form. This offers opportunity to extract extended context information from the structured knowledge source and use that to build robust and human readable rules. We evaluate accuracy and usefulness of such learned rules by utilizing them for prediction of missing kinship relation in CLUTRR dataset and relation linking in a KBQA system using SWQ-WD dataset. Results demonstrate the effectiveness of our approach - its generalizability, interpretability and ability to achieve an average performance gain of 17% on CLUTRR dataset.</abstract>
      <url hash="1a72fb8c">2023.findings-emnlp.117</url>
      <bibkey>ikbal-etal-2023-self</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.117</doi>
    </paper>
    <paper id="118">
      <title><fixed-case>T</fixed-case>a<fixed-case>TA</fixed-case>: A Multilingual Table-to-Text Dataset for <fixed-case>A</fixed-case>frican Languages</title>
      <author><first>Sebastian</first><last>Gehrmann</last></author>
      <author><first>Sebastian</first><last>Ruder</last></author>
      <author><first>Vitaly</first><last>Nikolaev</last></author>
      <author><first>Jan</first><last>Botha</last></author>
      <author><first>Michael</first><last>Chavinda</last></author>
      <author><first>Ankur</first><last>Parikh</last></author>
      <author><first>Clara</first><last>Rivera</last></author>
      <pages>1719-1740</pages>
      <abstract>Existing data-to-text generation datasets are mostly limited to English. To address this lack of data, we create Table-to-Text in African languages (TaTA), the first large multilingual table-to-text dataset with a focus on African languages. We created TaTA by transcribing figures and accompanying text in bilingual reports by the Demographic and Health Surveys Program, followed by professional translation to make the dataset fully parallel. TaTA includes 8,700 examples in nine languages including four African languages (Hausa, Igbo, Swahili, and Yorùbá) and a zero-shot test language (Russian). We additionally release screenshots of the original figures for future research on multilingual multi-modal approaches. Through an in-depth human evaluation, we show that TaTA is challenging for current models and that less than half the outputs from an mT5-XXL-based model are understandable and attributable to the source data. Our results highlight a) the need for validating metrics; and b) the importance of domain-specific metrics.</abstract>
      <url hash="58cbd879">2023.findings-emnlp.118</url>
      <bibkey>gehrmann-etal-2023-tata</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.118</doi>
    </paper>
    <paper id="119">
      <title>Explain-then-translate: an analysis on improving program translation with self-generated explanations</title>
      <author><first>Zilu</first><last>Tang</last></author>
      <author><first>Mayank</first><last>Agarwal</last></author>
      <author><first>Alexander</first><last>Shypula</last></author>
      <author><first>Bailin</first><last>Wang</last></author>
      <author><first>Derry</first><last>Wijaya</last></author>
      <author><first>Jie</first><last>Chen</last></author>
      <author><first>Yoon</first><last>Kim</last></author>
      <pages>1741-1788</pages>
      <abstract>This work explores the use of self-generated natural language explanations as an intermediate step for code-to-code translation with language models. Across three types of explanations and 19 programming languages constructed from the MultiPL-E dataset, we find the explanations to be particularly effective in the zero-shot case, improving performance by 12% on average. Improvements with natural language explanations are particularly pronounced on difficult programs. We release our dataset, code, and canonical solutions in all 19 languages.</abstract>
      <url hash="aa78db3b">2023.findings-emnlp.119</url>
      <bibkey>tang-etal-2023-explain</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.119</doi>
    </paper>
    <paper id="120">
      <title>Can Brain Signals Reveal Inner Alignment with Human Languages?</title>
      <author><first>Jielin</first><last>Qiu</last></author>
      <author><first>William</first><last>Han</last></author>
      <author><first>Jiacheng</first><last>Zhu</last></author>
      <author><first>Mengdi</first><last>Xu</last></author>
      <author><first>Douglas</first><last>Weber</last></author>
      <author id="bo-li"><first>Bo</first><last>Li</last></author>
      <author><first>Ding</first><last>Zhao</last></author>
      <pages>1789-1804</pages>
      <abstract>Brain Signals, such as Electroencephalography (EEG), and human languages have been widely explored independently for many downstream tasks, however, the connection between them has not been well explored. In this study, we explore the relationship and dependency between EEG and language. To study at the representation level, we introduced <b>MTAM</b>, a <b>M</b>ultimodal <b>T</b>ransformer <b>A</b>lignment <b>M</b>odel, to observe coordinated representations between the two modalities. We used various relationship alignment-seeking techniques, such as Canonical Correlation Analysis and Wasserstein Distance, as loss functions to transfigure features. On downstream applications, sentiment analysis and relation detection, we achieved new state-of-the-art results on two datasets, ZuCo and K-EmoCon. Our method achieved an F1-score improvement of 1.7% on K-EmoCon and 9.3% on Zuco datasets for sentiment analysis, and 7.4% on ZuCo for relation detection. In addition, we provide interpretations of the performance improvement: (1) feature distribution shows the effectiveness of the alignment module for discovering and encoding the relationship between EEG and language; (2) alignment weights show the influence of different language semantics as well as EEG frequency features; (3) brain topographical maps provide an intuitive demonstration of the connectivity in the brain regions. Our code is available at <url>https://github.com/Jason-Qiu/EEG_Language_Alignment</url>.</abstract>
      <url hash="bb2f8360">2023.findings-emnlp.120</url>
      <bibkey>qiu-etal-2023-brain</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.120</doi>
    </paper>
    <paper id="121">
      <title><fixed-case>D</fixed-case>emo<fixed-case>SG</fixed-case>: Demonstration-enhanced Schema-guided Generation for Low-resource Event Extraction</title>
      <author><first>Gang</first><last>Zhao</last></author>
      <author><first>Xiaocheng</first><last>Gong</last></author>
      <author><first>Xinjie</first><last>Yang</last></author>
      <author><first>Guanting</first><last>Dong</last></author>
      <author><first>Shudong</first><last>Lu</last></author>
      <author><first>Si</first><last>Li</last></author>
      <pages>1805-1816</pages>
      <abstract>Most current Event Extraction (EE) methods focus on the high-resource scenario, which requires a large amount of annotated data and can hardly be applied to low-resource domains. To address EE more effectively with limited resources, we propose the Demonstration-enhanced Schema-guided Generation (DemoSG) model, which benefits low-resource EE from two aspects: Firstly, we propose the demonstration-based learning paradigm for EE to fully use the annotated data, which transforms them into demonstrations to illustrate the extraction process and help the model learn effectively. Secondly, we formulate EE as a natural language generation task guided by schema-based prompts, thereby leveraging label semantics and promoting knowledge transfer in low-resource scenarios. We conduct extensive experiments under in-domain and domain adaptation low-resource settings on three datasets, and study the robustness of DemoSG. The results show that DemoSG significantly outperforms current methods in low-resource scenarios.</abstract>
      <url hash="52d4b0f2">2023.findings-emnlp.121</url>
      <bibkey>zhao-etal-2023-demosg</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.121</doi>
    </paper>
    <paper id="122">
      <title><fixed-case>GLGR</fixed-case>: Question-aware Global-to-Local Graph Reasoning for Multi-party Dialogue Reading Comprehension</title>
      <author><first>Yanling</first><last>Li</last></author>
      <author><first>Bowei</first><last>Zou</last></author>
      <author><first>Yifan</first><last>Fan</last></author>
      <author><first>Xibo</first><last>Li</last></author>
      <author><first>Ai Ti</first><last>Aw</last></author>
      <author><first>Yu</first><last>Hong</last></author>
      <pages>1817-1826</pages>
      <abstract>Graph reasoning contributes to the integration of discretely-distributed attentive information (clues) for Multi-party Dialogue Reading Comprehension (MDRC). This is attributed primarily to multi-hop reasoning over global conversational structures. However, existing approaches barely apply questions for anti-noise graph reasoning. More seriously, the local semantic structures in utterances are neglected, although they are beneficial for bridging across semantically-related clues. In this paper, we propose a question-aware global-to-local graph reasoning approach. It expands the canonical Interlocutor-Utterance graph by introducing a question node, enabling comprehensive global graph reasoning. More importantly, it constructs a semantic-role graph for each utterance, and accordingly performs local graph reasoning conditioned on the semantic relations. We design a two-stage encoder network to implement the progressive reasoning from the global graph to local. The experiments on the benchmark datasets Molweni and FriendsQA show that our approach yields significant improvements, compared to BERT and ELECTRA baselines. It achieves 73.6% and 77.2% F1-scores on Molweni and FriendsQA, respectively, outperforming state-of-the-art methods that employ different pretrained language models as backbones.</abstract>
      <url hash="f83af361">2023.findings-emnlp.122</url>
      <bibkey>li-etal-2023-glgr</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.122</doi>
    </paper>
    <paper id="123">
      <title>Towards Mitigating <fixed-case>LLM</fixed-case> Hallucination via Self Reflection</title>
      <author><first>Ziwei</first><last>Ji</last></author>
      <author><first>Tiezheng</first><last>Yu</last></author>
      <author><first>Yan</first><last>Xu</last></author>
      <author><first>Nayeon</first><last>Lee</last></author>
      <author><first>Etsuko</first><last>Ishii</last></author>
      <author><first>Pascale</first><last>Fung</last></author>
      <pages>1827-1843</pages>
      <abstract>Large language models (LLMs) have shown promise for generative and knowledge-intensive tasks including question-answering (QA) tasks. However, the practical deployment still faces challenges, notably the issue of “hallucination”, where models generate plausible-sounding but unfaithful or nonsensical information. This issue becomes particularly critical in the medical domain due to the uncommon professional concepts and potential social risks involved. This paper analyses the phenomenon of hallucination in medical generative QA systems using widely adopted LLMs and datasets. Our investigation centers on the identification and comprehension of common problematic answers, with a specific emphasis on hallucination. To tackle this challenge, we present an interactive self-reflection methodology that incorporates knowledge acquisition and answer generation. Through this feedback process, our approach steadily enhances the factuality, consistency, and entailment of the generated answers. Consequently, we harness the interactivity and multitasking ability of LLMs and produce progressively more precise and accurate answers. Experimental results on both automatic and human evaluation demonstrate the superiority of our approach in hallucination reduction compared to baselines.</abstract>
      <url hash="6199fbdb">2023.findings-emnlp.123</url>
      <bibkey>ji-etal-2023-towards</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.123</doi>
    </paper>
    <paper id="124">
      <title>Making Body Movement in Sign Language Corpus Accessible for Linguists and Machines with Three-Dimensional Normalization of <fixed-case>M</fixed-case>edia<fixed-case>P</fixed-case>ipe</title>
      <author><first>Victor</first><last>Skobov</last></author>
      <author><first>Mayumi</first><last>Bono</last></author>
      <pages>1844-1855</pages>
      <abstract>Linguists can access movement in the sign language video corpus through manual annotation or computational methods. The first relies on a predefinition of features, and the second requires technical knowledge. Methods like MediaPipe and OpenPose are now more often used in sign language processing. MediaPipe detects a two-dimensional (2D) body pose in a single image with a limited approximation of the depth coordinate. Such 2D projection of a three-dimensional (3D) body pose limits the potential application of the resulting models outside the capturing camera settings and position. 2D pose data does not provide linguists with direct and human-readable access to the collected movement data. We propose our four main contributions: A novel 3D normalization method for MediaPipe’s 2D pose, a novel human-readable way of representing the 3D normalized pose data, an analysis of Japanese Sign Language (JSL) sociolinguistic features using the proposed techniques, where we show how an individual signer can be identified based on unique personal movement patterns suggesting a potential threat to anonymity. Our method outperforms the common 2D normalization on a small, diverse JSL dataset. We demonstrate its benefit for deep learning approaches by significantly outperforming the pose-based state-of-the-art models on the open sign language recognition benchmark.</abstract>
      <url hash="6b8dfa2d">2023.findings-emnlp.124</url>
      <bibkey>skobov-bono-2023-making</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.124</doi>
    </paper>
    <paper id="125">
      <title><fixed-case>XTREME</fixed-case>-<fixed-case>UP</fixed-case>: A User-Centric Scarce-Data Benchmark for Under-Represented Languages</title>
      <author><first>Sebastian</first><last>Ruder</last></author>
      <author><first>Jonathan</first><last>Clark</last></author>
      <author><first>Alexander</first><last>Gutkin</last></author>
      <author><first>Mihir</first><last>Kale</last></author>
      <author><first>Min</first><last>Ma</last></author>
      <author><first>Massimo</first><last>Nicosia</last></author>
      <author><first>Shruti</first><last>Rijhwani</last></author>
      <author><first>Parker</first><last>Riley</last></author>
      <author><first>Jean-Michel</first><last>Sarr</last></author>
      <author><first>Xinyi</first><last>Wang</last></author>
      <author><first>John</first><last>Wieting</last></author>
      <author><first>Nitish</first><last>Gupta</last></author>
      <author><first>Anna</first><last>Katanova</last></author>
      <author><first>Christo</first><last>Kirov</last></author>
      <author><first>Dana</first><last>Dickinson</last></author>
      <author><first>Brian</first><last>Roark</last></author>
      <author><first>Bidisha</first><last>Samanta</last></author>
      <author><first>Connie</first><last>Tao</last></author>
      <author><first>David</first><last>Adelani</last></author>
      <author><first>Vera</first><last>Axelrod</last></author>
      <author><first>Isaac</first><last>Caswell</last></author>
      <author><first>Colin</first><last>Cherry</last></author>
      <author><first>Dan</first><last>Garrette</last></author>
      <author><first>Reeve</first><last>Ingle</last></author>
      <author><first>Melvin</first><last>Johnson</last></author>
      <author><first>Dmitry</first><last>Panteleev</last></author>
      <author><first>Partha</first><last>Talukdar</last></author>
      <pages>1856-1884</pages>
      <abstract>Data scarcity is a crucial issue for the development of highly multilingual NLP systems. Yet for many under-represented languages (ULs) — languages for which NLP research is particularly far behind in meeting user needs — it is feasible to annotate small amounts of data. Motivated by this, we propose XTREME-UP, a benchmark defined by: its focus on the scarce-data scenario rather than zero-shot; its focus on user-centric tasks — tasks with broad adoption by speakers of high-resource languages; and its focus on under-represented languages where this scarce-data scenario tends to be most realistic. XTREME-UP evaluates the capabilities of language models across 88 under-represented languages over 9 key user-centric technologies including ASR, OCR, MT, and information access tasks that are of general utility. We create new datasets for OCR, autocomplete, semantic parsing, and transliteration, and build on and refine existing datasets for other tasks. XTREME-UP provides methodology for evaluating many modeling scenarios including text only, multi-modal (vision, audio, and text), supervised parameter tuning, and in-context learning. We evaluate commonly used models on the benchmark. We release all code and scripts to train and evaluate models.</abstract>
      <url hash="f0c09eed">2023.findings-emnlp.125</url>
      <bibkey>ruder-etal-2023-xtreme</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.125</doi>
    </paper>
    <paper id="126">
      <title><fixed-case>D</fixed-case>iffu<fixed-case>VST</fixed-case>: Narrating Fictional Scenes with Global-History-Guided Denoising Models</title>
      <author><first>Shengguang</first><last>Wu</last></author>
      <author><first>Mei</first><last>Yuan</last></author>
      <author><first>Qi</first><last>Su</last></author>
      <pages>1885-1896</pages>
      <abstract>Recent advances in image and video creation, especially AI-based image synthesis, have led to the production of numerous visual scenes that exhibit a high level of abstractness and diversity. Consequently, Visual Storytelling (VST), a task that involves generating meaningful and coherent narratives from a collection of images, has become even more challenging and is increasingly desired beyond real-world imagery. While existing VST techniques, which typically use autoregressive decoders, have made significant progress, they suffer from low inference speed and are not well-suited for synthetic scenes. To this end, we propose a novel diffusion-based system DiffuVST, which models the generation of a series of visual descriptions as a single conditional denoising process. The stochastic and non-autoregressive nature of DiffuVST at inference time allows it to generate highly diverse narratives more efficiently. In addition, DiffuVST features a unique design with bi-directional text history guidance and multimodal adapter modules, which effectively improve inter-sentence coherence and image-to-text fidelity. Extensive experiments on the story generation task covering four fictional visual-story datasets demonstrate the superiority of DiffuVST over traditional autoregressive models in terms of both text quality and inference speed.</abstract>
      <url hash="f0e96049">2023.findings-emnlp.126</url>
      <bibkey>wu-etal-2023-diffuvst</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.126</doi>
    </paper>
    <paper id="127">
      <title><fixed-case>D</fixed-case>i<fixed-case>F</fixed-case>air: A Benchmark for Disentangled Assessment of Gender Knowledge and Bias</title>
      <author><first>Mahdi</first><last>Zakizadeh</last></author>
      <author><first>Kaveh</first><last>Miandoab</last></author>
      <author><first>Mohammad</first><last>Pilehvar</last></author>
      <pages>1897-1914</pages>
      <abstract>Numerous debiasing techniques have been proposed to mitigate the gender bias that is prevalent in pretrained language models. These are often evaluated on datasets that check the extent to which the model is gender-neutral in its predictions. Importantly, this evaluation protocol overlooks the possible adverse impact of bias mitigation on useful gender knowledge. To fill this gap, we propose **DiFair**, a manually curated dataset based on masked language modeling objectives. **DiFair** allows us to introduce a unified metric, *gender invariance score*, that not only quantifies a model’s biased behavior, but also checks if useful gender knowledge is preserved. We use **DiFair** as a benchmark for a number of widely-used pretained language models and debiasing techniques. Experimental results corroborate previous findings on the existing gender biases, while also demonstrating that although debiasing techniques ameliorate the issue of gender bias, this improvement usually comes at the price of lowering useful gender knowledge of the model.</abstract>
      <url hash="587072d6">2023.findings-emnlp.127</url>
      <bibkey>zakizadeh-etal-2023-difair</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.127</doi>
    </paper>
    <paper id="128">
      <title>Transformer-Based Language Model Surprisal Predicts Human Reading Times Best with About Two Billion Training Tokens</title>
      <author><first>Byung-Doh</first><last>Oh</last></author>
      <author><first>William</first><last>Schuler</last></author>
      <pages>1915-1921</pages>
      <abstract>Recent psycholinguistic studies have drawn conflicting conclusions about the relationship between the quality of a language model and the ability of its surprisal estimates to predict human reading times, which has been speculated to be due to the large gap in both the amount of training data and model capacity across studies. The current work aims to consolidate these findings by evaluating surprisal estimates from Transformer-based language model variants that vary systematically in the amount of training data and model capacity on their ability to predict human reading times. The results show that surprisal estimates from most variants with contemporary model capacities provide the best fit after seeing about two billion training tokens, after which they begin to diverge from humanlike expectations. Additionally, newly-trained smaller model variants reveal a ‘tipping point’ at convergence, after which the decrease in language model perplexity begins to result in poorer fits to human reading times. These results suggest that the massive amount of training data is mainly responsible for the poorer fit achieved by surprisal from larger pre-trained language models, and that a certain degree of model capacity is necessary for Transformer-based language models to capture humanlike expectations.</abstract>
      <url hash="a7880897">2023.findings-emnlp.128</url>
      <bibkey>oh-schuler-2023-transformer</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.128</doi>
    </paper>
    <paper id="129">
      <title><fixed-case>E</fixed-case>xplain<fixed-case>CPE</fixed-case>: A Free-text Explanation Benchmark of <fixed-case>C</fixed-case>hinese Pharmacist Examination</title>
      <author><first>Dongfang</first><last>Li</last></author>
      <author><first>Jindi</first><last>Yu</last></author>
      <author><first>Baotian</first><last>Hu</last></author>
      <author><first>Zhenran</first><last>Xu</last></author>
      <author><first>Min</first><last>Zhang</last></author>
      <pages>1922-1940</pages>
      <abstract>In the field of Large Language Models (LLMs), researchers are increasingly exploring their effectiveness across a wide range of tasks. However, a critical area that requires further investigation is the interpretability of these models, particularly the ability to generate rational explanations for their decisions. Most existing explanation datasets are limited to the English language and the general domain, which leads to a scarcity of linguistic diversity and a lack of resources in specialized domains, such as medical. To mitigate this, we propose ExplainCPE, a challenging medical dataset consisting of over 7K problems from Chinese Pharmacist Examination, specifically tailored to assess the model-generated explanations. From the overall results, only GPT-4 passes the pharmacist examination with a 75.7% accuracy, while other models like ChatGPT fail. Further detailed analysis of LLM-generated explanations reveals the limitations of LLMs in understanding medical text and executing computational reasoning. With the increasing importance of AI safety and trustworthiness, ExplainCPE takes a step towards improving and evaluating the interpretability of LLMs in the medical domain.</abstract>
      <url hash="6ba52125">2023.findings-emnlp.129</url>
      <bibkey>li-etal-2023-explaincpe</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.129</doi>
    </paper>
    <paper id="130">
      <title><fixed-case>CLASS</fixed-case>: A Design Framework for Building Intelligent Tutoring Systems Based on Learning Science principles</title>
      <author><first>Shashank</first><last>Sonkar</last></author>
      <author><first>Naiming</first><last>Liu</last></author>
      <author><first>Debshila</first><last>Mallick</last></author>
      <author><first>Richard</first><last>Baraniuk</last></author>
      <pages>1941-1961</pages>
      <abstract>We present a design framework called Conversational Learning with Analytical Step-by-Step Strategies (CLASS) for building advanced Intelligent Tutoring Systems (ITS) powered by high-performance Large Language Models (LLMs). The CLASS framework empowers ITS with two key capabilities. First, through a carefully curated scaffolding dataset, CLASS equips ITS with essential problem-solving strategies, enabling it to provide tutor-like, step-by-step guidance to students. Second, by using a dynamic conversational dataset, CLASS assists ITS in facilitating natural language interactions, fostering engaging student-tutor conversations. The CLASS framework also provides valuable insights into ITS’s internal decision-making process which allows seamless integration of user feedback, thus enabling continuous refinement and improvement. We also present a proof-of-concept ITS, referred to as SPOCK, which is trained using the CLASS framework with a focus on introductory college level biology content. A carefully constructed protocol was developed for SPOCK’s preliminary evaluation, examining aspects such as the factual accuracy and relevance of its responses. Experts in the field of biology offered favorable remarks, particularly highlighting SPOCK’s capability to break down questions into manageable subproblems and provide encouraging responses to students.</abstract>
      <url hash="05cf8c6b">2023.findings-emnlp.130</url>
      <bibkey>sonkar-etal-2023-class</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.130</doi>
    </paper>
    <paper id="131">
      <title>Normal-Abnormal Decoupling Memory for Medical Report Generation</title>
      <author><first>Guosheng</first><last>Zhao</last></author>
      <author><first>Yan</first><last>Yan</last></author>
      <author><first>Zijian</first><last>Zhao</last></author>
      <pages>1962-1977</pages>
      <abstract>The automatic generation of medical reports plays a crucial role in clinical automation. In contrast to natural images, radiological images exhibit a high degree of similarity, while medical data are prone to data bias and complex noise, posing challenges for existing methods in capturing nuanced visual information. To address these challenges, we introduce a novel normal-abnormal semantic decoupling network that utilizes abnormal pattern memory. Different from directly optimizing the network using medical reports, we optimize visual extraction through the extraction of abnormal semantics from the reports. Moreover, we independently learn normal semantics based on abnormal semantics, ensuring that the optimization of the visual network remains unaffected by normal semantics learning. Then, we divided the words in the report into four parts: normal/abnormal sentences and normal/abnormal semantics, optimizing the network with distinct weights for each partition. The two semantic components, along with visual information, are seamlessly integrated to facilitate the generation of precise and coherent reports. This approach mitigates the impact of noisy normal semantics and reports. Moreover, we develop a novel encoder for abnormal pattern memory, which improves the network’s ability to detect anomalies by capturing and embedding the abnormal patterns of images in the visual encoder. This approach demonstrates excellent performance on the benchmark MIMIC-CXR, surpassing the current state-of-the-art methods.</abstract>
      <url hash="af1018bd">2023.findings-emnlp.131</url>
      <bibkey>zhao-etal-2023-normal</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.131</doi>
    </paper>
    <paper id="132">
      <title>mm<fixed-case>T</fixed-case>5: Modular Multilingual Pre-Training Solves Source Language Hallucinations</title>
      <author><first>Jonas</first><last>Pfeiffer</last></author>
      <author><first>Francesco</first><last>Piccinno</last></author>
      <author><first>Massimo</first><last>Nicosia</last></author>
      <author><first>Xinyi</first><last>Wang</last></author>
      <author><first>Machel</first><last>Reid</last></author>
      <author><first>Sebastian</first><last>Ruder</last></author>
      <pages>1978-2008</pages>
      <abstract>Multilingual sequence-to-sequence models perform poorly with increased language coverage and fail to consistently generate text in the correct target language in few-shot settings. To address these challenges, we propose mmT5, a modular multilingual sequence-to-sequence model. mmT5 utilizes language-specific modules during pre-training, which disentangle language-specific information from language-agnostic information. We identify representation drift during fine-tuning as a key limitation of modular generative models and develop strategies that enable effective zero-shot transfer. Our model outperforms mT5 at the same parameter sizes by a large margin on representative natural language understanding and generation tasks in 40+ languages. Compared to mT5, mmT5 raises the rate of generating text in the correct language under zero-shot settings from 7% to 99%, thereby greatly alleviating the source language hallucination problem.</abstract>
      <url hash="e72209f9">2023.findings-emnlp.132</url>
      <bibkey>pfeiffer-etal-2023-mmt5</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.132</doi>
    </paper>
    <paper id="133">
      <title><fixed-case>I</fixed-case>mage<fixed-case>N</fixed-case>et<fixed-case>VC</fixed-case>: Zero- and Few-Shot Visual Commonsense Evaluation on 1000 <fixed-case>I</fixed-case>mage<fixed-case>N</fixed-case>et Categories</title>
      <author><first>Heming</first><last>Xia</last></author>
      <author><first>Qingxiu</first><last>Dong</last></author>
      <author><first>Lei</first><last>Li</last></author>
      <author><first>Jingjing</first><last>Xu</last></author>
      <author><first>Tianyu</first><last>Liu</last></author>
      <author><first>Ziwei</first><last>Qin</last></author>
      <author><first>Zhifang</first><last>Sui</last></author>
      <pages>2009-2026</pages>
      <abstract>Recently, Large Language Models (LLMs) have been serving as general-purpose interfaces, posing a significant demand for comprehensive visual knowledge. However, it remains unclear how well current LLMs and their visually augmented counterparts (VaLMs) can master visual commonsense knowledge. To investigate this, we propose ImageNetVC, a human-annotated dataset specifically designed for zero- and few-shot visual commonsense evaluation across 1,000 ImageNet categories. Utilizing ImageNetVC, we benchmark the fundamental visual commonsense knowledge of both unimodal LLMs and VaLMs. Furthermore, we analyze the factors affecting the visual commonsense knowledge of large-scale models, providing insights into the development of language models enriched with visual commonsense knowledge. Our code and dataset are available at https://github.com/hemingkx/ImageNetVC.</abstract>
      <url hash="7666d7bc">2023.findings-emnlp.133</url>
      <bibkey>xia-etal-2023-imagenetvc</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.133</doi>
    </paper>
    <paper id="134">
      <title><fixed-case>M</fixed-case>ulti<fixed-case>C</fixed-case>o<fixed-case>NER</fixed-case> v2: a Large Multilingual dataset for Fine-grained and Noisy Named Entity Recognition</title>
      <author><first>Besnik</first><last>Fetahu</last></author>
      <author><first>Zhiyu</first><last>Chen</last></author>
      <author><first>Sudipta</first><last>Kar</last></author>
      <author><first>Oleg</first><last>Rokhlenko</last></author>
      <author><first>Shervin</first><last>Malmasi</last></author>
      <pages>2027-2051</pages>
      <abstract>We present MULTICONER V2, a dataset for fine-grained Named Entity Recognition covering 33 entity classes across 12 languages, in both monolingual and multilingual settings. This dataset aims to tackle the following practical challenges in NER: (i) effective handling of fine-grained classes that include complex entities like movie titles, and (ii) performance degradation due to noise generated from typing mistakes or OCR errors. The dataset is compiled from open resources like Wikipedia and Wikidata, and is publicly available. Evaluation based on the XLM-RoBERTa baseline highlights the unique challenges posed by MULTICONER V2: (i) the fine-grained taxonomy is challenging, where the scores are low with macro-F1=0.63 (across all languages), and (ii) the corruption strategy significantly impairs performance, with entity corruption resulting in 9% lower performance relative to non-entity corruptions across all languages. This highlights the greater impact of entity noise in contrast to context noise.</abstract>
      <url hash="7185cd60">2023.findings-emnlp.134</url>
      <bibkey>fetahu-etal-2023-multiconer</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.134</doi>
    </paper>
    <paper id="135">
      <title>A Query-Parallel Machine Reading Comprehension Framework for Low-resource <fixed-case>NER</fixed-case></title>
      <author><first>Yuhao</first><last>Zhang</last></author>
      <author><first>Yongliang</first><last>Wang</last></author>
      <pages>2052-2065</pages>
      <abstract>Named entity recognition (NER) is a fundamental task in natural language processing. Recently, NER has been formulated as a machine reading comprehension (MRC) task, in which manually-crafted queries are used to extract entities of different types. However, current MRC-based NER techniques are limited to extracting a single type of entities at a time and are largely geared towards resource-rich settings. This renders them inefficient during the inference phase, while also leaving their potential untapped for utilization in low-resource settings. We suggest a query-parallel MRC-based approach to address these issues, which is capable of extracting multiple entity types concurrently and is applicable to both resource-rich and resource-limited settings. Specifically, we propose a query-parallel encoder which uses a query-segmented attention mechanism to isolate the semantics of queries and model the query-context interaction with a unidirectional flow. This allows for easier generalization to new entity types or transfer to new domains. After obtaining the query and context representations through the encoder, they are fed into a query-conditioned biaffine predictor to extract multiple entities at once. The model is trained with parameter-efficient tuning technique, making it more data-efficient. We conduct extensive experiments and demonstrate that our model performs competitively against strong baseline methods in resource-rich settings, and achieves state-of-the-art results in low-resource settings, including training-from-scratch, in-domain transfer and cross-domain transfer tasks.</abstract>
      <url hash="a4c5b2bc">2023.findings-emnlp.135</url>
      <bibkey>zhang-wang-2023-query</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.135</doi>
    </paper>
    <paper id="136">
      <title><fixed-case>B</fixed-case>i<fixed-case>SPN</fixed-case>: Generating Entity Set and Relation Set Coherently in One Pass</title>
      <author><first>Yuxin</first><last>He</last></author>
      <author><first>Buzhou</first><last>Tang</last></author>
      <pages>2066-2077</pages>
      <abstract>By modeling the interaction among instances and avoiding error propagation, Set Prediction Networks (SPNs) achieve state-of-the-art performance on the tasks of named entity recognition and relation triple extraction respectively. However, how to jointly extract entities and relation triples via SPNs remains an unexplored problem, where the main challenge is the maintenance of coherence between the predicted entity/relation sets during one-pass generation. In this work, we present Bipartite Set Prediction Network (BiSPN), a novel joint entity-relation extraction model that can efficiently generate entity set and relation set in parallel. To overcome the challenge of coherence, BiSPN is equipped with a novel bipartite consistency loss as well as an entity-relation linking loss during training. Experiments on three biomedical/clinical datasets and a general-domain dataset show that BiSPN achieves new state of the art in knowledge-intensive scene and performs competitively in general-domain, while being more efficient than two-stage joint extraction methods.</abstract>
      <url hash="1bd6900a">2023.findings-emnlp.136</url>
      <bibkey>he-tang-2023-bispn</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.136</doi>
    </paper>
    <paper id="137">
      <title><fixed-case>MEEP</fixed-case>: Is this Engaging? Prompting Large Language Models for Dialogue Evaluation in Multilingual Settings</title>
      <author><first>Amila</first><last>Ferron</last></author>
      <author><first>Amber</first><last>Shore</last></author>
      <author><first>Ekata</first><last>Mitra</last></author>
      <author><first>Ameeta</first><last>Agrawal</last></author>
      <pages>2078-2100</pages>
      <abstract>As dialogue systems become more popular, evaluation of their response quality gains importance. Engagingness highly correlates with overall quality and creates a sense of connection that gives human participants a more fulfilling experience. Although qualities like coherence and fluency are readily measured with well-worn automatic metrics, evaluating engagingness often relies on human assessment, which is a costly and time-consuming process. Existing automatic engagingness metrics evaluate the response without the conversation history, are designed for one dataset, or have limited correlation with human annotations. Furthermore, they have been tested exclusively on English conversations. Given that dialogue systems are increasingly available in languages beyond English, multilingual evaluation capabilities are essential. We propose that large language models (LLMs) may be used for evaluation of engagingness in dialogue through prompting, and ask how prompt constructs and translated prompts compare in a multilingual setting. We provide a prompt-design taxonomy for engagingness and find that using selected prompt elements with LLMs, including our comprehensive definition of engagingness, outperforms state-of-the-art methods on evaluation of engagingness in dialogue across multiple languages.</abstract>
      <url hash="a92ec7b4">2023.findings-emnlp.137</url>
      <bibkey>ferron-etal-2023-meep</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.137</doi>
    </paper>
    <paper id="138">
      <title>Exploring the Impact of Corpus Diversity on Financial Pretrained Language Models</title>
      <author><first>Jaeyoung</first><last>Choe</last></author>
      <author><first>Keonwoong</first><last>Noh</last></author>
      <author><first>Nayeon</first><last>Kim</last></author>
      <author><first>Seyun</first><last>Ahn</last></author>
      <author><first>Woohwan</first><last>Jung</last></author>
      <pages>2101-2112</pages>
      <abstract>Over the past few years, various domain-specific pretrained language models (PLMs) have been proposed and have outperformed general-domain PLMs in specialized areas such as biomedical, scientific, and clinical domains. In addition, financial PLMs have been studied because of the high economic impact of financial data analysis. However, we found that financial PLMs were not pretrained on sufficiently diverse financial data. This lack of diverse training data leads to a subpar generalization performance, resulting in general-purpose PLMs, including BERT, often outperforming financial PLMs on many downstream tasks. To address this issue, we collected a broad range of financial corpus and trained the Financial Language Model (FiLM) on these diverse datasets. Our experimental results confirm that FiLM outperforms not only existing financial PLMs but also general domain PLMs. Furthermore, we provide empirical evidence that this improvement can be achieved even for unseen corpus groups.</abstract>
      <url hash="2b0ba76b">2023.findings-emnlp.138</url>
      <bibkey>choe-etal-2023-exploring</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.138</doi>
    </paper>
    <paper id="139">
      <title><fixed-case>LLMD</fixed-case>et: A Third Party Large Language Models Generated Text Detection Tool</title>
      <author><first>Kangxi</first><last>Wu</last></author>
      <author><first>Liang</first><last>Pang</last></author>
      <author><first>Huawei</first><last>Shen</last></author>
      <author><first>Xueqi</first><last>Cheng</last></author>
      <author><first>Tat-Seng</first><last>Chua</last></author>
      <pages>2113-2133</pages>
      <abstract>Generated texts from large language models (LLMs) are remarkably close to high-quality human-authored text, raising concerns about their potential misuse in spreading false information and academic misconduct. Consequently, there is an urgent need for a highly practical detection tool capable of accurately identifying the source of a given text. However, existing detection tools typically rely on access to LLMs and can only differentiate between machine-generated and human-authored text, failing to meet the requirements of fine-grained tracing, intermediary judgment, and rapid detection. Therefore, we propose LLMDet, a model-specific, secure, efficient, and extendable detection tool, that can source text from specific LLMs, such as GPT-2, OPT, LLaMA, and others. In LLMDet, we record the next-token probabilities of salient n-grams as features to calculate proxy perplexity for each LLM. By jointly analyzing the proxy perplexities of LLMs, we can determine the source of the generated text. Experimental results show that LLMDet yields impressive detection performance while ensuring speed and security, achieving 98.54% precision and about <tex-math>\times 5.0</tex-math> faster for recognizing human-authored text. Additionally, LLMDet can effortlessly extend its detection capabilities to a new open-source model. We will provide an open-source tool at <url>https://github.com/TrustedLLM/LLMDet</url>.</abstract>
      <url hash="2cd14485">2023.findings-emnlp.139</url>
      <bibkey>wu-etal-2023-llmdet</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.139</doi>
    </paper>
    <paper id="140">
      <title><fixed-case>RECAP</fixed-case>: Towards Precise Radiology Report Generation via Dynamic Disease Progression Reasoning</title>
      <author><first>Wenjun</first><last>Hou</last></author>
      <author><first>Yi</first><last>Cheng</last></author>
      <author><first>Kaishuai</first><last>Xu</last></author>
      <author><first>Wenjie</first><last>Li</last></author>
      <author><first>Jiang</first><last>Liu</last></author>
      <pages>2134-2147</pages>
      <abstract>Automating radiology report generation can significantly alleviate radiologists’ workloads. Previous research has primarily focused on realizing highly concise observations while neglecting the precise attributes that determine the severity of diseases (e.g., small pleural effusion). Since incorrect attributes will lead to imprecise radiology reports, strengthening the generation process with precise attribute modeling becomes necessary. Additionally, the temporal information contained in the historical records, which is crucial in evaluating a patient’s current condition (e.g., heart size is unchanged), has also been largely disregarded. To address these issues, we propose RECAP, which generates precise and accurate radiology reports via dynamic disease progression reasoning. Specifically, RECAP first predicts the observations and progressions (i.e., spatiotemporal information) given two consecutive radiographs. It then combines the historical records, spatiotemporal information, and radiographs for report generation, where a disease progression graph and dynamic progression reasoning mechanism are devised to accurately select the attributes of each observation and progression. Extensive experiments on two publicly available datasets demonstrate the effectiveness of our model.</abstract>
      <url hash="5fe7e573">2023.findings-emnlp.140</url>
      <bibkey>hou-etal-2023-recap</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.140</doi>
    </paper>
    <paper id="141">
      <title>Causal Intervention for Abstractive Related Work Generation</title>
      <author><first>Jiachang</first><last>Liu</last></author>
      <author><first>Qi</first><last>Zhang</last></author>
      <author><first>Chongyang</first><last>Shi</last></author>
      <author><first>Usman</first><last>Naseem</last></author>
      <author><first>Shoujin</first><last>Wang</last></author>
      <author><first>Liang</first><last>Hu</last></author>
      <author><first>Ivor</first><last>Tsang</last></author>
      <pages>2148-2159</pages>
      <abstract>Abstractive related work generation has attracted increasing attention in generating coherent related work that helps readers grasp the current research. However, most existing models ignore the inherent causality during related work generation, leading to spurious correlations which downgrade the models’ generation quality and generalizability. In this study, we argue that causal intervention can address such limitations and improve the quality and coherence of generated related work. To this end, we propose a novel Causal Intervention Module for Related Work Generation (CaM) to effectively capture causalities in the generation process. Specifically, we first model the relations among the sentence order, document (reference) correlations, and transitional content in related work generation using a causal graph. Then, to implement causal interventions and mitigate the negative impact of spurious correlations, we use do-calculus to derive ordinary conditional probabilities and identify causal effects through CaM. Finally, we subtly fuse CaM with Transformer to obtain an end-to-end related work generation framework. Extensive experiments on two real-world datasets show that CaM can effectively promote the model to learn causal relations and thus produce related work of higher quality and coherence.</abstract>
      <url hash="d185ea14">2023.findings-emnlp.141</url>
      <bibkey>liu-etal-2023-causal</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.141</doi>
    </paper>
    <paper id="142">
      <title><fixed-case>G</fixed-case>-<fixed-case>SPEED</fixed-case>: General <fixed-case>SP</fixed-case>arse Efficient Editing <fixed-case>M</fixed-case>o<fixed-case>D</fixed-case>el</title>
      <author><first>Haoke</first><last>Zhang</last></author>
      <author><first>Yue</first><last>Wang</last></author>
      <author><first>Juntao</first><last>Li</last></author>
      <author><first>Xiabing</first><last>Zhou</last></author>
      <author><first>Min</first><last>Zhang</last></author>
      <pages>2160-2175</pages>
      <abstract>Large Language Models (LLMs) have demonstrated incredible capabilities in understanding, generating, and manipulating languages. Through human-model interactions, LLMs can automatically understand human-issued instructions and output the expected contents, which can significantly increase working efficiency. In various types of real-world demands, editing-oriented tasks account for a considerable proportion, which involves an interactive process that entails the continuous refinement of existing texts to meet specific criteria. Due to the need for multi-round human-model interaction and the generation of complicated editing tasks, there is an emergent need for efficient general editing models. In this paper, we propose <b>G</b>eneral <b>SP</b>arse <b>E</b>fficient <b>E</b>diting Mo<b>D</b>el (<b>G-SPEED</b>), which can fulfill diverse editing requirements through a single model while maintaining low computational costs. Specifically, we first propose a novel unsupervised text editing data clustering algorithm to deal with the data scarcity problem. Subsequently, we introduce a sparse editing model architecture to mitigate the inherently limited learning capabilities of small language models. The experimental outcomes indicate that G-SPEED, with its 508M parameters, can surpass LLMs equipped with 175B parameters. Our code and model checkpoints are available at <url>https://github.com/Banner-Z/G-SPEED</url>.</abstract>
      <url hash="373dcf23">2023.findings-emnlp.142</url>
      <bibkey>zhang-etal-2023-g</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.142</doi>
    </paper>
    <paper id="143">
      <title>Attack Prompt Generation for Red Teaming and Defending Large Language Models</title>
      <author><first>Boyi</first><last>Deng</last></author>
      <author><first>Wenjie</first><last>Wang</last></author>
      <author><first>Fuli</first><last>Feng</last></author>
      <author><first>Yang</first><last>Deng</last></author>
      <author><first>Qifan</first><last>Wang</last></author>
      <author><first>Xiangnan</first><last>He</last></author>
      <pages>2176-2189</pages>
      <abstract>Large language models (LLMs) are susceptible to red teaming attacks, which can induce LLMs to generate harmful content. Previous research constructs attack prompts via manual or automatic methods, which have their own limitations on construction cost and quality. To address these issues, we propose an integrated approach that combines manual and automatic methods to economically generate high-quality attack prompts. Specifically, considering the impressive capabilities of newly emerged LLMs, we propose an attack framework to instruct LLMs to mimic human-generated prompts through in-context learning. Furthermore, we propose a defense framework that fine-tunes victim LLMs through iterative interactions with the attack framework to enhance their safety against red teaming attacks. Extensive experiments on different LLMs validate the effectiveness of our proposed attack and defense frameworks. Additionally, we release a series of attack prompts datasets named SAP with varying sizes, facilitating the safety evaluation and enhancement of more LLMs.</abstract>
      <url hash="83baacf3">2023.findings-emnlp.143</url>
      <bibkey>deng-etal-2023-attack</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.143</doi>
    </paper>
    <paper id="144">
      <title>Smart “Chef”: Verifying the Effect of Role-based Paraphrasing for Aspect Term Extraction</title>
      <author><first>Jiaxiang</first><last>Chen</last></author>
      <author><first>Yu</first><last>Hong</last></author>
      <author><first>Qingting</first><last>Xu</last></author>
      <author><first>Jianmin</first><last>Yao</last></author>
      <pages>2190-2197</pages>
      <abstract>We tackle Aspect Term Extraction (ATE), a task of automatically extracting aspect terms from sentences. The current Pretrained Language Model (PLM) based extractors have achieved significant improvements. They primarily benefit from context-aware encoding. However, a considerable number of sentences in ATE corpora contain uninformative or low-quality contexts. Such sentences frequently act as “troublemakers” during test. In this study, we explore the context-oriented quality improvement method. Specifically, we propose to automatically rewrite the sentences from the perspectives of virtual experts with different roles, such as a “chef” in the restaurant domain. On this basis, we perform ATE over the paraphrased sentences during test, using the well-trained extractors without any change. In the experiments, we leverage ChatGPT to determine virtual experts in the considered domains, and induce ChatGPT to generate paraphrases conditioned on the roles of virtual experts. We experiment on the benchmark SemEval datasets, including Laptop-domain L14 and Restaurant-domain R14-16. The experimental results show that our approach effectively recalls the inconspicuous aspect terms like “al di la”, although it reduces the precision. In addition, it is proven that our approach can be substantially improved by redundancy elimination and multi-role voting. More importantly, our approach can be used to expand the predictions obtained on the original sentences. This yields state-of-the-art performance (i.e., F1-scores of 86.2%, 89.3%, 77.7%, 82.7% on L14 and R14-16) without retraining or fine-tuning the baseline extractors.</abstract>
      <url hash="f2636c0a">2023.findings-emnlp.144</url>
      <bibkey>chen-etal-2023-smart</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.144</doi>
    </paper>
    <paper id="145">
      <title>Multi-Defendant Legal Judgment Prediction via Hierarchical Reasoning</title>
      <author><first>Yougang</first><last>Lyu</last></author>
      <author><first>Jitai</first><last>Hao</last></author>
      <author><first>Zihan</first><last>Wang</last></author>
      <author><first>Kai</first><last>Zhao</last></author>
      <author><first>Shen</first><last>Gao</last></author>
      <author><first>Pengjie</first><last>Ren</last></author>
      <author><first>Zhumin</first><last>Chen</last></author>
      <author><first>Fang</first><last>Wang</last></author>
      <author><first>Zhaochun</first><last>Ren</last></author>
      <pages>2198-2209</pages>
      <abstract>Multiple defendants in a criminal fact description generally exhibit complex interactions, and cannot be well handled by existing Legal Judgment Prediction (LJP) methods which focus on predicting judgment results (e.g., law articles, charges, and terms of penalty) for single-defendant cases. To address this problem, we propose the task of multi-defendant LJP, which aims to automatically predict the judgment results for each defendant of multi-defendant cases. Two challenges arise with the task of multi-defendant LJP: (1) indistinguishable judgment results among various defendants; and (2) the lack of a real-world dataset for training and evaluation. To tackle the first challenge, we formalize the multi-defendant judgment process as hierarchical reasoning chains and introduce a multi-defendant LJP method, named Hierarchical Reasoning Network (HRN), which follows the hierarchical reasoning chains to determine criminal relationships, sentencing circumstances, law articles, charges, and terms of penalty for each defendant. To tackle the second challenge, we collect a real-world multi-defendant LJP dataset, namely MultiLJP, to accelerate the relevant research in the future. Extensive experiments on MultiLJP verify the effectiveness of our proposed HRN.</abstract>
      <url hash="c63b9e76">2023.findings-emnlp.145</url>
      <bibkey>lyu-etal-2023-multi</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.145</doi>
    </paper>
    <paper id="146">
      <title>Interpreting Indirect Answers to Yes-No Questions in Multiple Languages</title>
      <author><first>Zijie</first><last>Wang</last></author>
      <author><first>Md</first><last>Hossain</last></author>
      <author><first>Shivam</first><last>Mathur</last></author>
      <author><first>Terry</first><last>Melo</last></author>
      <author><first>Kadir</first><last>Ozler</last></author>
      <author><first>Keun</first><last>Park</last></author>
      <author><first>Jacob</first><last>Quintero</last></author>
      <author><first>MohammadHossein</first><last>Rezaei</last></author>
      <author><first>Shreya</first><last>Shakya</last></author>
      <author><first>Md</first><last>Uddin</last></author>
      <author><first>Eduardo</first><last>Blanco</last></author>
      <pages>2210-2227</pages>
      <abstract>Yes-no questions expect a yes or no for an answer, but people often skip polar keywords. Instead, they answer with long explanations that must be interpreted. In this paper, we focus on this challenging problem and release new benchmarks in eight languages. We present a distant supervision approach to collect training data, and demonstrate that direct answers (i.e., with polar keywords) are useful to train models to interpret indirect answers (i.e., without polar keywords). We show that monolingual fine-tuning is beneficial if training data can be obtained via distant supervision for the language of interest (5 languages). Additionally, we show that cross-lingual fine-tuning is always beneficial (8 languages).</abstract>
      <url hash="912bdec9">2023.findings-emnlp.146</url>
      <bibkey>wang-etal-2023-interpreting</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.146</doi>
    </paper>
    <paper id="147">
      <title>Generalizing Few-Shot Named Entity Recognizers to Unseen Domains with Type-Related Features</title>
      <author><first>Zihan</first><last>Wang</last></author>
      <author><first>Ziqi</first><last>Zhao</last></author>
      <author><first>Zhumin</first><last>Chen</last></author>
      <author><first>Pengjie</first><last>Ren</last></author>
      <author><first>Maarten</first><last>de Rijke</last></author>
      <author><first>Zhaochun</first><last>Ren</last></author>
      <pages>2228-2240</pages>
      <abstract>Few-shot named entity recognition (NER) has shown remarkable progress in identifying entities in low-resource domains. However, few-shot NER methods still struggle with out-of-domain (OOD) examples due to their reliance on manual labeling for the target domain. To address this limitation, recent studies enable generalization to an unseen target domain with only a few labeled examples using data augmentation techniques. Two important challenges remain: First, augmentation is limited to the training data, resulting in minimal overlap between the generated data and OOD examples. Second, knowledge transfer is implicit and insufficient, severely hindering model generalizability and the integration of knowledge from the source domain. In this paper, we propose a framework, prompt learning with type-related features (PLTR), to address these challenges. To identify useful knowledge in the source domain and enhance knowledge transfer, PLTR automatically extracts entity type-related features (TRFs) based on mutual information criteria. To bridge the gap between training and OOD data, PLTR generates a unique prompt for each unseen example by selecting relevant TRFs. We show that PLTR achieves significant performance improvements on in-domain and cross-domain datasets. The use of PLTR facilitates model adaptation and increases representation similarities between the source and unseen domains.</abstract>
      <url hash="1c28353e">2023.findings-emnlp.147</url>
      <bibkey>wang-etal-2023-generalizing</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.147</doi>
    </paper>
    <paper id="148">
      <title>Intervention-Based Alignment of Code Search with Execution Feedback</title>
      <author><first>Hojae</first><last>Han</last></author>
      <author><first>Minsoo</first><last>Kim</last></author>
      <author><first>Seung-won</first><last>Hwang</last></author>
      <author><first>Nan</first><last>Duan</last></author>
      <author><first>Shuai</first><last>Lu</last></author>
      <pages>2241-2263</pages>
      <abstract>One of the fundamental goals in code search is to retrieve a functionally correct code for a given natural language query. As annotating for correctness requires executing test cases (i.e. obtaining execution feedback), existing code search training datasets approximate text-code co-occurrences as positive execution feedback. However, this approximation may misalign models’ retrieval decisions from ground-truth correctness. To address such limitation, we propose Code Intervention-based Reinforcement Learning (CIRL) that perturbs training code to result in misalignment (i.e. code intervention), then tests models’ decisions and corrects them with the execution feedback by reinforcement learning. The first technical contribution of CIRL is to induce the execution feedback from perturbation, without actual execution. Secondly, CIRL introduces structural perturbations using abstract syntax trees, going beyond simple lexical changes. Experimental results on various datasets demonstrate the effectiveness of CIRL compared to conventional approaches.</abstract>
      <url hash="72bcf0b1">2023.findings-emnlp.148</url>
      <bibkey>han-etal-2023-intervention</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.148</doi>
    </paper>
    <paper id="149">
      <title>Enhancing Neural Machine Translation with Semantic Units</title>
      <author><first>Langlin</first><last>Huang</last></author>
      <author><first>Shuhao</first><last>Gu</last></author>
      <author><first>Zhang</first><last>Zhuocheng</last></author>
      <author><first>Yang</first><last>Feng</last></author>
      <pages>2264-2277</pages>
      <abstract>Conventional neural machine translation (NMT) models typically use subwords and words as the basic units for model input and comprehension. However, complete words and phrases composed of several tokens are often the fundamental units for expressing semantics, referred to as semantic units. To address this issue, we propose a method Semantic Units for Machine Translation (SU4MT) which models the integral meanings of semantic units within a sentence, and then leverages them to provide a new perspective for understanding the sentence. Specifically, we first propose Word Pair Encoding (WPE), a phrase extraction method to help identify the boundaries of semantic units. Next, we design an Attentive Semantic Fusion (ASF) layer to integrate the semantics of multiple subwords into a single vector: the semantic unit representation. Lastly, the semantic-unit-level sentence representation is concatenated to the token-level one, and they are combined as the input of encoder. Experimental results demonstrate that our method effectively models and leverages semantic-unit-level information and outperforms the strong baselines.</abstract>
      <url hash="8fd37af7">2023.findings-emnlp.149</url>
      <bibkey>huang-etal-2023-enhancing</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.149</doi>
    </paper>
    <paper id="150">
      <title><fixed-case>DRAFT</fixed-case>: Dense Retrieval Augmented Few-shot Topic classifier Framework</title>
      <author><first>Keonwoo</first><last>Kim</last></author>
      <author><first>Younggun</first><last>Lee</last></author>
      <pages>2278-2294</pages>
      <abstract>With the growing volume of diverse information, the demand for classifying arbitrary topics has become increasingly critical. To address this challenge, we introduce DRAFT, a simple framework designed to train a classifier for few-shot topic classification. DRAFT uses a few examples of a specific topic as queries to construct Customized dataset with a dense retriever model. Multi-query retrieval (MQR) algorithm, which effectively handles multiple queries related to a specific topic, is applied to construct the Customized dataset. Subsequently, we fine-tune a classifier using the Customized dataset to identify the topic. To demonstrate the efficacy of our proposed approach, we conduct evaluations on both widely used classification benchmark datasets and manually constructed datasets with 291 diverse topics, which simulate diverse contents encountered in real-world applications. DRAFT shows competitive or superior performance compared to baselines that use in-context learning, such as GPT-3 175B and InstructGPT 175B, on few-shot topic classification tasks despite having 177 times fewer parameters, demonstrating its effectiveness.</abstract>
      <url hash="742207e2">2023.findings-emnlp.150</url>
      <bibkey>kim-lee-2023-draft</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.150</doi>
    </paper>
    <paper id="151">
      <title>A Framework for Exploring Player Perceptions of <fixed-case>LLM</fixed-case>-Generated Dialogue in Commercial Video Games</title>
      <author><first>Nader</first><last>Akoury</last></author>
      <author><first>Qian</first><last>Yang</last></author>
      <author><first>Mohit</first><last>Iyyer</last></author>
      <pages>2295-2311</pages>
      <abstract>The growing capabilities of large language models (LLMs) have inspired recent efforts to integrate LLM-generated dialogue into video games. However, evaluation remains a major challenge: how do we assess the player experience in a commercial game augmented with LLM-generated dialogue? To explore this question, we introduce a dynamic evaluation framework for the dialogue management systems that govern the task-oriented dialogue often found in roleplaying video games. We first extract dialogue from the widely-acclaimed role-playing game *Disco Elysium: The Final Cut*, which contains 1.1M words of dialogue spread across a complex graph of utterances where node reachability depends on game state (e.g., whether a certain item is held). Using this dataset, we have GPT-4 perform *dialogue infilling* to generate grounded utterances based on game state represented via code. In a statistically robust study of 28 players recruited from the r/DiscoyElysium subreddit, the LLM outputs are evaluated against the game designers’ writing via both preference judgments and free-form feedback using a web interface that recreates the game’s core conversation functionality. Overall, the game designers’ prose is significantly preferred to GPT-4 generations, with participants citing reasons such as improved logical flow and grounding with the game state. To spur more principled future research in this area, we release our web interface and tools to enable researchers to build upon our work. https://pl.aiwright.dev</abstract>
      <url hash="55f7a830">2023.findings-emnlp.151</url>
      <bibkey>akoury-etal-2023-framework</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.151</doi>
    </paper>
    <paper id="152">
      <title>Generative Calibration for In-context Learning</title>
      <author><first>Zhongtao</first><last>Jiang</last></author>
      <author><first>Yuanzhe</first><last>Zhang</last></author>
      <author><first>Cao</first><last>Liu</last></author>
      <author><first>Jun</first><last>Zhao</last></author>
      <author><first>Kang</first><last>Liu</last></author>
      <pages>2312-2333</pages>
      <abstract>As one of the most exciting features of large language models (LLMs), in-context learning is a mixed blessing. While it allows users to fast-prototype a task solver with only a few training examples, the performance is generally sensitive to various configurations of the prompt such as the choice or order of the training examples. In this paper, we for the first time theoretically and empirically identify that such a paradox is mainly due to the label shift of the in-context model to the data distribution, in which LLMs shift the label marginal <tex-math>p(y)</tex-math> while having a good label conditional <tex-math>p(x|y)</tex-math>. With this understanding, we can simply calibrate the in-context predictive distribution by adjusting the label marginal, which is estimated via Monte-Carlo sampling over the in-context model, i.e., generation of LLMs. We call our approach as generative calibration. We conduct exhaustive experiments with 12 text classification tasks and 12 LLMs scaling from 774M to 33B, generally find that the proposed method greatly and consistently outperforms the ICL as well as state-of-the-art calibration methods, by up to 27% absolute in macro-F1. Meanwhile, the proposed method is also stable under different prompt configurations.</abstract>
      <url hash="f6075eba">2023.findings-emnlp.152</url>
      <bibkey>jiang-etal-2023-generative</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.152</doi>
    </paper>
    <paper id="153">
      <title>Chain of Thought with Explicit Evidence Reasoning for Few-shot Relation Extraction</title>
      <author><first>Xilai</first><last>Ma</last></author>
      <author><first>Jing</first><last>Li</last></author>
      <author><first>Min</first><last>Zhang</last></author>
      <pages>2334-2352</pages>
      <abstract>Few-shot relation extraction involves identifying the type of relationship between two specific entities within a text, using a limited number of annotated samples. A variety of solutions to this problem have emerged by applying meta-learning and neural graph techniques which typically necessitate a training process for adaptation. Recently, the strategy of in-context learning has been demonstrating notable results without the need of training. Few studies have already utilized in-context learning for zero-shot information extraction. Unfortunately, the evidence for inference is either not considered or implicitly modeled during the construction of chain-of-thought prompts. In this paper, we propose a novel approach for few-shot relation extraction using large language models, named CoT-ER, chain-of-thought with explicit evidence reasoning. In particular, CoT-ER first induces large language models to generate evidences using task-specific and concept-level knowledge. Then these evidences are explicitly incorporated into chain-of-thought prompting for relation extraction. Experimental results demonstrate that our CoT-ER approach (with 0% training data) achieves competitive performance compared to the fully-supervised (with 100% training data) state-of-the-art approach on the FewRel1.0 and FewRel2.0 datasets.</abstract>
      <url hash="43a0a4d1">2023.findings-emnlp.153</url>
      <bibkey>ma-etal-2023-chain-thought</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.153</doi>
    </paper>
    <paper id="154">
      <title><fixed-case>A</fixed-case>da<fixed-case>T</fixed-case>ran<fixed-case>S</fixed-case>: Adapting with Boundary-based Shrinking for End-to-End Speech Translation</title>
      <author><first>Xingshan</first><last>Zeng</last></author>
      <author><first>Liangyou</first><last>Li</last></author>
      <author><first>Qun</first><last>Liu</last></author>
      <pages>2353-2361</pages>
      <abstract>To alleviate the data scarcity problem in End-to-end speech translation (ST), pre-training on data for speech recognition and machine translation is considered as an important technique. However, the modality gap between speech and text prevents the ST model from efficiently inheriting knowledge from the pre-trained models. In this work, we propose AdaTranS for end-to-end ST. It adapts the speech features with a new shrinking mechanism to mitigate the length mismatch between speech and text features by predicting word boundaries. Experiments on the MUST-C dataset demonstrate that AdaTranS achieves better performance than the other shrinking-based methods, with higher inference speed and lower memory usage. Further experiments also show that AdaTranS can be equipped with additional alignment losses to further improve performance.</abstract>
      <url hash="8ccca615">2023.findings-emnlp.154</url>
      <bibkey>zeng-etal-2023-adatrans</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.154</doi>
    </paper>
    <paper id="155">
      <title>No offence, Bert - <fixed-case>I</fixed-case> insult only humans! Multilingual sentence-level attack on toxicity detection networks</title>
      <author><first>Sergey</first><last>Berezin</last></author>
      <author><first>Reza</first><last>Farahbakhsh</last></author>
      <author><first>Noel</first><last>Crespi</last></author>
      <pages>2362-2369</pages>
      <abstract>We introduce a simple yet efficient sentence-level attack on black-box toxicity detector models. By adding several positive words or sentences to the end of a hateful message, we are able to change the prediction of a neural network and pass the toxicity detection system check. This approach is shown to be working on seven languages from three different language families. We also describe the defence mechanism against the aforementioned attack and discuss its limitations.</abstract>
      <url hash="1f3f06d3">2023.findings-emnlp.155</url>
      <bibkey>berezin-etal-2023-offence</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.155</doi>
    </paper>
    <paper id="156">
      <title>Manipulating the Perceived Personality Traits of Language Models</title>
      <author><first>Graham</first><last>Caron</last></author>
      <author><first>Shashank</first><last>Srivastava</last></author>
      <pages>2370-2386</pages>
      <abstract>Psychology research has long explored aspects of human personality like extroversion, agreeableness and emotional stability, three of the personality traits that make up the ‘Big Five’. Categorizations like the ‘Big Five’ are commonly used to assess and diagnose personality types. In this work, we explore whether text generated from large language models exhibits consistency in it’s perceived ‘Big Five’ personality traits. For example, is a language model such as GPT2 likely to respond in a consistent way if asked to go out to a party? We also show that when exposed to different types of contexts (such as personality descriptions, or answers to diagnostic questions about personality traits), language models such as BERT and GPT2 consistently identify and mirror personality markers in those contexts. This behavior illustrates an ability to be manipulated in a predictable way (with correlations up to 0.84 between intended and realized changes in personality traits), and frames them as tools for controlling personas in applications such as dialog systems. We contribute two data-sets of personality descriptions of humans subjects.</abstract>
      <url hash="e11e36bf">2023.findings-emnlp.156</url>
      <bibkey>caron-srivastava-2023-manipulating</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.156</doi>
    </paper>
    <paper id="157">
      <title><fixed-case>W</fixed-case>iki<fixed-case>C</fixed-case>hat: Stopping the Hallucination of Large Language Model Chatbots by Few-Shot Grounding on <fixed-case>W</fixed-case>ikipedia</title>
      <author><first>Sina</first><last>Semnani</last></author>
      <author><first>Violet</first><last>Yao</last></author>
      <author><first>Heidi</first><last>Zhang</last></author>
      <author><first>Monica</first><last>Lam</last></author>
      <pages>2387-2413</pages>
      <abstract>This paper presents the first few-shot LLM-based chatbot that almost never hallucinates and has high conversationality and low latency. WikiChat is grounded on the English Wikipedia, the largest curated free-text corpus. WikiChat generates a response from an LLM, retains only the grounded facts, and combines them with additional information it retrieves from the corpus to form factual and engaging responses. We distill WikiChat based on GPT-4 into a 7B-parameter LLaMA model with minimal loss of quality, to significantly improve its latency, cost and privacy, and facilitate research and deployment. Using a novel hybrid human-and-LLM evaluation methodology, we show that our best system achieves 97.3% factual accuracy in simulated conversations. It significantly outperforms all retrieval-based and LLM-based baselines, and by 3.9%, 38.6% and 51.0% on head, tail and recent knowledge compared to GPT-4. Compared to previous state-of-the-art retrieval-based chatbots, WikiChat is also significantly more informative and engaging, just like an LLM. WikiChat achieves 97.9% factual accuracy in conversations with human users about recent topics, 55.0% better than GPT-4, while receiving significantly higher user ratings and more favorable comments.</abstract>
      <url hash="78689884">2023.findings-emnlp.157</url>
      <bibkey>semnani-etal-2023-wikichat</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.157</doi>
    </paper>
    <paper id="158">
      <title>Automated Few-Shot Classification with Instruction-Finetuned Language Models</title>
      <author><first>Rami</first><last>Aly</last></author>
      <author><first>Xingjian</first><last>Shi</last></author>
      <author><first>Kaixiang</first><last>Lin</last></author>
      <author><first>Aston</first><last>Zhang</last></author>
      <author><first>Andrew</first><last>Wilson</last></author>
      <pages>2414-2432</pages>
      <abstract>A particularly successful class of approaches for few-shot learning combines language models with prompts - hand-crafted task descriptions that complement data samples. However, designing prompts by hand for each task commonly requires domain knowledge and substantial guesswork. We observe, in the context of classification tasks, that instruction finetuned language models are remarkably robust towards some dimensions of a prompt’s design. We subsequently propose a simple method to eliminate the need for handcrafted prompts, named AuT-Few. This approach consists of (i) a prompt retrieval module that selects suitable task instructions from the instruction-tuning knowledge base, and (ii) the generation of two distinct, semantically meaningful, class descriptions and a selection mechanism via cross-validation. Over 12 datasets, spanning 8 classification tasks, we show that AuT-Few outperforms current state-of-the-art few-shot learning methods. Moreover, AuT-Few is the best ranking method across datasets on the RAFT few-shot benchmark. Notably, these results are achieved without task-specific handcrafted prompts on unseen tasks.</abstract>
      <url hash="c8667788">2023.findings-emnlp.158</url>
      <bibkey>aly-etal-2023-automated</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.158</doi>
    </paper>
    <paper id="159">
      <title>Meta-Learning of Prompt Generation for Lightweight Prompt Engineering on Language-Model-as-a-Service</title>
      <author><first>Hyeonmin</first><last>Ha</last></author>
      <author><first>Jihye</first><last>Lee</last></author>
      <author><first>Wookje</first><last>Han</last></author>
      <author><first>Byung-Gon</first><last>Chun</last></author>
      <pages>2433-2445</pages>
      <abstract>Recently, many companies have been providing the capabilities of large language models as services. These Language-Model-as-a-Service (LMaaS) offerings support a variety of user tasks through in-context learning from prompts, which include instructions and demonstrations of the task. However, for users, manually crafting prompts or running automatic prompt tuning methods themselves can be demanding. Despite these challenges, LMaaS providers do not offer automatic prompt engineering methods as part of their services. One of the major obstacles to deploying them on an LMaaS is the heavy computational costs associated with automatic prompt engineering methods. These methods are typically designed to iterate through tens of thousands of examples, which impose unaffordable overheads for LMaaS providers. In this paper, we introduce MetaL-Prompt, a novel lightweight automatic prompt generation method for LMaaS. MetaL-Prompt meta-trains a prompt generation model (PGM) to enable robust learning by the language model from the contexts created by the generated prompts (i.e., in-context learning). Thanks to our meta-learning approach, a PGM can generate prompts for unseen tasks without requiring additional training for those specific tasks. Furthermore, the PGM can generate prompts with a single forward pass, significantly reducing computational costs compared to previous methods. We evaluate MetaL-Prompt on a range of unseen tasks and find that it improves performance by up to 19.4% in terms of mean F1 score on QA datasets compared to the state-of-the-art baseline P-tuning, with limited computational cost.</abstract>
      <url hash="b2f2afff">2023.findings-emnlp.159</url>
      <bibkey>ha-etal-2023-meta</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.159</doi>
    </paper>
    <paper id="160">
      <title>Beneath Surface Similarity: Large Language Models Make Reasonable Scientific Analogies after Structure Abduction</title>
      <author><first>Siyu</first><last>Yuan</last></author>
      <author><first>Jiangjie</first><last>Chen</last></author>
      <author><first>Xuyang</first><last>Ge</last></author>
      <author><first>Yanghua</first><last>Xiao</last></author>
      <author><first>Deqing</first><last>Yang</last></author>
      <pages>2446-2460</pages>
      <abstract>The vital role of analogical reasoning in human cognition allows us to grasp novel concepts by linking them with familiar ones through shared relational structures. Despite the attention previous research has given to word analogies, this work suggests that Large Language Models (LLMs) often overlook the structures that underpin these analogies, raising questions about the efficacy of word analogies as a measure of analogical reasoning skills akin to human cognition. In response to this, our paper introduces a task of analogical structure abduction, grounded in cognitive psychology, designed to abduce structures that form an analogy between two systems. In support of this task, we establish a benchmark called SCAR, containing 400 scientific analogies from 13 distinct fields, tailored for evaluating analogical reasoning with structure abduction. The empirical evidence underlines the continued challenges faced by LLMs, including ChatGPT and GPT-4, in mastering this task, signifying the need for future exploration to enhance their abilities.</abstract>
      <url hash="121c506a">2023.findings-emnlp.160</url>
      <bibkey>yuan-etal-2023-beneath</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.160</doi>
    </paper>
    <paper id="161">
      <title><fixed-case>H</fixed-case>i<fixed-case>CL</fixed-case>: Hierarchical Contrastive Learning of Unsupervised Sentence Embeddings</title>
      <author><first>Zhuofeng</first><last>Wu</last></author>
      <author><first>Chaowei</first><last>Xiao</last></author>
      <author><first>VG Vinod</first><last>Vydiswaran</last></author>
      <pages>2461-2476</pages>
      <abstract>In this paper, we propose a hierarchical contrastive learning framework, HiCL, which considers local segment-level and global sequence-level relationships to improve training efficiency and effectiveness. Traditional methods typically encode a sequence in its entirety for contrast with others, often neglecting local representation learning, leading to challenges in generalizing to shorter texts. Conversely, HiCL improves its effectiveness by dividing the sequence into several segments and employing both local and global contrastive learning to model segment-level and sequence-level relationships. Further, considering the quadratic time complexity of transformers over input tokens, HiCL boosts training efficiency by first encoding short segments and then aggregating them to obtain the sequence representation. Extensive experiments show that HiCL enhances the prior top-performing SNCSE model across seven extensively evaluated STS tasks, with an average increase of +0.2% observed on <tex-math>BERT_{large}</tex-math> and +0.44% on <tex-math>RoBERTa_{large}</tex-math>.</abstract>
      <url hash="4994eb6c">2023.findings-emnlp.161</url>
      <bibkey>wu-etal-2023-hicl</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.161</doi>
    </paper>
    <paper id="162">
      <title>Density-Aware Prototypical Network for Few-Shot Relation Classification</title>
      <author><first>Jianfeng</first><last>Wu</last></author>
      <author><first>Mengting</first><last>Hu</last></author>
      <author><first>Yike</first><last>Wu</last></author>
      <author><first>Bingzhe</first><last>Wu</last></author>
      <author><first>Yalan</first><last>Xie</last></author>
      <author><first>Mingming</first><last>Liu</last></author>
      <author><first>Renhong</first><last>Cheng</last></author>
      <pages>2477-2489</pages>
      <abstract>In recent years, few-shot relation classification has evoked many research interests. Yet a more challenging problem, i.e. none-of-the-above (NOTA), is under-explored. Existing works mainly regard NOTA as an extra class and treat it the same as known relations. However, such a solution ignores the overall instance distribution, where NOTA instances are actually outliers and distributed unnaturally compared with known ones. In this paper, we propose a density-aware prototypical network (D-Proto) to treat various instances distinctly. Specifically, we design unique training objectives to separate known instances and isolate NOTA instances, respectively. This produces an ideal instance distribution, where known instances are dense yet NOTAs have a small density. Moreover, we propose a NOTA detection module to further enlarge the density of known samples, and discriminate NOTA and known samples accurately. Experimental results demonstrate that the proposed method outperforms strong baselines with robustness towards various NOTA rates. The code will be made public after the paper is accepted.</abstract>
      <url hash="60dc4758">2023.findings-emnlp.162</url>
      <bibkey>wu-etal-2023-density</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.162</doi>
    </paper>
    <paper id="163">
      <title>Improved Training of Deep Text Clustering</title>
      <author><first>Zonghao</first><last>Yang</last></author>
      <author><first>Wenpeng</first><last>Hu</last></author>
      <author><first>Yushan</first><last>Tan</last></author>
      <author><first>Zhunchen</first><last>Luo</last></author>
      <pages>2490-2499</pages>
      <abstract>The classical deep clustering optimization methods basically leverage information such as clustering centers, mutual information, and distance metrics to construct implicit generalized labels to establish information feedback (weak supervision) and thus optimize the deep model. However, the resulting generalized labels have different degrees of errors in the whole clustering process due to the limitation of clustering accuracy, which greatly interferes with the clustering process. To this end, this paper proposes a general deep clustering optimization method from the perspective of empirical risk minimization, using the correlation relationship between the samples. Experiments on two classical deep clustering methods demonstrate the necessity and effectiveness of the method. Code is available at https://github.com/yangzonghao1024/DCGLU.</abstract>
      <url hash="dc400783">2023.findings-emnlp.163</url>
      <bibkey>yang-etal-2023-improved</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.163</doi>
    </paper>
    <paper id="164">
      <title><fixed-case>R</fixed-case>ega<fixed-case>VAE</fixed-case>: A Retrieval-Augmented <fixed-case>G</fixed-case>aussian Mixture Variational Auto-Encoder for Language Modeling</title>
      <author><first>Jingcheng</first><last>Deng</last></author>
      <author><first>Liang</first><last>Pang</last></author>
      <author><first>Huawei</first><last>Shen</last></author>
      <author><first>Xueqi</first><last>Cheng</last></author>
      <pages>2500-2510</pages>
      <abstract>Retrieval-augmented language models show promise in addressing issues like outdated information and hallucinations in language models (LMs). However, current research faces two main problems: 1) determining what information to retrieve, and 2) effectively combining retrieved information during generation. We argue that valuable retrieved information should not only be related to the current source text but also consider the future target text, given the nature of LMs that model future tokens. Moreover, we propose that aggregation using latent variables derived from a compact latent space is more efficient than utilizing explicit raw text, which is limited by context length and susceptible to noise. Therefore, we introduce RegaVAE, a retrieval-augmented language model built upon the variational auto-encoder (VAE). It encodes the text corpus into a latent space, capturing current and future information from both source and target text. Additionally, we leverage the VAE to initialize the latent space and adopt the probabilistic form of the retrieval generation paradigm by expanding the Gaussian prior distribution into a Gaussian mixture distribution. Theoretical analysis provides an optimizable upper bound for RegaVAE. Experimental results on various datasets demonstrate significant improvements in text generation quality and hallucination removal.</abstract>
      <url hash="fc830c16">2023.findings-emnlp.164</url>
      <bibkey>deng-etal-2023-regavae</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.164</doi>
    </paper>
    <paper id="165">
      <title><fixed-case>R</fixed-case>ef<fixed-case>GPT</fixed-case>: Dialogue Generation of <fixed-case>GPT</fixed-case>, by <fixed-case>GPT</fixed-case>, and for <fixed-case>GPT</fixed-case></title>
      <author><first>Dongjie</first><last>Yang</last></author>
      <author><first>Ruifeng</first><last>Yuan</last></author>
      <author><first>Yuantao</first><last>Fan</last></author>
      <author><first>Yifei</first><last>Yang</last></author>
      <author><first>Zili</first><last>Wang</last></author>
      <author><first>Shusen</first><last>Wang</last></author>
      <author><first>Hai</first><last>Zhao</last></author>
      <pages>2511-2535</pages>
      <abstract>Large Language Models (LLMs) have attained the impressive capability to resolve a wide range of NLP tasks by fine-tuning high-quality instruction data. However, collecting human-written data of high quality, especially multi-turn dialogues, is expensive and unattainable for most people. Though previous studies have used powerful LLMs to generate the dialogues automatically, they all suffer from generating untruthful dialogues because of the model hallucination. Therefore, we propose a method called RefGPT to generate enormous truthful and customized dialogues without worrying about factual errors caused by the model hallucination. RefGPT solves the model hallucination in dialogue generation by restricting the LLMs to leverage the given reference instead of reciting their own knowledge to generate dialogues. Additionally, RefGPT adds detailed controls on every utterance to enable high customization capability, which previous studies have ignored. On the basis of RefGPT, we also propose two high-quality dialogue datasets generated by GPT-4, namely **RefGPT-Fact** and **RefGPT-Code**. RefGPT-Fact is a dataset with 100k multi-turn dialogues based on factual knowledge and RefGPT-Code has 76k multi-turn dialogues covering a wide range of coding scenarios. Our code and datasets are released in https://github.com/mutonix/RefGPT.</abstract>
      <url hash="6f543d3a">2023.findings-emnlp.165</url>
      <bibkey>yang-etal-2023-refgpt</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.165</doi>
    </paper>
    <paper id="166">
      <title><fixed-case>INA</fixed-case>: An Integrative Approach for Enhancing Negotiation Strategies with Reward-Based Dialogue Agent</title>
      <author><first>Zishan</first><last>Ahmad</last></author>
      <author><first>Suman</first><last>Saurabh</last></author>
      <author><first>Vaishakh</first><last>Menon</last></author>
      <author><first>Asif</first><last>Ekbal</last></author>
      <author><first>Roshni</first><last>Ramnani</last></author>
      <author><first>Anutosh</first><last>Maitra</last></author>
      <pages>2536-2549</pages>
      <abstract>In this paper, we propose a novel negotiation agent designed for the online marketplace. Our dialogue agent is integrative in nature i.e, it possesses the capability to negotiate on price as well as other factors, such as the addition or removal of items from a deal bundle, thereby offering a more flexible and comprehensive negotiation experience. To enable this functionality, we create a new dataset called Integrative Negotiation Dataset (IND). For this dataset creation, we introduce a new semi-automated data creation method, which combines defining negotiation intents, actions, and intent-action simulation between users and the agent to generate potential dialogue flows. Finally, the prompting of GPT-J, a state-of-the-art language model, is done to generate dialogues for a given intent, with a human-in-the-loop process for post-editing and refining minor errors to ensure high data quality. We first train a maximum likelihood loss based model on IND, and then employ a set of novel rewards specifically tailored for the negotiation task to train our Integrative Negotiation Agent (INA). These rewards incentivize the agent to learn effective negotiation strategies that can adapt to various contextual requirements and price proposals. We train our model and conduct experiments to evaluate the effectiveness of our reward-based dialogue agent for negotiation. Our results demonstrate that the proposed approach and reward functions significantly enhance the negotiation capabilities of the dialogue agent. The INA successfully engages in integrative negotiations, displaying the ability to dynamically adjust prices and negotiate the inclusion or exclusion of items in a deal bundle.</abstract>
      <url hash="d8ca7340">2023.findings-emnlp.166</url>
      <bibkey>ahmad-etal-2023-ina</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.166</doi>
    </paper>
    <paper id="167">
      <title>Large Language Models are Better Reasoners with Self-Verification</title>
      <author><first>Yixuan</first><last>Weng</last></author>
      <author><first>Minjun</first><last>Zhu</last></author>
      <author><first>Fei</first><last>Xia</last></author>
      <author><first>Bin</first><last>Li</last></author>
      <author><first>Shizhu</first><last>He</last></author>
      <author><first>Shengping</first><last>Liu</last></author>
      <author><first>Bin</first><last>Sun</last></author>
      <author><first>Kang</first><last>Liu</last></author>
      <author><first>Jun</first><last>Zhao</last></author>
      <pages>2550-2575</pages>
      <abstract>Recently, with the chain of thought (CoT) prompting, large language models (LLMs), e.g., GPT-3, have shown strong reasoning ability in several natural language processing tasks such as arithmetic, commonsense, and logical reasoning. However, LLMs with CoT require multi-step prompting and multi-token prediction, which is highly sensitive to individual mistakes and vulnerable to error accumulation. The above issues make the LLMs need the ability to verify the answers. In fact, after inferring conclusions in some thinking decision tasks, people often check them by re-verifying steps to avoid some mistakes. In this paper, we propose and prove that LLMs also have similar self-verification abilities. We take the conclusion obtained by CoT as one of the conditions for solving the original problem. By performing a backward verification of the answers that LLM deduced for itself, we can obtain interpretable answer validation scores to select the candidate answer with the highest score. Experimental results demonstrate that the proposed method can improve the reasoning performance on various arithmetic, commonsense, and logical reasoning datasets. Our code is publicly available at: https://github.com/WENGSYX/Self-Verification.</abstract>
      <url hash="eb8841d3">2023.findings-emnlp.167</url>
      <bibkey>weng-etal-2023-large</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.167</doi>
    </paper>
    <paper id="168">
      <title>Multi-Granularity Information Interaction Framework for Incomplete Utterance Rewriting</title>
      <author><first>Haowei</first><last>Du</last></author>
      <author><first>Dinghao</first><last>Zhang</last></author>
      <author><first>Chen</first><last>Li</last></author>
      <author><first>Yang</first><last>Li</last></author>
      <author><first>Dongyan</first><last>Zhao</last></author>
      <pages>2576-2581</pages>
      <abstract>Recent approaches in Incomplete Utterance Rewriting (IUR) fail to capture the source of important words, which is crucial to edit the incomplete utterance, and introduce words from irrelevant utterances. We propose a novel and effective multi-task information interaction framework including context selection, edit matrix construction, and relevance merging to capture the multi-granularity of semantic information. Benefiting from fetching the relevant utterance and figuring out the important words, our approach outperforms existing state-of-the-art models on two benchmark datasets Restoration-200K and CANAND in this field.</abstract>
      <url hash="12e539b2">2023.findings-emnlp.168</url>
      <bibkey>du-etal-2023-multi</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.168</doi>
    </paper>
    <paper id="169">
      <title>Accuracy is not enough: Evaluating Personalization in Summarizers</title>
      <author><first>Rahul</first><last>Vansh</last></author>
      <author><first>Darsh</first><last>Rank</last></author>
      <author><first>Sourish</first><last>Dasgupta</last></author>
      <author><first>Tanmoy</first><last>Chakraborty</last></author>
      <pages>2582-2595</pages>
      <abstract>Text summarization models are evaluated in terms of their accuracy and quality using various measures such as ROUGE, BLEU, METEOR, BERTScore, PYRAMID, readability, and several other recently proposed ones. The central objective of all accuracy measures is to evaluate the model’s ability to capture <tex-math>\textit{saliency}</tex-math> accurately. Since saliency is subjective w.r.t the readers’ preferences, there cannot be a fit-all summary for a given document. This means that in many use-cases, summarization models need to be personalized w.r.t user-profiles. However, to our knowledge, there is no measure to evaluate the <tex-math>\textit{degree-of-personalization}</tex-math> of a summarization model. In this paper, we first establish that existing accuracy measures cannot evaluate the degree of personalization of any summarization model, and then propose a novel measure, called <tex-math>EGISES</tex-math>, for automatically computing the same. Using the PENS dataset released by Microsoft Research, we analyze the degree of personalization of ten different state-of-the-art summarization models (both extractive and abstractive), five of which are explicitly trained for personalized summarization, and the remaining are appropriated to exhibit personalization. We conclude by proposing a generalized accuracy measure, called <tex-math>P</tex-math>-<tex-math>Accuracy</tex-math>, for designing accuracy measures that should also take personalization into account and demonstrate the robustness and reliability of the measure through meta-evaluation.</abstract>
      <url hash="fdc074f5">2023.findings-emnlp.169</url>
      <bibkey>vansh-etal-2023-accuracy</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.169</doi>
    </paper>
    <paper id="170">
      <title>For Generated Text, Is <fixed-case>NLI</fixed-case>-Neutral Text the Best Text?</title>
      <author><first>Michail</first><last>Mersinias</last></author>
      <author><first>Kyle</first><last>Mahowald</last></author>
      <pages>2596-2602</pages>
      <abstract>We explore incorporating natural language inference (NLI) into the text generative pipeline by using a pre-trained NLI model to assess whether a generated sentence entails, contradicts, or is neutral to the prompt and preceding text. First, we show that the NLI task is predictive of generation errors made by GPT-3. We use these results to develop an NLI-informed generation procedure for GPT-J. Then, we evaluate these generations by obtaining human annotations on error types and overall quality. We find that an NLI strategy of maximizing entailment improves text generation when the nucleus sampling randomness parameter value is high, while one which maximizes contradiction is in fact productive when the parameter value is low. Overall, though, we demonstrate that an NLI strategy of maximizing the neutral class provides the highest quality of generated text (significantly better than the vanilla generations), regardless of parameter value.</abstract>
      <url hash="fd3e120b">2023.findings-emnlp.170</url>
      <bibkey>mersinias-mahowald-2023-generated</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.170</doi>
    </paper>
    <paper id="171">
      <title>Combining Counting Processes and Classification Improves a Stopping Rule for Technology Assisted Review</title>
      <author><first>Reem</first><last>Bin-Hezam</last></author>
      <author><first>Mark</first><last>Stevenson</last></author>
      <pages>2603-2609</pages>
      <abstract>Technology Assisted Review (TAR) stopping rules aim to reduce the cost of manually assessing documents for relevance by minimising the number of documents that need to be examined to ensure a desired level of recall. This paper extends an effective stopping rule using information derived from a text classifier that can be trained without the need for any additional annotation. Experiments on multiple data sets (CLEF e-Health, TREC Total Recall, TREC Legal and RCV1) showed that the proposed approach consistently improves performance and outperforms several alternative methods.</abstract>
      <url hash="a045e080">2023.findings-emnlp.171</url>
      <bibkey>hezam-stevenson-2023-combining</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.171</doi>
    </paper>
    <paper id="172">
      <title>Complexity-Guided Curriculum Learning for Text Graphs</title>
      <author><first>Nidhi</first><last>Vakil</last></author>
      <author><first>Hadi</first><last>Amiri</last></author>
      <pages>2610-2626</pages>
      <abstract>Curriculum learning provides a systematic approach to training. It refines training progressively, tailors training to task requirements, and improves generalization through exposure to diverse examples. We present a curriculum learning approach that builds on existing knowledge about text and graph complexity formalisms for training with text graph data. The core part of our approach is a novel data scheduler, which employs “spaced repetition” and complexity formalisms to guide the training process. We demonstrate the effectiveness of the proposed approach on several text graph tasks and graph neural network architectures. The proposed model gains more and uses less data; consistently prefers text over graph complexity indices throughout training, while the best curricula derived from text and graph complexity indices are equally effective; and it learns transferable curricula across GNN models and datasets. In addition, we find that both node-level (local) and graph-level (global) graph complexity indices, as well as shallow and traditional text complexity indices play a crucial role in effective curriculum learning.</abstract>
      <url hash="f1f70332">2023.findings-emnlp.172</url>
      <bibkey>vakil-amiri-2023-complexity</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.172</doi>
    </paper>
    <paper id="173">
      <title><fixed-case>C</fixed-case>o<fixed-case>V</fixed-case>ariance-based Causal Debiasing for Entity and Relation Extraction</title>
      <author><first>Lin</first><last>Ren</last></author>
      <author><first>Yongbin</first><last>Liu</last></author>
      <author><first>Yixin</first><last>Cao</last></author>
      <author><first>Chunping</first><last>Ouyang</last></author>
      <pages>2627-2640</pages>
      <abstract>Joint entity and relation extraction tasks aim to recognize named entities and extract relations simultaneously. Suffering from a variety of data biases, such as data selection bias, and distribution bias (out of distribution, long-tail distribution), serious concerns can be witnessed to threaten the model’s transferability, robustness, and generalization. In this work, we address the above problems from a causality perspective. We propose a novel causal framework called c<tex-math>\underline{\textbf{o}}</tex-math>variance and <tex-math>\underline{\textbf{v}}</tex-math>ariance <tex-math>\underline{\textbf{o}}</tex-math>ptimization framework (OVO) to optimize feature representations and conduct general debiasing. In particular, the proposed <tex-math>\underline{\textbf{c}}</tex-math>ovariance <tex-math>\underline{\textbf{op}}</tex-math>timizing (COP) minimizes characterizing features’ covariance for alleviating the selection and distribution bias and enhances feature representation in the feature space. Furthermore, based on the causal backdoor adjustment, we propose <tex-math>\\underline{\textbf{v}}</tex-math>ariance <tex-math>\underline{\textbf{op}}</tex-math>timizing (VOP) separates samples in terms of label information and minimizes the variance of each dimension in the feature vectors of the same class label for mitigating the distribution bias further. By applying it to three strong baselines in two widely used datasets, the results demonstrate the effectiveness and generalization of OVO for joint entity and relation extraction tasks. Furthermore, a fine-grained analysis reveals that OVO possesses the capability to mitigate the impact of long-tail distribution.</abstract>
      <url hash="3d4ec092">2023.findings-emnlp.173</url>
      <bibkey>ren-etal-2023-covariance</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.173</doi>
    </paper>
    <paper id="174">
      <title>Multi-label and Multi-target Sampling of Machine Annotation for Computational Stance Detection</title>
      <author><first>Zhengyuan</first><last>Liu</last></author>
      <author><first>Hai</first><last>Chieu</last></author>
      <author><first>Nancy</first><last>Chen</last></author>
      <pages>2641-2649</pages>
      <abstract>Data collection from manual labeling provides domain-specific and task-aligned supervision for data-driven approaches, and a critical mass of well-annotated resources is required to achieve reasonable performance in natural language processing tasks. However, manual annotations are often challenging to scale up in terms of time and budget, especially when domain knowledge, capturing subtle semantic features, and reasoning steps are needed. In this paper, we investigate the efficacy of leveraging large language models on automated labeling for computational stance detection. We empirically observe that while large language models show strong potential as an alternative to human annotators, their sensitivity to task-specific instructions and their intrinsic biases pose intriguing yet unique challenges in machine annotation. We introduce a multi-label and multi-target sampling strategy to optimize the annotation quality. Experimental results on the benchmark stance detection corpora show that our method can significantly improve performance and learning efficacy.</abstract>
      <url hash="2ed53329">2023.findings-emnlp.174</url>
      <bibkey>liu-etal-2023-multi</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.174</doi>
    </paper>
    <paper id="175">
      <title>In What Languages are Generative Language Models the Most Formal? Analyzing Formality Distribution across Languages</title>
      <author><first>Asım</first><last>Ersoy</last></author>
      <author><first>Gerson</first><last>Vizcarra</last></author>
      <author><first>Tahsin</first><last>Mayeesha</last></author>
      <author><first>Benjamin</first><last>Muller</last></author>
      <pages>2650-2666</pages>
      <abstract>Multilingual generative language models (LMs) are increasingly fluent in a large variety of languages. Trained on the concatenation of corpora in multiple languages, they enable powerful transfer from high-resource languages to low-resource ones. However, it is still unknown what cultural biases are induced in the predictions of these models. In this work, we focus on one language property highly influenced by culture: formality. We analyze the formality distributions of XGLM and BLOOM’s predictions, two popular generative multilingual language models, in 5 languages. We classify 1,200 generations per language as formal, informal, or incohesive and measure the impact of the prompt formality on the predictions. Overall, we observe a diversity of behaviors across the models and languages. For instance, XGLM generates informal text in Arabic and Bengali when conditioned with informal prompts, much more than BLOOM. In addition, even though both models are highly biased toward the formal style when prompted neutrally, we find that the models generate a significant amount of informal predictions even when prompted with formal text. We release with this work 6,000 annotated samples, paving the way for future work on the formality of generative multilingual LMs.</abstract>
      <url hash="245c49a8">2023.findings-emnlp.175</url>
      <bibkey>ersoy-etal-2023-languages</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.175</doi>
    </paper>
    <paper id="176">
      <title><fixed-case>M</fixed-case>a<fixed-case>XM</fixed-case>: Towards Multilingual Visual Question Answering</title>
      <author><first>Soravit</first><last>Changpinyo</last></author>
      <author><first>Linting</first><last>Xue</last></author>
      <author><first>Michal</first><last>Yarom</last></author>
      <author><first>Ashish</first><last>Thapliyal</last></author>
      <author><first>Idan</first><last>Szpektor</last></author>
      <author><first>Julien</first><last>Amelot</last></author>
      <author><first>Xi</first><last>Chen</last></author>
      <author><first>Radu</first><last>Soricut</last></author>
      <pages>2667-2682</pages>
      <abstract>Visual Question Answering (VQA) has been primarily studied through the lens of the English language. Yet, tackling VQA in other languages in the same manner would require a considerable amount of resources. In this paper, we propose scalable solutions to multilingual visual question answering (mVQA), on both data and modeling fronts. We first propose a translation-based framework to mVQA data generation that requires much less human annotation efforts than the conventional approach of directly collection questions and answers. Then, we apply our framework to the multilingual captions in the Crossmodal-3600 dataset and develop an efficient annotation protocol to create MaXM, a test-only VQA benchmark in 7 diverse languages. Finally, we develop a simple, lightweight, and effective approach as well as benchmark state-of-the-art English and multilingual VQA models. We hope that our benchmark encourages further research on mVQA.</abstract>
      <url hash="06ad9870">2023.findings-emnlp.176</url>
      <bibkey>changpinyo-etal-2023-maxm</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.176</doi>
    </paper>
    <paper id="177">
      <title>Efficient Latent Variable Modeling for Knowledge-Grounded Dialogue Generation</title>
      <author><first>Gunsoo</first><last>Han</last></author>
      <author><first>Daejin</first><last>Jo</last></author>
      <author><first>Daniel</first><last>Nam</last></author>
      <author><first>Eunseop</first><last>Yoon</last></author>
      <author><first>Taehwan</first><last>Kwon</last></author>
      <author><first>Seungeun</first><last>Rho</last></author>
      <author><first>Kyoung-Woon</first><last>On</last></author>
      <author><first>Chang</first><last>Yoo</last></author>
      <author><first>Sungwoong</first><last>Kim</last></author>
      <pages>2683-2702</pages>
      <abstract>Knowledge-grounded dialogue generation requires first retrieving appropriate external knowledge based on a conversational context and then generating a response grounded on the retrieved knowledge. In general, these two sequential modules, a knowledge retriever and a response generator, have been separately trained in a supervised manner. However, obtaining intermediate labels of the ground-truth knowledge is expensive, especially in open-domain conversations. Latent variable modeling avoids this need for the labels. In this paper, we propose an efficient algorithm for this latent variable modeling that is able to leverage a large amount of dialogue data. Rather than directly training the complex retriever, we adapt a query generator with an off-the-shelf retriever, and the query generator and response generator are simultaneously trained over the latent variable of query. Moreover, we employ lower bound of the evidence as a training objective and modify it to robustly perform the joint training. Experimental results on diverse knowledge-grounded dialogue datasets show that the proposed algorithm significantly outperforms the supervised learning algorithm even without the use of the annotated knowledge while maintaining efficiency and scalability.</abstract>
      <url hash="6789687d">2023.findings-emnlp.177</url>
      <bibkey>han-etal-2023-efficient</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.177</doi>
    </paper>
    <paper id="178">
      <title>Ask To The Point: Open-Domain Entity-Centric Question Generation</title>
      <author><first>Yuxiang</first><last>Liu</last></author>
      <author><first>Jie</first><last>Huang</last></author>
      <author><first>Kevin</first><last>Chang</last></author>
      <pages>2703-2716</pages>
      <abstract>We introduce a new task called *entity-centric question generation* (ECQG), motivated by real-world applications such as topic-specific learning, assisted reading, and fact-checking. The task aims to generate questions from an entity perspective. To solve ECQG, we propose a coherent PLM-based framework GenCONE with two novel modules: content focusing and question verification. The content focusing module first identifies a focus as “what to ask” to form draft questions, and the question verification module refines the questions afterwards by verifying the answerability. We also construct a large-scale open-domain dataset from SQuAD to support this task. Our extensive experiments demonstrate that GenCONE significantly and consistently outperforms various baselines, and two modules are effective and complementary in generating high-quality questions.</abstract>
      <url hash="fcd671ff">2023.findings-emnlp.178</url>
      <bibkey>liu-etal-2023-ask</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.178</doi>
    </paper>
    <paper id="179">
      <title>Self-prompted Chain-of-Thought on Large Language Models for Open-domain Multi-hop Reasoning</title>
      <author><first>Jinyuan</first><last>Wang</last></author>
      <author><first>Junlong</first><last>Li</last></author>
      <author><first>Hai</first><last>Zhao</last></author>
      <pages>2717-2731</pages>
      <abstract>In open-domain question-answering (ODQA), most existing questions require single-hop reasoning on commonsense. To further extend this task, we officially introduce open-domain multi-hop reasoning (ODMR) by answering multi-hop questions with explicit reasoning steps in open-domain setting. Recently, large language models (LLMs) have found significant utility in facilitating ODQA without external corpus. Furthermore, chain-of-thought (CoT) prompting boosts the reasoning capability of LLMs to a greater extent with manual or automated paradigms. However, existing automated methods lack of quality assurance, while manual approaches suffer from limited scalability and poor diversity, hindering the capabilities of LLMs. In this paper, we propose Self-prompted Chain-of-Thought (SP-CoT), an automated framework to mass-produce high quality CoTs of LLMs, by LLMs and for LLMs. SP-CoT introduces an automated generation pipeline of high quality ODMR datasets, an adaptive sampler for in-context CoT selection and self-prompted inference via in-context learning. Extensive experiments on four multi-hop question-answering benchmarks show that our proposed SP-CoT not only significantly surpasses the previous SOTA methods on large-scale (175B) LLMs, but also nearly doubles the zero-shot performance of small-scale (13B) LLMs. Further analysis reveals the remarkable capability of SP-CoT to elicit direct and concise intermediate reasoning steps by recalling ~50% of intermediate answers on MuSiQue-Ans dataset.</abstract>
      <url hash="088065c9">2023.findings-emnlp.179</url>
      <bibkey>wang-etal-2023-self-prompted</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.179</doi>
    </paper>
    <paper id="180">
      <title><fixed-case>CASE</fixed-case>: Commonsense-Augmented Score with an Expanded Answer Space</title>
      <author><first>Wenkai</first><last>Chen</last></author>
      <author><first>Sahithya</first><last>Ravi</last></author>
      <author><first>Vered</first><last>Shwartz</last></author>
      <pages>2732-2744</pages>
      <abstract>LLMs have demonstrated impressive zero-shot performance on NLP tasks thanks to the knowledge they acquired in their training. In multiple-choice QA tasks, the LM probabilities are used as an imperfect measure of the plausibility of each answer choice. One of the major limitations of the basic score is that it treats all words as equally important. We propose CASE, a Commonsense-Augmented Score with an Expanded Answer Space. CASE addresses this limitation by assigning importance weights for individual words based on their semantic relations to other words in the input. The dynamic weighting approach outperforms basic LM scores, not only because it reduces noise from unimportant words, but also because it informs the model of implicit commonsense knowledge that may be useful for answering the question. We then also follow prior work in expanding the answer space by generating lexically-divergent answers that are conceptually-similar to the choices. When combined with answer space expansion, our method outperforms strong baselines on 5 commonsense benchmarks. We further show these two approaches are complementary and may be especially beneficial when using smaller LMs.</abstract>
      <url hash="50cc86ae">2023.findings-emnlp.180</url>
      <bibkey>chen-etal-2023-case</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.180</doi>
    </paper>
    <paper id="181">
      <title><fixed-case>GRENADE</fixed-case>: Graph-Centric Language Model for Self-Supervised Representation Learning on Text-Attributed Graphs</title>
      <author><first>Yichuan</first><last>Li</last></author>
      <author><first>Kaize</first><last>Ding</last></author>
      <author><first>Kyumin</first><last>Lee</last></author>
      <pages>2745-2757</pages>
      <abstract>Self-supervised representation learning on text-attributed graphs, which aims to create expressive and generalizable representations for various downstream tasks, has received increasing research attention lately. However, existing methods either struggle to capture the full extent of structural context information or rely on task-specific training labels, which largely hampers their effectiveness and generalizability in practice. To solve the problem of self-supervised representation learning on text-attributed graphs, we develop a novel Graph-Centric Language model – GRENADE. Specifically, GRENADE harnesses the synergy of both pre-trained language model and graph neural network by optimizing with two specialized self-supervised learning algorithms: graph-centric contrastive learning and graph-centric knowledge alignment. The proposed graph-centric self-supervised learning algorithms effectively help GRENADE to capture informative textual semantics as well as structural context information on text-attributed graphs. Through extensive experiments, GRENADE shows its superiority over state-of-the-art methods.</abstract>
      <url hash="afcf8d2b">2023.findings-emnlp.181</url>
      <bibkey>li-etal-2023-grenade</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.181</doi>
    </paper>
    <paper id="182">
      <title>Sources of Hallucination by Large Language Models on Inference Tasks</title>
      <author><first>Nick</first><last>McKenna</last></author>
      <author><first>Tianyi</first><last>Li</last></author>
      <author><first>Liang</first><last>Cheng</last></author>
      <author><first>Mohammad</first><last>Hosseini</last></author>
      <author><first>Mark</first><last>Johnson</last></author>
      <author><first>Mark</first><last>Steedman</last></author>
      <pages>2758-2774</pages>
      <abstract>Large Language Models (LLMs) are claimed to be capable of Natural Language Inference (NLI), necessary for applied tasks like question answering and summarization. We present a series of behavioral studies on several LLM families (LLaMA, GPT-3.5, and PaLM) which probe their behavior using controlled experiments. We establish two biases originating from pretraining which predict much of their behavior, and show that these are major sources of hallucination in generative LLMs. First, memorization at the level of sentences: we show that, regardless of the premise, models falsely label NLI test samples as entailing when the hypothesis is attested in training data, and that entities are used as “indices’ to access the memorized data. Second, statistical patterns of usage learned at the level of corpora: we further show a similar effect when the premise predicate is less frequent than that of the hypothesis in the training data, a bias following from previous studies. We demonstrate that LLMs perform significantly worse on NLI test samples which do not conform to these biases than those which do, and we offer these as valuable controls for future LLM evaluation.</abstract>
      <url hash="6acdf9ab">2023.findings-emnlp.182</url>
      <bibkey>mckenna-etal-2023-sources</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.182</doi>
    </paper>
    <paper id="183">
      <title>Efficient Long-Range Transformers: You Need to Attend More, but Not Necessarily at Every Layer</title>
      <author><first>Qingru</first><last>Zhang</last></author>
      <author><first>Dhananjay</first><last>Ram</last></author>
      <author><first>Cole</first><last>Hawkins</last></author>
      <author><first>Sheng</first><last>Zha</last></author>
      <author><first>Tuo</first><last>Zhao</last></author>
      <pages>2775-2786</pages>
      <abstract>Pretrained transformer models have demonstrated remarkable performance across various natural language processing tasks. These models leverage the attention mechanism to capture long- and short-range dependencies in the sequence. However, the (full) attention mechanism incurs high computational cost – quadratic in the sequence length, which is not affordable in tasks with long sequences, e.g., inputs with 8k tokens. Although sparse attention can be used to improve computational efficiency, as suggested in existing work, it has limited modeling capacity and often fails to capture complicated dependencies in long sequences. To tackle this challenge, we propose MASFormer, an easy-to-implement transformer variant with mixed attention spans. Specifically, MASFormer is equipped with full attention to capture long-range dependencies, but only at a small number of layers. For the remaining layers, MASformer only employs sparse attention to capture short-range dependencies. Our experiments on natural language modeling and generation tasks show that a decoder-only MASFormer model of 1.3B parameters can achieve competitive performance to vanilla transformers with full attention while significantly reducing computational cost (up to 75%). Additionally, we investigate the effectiveness of continual training with long sequence data and how sequence length impacts downstream generation performance, which may be of independent interest.</abstract>
      <url hash="61c79cfc">2023.findings-emnlp.183</url>
      <bibkey>zhang-etal-2023-efficient-long</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.183</doi>
    </paper>
    <paper id="184">
      <title>Prompting <fixed-case>C</fixed-case>hat<fixed-case>GPT</fixed-case> in <fixed-case>MNER</fixed-case>: Enhanced Multimodal Named Entity Recognition with Auxiliary Refined Knowledge</title>
      <author><first>Jinyuan</first><last>Li</last></author>
      <author><first>Han</first><last>Li</last></author>
      <author><first>Zhuo</first><last>Pan</last></author>
      <author><first>Di</first><last>Sun</last></author>
      <author><first>Jiahao</first><last>Wang</last></author>
      <author><first>Wenkun</first><last>Zhang</last></author>
      <author><first>Gang</first><last>Pan</last></author>
      <pages>2787-2802</pages>
      <abstract>Multimodal Named Entity Recognition (MNER) on social media aims to enhance textual entity prediction by incorporating image-based clues. Existing studies mainly focus on maximizing the utilization of pertinent image information or incorporating external knowledge from explicit knowledge bases. However, these methods either neglect the necessity of providing the model with external knowledge, or encounter issues of high redundancy in the retrieved knowledge. In this paper, we present PGIM — a two-stage framework that aims to leverage ChatGPT as an implicit knowledge base and enable it to heuristically generate auxiliary knowledge for more efficient entity prediction. Specifically, PGIM contains a Multimodal Similar Example Awareness module that selects suitable examples from a small number of predefined artificial samples. These examples are then integrated into a formatted prompt template tailored to the MNER and guide ChatGPT to generate auxiliary refined knowledge. Finally, the acquired knowledge is integrated with the original text and fed into a downstream model for further processing. Extensive experiments show that PGIM outperforms state-of-the-art methods on two classic MNER datasets and exhibits a stronger robustness and generalization capability.</abstract>
      <url hash="41245e0d">2023.findings-emnlp.184</url>
      <bibkey>li-etal-2023-prompting</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.184</doi>
    </paper>
    <paper id="185">
      <title>Understanding <fixed-case>HTML</fixed-case> with Large Language Models</title>
      <author><first>Izzeddin</first><last>Gur</last></author>
      <author><first>Ofir</first><last>Nachum</last></author>
      <author><first>Yingjie</first><last>Miao</last></author>
      <author><first>Mustafa</first><last>Safdari</last></author>
      <author><first>Austin</first><last>Huang</last></author>
      <author><first>Aakanksha</first><last>Chowdhery</last></author>
      <author><first>Sharan</first><last>Narang</last></author>
      <author><first>Noah</first><last>Fiedel</last></author>
      <author><first>Aleksandra</first><last>Faust</last></author>
      <pages>2803-2821</pages>
      <abstract>Large language models (LLMs) have shown exceptional performance on a variety of natural language tasks. Yet, their capabilities for HTML understanding – i.e., parsing the raw HTML of a webpage, with applications to automation of web-based tasks, crawling, and browser-assisted retrieval – have not been fully explored. We contribute HTML understanding models (fine-tuned LLMs) and an in-depth analysis of their capabilities under three tasks: (i) Semantic Classification of HTML elements, (ii) Description Generation for HTML inputs, and (iii) Autonomous Web Navigation of HTML pages. While previous work has developed dedicated architectures and training procedures for HTML understanding, we show that LLMs pretrained on standard natural language corpora transfer remarkably well to HTML understanding tasks. For instance, when fine-tuned on data from the MiniWoB benchmark, LLMs successfully complete 50% more tasks using 192x less data compared to the previous best supervised model. We create and open-source a large-scale HTML dataset distilled and auto-labeled from CommonCrawl</abstract>
      <url hash="ad43becf">2023.findings-emnlp.185</url>
      <bibkey>gur-etal-2023-understanding</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.185</doi>
    </paper>
    <paper id="186">
      <title>The <fixed-case>PEACE</fixed-case>-Reviews dataset: Modeling Cognitive Appraisals in Emotion Text Analysis</title>
      <author><first>Gerard</first><last>Yeo</last></author>
      <author><first>Kokil</first><last>Jaidka</last></author>
      <pages>2822-2840</pages>
      <abstract>Cognitive appraisal plays a pivotal role in deciphering emotions. Recent studies have delved into its significance, yet the interplay between various forms of cognitive appraisal and specific emotions, such as joy and anger, remains an area of exploration in consumption contexts. Our research introduces the PEACE-Reviews dataset, a unique compilation of annotated autobiographical accounts where individuals detail their emotional and appraisal experiences during interactions with personally significant products or services. Focusing on the inherent variability in consumer experiences, this dataset offers an in-depth analysis of participants’ psychological traits, their evaluative feedback on purchases, and the resultant emotions. Notably, the PEACE-Reviews dataset encompasses emotion, cognition, individual traits, and demographic data. We also introduce preliminary models that predict certain features based on the autobiographical narratives.</abstract>
      <url hash="8753e58f">2023.findings-emnlp.186</url>
      <bibkey>yeo-jaidka-2023-peace</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.186</doi>
    </paper>
    <paper id="187">
      <title><fixed-case>UR</fixed-case>eader: Universal <fixed-case>OCR</fixed-case>-free Visually-situated Language Understanding with Multimodal Large Language Model</title>
      <author><first>Jiabo</first><last>Ye</last></author>
      <author><first>Anwen</first><last>Hu</last></author>
      <author><first>Haiyang</first><last>Xu</last></author>
      <author><first>Qinghao</first><last>Ye</last></author>
      <author><first>Ming</first><last>Yan</last></author>
      <author><first>Guohai</first><last>Xu</last></author>
      <author><first>Chenliang</first><last>Li</last></author>
      <author><first>Junfeng</first><last>Tian</last></author>
      <author><first>Qi</first><last>Qian</last></author>
      <author><first>Ji</first><last>Zhang</last></author>
      <author><first>Qin</first><last>Jin</last></author>
      <author><first>Liang</first><last>He</last></author>
      <author><first>Xin</first><last>Lin</last></author>
      <author><first>Fei</first><last>Huang</last></author>
      <pages>2841-2858</pages>
      <abstract>Text is ubiquitous in our visual world, conveying crucial information, such as in documents, websites, and everyday photographs. In this work, we propose UReader, a first exploration of universal OCR-free visually-situated language understanding based on the Multimodal Large Language Model (MLLM). By leveraging the shallow text recognition ability of the MLLM, we only finetuned 1.2% parameters and the training cost is much lower than previous work following domain-specific pretraining and finetuning paradigms. Concretely, UReader is jointly finetuned on a wide range of Visually-situated Language Understanding tasks via a unified instruction format. To enhance the visual text and semantic understanding, we further apply two auxiliary tasks with the same format, namely text reading and key points generation tasks. We design a shape-adaptive cropping module before the encoder-decoder architecture of MLLM to leverage the frozen low-resolution vision encoder for processing high-resolution images. Without downstream finetuning, our single model achieves state-of-the-art ocr-free performance in 8 out of 10 visually-situated language understanding tasks, across 5 domains: documents, tables, charts, natural images, and webpage screenshots. Codes and instruction-tuning datasets will be released.</abstract>
      <url hash="961f135e">2023.findings-emnlp.187</url>
      <bibkey>ye-etal-2023-ureader</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.187</doi>
    </paper>
    <paper id="188">
      <title>Loose lips sink ships: Mitigating Length Bias in Reinforcement Learning from Human Feedback</title>
      <author><first>Wei</first><last>Shen</last></author>
      <author><first>Rui</first><last>Zheng</last></author>
      <author><first>Wenyu</first><last>Zhan</last></author>
      <author><first>Jun</first><last>Zhao</last></author>
      <author><first>Shihan</first><last>Dou</last></author>
      <author><first>Tao</first><last>Gui</last></author>
      <author><first>Qi</first><last>Zhang</last></author>
      <author><first>Xuanjing</first><last>Huang</last></author>
      <pages>2859-2873</pages>
      <abstract>Reinforcement learning from human feedback serves as a crucial bridge, aligning large language models with human and societal values. This alignment requires a vast corpus of human feedback to learn a reward model, which is subsequently used to finetune language models. However, we have identified that the reward model often finds shortcuts to bypass its intended objectives, misleadingly assuming that humans prefer longer responses. The emergence of length bias often induces the model to favor longer outputs, yet it doesn’t equate to an increase in helpful information within these outputs. In this paper, we propose an innovative solution, applying the Product-of-Experts (PoE) technique to separate reward modeling from the influence of sequence length. In our framework, the main expert concentrates on understanding human intents, while the biased expert targets the identification and capture of length bias. To further enhance the learning of bias, we introduce perturbations into the bias-focused expert, disrupting the flow of semantic information. Experimental results validate the effectiveness of our approach, indicating that language model performance is improved, irrespective of sequence length.</abstract>
      <url hash="bb09e889">2023.findings-emnlp.188</url>
      <bibkey>shen-etal-2023-loose</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.188</doi>
    </paper>
    <paper id="189">
      <title>Filling the Image Information Gap for <fixed-case>VQA</fixed-case>: Prompting Large Language Models to Proactively Ask Questions</title>
      <author><first>Ziyue</first><last>Wang</last></author>
      <author><first>Chi</first><last>Chen</last></author>
      <author><first>Peng</first><last>Li</last></author>
      <author id="yang-liu"><first>Yang</first><last>Liu</last></author>
      <pages>2874-2890</pages>
      <abstract>Large Language Models (LLMs) demonstrate impressive reasoning ability and the maintenance of world knowledge not only in natural language tasks, but also in some vision-language tasks such as open-domain knowledge-based visual question answering (OK-VQA). As images are invisible to LLMs, researchers convert images to text to engage LLMs into the visual question reasoning procedure. This leads to discrepancies between images and their textual representations presented to LLMs, which consequently impedes final reasoning performance. To fill the information gap and better leverage the reasoning capability, we design a framework that enables LLMs to proactively ask relevant questions to unveil more details in the image, along with filters for refining the generated information. We validate our idea on OK-VQA and A-OKVQA. Our method continuously boosts the performance of baselines methods by an average gain of 2.15% on OK-VQA, and achieves consistent improvements across different LLMs.</abstract>
      <url hash="f0158b42">2023.findings-emnlp.189</url>
      <bibkey>wang-etal-2023-filling</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.189</doi>
    </paper>
    <paper id="190">
      <title>Take a Closer Look at Multilinguality! Improve Multilingual Pre-Training Using Monolingual Corpora Only</title>
      <author><first>Jinliang</first><last>Lu</last></author>
      <author><first>Yu</first><last>Lu</last></author>
      <author><first>Jiajun</first><last>Zhang</last></author>
      <pages>2891-2907</pages>
      <abstract>Recent studies have revealed the remarkable cross-lingual capability of multilingual pre-trained language models (mPLMs), even when pre-trained without parallel corpora (mono-mPLMs). Intuitively, semantic alignments may be the reason behind such capability but remain under-explored. In this work, we investigate the alignment properties from the token perspective in mono-mPLMs and find that the alignments correspond to the geometric similarity of embedding space across different languages. Nevertheless, mono-mPLMs tend to damage this geometric similarity at the higher layers due to the lack of cross-lingual interactions, thus limiting their cross-lingual transfer capabilities. To address this issue, we introduce token-level and semantic-level code-switched masked language modeling, employing the self-induced token alignments to explicitly improve cross-lingual interactions over layers of mono-mPLMs without relying on parallel sentences. We evaluate our method on various natural language understanding tasks and unsupervised machine translation tasks. The results demonstrate that our methods outperform the strong baselines and achieve comparable performance with mPLMs trained with parallel corpora.</abstract>
      <url hash="352853ef">2023.findings-emnlp.190</url>
      <bibkey>lu-etal-2023-take</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.190</doi>
    </paper>
    <paper id="191">
      <title><fixed-case>L</fixed-case>ogi<fixed-case>C</fixed-case>o<fixed-case>T</fixed-case>: Logical Chain-of-Thought Instruction Tuning</title>
      <author><first>Hanmeng</first><last>Liu</last></author>
      <author><first>Zhiyang</first><last>Teng</last></author>
      <author><first>Leyang</first><last>Cui</last></author>
      <author><first>Chaoli</first><last>Zhang</last></author>
      <author><first>Qiji</first><last>Zhou</last></author>
      <author><first>Yue</first><last>Zhang</last></author>
      <pages>2908-2921</pages>
      <abstract>Generative Pre-trained Transformer 4 (GPT-4) demonstrates impressive chain-of-thought reasoning ability. Recent work on self-instruction tuning, such as Alpaca, has focused on enhancing the general proficiency of models. These instructions enable the model to achieve performance comparable to GPT-3.5 on general tasks like open-domain text generation and paraphrasing. However, they fall short of helping the model handle complex reasoning tasks. To bridge the gap, this paper presents LogiCoT, a new instruction-tuning dataset for Logical Chain-of-Thought reasoning with GPT-4. We elaborate on the process of harvesting instructions for prompting GPT-4 to generate chain-of-thought rationales. LogiCoT serves as an instruction set for teaching models of logical reasoning and elicits general reasoning skills.</abstract>
      <url hash="f9377362">2023.findings-emnlp.191</url>
      <bibkey>liu-etal-2023-logicot</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.191</doi>
    </paper>
    <paper id="192">
      <title>Hiding in Plain Sight: Tweets with Hate Speech Masked by Homoglyphs</title>
      <author><first>Portia</first><last>Cooper</last></author>
      <author><first>Mihai</first><last>Surdeanu</last></author>
      <author><first>Eduardo</first><last>Blanco</last></author>
      <pages>2922-2929</pages>
      <abstract>To avoid detection by current NLP monitoring applications, progenitors of hate speech often replace one or more letters in offensive words with homoglyphs, visually similar Unicode characters. Harvesting real-world hate speech containing homoglyphs is challenging due to the vast replacement possibilities. We developed a character substitution scraping method and assembled the Offensive Tweets with Homoglyphs (OTH) Dataset (N=90,788) with more than 1.5 million occurrences of 1,281 non-Latin characters (emojis excluded). In an annotated sample (n=700), 40.14% of the tweets were found to contain hate speech. We assessed the performance of seven transformer-based hate speech detection models and found that they performed poorly in a zero-shot setting (F1 scores between 0.04 and 0.52) but normalizing the data dramatically improved detection (F1 scores between 0.59 and 0.71). Training the models using the annotated data further boosted performance (highest micro-averaged F1 score=0.88, using five-fold cross validation). This study indicates that a dataset containing homoglyphs known and unknown to the scraping script can be collected, and that neural models can be trained to recognize camouflaged real-world hate speech.</abstract>
      <url hash="81f0eb9c">2023.findings-emnlp.192</url>
      <bibkey>cooper-etal-2023-hiding</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.192</doi>
    </paper>
    <paper id="193">
      <title>Reducing Spurious Correlations in Aspect-based Sentiment Analysis with Explanation from Large Language Models</title>
      <author><first>Qianlong</first><last>Wang</last></author>
      <author><first>Keyang</first><last>Ding</last></author>
      <author><first>Bin</first><last>Liang</last></author>
      <author><first>Min</first><last>Yang</last></author>
      <author><first>Ruifeng</first><last>Xu</last></author>
      <pages>2930-2941</pages>
      <abstract>Recently, aspect-based sentiment analysis (ABSA) models have yielded promising results. However, they are susceptible to learning spurious correlations between certain words of the input text and output labels while modeling the sentiment feature of the aspect. This spurious correlation will potentially undermine the performance of ABSA models. One direct solution for this problem is to make the model see and learn an explanation of sentiment expression rather than certain words. Motivated by this, we exploit explanations for the sentiment polarity of each aspect from large language models (LLMs) to reduce spurious correlations in ABSA. First, we formulate a prompt template that wraps the sentence, an aspect, and the sentiment label. This template is utilized to prompt LLMs to generate an appropriate explanation that states the sentiment cause. Then, we propose two straightforward yet effective methods to leverage the explanation for preventing the learning of spurious correlations. We conducted extensive comparative experiments on five datasets by integrating them with some representative ABSA models. Results show that our methods can achieve performance gains and enhance the performance and generalization ability of ABSA models.</abstract>
      <url hash="b72f1640">2023.findings-emnlp.193</url>
      <bibkey>wang-etal-2023-reducing</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.193</doi>
    </paper>
    <paper id="194">
      <title>High-quality argumentative information in low resources approaches improve counter-narrative generation</title>
      <author><first>Damián</first><last>Furman</last></author>
      <author><first>Pablo</first><last>Torres</last></author>
      <author><first>José</first><last>Rodríguez</last></author>
      <author><first>Diego</first><last>Letzen</last></author>
      <author><first>Maria</first><last>Martinez</last></author>
      <author><first>Laura</first><last>Alemany</last></author>
      <pages>2942-2956</pages>
      <abstract>It has been shown that high quality fine-tuning boosts the performance of language models, even if the size of the fine-tuning is small. In this work we show how highly targeted fine-tuning improves the task of hate speech counter-narrative generation in user-generated text, even for very small sizes of training (1722 counter-narratives for English and 355 for Spanish). Providing a small subset of examples focusing on single argumentative strategies, together with the argumentative analysis relevant to that strategy, yields counter-narratives that are as satisfactory as providing the whole set of counter-narratives. We also show that a good base model is required for the fine-tuning to have a positive impact. Indeed, for Spanish, the counter-narratives obtained without fine-tuning are mostly unacceptable, and, while fine-tuning improves their overall quality, the performance still remains quite unsatisfactory.</abstract>
      <url hash="6c4f0750">2023.findings-emnlp.194</url>
      <bibkey>furman-etal-2023-high</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.194</doi>
    </paper>
    <paper id="195">
      <title>A Reference-free Segmentation Quality Index (<fixed-case>S</fixed-case>eg<fixed-case>R</fixed-case>e<fixed-case>F</fixed-case>ree)</title>
      <author><first>Evan</first><last>Lucas</last></author>
      <author><first>Dylan</first><last>Kangas</last></author>
      <author><first>Timothy</first><last>Havens</last></author>
      <pages>2957-2968</pages>
      <abstract>Topic segmentation, in the context of natural language processing, is the process of finding boundaries in a sequence of sentences that separate groups of adjacent sentences at shifts in semantic meaning. Currently, assessing the quality of a segmentation is done by comparing segmentation boundaries selected by a human or algorithm to those selected by a known good reference. This means that it is not possible to quantify the quality of a segmentation without a human annotator, which can be costly and time consuming. This work seeks to improve assessment of segmentation by proposing a reference-free segmentation quality index (SegReFree). The metric takes advantage of the fact that segmentation at a sentence level generally seeks to identify segment boundaries at semantic boundaries within the text. The proposed metric uses a modified cluster validity metric with semantic embeddings of the sentences to determine the quality of the segmentation. Multiple segmentation data sets are used to compare our proposed metric with existing reference-based segmentation metrics by progressively degrading the reference segmentation while computing all possible metrics; through this process, a strong correlation with existing segmentation metrics is shown. A Python library implementing the metric is released under the GNU General Public License and the repository is available at <url>https://github.com/evan-person/reference_free_segmentation_metric</url>.</abstract>
      <url hash="f20bcf6e">2023.findings-emnlp.195</url>
      <bibkey>lucas-etal-2023-reference</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.195</doi>
    </paper>
    <paper id="196">
      <title>In-context Learning for Few-shot Multimodal Named Entity Recognition</title>
      <author><first>Chenran</first><last>Cai</last></author>
      <author><first>Qianlong</first><last>Wang</last></author>
      <author><first>Bin</first><last>Liang</last></author>
      <author><first>Bing</first><last>Qin</last></author>
      <author><first>Min</first><last>Yang</last></author>
      <author><first>Kam-Fai</first><last>Wong</last></author>
      <author><first>Ruifeng</first><last>Xu</last></author>
      <pages>2969-2979</pages>
      <abstract>Thanks in part to the availability of copious annotated resources for some entity categories, existing studies have achieved superior performance in multimodal named entity recognition (MNER). However, in the real-world scenario, it is infeasible to enumerate all entity categories in advance. Therefore, in this paper, we formulate a new few-shot multimodal named entity recognition (FewMNER) task, which aims to effectively locate and identify named entities for a text-image pair only using a small number of labeled examples. Further, we explore the merit of in-context learning (ICL) and propose a novel framework to deal with FewMNER, where three points are taken into account: i.e., converting visual modality, selecting useful examples, and designing an effective task demonstration. Specifically, we first employ an image caption model to convert images into textual descriptions, enabling large language models to absorb information from visual modality. Then, we use the ranking of the sum of similarity rankings from both text and image modalities to select k-nearest examples, which form a demonstration context. Finally, we utilize the MNER definition and the meaning of each entity category as effective instruction. Extensive experimental results demonstrate that our framework outperforms baselines under several few-shot settings.</abstract>
      <url hash="6446202d">2023.findings-emnlp.196</url>
      <bibkey>cai-etal-2023-context</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.196</doi>
    </paper>
    <paper id="197">
      <title>On Uncertainty Calibration and Selective Generation in Probabilistic Neural Summarization: A Benchmark Study</title>
      <author><first>Polina</first><last>Zablotskaia</last></author>
      <author><first>Du</first><last>Phan</last></author>
      <author><first>Joshua</first><last>Maynez</last></author>
      <author><first>Shashi</first><last>Narayan</last></author>
      <author><first>Jie</first><last>Ren</last></author>
      <author><first>Jeremiah</first><last>Liu</last></author>
      <pages>2980-2992</pages>
      <abstract>Modern deep models for summarization attains impressive benchmark performance, but they are prone to generating miscalibrated predictive uncertainty. This means that they assign high confidence to low-quality predictions, leading to compromised reliability and trustworthiness in real-world applications. Probabilistic deep learning methods are common solutions to the miscalibration problem. However, their relative effectiveness in complex autoregressive summarization tasks are not well-understood. In this work, we thoroughly investigate different state-of-the-art probabilistic methods’ effectiveness in improving the uncertainty quality of the neural summarization models, across three large-scale benchmarks with varying difficulty using our newly introduced evaluation protocol. We show that the probabilistic methods consistently improve the model’s generation and uncertainty quality, leading to improved selective generation performance (i.e., abstaining from low-quality summaries) in practice. We also reveal notable failure patterns of probabilistic methods widely-adopted in NLP community (e.g., Deep Ensemble and Monte Carlo Dropout), cautioning the importance of choosing appropriate method for the data setting.</abstract>
      <url hash="c1721258">2023.findings-emnlp.197</url>
      <bibkey>zablotskaia-etal-2023-uncertainty</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.197</doi>
    </paper>
    <paper id="198">
      <title>Handshape-Aware Sign Language Recognition: Extended Datasets and Exploration of Handshape-Inclusive Methods</title>
      <author><first>Xuan</first><last>Zhang</last></author>
      <author><first>Kevin</first><last>Duh</last></author>
      <pages>2993-3002</pages>
      <abstract>The majority of existing work on sign language recognition encodes signed videos without explicitly acknowledging the phonological attributes of signs. Given that handshape is a vital parameter in sign languages, we explore the potential of handshape-aware sign language recognition. We augment the PHOENIX14T dataset with gloss-level handshape labels, resulting in the new PHOENIX14T-HS dataset. Two unique methods are proposed for handshape-inclusive sign language recognition: a single-encoder network and a dual-encoder network, complemented by a training strategy that simultaneously optimizes both the CTC loss and frame-level cross-entropy loss. The proposed methodology consistently outperforms the baseline performance. The dataset and code can be accessed at: www.anonymous.com.</abstract>
      <url hash="f8495bf1">2023.findings-emnlp.198</url>
      <bibkey>zhang-duh-2023-handshape</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.198</doi>
    </paper>
    <paper id="199">
      <title><fixed-case>S</fixed-case>im<fixed-case>CKP</fixed-case>: Simple Contrastive Learning of Keyphrase Representations</title>
      <author><first>Minseok</first><last>Choi</last></author>
      <author><first>Chaeheon</first><last>Gwak</last></author>
      <author><first>Seho</first><last>Kim</last></author>
      <author><first>Si</first><last>Kim</last></author>
      <author><first>Jaegul</first><last>Choo</last></author>
      <pages>3003-3015</pages>
      <abstract>Keyphrase generation (KG) aims to generate a set of summarizing words or phrases given a source document, while keyphrase extraction (KE) aims to identify them from the text. Because the search space is much smaller in KE, it is often combined with KG to predict keyphrases that may or may not exist in the corresponding document. However, current unified approaches adopt sequence labeling and maximization-based generation that primarily operate at a token level, falling short in observing and scoring keyphrases as a whole. In this work, we propose SimCKP, a simple contrastive learning framework that consists of two stages: 1) An extractor-generator that extracts keyphrases by learning context-aware phrase-level representations in a contrastive manner while also generating keyphrases that do not appear in the document; 2) A reranker that adapts scores for each generated phrase by likewise aligning their representations with the corresponding document. Experimental results on multiple benchmark datasets demonstrate the effectiveness of our proposed approach, which outperforms the state-of-the-art models by a significant margin.</abstract>
      <url hash="557ffcf4">2023.findings-emnlp.199</url>
      <bibkey>choi-etal-2023-simckp</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.199</doi>
    </paper>
    <paper id="200">
      <title><fixed-case>LEXTREME</fixed-case>: A Multi-Lingual and Multi-Task Benchmark for the Legal Domain</title>
      <author><first>Joel</first><last>Niklaus</last></author>
      <author><first>Veton</first><last>Matoshi</last></author>
      <author><first>Pooja</first><last>Rani</last></author>
      <author><first>Andrea</first><last>Galassi</last></author>
      <author><first>Matthias</first><last>Stürmer</last></author>
      <author><first>Ilias</first><last>Chalkidis</last></author>
      <pages>3016-3054</pages>
      <abstract>Lately, propelled by phenomenal advances around the transformer architecture, the legal NLP field has enjoyed spectacular growth. To measure progress, well-curated and challenging benchmarks are crucial. Previous efforts have produced numerous benchmarks for general NLP models, typically based on news or Wikipedia. However, these may not fit specific domains such as law, with its unique lexicons and intricate sentence structures. Even though there is a rising need to build NLP systems for languages other than English, many benchmarks are available only in English and no multilingual benchmark exists in the legal NLP field. We survey the legal NLP literature and select 11 datasets covering 24 languages, creating LEXTREME. To fairly compare models, we propose two aggregate scores, i.e., dataset aggregate score and language aggregate score. Our results show that even the best baseline only achieves modest results, and also ChatGPT struggles with many tasks. This indicates that LEXTREME remains a challenging task with ample room for improvement. To facilitate easy use for researchers and practitioners, we release LEXTREME on huggingface along with a public leaderboard and the necessary code to evaluate models. We also provide a public Weights and Biases project containing all runs for transparency.</abstract>
      <url hash="bd55d0dd">2023.findings-emnlp.200</url>
      <bibkey>niklaus-etal-2023-lextreme</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.200</doi>
    </paper>
    <paper id="201">
      <title>Three Questions Concerning the Use of Large Language Models to Facilitate Mathematics Learning</title>
      <author><first>An-Zi</first><last>Yen</last></author>
      <author><first>Wei-Ling</first><last>Hsu</last></author>
      <pages>3055-3069</pages>
      <abstract>Due to the remarkable language understanding and generation abilities of large language models (LLMs), their use in educational applications has been explored. However, little work has been done on investigating the pedagogical ability of LLMs in helping students to learn mathematics. In this position paper, we discuss the challenges associated with employing LLMs to enhance students’ mathematical problem-solving skills by providing adaptive feedback. Apart from generating the wrong reasoning processes, LLMs can misinterpret the meaning of the question, and also exhibit difficulty in understanding the given questions’ rationales when attempting to correct students’ answers. Three research questions are formulated.</abstract>
      <url hash="8828542f">2023.findings-emnlp.201</url>
      <bibkey>yen-hsu-2023-three</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.201</doi>
    </paper>
    <paper id="202">
      <title>Simultaneous Machine Translation with Tailored Reference</title>
      <author><first>Shoutao</first><last>Guo</last></author>
      <author><first>Shaolei</first><last>Zhang</last></author>
      <author><first>Yang</first><last>Feng</last></author>
      <pages>3070-3084</pages>
      <abstract>Simultaneous machine translation (SiMT) generates translation while reading the whole source sentence. However, existing SiMT models are typically trained using the same reference disregarding the varying amounts of available source information at different latency. Training the model with ground-truth at low latency may introduce forced anticipations, whereas utilizing reference consistent with the source word order at high latency results in performance degradation. Consequently, it is crucial to train the SiMT model with appropriate reference that avoids forced anticipations during training while maintaining high quality. In this paper, we propose a novel method that provides tailored reference for the SiMT models trained at different latency by rephrasing the ground-truth. Specifically, we introduce the tailor, induced by reinforcement learning, to modify ground-truth to the tailored reference. The SiMT model is trained with the tailored reference and jointly optimized with the tailor to enhance performance. Importantly, our method is applicable to a wide range of current SiMT approaches. Experiments on three translation tasks demonstrate that our method achieves state-of-the-art performance in both fixed and adaptive policies.</abstract>
      <url hash="8a1339da">2023.findings-emnlp.202</url>
      <bibkey>guo-etal-2023-simultaneous</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.202</doi>
    </paper>
    <paper id="203">
      <title>Dynamic Voting for Efficient Reasoning in Large Language Models</title>
      <author><first>Mingfeng</first><last>Xue</last></author>
      <author><first>Dayiheng</first><last>Liu</last></author>
      <author><first>Wenqiang</first><last>Lei</last></author>
      <author><first>Xingzhang</first><last>Ren</last></author>
      <author><first>Baosong</first><last>Yang</last></author>
      <author><first>Jun</first><last>Xie</last></author>
      <author><first>Yidan</first><last>Zhang</last></author>
      <author><first>Dezhong</first><last>Peng</last></author>
      <author><first>Jiancheng</first><last>Lv</last></author>
      <pages>3085-3104</pages>
      <abstract>Multi-path voting methods like Self-consistency have been used to mitigate reasoning errors in large language models caused by factual errors and illusion generation. However, these methods require excessive computing resources as they generate numerous reasoning paths for each problem. And our experiments show that on the arithmetic reasoning task, SVAMP, half of the problems fail to obtain noticeable accuracy gains when voting with more than three paths. In this paper, we propose a novel multi-path voting technique called Dynamic Voting, which effectively reduces the number of reasoning paths during multi-path voting while preserving accuracies by applying early exiting for problems that large language models can confidently solve. Experimental evaluations on arithmetic, commonsense, and symbolic reasoning tasks under few-shot and zero-shot settings demonstrate that Dynamic Voting achieves comparable accuracies employing significantly fewer reasoning paths. Notably, one of our Dynamic Voting strategies outperforms Self-consistency using only 24.7% of the number of paths on the LetterConcat task in the few-shot setting. Furthermore, Dynamic Voting showcases strong robustness in threshold selection. It also demonstrates excellent generalizability when combined with other voting techniques, different models, and diverse prompts.</abstract>
      <url hash="9d48d70a">2023.findings-emnlp.203</url>
      <bibkey>xue-etal-2023-dynamic</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.203</doi>
    </paper>
    <paper id="204">
      <title>On Surgical Fine-tuning for Language Encoders</title>
      <author><first>Abhilasha</first><last>Lodha</last></author>
      <author><first>Gayatri</first><last>Belapurkar</last></author>
      <author><first>Saloni</first><last>Chalkapurkar</last></author>
      <author><first>Yuanming</first><last>Tao</last></author>
      <author><first>Reshmi</first><last>Ghosh</last></author>
      <author><first>Samyadeep</first><last>Basu</last></author>
      <author><first>Dmitrii</first><last>Petrov</last></author>
      <author><first>Soundararajan</first><last>Srinivasan</last></author>
      <pages>3105-3113</pages>
      <abstract>Fine-tuning all the layers of a pre-trained neural language encoder (either using all the parameters or using parameter-efficient methods) is often the de-facto way of adapting it to a new task. We show evidence that for different downstream language tasks, fine-tuning only a subset of layers is sufficient to obtain performance that is close to and often better than fine-tuning all the layers in the language encoder. We propose an efficient metric based on the diagonal of the Fisher information matrix (FIM score), to select the candidate layers for selective fine-tuning. We show, empirically on GLUE and SuperGLUE tasks and across distinct language encoders, that this metric can effectively select layers leading to a strong downstream performance. Our work highlights that task-specific information corresponding to a given downstream task is often localized within a few layers, and tuning only those is sufficient for strong performance. Additionally, we demonstrate the robustness of the FIM score to rank layers in a manner that remains constant during the optimization process.</abstract>
      <url hash="53a7f06d">2023.findings-emnlp.204</url>
      <bibkey>lodha-etal-2023-surgical</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.204</doi>
    </paper>
    <paper id="205">
      <title><fixed-case>A</fixed-case>uto<fixed-case>P</fixed-case>lan: Automatic Planning of Interactive Decision-Making Tasks With Large Language Models</title>
      <author><first>Siqi</first><last>Ouyang</last></author>
      <author><first>Lei</first><last>Li</last></author>
      <pages>3114-3128</pages>
      <abstract>Recent large language models (LLMs) are promising for making decisions in grounded environments. However, LLMs frequently fail in complex decision-making tasks due to the misalignment between the pre-trained knowledge in LLMs and the actual rules in the environment. Existing methods require either costly gradient computation or lengthy in-context demonstrations. In this paper, we propose AutoPlan, an approach to guide LLM-based agents to accomplish interactive decision-making tasks. AutoPlan augments the LLM prompt with a task-solving plan and optimizes it through iterative experience collection and reflection. Our experiments show that AutoPlan, though using no in-context demonstrations, achieves success rates on par with the baselines using human-written demonstrations on ALFWorld and even outperforms them by 8% on HotpotQA. The code is available at https://github.com/owaski/AutoPlan.</abstract>
      <url hash="f0682f9d">2023.findings-emnlp.205</url>
      <bibkey>ouyang-li-2023-autoplan</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.205</doi>
    </paper>
    <paper id="206">
      <title>Measuring Faithful and Plausible Visual Grounding in <fixed-case>VQA</fixed-case></title>
      <author><first>Daniel</first><last>Reich</last></author>
      <author><first>Felix</first><last>Putze</last></author>
      <author><first>Tanja</first><last>Schultz</last></author>
      <pages>3129-3144</pages>
      <abstract>Metrics for Visual Grounding (VG) in Visual Question Answering (VQA) systems primarily aim to measure a system’s reliance on relevant parts of the image when inferring an answer to the given question. Lack of VG has been a common problem among state-of-the-art VQA systems and can manifest in over-reliance on irrelevant image parts or a disregard for the visual modality entirely. Although inference capabilities of VQA models are often illustrated by a few qualitative illustrations, most systems are not quantitatively assessed for their VG properties. We believe, an easily calculated criterion for meaningfully measuring a system’s VG can help remedy this shortcoming, as well as add another valuable dimension to model evaluations and analysis. To this end, we propose a new VG metric that captures if a model a) identifies question-relevant objects in the scene, and b) actually relies on the information contained in the relevant objects when producing its answer, i.e., if its visual grounding is both “faithful” and “plausible”. Our metric, called Faithful &amp; Plausible Visual Grounding (FPVG), is straightforward to determine for most VQA model designs. We give a detailed description of FPVG and evaluate several reference systems spanning various VQA architectures. Code to support the metric calculations on the GQA data set is available on GitHub.</abstract>
      <url hash="a21b7af9">2023.findings-emnlp.206</url>
      <bibkey>reich-etal-2023-measuring</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.206</doi>
    </paper>
    <paper id="207">
      <title>Improving Zero-shot Reader by Reducing Distractions from Irrelevant Documents in Open-Domain Question Answering</title>
      <author><first>Sukmin</first><last>Cho</last></author>
      <author><first>Jeongyeon</first><last>Seo</last></author>
      <author><first>Soyeong</first><last>Jeong</last></author>
      <author><first>Jong</first><last>Park</last></author>
      <pages>3145-3157</pages>
      <abstract>Large language models (LLMs) enable zero-shot approaches in open-domain question answering (ODQA), yet with limited advancements as the reader is compared to the retriever. This study aims at the feasibility of a zero-shot reader that addresses the challenges of computational cost and the need for labeled data. We find that LLMs are distracted due to irrelevant documents in the retrieved set and the overconfidence of the generated answers when they are exploited as zero-shot readers. To tackle these problems, we mitigate the impact of such documents via Distraction-aware Answer Selection (DAS) with a negation-based instruction and score adjustment for proper answer selection. Experimental results show that our approach successfully handles distraction across diverse scenarios, enhancing the performance of zero-shot readers. Furthermore, unlike supervised readers struggling with unseen data, zero-shot readers demonstrate outstanding transferability without any training.</abstract>
      <url hash="af8f3281">2023.findings-emnlp.207</url>
      <bibkey>cho-etal-2023-improving</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.207</doi>
    </paper>
    <paper id="208">
      <title>Can you Summarize my learnings? Towards Perspective-based Educational Dialogue Summarization</title>
      <author><first>Raghav</first><last>Jain</last></author>
      <author><first>Tulika</first><last>Saha</last></author>
      <author><first>Jhagrut</first><last>Lalwani</last></author>
      <author><first>Sriparna</first><last>Saha</last></author>
      <pages>3158-3173</pages>
      <abstract>The steady increase in the utilization of Virtual Tutors (VT) over recent years has allowed for a more efficient, personalized, and interactive AI-based learning experiences. A vital aspect in these educational chatbots is summarizing the conversations between the VT and the students, as it is critical in consolidating learning points and monitoring progress. However, the approach to summarization should be tailored according to the perspective. Summarization from the VTs perspective should emphasize on its teaching efficiency and potential improvements. Conversely, student-oriented summaries should distill learning points, track progress, and suggest scope for improvements. Based on this hypothesis, in this work, we propose a new task of Multi-modal Perspective based Dialogue Summarization (MM-PerSumm), demonstrated in an educational setting. Towards this aim, we introduce a novel dataset, CIMA-Summ that summarizes educational dialogues from three unique perspectives: the Student, the Tutor, and a Generic viewpoint. In addition, we propose an Image and Perspective-guided Dialogue Summarization (IP-Summ) model which is a Seq2Seq language model incorporating (i) multi-modal learning from images and (ii) a perspective-based encoder that constructs a dialogue graph capturing the intentions and actions of both the VT and the student, enabling the summarization of a dialogue from diverse perspectives. Lastly, we conduct detailed analyses of our model’s performance, highlighting the aspects that could lead to optimal modeling of IP-Summ.</abstract>
      <url hash="a59f88b8">2023.findings-emnlp.208</url>
      <bibkey>jain-etal-2023-summarize</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.208</doi>
    </paper>
    <paper id="209">
      <title>Adaptive Textual Label Noise Learning based on Pre-trained Models</title>
      <author><first>Shaohuan</first><last>Cheng</last></author>
      <author><first>Wenyu</first><last>Chen</last></author>
      <author><first>Fu</first><last>Mingsheng</last></author>
      <author><first>Xuanting</first><last>Xie</last></author>
      <author><first>Hong</first><last>Qu</last></author>
      <pages>3174-3188</pages>
      <abstract>The label noise in real-world scenarios is unpredictable and can even be a mixture of different types of noise. To meet this challenge, we develop an adaptive textual label noise learning framework based on pre-trained models, which consists of an adaptive warm-up stage and a hybrid training stage. Specifically, an early stopping method, relying solely on the training set, is designed to dynamically terminate the warm-up process based on the model’s fit level to different noise scenarios. The hybrid training stage incorporates several generalization strategies to gradually correct mislabeled instances, thereby making better use of noisy data. Experiments on multiple datasets demonstrate that our approach performs comparably or even surpasses the state-of-the-art methods in various noise scenarios, including scenarios with the mixture of multiple types of noise.</abstract>
      <url hash="36cafcd1">2023.findings-emnlp.209</url>
      <bibkey>cheng-etal-2023-adaptive</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.209</doi>
    </paper>
    <paper id="210">
      <title>Towards Informative Open-ended Text Generation with Dynamic Knowledge Triples</title>
      <author><first>Zixuan</first><last>Ren</last></author>
      <author><first>Yang</first><last>Zhao</last></author>
      <author><first>Chengqing</first><last>Zong</last></author>
      <pages>3189-3203</pages>
      <abstract>Pretrained language models (PLMs), especially large language models (LLMs) demonstrate impressive capabilities in open-ended text generation. While our statistical results show that LLMs often suffer from over-concentrated information, where the generated texts overly focus on the given prompt and fail to provide sufficient background and detailed information as humans do. To address this issue, we propose a dynamic knowledge-guided informative open-ended text generation approach, that utilizes a knowledge graph to help the model generate more contextually related entities and detailed facts. Specifically, we first employ a local knowledge filter to extract relevant knowledge from the comprehensive knowledge graph for a given topic sentence. Then we introduce a dynamic knowledge selector to predict the entity to be mentioned in the subsequent sentence. Finally, we utilize a knowledge-enhanced text generator to produce a more informative output. To evaluate the effectiveness of our approach, we evaluate the proposed approach in two scenarios: fine-tuning for small PLMs and prompt tuning for LLMs. Experimental results show that our approach could generate more informative texts than baselines.</abstract>
      <url hash="97192a55">2023.findings-emnlp.210</url>
      <bibkey>ren-etal-2023-towards</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.210</doi>
    </paper>
    <paper id="211">
      <title>Novel Relation Detection: Discovering Unknown Relation Types via Multi-Strategy Self-Supervised Learning</title>
      <author><first>Qingbin</first><last>Liu</last></author>
      <author><first>Yin</first><last>Kung</last></author>
      <author><first>Yanchao</first><last>Hao</last></author>
      <author><first>Dianbo</first><last>Sui</last></author>
      <author><first>Siyuan</first><last>Cheng</last></author>
      <author><first>Xi</first><last>Chen</last></author>
      <author><first>Ningyu</first><last>Zhang</last></author>
      <author><first>Jiaoyan</first><last>Chen</last></author>
      <pages>3204-3214</pages>
      <abstract>Conventional approaches to relation extraction can only recognize predefined relation types. In the real world, new or out-of-scope relation types may keep challenging the deployed models. In this paper, we formalize such a challenging problem as Novel Relation Detection (NRD), which aims to discover potential new relation types based on training samples of known relations. To this end, we construct two NRD datasets and exhaustively investigate a variety of out-of-scope detection methods. We further propose an effective NRD method that utilizes multi-strategy self-supervised learning to handle the problem of shallow semantic similarity in the NRD task. Experimental results demonstrate the effectiveness of our method, which significantly outperforms previous state-of-the-art methods on both datasets.</abstract>
      <url hash="51b30f18">2023.findings-emnlp.211</url>
      <bibkey>liu-etal-2023-novel</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.211</doi>
    </paper>
    <paper id="212">
      <title>Ask Language Model to Clean Your Noisy Translation Data</title>
      <author><first>Quinten</first><last>Bolding</last></author>
      <author><first>Baohao</first><last>Liao</last></author>
      <author><first>Brandon</first><last>Denis</last></author>
      <author><first>Jun</first><last>Luo</last></author>
      <author><first>Christof</first><last>Monz</last></author>
      <pages>3215-3236</pages>
      <abstract>TTransformer models have demonstrated remarkable performance in neural machine translation (NMT). However, their vulnerability to noisy input poses a significant challenge in practical implementation, where generating clean output from noisy input is crucial. The MTNT dataset is widely used as a benchmark for evaluating the robustness of NMT models against noisy input. Nevertheless, its utility is limited due to the presence of noise in both the source and target sentences. To address this limitation, we focus on cleaning the noise from the target sentences in MTNT, making it more suitable as a benchmark for noise evaluation. Leveraging the capabilities of large language models (LLMs), we observe their impressive abilities in noise removal. For example, they can remove emojis while considering their semantic meaning. Additionally, we show that LLM can effectively rephrase slang, jargon, and profanities. The resulting datasets, called C-MTNT, exhibit significantly less noise in the target sentences while preserving the semantic integrity of the original sentences. Our human and GPT-4 evaluations also lead to a consistent conclusion that LLM performs well on this task. Lastly, experiments on C-MTNT showcased its effectiveness in evaluating the robustness of NMT models, highlighting the potential of advanced language models for data cleaning and emphasizing C-MTNT as a valuable resource.</abstract>
      <url hash="930974f0">2023.findings-emnlp.212</url>
      <bibkey>bolding-etal-2023-ask</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.212</doi>
    </paper>
    <paper id="213">
      <title>Multi-User <fixed-case>M</fixed-case>ulti<fixed-case>WOZ</fixed-case>: Task-Oriented Dialogues among Multiple Users</title>
      <author><first>Yohan</first><last>Jo</last></author>
      <author><first>Xinyan</first><last>Zhao</last></author>
      <author><first>Arijit</first><last>Biswas</last></author>
      <author><first>Nikoletta</first><last>Basiou</last></author>
      <author><first>Vincent</first><last>Auvray</last></author>
      <author><first>Nikolaos</first><last>Malandrakis</last></author>
      <author><first>Angeliki</first><last>Metallinou</last></author>
      <author><first>Alexandros</first><last>Potamianos</last></author>
      <pages>3237-3269</pages>
      <abstract>While most task-oriented dialogues assume conversations between the agent and one user at a time, dialogue systems are increasingly expected to communicate with multiple users simultaneously who make decisions collaboratively. To facilitate development of such systems, we release the Multi-User MultiWOZ dataset: task-oriented dialogues among two users and one agent. To collect this dataset, each user utterance from MultiWOZ 2.2 was replaced with a small chat between two users that is semantically and pragmatically consistent with the original user utterance, thus resulting in the same dialogue state and system response. These dialogues reflect interesting dynamics of collaborative decision-making in task-oriented scenarios, e.g., social chatter and deliberation. Supported by this data, we propose the novel task of multi-user contextual query rewriting: to rewrite a task-oriented chat between two users as a concise task-oriented query that retains only task-relevant information and that is directly consumable by the dialogue system. We demonstrate that in multi-user dialogues, using predicted rewrites substantially improves dialogue state tracking without modifying existing dialogue systems that are trained for single-user dialogues. Further, this method surpasses training a medium-sized model directly on multi-user dialogues and generalizes to unseen domains.</abstract>
      <url hash="d7e5371c">2023.findings-emnlp.213</url>
      <bibkey>jo-etal-2023-multi</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.213</doi>
    </paper>
    <paper id="214">
      <title>Extractive Summarization via <fixed-case>C</fixed-case>hat<fixed-case>GPT</fixed-case> for Faithful Summary Generation</title>
      <author><first>Haopeng</first><last>Zhang</last></author>
      <author><first>Xiao</first><last>Liu</last></author>
      <author><first>Jiawei</first><last>Zhang</last></author>
      <pages>3270-3278</pages>
      <abstract>Extractive summarization is a crucial task in natural language processing that aims to condense long documents into shorter versions by directly extracting sentences. The recent introduction of large language models has attracted significant interest in the NLP community due to its remarkable performance on a wide range of downstream tasks. This paper first presents a thorough evaluation of ChatGPT’s performance on extractive summarization and compares it with traditional fine-tuning methods on various benchmark datasets. Our experimental analysis reveals that ChatGPT exhibits inferior extractive summarization performance in terms of ROUGE scores compared to existing supervised systems, while achieving higher performance based on LLM-based evaluation metrics. In addition, we explore the effectiveness of in-context learning and chain-of-thought reasoning for enhancing its performance. Furthermore, we find that applying an extract-then-generate pipeline with ChatGPT yields significant performance improvements over abstractive baselines in terms of summary faithfulness. These observations highlight potential directions for enhancing ChatGPT’s capabilities in faithful summarization using two-stage approaches.</abstract>
      <url hash="28a915f3">2023.findings-emnlp.214</url>
      <bibkey>zhang-etal-2023-extractive-summarization</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.214</doi>
    </paper>
    <paper id="215">
      <title><fixed-case>MAPO</fixed-case>: Boosting Large Language Model Performance with Model-Adaptive Prompt Optimization</title>
      <author><first>Yuyan</first><last>Chen</last></author>
      <author><first>Zhihao</first><last>Wen</last></author>
      <author><first>Ge</first><last>Fan</last></author>
      <author><first>Zhengyu</first><last>Chen</last></author>
      <author><first>Wei</first><last>Wu</last></author>
      <author><first>Dayiheng</first><last>Liu</last></author>
      <author><first>Zhixu</first><last>Li</last></author>
      <author><first>Bang</first><last>Liu</last></author>
      <author><first>Yanghua</first><last>Xiao</last></author>
      <pages>3279-3304</pages>
      <abstract>Prompt engineering, as an efficient and effective way to leverage Large Language Models (LLM), has drawn a lot of attention from the research community. The existing research primarily emphasizes the importance of adapting prompts to specific tasks, rather than specific LLMs. However, a good prompt is not solely defined by its wording, but also binds to the nature of the LLM in question. In this work, we first quantitatively demonstrate that different prompts should be adapted to different LLMs to enhance their capabilities across various downstream tasks in NLP. Then we novelly propose a model-adaptive prompt optimizer (MAPO) method that optimizes the original prompts for each specific LLM in downstream tasks. Extensive experiments indicate that the proposed method can effectively refine prompts for an LLM, leading to significant improvements over various downstream tasks.</abstract>
      <url hash="6fe3c7b9">2023.findings-emnlp.215</url>
      <bibkey>chen-etal-2023-mapo</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.215</doi>
    </paper>
    <paper id="216">
      <title><fixed-case>P</fixed-case>sy<fixed-case>C</fixed-case>o<fixed-case>T</fixed-case>: Psychological Questionnaire as Powerful Chain-of-Thought for Personality Detection</title>
      <author><first>Tao</first><last>Yang</last></author>
      <author><first>Tianyuan</first><last>Shi</last></author>
      <author><first>Fanqi</first><last>Wan</last></author>
      <author><first>Xiaojun</first><last>Quan</last></author>
      <author><first>Qifan</first><last>Wang</last></author>
      <author><first>Bingzhe</first><last>Wu</last></author>
      <author><first>Jiaxiang</first><last>Wu</last></author>
      <pages>3305-3320</pages>
      <abstract>Recent advances in large language models (LLMs), such as ChatGPT, have showcased remarkable zero-shot performance across various NLP tasks. However, the potential of LLMs in personality detection, which involves identifying an individual’s personality from their written texts, remains largely unexplored. Drawing inspiration from Psychological Questionnaires, which are carefully designed by psychologists to evaluate individual personality traits through a series of targeted items, we argue that these items can be regarded as a collection of well-structured chain-of-thought (CoT) processes. By incorporating these processes, LLMs can enhance their capabilities to make more reasonable inferences on personality from textual input. In light of this, we propose a novel personality detection method, called PsyCoT, which mimics the way individuals complete psychological questionnaires in a multi-turn dialogue manner. In particular, we employ a LLM as an AI assistant with a specialization in text analysis. We prompt the assistant to rate individual items at each turn and leverage the historical rating results to derive a conclusive personality preference. Our experiments demonstrate that PsyCoT significantly improves the performance and robustness of GPT-3.5 in personality detection, achieving an average F1 score improvement of 4.23/10.63 points on two benchmark datasets compared to the standard prompting method. Our code is available at <url>https://github.com/TaoYang225/PsyCoT</url>.</abstract>
      <url hash="9d7b8f51">2023.findings-emnlp.216</url>
      <bibkey>yang-etal-2023-psycot</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.216</doi>
    </paper>
    <paper id="217">
      <title>Harnessing the power of <fixed-case>LLM</fixed-case>s: Evaluating human-<fixed-case>AI</fixed-case> text co-creation through the lens of news headline generation</title>
      <author><first>Zijian</first><last>Ding</last></author>
      <author><first>Alison</first><last>Smith-Renner</last></author>
      <author><first>Wenjuan</first><last>Zhang</last></author>
      <author><first>Joel</first><last>Tetreault</last></author>
      <author><first>Alejandro</first><last>Jaimes</last></author>
      <pages>3321-3339</pages>
      <abstract>To explore how humans can best leverage LLMs for writing and how interacting with these models affects feelings of ownership and trust in the writing process, we compared common human-AI interaction types (e.g., guiding system, selecting from system outputs, post-editing outputs) in the context of LLM-assisted news headline generation. While LLMs alone can generate satisfactory news headlines, on average, human control is needed to fix undesirable model outputs. Of the interaction methods, guiding and selecting model output added the most benefit with the lowest cost (in time and effort). Further, AI assistance did not harm participants’ perception of control compared to freeform editing.</abstract>
      <url hash="f74575cb">2023.findings-emnlp.217</url>
      <bibkey>ding-etal-2023-harnessing</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.217</doi>
    </paper>
    <paper id="218">
      <title><fixed-case>NER</fixed-case>etrieve: Dataset for Next Generation Named Entity Recognition and Retrieval</title>
      <author><first>Uri</first><last>Katz</last></author>
      <author><first>Matan</first><last>Vetzler</last></author>
      <author><first>Amir</first><last>Cohen</last></author>
      <author><first>Yoav</first><last>Goldberg</last></author>
      <pages>3340-3354</pages>
      <abstract>Recognizing entities in texts is a central need in many information-seeking scenarios, and indeed, Named Entity Recognition (NER) is arguably one of the most successful examples of a widely adopted NLP task and corresponding NLP technology. Recent advances in large language models (LLMs) appear to provide effective solutions (also) for NER tasks that were traditionally handled with dedicated models, often matching or surpassing the abilities of the dedicated models. Should NER be considered a solved problem? We argue to the contrary: the capabilities provided by LLMs are not the end of NER research, but rather an exciting beginning. They allow taking NER to the next level, tackling increasingly more useful, and increasingly more challenging, variants. We present three variants of the NER task, together with a dataset to support them. The first is a move towards more fine-grained—and intersectional—entity types. The second is a move towards zero-shot recognition and extraction of these fine-grained types based on entity-type labels. The third, and most challenging, is the move from the recognition setup to a novel retrieval setup, where the query is a zero-shot entity type, and the expected result is all the sentences from a large, pre-indexed corpus that contain entities of these types, and their corresponding spans. We show that all of these are far from being solved. We provide a large, silver-annotated corpus of 4 million paragraphs covering 500 entity types, to facilitate research towards all of these three goals.</abstract>
      <url hash="1dad7a1b">2023.findings-emnlp.218</url>
      <bibkey>katz-etal-2023-neretrieve</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.218</doi>
    </paper>
    <paper id="219">
      <title><fixed-case>SWEET</fixed-case> - Weakly Supervised Person Name Extraction for Fighting Human Trafficking</title>
      <author><first>Javin</first><last>Liu</last></author>
      <author><first>Hao</first><last>Yu</last></author>
      <author><first>Vidya</first><last>Sujaya</last></author>
      <author><first>Pratheeksha</first><last>Nair</last></author>
      <author><first>Kellin</first><last>Pelrine</last></author>
      <author><first>Reihaneh</first><last>Rabbany</last></author>
      <pages>3355-3367</pages>
      <abstract>In this work, we propose a weak supervision pipeline SWEET: Supervise Weakly for Entity Extraction to fight Trafficking for extracting person names from noisy escort advertisements. Our method combines the simplicity of rule-matching (through antirules, i.e., negated rules) and the generalizability of large language models fine-tuned on benchmark, domain-specific and synthetic datasets, treating them as weak labels. One of the major challenges in this domain is limited labeled data. SWEET addresses this by obtaining multiple weak labels through labeling functions and effectively aggregating them. SWEET outperforms the previous supervised SOTA method for this task by 9% F1 score on domain data and better generalizes to common benchmark datasets. Furthermore, we also release HTGEN, a synthetically generated dataset of escort advertisements (built using ChatGPT) to facilitate further research within the community.</abstract>
      <url hash="fdd4765d">2023.findings-emnlp.219</url>
      <bibkey>liu-etal-2023-sweet</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.219</doi>
    </paper>
    <paper id="220">
      <title>Watermarking <fixed-case>LLM</fixed-case>s with Weight Quantization</title>
      <author><first>Linyang</first><last>Li</last></author>
      <author><first>Botian</first><last>Jiang</last></author>
      <author><first>Pengyu</first><last>Wang</last></author>
      <author><first>Ke</first><last>Ren</last></author>
      <author><first>Hang</first><last>Yan</last></author>
      <author><first>Xipeng</first><last>Qiu</last></author>
      <pages>3368-3378</pages>
      <abstract>Abuse of large language models reveals high risks as large language models are being deployed at an astonishing speed. It is important to protect the model weights to avoid malicious usage that violates licenses of open-source large language models. This paper proposes a novel watermarking strategy that plants watermarks in the quantization process of large language models without pre-defined triggers during inference. The watermark works when the model is used in the fp32 mode and remains hidden when the model is quantized to int8, in this way, the users can only inference the model without further supervised fine-tuning of the model. We successfully plant the watermark into open-source large language model weights including GPT-Neo and LLaMA. We hope our proposed method can provide a potential direction for protecting model weights in the era of large language model applications.</abstract>
      <url hash="490df14f">2023.findings-emnlp.220</url>
      <bibkey>li-etal-2023-watermarking</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.220</doi>
    </paper>
    <paper id="221">
      <title>Disentangling Extraction and Reasoning in Multi-hop Spatial Reasoning</title>
      <author><first>Roshanak</first><last>Mirzaee</last></author>
      <author><first>Parisa</first><last>Kordjamshidi</last></author>
      <pages>3379-3397</pages>
      <abstract>Spatial reasoning over text is challenging as the models not only need to extract the direct spatial information from the text but also reason over those and infer implicit spatial relations. Recent studies highlight the struggles even large language models encounter when it comes to performing spatial reasoning over text. In this paper, we explore the potential benefits of disentangling the processes of information extraction and reasoning in models to address this challenge. To explore this, we design various models that disentangle extraction and reasoning(either symbolic or neural) and compare them with state-of-the-art(SOTA) baselines with no explicit design for these parts. Our experimental results consistently demonstrate the efficacy of disentangling, showcasing its ability to enhance models’ generalizability within realistic data domains.</abstract>
      <url hash="a41f2470">2023.findings-emnlp.221</url>
      <bibkey>mirzaee-kordjamshidi-2023-disentangling</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.221</doi>
    </paper>
    <paper id="222">
      <title><fixed-case>P</fixed-case>sy<fixed-case>A</fixed-case>ttention: Psychological Attention Model for Personality Detection</title>
      <author><first>Baohua</first><last>Zhang</last></author>
      <author><first>Yongyi</first><last>Huang</last></author>
      <author><first>Wenyao</first><last>Cui</last></author>
      <author><first>Zhang</first><last>Huaping</last></author>
      <author><first>Jianyun</first><last>Shang</last></author>
      <pages>3398-3411</pages>
      <abstract>Work on personality detection has tended to incorporate psychological features from different personality models, such as BigFive and MBTI. There are more than 900 psychological features, each of which is helpful for personality detection. However, when used in combination, the application of different calculation standards among these features may result in interference between features calculated using distinct systems, thereby introducing noise and reducing performance. This paper adapts different psychological models in the proposed PsyAttention for personality detection, which can effectively encode psychological features, reducing their number by 85%. In experiments on the BigFive and MBTI models, PysAttention achieved average accuracy of 65.66% and 86.30%, respectively, outperforming state-of-the-art methods, indicating that it is effective at encoding psychological features.</abstract>
      <url hash="0ab72d27">2023.findings-emnlp.222</url>
      <bibkey>zhang-etal-2023-psyattention</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.222</doi>
    </paper>
    <paper id="223">
      <title><fixed-case>R</fixed-case>o<fixed-case>AST</fixed-case>: Robustifying Language Models via Adversarial Perturbation with Selective Training</title>
      <author><first>Jaehyung</first><last>Kim</last></author>
      <author><first>Yuning</first><last>Mao</last></author>
      <author><first>Rui</first><last>Hou</last></author>
      <author><first>Hanchao</first><last>Yu</last></author>
      <author><first>Davis</first><last>Liang</last></author>
      <author><first>Pascale</first><last>Fung</last></author>
      <author><first>Qifan</first><last>Wang</last></author>
      <author><first>Fuli</first><last>Feng</last></author>
      <author><first>Lifu</first><last>Huang</last></author>
      <author><first>Madian</first><last>Khabsa</last></author>
      <pages>3412-3444</pages>
      <abstract>Fine-tuning pre-trained language models (LMs) has become the de facto standard in many NLP tasks. Nevertheless, fine-tuned LMs are still prone to robustness issues, such as adversarial robustness and model calibration. Several perspectives of robustness for LMs have been studied independently, but lacking a unified consideration in multiple perspectives. In this paper, we propose Robustifying LMs via Adversarial perturbation with Selective Training (RoAST), a simple yet effective fine-tuning technique to enhance the multi-perspective robustness of LMs in a unified way. RoAST effectively incorporates two important sources for the model robustness, robustness on the perturbed inputs and generalizable knowledge in pre-trained LMs. To be specific, RoAST introduces adversarial perturbation during fine-tuning while the model parameters are selectively updated upon their relative importance to minimize unnecessary deviation. Under a unified evaluation of fine-tuned LMs by incorporating four representative perspectives of model robustness, we demonstrate the effectiveness of RoAST compared to state-of-the-art fine-tuning methods on six different types of LMs, which indicates its usefulness in practice.</abstract>
      <url hash="c0129852">2023.findings-emnlp.223</url>
      <bibkey>kim-etal-2023-roast</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.223</doi>
    </paper>
    <paper id="224">
      <title>The Law and <fixed-case>NLP</fixed-case>: Bridging Disciplinary Disconnects</title>
      <author><first>Robert</first><last>Mahari</last></author>
      <author><first>Dominik</first><last>Stammbach</last></author>
      <author><first>Elliott</first><last>Ash</last></author>
      <author><first>Alex</first><last>Pentland</last></author>
      <pages>3445-3454</pages>
      <abstract>Legal practice is intrinsically rooted in the fabric of language, yet legal practitioners and scholars have been slow to adopt tools from natural language processing (NLP). At the same time, the legal system is experiencing an access to justice crisis, which could be partially alleviated with NLP. In this position paper, we argue that the slow uptake of NLP in legal practice is exacerbated by a disconnect between the needs of the legal community and the focus of NLP researchers. In a review of recent trends in the legal NLP literature, we find limited overlap between the legal NLP community and legal academia. Our interpretation is that some of the most popular legal NLP tasks fail to address the needs of legal practitioners. We discuss examples of legal NLP tasks that promise to bridge disciplinary disconnects and highlight interesting areas for legal NLP research that remain underexplored.</abstract>
      <url hash="6d2eb65f">2023.findings-emnlp.224</url>
      <bibkey>mahari-etal-2023-law</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.224</doi>
    </paper>
    <paper id="225">
      <title>Symbolization, Prompt, and Classification: A Framework for Implicit Speaker Identification in Novels</title>
      <author><first>Yue</first><last>Chen</last></author>
      <author><first>Tianwei</first><last>He</last></author>
      <author><first>Hongbin</first><last>Zhou</last></author>
      <author><first>Jia-Chen</first><last>Gu</last></author>
      <author><first>Heng</first><last>Lu</last></author>
      <author><first>Zhen-Hua</first><last>Ling</last></author>
      <pages>3455-3467</pages>
      <abstract>Speaker identification in novel dialogues can be widely applied to various downstream tasks, such as producing multi-speaker audiobooks and converting novels into scripts. However, existing state-of-the-art methods are limited to handling explicit narrative patterns like “Tom said, '...'", unable to thoroughly understand long-range contexts and to deal with complex cases. To this end, we propose a framework named SPC, which identifies implicit speakers in novels via symbolization, prompt, and classification. First, SPC symbolizes the mentions of candidate speakers to construct a unified label set. Then, by inserting a prompt we re-formulate speaker identification as a classification task to minimize the gap between the training objectives of speaker identification and the pre-training task. Two auxiliary tasks are also introduced in SPC to enhance long-range context understanding. Experimental results show that SPC outperforms previous methods by a large margin of 4.8% accuracy on the web novel collection, which reduces 47% of speaker identification errors, and also outperforms the emerging ChatGPT. In addition, SPC is more accurate in implicit speaker identification cases that require long-range context semantic understanding.</abstract>
      <url hash="6ec0e7d2">2023.findings-emnlp.225</url>
      <bibkey>chen-etal-2023-symbolization</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.225</doi>
    </paper>
    <paper id="226">
      <title>Open-Ended Instructable Embodied Agents with Memory-Augmented Large Language Models</title>
      <author><first>Gabriel</first><last>Sarch</last></author>
      <author><first>Yue</first><last>Wu</last></author>
      <author><first>Michael</first><last>Tarr</last></author>
      <author><first>Katerina</first><last>Fragkiadaki</last></author>
      <pages>3468-3500</pages>
      <abstract>Pre-trained and frozen LLMs can effectively map simple scene re-arrangement instructions to programs over a robot’s visuomotor functions through appropriate few-shot example prompting. To parse open-domain natural language and adapt to a user’s idiosyncratic procedures, not known during prompt engineering time, fixed prompts fall short. In this paper, we introduce HELPER, an embodied agent equipped with an external memory of language-program pairs that parses free-form human-robot dialogue into action programs through retrieval-augmented LLM prompting: relevant memories are retrieved based on the current dialogue, instruction, correction or VLM description, and used as in-context prompt examples for LLM querying. The memory is expanded during deployment to include pairs of user’s language and action plans, to assist future inferences and personalize them to the user’s language and routines. HELPER sets a new state-of-the-art in the TEACh benchmark in both Execution from Dialog History (EDH) and Trajectory from Dialogue (TfD), with 1.7x improvement over the previous SOTA for TfD. Our models, code and video results can be found in our project’s website: https://helper-agent-llm.github.io.</abstract>
      <url hash="d2ee979b">2023.findings-emnlp.226</url>
      <bibkey>sarch-etal-2023-open</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.226</doi>
    </paper>
    <paper id="227">
      <title><fixed-case>ACT</fixed-case>-<fixed-case>SQL</fixed-case>: In-Context Learning for Text-to-<fixed-case>SQL</fixed-case> with Automatically-Generated Chain-of-Thought</title>
      <author><first>Hanchong</first><last>Zhang</last></author>
      <author><first>Ruisheng</first><last>Cao</last></author>
      <author><first>Lu</first><last>Chen</last></author>
      <author><first>Hongshen</first><last>Xu</last></author>
      <author><first>Kai</first><last>Yu</last></author>
      <pages>3501-3532</pages>
      <abstract>Recently Large Language Models (LLMs) have been proven to have strong abilities in various domains and tasks. We study the problem of prompt designing in the text-to-SQL task and attempt to improve the LLMs’ reasoning ability when generating SQL queries. Besides the trivial few-shot in-context learning setting, we design our chain-of-thought (CoT) prompt with a similar method to schema linking. We provide a method named ACT-SQL to automatically generate auto-CoT exemplars and thus the whole process doesn’t need manual labeling. Our approach is cost-saving since we only use the LLMs’ API call once when generating one SQL query. Furthermore, we extend our in-context learning method to the multi-turn text-to-SQL task. The experiment results show that the LLMs’ performance can benefit from our ACT-SQL approach. Our approach achieves SOTA performance on the Spider dev set among existing in-context learning approaches.</abstract>
      <url hash="7b314ade">2023.findings-emnlp.227</url>
      <bibkey>zhang-etal-2023-act</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.227</doi>
    </paper>
    <paper id="228">
      <title>Manifold-Preserving Transformers are Effective for Short-Long Range Encoding</title>
      <author><first>Ayan</first><last>Sengupta</last></author>
      <author><first>Md</first><last>Akhtar</last></author>
      <author><first>Tanmoy</first><last>Chakraborty</last></author>
      <pages>3533-3549</pages>
      <abstract>Multi-head self-attention-based Transformers have shown promise in different learning tasks. Albeit these models exhibit significant improvement in understanding short-term and long-term contexts from sequences, encoders of Transformers and their variants fail to preserve layer-wise contextual information. Transformers usually project tokens onto sparse manifolds and fail to preserve mathematical equivalence among the token representations. In this work, we propose TransJect, an encoder model that guarantees a theoretical bound for layer-wise distance preservation between a pair of tokens. We propose a simple alternative to dot-product attention to ensure Lipschitz continuity. This allows TransJect to learn injective mappings to transform token representations to different manifolds with similar topology and preserve Euclidean distance between every pair of tokens in subsequent layers. Evaluations across multiple benchmark short- and long-sequence classification tasks show maximum improvements of 6.8% and 5.9%, respectively, over the variants of Transformers. Additionally, TransJect displays 79% better performance than Transformer on the language modeling task. We further highlight the shortcomings of multi-head self-attention from the statistical physics viewpoint. Although multi-head self-attention was incepted to learn different abstraction levels within the networks, our empirical analyses suggest that different attention heads learn randomly and unorderly. In contrast, TransJect adapts a mixture of experts for regularization; these experts are more orderly and balanced and learn different sparse representations from the input sequences. TransJect exhibits very low entropy and can be efficiently scaled to larger depths.</abstract>
      <url hash="0f74698d">2023.findings-emnlp.228</url>
      <bibkey>sengupta-etal-2023-manifold</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.228</doi>
    </paper>
    <paper id="229">
      <title><fixed-case>ASPIRO</fixed-case>: Any-shot Structured Parsing-error-Induced <fixed-case>R</fixed-case>epr<fixed-case>O</fixed-case>mpting for Consistent Data-to-Text Generation</title>
      <author><first>Martin</first><last>Vejvar</last></author>
      <author><first>Yasutaka</first><last>Fujimoto</last></author>
      <pages>3550-3563</pages>
      <abstract>We present ASPIRO, an approach for structured data verbalisation into short template sentences in zero to few-shot settings. Unlike previous methods, our approach prompts Large Language Models (LLMs) to directly produce entity-agnostic templates, rather than relying on LLMs to faithfully copy the given example entities, or validating/crafting the templates manually. We incorporate LLM re-prompting, triggered by algorithmic parsing checks, as well as the PARENT metric induced consistency validation to identify and rectify template generation problems in real-time. ASPIRO, compared to direct LLM output, averages 66% parsing error rate reduction in generated verbalisations of RDF triples on the DART dataset. Our best 5-shot text-davinci-003 setup, scoring BLEU of 50.62, METEOR of 45.16, BLEURT of 0.82, NUBIA of 0.87, and PARENT of 0.8962 on the Rel2Text dataset, competes effectively with recent fine-tuned pretrained language models.</abstract>
      <url hash="f02928fb">2023.findings-emnlp.229</url>
      <bibkey>vejvar-fujimoto-2023-aspiro</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.229</doi>
    </paper>
    <paper id="230">
      <title>Detecting Syntactic Change with Pre-trained Transformer Models</title>
      <author><first>Liwen</first><last>Hou</last></author>
      <author><first>David</first><last>Smith</last></author>
      <pages>3564-3574</pages>
      <abstract>We investigate the ability of Transformer-based language models to find syntactic differences between the English of the early 1800s and that of the late 1900s. First, we show that a fine-tuned BERT model can distinguish between text from these two periods using syntactic information only; to show this, we employ a strategy to hide semantic information from the text. Second, we make further use of fine-tuned BERT models to identify specific instances of syntactic change and specific words for which a new part of speech was introduced. To do this, we employ an automatic part-of-speech (POS) tagger and use it to train corpora-specific taggers based only on BERT representations pretrained on different corpora. Notably, our methods of identifying specific candidates for syntactic change avoid using any automatic POS tagger on old text, where its performance may be unreliable; instead, our methods only use untagged old text together with tagged modern text. We examine samples and distributional properties of the model output to validate automatically identified cases of syntactic change. Finally, we use our techniques to confirm the historical rise of the progressive construction, a known example of syntactic change.</abstract>
      <url hash="83d35615">2023.findings-emnlp.230</url>
      <bibkey>hou-smith-2023-detecting</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.230</doi>
    </paper>
    <paper id="231">
      <title>Can Word Sense Distribution Detect Semantic Changes of Words?</title>
      <author><first>Xiaohang</first><last>Tang</last></author>
      <author><first>Yi</first><last>Zhou</last></author>
      <author><first>Taichi</first><last>Aida</last></author>
      <author><first>Procheta</first><last>Sen</last></author>
      <author><first>Danushka</first><last>Bollegala</last></author>
      <pages>3575-3590</pages>
      <abstract>Semantic Change Detection of words is an important task for various NLP applications that must make time-sensitive predictions. Some words are used over time in novel ways to express new meanings, and these new meanings establish themselves as novel senses of existing words. On the other hand, Word Sense Disambiguation (WSD) methods associate ambiguous words with sense ids, depending on the context in which they occur. Given this relationship between WSD and SCD, we explore the possibility of predicting whether a target word has its meaning changed between two corpora collected at different time steps, by comparing the distributions of senses of that word in each corpora. For this purpose, we use pretrained static sense embeddings to automatically annotate each occurrence of the target word in a corpus with a sense id. Next, we compute the distribution of sense ids of a target word in a given corpus. Finally, we use different divergence or distance measures to quantify the semantic change of the target word across the two given corpora. Our experimental results on SemEval 2020 Task 1 dataset show that word sense distributions can be accurately used to predict semantic changes of words in English, German, Swedish and Latin.</abstract>
      <url hash="c8a532c2">2023.findings-emnlp.231</url>
      <bibkey>tang-etal-2023-word</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.231</doi>
    </paper>
    <paper id="232">
      <title>Gold: A Global and Local-aware Denoising Framework for Commonsense Knowledge Graph Noise Detection</title>
      <author><first>Zheye</first><last>Deng</last></author>
      <author><first>Weiqi</first><last>Wang</last></author>
      <author><first>Zhaowei</first><last>Wang</last></author>
      <author><first>Xin</first><last>Liu</last></author>
      <author><first>Yangqiu</first><last>Song</last></author>
      <pages>3591-3608</pages>
      <abstract>Commonsense Knowledge Graphs (CSKGs) are crucial for commonsense reasoning, yet constructing them through human annotations can be costly. As a result, various automatic methods have been proposed to construct CSKG with larger semantic coverage. However, these unsupervised approaches introduce spurious noise that can lower the quality of the resulting CSKG, which cannot be tackled easily by existing denoising algorithms due to the unique characteristics of nodes and structures in CSKGs. To address this issue, we propose Gold (Global and Local-aware Denoising), a denoising framework for CSKGs that incorporates entity semantic information, global rules, and local structural information from the CSKG. Experiment results demonstrate that Gold outperforms all baseline methods in noise detection tasks on synthetic noisy CSKG benchmarks. Furthermore, we show that denoising a real-world CSKG is effective and even benefits the downstream zero-shot commonsense question-answering task. Our code and data are publicly available at https://github.com/HKUST-KnowComp/GOLD.</abstract>
      <url hash="d1cbe942">2023.findings-emnlp.232</url>
      <bibkey>deng-etal-2023-gold</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.232</doi>
    </paper>
    <paper id="233">
      <title>Improving Conversational Recommendation Systems via Bias Analysis and Language-Model-Enhanced Data Augmentation</title>
      <author><first>Xi</first><last>Wang</last></author>
      <author><first>Hossein</first><last>Rahmani</last></author>
      <author><first>Jiqun</first><last>Liu</last></author>
      <author><first>Emine</first><last>Yilmaz</last></author>
      <pages>3609-3622</pages>
      <abstract>Conversational Recommendation System (CRS) is a rapidly growing research area that has gained significant attention alongside advancements in language modelling techniques. However, the current state of conversational recommendation faces numerous challenges due to its relative novelty and limited existing contributions. In this study, we delve into benchmark datasets for developing CRS models and address potential biases arising from the feedback loop inherent in multi-turn interactions, including selection bias and multiple popularity bias variants. Drawing inspiration from the success of generative data via using language models and data augmentation techniques, we present two novel strategies, ‘Once-Aug’ and ‘PopNudge’, to enhance model performance while mitigating biases. Through extensive experiments on ReDial and TG-ReDial benchmark datasets, we show a consistent improvement of CRS techniques with our data augmentation approaches and offer additional insights on addressing multiple newly formulated biases.</abstract>
      <url hash="ec2de9e3">2023.findings-emnlp.233</url>
      <bibkey>wang-etal-2023-improving-conversational</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.233</doi>
    </paper>
    <paper id="234">
      <title>Exploring Graph Pre-training for Aspect-based Sentiment Analysis</title>
      <author><first>Xiaoyi</first><last>Bao</last></author>
      <author><first>Zhongqing</first><last>Wang</last></author>
      <author><first>Guodong</first><last>Zhou</last></author>
      <pages>3623-3634</pages>
      <abstract>Existing studies tend to extract the sentiment elements in a generative manner in order to avoid complex modeling. Despite their effectiveness, they ignore importance of the relationships between sentiment elements that could be crucial, making the large pre-trained generative models sub-optimal for modeling sentiment knowledge. Therefore, we introduce two pre-training paradigms to improve the generation model by exploring graph pre-training that targeting to strengthen the model in capturing the elements’ relationships. Specifically, We first employ an Element-level Graph Pre-training paradigm, which is designed to improve the structure awareness of the generative model. Then, we design a Task Decomposition Pre-training paradigm to make the generative model generalizable and robust against various irregular sentiment quadruples. Extensive experiments show the superiority of our proposed method, validate the correctness of our motivation.</abstract>
      <url hash="ed263e09">2023.findings-emnlp.234</url>
      <bibkey>bao-etal-2023-exploring</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.234</doi>
    </paper>
    <paper id="235">
      <title><fixed-case>D</fixed-case>ema<fixed-case>F</fixed-case>ormer: Damped Exponential Moving Average Transformer with Energy-Based Modeling for Temporal Language Grounding</title>
      <author><first>Thong</first><last>Nguyen</last></author>
      <author><first>Xiaobao</first><last>Wu</last></author>
      <author><first>Xinshuai</first><last>Dong</last></author>
      <author><first>Cong-Duy</first><last>Nguyen</last></author>
      <author><first>See-Kiong</first><last>Ng</last></author>
      <author><first>Anh</first><last>Luu</last></author>
      <pages>3635-3649</pages>
      <abstract>Temporal Language Grounding seeks to localize video moments that semantically correspond to a natural language query. Recent advances employ the attention mechanism to learn the relations between video moments and the text query. However, naive attention might not be able to appropriately capture such relations, resulting in ineffective distributions where target video moments are difficult to separate from the remaining ones. To resolve the issue, we propose an energy-based model framework to explicitly learn moment-query distributions. Moreover, we propose DemaFormer, a novel Transformer-based architecture that utilizes exponential moving average with a learnable damping factor to effectively encode moment-query inputs. Comprehensive experiments on four public temporal language grounding datasets showcase the superiority of our methods over the state-of-the-art baselines.</abstract>
      <url hash="8a87d914">2023.findings-emnlp.235</url>
      <bibkey>nguyen-etal-2023-demaformer</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.235</doi>
    </paper>
    <paper id="236">
      <title>Test-time Augmentation for Factual Probing</title>
      <author><first>Go</first><last>Kamoda</last></author>
      <author><first>Benjamin</first><last>Heinzerling</last></author>
      <author><first>Keisuke</first><last>Sakaguchi</last></author>
      <author><first>Kentaro</first><last>Inui</last></author>
      <pages>3650-3661</pages>
      <abstract>Factual probing is a method that uses prompts to test if a language model “knows” certain world knowledge facts. A problem in factual probing is that small changes to the prompt can lead to large changes in model output. Previous work aimed to alleviate this problem by optimizing prompts via text mining or fine-tuning. However, such approaches are relation-specific and do not generalize to unseen relation types. Here, we propose to use test-time augmentation (TTA) as a relation-agnostic method for reducing sensitivity to prompt variations by automatically augmenting and ensembling prompts at test time. Experiments show improved model calibration, i.e., with TTA, model confidence better reflects prediction accuracy. Improvements in prediction accuracy are observed for some models, but for other models, TTA leads to degradation. Error analysis identifies the difficulty of producing high-quality prompt variations as the main challenge for TTA.</abstract>
      <url hash="eb777b69">2023.findings-emnlp.236</url>
      <bibkey>kamoda-etal-2023-test</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.236</doi>
    </paper>
    <paper id="237">
      <title>Methodological Insights in Detecting Subtle Semantic Shifts with Contextualized and Static Language Models</title>
      <author><first>Sanne</first><last>Hoeken</last></author>
      <author><first>Özge</first><last>Alacam</last></author>
      <author><first>Antske</first><last>Fokkens</last></author>
      <author><first>Pia</first><last>Sommerauer</last></author>
      <pages>3662-3675</pages>
      <abstract>In this paper, we investigate automatic detection of subtle semantic shifts between social communities of different political convictions in Dutch and English. We perform a methodological study comparing methods using static and contextualized language models. We investigate the impact of specializing contextualized models through fine-tuning on target corpora, word sense disambiguation and sentiment. We furthermore propose a new approach using masked token prediction, that relies on behavioral information, specifically the most probable substitutions, instead of geometrical comparison of representations. Our results show that methods using static models and our masked token prediction method can detect differences in connotation of politically loaded terms, whereas methods that rely on measuring the distance between contextualized representations are not providing clear signals, even in synthetic scenarios of extreme shifts.</abstract>
      <url hash="ec560544">2023.findings-emnlp.237</url>
      <bibkey>hoeken-etal-2023-methodological</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.237</doi>
    </paper>
    <paper id="238">
      <title>Disfluent Cues for Enhanced Speech Understanding in Large Language Models</title>
      <author><first>Morteza</first><last>Rohanian</last></author>
      <author><first>Farhad</first><last>Nooralahzadeh</last></author>
      <author><first>Omid</first><last>Rohanian</last></author>
      <author><first>David</first><last>Clifton</last></author>
      <author><first>Michael</first><last>Krauthammer</last></author>
      <pages>3676-3684</pages>
      <abstract>In computational linguistics, the common practice is to “clean” disfluent content from spontaneous speech. However, we hypothesize that these disfluencies might serve as more than mere noise, potentially acting as informative cues. We use a range of pre-trained models for a reading comprehension task involving disfluent queries, specifically featuring different types of speech repairs. The findings indicate that certain disfluencies can indeed improve model performance, particularly those stemming from context-based adjustments. However, large-scale language models struggle to handle repairs involving decision-making or the correction of lexical or syntactic errors, suggesting a crucial area for potential improvement. This paper thus highlights the importance of a nuanced approach to disfluencies, advocating for their potential utility in enhancing model performance rather than their removal.</abstract>
      <url hash="3cbe285c">2023.findings-emnlp.238</url>
      <bibkey>rohanian-etal-2023-disfluent</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.238</doi>
    </paper>
    <paper id="239">
      <title>Watermarking <fixed-case>PLM</fixed-case>s on Classification Tasks by Combining Contrastive Learning with Weight Perturbation</title>
      <author><first>Chenxi</first><last>Gu</last></author>
      <author><first>Xiaoqing</first><last>Zheng</last></author>
      <author><first>Jianhan</first><last>Xu</last></author>
      <author><first>Muling</first><last>Wu</last></author>
      <author><first>Cenyuan</first><last>Zhang</last></author>
      <author><first>Chengsong</first><last>Huang</last></author>
      <author><first>Hua</first><last>Cai</last></author>
      <author><first>Xuanjing</first><last>Huang</last></author>
      <pages>3685-3694</pages>
      <abstract>Large pre-trained language models (PLMs) have achieved remarkable success, making them highly valuable intellectual property due to their expensive training costs. Consequently, model watermarking, a method developed to protect the intellectual property of neural models, has emerged as a crucial yet underexplored technique. The problem of watermarking PLMs has remained unsolved since the parameters of PLMs will be updated when fine-tuned on downstream datasets, and then embedded watermarks could be removed easily due to the catastrophic forgetting phenomenon. This study investigates the feasibility of watermarking PLMs by embedding backdoors that can be triggered by specific inputs. We employ contrastive learning during the watermarking phase, allowing the representations of specific inputs to be isolated from others and mapped to a particular label after fine-tuning. Moreover, we demonstrate that by combining weight perturbation with the proposed method, watermarks can be embedded in a flatter region of the loss landscape, thereby increasing their robustness to watermark removal. Extensive experiments on multiple datasets demonstrate that the embedded watermarks can be robustly extracted without any knowledge about downstream tasks, and with a high success rate.</abstract>
      <url hash="acde7072">2023.findings-emnlp.239</url>
      <bibkey>gu-etal-2023-watermarking</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.239</doi>
    </paper>
    <paper id="240">
      <title><fixed-case>B</fixed-case>an<fixed-case>L</fixed-case>emma: A Word Formation Dependent Rule and Dictionary Based <fixed-case>B</fixed-case>angla Lemmatizer</title>
      <author><first>Sadia</first><last>Afrin</last></author>
      <author><first>Md. Shahad Mahmud</first><last>Chowdhury</last></author>
      <author><first>Md.</first><last>Islam</last></author>
      <author><first>Faisal</first><last>Khan</last></author>
      <author><first>Labib</first><last>Chowdhury</last></author>
      <author><first>Md.</first><last>Mahtab</last></author>
      <author><first>Nazifa</first><last>Chowdhury</last></author>
      <author><first>Massud</first><last>Forkan</last></author>
      <author><first>Neelima</first><last>Kundu</last></author>
      <author><first>Hakim</first><last>Arif</last></author>
      <author><first>Mohammad Mamun Or</first><last>Rashid</last></author>
      <author><first>Mohammad</first><last>Amin</last></author>
      <author><first>Nabeel</first><last>Mohammed</last></author>
      <pages>3695-3710</pages>
      <abstract>Lemmatization holds significance in both natural language processing (NLP) and linguistics, as it effectively decreases data density and aids in comprehending contextual meaning. However, due to the highly inflected nature and morphological richness, lemmatization in Bangla text poses a complex challenge. In this study, we propose linguistic rules for lemmatization and utilize a dictionary along with the rules to design a lemmatizer specifically for Bangla. Our system aims to lemmatize words based on their parts of speech class within a given sentence. Unlike previous rule-based approaches, we analyzed the suffix marker occurrence according to the morpho-syntactic values and then utilized sequences of suffix markers instead of entire suffixes. To develop our rules, we analyze a large corpus of Bangla text from various domains, sources, and time periods to observe the word formation of inflected words. The lemmatizer achieves an accuracy of 96.36% when tested against a manually annotated test dataset by trained linguists and demonstrates competitive performance on three previously published Bangla lemmatization datasets. We are making the code and datasets publicly available at https://github.com/eblict-gigatech/BanLemma in order to contribute to the further advancement of Bangla NLP.</abstract>
      <url hash="eef93fbc">2023.findings-emnlp.240</url>
      <bibkey>afrin-etal-2023-banlemma</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.240</doi>
    </paper>
    <paper id="241">
      <title>Exploring the Sensitivity of <fixed-case>LLM</fixed-case>s’ Decision-Making Capabilities: Insights from Prompt Variations and Hyperparameters</title>
      <author><first>Manikanta</first><last>Loya</last></author>
      <author><first>Divya</first><last>Sinha</last></author>
      <author><first>Richard</first><last>Futrell</last></author>
      <pages>3711-3716</pages>
      <abstract>The advancement of Large Language Models (LLMs) has led to their widespread use across a broad spectrum of tasks, including decision-making. Prior studies have compared the decision-making abilities of LLMs with those of humans from a psychological perspective. However, these studies have not always properly accounted for the sensitivity of LLMs’ behavior to hyperparameters and variations in the prompt. In this study, we examine LLMs’ performance on the Horizon decision-making task studied by Binz and Schulz (2023), analyzing how LLMs respond to variations in prompts and hyperparameters. By experimenting on three OpenAI language models possessing different capabilities, we observe that the decision-making abilities fluctuate based on the input prompts and temperature settings. Contrary to previous findings, language models display a human-like exploration–exploitation tradeoff after simple adjustments to the prompt.</abstract>
      <url hash="966544f2">2023.findings-emnlp.241</url>
      <bibkey>loya-etal-2023-exploring</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.241</doi>
    </paper>
    <paper id="242">
      <title>Search Augmented Instruction Learning</title>
      <author><first>Hongyin</first><last>Luo</last></author>
      <author><first>Tianhua</first><last>Zhang</last></author>
      <author><first>Yung-Sung</first><last>Chuang</last></author>
      <author><first>Yuan</first><last>Gong</last></author>
      <author><first>Yoon</first><last>Kim</last></author>
      <author><first>Xixin</first><last>Wu</last></author>
      <author><first>Helen</first><last>Meng</last></author>
      <author><first>James</first><last>Glass</last></author>
      <pages>3717-3729</pages>
      <abstract>Large language models (LLMs) have been significantly improved by instruction fine-tuning, but still lack transparency and the ability to utilize up-to-date knowledge and information. In this work, we propose search-augmented instruction learning (SAIL), which grounds the language generation and instruction following abilities on complex search results generated by in-house and external search engines. With an instruction tuning corpus, we collect search results for each training case from different search APIs and domains, and construct a new search-grounded training set containing (instruction, grounding information, response) triplets. We then fine-tune the LLaMA-7B model on the constructed training set. Since the collected results contain unrelated and disputing languages, the model needs to learn to ground on trustworthy search results, filter out distracting passages, and generate the target response. The search result-denoising process entails explicit trustworthy information selection and multi-hop reasoning, since the retrieved passages might be informative but not contain the instruction-following answer. Experiments show that the fine-tuned SAIL-7B model has a strong instruction-following ability, and it performs significantly better on transparency-sensitive tasks, including open-ended question answering and fact checking.</abstract>
      <url hash="a42d9088">2023.findings-emnlp.242</url>
      <bibkey>luo-etal-2023-search</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.242</doi>
    </paper>
    <paper id="243">
      <title>“Kelly is a Warm Person, Joseph is a Role Model”: Gender Biases in <fixed-case>LLM</fixed-case>-Generated Reference Letters</title>
      <author><first>Yixin</first><last>Wan</last></author>
      <author><first>George</first><last>Pu</last></author>
      <author><first>Jiao</first><last>Sun</last></author>
      <author><first>Aparna</first><last>Garimella</last></author>
      <author><first>Kai-Wei</first><last>Chang</last></author>
      <author><first>Nanyun</first><last>Peng</last></author>
      <pages>3730-3748</pages>
      <abstract>Large Language Models (LLMs) have recently emerged as an effective tool to assist individuals in writing various types of content, including professional documents such as recommendation letters. Though bringing convenience, this application also introduces unprecedented fairness concerns. Model-generated reference letters might be directly used by users in professional scenarios. If underlying biases exist in these model-constructed letters, using them without scrutinization could lead to direct societal harms, such as sabotaging application success rates for female applicants. In light of this pressing issue, it is imminent and necessary to comprehensively study fairness issues and associated harms in this real-world use case. In this paper, we critically examine gender biases in LLM-generated reference letters. Drawing inspiration from social science findings, we design evaluation methods to manifest biases through 2 dimensions: (1) biases in language style and (2) biases in lexical content. We further investigate the extent of bias propagation by analyzing the hallucination bias of models, a term that we define to be bias exacerbation in model-hallucinated contents. Through benchmarking evaluation on 2 popular LLMs- ChatGPT and Alpaca, we reveal significant gender biases in LLM-generated recommendation letters. Our findings not only warn against using LLMs for this application without scrutinization, but also illuminate the importance of thoroughly studying hidden biases and harms in LLM-generated professional documents.</abstract>
      <url hash="2062b2b2">2023.findings-emnlp.243</url>
      <bibkey>wan-etal-2023-kelly</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.243</doi>
    </paper>
    <paper id="244">
      <title><fixed-case>T</fixed-case>ext<fixed-case>M</fixed-case>ixer: Mixing Multiple Inputs for Privacy-Preserving Inference</title>
      <author><first>Xin</first><last>Zhou</last></author>
      <author><first>Yi</first><last>Lu</last></author>
      <author><first>Ruotian</first><last>Ma</last></author>
      <author><first>Tao</first><last>Gui</last></author>
      <author><first>Qi</first><last>Zhang</last></author>
      <author><first>Xuanjing</first><last>Huang</last></author>
      <pages>3749-3762</pages>
      <abstract>Pre-trained language models (PLMs) are often deployed as cloud services, enabling users to upload textual data and perform inference remotely. However, users’ personal text often contains sensitive information, and sharing such data directly with the service providers can lead to serious privacy leakage. To address this problem, we introduce a novel privacy-preserving inference framework called <b>
          <i>MixPi</i>
 </b>, which prevents plaintext leakage during the inference phase. Inspired by <tex-math>k</tex-math>-anonymity, MixPi aims to obfuscate a user’s private input by mixing it with multiple other inputs, thereby confounding potential privacy attackers. To achieve this, our approach involves: (1) proposing a novel encryption module, Privacy Mixer, which encrypts input from three distinct dimensions: mixing, representation, and position. (2) adopting a pre-trained Multi-input Multi-output network to handle mixed representations and obtain multiple predictions. (3) employing a Privacy Demixer to ensure only the user can decrypt the real output among the multiple predictions. Furthermore, we explore different ways to automatically generate synthetic inputs required for mixing. Experimental results on token and sentence classification tasks demonstrate that MixPi greatly surpasses existing privacy-preserving methods in both performance and privacy.</abstract>
      <url hash="df66e5cf">2023.findings-emnlp.244</url>
      <bibkey>zhou-etal-2023-textmixer</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.244</doi>
    </paper>
    <paper id="245">
      <title><fixed-case>F</fixed-case>ine<fixed-case>P</fixed-case>rompt: Unveiling the Role of Finetuned Inductive Bias on Compositional Reasoning in <fixed-case>GPT</fixed-case>-4</title>
      <author><first>Jeonghwan</first><last>Kim</last></author>
      <author><first>Giwon</first><last>Hong</last></author>
      <author><first>Sung-Hyon</first><last>Myaeng</last></author>
      <author><first>Joyce</first><last>Whang</last></author>
      <pages>3763-3775</pages>
      <abstract>Compositional reasoning across texts has been a long-standing challenge in natural language processing. With large language models like GPT-4 taking over the field, prompting techniques such as chain-of-thought (CoT) were proposed to unlock compositional, multi-step reasoning capabilities of LLMs. Despite their success, the prompts demand significant human effort to discover and validate them. Our work draws attention to the idea of transferring task-specific inductive biases from finetuned models to prompts, as a way of improving GPT-4’s compositional reasoning capabilities. To leverage these inductive biases, we formulate prompt templates to ease the transfer of inductive biases. The experimental results on multi-hop question answering and numerical reasoning over text show that our proposed prompt scheme shows competitive zero-shot and few-shot performances compared to existing prompts on complicated reasoning tasks, highlighting the importance of adopting the validated biases of the previous paradigm.</abstract>
      <url hash="24751709">2023.findings-emnlp.245</url>
      <bibkey>kim-etal-2023-fineprompt</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.245</doi>
    </paper>
    <paper id="246">
      <title>Teacher Perception of Automatically Extracted Grammar Concepts for <fixed-case>L</fixed-case>2 Language Learning</title>
      <author><first>Aditi</first><last>Chaudhary</last></author>
      <author><first>Arun</first><last>Sampath</last></author>
      <author><first>Ashwin</first><last>Sheshadri</last></author>
      <author><first>Antonios</first><last>Anastasopoulos</last></author>
      <author><first>Graham</first><last>Neubig</last></author>
      <pages>3776-3793</pages>
      <abstract>One of the challenges in language teaching is how best to organize rules regarding syntax, semantics, or phonology in a meaningful manner. This not only requires content creators to have pedagogical skills, but also have that language’s deep understanding. While comprehensive materials to develop such curricula are available in English and some broadly spoken languages, for many other languages, teachers need to manually create them in response to their students’ needs. This is challenging because i) it requires that such experts be accessible and have the necessary resources, and ii) describing all the intricacies of a language is time-consuming and prone to omission. In this work, we aim to facilitate this process by automatically discovering and visualizing grammar descriptions. We extract descriptions from a natural text corpus that answer questions about morphosyntax (learning of word order, agreement, case marking, or word formation) and semantics (learning of vocabulary). We apply this method for teaching two Indian languages, Kannada and Marathi, which, unlike English, do not have well-developed resources for second language learning. To assess the perceived utility of the extracted material, we enlist the help of language educators from schools in North America to perform a manual evaluation, who find the materials have potential to be used for their lesson preparation and learner evaluation.</abstract>
      <url hash="e04d63ad">2023.findings-emnlp.246</url>
      <bibkey>chaudhary-etal-2023-teacher</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.246</doi>
    </paper>
    <paper id="247">
      <title>Allies: Prompting Large Language Model with Beam Search</title>
      <author><first>Hao</first><last>Sun</last></author>
      <author><first>Xiao</first><last>Liu</last></author>
      <author><first>Yeyun</first><last>Gong</last></author>
      <author><first>Yan</first><last>Zhang</last></author>
      <author><first>Daxin</first><last>Jiang</last></author>
      <author><first>Linjun</first><last>Yang</last></author>
      <author><first>Nan</first><last>Duan</last></author>
      <pages>3794-3805</pages>
      <abstract>With the advance of large language models (LLMs), the research field of LLM applications becomes more and more popular and the idea of constructing pipelines to accomplish complex tasks by stacking LLM API calls come true. However, this kind of methods face two limitations: narrow information coverage and low fault tolerance. In this work, we propose a novel method called ALLIES. Given an input query, ALLIES leverages LLMs to iteratively generate new queries related to the original query, enabling an iterative reasoning process. By iteratively refining and expanding the scope of the original query, ALLIES captures and utilizes hidden knowledge that may not be directly obtainable through retrieval. We take zero-shot open-domain question answering (ODQA) as an application scene and evaluate ALLIES on the widely-used benchmarks, such as NQ, WebQ and TriviaQA. The experimental results demonstrate that ALLIES significantly outperforms other zero-shot baselines, indicating its effectiveness in tackling those challenges. Our code is available in https://github.com/microsoft/SimXNS/tree/main/ALLIES.</abstract>
      <url hash="1059d157">2023.findings-emnlp.247</url>
      <bibkey>sun-etal-2023-allies</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.247</doi>
    </paper>
    <paper id="248">
      <title>Logic-<fixed-case>LM</fixed-case>: Empowering Large Language Models with Symbolic Solvers for Faithful Logical Reasoning</title>
      <author><first>Liangming</first><last>Pan</last></author>
      <author><first>Alon</first><last>Albalak</last></author>
      <author><first>Xinyi</first><last>Wang</last></author>
      <author><first>William</first><last>Wang</last></author>
      <pages>3806-3824</pages>
      <abstract>Large Language Models (LLMs) have shown human-like reasoning abilities but still struggle with complex logical problems. This paper introduces a novel framework, Logic-LM, which integrates LLMs with symbolic solvers to improve logical problem-solving. Our method first utilizes LLMs to translate a natural language problem into a symbolic formulation. Afterward, a deterministic symbolic solver performs inference on the formulated problem. We also introduce a self-refinement module, which utilizes the symbolic solver’s error messages to revise symbolic formalizations. We demonstrate Logic-LM’s effectiveness on five logical reasoning datasets: ProofWriter, PrOntoQA, FOLIO, LogicalDeduction, and AR-LSAT. On average, Logic-LM achieves a significant performance boost of 39.2% over using LLM alone with standard prompting and 18.4% over LLM with chain-of-thought prompting. Our findings suggest that Logic-LM, by combining LLMs with symbolic logic, offers a promising avenue for faithful logical reasoning.</abstract>
      <url hash="83e50006">2023.findings-emnlp.248</url>
      <bibkey>pan-etal-2023-logic</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.248</doi>
    </paper>
    <paper id="249">
      <title><fixed-case>S</fixed-case>i<fixed-case>MF</fixed-case>y: A Simple Yet Effective Approach for Temporal Knowledge Graph Reasoning</title>
      <author><first>Zhengtao</first><last>Liu</last></author>
      <author><first>Lei</first><last>Tan</last></author>
      <author><first>Mengfan</first><last>Li</last></author>
      <author><first>Yao</first><last>Wan</last></author>
      <author><first>Hai</first><last>Jin</last></author>
      <author><first>Xuanhua</first><last>Shi</last></author>
      <pages>3825-3836</pages>
      <abstract>Temporal Knowledge Graph (TKG) reasoning, which focuses on leveraging temporal information to infer future facts in knowledge graphs, plays a vital role in knowledge graph completion. Typically, existing works for this task design graph neural networks and recurrent neural networks to respectively capture the structural and temporal information in KGs. Despite their effectiveness, in our practice, we find that they tend to suffer the issues of low training efficiency and insufficient generalization ability, which can be attributed to the over design of model architectures. To this end, this paper aims to figure out whether the current complex model architectures are necessary for temporal knowledge graph reasoning. As a result, we put forward a simple yet effective approach (termed SiMFy), which simply utilizes multilayer perceptron (MLP) to model the structural dependencies of events and adopts a fixed-frequency strategy to incorporate historical frequency during inference. Extensive experiments on real-world datasets demonstrate that our SiMFy can reach state-of-the-art performance with the following strengths: 1) faster convergence speed and better generalization ability; 2) a much smaller time consumption in the training process; and 3) better ability to capture the structural dependencies of events in KGs. These results provide evidence that the substitution of complex models with simpler counterparts is a feasible strategy.</abstract>
      <url hash="116b3a22">2023.findings-emnlp.249</url>
      <bibkey>liu-etal-2023-simfy</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.249</doi>
    </paper>
    <paper id="250">
      <title>Understanding Translationese in Cross-Lingual Summarization</title>
      <author><first>Jiaan</first><last>Wang</last></author>
      <author><first>Fandong</first><last>Meng</last></author>
      <author><first>Yunlong</first><last>Liang</last></author>
      <author><first>Tingyi</first><last>Zhang</last></author>
      <author><first>Jiarong</first><last>Xu</last></author>
      <author><first>Zhixu</first><last>Li</last></author>
      <author><first>Jie</first><last>Zhou</last></author>
      <pages>3837-3849</pages>
      <abstract>Given a document in a source language, cross-lingual summarization (CLS) aims at generating a concise summary in a different target language. Unlike monolingual summarization (MS), naturally occurring source-language documents paired with target-language summaries are rare. To collect large-scale CLS data, existing datasets typically involve translation in their creation. However, the translated text is distinguished from the text originally written in that language, i.e., translationese. In this paper, we first confirm that different approaches of constructing CLS datasets will lead to different degrees of translationese. Then we systematically investigate how translationese affects CLS model evaluation and performance when it appears in source documents or target summaries. In detail, we find that (1) the translationese in documents or summaries of test sets might lead to the discrepancy between human judgment and automatic evaluation; (2) the translationese in training sets would harm model performance in real-world applications; (3) though machine-translated documents involve translationese, they are very useful for building CLS systems on low-resource languages under specific training strategies. Lastly, we give suggestions for future CLS research including dataset and model developments. We hope that our work could let researchers notice the phenomenon of translationese in CLS and take it into account in the future.</abstract>
      <url hash="cfaa8300">2023.findings-emnlp.250</url>
      <bibkey>wang-etal-2023-understanding</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.250</doi>
    </paper>
    <paper id="251">
      <title>The Truth, The Whole Truth, and Nothing but the Truth: A New Benchmark Dataset for <fixed-case>H</fixed-case>ebrew Text Credibility Assessment</title>
      <author><first>Ben</first><last>Hagag</last></author>
      <author><first>Reut</first><last>Tsarfaty</last></author>
      <pages>3850-3865</pages>
      <abstract>In the age of information overload, it is more important than ever to discern fact from fiction. From the internet to traditional media, we are constantly confronted with a deluge of information, much of which comes from politicians and other public figures who wield significant influence. In this paper, we introduce HeTrue: a new, publicly available dataset for evaluating the credibility of statements made by Israeli public figures and politicians. This dataset consists of 1021 statements, manually annotated by Israeli professional journalists, for their credibility status. Using this corpus, we set out to assess whether the credibility of statements can be predicted based on the text alone. To establish a baseline, we compare text-only methods with others using additional data like metadata, context, and evidence. Furthermore, we develop several credibility assessment models, including a feature-based model that utilizes linguistic features, and state-of-the-art transformer-based models with contextualized embeddings from a pre-trained encoder. Empirical results demonstrate improved performance when models integrate statement and context, outperforming those relying on the statement text alone. Our best model, which also integrates evidence, achieves a 48.3 F1 Score, suggesting that HeTrue is a challenging benchmark, calling for further work on this task.</abstract>
      <url hash="990f5d35">2023.findings-emnlp.251</url>
      <bibkey>hagag-tsarfaty-2023-truth</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.251</doi>
    </paper>
    <paper id="252">
      <title><fixed-case>I</fixed-case>ndi<fixed-case>S</fixed-case>ocial<fixed-case>FT</fixed-case>: Multilingual Word Representation for <fixed-case>I</fixed-case>ndian languages in code-mixed environment</title>
      <author><first>Saurabh</first><last>Kumar</last></author>
      <author><first>Ranbir</first><last>Sanasam</last></author>
      <author><first>Sukumar</first><last>Nandi</last></author>
      <pages>3866-3871</pages>
      <abstract>The increasing number of Indian language users on the internet necessitates the development of Indian language technologies. In response to this demand, our paper presents a generalized representation vector for diverse text characteristics, including native scripts, transliterated text, multilingual, code-mixed, and social media-related attributes. We gather text from both social media and well-formed sources and utilize the FastText model to create the “IndiSocialFT” embedding. Through intrinsic and extrinsic evaluation methods, we compare IndiSocialFT with three popular pretrained embeddings trained over Indian languages. Our findings show that the proposed embedding surpasses the baselines in most cases and languages, demonstrating its suitability for various NLP applications.</abstract>
      <url hash="ced76d4e">2023.findings-emnlp.252</url>
      <bibkey>kumar-etal-2023-indisocialft</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.252</doi>
    </paper>
    <paper id="253">
      <title>Adaptive Hinge Balance Loss for Document-Level Relation Extraction</title>
      <author><first>Jize</first><last>Wang</last></author>
      <author><first>Xinyi</first><last>Le</last></author>
      <author><first>Xiaodi</first><last>Peng</last></author>
      <author><first>Cailian</first><last>Chen</last></author>
      <pages>3872-3878</pages>
      <abstract>Document-Level Relation Extraction aims at predicting relations between entities from multiple sentences. A common practice is to select multi-label classification thresholds to decide whether a relation exists between an entity pair. However, in the document-level task, most entity pairs do not express any relations, resulting in a highly imbalanced distribution between positive and negative classes. We argue that the imbalance problem affects threshold selection and may lead to incorrect “no-relation” predictions. In this paper, we propose to down-weight the easy negatives by utilizing a distance between the classification threshold and the predicted score of each relation. Our novel Adaptive Hinge Balance Loss measures the difficulty of each relation class with the distance, putting more focus on hard, misclassified relations, i.e. the minority positive relations. Experiment results on Re-DocRED demonstrate the superiority of our approach over other balancing methods. Source codes are available at https://github.com/Jize-W/HingeABL.</abstract>
      <url hash="5e5b83ec">2023.findings-emnlp.253</url>
      <bibkey>wang-etal-2023-adaptive</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.253</doi>
    </paper>
    <paper id="254">
      <title>Answer-state Recurrent Relational Network (<fixed-case>A</fixed-case>s<fixed-case>RRN</fixed-case>) for Constructed Response Assessment and Feedback Grouping</title>
      <author><first>Zhaohui</first><last>Li</last></author>
      <author><first>Susan</first><last>Lloyd</last></author>
      <author><first>Matthew</first><last>Beckman</last></author>
      <author><first>Rebecca</first><last>Passonneau</last></author>
      <pages>3879-3891</pages>
      <abstract>STEM educators must trade off the ease of assessing selected response (SR) questions, like multiple choice, with constructed response (CR) questions, where students articulate their own reasoning. Our work addresses a CR type new to NLP but common in college STEM, consisting of multiple questions per context. To relate the context, the questions, the reference responses, and students’ answers, we developed an Answer-state Recurrent Relational Network (AsRRN). In recurrent time-steps, relation vectors are learned for specific dependencies in a computational graph, where the nodes encode the distinct types of text input. AsRRN incorporates contrastive loss for better representation learning, which improves performance and supports student feedback. AsRRN was developed on a new dataset of 6,532 student responses to three, two-part CR questions. AsRRN outperforms classifiers based on LLMs, a previous relational network for CR questions, and few-shot learning with GPT-3.5. Ablation studies show the distinct contributions of AsRRN’s dependency structure, the number of time steps in the recurrence, and the contrastive loss.</abstract>
      <url hash="2278ebec">2023.findings-emnlp.254</url>
      <bibkey>li-etal-2023-answer</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.254</doi>
    </paper>
    <paper id="255">
      <title>Low-Resource Comparative Opinion Quintuple Extraction by Data Augmentation with Prompting</title>
      <author><first>Qingting</first><last>Xu</last></author>
      <author><first>Yu</first><last>Hong</last></author>
      <author><first>Fubang</first><last>Zhao</last></author>
      <author><first>Kaisong</first><last>Song</last></author>
      <author><first>Yangyang</first><last>Kang</last></author>
      <author><first>Jiaxiang</first><last>Chen</last></author>
      <author><first>Guodong</first><last>Zhou</last></author>
      <pages>3892-3897</pages>
      <abstract>Comparative Opinion Quintuple Extraction (COQE) aims to predict comparative opinion quintuples from comparative sentences. These quintuples include subject, object, shareable aspect, comparative opinion, and preference. The existing pipeline-based COQE method fails in error propagation. In addition, the complexity and insufficient amounts of annotated data hinder the performance of COQE models. In this paper, we introduce a novel approach called low-resource comparative opinion quintuple extraction by Data Augmentation with Prompting (DAP). Firstly, we present an end-to-end model architecture better suited to the data augmentation method from triplets to quintuples and can effectively avoid error propagation. Additionally, we introduce a data-centric augmentation approach that leverages the robust generative abilities of ChatGPT and integrates transfer learning techniques. Experimental results over three datasets (Camera, Car, Ele) demonstrate that our approach yields substantial improvements and achieves state-of-the-art results. The source code and data are publicly released at: https://github.com/qtxu-nlp/COQE-DAP.</abstract>
      <url hash="9570c937">2023.findings-emnlp.255</url>
      <bibkey>xu-etal-2023-low</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.255</doi>
    </paper>
    <paper id="256">
      <title>A New Benchmark and Reverse Validation Method for Passage-level Hallucination Detection</title>
      <author><first>Shiping</first><last>Yang</last></author>
      <author><first>Renliang</first><last>Sun</last></author>
      <author><first>Xiaojun</first><last>Wan</last></author>
      <pages>3898-3908</pages>
      <abstract>Large Language Models (LLMs) have shown their ability to collaborate effectively with humans in real-world scenarios. However, LLMs are apt to generate hallucinations, i.e., makeup incorrect text and unverified information, which can cause significant damage when deployed for mission-critical tasks. In this paper, we propose a self-check approach based on reverse validation to detect factual errors automatically in a zero-resource fashion. To facilitate future studies and assess different methods, we construct a hallucination detection benchmark named PHD, which is generated by ChatGPT and annotated by human annotators. Contrasting previous studies of zero-resource hallucination detection, our method and benchmark concentrate on passage-level detection instead of sentence-level. We empirically evaluate our method and existing zero-resource detection methods on two datasets. The experimental results demonstrate that the proposed method considerably outperforms the baselines while costing fewer tokens and less time. Furthermore, we manually analyze some hallucination cases that LLM failed to capture, revealing the shared limitation of zero-resource methods.</abstract>
      <url hash="c10603ec">2023.findings-emnlp.256</url>
      <bibkey>yang-etal-2023-new-benchmark</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.256</doi>
    </paper>
    <paper id="257">
      <title>Speculative Decoding: Exploiting Speculative Execution for Accelerating Seq2seq Generation</title>
      <author><first>Heming</first><last>Xia</last></author>
      <author><first>Tao</first><last>Ge</last></author>
      <author><first>Peiyi</first><last>Wang</last></author>
      <author><first>Si-Qing</first><last>Chen</last></author>
      <author><first>Furu</first><last>Wei</last></author>
      <author><first>Zhifang</first><last>Sui</last></author>
      <pages>3909-3925</pages>
      <abstract>We propose Speculative Decoding (SpecDec), for the first time ever, to formally study exploiting the idea of speculative execution to accelerate autoregressive (AR) decoding. Speculative Decoding has two innovations: Spec-Drafter – an independent model specially optimized for efficient and accurate drafting – and Spec-Verification – a reliable method for verifying the drafted tokens efficiently in the decoding paradigm. Experimental results on various seq2seq tasks including machine translation and abstractive summarization show our approach can achieve around 5x speedup for the popular Transformer architectures with comparable generation quality to beam search decoding, refreshing the impression that the draft-then-verify paradigm introduces only 1.4x~2x speedup. In addition to the remarkable speedup, we also demonstrate 3 additional advantages of SpecDec, revealing its practical value for accelerating generative models in real-world applications. Our models and codes are available at https://github.com/hemingkx/SpecDec.</abstract>
      <url hash="8c33430c">2023.findings-emnlp.257</url>
      <bibkey>xia-etal-2023-speculative</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.257</doi>
    </paper>
    <paper id="258">
      <title><fixed-case>APP</fixed-case>: Adaptive Prototypical Pseudo-Labeling for Few-shot <fixed-case>OOD</fixed-case> Detection</title>
      <author><first>Pei</first><last>Wang</last></author>
      <author><first>Keqing</first><last>He</last></author>
      <author><first>Yutao</first><last>Mou</last></author>
      <author><first>Xiaoshuai</first><last>Song</last></author>
      <author><first>Yanan</first><last>Wu</last></author>
      <author><first>Jingang</first><last>Wang</last></author>
      <author><first>Yunsen</first><last>Xian</last></author>
      <author><first>Xunliang</first><last>Cai</last></author>
      <author><first>Weiran</first><last>Xu</last></author>
      <pages>3926-3939</pages>
      <abstract>Detecting out-of-domain (OOD) intents from user queries is essential for a task-oriented dialogue system. Previous OOD detection studies generally work on the assumption that plenty of labeled IND intents exist. In this paper, we focus on a more practical few-shot OOD setting where there are only a few labeled IND data and massive unlabeled mixed data that may belong to IND or OOD. The new scenario carries two key challenges: learning discriminative representations using limited IND data and leveraging unlabeled mixed data. Therefore, we propose an adaptive prototypical pseudo-labeling(APP) method for few-shot OOD detection, including a prototypical OOD detection framework (ProtoOOD) to facilitate low-resourceOOD detection using limited IND data, and an adaptive pseudo-labeling method to produce high-quality pseudo OOD and IND labels. Extensive experiments and analysis demonstrate the effectiveness of our method for few-shot OOD detection.</abstract>
      <url hash="be3da2ea">2023.findings-emnlp.258</url>
      <bibkey>wang-etal-2023-app</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.258</doi>
    </paper>
    <paper id="259">
      <title>2<fixed-case>INER</fixed-case>: Instructive and In-Context Learning on Few-Shot Named Entity Recognition</title>
      <author><first>Jiasheng</first><last>Zhang</last></author>
      <author><first>Xikai</first><last>Liu</last></author>
      <author><first>Xinyi</first><last>Lai</last></author>
      <author><first>Yan</first><last>Gao</last></author>
      <author><first>Shusen</first><last>Wang</last></author>
      <author><first>Yao</first><last>Hu</last></author>
      <author><first>Yiqing</first><last>Lin</last></author>
      <pages>3940-3951</pages>
      <abstract>Prompt-based learning has emerged as a powerful technique in natural language processing (NLP) due to its ability to leverage pre-training knowledge for downstream few-shot tasks. In this paper, we propose 2INER, a novel text-to-text framework for Few-Shot Named Entity Recognition (NER) tasks. Our approach employs instruction finetuning based on InstructionNER to enable the model to effectively comprehend and process task-specific instructions, including both main and auxiliary tasks. We also introduce a new auxiliary task, called Type Extracting, to enhance the model’s understanding of entity types in the overall semantic context of a sentence. To facilitate in-context learning, we concatenate examples to the input, enabling the model to learn from additional contextual information. Experimental results on four datasets demonstrate that our approach outperforms existing Few-Shot NER methods and remains competitive with state-of-the-art standard NER algorithms.</abstract>
      <url hash="a986fa0f">2023.findings-emnlp.259</url>
      <bibkey>zhang-etal-2023-2iner</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.259</doi>
    </paper>
    <paper id="260">
      <title>Generative Emotion Cause Triplet Extraction in Conversations with Commonsense Knowledge</title>
      <author><first>Fanfan</first><last>Wang</last></author>
      <author><first>Jianfei</first><last>Yu</last></author>
      <author><first>Rui</first><last>Xia</last></author>
      <pages>3952-3963</pages>
      <abstract>Emotion Cause Triplet Extraction in Conversations (ECTEC) aims to simultaneously extract emotion utterances, emotion categories, and cause utterances from conversations. However, existing studies mainly decompose the ECTEC task into multiple subtasks and solve them in a pipeline manner. Moreover, since conversations tend to contain many informal and implicit expressions, it often requires external knowledge and reasoning-based inference to accurately identify emotional and causal clues implicitly mentioned in the context, which are ignored by previous work. To address these limitations, in this paper, we propose a commonSense knowledge-enHanced generAtive fRameworK named SHARK, which formulates the ECTEC task as an index generation problem and generates the emotion-cause-category triplets in an end-to-end manner with a sequence-to-sequence model. Furthermore, we propose to incorporate both retrieved and generated commonsense knowledge into the generative model via a dual-view gate mechanism and a graph attention layer. Experimental results show that our SHARK model consistently outperforms several competitive systems on two benchmark datasets. Our source codes are publicly released at https://github.com/NUSTM/SHARK.</abstract>
      <url hash="9d288ca0">2023.findings-emnlp.260</url>
      <bibkey>wang-etal-2023-generative-emotion</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.260</doi>
    </paper>
    <paper id="261">
      <title>Proto-lm: A Prototypical Network-Based Framework for Built-in Interpretability in Large Language Models</title>
      <author><first>Sean</first><last>Xie</last></author>
      <author><first>Soroush</first><last>Vosoughi</last></author>
      <author><first>Saeed</first><last>Hassanpour</last></author>
      <pages>3964-3979</pages>
      <abstract>Large Language Models (LLMs) have significantly advanced the field of Natural Language Processing (NLP), but their lack of interpretability has been a major concern. Current methods for interpreting LLMs are post hoc, applied after inference time, and have limitations such as their focus on low-level features and lack of explainability at higher-level text units. In this work, we introduce proto-lm, a prototypical network-based white-box framework that allows LLMs to learn immediately interpretable embeddings during the fine-tuning stage while maintaining competitive performance. Our method’s applicability and interpretability are demonstrated through experiments on a wide range of NLP tasks, and our results indicate a new possibility of creating interpretable models without sacrificing performance. This novel approach to interpretability in LLMs can pave the way for more interpretable models without the need to sacrifice performance. We release our code at https://github.com/yx131/proto-lm.</abstract>
      <url hash="9193d4a2">2023.findings-emnlp.261</url>
      <bibkey>xie-etal-2023-proto</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.261</doi>
    </paper>
    <paper id="262">
      <title><fixed-case>GROVE</fixed-case>: A Retrieval-augmented Complex Story Generation Framework with A Forest of Evidence</title>
      <author><first>Zhihua</first><last>Wen</last></author>
      <author><first>Zhiliang</first><last>Tian</last></author>
      <author><first>Wei</first><last>Wu</last></author>
      <author><first>Yuxin</first><last>Yang</last></author>
      <author><first>Yanqi</first><last>Shi</last></author>
      <author><first>Zhen</first><last>Huang</last></author>
      <author><first>Dongsheng</first><last>Li</last></author>
      <pages>3980-3998</pages>
      <abstract>Conditional story generation is significant in human-machine interaction, particularly in producing stories with complex plots. While Large language models (LLMs) perform well on multiple NLP tasks, including story generation, it is challenging to generate stories with both complex and creative plots. Existing methods often rely on detailed prompts to guide LLMs to meet target conditions, which inadvertently restrict the creative potential of the generated stories. We argue that leveraging information from exemplary human-written stories facilitates generating more diverse plotlines. Delving deeper into story details helps build complex and credible plots. In this paper, we propose a retrieval-auGmented stoRy generation framework with a fOrest of eVidEnce (GROVE) to enhance stories’ complexity. We build a retrieval repository for target conditions to produce few-shot examples to prompt LLMs. Additionally, we design an “asking-why” prompting scheme that extracts a forest of evidence, providing compensation for the ambiguities that may occur in the generated story. This iterative process uncovers underlying story backgrounds. Finally, we select the most fitting chains of evidence from the evidence forest and integrate them into the generated story, thereby enhancing the narrative’s complexity and credibility. Experimental results and numerous examples verify the effectiveness of our method.</abstract>
      <url hash="f8b9209a">2023.findings-emnlp.262</url>
      <bibkey>wen-etal-2023-grove</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.262</doi>
    </paper>
    <paper id="263">
      <title><fixed-case>KAPALM</fixed-case>: Knowledge gr<fixed-case>AP</fixed-case>h enh<fixed-case>A</fixed-case>nced Language Models for Fake News Detection</title>
      <author><first>Jing</first><last>Ma</last></author>
      <author><first>Chen</first><last>Chen</last></author>
      <author><first>Chunyan</first><last>Hou</last></author>
      <author><first>Xiaojie</first><last>Yuan</last></author>
      <pages>3999-4009</pages>
      <abstract>Social media has not only facilitated news consumption, but also led to the wide spread of fake news. Because news articles in social media is usually condensed and full of knowledge entities, existing methods of fake news detection use external entity knowledge. However, majority of these methods focus on news entity information and ignore the structured knowledge among news entities. To address this issue, in this work, we propose a Knowledge grAPh enhAnced Language Model (KAPALM) which is a novel model that fuses coarse- and fine-grained representations of entity knowledge from Knowledge Graphs (KGs). Firstly, we identify entities in news content and link them to entities in KGs. Then, a subgraph of KGs is extracted to provide structured knowledge of entities in KGs and fed into a graph neural network to obtain the coarse-grained knowledge representation. This subgraph is pruned to provide fine-grained knowledge and fed into the attentive graph and graph pooling layer. Finally, we integrate the coarse- and fine-grained entity knowledge representations with the textual representation for fake news detection. The experimental results on two benchmark datasets show that our method is superior to state-of-the-art baselines. In addition, it is competitive in the few-shot scenario.</abstract>
      <url hash="bed9782f">2023.findings-emnlp.263</url>
      <bibkey>ma-etal-2023-kapalm</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.263</doi>
    </paper>
    <paper id="264">
      <title>Comparing the Evaluation and Production of Loophole Behavior in Humans and Large Language Models</title>
      <author><first>Sonia</first><last>Murthy</last></author>
      <author><first>Kiera</first><last>Parece</last></author>
      <author><first>Sophie</first><last>Bridgers</last></author>
      <author><first>Peng</first><last>Qian</last></author>
      <author><first>Tomer</first><last>Ullman</last></author>
      <pages>4010-4025</pages>
      <abstract>In law, lore, and everyday life, loopholes are commonplace. When people exploit a loophole, they understand the intended meaning or goal of another person, but choose to go with a different interpretation. Past and current AI research has shown that artificial intelligence engages in what seems superficially like the exploitation of loopholes, but this is likely anthropomorphization. It remains unclear to what extent current models, especially Large Language Models (LLMs), capture the pragmatic understanding required for engaging in loopholes. We examined the performance of LLMs on two metrics developed for studying loophole behavior in humans: evaluation (ratings of trouble, upset, and humor), and generation (coming up with new loopholes in a given context). We conducted a fine-grained comparison of state-of-the-art LLMs to humans, and find that while many of the models rate loophole behaviors as resulting in less trouble and upset than outright non-compliance (in line with adults), they struggle to recognize the humor in the creative exploitation of loopholes in the way that humans do. Furthermore, only two of the models, GPT 3 and 3.5, are capable of generating loopholes of their own, with GPT3.5 performing closest to the human baseline.</abstract>
      <url hash="77425072">2023.findings-emnlp.264</url>
      <bibkey>murthy-etal-2023-comparing</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.264</doi>
    </paper>
    <paper id="265">
      <title><fixed-case>I</fixed-case>nstruct<fixed-case>E</fixed-case>xcel: A Benchmark for Natural Language Instruction in Excel</title>
      <author><first>Justin</first><last>Payan</last></author>
      <author><first>Swaroop</first><last>Mishra</last></author>
      <author><first>Mukul</first><last>Singh</last></author>
      <author><first>Carina</first><last>Negreanu</last></author>
      <author><first>Christian</first><last>Poelitz</last></author>
      <author><first>Chitta</first><last>Baral</last></author>
      <author><first>Subhro</first><last>Roy</last></author>
      <author><first>Rasika</first><last>Chakravarthy</last></author>
      <author><first>Benjamin</first><last>Van Durme</last></author>
      <author><first>Elnaz</first><last>Nouri</last></author>
      <pages>4026-4043</pages>
      <abstract>With the evolution of Large Language Models (LLMs) we can solve increasingly more complex NLP tasks across various domains, including spreadsheets. This work investigates whether LLMs can generate code (Excel OfficeScripts, a TypeScript API for executing many tasks in Excel) that solves Excel specific tasks provided via natural language user instructions. To do so we introduce a new large-scale benchmark, InstructExcel, created by leveraging the ‘Automate’ feature in Excel to automatically generate OfficeScripts from users’ actions. Our benchmark includes over 10k samples covering 170+ Excel operations across 2,000 publicly available Excel spreadsheets. Experiments across various zero-shot and few-shot settings show that InstructExcel is a hard benchmark for state of the art models like GPT-4. We observe that (1) using GPT-4 over GPT-3.5, (2) providing more in-context examples, and (3) dynamic prompting can help improve performance on this benchmark.</abstract>
      <url hash="760b9573">2023.findings-emnlp.265</url>
      <bibkey>payan-etal-2023-instructexcel</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.265</doi>
    </paper>
    <paper id="266">
      <title>Hallucination Detection for Grounded Instruction Generation</title>
      <author><first>Lingjun</first><last>Zhao</last></author>
      <author><first>Khanh</first><last>Nguyen</last></author>
      <author><first>Hal</first><last>Daumé III</last></author>
      <pages>4044-4053</pages>
      <abstract>We investigate the problem of generating instructions to guide humans to navigate in simulated residential environments. A major issue with current models is hallucination: they generate references to actions or objects that are inconsistent with what a human follower would perform or encounter along the described path. We develop a model that detects these hallucinated references by adopting a model pre-trained on a large corpus of image-text pairs, and fine-tuning it with a contrastive loss that separates correct instructions from instructions containing synthesized hallucinations. Our final model outperforms several baselines, including using word probability estimated by the instruction-generation model, and supervised models based on LSTM and Transformer.</abstract>
      <url hash="9389f8e2">2023.findings-emnlp.266</url>
      <bibkey>zhao-etal-2023-hallucination</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.266</doi>
    </paper>
    <paper id="267">
      <title>Definitions Matter: Guiding <fixed-case>GPT</fixed-case> for Multi-label Classification</title>
      <author><first>Youri</first><last>Peskine</last></author>
      <author><first>Damir</first><last>Korenčić</last></author>
      <author><first>Ivan</first><last>Grubisic</last></author>
      <author><first>Paolo</first><last>Papotti</last></author>
      <author><first>Raphael</first><last>Troncy</last></author>
      <author><first>Paolo</first><last>Rosso</last></author>
      <pages>4054-4063</pages>
      <abstract>Large language models have recently risen in popularity due to their ability to perform many natural language tasks without requiring any fine-tuning. In this work, we focus on two novel ideas: (1) generating definitions from examples and using them for zero-shot classification, and (2) investigating how an LLM makes use of the definitions. We thoroughly analyze the performance of GPT-3 model for fine-grained multi-label conspiracy theory classification of tweets using zero-shot labeling. In doing so, we asses how to improve the labeling by providing minimal but meaningful context in the form of the definitions of the labels. We compare descriptive noun phrases, human-crafted definitions, introduce a new method to help the model generate definitions from examples, and propose a method to evaluate GPT-3’s understanding of the definitions. We demonstrate that improving definitions of class labels has a direct consequence on the downstream classification results.</abstract>
      <url hash="5f7c52e2">2023.findings-emnlp.267</url>
      <bibkey>peskine-etal-2023-definitions</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.267</doi>
    </paper>
    <paper id="268">
      <title><fixed-case>ECH</fixed-case>o: A Visio-Linguistic Dataset for Event Causality Inference via Human-Centric Reasoning</title>
      <author><first>Yuxi</first><last>Xie</last></author>
      <author><first>Guanzhen</first><last>Li</last></author>
      <author><first>Min-Yen</first><last>Kan</last></author>
      <pages>4064-4085</pages>
      <abstract>We introduce ECHo (Event Causality Inference via Human-Centric Reasoning), a diagnostic dataset of event causality inference grounded in visio-linguistic social scenarios. ECHo employs real-world human-centric deductive information building on a television crime drama. ECHo requires the Theory-of-Mind (ToM) ability to understand and reason about social interactions based on multimodal information. Using ECHo, we propose a unified Chain-of-Thought (CoT) framework to assess the reasoning capability of current AI systems. Our ToM-enhanced CoT pipeline accommodates various large foundation models in both zero-shot and few-shot visio-linguistic reasoning. We use this framework to scrutinize recent large foundation models such as InstructGPT and MiniGPT-4 on three diagnostic human-centric tasks. Further analysis demonstrates ECHo as a challenging dataset to expose imperfections and inconsistencies in reasoning. Our data and code are publicly available at [https://github.com/YuxiXie/ECHo](https://github.com/YuxiXie/ECHo).</abstract>
      <url hash="d95d2edc">2023.findings-emnlp.268</url>
      <bibkey>xie-etal-2023-echo</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.268</doi>
    </paper>
    <paper id="269">
      <title>An Empirical Study of Instruction-tuning Large Language Models in <fixed-case>C</fixed-case>hinese</title>
      <author><first>Qingyi</first><last>Si</last></author>
      <author><first>Tong</first><last>Wang</last></author>
      <author><first>Zheng</first><last>Lin</last></author>
      <author><first>Xu</first><last>Zhang</last></author>
      <author><first>Yanan</first><last>Cao</last></author>
      <author><first>Weiping</first><last>Wang</last></author>
      <pages>4086-4107</pages>
      <abstract>The success of ChatGPT validates the potential of large language models (LLMs) in artificial general intelligence (AGI). Subsequently, the release of LLMs has sparked the open-source community’s interest in instruction-tuning, which is deemed to accelerate ChatGPT’s replication process. However, research on instruction-tuning LLMs in Chinese, the world’s most spoken language, is still in its early stages. Therefore, this paper makes an in-depth empirical study of instruction-tuning LLMs in Chinese, which can serve as a cookbook that provides valuable findings for effectively customizing LLMs that can better respond to Chinese instructions. Specifically, we systematically explore the impact of LLM bases, parameter-efficient methods, instruction data types, which are the three most important elements for instruction-tuning. Besides, we also conduct experiment to study the impact of other factors, e.g., chain-of-thought data and human-value alignment. We hope that this empirical study can make a modest contribution to the open Chinese version of ChatGPT. This paper will release a powerful Chinese LLM that is comparable to ChatGLM. The code and data are available at https: //github.com/PhoebusSi/Alpaca-CoT.</abstract>
      <url hash="a17d70b8">2023.findings-emnlp.269</url>
      <bibkey>si-etal-2023-empirical</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.269</doi>
    </paper>
    <paper id="270">
      <title>Debiasing Multimodal Models via Causal Information Minimization</title>
      <author><first>Vaidehi</first><last>Patil</last></author>
      <author><first>Adyasha</first><last>Maharana</last></author>
      <author><first>Mohit</first><last>Bansal</last></author>
      <pages>4108-4123</pages>
      <abstract>Most existing debiasing methods for multimodal models, including causal intervention and inference methods, utilize approximate heuristics to represent the biases, such as shallow features from early stages of training or unimodal features for multimodal tasks like VQA, etc., which may not be accurate. In this paper, we study bias arising from confounders in a causal graph for multimodal data, and examine a novel approach that leverages causally-motivated information minimization to learn the confounder representations. Robust predictive features contain diverse information that helps a model generalize to out-of-distribution data. Hence, minimizing the information content of features obtained from a pretrained biased model helps learn the simplest predictive features that capture the underlying data distribution. We treat these features as confounder representations and use them via methods motivated by causal theory to remove bias from models. We find that the learned confounder representations indeed capture dataset biases and the proposed debiasing methods improve out-of-distribution (OOD) performance on multiple multimodal datasets without sacrificing in-distribution performance. Additionally, we introduce a novel metric to quantify the sufficiency of spurious features in models’ predictions that further demonstrates the effectiveness of our proposed methods.</abstract>
      <url hash="007a5874">2023.findings-emnlp.270</url>
      <bibkey>patil-etal-2023-debiasing</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.270</doi>
    </paper>
    <paper id="271">
      <title>Evaluating Emotion Arcs Across Languages: Bridging the Global Divide in Sentiment Analysis</title>
      <author><first>Daniela</first><last>Teodorescu</last></author>
      <author><first>Saif</first><last>Mohammad</last></author>
      <pages>4124-4137</pages>
      <abstract>Emotion arcs capture how an individual (or a population) feels over time. They are widely used in industry and research; however, there is little work on evaluating the automatically generated arcs. This is because of the difficulty of establishing the true (gold) emotion arc. Our work, for the first time, systematically and quantitatively evaluates automatically generated emotion arcs. We also compare two common ways of generating emotion arcs: Machine-Learning (ML) models and Lexicon-Only (LexO) methods. By running experiments on 18 diverse datasets in 9 languages, we show that despite being markedly poor at instance level emotion classification, LexO methods are highly accurate at generating emotion arcs when aggregating information from hundreds of instances. We also show, through experiments on six indigenous African languages, as well as Arabic, and Spanish, that automatic translations of English emotion lexicons can be used to generate high-quality emotion arcs in less-resource languages. This opens up avenues for work on emotions in languages from around the world; which is crucial for commerce, public policy, and health research in service of speakers often left behind. Code and resources: https://github.com/dteodore/EmotionArcs</abstract>
      <url hash="d293cb3a">2023.findings-emnlp.271</url>
      <bibkey>teodorescu-mohammad-2023-evaluating</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.271</doi>
    </paper>
    <paper id="272">
      <title>Multi-step Jailbreaking Privacy Attacks on <fixed-case>C</fixed-case>hat<fixed-case>GPT</fixed-case></title>
      <author><first>Haoran</first><last>Li</last></author>
      <author><first>Dadi</first><last>Guo</last></author>
      <author><first>Wei</first><last>Fan</last></author>
      <author><first>Mingshi</first><last>Xu</last></author>
      <author><first>Jie</first><last>Huang</last></author>
      <author><first>Fanpu</first><last>Meng</last></author>
      <author><first>Yangqiu</first><last>Song</last></author>
      <pages>4138-4153</pages>
      <abstract>With the rapid progress of large language models (LLMs), many downstream NLP tasks can be well solved given appropriate prompts. Though model developers and researchers work hard on dialog safety to avoid generating harmful content from LLMs, it is still challenging to steer AI-generated content (AIGC) for the human good. As powerful LLMs are devouring existing text data from various domains (e.g., GPT-3 is trained on 45TB texts), it is natural to doubt whether the private information is included in the training data and what privacy threats can these LLMs and their downstream applications bring. In this paper, we study the privacy threats from OpenAI’s ChatGPT and the New Bing enhanced by ChatGPT and show that application-integrated LLMs may cause new privacy threats. To this end, we conduct extensive experiments to support our claims and discuss LLMs’ privacy implications.</abstract>
      <url hash="01f11c00">2023.findings-emnlp.272</url>
      <bibkey>li-etal-2023-multi-step</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.272</doi>
    </paper>
    <paper id="273">
      <title>Chain-of-Thought Embeddings for Stance Detection on Social Media</title>
      <author><first>Joseph</first><last>Gatto</last></author>
      <author><first>Omar</first><last>Sharif</last></author>
      <author><first>Sarah</first><last>Preum</last></author>
      <pages>4154-4161</pages>
      <abstract>Stance detection on social media is challenging for Large Language Models (LLMs), as emerging slang and colloquial language in online conversations often contain deeply implicit stance labels. Chain-of-Thought (COT) prompting has recently been shown to improve performance on stance detection tasks — alleviating some of these issues. However, COT prompting still struggles with implicit stance identification. This challenge arises because many samples are initially challenging to comprehend before a model becomes familiar with the slang and evolving knowledge related to different topics, all of which need to be acquired through the training data. In this study, we address this problem by introducing COT Embeddings which improve COT performance on stance detection tasks by embedding COT reasonings and integrating them into a traditional RoBERTa-based stance detection pipeline. Our analysis demonstrates that 1) text encoders can leverage COT reasonings with minor errors or hallucinations that would otherwise distort the COT output label. 2) Text encoders can overlook misleading COT reasoning when a sample’s prediction heavily depends on domain-specific patterns. Our model achieves SOTA performance on multiple stance detection datasets collected from social media.</abstract>
      <url hash="c713e584">2023.findings-emnlp.273</url>
      <bibkey>gatto-etal-2023-chain</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.273</doi>
    </paper>
    <paper id="274">
      <title>Using <fixed-case>LLM</fixed-case> for Improving Key Event Discovery: Temporal-Guided News Stream Clustering with Event Summaries</title>
      <author><first>Nishanth</first><last>Nakshatri</last></author>
      <author><first>Siyi</first><last>Liu</last></author>
      <author><first>Sihao</first><last>Chen</last></author>
      <author><first>Dan</first><last>Roth</last></author>
      <author><first>Dan</first><last>Goldwasser</last></author>
      <author><first>Daniel</first><last>Hopkins</last></author>
      <pages>4162-4173</pages>
      <abstract>Understanding and characterizing the discus- sions around key events in news streams is important for analyzing political discourse. In this work, we study the problem of identification of such key events and the news articles associated with those events from news streams. We propose a generic framework for news stream clustering that analyzes the temporal trend of news articles to automatically extract the underlying key news events that draw significant media attention. We characterize such key events by generating event summaries, based on which we form document clusters in an unsupervised fashion. We evaluate our simple yet effective framework, and show that it produces more coherent event-focused clusters. To demonstrate the utility of our approach, and facilitate future research along the line, we use our framework to construct KeyEvents, a dataset of 40k articles with 611 key events from 11 topics.</abstract>
      <url hash="4681bd4d">2023.findings-emnlp.274</url>
      <bibkey>nakshatri-etal-2023-using</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.274</doi>
    </paper>
    <paper id="275">
      <title>Descriptive Prompt Paraphrasing for Target-Oriented Multimodal Sentiment Classification</title>
      <author><first>Dan</first><last>Liu</last></author>
      <author><first>Lin</first><last>Li</last></author>
      <author><first>Xiaohui</first><last>Tao</last></author>
      <author><first>Jian</first><last>Cui</last></author>
      <author><first>Qing</first><last>Xie</last></author>
      <pages>4174-4186</pages>
      <abstract>Target-Oriented Multimodal Sentiment Classification (TMSC) aims to perform sentiment polarity on a target jointly considering its corresponding multiple modalities including text, image, and others. Current researches mainly work on either of two types of targets in a decentralized manner. One type is entity, such as a person name, a location name, etc. and the other is aspect, such as ‘food’, ‘service’, etc. We believe that this target type based division in task modelling is not necessary because the sentiment polarity of the specific target is not governed by its type but its context. For this reason, we propose a unified model for target-oriented multimodal sentiment classification, so called UnifiedTMSC. It is prompt-based language modelling and performs well on four datasets spanning the above two target types. Specifically, we design descriptive prompt paraphrasing to reformulate TMSC task via (1) task paraphrasing, which obtains paraphrased prompts based on the task description through a paraphrasing rule, and (2) image prefix tuning, which optimizes a small continuous image vector throughout the multimodal representation space of text and images. Conducted on two entity-level multimodal datasets: Twitter-2015 and Twitter-2017, and two aspect-level multimodal datasets: Multi-ZOL and MASAD, the experimental results show the effectiveness of our UnifiedTMSC.</abstract>
      <url hash="632cc0f3">2023.findings-emnlp.275</url>
      <bibkey>liu-etal-2023-descriptive</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.275</doi>
    </paper>
    <paper id="276">
      <title>Joint Semantic and Strategy Matching for Persuasive Dialogue</title>
      <author><first>Chuhao</first><last>Jin</last></author>
      <author><first>Yutao</first><last>Zhu</last></author>
      <author><first>Lingzhen</first><last>Kong</last></author>
      <author><first>Shijie</first><last>Li</last></author>
      <author><first>Xiao</first><last>Zhang</last></author>
      <author><first>Ruihua</first><last>Song</last></author>
      <author><first>Xu</first><last>Chen</last></author>
      <author><first>Huan</first><last>Chen</last></author>
      <author><first>Yuchong</first><last>Sun</last></author>
      <author><first>Yu</first><last>Chen</last></author>
      <author><first>Jun</first><last>Xu</last></author>
      <pages>4187-4197</pages>
      <abstract>Persuasive dialogue aims to persuade users to achieve some targets by conversations. While previous persuasion models have achieved notable successes, they mostly base themselves on utterance semantic matching, and an important aspect has been ignored, that is, the strategy of the conversations, for example, the agent can choose an <i>emotional-appeal</i> strategy to impress users. Compared with utterance semantics, conversation strategies are high-level concepts, which can be informative and provide complementary information to achieve effective persuasions. In this paper, we propose to build a persuasion model by jointly modeling the conversation semantics and strategies, where we design a BERT-like module and an auto-regressive predictor to match the semantics and strategies, respectively. Experimental results indicate that our proposed approach can significantly improve the state-of-the-art baseline by 5% on a small dataset and 37% on a large dataset in terms of Recall@1. Detailed analyses show that the auto-regressive predictor contributes most to the final performance.</abstract>
      <url hash="453d278b">2023.findings-emnlp.276</url>
      <bibkey>jin-etal-2023-joint</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.276</doi>
    </paper>
    <paper id="277">
      <title>Non-Autoregressive Sentence Ordering</title>
      <author><first>Yi</first><last>Bin</last></author>
      <author><first>Wenhao</first><last>Shi</last></author>
      <author><first>Bin</first><last>Ji</last></author>
      <author><first>Jipeng</first><last>Zhang</last></author>
      <author><first>Yujuan</first><last>Ding</last></author>
      <author><first>Yang</first><last>Yang</last></author>
      <pages>4198-4214</pages>
      <abstract>Existing sentence ordering approaches generally employ encoder-decoder frameworks with the pointer net to recover the coherence by recurrently predicting each sentence step-by-step. Such an autoregressive manner only leverages unilateral dependencies during decoding and cannot fully explore the semantic dependency between sentences for ordering. To overcome these limitations, in this paper, we propose a novel Non-Autoregressive Ordering Network, dubbed <i>NAON</i>, which explores bilateral dependencies between sentences and predicts the sentence for each position in parallel. We claim that the non-autoregressive manner is not just applicable but also particularly suitable to the sentence ordering task because of two peculiar characteristics of the task: 1) each generation target is in deterministic length, and 2) the sentences and positions should match exclusively. Furthermore, to address the repetition issue of the naive non-autoregressive Transformer, we introduce an exclusive loss to constrain the exclusiveness between positions and sentences. To verify the effectiveness of the proposed model, we conduct extensive experiments on several common-used datasets and the experimental results show that our method outperforms all the autoregressive approaches and yields competitive performance compared with the state-of-the-arts. The codes are available at: <url>https://github.com/steven640pixel/nonautoregressive-sentence-ordering</url>.</abstract>
      <url hash="77cb8bbb">2023.findings-emnlp.277</url>
      <bibkey>bin-etal-2023-non-autoregressive</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.277</doi>
    </paper>
    <paper id="278">
      <title>Large Language Models are Not Yet Human-Level Evaluators for Abstractive Summarization</title>
      <author><first>Chenhui</first><last>Shen</last></author>
      <author><first>Liying</first><last>Cheng</last></author>
      <author><first>Xuan-Phi</first><last>Nguyen</last></author>
      <author><first>Yang</first><last>You</last></author>
      <author><first>Lidong</first><last>Bing</last></author>
      <pages>4215-4233</pages>
      <abstract>With the recent undeniable advancement in reasoning abilities in large language models (LLMs) like ChatGPT and GPT-4, there is a growing trend for using LLMs on various tasks. One area where LLMs can be employed is as an alternative evaluation metric for complex generative tasks, which generally demands expensive human judges to complement the traditional automatic metrics for various evaluation dimensions such as fluency and consistency. In this work, we conduct extensive analysis to investigate the stability and reliability of LLMs as automatic evaluators for abstractive summarization. We found that while ChatGPT and GPT-4 outperform the commonly used automatic metrics, they are not ready as human replacements due to significant limitations. That is, LLM evaluators rate each candidate system inconsistently and are dimension-dependent. They also struggle to compare candidates with close performance and become more unreliable with higher-quality summaries by obtaining a lower correlation with humans. In other words, with better abstractive summarization systems being introduced at a fast pace, LLMs may result in misleading and unreliable evaluations.</abstract>
      <url hash="4d0d78fa">2023.findings-emnlp.278</url>
      <bibkey>shen-etal-2023-large</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.278</doi>
    </paper>
    <paper id="279">
      <title>Women Wearing Lipstick: Measuring the Bias Between an Object and Its Related Gender</title>
      <author><first>Ahmed</first><last>Sabir</last></author>
      <author><first>Lluís</first><last>Padró</last></author>
      <pages>4234-4240</pages>
      <abstract>In this paper, we investigate the impact of objects on gender bias in image captioning systems. Our results show that only gender-specific objects have a strong gender bias (e.g., women-lipstick). In addition, we propose a visual semantic-based gender score that measures the degree of bias and can be used as a plug-in for any image captioning system. Our experiments demonstrate the utility of the gender score, since we observe that our score can measure the bias relation between a caption and its related gender; therefore, our score can be used as an additional metric to the existing Object Gender Co-Occ approach.</abstract>
      <url hash="d616408a">2023.findings-emnlp.279</url>
      <bibkey>sabir-padro-2023-women</bibkey>
      <revision id="1" href="2023.findings-emnlp.279v1" hash="a91c81f7"/>
      <revision id="2" href="2023.findings-emnlp.279v2" hash="d616408a" date="2023-12-19">Fixed figure 1.</revision>
    </paper>
    <paper id="280">
      <title><fixed-case>FREDS</fixed-case>um: A Dialogue Summarization Corpus for <fixed-case>F</fixed-case>rench Political Debates</title>
      <author><first>Virgile</first><last>Rennard</last></author>
      <author><first>Guokan</first><last>Shang</last></author>
      <author><first>Damien</first><last>Grari</last></author>
      <author><first>Julie</first><last>Hunter</last></author>
      <author><first>Michalis</first><last>Vazirgiannis</last></author>
      <pages>4241-4253</pages>
      <abstract>Recent advances in deep learning, and especially the invention of encoder-decoder architectures, have significantly improved the performance of abstractive summarization systems. While the majority of research has focused on written documents, we have observed an increasing interest in the summarization of dialogues and multi-party conversations over the past few years. In this paper, we present a dataset of French political debates for the purpose of enhancing resources for multi-lingual dialogue summarization. Our dataset consists of manually transcribed and annotated political debates, covering a range of topics and perspectives. We highlight the importance of high-quality transcription and annotations for training accurate and effective dialogue summarization models, and emphasize the need for multilingual resources to support dialogue summarization in non-English languages. We also provide baseline experiments using state-of-the-art methods, and encourage further research in this area to advance the field of dialogue summarization. Our dataset will be made publicly available for use by the research community, enabling further advances in multilingual dialogue summarization.</abstract>
      <url hash="c34cb7ba">2023.findings-emnlp.280</url>
      <bibkey>rennard-etal-2023-fredsum</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.280</doi>
    </paper>
    <paper id="281">
      <title>Towards Zero-shot Relation Extraction in Web Mining: A Multimodal Approach with Relative <fixed-case>XML</fixed-case> Path</title>
      <author><first>Zilong</first><last>Wang</last></author>
      <author><first>Jingbo</first><last>Shang</last></author>
      <pages>4254-4265</pages>
      <abstract>The rapid growth of web pages and the increasing complexity of their structure poses a challenge for web mining models. Web mining models are required to understand semi-structured web pages, particularly when little is known about the subject or template of a new page. Current methods migrate language models to web mining by embedding the XML source code into the transformer or encoding the rendered layout with graph neural networks. However, these approaches do not take into account the relationships between text nodes within and across pages. In this paper, we propose a new approach, ReXMiner, for zero-shot relation extraction in web mining. ReXMiner encodes the shortest relative paths in the Document Object Model (DOM) tree of the web page which is a more accurate and efficient signal for key-value pair extraction within a web page. It also incorporates the popularity of each text node by counting the occurrence of the same text node across different web pages. We use contrastive learning to address the issue of sparsity in relation extraction. Extensive experiments on public benchmarks show that our method, ReXMiner, outperforms the state-of-the-art baselines in the task of zero-shot relation extraction in web mining.</abstract>
      <url hash="bd04cad6">2023.findings-emnlp.281</url>
      <bibkey>wang-shang-2023-towards</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.281</doi>
    </paper>
    <paper id="282">
      <title>Narrative Style and the Spread of Health Misinformation on <fixed-case>T</fixed-case>witter</title>
      <author><first>Achyutarama</first><last>Ganti</last></author>
      <author><first>Eslam Ali Hassan</first><last>Hussein</last></author>
      <author><first>Steven</first><last>Wilson</last></author>
      <author><first>Zexin</first><last>Ma</last></author>
      <author><first>Xinyan</first><last>Zhao</last></author>
      <pages>4266-4282</pages>
      <abstract>Using a narrative style is an effective way to communicate health information both on and off social media. Given the amount of misinformation being spread online and its potential negative effects, it is crucial to investigate the interplay between narrative communication style and misinformative health content on user engagement on social media platforms. To explore this in the context of Twitter, we start with previously annotated health misinformation tweets (n <tex-math>\approx</tex-math>15,000) and annotate a subset of the data (n=3,000) for the presence of narrative style. We then use these manually assigned labels to train text classifiers, experimenting with supervised fine-tuning and in-context learning for automatic narrative detection. We use our best model to label remaining portion of the dataset, then statistically analyze the relationship between narrative style, misinformation, and user-level features on engagement, finding that narrative use is connected to increased tweet engagement and can, in some cases, lead to increased engagement with misinformation. Finally, we analyze the general categories of language used in narratives and health misinformation in our dataset.</abstract>
      <url hash="63a03f5f">2023.findings-emnlp.282</url>
      <bibkey>ganti-etal-2023-narrative</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.282</doi>
    </paper>
    <paper id="283">
      <title><fixed-case>H</fixed-case>ad<fixed-case>S</fixed-case>kip: Homotopic and Adaptive Layer Skipping of Pre-trained Language Models for Efficient Inference</title>
      <author><first>Haoyu</first><last>Wang</last></author>
      <author><first>Yaqing</first><last>Wang</last></author>
      <author><first>Tianci</first><last>Liu</last></author>
      <author><first>Tuo</first><last>Zhao</last></author>
      <author><first>Jing</first><last>Gao</last></author>
      <pages>4283-4294</pages>
      <abstract>Pre-trained language models (LMs) have brought remarkable performance on numerous NLP tasks. However, they require significant resources and entail high computational costs for inference, making them challenging to deploy in real-world and real-time systems. Existing early exiting methods aim to reduce computational complexity by selecting the layer at which to exit, but suffer from the limitation that they have to sequentially traverse through all layers prior to the selected exit layer, which lacks flexibility and degrades their performance. To solve this problem, we propose a <b>h</b>omotopic and <b>ad</b>aptive layer <b>skip</b>ping fine-tuning method named HadSkip. HadSkip adaptively selects the layers to skip based on a predefined budget. Specifically, we introduce a learnable gate before each layer of the LM to determine whether the current layer should be skipped. To tackle various challenges in training such as discrete gates and the budget constraint, we propose a fine-grained initialization strategy and homotopic optimization strategy. We conduct extensive experiments on the GLUE benchmark, and experimental results demonstrate the proposed HadSkip outperforms all state-of-the-art baselines significantly.</abstract>
      <url hash="2d16d456">2023.findings-emnlp.283</url>
      <bibkey>wang-etal-2023-hadskip</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.283</doi>
    </paper>
    <paper id="284">
      <title>Empowering Psychotherapy with Large Language Models: Cognitive Distortion Detection through Diagnosis of Thought Prompting</title>
      <author><first>Zhiyu</first><last>Chen</last></author>
      <author><first>Yujie</first><last>Lu</last></author>
      <author><first>William</first><last>Wang</last></author>
      <pages>4295-4304</pages>
      <abstract>Mental illness remains one of the most critical public health issues of our time, due to the severe scarcity and accessibility limit of professionals. Psychotherapy requires high-level expertise to conduct deep, complex reasoning and analysis on the cognition modeling of the patients. In the era of Large Language Models, we believe it is the right time to develop AI assistance for computational psychotherapy. We study the task of cognitive distortion detection and propose the Diagnosis of Thought (DoT) prompting. DoT performs diagnosis on the patient’s speech via three stages: subjectivity assessment to separate the facts and the thoughts; contrastive reasoning to elicit the reasoning processes supporting and contradicting the thoughts; and schema analysis to summarize the cognition schemas. The generated diagnosis rationales through the three stages are essential for assisting the professionals. Experiments demonstrate that DoT obtains significant improvements over ChatGPT for cognitive distortion detection, while generating high-quality rationales approved by human experts.</abstract>
      <url hash="f328ba3a">2023.findings-emnlp.284</url>
      <bibkey>chen-etal-2023-empowering</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.284</doi>
    </paper>
    <paper id="285">
      <title>Measuring the Knowledge Acquisition-Utilization Gap in Pretrained Language Models</title>
      <author><first>Amirhossein</first><last>Kazemnejad</last></author>
      <author><first>Mehdi</first><last>Rezagholizadeh</last></author>
      <author><first>Prasanna</first><last>Parthasarathi</last></author>
      <author><first>Sarath</first><last>Chandar</last></author>
      <pages>4305-4319</pages>
      <abstract>While pre-trained language models (PLMs) have shown evidence of acquiring vast amounts of knowledge, it remains unclear how much of this parametric knowledge is actually usable in performing downstream tasks. We propose a systematic framework to measure parametric knowledge utilization in PLMs. Our framework first extracts knowledge from a PLM’s parameters and subsequently constructs a downstream task around this extracted knowledge. Performance on this task thus depends exclusively on utilizing the model’s possessed knowledge, avoiding confounding factors like insufficient signal. As an instantiation, we study factual knowledge of PLMs and measure utilization across 125M to 13B parameter PLMs. We observe that: (1) PLMs exhibit two gaps - in acquired vs. utilized knowledge, (2) they show limited robustness in utilizing knowledge under distribution shifts, and (3) larger models close the acquired knowledge gap but the utilized knowledge gap remains. Overall, our study provides insights into PLMs’ capabilities beyond their acquired knowledge.</abstract>
      <url hash="744adb60">2023.findings-emnlp.285</url>
      <bibkey>kazemnejad-etal-2023-measuring</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.285</doi>
    </paper>
    <paper id="286">
      <title>Non-compositional Expression Generation Based on Curriculum Learning and Continual Learning</title>
      <author><first>Jianing</first><last>Zhou</last></author>
      <author><first>Ziheng</first><last>Zeng</last></author>
      <author><first>Hongyu</first><last>Gong</last></author>
      <author><first>Suma</first><last>Bhat</last></author>
      <pages>4320-4335</pages>
      <abstract>Non-compositional expressions, by virtue of their non-compositionality, are a classic ‘pain in the neck’ for NLP systems. Different from the general language modeling and generation tasks that are primarily compositional, generating non-compositional expressions is more challenging for current neural models, including large pre-trained language models. The main reasons are 1) their non-compositionality, and 2) the limited data resources. Therefore, to make the best use of available data for modeling non-compositionality, we propose a dynamic curriculum learning framework, which learns training examples from easy ones to harder ones thus optimizing the learning step by step but suffers from the forgetting problem. To alleviate the forgetting problem brought by the arrangement of training examples, we also apply a continual learning method into our curriculum learning framework. Our proposed method combined curriculum and continual learning, to gradually improve the model’s performance on the task of non-compositional expression generation. Experiments on idiomatic expression generation and metaphor generation affirm the effectiveness of our proposed curriculum learning framework and the application of continual learning. Our codes are available at https://github.com/zhjjn/CL2Gen.git.</abstract>
      <url hash="63b5f0db">2023.findings-emnlp.286</url>
      <bibkey>zhou-etal-2023-non-compositional</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.286</doi>
    </paper>
    <paper id="287">
      <title>Information Extraction from Legal Wills: How Well Does <fixed-case>GPT</fixed-case>-4 Do?</title>
      <author><first>Alice</first><last>Kwak</last></author>
      <author><first>Cheonkam</first><last>Jeong</last></author>
      <author><first>Gaetano</first><last>Forte</last></author>
      <author><first>Derek</first><last>Bambauer</last></author>
      <author><first>Clayton</first><last>Morrison</last></author>
      <author><first>Mihai</first><last>Surdeanu</last></author>
      <pages>4336-4353</pages>
      <abstract>This work presents a manually annotated dataset for Information Extraction (IE) from legal wills, and relevant in-context learning experiments on the dataset. The dataset consists of entities, binary relations between the entities (e.g., relations between testator and beneficiary), and n-ary events (e.g., bequest) extracted from 45 legal wills from two US states. This dataset can serve as a foundation for downstream tasks in the legal domain. Another use case of this dataset is evaluating the performance of large language models (LLMs) on this IE task. We evaluated GPT-4 with our dataset to investigate its ability to extract information from legal wills. Our evaluation result demonstrates that the model is capable of handling the task reasonably well. When given instructions and examples as a prompt, GPT-4 shows decent performance for both entity extraction and relation extraction tasks. Nevertheless, the evaluation result also reveals that the model is not perfect. We observed inconsistent outputs (given a prompt) as well as prompt over-generalization.</abstract>
      <url hash="61b97295">2023.findings-emnlp.287</url>
      <bibkey>kwak-etal-2023-information</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.287</doi>
    </paper>
    <paper id="288">
      <title>Transparency at the Source: Evaluating and Interpreting Language Models With Access to the True Distribution</title>
      <author><first>Jaap</first><last>Jumelet</last></author>
      <author><first>Willem</first><last>Zuidema</last></author>
      <pages>4354-4369</pages>
      <abstract>We present a setup for training, evaluating and interpreting neural language models, that uses artificial, language-like data. The data is generated using a massive probabilistic grammar (based on state-split PCFGs), that is itself derived from a large natural language corpus, but also provides us complete control over the generative process. We describe and release both grammar and corpus, and test for the naturalness of our generated data. This approach allows us define closed-form expressions to efficiently compute exact lower bounds on obtainable perplexity using both causal and masked language modelling. Our results show striking differences between neural language modelling architectures and training objectives in how closely they allow approximating the lower bound on perplexity. Our approach also allows us to directly compare learned representations to symbolic rules in the underlying source. We experiment with various techniques for interpreting model behaviour and learning dynamics. With access to the underlying true source, our results show striking differences and outcomes in learning dynamics between different classes of words.</abstract>
      <url hash="114d6d64">2023.findings-emnlp.288</url>
      <bibkey>jumelet-zuidema-2023-transparency</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.288</doi>
    </paper>
    <paper id="289">
      <title>Continual Generalized Intent Discovery: Marching Towards Dynamic and Open-world Intent Recognition</title>
      <author><first>Xiaoshuai</first><last>Song</last></author>
      <author><first>Yutao</first><last>Mou</last></author>
      <author><first>Keqing</first><last>He</last></author>
      <author><first>Yueyan</first><last>Qiu</last></author>
      <author><first>Jinxu</first><last>Zhao</last></author>
      <author><first>Pei</first><last>Wang</last></author>
      <author><first>Weiran</first><last>Xu</last></author>
      <pages>4370-4382</pages>
      <abstract>In a practical dialogue system, users may input out-of-domain (OOD) queries. The Generalized Intent Discovery (GID) task aims to discover OOD intents from OOD queries and extend them to the in-domain (IND) classifier. However, GID only considers one stage of OOD learning, and needs to utilize the data in all previous stages for joint training, which limits its wide application in reality. In this paper, we introduce a new task, Continual Generalized Intent Discovery (CGID), which aims to continuously and automatically discover OOD intents from dynamic OOD data streams and then incrementally add them to the classifier with almost no previous data, thus moving towards dynamic intent recognition in an open world. Next, we propose a method called Prototype-guided Learning with Replay and Distillation (PLRD) for CGID, which bootstraps new intent discovery through class prototypes and balances new and old intents through data replay and feature distillation. Finally, we conduct detailed experiments and analysis to verify the effectiveness of PLRD and understand the key challenges of CGID for future research.</abstract>
      <url hash="2ad26432">2023.findings-emnlp.289</url>
      <bibkey>song-etal-2023-continual</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.289</doi>
    </paper>
    <paper id="290">
      <title>Frugal Prompting for Dialog Models</title>
      <author><first>Bishal</first><last>Santra</last></author>
      <author><first>Sakya</first><last>Basak</last></author>
      <author><first>Abhinandan</first><last>De</last></author>
      <author><first>Manish</first><last>Gupta</last></author>
      <author><first>Pawan</first><last>Goyal</last></author>
      <pages>4383-4407</pages>
      <abstract>The use of large language models (LLMs) in natural language processing (NLP) tasks is rapidly increasing, leading to changes in how researchers approach problems in the field. To fully utilize these models’ abilities, a better understanding of their behavior for different input protocols is required. With LLMs, users can directly interact with the models through a text-based interface to define and solve various tasks. Hence, understanding the conversational abilities of these LLMs, which may not have been specifically trained for dialog modeling, is also important. This study examines different approaches for building dialog systems using LLMs by considering various aspects of the prompt. As part of prompt tuning, we experiment with various ways of providing instructions, exemplars, current query and additional context. The research also analyzes the representations of dialog history that have the optimal usable-information density. Based on the findings, the paper suggests more compact ways of providing dialog history information while ensuring good performance and reducing model’s inference-API costs. The research contributes to a better understanding of how LLMs can be effectively used for building interactive systems.</abstract>
      <url hash="ca80f6ab">2023.findings-emnlp.290</url>
      <bibkey>santra-etal-2023-frugal</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.290</doi>
    </paper>
    <paper id="291">
      <title>The Interpreter Understands Your Meaning: End-to-end Spoken Language Understanding Aided by Speech Translation</title>
      <author><first>Mutian</first><last>He</last></author>
      <author><first>Philip</first><last>Garner</last></author>
      <pages>4408-4423</pages>
      <abstract>End-to-end spoken language understanding (SLU) remains elusive even with current large pretrained language models on text and speech, especially in multilingual cases. Machine translation has been established as a powerful pretraining objective on text as it enables the model to capture high-level semantics of the input utterance and associations between different languages, which is desired for speech models that work on lower-level acoustic frames. Motivated particularly by the task of cross-lingual SLU, we demonstrate that the task of speech translation (ST) is a good means of pretraining speech models for end-to-end SLU on both intra- and cross-lingual scenarios. By introducing ST, our models reach higher performance over baselines on monolingual and multilingual intent classification as well as spoken question answering using SLURP, MINDS-14, and NMSQA benchmarks. To verify the effectiveness of our methods, we also create new benchmark datasets from both synthetic and real sources, for speech summarization and low-resource/zero-shot transfer from English to French or Spanish. We further show the value of preserving knowledge for the ST pretraining task for better downstream performance, possibly using Bayesian transfer regularizers.</abstract>
      <url hash="a07f4711">2023.findings-emnlp.291</url>
      <bibkey>he-garner-2023-interpreter</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.291</doi>
    </paper>
    <paper id="292">
      <title><fixed-case>M</fixed-case>ac<fixed-case>L</fixed-case>a<fixed-case>S</fixed-case>a: Multi-Aspect Controllable Text Generation via Efficient Sampling from Compact Latent Space</title>
      <author><first>Hanxing</first><last>Ding</last></author>
      <author><first>Liang</first><last>Pang</last></author>
      <author><first>Zihao</first><last>Wei</last></author>
      <author><first>Huawei</first><last>Shen</last></author>
      <author><first>Xueqi</first><last>Cheng</last></author>
      <author><first>Tat-Seng</first><last>Chua</last></author>
      <pages>4424-4436</pages>
      <abstract>Multi-aspect controllable text generation aims to generate fluent sentences that possess multiple desired attributes simultaneously. Traditional methods either require expensive iteration / searching within the discrete text space during the decoding stage, or train separate controllers for each aspect, resulting in a degradation of text quality due to the discrepancy between different aspects. To address these limitations, we introduce a novel approach for <tex-math>\textbf{M}</tex-math>ulti-<tex-math>\textbf{a}</tex-math>spect <tex-math>\textbf{c}</tex-math>ontrol, namely MacLaSa, that estimates compact <tex-math>\textbf{La}</tex-math>tent space for multiple aspects, and performs efficient <tex-math>\textbf{Sa}</tex-math>mpling with a fast sampler. To eliminate the domain discrepancies between different aspects, we first utilize a variational autoencoder (VAE) network to map text sequences from various data sources into close latent representations. The estimated latent space enables the formulation of joint energy-based models and the plugging in of arbitrary attribute discriminators to achieve multi-aspect control. Afterwards, we draw latent samples with a fast sampler based on ordinary differential equations and feed sampled examples to the VAE decoder to produce target text sequences. Experimental results demonstrate that MacLaSa outperforms strong baselines on both attribute relevance and textual quality while maintaining a high inference speed.</abstract>
      <url hash="7475a45d">2023.findings-emnlp.292</url>
      <bibkey>ding-etal-2023-maclasa</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.292</doi>
    </paper>
    <paper id="293">
      <title><fixed-case>HPE</fixed-case>: Answering Complex Questions over Text by Hybrid Question Parsing and Execution</title>
      <author><first>Ye</first><last>Liu</last></author>
      <author><first>Semih</first><last>Yavuz</last></author>
      <author><first>Rui</first><last>Meng</last></author>
      <author><first>Dragomir</first><last>Radev</last></author>
      <author><first>Caiming</first><last>Xiong</last></author>
      <author><first>Shafiq</first><last>Joty</last></author>
      <author><first>Yingbo</first><last>Zhou</last></author>
      <pages>4437-4451</pages>
      <abstract>The dominant paradigm of textual question answering systems is based on end-to-end neural networks, which excels at answering natural language questions but falls short on complex ones. This stands in contrast to the broad adaptation of semantic parsing approaches over structured data sources (e.g., relational database, knowledge graphs), that convert natural language questions to logical forms and execute them with query engines. Towards combining the strengths of neural and symbolic methods, we propose a framework of question parsing and execution on textual QA. It comprises two central pillars: (1) We parse the question of varying complexity into an intermediate representation, named H-expression, which is composed of simple questions as the primitives and symbolic operations representing the relationships among them; (2) To execute the resulting H-expressions, we design a hybrid executor, which integrates the deterministic rules to translate the symbolic operations with a drop-in neural reader network to answer each decomposed simple question. Hence, the proposed framework can be viewed as a top-down question parsing followed by a bottom-up answer backtracking. The resulting H-expressions closely guide the execution process, offering higher precision besides better interpretability while still preserving the advantages of the neural readers for resolving its primitive elements. Our extensive experiments on MuSiQue, 2WikiQA, HotpotQA, and NQ show that the proposed parsing and hybrid execution framework outperforms existing approaches in supervised, few-shot, and zero-shot settings, while also effectively exposing its underlying reasoning process.</abstract>
      <url hash="5ad43b20">2023.findings-emnlp.293</url>
      <bibkey>liu-etal-2023-hpe</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.293</doi>
    </paper>
    <paper id="294">
      <title>Length-Adaptive Distillation: Customizing Small Language Model for Dynamic Token Pruning</title>
      <author><first>Chang</first><last>Liu</last></author>
      <author><first>Chongyang</first><last>Tao</last></author>
      <author><first>Jianxin</first><last>Liang</last></author>
      <author><first>Jiazhan</first><last>Feng</last></author>
      <author><first>Tao</first><last>Shen</last></author>
      <author><first>Quzhe</first><last>Huang</last></author>
      <author><first>Dongyan</first><last>Zhao</last></author>
      <pages>4452-4463</pages>
      <abstract>Pre-trained language models greatly improve the performance of various tasks but at a cost of high computation overhead. To facilitate practical applications, there are mainly two lines of research to accelerate model inference: model compression and dynamic computation (e.g., dynamic token pruning). Existing works either adopt these methods individually or simply apply dynamic computation approaches upon a compressed small language model. We argue that they are sub-optimal since the two approaches are separately designed so the compressed model may not be tailored for dynamic computation. To tackle this problem and make compressed small language models faster, we propose Length-Adaptive Distillation, a two-stage knowledge distillation framework that aims to produce a customized small language model for dynamic token pruning. In the general distillation stage, we enforce the student to mimic and reconstruct the teacher’s output based on the dynamically pruned representations. Then in the task-specific distillation stage, the student is further accustomed to token pruning while absorbing the task-specific knowledge. Experimental results on GLUE benchmark demonstrate that our method can make the small language model more customized for dynamic token pruning and achieve better speed-performance trade-off.</abstract>
      <url hash="ae3f0d40">2023.findings-emnlp.294</url>
      <bibkey>liu-etal-2023-length</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.294</doi>
    </paper>
    <paper id="295">
      <title>Toxicity, Morality, and Speech Act Guided Stance Detection</title>
      <author><first>Apoorva</first><last>Upadhyaya</last></author>
      <author><first>Marco</first><last>Fisichella</last></author>
      <author><first>Wolfgang</first><last>Nejdl</last></author>
      <pages>4464-4478</pages>
      <abstract>In this work, we focus on the task of determining the public attitude toward various social issues discussed on social media platforms. Platforms such as Twitter, however, are often used to spread misinformation, fake news through polarizing views. Existing literature suggests that higher levels of toxicity prevalent in Twitter conversations often spread negativity and delay addressing issues. Further, the embedded moral values and speech acts specifying the intention of the tweet correlate with public opinions expressed on various topics. However, previous works, which mainly focus on stance detection, either ignore the speech act, toxic, and moral features of these tweets that can collectively help capture public opinion or lack an efficient architecture that can detect the attitudes across targets. Therefore, in our work, we focus on the main task of stance detection by exploiting the toxicity, morality, and speech act as auxiliary tasks. We propose a multitasking model TWISTED that initially extracts the valence, arousal, and dominance aspects hidden in the tweets and injects the emotional sense into the embedded text followed by an efficient attention framework to correctly detect the tweet’s stance by using the shared features of toxicity, morality, and speech acts present in the tweet. Extensive experiments conducted on 4 benchmark stance detection datasets (SemEval-2016, P-Stance, COVID19-Stance, and ClimateChange) comprising different domains demonstrate the effectiveness and generalizability of our approach.</abstract>
      <url hash="b01e9e7d">2023.findings-emnlp.295</url>
      <bibkey>upadhyaya-etal-2023-toxicity</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.295</doi>
    </paper>
    <paper id="296">
      <title>Reasoning about Ambiguous Definite Descriptions</title>
      <author><first>Stefan</first><last>Schouten</last></author>
      <author><first>Peter</first><last>Bloem</last></author>
      <author><first>Ilia</first><last>Markov</last></author>
      <author><first>Piek</first><last>Vossen</last></author>
      <pages>4479-4484</pages>
      <abstract>Natural language reasoning plays an increasingly important role in improving language models’ ability to solve complex language understanding tasks. An interesting use case for reasoning is the resolution of context-dependent ambiguity. But no resources exist to evaluate how well Large Language Models can use explicit reasoning to resolve ambiguity in language. We propose to use ambiguous definite descriptions for this purpose and create and publish the first benchmark dataset consisting of such phrases. Our method includes all information required to resolve the ambiguity in the prompt, which means a model does not require anything but reasoning to do well. We find this to be a challenging task for recent LLMs. Code and data available at: https://github.com/sfschouten/exploiting-ambiguity</abstract>
      <url hash="2ec2be4a">2023.findings-emnlp.296</url>
      <bibkey>schouten-etal-2023-reasoning</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.296</doi>
    </paper>
    <paper id="297">
      <title>A Framework for Bidirectional Decoding: Case Study in Morphological Inflection</title>
      <author><first>Marc</first><last>Canby</last></author>
      <author><first>Julia</first><last>Hockenmaier</last></author>
      <pages>4485-4507</pages>
      <abstract>Transformer-based encoder-decoder models that generate outputs in a left-to-right fashion have become standard for sequence-to-sequence tasks. In this paper, we propose a framework for decoding that produces sequences from the “outside-in”: at each step, the model chooses to generate a token on the left, on the right, or join the left and right sequences. We argue that this is more principled than prior bidirectional decoders. Our proposal supports a variety of model architectures and includes several training methods, such as a dynamic programming algorithm that marginalizes out the latent ordering variable. Our model sets state-of-the-art (SOTA) on the 2022 and 2023 shared tasks, beating the next best systems by over 4.7 and 2.7 points in average accuracy respectively. The model performs particularly well on long sequences, can implicitly learn the split point of words composed of stem and affix, and performs better relative to the baseline on datasets that have fewer unique lemmas.</abstract>
      <url hash="b8e7b841">2023.findings-emnlp.297</url>
      <bibkey>canby-hockenmaier-2023-framework</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.297</doi>
    </paper>
    <paper id="298">
      <title>Text-guided 3<fixed-case>D</fixed-case> Human Generation from 2<fixed-case>D</fixed-case> Collections</title>
      <author><first>Tsu-Jui</first><last>Fu</last></author>
      <author><first>Wenhan</first><last>Xiong</last></author>
      <author><first>Yixin</first><last>Nie</last></author>
      <author><first>Jingyu</first><last>Liu</last></author>
      <author><first>Barlas</first><last>Oguz</last></author>
      <author><first>William</first><last>Wang</last></author>
      <pages>4508-4520</pages>
      <abstract>3D human modeling has been widely used for engaging interaction in gaming, film, and animation. The customization of these characters is crucial for creativity and scalability, which highlights the importance of controllability. In this work, we introduce Text-guided 3D Human Generation (T3H), where a model is to generate a 3D human, guided by the fashion description. There are two goals: 1) the 3D human should render articulately, and 2) its outfit is controlled by the given text. To address this T3H task, we propose Compositional Cross-modal Human (CCH). CCH adopts cross-modal attention to fuse compositional human rendering with the extracted fashion semantics. Each human body part perceives relevant textual guidance as its visual patterns. We incorporate the human prior and semantic discrimination to enhance 3D geometry transformation and fine-grained consistency, enabling it to learn from 2D collections for data efficiency. We conduct evaluations on DeepFashion and SHHQ with diverse fashion attributes covering the shape, fabric, and color of upper and lower clothing. Extensive experiments demonstrate that CCH achieves superior results for T3H with high efficiency.</abstract>
      <url hash="ef664d37">2023.findings-emnlp.298</url>
      <bibkey>fu-etal-2023-text</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.298</doi>
    </paper>
    <paper id="299">
      <title>Statistically Profiling Biases in Natural Language Reasoning Datasets and Models</title>
      <author><first>Shanshan</first><last>Huang</last></author>
      <author><first>Kenny</first><last>Zhu</last></author>
      <pages>4521-4530</pages>
      <abstract>Recent studies have shown that many natural language understanding and reasoning datasets contain statistical cues that can be exploited by NLP models, resulting in an overestimation of their capabilities. Existing methods, such as “hypothesis-only” tests and CheckList, are limited in identifying these cues and evaluating model weaknesses. We introduce ICQ (I-See-Cue), a lightweight, general statistical profiling framework that automatically identifies potential biases in multiple-choice NLU datasets without requiring additional test cases. ICQ assesses the extent to which models exploit these biases through black-box testing, addressing the limitations of current methods. In this work, we conduct a comprehensive evaluation of statistical biases in 10 popular NLU datasets and 4 models, confirming prior findings, revealing new insights, and offering an online demonstration system to encourage users to assess their own datasets and models. Furthermore, we present a case study on investigating ChatGPT’s bias, providing valuable recommendations for practical applications.</abstract>
      <url hash="ff20ee3b">2023.findings-emnlp.299</url>
      <bibkey>huang-zhu-2023-statistically</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.299</doi>
    </paper>
    <paper id="300">
      <title>Verb Conjugation in Transformers Is Determined by Linear Encodings of Subject Number</title>
      <author><first>Sophie</first><last>Hao</last></author>
      <author><first>Tal</first><last>Linzen</last></author>
      <pages>4531-4539</pages>
      <abstract>Deep architectures such as Transformers are sometimes criticized for having uninterpretable “black-box” representations. We use causal intervention analysis to show that, in fact, some linguistic features are represented in a linear, interpretable format. Specifically, we show that BERT’s ability to conjugate verbs relies on a linear encoding of subject number that can be manipulated with predictable effects on conjugation accuracy. This encoding is found in the subject position at the first layer and the verb position at the last layer, but distributed across positions at middle layers, particularly when there are multiple cues to subject number.</abstract>
      <url hash="10744f16">2023.findings-emnlp.300</url>
      <bibkey>hao-linzen-2023-verb</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.300</doi>
    </paper>
    <paper id="301">
      <title><fixed-case>MUX</fixed-case>-<fixed-case>PLM</fixed-case>s: Data Multiplexing for High-throughput Language Models</title>
      <author><first>Vishvak</first><last>Murahari</last></author>
      <author><first>Ameet</first><last>Deshpande</last></author>
      <author><first>Carlos</first><last>Jimenez</last></author>
      <author><first>Izhak</first><last>Shafran</last></author>
      <author><first>Mingqiu</first><last>Wang</last></author>
      <author><first>Yuan</first><last>Cao</last></author>
      <author><first>Karthik</first><last>Narasimhan</last></author>
      <pages>4540-4554</pages>
      <abstract>The widespread adoption of large language models such as ChatGPT and Bard has led to unprecedented demand for these technologies. The burgeoning cost of inference for ever-increasing model sizes coupled with hardware shortages has limited affordable access and poses a pressing need for efficiency approaches geared towards high throughput and performance. Multi-input multi-output (MIMO) algorithms such as data multiplexing, offer a promising solution with a many-fold increase in throughput by performing inference for multiple inputs at the cost of a single input. Yet these approaches are not currently performant enough to be deployed in modern systems. We change that by developing MUX-PLMs, a class of high throughput pre-trained language models (PLMs) trained with data multiplexing, that can be fine-tuned for any downstream task to yield high-throughput high-performance. Our novel multiplexing and demultiplexing modules proficiently entangle and disentangle inputs, and enable high-performance high throughput MUX-PLMs that are competitive with vanilla PLMs while achieving 2x/5x inference speedup with only a 1-4 % drop on a broad suite of tasks.</abstract>
      <url hash="e32aa31c">2023.findings-emnlp.301</url>
      <bibkey>murahari-etal-2023-mux-plms</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.301</doi>
    </paper>
    <paper id="302">
      <title>That was the last straw, we need more: Are Translation Systems Sensitive to Disambiguating Context?</title>
      <author><first>Jaechan</first><last>Lee</last></author>
      <author><first>Alisa</first><last>Liu</last></author>
      <author><first>Orevaoghene</first><last>Ahia</last></author>
      <author><first>Hila</first><last>Gonen</last></author>
      <author><first>Noah</first><last>Smith</last></author>
      <pages>4555-4569</pages>
      <abstract>The translation of ambiguous text presents a challenge for translation systems, as it requires using the surrounding context to disambiguate the intended meaning as much as possible. While prior work has studied ambiguities that result from different grammatical features of the source and target language, we study semantic ambiguities that exist in the source (English in this work) itself. In particular, we focus on idioms that are open to both literal and figurative interpretations (e.g., goose egg), and collect TIDE, a dataset of 512 pairs of English sentences containing idioms with disambiguating context such that one is literal (it laid a goose egg) and another is figurative (they scored a goose egg, as in a score of zero). In experiments, we compare MT-specific models and language models for (i) their preference when given an ambiguous subsentence, (ii) their sensitivity to disambiguating context, and (iii) the performance disparity between figurative and literal source sentences. We find that current MT models consistently translate English idioms literally, even when the context suggests a figurative interpretation. On the other hand, LMs are far more context-aware, although there remain disparities across target languages. Our findings underline the potential of LMs as a strong backbone for context-aware translation.</abstract>
      <url hash="4ad0713c">2023.findings-emnlp.302</url>
      <bibkey>lee-etal-2023-last</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.302</doi>
    </paper>
    <paper id="303">
      <title><fixed-case>M</fixed-case>ind<fixed-case>G</fixed-case>ames: Targeting Theory of Mind in Large Language Models with Dynamic Epistemic Modal Logic</title>
      <author><first>Damien</first><last>Sileo</last></author>
      <author><first>Antoine</first><last>Lernould</last></author>
      <pages>4570-4577</pages>
      <abstract>Theory of Mind (ToM) is a critical component of intelligence but its assessment remains the subject of heated debates. Prior research applied human ToM assessments to natural language processing models using either human-created standardized tests or rule-based templates. However, these methods primarily focus on simplistic reasoning and require further validation. Here, we leverage dynamic epistemic logic to isolate a particular component of ToM and to generate controlled problems. We also introduce new verbalization techniques to express these problems in English natural language. Our findings indicate that some language model scaling (from 70M to 6B and 350M to 174B) does not consistently yield results better than random chance. While GPT-4 demonstrates superior epistemic reasoning capabilities, there is still room for improvement. Our code and datasets are publicly available.</abstract>
      <url hash="dd392811">2023.findings-emnlp.303</url>
      <bibkey>sileo-lernould-2023-mindgames</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.303</doi>
    </paper>
    <paper id="304">
      <title><fixed-case>LATENTLOGIC</fixed-case>: Learning Logic Rules in Latent Space over Knowledge Graphs</title>
      <author><first>Junnan</first><last>Liu</last></author>
      <author><first>Qianren</first><last>Mao</last></author>
      <author><first>Chenghua</first><last>Lin</last></author>
      <author><first>Yangqiu</first><last>Song</last></author>
      <author><first>Jianxin</first><last>Li</last></author>
      <pages>4578-4586</pages>
      <abstract>Learning logic rules for knowledge graph reasoning is essential as such rules provide interpretable explanations for reasoning and can be generalized to different domains. However, existing methods often face challenges such as searching in a vast search space (e.g., enumeration of relational paths or multiplication of high-dimensional matrices) and inefficient optimization (e.g., techniques based on reinforcement learning or EM algorithm). To address these limitations, this paper proposes a novel framework called LatentLogic to efficiently mine logic rules by controllable generation in the latent space. Specifically, to map the discrete relational paths into the latent space, we leverage a pre-trained VAE and employ a discriminator to establish an energy-based distribution. Additionally, we incorporate a sampler based on ordinary differential equations, enabling the efficient generation of logic rules in our approach. Extensive experiments on benchmark datasets demonstrate the effectiveness and efficiency of our proposed method.</abstract>
      <url hash="9f0a58b2">2023.findings-emnlp.304</url>
      <bibkey>liu-etal-2023-latentlogic</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.304</doi>
    </paper>
    <paper id="305">
      <title><fixed-case>R</fixed-case>obust<fixed-case>E</fixed-case>mbed: Robust Sentence Embeddings Using Self-Supervised Contrastive Pre-Training</title>
      <author><first>Javad</first><last>Asl</last></author>
      <author><first>Eduardo</first><last>Blanco</last></author>
      <author><first>Daniel</first><last>Takabi</last></author>
      <pages>4587-4603</pages>
      <abstract>Pre-trained language models (PLMs) have demonstrated their exceptional performance across a wide range of natural language processing tasks. The utilization of PLM-based sentence embeddings enables the generation of contextual representations that capture rich semantic information. However, despite their success with unseen samples, current PLM-based representations suffer from poor robustness in adversarial scenarios. In this paper, we propose RobustEmbed, a self-supervised sentence embedding framework that enhances both generalization and robustness in various text representation tasks and against diverse adversarial attacks. By generating high-risk adversarial perturbations to promote higher invariance in the embedding space and leveraging the perturbation within a novel contrastive objective approach, RobustEmbed effectively learns high-quality sentence embeddings. Our extensive experiments validate the superiority of RobustEmbed over previous state-of-the-art self-supervised representations in adversarial settings, while also showcasing relative improvements in seven semantic textual similarity (STS) tasks and six transfer tasks. Specifically, our framework achieves a significant reduction in attack success rate from 75.51% to 39.62% for the BERTAttack attack technique, along with enhancements of 1.20% and 0.40% in STS tasks and transfer tasks, respectively.</abstract>
      <url hash="14898bef">2023.findings-emnlp.305</url>
      <bibkey>asl-etal-2023-robustembed</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.305</doi>
    </paper>
    <paper id="306">
      <title>More than Votes? Voting and Language based Partisanship in the <fixed-case>US</fixed-case> <fixed-case>S</fixed-case>upreme <fixed-case>C</fixed-case>ourt</title>
      <author><first>Biaoyan</first><last>Fang</last></author>
      <author><first>Trevor</first><last>Cohn</last></author>
      <author><first>Timothy</first><last>Baldwin</last></author>
      <author><first>Lea</first><last>Frermann</last></author>
      <pages>4604-4614</pages>
      <abstract>Understanding the prevalence and dynamics of justice partisanship and ideology in the US Supreme Court is critical in studying jurisdiction. Most research quantifies partisanship based on voting behavior, and oral arguments in the courtroom — the last essential procedure before the final case outcome — have not been well studied for this purpose. To address this gap, we present a framework for analyzing the language of justices in the courtroom for partisan signals, and study how partisanship in speech aligns with voting patterns. Our results show that the affiliated party of justices can be predicted reliably from their oral contributions. We further show a strong correlation between language partisanship and voting ideology.</abstract>
      <url hash="f38877c9">2023.findings-emnlp.306</url>
      <bibkey>fang-etal-2023-votes</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.306</doi>
    </paper>
    <paper id="307">
      <title>Automatic Evaluation of Attribution by Large Language Models</title>
      <author><first>Xiang</first><last>Yue</last></author>
      <author><first>Boshi</first><last>Wang</last></author>
      <author><first>Ziru</first><last>Chen</last></author>
      <author><first>Kai</first><last>Zhang</last></author>
      <author><first>Yu</first><last>Su</last></author>
      <author><first>Huan</first><last>Sun</last></author>
      <pages>4615-4635</pages>
      <abstract>A recent focus of large language model (LLM) development, as exemplified by generative search engines, is to incorporate external references to generate and support its claims. However, evaluating the attribution, i.e., verifying whether the generated statement is fully supported by the cited reference, remains an open problem. Although human evaluation is common practice, it is costly and time-consuming. In this paper, we investigate automatic evaluation of attribution given by LLMs. We begin by defining different types of attribution errors, and then explore two approaches for automatic evaluation: prompting LLMs and fine-tuning smaller LMs. The fine-tuning data is repurposed from related tasks such as question answering, fact-checking, natural language inference, and summarization. We manually curate a set of test examples covering 12 domains from a generative search engine, New Bing. Our results on this curated test set and simulated examples from existing benchmarks highlight both promising signals and challenges. We hope our problem formulation, testbeds, and findings will help lay the foundation for future studies on this important problem.</abstract>
      <url hash="93732135">2023.findings-emnlp.307</url>
      <bibkey>yue-etal-2023-automatic</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.307</doi>
    </paper>
    <paper id="308">
      <title>Modeling Highlighting of Metaphors in Multitask Contrastive Learning Paradigms</title>
      <author><first>Meghdut</first><last>Sengupta</last></author>
      <author><first>Milad</first><last>Alshomary</last></author>
      <author><first>Ingrid</first><last>Scharlau</last></author>
      <author><first>Henning</first><last>Wachsmuth</last></author>
      <pages>4636-4659</pages>
      <abstract>Metaphorical language, such as “spending time together”, projects meaning from a source domain (here, <tex-math>\textit{money}</tex-math>) to a target domain (<tex-math>\textit{time}</tex-math>). Thereby, it highlights certain aspects of the target domain, such as the <tex-math>\textit{effort}</tex-math> behind the time investment. Highlighting aspects with metaphors (while hiding others) bridges the two domains and is the core of metaphorical meaning construction. For metaphor interpretation, linguistic theories stress that identifying the highlighted aspects is important for a better understanding of metaphors. However, metaphor research in NLP has not yet dealt with the phenomenon of highlighting. In this paper, we introduce the task of identifying the main aspect highlighted in a metaphorical sentence. Given the inherent interaction of source domains and highlighted aspects, we propose two multitask approaches - a joint learning approach and a continual learning approach - based on a finetuned contrastive learning model to jointly predict highlighted aspects and source domains. We further investigate whether (predicted) information about a source domain leads to better performance in predicting the highlighted aspects, and vice versa. Our experiments on an existing corpus suggest that, with the corresponding information, the performance to predict the other improves in terms of model accuracy in predicting highlighted aspects and source domains notably compared to the single-task baselines.</abstract>
      <url hash="de3e3103">2023.findings-emnlp.308</url>
      <bibkey>sengupta-etal-2023-modeling</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.308</doi>
    </paper>
    <paper id="309">
      <title><fixed-case>LDM</fixed-case><tex-math>^2</tex-math>: A Large Decision Model Imitating Human Cognition with Dynamic Memory Enhancement</title>
      <author><first>Xingjin</first><last>Wang</last></author>
      <author><first>Linjing</first><last>Li</last></author>
      <author><first>Daniel</first><last>Zeng</last></author>
      <pages>4660-4681</pages>
      <abstract>With the rapid development of large language models (LLMs), it is highly demanded that LLMs can be adopted to make decisions to enable the artificial general intelligence. Most approaches leverage manually crafted examples to prompt the LLMs to imitate the decision process of human. However, designing optimal prompts is difficult and the patterned prompts can hardly be generalized to more complex environments. In this paper, we propose a novel model named Large Decision Model with Memory (LDM<tex-math>^2</tex-math>), which leverages a dynamic memory mechanism to construct dynamic prompts, guiding the LLMs in making proper decisions according to the faced state. LDM<tex-math>^2</tex-math> consists of two stages: memory formation and memory refinement. In the former stage, human behaviors are decomposed into state-action tuples utilizing the powerful summarizing ability of LLMs. Then, these tuples are stored in the memory, whose indices are generated by the LLMs, to facilitate the retrieval of the most relevant subset of memorized tuples based on the current state. In the latter stage, our LDM<tex-math>^2</tex-math> employs tree exploration to discover more suitable decision processes and enrich the memory by adding valuable state-action tuples. The dynamic circle of exploration and memory enhancement provides LDM<tex-math>^2</tex-math> a better understanding of the global environment. Extensive experiments conducted in two interactive environments have shown that our LDM<tex-math>^2</tex-math> outperforms the baselines in terms of both score and success rate, which demonstrates its effectiveness.</abstract>
      <url hash="98ed2140">2023.findings-emnlp.309</url>
      <bibkey>wang-etal-2023-ldm2</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.309</doi>
    </paper>
    <paper id="310">
      <title><fixed-case>ZARA</fixed-case>: Improving Few-Shot Self-Rationalization for Small Language Models</title>
      <author><first>Wei-Lin</first><last>Chen</last></author>
      <author><first>An-Zi</first><last>Yen</last></author>
      <author><first>Cheng-Kuang</first><last>Wu</last></author>
      <author><first>Hen-Hsen</first><last>Huang</last></author>
      <author><first>Hsin-Hsi</first><last>Chen</last></author>
      <pages>4682-4693</pages>
      <abstract>Language models (LMs) that jointly generate end-task answers as well as free-text rationales are known as self-rationalization models. Recent works demonstrate great performance gain for self-rationalization by few-shot prompting LMs with rationale-augmented exemplars. However, the ability to benefit from explanations only emerges with large-scale LMs, which have poor accessibility. In this work, we explore the less-studied setting of leveraging explanations for small LMs to improve few-shot self-rationalization. We first revisit the relationship between rationales and answers. Inspired by the implicit mental process of how human beings assess explanations, we present a novel approach, Zero-shot Augmentation of Rationale-Answer pairs (ZARA), to automatically construct pseudo-parallel data for self-training by reducing the problem of plausibility judgement to natural language inference. Experimental results show ZARA achieves SOTA performance on the FEB benchmark, for both the task accuracy and the explanation metric. In addition, we conduct human and quantitative evaluation validating ZARA’s ability to automatically identify plausible and accurate rationale-answer pairs.</abstract>
      <url hash="eaab7945">2023.findings-emnlp.310</url>
      <bibkey>chen-etal-2023-zara</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.310</doi>
    </paper>
    <paper id="311">
      <title><fixed-case>T</fixed-case>oxic<fixed-case>C</fixed-case>hat: Unveiling Hidden Challenges of Toxicity Detection in Real-World User-<fixed-case>AI</fixed-case> Conversation</title>
      <author><first>Zi</first><last>Lin</last></author>
      <author><first>Zihan</first><last>Wang</last></author>
      <author><first>Yongqi</first><last>Tong</last></author>
      <author><first>Yangkun</first><last>Wang</last></author>
      <author><first>Yuxin</first><last>Guo</last></author>
      <author><first>Yujia</first><last>Wang</last></author>
      <author><first>Jingbo</first><last>Shang</last></author>
      <pages>4694-4702</pages>
      <abstract>Despite remarkable advances that large language models have achieved in chatbots nowadays, maintaining a non-toxic user-AI interactive environment has become increasingly critical nowadays. However, previous efforts in toxicity detection have been mostly based on benchmarks derived from social media contents, leaving the unique challenges inherent to real-world user-AI interactions insufficiently explored. In this work, we introduce ToxicChat, a novel benchmark constructed based on real user queries from an open-source chatbot. This benchmark contains the rich, nuanced phenomena that can be tricky for current toxicity detection models to identify, revealing a significant domain difference when compared to social media contents. Our systematic evaluation of models trained on existing toxicity datasets has shown their shortcomings when applied to this unique domain of ToxicChat. Our work illuminates the potentially overlooked challenges of toxicity detection in real-world user-AI conversations. In the future, ToxicChat can be a valuable resource to drive further advancements toward building a safe and healthy environment for user-AI interactions.</abstract>
      <url hash="a9322d2d">2023.findings-emnlp.311</url>
      <bibkey>lin-etal-2023-toxicchat</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.311</doi>
    </paper>
    <paper id="312">
      <title>Mind the Gap: Automated Corpus Creation for Enthymeme Detection and Reconstruction in Learner Arguments</title>
      <author><first>Maja</first><last>Stahl</last></author>
      <author><first>Nick</first><last>Düsterhus</last></author>
      <author><first>Mei-Hua</first><last>Chen</last></author>
      <author><first>Henning</first><last>Wachsmuth</last></author>
      <pages>4703-4717</pages>
      <abstract>Writing strong arguments can be challenging for learners. It requires to select and arrange multiple argumentative discourse units (ADUs) in a logical and coherent way as well as to decide which ADUs to leave implicit, so called enthymemes. However, when important ADUs are missing, readers might not be able to follow the reasoning or understand the argument’s main point. This paper introduces two new tasks for learner arguments: to identify gaps in arguments (enthymeme detection) and to fill such gaps (enthymeme reconstruction). Approaches to both tasks may help learners improve their argument quality. We study how corpora for these tasks can be created automatically by deleting ADUs from an argumentative text that are central to the argument and its quality, while maintaining the text’s naturalness. Based on the ICLEv3 corpus of argumentative learner essays, we create 40,089 argument instances for enthymeme detection and reconstruction. Through manual studies, we provide evidence that the proposed corpus creation process leads to the desired quality reduction, and results in arguments that are similarly natural to those written by learners. Finally, first baseline approaches to enthymeme detection and reconstruction demonstrate the corpus’ usefulness.</abstract>
      <url hash="01a500f2">2023.findings-emnlp.312</url>
      <bibkey>stahl-etal-2023-mind</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.312</doi>
    </paper>
    <paper id="313">
      <title>Dior-<fixed-case>CVAE</fixed-case>: Pre-trained Language Models and Diffusion Priors for Variational Dialog Generation</title>
      <author><first>Tianyu</first><last>Yang</last></author>
      <author><first>Thy</first><last>Tran</last></author>
      <author><first>Iryna</first><last>Gurevych</last></author>
      <pages>4718-4735</pages>
      <abstract>Current variational dialog models have employed pre-trained language models (PLMs) to parameterize the likelihood and posterior distributions. However, the Gaussian assumption made on the prior distribution is incompatible with these distributions, thus restricting the diversity of generated responses. These models also suffer from posterior collapse, i.e., the decoder tends to ignore latent variables and directly access information captured in the encoder through the cross-attention mechanism. In this work, we propose Dior-CVAE, a hierarchical conditional variational autoencoder (CVAE) with diffusion priors to address these challenges. We employ a diffusion model to increase the complexity of the prior distribution and its compatibility with the distributions produced by a PLM. Also, we propose memory dropout to the cross-attention mechanism, which actively encourages the use of latent variables for response generation. Overall, experiments across two commonly used open-domain dialog datasets show that our method can generate more diverse responses without large-scale dialog pre-training. Code is available at https://github.com/UKPLab/dior-cvae.</abstract>
      <url hash="131cf9b4">2023.findings-emnlp.313</url>
      <bibkey>yang-etal-2023-dior</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.313</doi>
    </paper>
    <paper id="314">
      <title>Retrieving Multimodal Information for Augmented Generation: A Survey</title>
      <author><first>Ruochen</first><last>Zhao</last></author>
      <author><first>Hailin</first><last>Chen</last></author>
      <author><first>Weishi</first><last>Wang</last></author>
      <author><first>Fangkai</first><last>Jiao</last></author>
      <author><first>Xuan Long</first><last>Do</last></author>
      <author><first>Chengwei</first><last>Qin</last></author>
      <author><first>Bosheng</first><last>Ding</last></author>
      <author><first>Xiaobao</first><last>Guo</last></author>
      <author><first>Minzhi</first><last>Li</last></author>
      <author><first>Xingxuan</first><last>Li</last></author>
      <author><first>Shafiq</first><last>Joty</last></author>
      <pages>4736-4756</pages>
      <abstract>As Large Language Models (LLMs) become popular, there emerged an important trend of using multimodality to augment the LLMs’ generation ability, which enables LLMs to better interact with the world. However, there lacks a unified perception of at which stage and how to incorporate different modalities. In this survey, we review methods that assist and augment generative models by retrieving multimodal knowledge, whose formats range from images, codes, tables, graphs, to audio. Such methods offer a promising solution to important concerns such as factuality, reasoning, interpretability, and robustness. By providing an in-depth review, this survey is expected to provide scholars with a deeper understanding of the methods’ applications and encourage them to adapt existing techniques to the fast-growing field of LLMs.</abstract>
      <url hash="6c55431b">2023.findings-emnlp.314</url>
      <bibkey>zhao-etal-2023-retrieving</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.314</doi>
    </paper>
    <paper id="315">
      <title>Improving Contrastive Learning of Sentence Embeddings with Focal <fixed-case>I</fixed-case>nfo<fixed-case>NCE</fixed-case></title>
      <author><first>Pengyue</first><last>Hou</last></author>
      <author><first>Xingyu</first><last>Li</last></author>
      <pages>4757-4762</pages>
      <abstract>The recent success of SimCSE has greatly advanced state-of-the-art sentence representations. However, the original formulation of SimCSE does not fully exploit the potential of hard negative samples in contrastive learning. This study introduces an unsupervised contrastive learning framework that combines SimCSE with hard negative mining, aiming to enhance the quality of sentence embeddings. The proposed focal-InfoNCE function introduces self-paced modulation terms in the contrastive objective, downweighting the loss associated with easy negatives and encouraging the model focusing on hard negatives. Experimentation on various STS benchmarks shows that our method improves sentence embeddings in terms of Spearman’s correlation and representation alignment and uniformity.</abstract>
      <url hash="894fb60e">2023.findings-emnlp.315</url>
      <bibkey>hou-li-2023-improving</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.315</doi>
    </paper>
    <paper id="316">
      <title>The Vault: A Comprehensive Multilingual Dataset for Advancing Code Understanding and Generation</title>
      <author><first>Dung</first><last>Nguyen</last></author>
      <author><first>Le</first><last>Nam</last></author>
      <author><first>Anh</first><last>Dau</last></author>
      <author><first>Anh</first><last>Nguyen</last></author>
      <author><first>Khanh</first><last>Nghiem</last></author>
      <author><first>Jin</first><last>Guo</last></author>
      <author><first>Nghi</first><last>Bui</last></author>
      <pages>4763-4788</pages>
      <abstract>We present The Vault, an open-source dataset of high quality code-text pairs in multiple programming languages for training large language models to understand and generate code. We propose methods for thoroughly extracting samples that use both rules and deep learning to ensure that they contain high-quality pairs of code and text, resulting in a dataset of 43 million high-quality code-text pairs. We thoroughly evaluated this dataset and discovered that when used to train common code language models (such as CodeT5, CodeBERT, and CodeGen), it outperforms the same models train on other datasets such as CodeSearchNet. These evaluations included common coding tasks such as code generation, code summarization, and code search. The Vault can be used by researchers and practitioners to train a wide range of big language models that understand code. Alternatively, researchers can use our data cleaning methods and scripts to improve their own datasets. We anticipate that using The Vault to train large language models will improve their ability to understand and generate code, propelling AI research and software development forward. We are releasing our source code and a framework to make it easier for others to replicate our results.</abstract>
      <url hash="e300f211">2023.findings-emnlp.316</url>
      <bibkey>nguyen-etal-2023-vault</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.316</doi>
    </paper>
    <paper id="317">
      <title><fixed-case>SDOH</fixed-case>-<fixed-case>NLI</fixed-case>: a Dataset for Inferring Social Determinants of Health from Clinical Notes</title>
      <author><first>Adam</first><last>Lelkes</last></author>
      <author><first>Eric</first><last>Loreaux</last></author>
      <author><first>Tal</first><last>Schuster</last></author>
      <author><first>Ming-Jun</first><last>Chen</last></author>
      <author><first>Alvin</first><last>Rajkomar</last></author>
      <pages>4789-4798</pages>
      <abstract>Social and behavioral determinants of health (SDOH) play a significant role in shaping health outcomes, and extracting these determinants from clinical notes is a first step to help healthcare providers systematically identify opportunities to provide appropriate care and address disparities. Progress on using NLP methods for this task has been hindered by the lack of high-quality publicly available labeled data, largely due to the privacy and regulatory constraints on the use of real patients’ information. This paper introduces a new dataset, SDOH-NLI, that is based on publicly available notes and which we release publicly. We formulate SDOH extraction as a natural language inference task, and provide binary textual entailment labels obtained from human raters for a cross product of a set of social history snippets as premises and SDOH factors as hypotheses. Our dataset differs from standard NLI benchmarks in that our premises and hypotheses are obtained independently. We evaluate both “off-the-shelf” entailment models as well as models fine-tuned on our data, and highlight the ways in which our dataset appears more challenging than commonly used NLI datasets.</abstract>
      <url hash="2a3f75ba">2023.findings-emnlp.317</url>
      <bibkey>lelkes-etal-2023-sdoh</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.317</doi>
    </paper>
    <paper id="318">
      <title>On the Zero-Shot Generalization of Machine-Generated Text Detectors</title>
      <author><first>Xiao</first><last>Pu</last></author>
      <author><first>Jingyu</first><last>Zhang</last></author>
      <author><first>Xiaochuang</first><last>Han</last></author>
      <author><first>Yulia</first><last>Tsvetkov</last></author>
      <author><first>Tianxing</first><last>He</last></author>
      <pages>4799-4808</pages>
      <abstract>The rampant proliferation of large language models, fluent enough to generate text indistinguishable from human-written language, gives unprecedented importance to the detection of machine-generated text. This work is motivated by an important research question: How will the detectors of machine-generated text perform on outputs of a new generator, that the detectors were not trained on? We begin by collecting generation data from a wide range of LLMs, and train neural detectors on data from each generator and test its performance on held-out generators. While none of the detectors can generalize to all generators, we observe a consistent and interesting pattern that the detectors trained on data from a medium-size LLM can zero-shot generalize to the larger version. As a concrete application, we demonstrate that robust detectors can be built on an ensemble of training data from medium-sized models.</abstract>
      <url hash="1078afa8">2023.findings-emnlp.318</url>
      <bibkey>pu-etal-2023-zero</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.318</doi>
    </paper>
    <paper id="319">
      <title>Complex Event Schema Induction with Knowledge-Enriched Diffusion Model</title>
      <author><first>Yupu</first><last>Hao</last></author>
      <author><first>Pengfei</first><last>Cao</last></author>
      <author><first>Yubo</first><last>Chen</last></author>
      <author><first>Kang</first><last>Liu</last></author>
      <author><first>Jiexin</first><last>Xu</last></author>
      <author><first>Huaijun</first><last>Li</last></author>
      <author><first>Xiaojian</first><last>Jiang</last></author>
      <author><first>Jun</first><last>Zhao</last></author>
      <pages>4809-4825</pages>
      <abstract>The concept of a complex event schema pertains to the graph structure that represents real-world knowledge of events and their multi-dimensional relationships. However, previous studies on event schema induction have been hindered by challenges such as error propagation and data quality issues. To tackle these challenges, we propose a knowledge-enriched discrete diffusion model. Specifically, we distill the abundant event scenario knowledge of Large Language Models (LLMs) through an object-oriented Python style prompt. We incorporate this knowledge into the training data, enhancing its quality. Subsequently, we employ a discrete diffusion process to generate all nodes and links simultaneously in a non-auto-regressive manner to tackle the problem of error propagation. Additionally, we devise an entity relationship prediction module to complete entity relationships between event arguments. Experimental results demonstrate that our approach achieves outstanding performance across a range of evaluation metrics.</abstract>
      <url hash="982db73b">2023.findings-emnlp.319</url>
      <bibkey>hao-etal-2023-complex</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.319</doi>
    </paper>
    <paper id="320">
      <title>Exploiting Emotion-Semantic Correlations for Empathetic Response Generation</title>
      <author><first>Zhou</first><last>Yang</last></author>
      <author><first>Zhaochun</first><last>Ren</last></author>
      <author><first>Wang</first><last>Yufeng</last></author>
      <author><first>Xiaofei</first><last>Zhu</last></author>
      <author><first>Zhihao</first><last>Chen</last></author>
      <author><first>Tiecheng</first><last>Cai</last></author>
      <author><first>Wu</first><last>Yunbing</last></author>
      <author><first>Yisong</first><last>Su</last></author>
      <author><first>Sibo</first><last>Ju</last></author>
      <author><first>Xiangwen</first><last>Liao</last></author>
      <pages>4826-4837</pages>
      <abstract>Empathetic response generation aims to generate empathetic responses by understanding the speaker’s emotional feelings from the language of dialogue. Recent methods capture emotional words in the language of communicators and construct them as static vectors to perceive nuanced emotions. However, linguistic research has shown that emotional words in language are dynamic and have correlations with other grammar semantic roles, i.e., words with semantic meanings, in grammar. Previous methods overlook these two characteristics, which easily lead to misunderstandings of emotions and neglect of key semantics. To address this issue, we propose a dynamical Emotion-Semantic Correlation Model (ESCM) for empathetic dialogue generation tasks. ESCM constructs dynamic emotion-semantic vectors through the interaction of context and emotions. We introduce dependency trees to reflect the correlations between emotions and semantics. Based on dynamic emotion-semantic vectors and dependency trees, we propose a dynamic correlation graph convolutional network to guide the model in learning context meanings in dialogue and generating empathetic responses. Experimental results on the EMPATHETIC-DIALOGUES dataset show that ESCM understands semantics and emotions more accurately and expresses fluent and informative empathetic responses. Our analysis results also indicate that the correlations between emotions and semantics are frequently used in dialogues, which is of great significance for empathetic perception and expression.</abstract>
      <url hash="f77fb406">2023.findings-emnlp.320</url>
      <bibkey>yang-etal-2023-exploiting-emotion</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.320</doi>
    </paper>
    <paper id="321">
      <title>Long-Range Language Modeling with Selective Cache</title>
      <author><first>Xinting</first><last>Huang</last></author>
      <author><first>Nora</first><last>Hollenstein</last></author>
      <pages>4838-4858</pages>
      <abstract>The computational cost of transformer-based language models grows quadratically with the sequence length. In this paper, we introduce the selective cache, which stores the selected key-value pairs from the previous context. By selecting important key-value pairs the model makes better use of the cache so that in limited cache size, a longer context history can be stored. We design three kinds of selection methods. The first is based on human language processing. The key-value pairs are selected if they correspond to tokens that are fixated longer, as recorded in eye-tracking-while-reading experiments. We also incorporate the cognitively-inspired selection process into the language model as a trainable process, resulting in two additional methods with improved performance. The selection task is converted into a pruning task so they can be trained with differentiable masks. We demonstrate that the proposed selective cache improves the language modeling performance across different datasets. With the same number of stored key-value pairs (cache size), our selective cache outperforms XL cache and compressive cache by considerable margins.</abstract>
      <url hash="f55e5bdb">2023.findings-emnlp.321</url>
      <bibkey>huang-hollenstein-2023-long</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.321</doi>
    </paper>
    <paper id="322">
      <title>Medical Text Simplification: Optimizing for Readability with Unlikelihood Training and Reranked Beam Search Decoding</title>
      <author><first>Lorenzo Jaime Yu</first><last>Flores</last></author>
      <author><first>Heyuan</first><last>Huang</last></author>
      <author><first>Kejian</first><last>Shi</last></author>
      <author><first>Sophie</first><last>Chheang</last></author>
      <author><first>Arman</first><last>Cohan</last></author>
      <pages>4859-4873</pages>
      <abstract>Text simplification has emerged as an increasingly useful application of AI for bridging the communication gap in specialized fields such as medicine, where the lexicon is often dominated by technical jargon and complex constructs. Despite notable progress, methods in medical simplification sometimes result in the generated text having lower quality and diversity. In this work, we explore ways to further improve the readability of text simplification in the medical domain. We propose (1) a new unlikelihood loss that encourages generation of simpler terms and (2) a reranked beam search decoding method that optimizes for simplicity, which achieve better performance on readability metrics on three datasets. This study’s findings offer promising avenues for improving text simplification in the medical field.</abstract>
      <url hash="8746b009">2023.findings-emnlp.322</url>
      <bibkey>flores-etal-2023-medical</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.322</doi>
    </paper>
    <paper id="323">
      <title><fixed-case>F</fixed-case>a<fixed-case>LA</fixed-case>: Fast Linear Adaptation for Replacing Backbone Models on Edge Devices</title>
      <author><first>Shuo</first><last>Huang</last></author>
      <author><first>Lizhen</first><last>Qu</last></author>
      <author><first>Xingliang</first><last>Yuan</last></author>
      <author><first>Chunyang</first><last>Chen</last></author>
      <pages>4874-4885</pages>
      <abstract>In this work, we study the language model backbone replacement problem for personalized downstream tasks in a non-stationary on-device scenario. In real world, company may periodically update the knowledge and architectures of backbones to keep the competitive in the market, meanwhile, to accommodate the users’ own preference, models are personalized to fit users’ own distribution locally. Traditional full model tuning or transfer learning for such replacements often incur considerable local device training costs and necessitate extensive backpropagation within deep transformer layers. Addressing this issue, we propose a novel, lightweight tuning method for personalized NLP classification tasks post-backbone replacement. Our approach leverages a personalized matrix calculated from documents corresponding to users’ old and new backbones. This matrix facilitates top-layer parameter tuning, drastically reducing backpropagation computation. To further mitigate training costs associated with matrix linear optimization, we employ correlation clustering to curate a few examples from personalized cluster sets for individuals. Our method achieves over 1000 times computation reduction in Flops for backpropagation and brings the user-specific initialization for personal matrix yielding significant performance boost compared with popular transfer learning methods.</abstract>
      <url hash="73588cc7">2023.findings-emnlp.323</url>
      <bibkey>huang-etal-2023-fala</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.323</doi>
    </paper>
    <paper id="324">
      <title>Intuitive Multilingual Audio-Visual Speech Recognition with a Single-Trained Model</title>
      <author><first>Joanna</first><last>Hong</last></author>
      <author><first>Se</first><last>Park</last></author>
      <author><first>Yong</first><last>Ro</last></author>
      <pages>4886-4890</pages>
      <abstract>We present a novel approach to multilingual audio-visual speech recognition tasks by introducing a single model on a multilingual dataset. Motivated by a human cognitive system where humans can intuitively distinguish different languages without any conscious effort or guidance, we propose a model that can capture which language is given as an input speech by distinguishing the inherent similarities and differences between languages. To do so, we design a prompt fine-tuning technique into the largely pre-trained audio-visual representation model so that the network can recognize the language class as well as the speech with the corresponding language. Our work contributes to developing robust and efficient multilingual audio-visual speech recognition systems, reducing the need for language-specific models.</abstract>
      <url hash="0329e868">2023.findings-emnlp.324</url>
      <bibkey>hong-etal-2023-intuitive</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.324</doi>
    </paper>
    <paper id="325">
      <title>Controllable Chest <fixed-case>X</fixed-case>-Ray Report Generation from Longitudinal Representations</title>
      <author><first>Francesco</first><last>Dalla Serra</last></author>
      <author><first>Chaoyang</first><last>Wang</last></author>
      <author><first>Fani</first><last>Deligianni</last></author>
      <author><first>Jeff</first><last>Dalton</last></author>
      <author><first>Alison</first><last>O’Neil</last></author>
      <pages>4891-4904</pages>
      <abstract>Radiology reports are detailed text descriptions of the content of medical scans. Each report describes the presence/absence and location of relevant clinical findings, commonly including comparison with prior exams of the same patient to describe how they evolved. Radiology reporting is a time-consuming process, and scan results are often subject to delays. One strategy to speed up reporting is to integrate automated reporting systems, however clinical deployment requires high accuracy and interpretability. Previous approaches to automated radiology reporting generally do not provide the prior study as input, precluding comparison which is required for clinical accuracy in some types of scans, and offer only unreliable methods of interpretability. Therefore, leveraging an existing visual input format of anatomical tokens, we introduce two novel aspects: (1) longitudinal representation learning – we input the prior scan as an additional input, proposing a method to align, concatenate and fuse the current and prior visual information into a joint longitudinal representation which can be provided to the multimodal report generation model; (2) sentence-anatomy dropout – a training strategy for controllability in which the report generator model is trained to predict only sentences from the original report which correspond to the subset of anatomical regions given as input. We show through in-depth experiments on the MIMIC-CXR dataset how the proposed approach achieves state-of-the-art results while enabling anatomy-wise controllable report generation.</abstract>
      <url hash="7b3ee2fb">2023.findings-emnlp.325</url>
      <bibkey>serra-etal-2023-controllable</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.325</doi>
    </paper>
    <paper id="326">
      <title>Is <fixed-case>C</fixed-case>hat<fixed-case>GPT</fixed-case> a Good Multi-Party Conversation Solver?</title>
      <author><first>Chao-Hong</first><last>Tan</last></author>
      <author><first>Jia-Chen</first><last>Gu</last></author>
      <author><first>Zhen-Hua</first><last>Ling</last></author>
      <pages>4905-4915</pages>
      <abstract>Large Language Models (LLMs) have emerged as influential instruments within the realm of natural language processing; nevertheless, their capacity to handle multi-party conversations (MPCs) – a scenario marked by the presence of multiple interlocutors involved in intricate information exchanges – remains uncharted. In this paper, we delve into the potential of generative LLMs such as ChatGPT and GPT-4 within the context of MPCs. An empirical analysis is conducted to assess the zero-shot learning capabilities of ChatGPT and GPT-4 by subjecting them to evaluation across three MPC datasets that encompass five representative tasks. The findings reveal that ChatGPT’s performance on a number of evaluated MPC tasks leaves much to be desired, whilst GPT-4’s results portend a promising future. Additionally, we endeavor to bolster performance through the incorporation of MPC structures, encompassing both speaker and addressee architecture. This study provides an exhaustive evaluation and analysis of applying generative LLMs to MPCs, casting a light upon the conception and creation of increasingly effective and robust MPC agents. Concurrently, this work underscores the challenges implicit in the utilization of LLMs for MPCs, such as deciphering graphical information flows and generating stylistically consistent responses.</abstract>
      <url hash="c77fc67e">2023.findings-emnlp.326</url>
      <bibkey>tan-etal-2023-chatgpt</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.326</doi>
    </paper>
    <paper id="327">
      <title>Improving End-to-End Speech Processing by Efficient Text Data Utilization with Latent Synthesis</title>
      <author><first>Jianqiao</first><last>Lu</last></author>
      <author><first>Wenyong</first><last>Huang</last></author>
      <author><first>Nianzu</first><last>Zheng</last></author>
      <author><first>Xingshan</first><last>Zeng</last></author>
      <author><first>Yu</first><last>Yeung</last></author>
      <author><first>Xiao</first><last>Chen</last></author>
      <pages>4916-4928</pages>
      <abstract>Training a high performance end-to-end speech (E2E) processing model requires an enormous amount of labeled speech data, especially in the era of data-centric artificial intelligence. However, labeled speech data are usually scarcer and more expensive for collection, compared to textual data. We propose Latent Synthesis (LaSyn), an efficient textual data utilization framework for E2E speech processing models. We train a latent synthesizer to convert textual data into an intermediate latent representation of a pre-trained speech model. These pseudo acoustic representations of textual data augment acoustic data for model training. We evaluate LaSyn on low-resource automatic speech recognition (ASR) and spoken language understanding (SLU) tasks. For ASR, LaSyn improves an E2E baseline trained on LibriSpeech train-clean-100, with relative word error rate reductions over 22.3% on different test sets. For SLU, LaSyn improves our E2E baseline by absolute 4.1% for intent classification accuracy and 3.8% for slot filling SLU-F1 on SLURP, and absolute 4.49% and 2.25% for exact match (EM) and EM-Tree accuracies on STOP respectively. With fewer parameters, the results of LaSyn are competitive to published state-of-the-art works. The results demonstrate the quality of the augmented training data.</abstract>
      <url hash="ac990b4a">2023.findings-emnlp.327</url>
      <bibkey>lu-etal-2023-improving</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.327</doi>
    </paper>
    <paper id="328">
      <title>Bipartite Graph Pre-training for Unsupervised Extractive Summarization with Graph Convolutional Auto-Encoders</title>
      <author><first>Qianren</first><last>Mao</last></author>
      <author><first>Shaobo</first><last>Zhao</last></author>
      <author><first>Jiarui</first><last>Li</last></author>
      <author><first>Xiaolei</first><last>Gu</last></author>
      <author><first>Shizhu</first><last>He</last></author>
      <author id="bo-li"><first>Bo</first><last>Li</last></author>
      <author><first>Jianxin</first><last>Li</last></author>
      <pages>4929-4941</pages>
      <abstract>Pre-trained sentence representations are crucial for identifying significant sentences in unsupervised document extractive summarization. However, the traditional two-step paradigm of pre-training and sentence-ranking, creates a gap due to differing optimization objectives. To address this issue, we argue that utilizing pre-trained embeddings derived from a process specifically designed to optimize informative and distinctive sentence representations helps rank significant sentences. To do so, we propose a novel graph pre-training auto-encoder to obtain sentence embeddings by explicitly modelling intra-sentential distinctive features and inter-sentential cohesive features through sentence-word bipartite graphs. These fine-tuned sentence embeddings are then utilized in a graph-based ranking algorithm for unsupervised summarization. Our method is a plug-and-play pre-trained model that produces predominant performance for unsupervised summarization frameworks by providing summary-worthy sentence representations. It surpasses heavy BERT- or RoBERTa-based sentence representations in downstream tasks.</abstract>
      <url hash="f6e5ad21">2023.findings-emnlp.328</url>
      <bibkey>mao-etal-2023-bipartite</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.328</doi>
    </paper>
    <paper id="329">
      <title><fixed-case>B</fixed-case>ayesian Multi-Task Transfer Learning for Soft Prompt Tuning</title>
      <author><first>Haeju</first><last>Lee</last></author>
      <author><first>Minchan</first><last>Jeong</last></author>
      <author><first>Se-Young</first><last>Yun</last></author>
      <author><first>Kee-Eung</first><last>Kim</last></author>
      <pages>4942-4958</pages>
      <abstract>Prompt tuning, in which prompts are optimized to adapt large-scale pre-trained language models to downstream tasks instead of fine-tuning the full model parameters, has been shown to be particularly effective when the prompts are trained in the multi-task transfer learning setting. These methods generally involve individually training prompts for each source task and then aggregating them to provide the initialization of the prompt for the target task. However, this approach critically ignores the fact that some of the source tasks could be negatively or positively interfering with each other. We argue that when we extract knowledge from source tasks via training source prompts, we need to consider this correlation among source tasks for better transfer to target tasks. To this end, we propose a Bayesian approach where we work with the posterior distribution of prompts across source tasks. We obtain representative source prompts corresponding to the samples from the posterior utilizing Stein Variational Gradient Descent, which are then aggregated to constitute the initial target prompt. We show extensive experimental results on the standard benchmark NLP tasks, where our Bayesian multi-task transfer learning approach outperforms the state-of-the-art methods in many settings. Furthermore, our approach requires no auxiliary models other than the prompt itself, achieving high degree of parameter-efficiency.</abstract>
      <url hash="2ed2799b">2023.findings-emnlp.329</url>
      <bibkey>lee-etal-2023-bayesian</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.329</doi>
    </paper>
    <paper id="330">
      <title><fixed-case>CCIM</fixed-case>: Cross-modal Cross-lingual Interactive Image Translation</title>
      <author><first>Cong</first><last>Ma</last></author>
      <author><first>Yaping</first><last>Zhang</last></author>
      <author><first>Mei</first><last>Tu</last></author>
      <author><first>Yang</first><last>Zhao</last></author>
      <author><first>Yu</first><last>Zhou</last></author>
      <author><first>Chengqing</first><last>Zong</last></author>
      <pages>4959-4965</pages>
      <abstract>Text image machine translation (TIMT) which translates source language text images into target language texts has attracted intensive attention in recent years. Although the end-to-end TIMT model directly generates target translation from encoded text image features with an efficient architecture, it lacks the recognized source language information resulting in a decrease in translation performance. In this paper, we propose a novel Cross-modal Cross-lingual Interactive Model (CCIM) to incorporate source language information by synchronously generating source language and target language results through an interactive attention mechanism between two language decoders. Extensive experimental results have shown the interactive decoder significantly outperforms end-to-end TIMT models and has faster decoding speed with smaller model size than cascade models.</abstract>
      <url hash="5e043aa8">2023.findings-emnlp.330</url>
      <bibkey>ma-etal-2023-ccim</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.330</doi>
    </paper>
    <paper id="331">
      <title><fixed-case>TRAMS</fixed-case>: Training-free Memory Selection for Long-range Language Modeling</title>
      <author><first>Haofei</first><last>Yu</last></author>
      <author><first>Cunxiang</first><last>Wang</last></author>
      <author><first>Yue</first><last>Zhang</last></author>
      <author><first>Wei</first><last>Bi</last></author>
      <pages>4966-4972</pages>
      <abstract>The Transformer architecture is crucial for numerous AI models, but it still faces challenges in long-range language modeling. Though several specific transformer architectures have been designed to tackle issues of long-range dependencies, existing methods like Transformer-XL are plagued by a high percentage of ineffective memories. In this study, we present a plug-and-play strategy, known as TRAining-free Memory Selection (TRAMS), that selects tokens participating in attention calculation based on one simple metric. This strategy allows us to keep tokens that are likely to have a high attention score with the current queries and ignore the other ones. We have tested our approach on the word-level benchmark (WikiText-103) and the character-level benchmark (enwik8), and the results indicate an improvement without having additional training or adding additional parameters.</abstract>
      <url hash="b1d9ee42">2023.findings-emnlp.331</url>
      <bibkey>yu-etal-2023-trams</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.331</doi>
    </paper>
    <paper id="332">
      <title>A Critical Analysis of Document Out-of-Distribution Detection</title>
      <author><first>Jiuxiang</first><last>Gu</last></author>
      <author><first>Yifei</first><last>Ming</last></author>
      <author><first>Yi</first><last>Zhou</last></author>
      <author><first>Jason</first><last>Kuen</last></author>
      <author><first>Vlad</first><last>Morariu</last></author>
      <author><first>Handong</first><last>Zhao</last></author>
      <author><first>Ruiyi</first><last>Zhang</last></author>
      <author><first>Nikolaos</first><last>Barmpalios</last></author>
      <author><first>Anqi</first><last>Liu</last></author>
      <author><first>Yixuan</first><last>Li</last></author>
      <author><first>Tong</first><last>Sun</last></author>
      <author><first>Ani</first><last>Nenkova</last></author>
      <pages>4973-4999</pages>
      <abstract>Large-scale pre-training is widely used in recent document understanding tasks. During deployment, one may expect that models should trigger a conservative fallback policy when encountering out-of-distribution (OOD) samples, which highlights the importance of OOD detection. However, most existing OOD detection methods focus on single-modal inputs such as images or texts. While documents are multi-modal in nature, it is underexplored if and how multi-modal information in documents can be exploited for OOD detection. In this work, we first provide a systematic and in-depth analysis on OOD detection for document understanding models. We study the effects of model modality, pre-training, and fine-tuning across various types of OOD inputs. In particular, we find that spatial information is critical for document OOD detection. To better exploit spatial information, we propose a spatial-aware adapter, which serves as a parameter-efficient add-on module to adapt transformer-based language models to the document domain. Extensive experiments show that adding the spatial-aware adapter significantly improves the OOD detection performance compared to directly using the language model and achieves superior performance compared to competitive baselines.</abstract>
      <url hash="9ebc1d79">2023.findings-emnlp.332</url>
      <bibkey>gu-etal-2023-critical</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.332</doi>
    </paper>
    <paper id="333">
      <title>Improving Neural Machine Translation by Multi-Knowledge Integration with Prompting</title>
      <author><first>Ke</first><last>Wang</last></author>
      <author><first>Jun</first><last>Xie</last></author>
      <author><first>Yuqi</first><last>Zhang</last></author>
      <author><first>Yu</first><last>Zhao</last></author>
      <pages>5000-5010</pages>
      <abstract>Improving neural machine translation (NMT) systems with prompting has achieved significant progress in recent years. In this work, we focus on how to integrate multi-knowledge, multiple types of knowledge, into NMT models to enhance the performance with prompting. We propose a unified framework, which can integrate effectively multiple types of knowledge including sentences, terminologies/phrases and translation templates into NMT models. We utilize multiple types of knowledge as prefix-prompts of input for the encoder and decoder of NMT models to guide the translation process. The approach requires no changes to the model architecture and effectively adapts to domain-specific translation without retraining. The experiments on English-Chinese and English-German translation demonstrate that our approach significantly outperform strong baselines, achieving high translation quality and terminology match accuracy.</abstract>
      <url hash="f2bc3351">2023.findings-emnlp.333</url>
      <bibkey>wang-etal-2023-improving-neural</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.333</doi>
    </paper>
    <paper id="334">
      <title>Active Learning Principles for In-Context Learning with Large Language Models</title>
      <author><first>Katerina</first><last>Margatina</last></author>
      <author><first>Timo</first><last>Schick</last></author>
      <author><first>Nikolaos</first><last>Aletras</last></author>
      <author><first>Jane</first><last>Dwivedi-Yu</last></author>
      <pages>5011-5034</pages>
      <abstract>The remarkable advancements in large language models (LLMs) have significantly enhanced predictive performance in few-shot learning settings. By using only a small number of labeled examples, referred to as demonstrations, LLMs can effectively perform the task at hand through in-context learning. However, the process of selecting demonstrations for maximizing performance has received limited attention in prior work. This paper addresses the issue of identifying the most informative demonstrations for few-shot learning by approaching it as a pool-based Active Learning (AL) problem over a single iteration. We compare standard AL algorithms based on uncertainty, diversity, and similarity, and consistently observe that the latter outperforms all other methods, including random sampling. Our extensive experimentation involving a diverse range of GPT and OPT models across 24 classification and multi-choice tasks, coupled with thorough analysis, unambiguously demonstrates the importance of using demonstrations that are semantically similar to the domain of the test examples. In fact, we show higher average classification performance using “similar” demonstrations with GPT-2 (124M) than random demonstrations with GPT-Neox (20B). Notably, while diversity sampling shows promise, uncertainty sampling, despite its success in conventional supervised learning AL scenarios, performs poorly in in-context learning.</abstract>
      <url hash="1212b0d4">2023.findings-emnlp.334</url>
      <bibkey>margatina-etal-2023-active</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.334</doi>
    </paper>
    <paper id="335">
      <title><fixed-case>I</fixed-case>nte<fixed-case>MAT</fixed-case>s: Integrating Granularity-Specific Multilingual Adapters for Cross-Lingual Transfer</title>
      <author><first>Meizhen</first><last>Liu</last></author>
      <author><first>Xu</first><last>Guo</last></author>
      <author><first>He</first><last>Jiakai</last></author>
      <author><first>Jianye</first><last>Chen</last></author>
      <author><first>Fengyu</first><last>Zhou</last></author>
      <author><first>Siu</first><last>Hui</last></author>
      <pages>5035-5049</pages>
      <abstract>Multilingual language models (MLLMs) have achieved remarkable success in various cross-lingual transfer tasks. However, they suffer poor performance in zero-shot low-resource languages, particularly when dealing with longer contexts. Existing research mainly relies on full-model fine-tuning on large parallel datasets to enhance the cross-lingual alignment of MLLMs, which is computationally expensive. In this paper, we propose InteMATs, a novel approach that integrates multilingual adapters trained on texts of different levels of granularity. To achieve this, we curate a multilingual parallel dataset comprising 42 languages to pre-train sentence-level and document-level adapters under the contrastive learning framework. Extensive experiments demonstrate the effectiveness of InteMATs in improving the cross-lingual transfer performance of MLLMs, especially on low-resource languages. Finally, our comprehensive analyses and ablation studies provide a deep understanding of the high-quality representations derived by InteMATs.</abstract>
      <url hash="6c255c29">2023.findings-emnlp.335</url>
      <bibkey>liu-etal-2023-intemats</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.335</doi>
    </paper>
    <paper id="336">
      <title><fixed-case>P</fixed-case>lug<fixed-case>M</fixed-case>ed: Improving Specificity in Patient-Centered Medical Dialogue Generation using In-Context Learning</title>
      <author><first>Chengfeng</first><last>Dou</last></author>
      <author><first>Zhi</first><last>Jin</last></author>
      <author><first>Wenpin</first><last>Jiao</last></author>
      <author><first>Haiyan</first><last>Zhao</last></author>
      <author><first>Yongqiang</first><last>Zhao</last></author>
      <author><first>Zhengwei</first><last>Tao</last></author>
      <pages>5050-5066</pages>
      <abstract>The patient-centered medical dialogue systems strive to offer diagnostic interpretation services to users who are less knowledgeable about medical knowledge, through emphasizing the importance of providing responses specific to the patients. It is difficult for the large language models (LLMs) to guarantee the specificity of responses in spite of its promising performance even in some tasks in medical field. Inspired by in-context learning, we propose PlugMed, a Plug-and-Play Medical Dialogue System, for addressing this challenge. PlugMed is equipped with two modules, the prompt generation (PG) module and the response ranking (RR) module, to enhances LLMs’ dialogue strategies for improving the specificity of the dialogue. The PG module is designed to stimulate the imitative ability of LLMs by providing them with real dialogues from similar patients as prompts. The RR module incorporates fine-tuned small model as response filter to enable the selection of appropriate responses generated by LLMs. Furthermore, we introduce a new evaluation method based on matching both user’s intent and high-frequency medical term to effectively assess the specificity of the responses. We conduct experimental evaluations on three medical dialogue datasets, and the results, including both automatic and human evaluation, demonstrate the effectiveness of our approach.</abstract>
      <url hash="52e05c8e">2023.findings-emnlp.336</url>
      <bibkey>dou-etal-2023-plugmed</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.336</doi>
    </paper>
    <paper id="337">
      <title><fixed-case>C</fixed-case>ode<fixed-case>T</fixed-case>rans<fixed-case>O</fixed-case>cean: A Comprehensive Multilingual Benchmark for Code Translation</title>
      <author><first>Weixiang</first><last>Yan</last></author>
      <author><first>Yuchen</first><last>Tian</last></author>
      <author><first>Yunzhe</first><last>Li</last></author>
      <author><first>Qian</first><last>Chen</last></author>
      <author><first>Wen</first><last>Wang</last></author>
      <pages>5067-5089</pages>
      <abstract>Recent code translation techniques exploit neural machine translation models to translate source code from one programming language to another to satisfy production compatibility or to improve efficiency of codebase maintenance. Most existing code translation datasets only focus on a single pair of popular programming languages. To advance research on code translation and meet diverse requirements of real-world applications, we construct **CodeTransOcean**, a large-scale comprehensive benchmark that supports the largest variety of programming languages for code translation. CodeTransOcean consists of three novel multilingual datasets, namely, **MultilingualTrans** supporting translations between multiple popular programming languages, **NicheTrans** for translating between niche programming languages and popular ones, and **LLMTrans** for evaluating executability of translated code by large language models (LLMs). CodeTransOcean also includes a novel cross-framework dataset, **DLTrans**, for translating deep learning code across different frameworks. We develop multilingual modeling approaches for code translation and demonstrate their great potential in improving the translation quality of both low-resource and high-resource language pairs and boosting the training efficiency. We also propose a novel evaluation metric **Debugging Success Rate@K** for program-level code translation. Last but not least, we evaluate LLM ChatGPT on our datasets and investigate its potential for fuzzy execution predictions. We build baselines for CodeTransOcean and analyze challenges of code translation for guiding future research. The CodeTransOcean datasets and code are publicly available at https://github.com/WeixiangYAN/CodeTransOcean.</abstract>
      <url hash="25da2107">2023.findings-emnlp.337</url>
      <bibkey>yan-etal-2023-codetransocean</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.337</doi>
    </paper>
    <paper id="338">
      <title>impact of sample selection on in-context learning for entity extraction from scientific writing</title>
      <author><first>Necva</first><last>Bölücü</last></author>
      <author><first>Maciej</first><last>Rybinski</last></author>
      <author><first>Stephen</first><last>Wan</last></author>
      <pages>5090-5107</pages>
      <abstract>Prompt-based usage of Large Language Models (LLMs) is an increasingly popular way to tackle many well-known natural language problems. This trend is due, in part, to the appeal of the In-Context Learning (ICL) prompt set-up, in which a few selected training examples are provided along with the inference request. ICL, a type of few-shot learning, is especially attractive for natural language processing (NLP) tasks defined for specialised domains, such as entity extraction from scientific documents, where the annotation is very costly due to expertise requirements for the annotators. In this paper, we present a comprehensive analysis of in-context sample selection methods for entity extraction from scientific documents using GPT-3.5 and compare these results against a fully supervised transformer-based baseline. Our results indicate that the effectiveness of the in-context sample selection methods is heavily domain-dependent, but the improvements are more notable for problems with a larger number of entity types. More in-depth analysis shows that ICL is more effective for low-resource set-ups of scientific information extraction</abstract>
      <url hash="1ce42964">2023.findings-emnlp.338</url>
      <bibkey>bolucu-etal-2023-impact</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.338</doi>
    </paper>
    <paper id="339">
      <title>Goodtriever: Adaptive Toxicity Mitigation with Retrieval-augmented Models</title>
      <author><first>Luiza</first><last>Pozzobon</last></author>
      <author><first>Beyza</first><last>Ermis</last></author>
      <author><first>Patrick</first><last>Lewis</last></author>
      <author><first>Sara</first><last>Hooker</last></author>
      <pages>5108-5125</pages>
      <abstract>Considerable effort has been dedicated to mitigating toxicity, but existing methods often require drastic modifications to model parameters or the use of computationally intensive auxiliary models. Furthermore, previous approaches have often neglected the crucial factor of language’s evolving nature over time. In this work, we present a comprehensive perspective on toxicity mitigation that takes into account its changing nature. We introduce Goodtriever, a flexible methodology that matches the current state-of-the-art toxicity mitigation while achieving 43% relative latency reduction during inference and being more computationally efficient. By incorporating a retrieval-based approach at decoding time, Goodtriever enables toxicity-controlled text generation. Our research advocates for an increased focus on adaptable mitigation techniques, which better reflect the data drift models face when deployed in the wild.</abstract>
      <url hash="58f57d3e">2023.findings-emnlp.339</url>
      <bibkey>pozzobon-etal-2023-goodtriever</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.339</doi>
    </paper>
    <paper id="340">
      <title>Robustness Tests for Automatic Machine Translation Metrics with Adversarial Attacks</title>
      <author><first>Yichen</first><last>Huang</last></author>
      <author><first>Timothy</first><last>Baldwin</last></author>
      <pages>5126-5135</pages>
      <abstract>We investigate MT evaluation metric performance on adversarially-synthesized texts, to shed light on metric robustness. We experiment with word- and character-level attacks on three popular machine translation metrics: BERTScore, BLEURT, and COMET. Our human experiments validate that automatic metrics tend to overpenalize adversarially-degraded translations. We also identify inconsistencies in BERTScore ratings, where it judges the original sentence and the adversarially-degraded one as similar, while judging the degraded translation as notably worse than the original with respect to the reference. We identify patterns of brittleness that motivate more robust metric development.</abstract>
      <url hash="003d72c8">2023.findings-emnlp.340</url>
      <bibkey>huang-baldwin-2023-robustness</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.340</doi>
    </paper>
    <paper id="341">
      <title>Time-Considerable Dialogue Models via Reranking by Time Dependency</title>
      <author><first>Yuiko</first><last>Tsunomori</last></author>
      <author><first>Masakazu</first><last>Ishihata</last></author>
      <author><first>Hiroaki</first><last>Sugiyama</last></author>
      <pages>5136-5149</pages>
      <abstract>In the last few years, generative dialogue models have shown excellent performance and have been used for various applications. As chatbots become more prevalent in our daily lives, more and more people expect them to behave more like humans, but existing dialogue models do not consider the time information that people are constantly aware of. In this paper, we aim to construct a time-considerable dialogue model that actively utilizes time information. First, we categorize responses by their naturalness at different times and introduce a new metric to classify responses into our categories. Then, we propose a new reranking method to make the existing dialogue model time-considerable using the proposed metric and subjectively evaluate the performances of the obtained time-considerable dialogue models by humans.</abstract>
      <url hash="486f53b1">2023.findings-emnlp.341</url>
      <bibkey>tsunomori-etal-2023-time</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.341</doi>
    </paper>
    <paper id="342">
      <title>Non-Compositionality in Sentiment: New Data and Analyses</title>
      <author><first>Verna</first><last>Dankers</last></author>
      <author><first>Christopher</first><last>Lucas</last></author>
      <pages>5150-5162</pages>
      <abstract>When natural language phrases are combined, their meaning is often more than the sum of their parts. In the context of NLP tasks such as sentiment analysis, where the meaning of a phrase is its sentiment, that still applies. Many NLP studies on sentiment analysis, however, focus on the fact that sentiment computations are largely compositional. We, instead, set out to obtain non-compositionality ratings for phrases with respect to their sentiment. Our contributions are as follows: a) a methodology for obtaining those non-compositionality ratings, b) a resource of ratings for 259 phrases – NonCompSST – along with an analysis of that resource, and c) an evaluation of computational models for sentiment analysis using this new resource.</abstract>
      <url hash="07f34b0e">2023.findings-emnlp.342</url>
      <bibkey>dankers-lucas-2023-non</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.342</doi>
    </paper>
    <paper id="343">
      <title><fixed-case>MP</fixed-case>rompt: Exploring Multi-level Prompt Tuning for Machine Reading Comprehension</title>
      <author><first>Guoxin</first><last>Chen</last></author>
      <author><first>Yiming</first><last>Qian</last></author>
      <author><first>Bowen</first><last>Wang</last></author>
      <author><first>Liangzhi</first><last>Li</last></author>
      <pages>5163-5175</pages>
      <abstract>The large language models have achieved superior performance on various natural language tasks. One major drawback of such approaches is they are resource-intensive in fine-tuning new datasets. Soft-prompt tuning presents a resource-efficient solution to fine-tune the pre-trained language models (PLMs) while keeping their weight frozen. Existing soft prompt methods mainly focus on designing the input-independent prompts that steer the model to fit the domain of the new dataset. Those methods often ignore the fine-grained information about the task and context of the text. In this paper, we propose a multi-level prompt tuning (MPrompt) method for machine reading comprehension. It utilizes prompts at task-specific, domain-specific, and context-specific levels to enhance the comprehension of input semantics at different granularities. We also propose an independence constraint to steer each domain-specific prompt to focus on information within its domain to avoid redundancy. Moreover, we present a prompt generator that incorporates context-related knowledge in the prompt generation to enhance contextual relevancy. We conducted extensive experiments on 12 benchmarks of various QA formats and achieved an average improvement of 1.94% over the state-of-the-art methods.</abstract>
      <url hash="728be829">2023.findings-emnlp.343</url>
      <bibkey>chen-etal-2023-mprompt</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.343</doi>
    </paper>
    <paper id="344">
      <title><fixed-case>D</fixed-case>oc<fixed-case>T</fixed-case>rack: A Visually-Rich Document Dataset Really Aligned with Human Eye Movement for Machine Reading</title>
      <author><first>Hao</first><last>Wang</last></author>
      <author><first>Qingxuan</first><last>Wang</last></author>
      <author><first>Yue</first><last>Li</last></author>
      <author><first>Changqing</first><last>Wang</last></author>
      <author><first>Chenhui</first><last>Chu</last></author>
      <author><first>Rui</first><last>Wang</last></author>
      <pages>5176-5189</pages>
      <abstract>The use of visually-rich documents in various fields has created a demand for Document AI models that can read and comprehend documents like humans, which requires the overcoming of technical, linguistic, and cognitive barriers. Unfortunately, the lack of appropriate datasets has significantly hindered advancements in the field. To address this issue, we introduce DocTrack, a visually-rich document dataset really aligned with human eye-movement information using eye-tracking technology. This dataset can be used to investigate the challenges mentioned above. Additionally, we explore the impact of human reading order on document understanding tasks and examine what would happen if a machine reads in the same order as a human. Our results suggest that although Document AI models have made significant progresses, they still have a long way to go before they can read visually richer documents as accurately, continuously, and flexibly as humans do. These findings have potential implications for future research and development of document intelligence.</abstract>
      <url hash="37a71050">2023.findings-emnlp.344</url>
      <bibkey>wang-etal-2023-doctrack</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.344</doi>
    </paper>
    <paper id="345">
      <title>Adaptation with Self-Evaluation to Improve Selective Prediction in <fixed-case>LLM</fixed-case>s</title>
      <author><first>Jiefeng</first><last>Chen</last></author>
      <author><first>Jinsung</first><last>Yoon</last></author>
      <author><first>Sayna</first><last>Ebrahimi</last></author>
      <author><first>Sercan</first><last>Arik</last></author>
      <author><first>Tomas</first><last>Pfister</last></author>
      <author><first>Somesh</first><last>Jha</last></author>
      <pages>5190-5213</pages>
      <abstract>Large language models (LLMs) have recently shown great advances in a variety of tasks, including natural language understanding and generation. However, their use in high-stakes decision-making scenarios is still limited due to the potential for errors. *Selective prediction* is a technique that can be used to improve the reliability of the LLMs by allowing them to abstain from making predictions when they are unsure of the answer. In this work, we propose a novel framework for adaptation with self-evaluation to improve the selective prediction performance of LLMs. Our framework is based on the idea of using parameter-efficient tuning to adapt the LLM to the specific task at hand while improving its ability to perform self-evaluation. We evaluate our method on a variety of question-answering (QA) datasets and show that it outperforms state-of-the-art selective prediction methods. For example, on the CoQA benchmark, our method improves the AUACC from 91.23% to 92.63% and improves the AUROC from 74.61% to 80.25%.</abstract>
      <url hash="d48178bf">2023.findings-emnlp.345</url>
      <bibkey>chen-etal-2023-adaptation</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.345</doi>
    </paper>
    <paper id="346">
      <title>Bi-Drop: Enhancing Fine-tuning Generalization via Synchronous sub-net Estimation and Optimization</title>
      <author><first>Shoujie</first><last>Tong</last></author>
      <author><first>Heming</first><last>Xia</last></author>
      <author><first>Damai</first><last>Dai</last></author>
      <author><first>Runxin</first><last>Xu</last></author>
      <author><first>Tianyu</first><last>Liu</last></author>
      <author><first>Binghuai</first><last>Lin</last></author>
      <author><first>Yunbo</first><last>Cao</last></author>
      <author><first>Zhifang</first><last>Sui</last></author>
      <pages>5214-5227</pages>
      <abstract>Pretrained language models have achieved remarkable success in natural language understanding. However, fine-tuning pretrained models on limited training data tends to overfit and thus diminish performance. This paper presents Bi-Drop, a fine-tuning strategy that selectively updates model parameters using gradients from various sub-nets dynamically generated by dropout. The sub-net estimation of Bi-Drop is performed in an in-batch manner, so it overcomes the problem of hysteresis in sub-net updating, which is possessed by previous methods that perform asynchronous sub-net estimation. Also, Bi-Drop needs only one mini-batch to estimate the sub-net so it achieves higher utility of training data. Experiments on the GLUE benchmark demonstrate that Bi-Drop consistently outperforms previous fine-tuning methods. Furthermore, empirical results also show that Bi-Drop exhibits excellent generalization ability and robustness for domain transfer, data imbalance, and low-resource scenarios.</abstract>
      <url hash="f87b6979">2023.findings-emnlp.346</url>
      <bibkey>tong-etal-2023-bi</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.346</doi>
    </paper>
    <paper id="347">
      <title><fixed-case>C</fixed-case>loz<fixed-case>E</fixed-case>x: A Task toward Generation of <fixed-case>E</fixed-case>nglish Cloze Explanation</title>
      <author><first>Zizheng</first><last>Zhang</last></author>
      <author><first>Masato</first><last>Mita</last></author>
      <author><first>Mamoru</first><last>Komachi</last></author>
      <pages>5228-5242</pages>
      <abstract>Providing explanations for cloze questions in language assessment (LA) has been recognized as a valuable approach to enhancing the language proficiency of learners. However, there is a noticeable absence of dedicated tasks and datasets specifically designed for generating language learner explanations. In response to this gap, this paper introduces a novel task ClozEx of generating explanations for cloze questions in LA, with a particular focus on English as a Second Language (ESL) learners. To support this task, we present a meticulously curated dataset comprising cloze questions paired with corresponding explanations. This dataset aims to assess language proficiency and facilitates language learning by offering informative and accurate explanations. To tackle the task, we fine-tuned various baseline models with our training data, including encoder-decoder and decoder-only architectures. We also explored whether large language models (LLMs) are able to generate good explanations without fine-tuning, just using pre-defined prompts. The evaluation results demonstrate that encoder-decoder models have the potential to deliver fluent and valid explanations when trained on our dataset.</abstract>
      <url hash="09dcc4e7">2023.findings-emnlp.347</url>
      <bibkey>zhang-etal-2023-clozex</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.347</doi>
    </paper>
    <paper id="348">
      <title>Is Probing All You Need? Indicator Tasks as an Alternative to Probing Embedding Spaces</title>
      <author><first>Tal</first><last>Levy</last></author>
      <author><first>Omer</first><last>Goldman</last></author>
      <author><first>Reut</first><last>Tsarfaty</last></author>
      <pages>5243-5254</pages>
      <abstract>The ability to identify and control different kinds of linguistic information encoded in vector representations of words has many use cases, especially for explainability and bias removal. This is usually done via a set of simple classification tasks, termed <i>probes</i>, to evaluate the information encoded in the embedding space. However, the involvement of a trainable classifier leads to entanglement between the probe’s results and the classifier’s nature. As a result, contemporary works on probing include tasks that do not involve training of auxiliary models. In this work we introduce the term <i>indicator tasks</i> for non-trainable tasks which are used to query embedding spaces for the existence of certain properties, and claim that this kind of tasks may point to a direction opposite to probes, and that this contradiction complicates the decision on whether a property exists in an embedding space. We demonstrate our claims with two test cases, one dealing with gender debiasing and another with the erasure of morphological information from embedding spaces. We show that the application of a suitable indicator provides a more accurate picture of the information captured and removed compared to probes. We thus conclude that indicator tasks should be implemented and taken into consideration when eliciting information from embedded representations.</abstract>
      <url hash="0fd480a2">2023.findings-emnlp.348</url>
      <bibkey>levy-etal-2023-probing</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.348</doi>
    </paper>
    <paper id="349">
      <title>The Cost of Compression: Investigating the Impact of Compression on Parametric Knowledge in Language Models</title>
      <author><first>Satya Sai Srinath</first><last>Namburi</last></author>
      <author><first>Makesh</first><last>Sreedhar</last></author>
      <author><first>Srinath</first><last>Srinivasan</last></author>
      <author><first>Frederic</first><last>Sala</last></author>
      <pages>5255-5273</pages>
      <abstract>Compressing large language models (LLMs), often consisting of billions of parameters, provides faster inference, smaller memory footprints, and enables local deployment. The standard compression techniques are pruning and quantization, with the former eliminating redundant connections in model layers and the latter representing model parameters with as little as 4 bits. The key tradeoff is between the degree of compression and the impact on the quality of the compressed model. Existing research on LLM compression primarily focuses on performance in terms of general metrics like perplexity or downstream task accuracy. More fine-grained metrics, such as those measuring parametric knowledge, remain significantly underexplored. To help bridge this gap, we present a comprehensive analysis across multiple model families using the LAMA and LM-Harness benchmarks in order to systematically quantify the effect of commonly employed compression techniques on model performance. A particular focus is on tradeoffs involving parametric knowledge, with the goal of providing practitioners with practical insights to make informed decisions on compression.</abstract>
      <url hash="8737addb">2023.findings-emnlp.349</url>
      <bibkey>namburi-etal-2023-cost</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.349</doi>
    </paper>
    <paper id="350">
      <title><fixed-case>C</fixed-case>o<fixed-case>E</fixed-case>d<fixed-case>IT</fixed-case>: Text Editing by Task-Specific Instruction Tuning</title>
      <author><first>Vipul</first><last>Raheja</last></author>
      <author><first>Dhruv</first><last>Kumar</last></author>
      <author><first>Ryan</first><last>Koo</last></author>
      <author><first>Dongyeop</first><last>Kang</last></author>
      <pages>5274-5291</pages>
      <abstract>We introduce CoEdIT, a state-of-the-art text editing system for writing assistance. CoEdIT takes instructions from the user specifying the attributes of the desired text, such as “Make the sentence simpler” or “Write it in a more neutral style,” and outputs the edited text. We present a large language model fine-tuned on a diverse collection of task-specific instructions for text editing (a total of 82K instructions). Our model (1) achieves state-of-the-art performance on various text editing benchmarks, (2) is competitive with publicly available largest-sized LLMs trained on instructions while being ~60x smaller, (3) is capable of generalizing to unseen edit instructions, and (4) exhibits abilities to generalize to composite instructions containing different combinations of edit actions. Through extensive qualitative and quantitative analysis, we show that writers prefer the edits suggested by CoEdIT relative to other state-of-the-art text editing models. Our code, data, and models are publicly available at https://github.com/vipulraheja/coedit.</abstract>
      <url hash="cb37c3ca">2023.findings-emnlp.350</url>
      <bibkey>raheja-etal-2023-coedit</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.350</doi>
    </paper>
    <paper id="351">
      <title>Exploring Large Language Models for Multi-Modal Out-of-Distribution Detection</title>
      <author><first>Yi</first><last>Dai</last></author>
      <author><first>Hao</first><last>Lang</last></author>
      <author><first>Kaisheng</first><last>Zeng</last></author>
      <author><first>Fei</first><last>Huang</last></author>
      <author><first>Yongbin</first><last>Li</last></author>
      <pages>5292-5305</pages>
      <abstract>Out-of-distribution (OOD) detection is essential for reliable and trustworthy machine learning. Recent multi-modal OOD detection leverages textual information from in-distribution (ID) class names for visual OOD detection, yet it currently neglects the rich contextual information of ID classes. Large language models (LLMs) encode a wealth of world knowledge and can be prompted to generate descriptive features for each class. Indiscriminately using such knowledge causes catastrophic damage to OOD detection due to LLMs’ hallucinations, as is observed by our analysis. In this paper, we propose to apply world knowledge to enhance OOD detection performance through selective generation from LLMs. Specifically, we introduce a consistency-based uncertainty calibration method to estimate the confidence score of each generation. We further extract visual objects from each image to fully capitalize on the aforementioned world knowledge. Extensive experiments demonstrate that our method consistently outperforms the state-of-the-art.</abstract>
      <url hash="dea5db4f">2023.findings-emnlp.351</url>
      <bibkey>dai-etal-2023-exploring</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.351</doi>
    </paper>
    <paper id="352">
      <title>Better Together: Enhancing Generative Knowledge Graph Completion with Language Models and Neighborhood Information</title>
      <author><first>Alla</first><last>Chepurova</last></author>
      <author><first>Aydar</first><last>Bulatov</last></author>
      <author><first>Yuri</first><last>Kuratov</last></author>
      <author><first>Mikhail</first><last>Burtsev</last></author>
      <pages>5306-5316</pages>
      <abstract>Real-world Knowledge Graphs (KGs) often suffer from incompleteness, which limits their potential performance. Knowledge Graph Completion (KGC) techniques aim to address this issue. However, traditional KGC methods are computationally intensive and impractical for large-scale KGs, necessitating the learning of dense node embeddings and computing pairwise distances. Generative transformer-based language models (e.g., T5 and recent KGT5) offer a promising solution as they can predict the tail nodes directly. In this study, we propose to include node neighborhoods as additional information to improve KGC methods based on language models. We examine the effects of this imputation and show that, on both inductive and transductive Wikidata subsets, our method outperforms KGT5 and conventional KGC approaches. We also provide an extensive analysis of the impact of neighborhood on model prediction and show its importance. Furthermore, we point the way to significantly improve KGC through more effective neighborhood selection.</abstract>
      <url hash="943c21b8">2023.findings-emnlp.352</url>
      <bibkey>chepurova-etal-2023-better</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.352</doi>
    </paper>
    <paper id="353">
      <title><fixed-case>D</fixed-case>elta<fixed-case>S</fixed-case>core: Fine-Grained Story Evaluation with Perturbations</title>
      <author><first>Zhuohan</first><last>Xie</last></author>
      <author><first>Miao</first><last>Li</last></author>
      <author><first>Trevor</first><last>Cohn</last></author>
      <author><first>Jey</first><last>Lau</last></author>
      <pages>5317-5331</pages>
      <abstract>Numerous evaluation metrics have been developed for natural language generation tasks, but their effectiveness in evaluating stories is limited as they are not specifically tailored to assess intricate aspects of storytelling, such as fluency and interestingness. In this paper, we introduce DeltaScore, a novel methodology that uses perturbation techniques for the evaluation of nuanced story aspects. We posit that the extent to which a story excels in a specific aspect (e.g., fluency) correlates with the magnitude of its susceptibility to particular perturbations (e.g., the introduction of typos). Given this, we measure the quality of an aspect by calculating the likelihood difference between pre- and post-perturbation states using pre-trained language models. We compare DeltaScore with existing metrics on storytelling datasets from two domains in five fine-grained story aspects: fluency, coherence, relatedness, logicality, and interestingness. DeltaScore demonstrates strong performance, revealing a surprising finding that one specific perturbation proves highly effective in capturing multiple aspects. Source code is available on our GitHub repository.</abstract>
      <url hash="10fb96dd">2023.findings-emnlp.353</url>
      <bibkey>xie-etal-2023-deltascore</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.353</doi>
    </paper>
    <paper id="354">
      <title><fixed-case>M</fixed-case>u<fixed-case>G</fixed-case>: A Multimodal Classification Benchmark on Game Data with Tabular, Textual, and Visual Fields</title>
      <author><first>Jiaying</first><last>Lu</last></author>
      <author><first>Yongchen</first><last>Qian</last></author>
      <author><first>Shifan</first><last>Zhao</last></author>
      <author><first>Yuanzhe</first><last>Xi</last></author>
      <author><first>Carl</first><last>Yang</last></author>
      <pages>5332-5346</pages>
      <abstract>Previous research has demonstrated the advantages of integrating data from multiple sources over traditional unimodal data, leading to the emergence of numerous novel multimodal applications. We propose a multimodal classification benchmark MuG with eight datasets that allows researchers to evaluate and improve their models. These datasets are collected from four various genres of games that cover tabular, textual, and visual modalities. We conduct multi-aspect data analysis to provide insights into the benchmark, including label balance ratios, percentages of missing features, distributions of data within each modality, and the correlations between labels and input modalities. We further present experimental results obtained by several state-of-the-art unimodal classifiers and multimodal classifiers, which demonstrate the challenging and multimodal-dependent properties of the benchmark. MuG is released at https://github.com/lujiaying/MUG-Bench with the data, tutorials, and implemented baselines.</abstract>
      <url hash="07000924">2023.findings-emnlp.354</url>
      <bibkey>lu-etal-2023-mug</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.354</doi>
    </paper>
    <paper id="355">
      <title>Don’t waste a single annotation: improving single-label classifiers through soft labels</title>
      <author><first>Ben</first><last>Wu</last></author>
      <author><first>Yue</first><last>Li</last></author>
      <author><first>Yida</first><last>Mu</last></author>
      <author><first>Carolina</first><last>Scarton</last></author>
      <author><first>Kalina</first><last>Bontcheva</last></author>
      <author><first>Xingyi</first><last>Song</last></author>
      <pages>5347-5355</pages>
      <abstract>In this paper, we address the limitations of the common data annotation and training methods for objective single-label classification tasks. Typically, when annotating such tasks annotators are only asked to provide a single label for each sample and annotator disagreement is discarded when a final hard label is decided through majority voting. We challenge this traditional approach, acknowledging that determining the appropriate label can be difficult due to the ambiguity and lack of context in the data samples. Rather than discarding the information from such ambiguous annotations, our soft label method makes use of them for training. Our findings indicate that additional annotator information, such as confidence, secondary label and disagreement, can be used to effectively generate soft labels. Training classifiers with these soft labels then leads to improved performance and calibration on the hard label test set.</abstract>
      <url hash="ae03a3f0">2023.findings-emnlp.355</url>
      <bibkey>wu-etal-2023-dont</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.355</doi>
    </paper>
    <paper id="356">
      <title>Black-Box Tuning of Vision-Language Models with Effective Gradient Approximation</title>
      <author><first>Zixian</first><last>Guo</last></author>
      <author><first>Yuxiang</first><last>Wei</last></author>
      <author><first>Ming</first><last>Liu</last></author>
      <author><first>Zhilong</first><last>Ji</last></author>
      <author><first>Jinfeng</first><last>Bai</last></author>
      <author><first>Yiwen</first><last>Guo</last></author>
      <author><first>Wangmeng</first><last>Zuo</last></author>
      <pages>5356-5368</pages>
      <abstract>Parameter-efficient fine-tuning (PEFT) methods have provided an effective way for adapting large vision-language models to specific tasks or scenarios. Typically, they learn a very small scale of parameters for pre-trained models in a white-box formulation, which assumes model architectures to be known and parameters to be accessible. However, large models are often not open-source due to considerations of preventing abuse or commercial factors, hence posing a barrier to the deployment of white-box PEFT methods. To alleviate the dependence on model accessibility, we introduce collaborative black-box tuning (CBBT) for both textual prompt optimization and output feature adaptation for black-box models. Specifically, considering that the backpropagation gradients are blocked, we approximate the gradients of textual prompts by analyzing the predictions with perturbed prompts. Secondly, a lightweight adapter is deployed over the output feature of the inaccessible model, further facilitating the model adaptation process. Empowered with these designs, our CBBT is extensively evaluated on eleven downstream benchmarks and achieves remarkable improvements compared to existing black-box VL adaptation methods. Our code will be made publicly available.</abstract>
      <url hash="e1deaedd">2023.findings-emnlp.356</url>
      <bibkey>guo-etal-2023-black</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.356</doi>
    </paper>
    <paper id="357">
      <title>How to Determine the Most Powerful Pre-trained Language Model without Brute Force Fine-tuning? An Empirical Survey</title>
      <author><first>Jun</first><last>Bai</last></author>
      <author><first>Xiaofeng</first><last>Zhang</last></author>
      <author><first>Chen</first><last>Li</last></author>
      <author><first>Hanhua</first><last>Hong</last></author>
      <author><first>Xi</first><last>Xu</last></author>
      <author><first>Chenghua</first><last>Lin</last></author>
      <author><first>Wenge</first><last>Rong</last></author>
      <pages>5369-5382</pages>
      <abstract>Transferability estimation has been attached to great attention in the computer vision fields. Researchers try to estimate with low computational cost the performance of a model when transferred from a source task to a given target task. Considering the effectiveness of such estimations, the communities of natural language processing also began to study similar problems for the selection of pre-trained language models. However, there is a lack of a comprehensive comparison between these estimation methods yet. Also, the differences between vision and language scenarios make it doubtful whether previous conclusions can be established across fields. In this paper, we first conduct a thorough survey of existing transferability estimation methods being able to find the most suitable model, then we conduct a detailed empirical study for the surveyed methods based on the GLUE benchmark. From qualitative and quantitative analyses, we demonstrate the strengths and weaknesses of existing methods and show that H-Score generally performs well with superiorities in effectiveness and efficiency. We also outline the difficulties of consideration of training details, applicability to text generation, and consistency to certain metrics which shed light on future directions.</abstract>
      <url hash="77c44cbb">2023.findings-emnlp.357</url>
      <bibkey>bai-etal-2023-determine</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.357</doi>
    </paper>
    <paper id="358">
      <title>Licon: A Diverse, Controllable and Challenging Linguistic Concept Learning Benchmark</title>
      <author><first>Shenglong</first><last>Yu</last></author>
      <author><first>Ying</first><last>Zhang</last></author>
      <author><first>Wenya</first><last>Guo</last></author>
      <author><first>Zhengkun</first><last>Zhang</last></author>
      <author><first>Ru</first><last>Zhou</last></author>
      <author><first>Xiaojie</first><last>Yuan</last></author>
      <pages>5383-5398</pages>
      <abstract>Concept Learning requires learning the definition of a general category from given training examples. Most of the existing methods focus on learning concepts from images. However, the visual information cannot present abstract concepts exactly, which struggles the introduction of novel concepts related to known concepts (e.g., ‘Plant’<tex-math>\rightarrow</tex-math>‘Asteroids’). In this paper, inspired by the fact that humans learn most concepts through linguistic description, we introduce Linguistic Concept Learning benchmark (Licon), where concepts in diverse forms (e.g., plain attributes, images, and text) are defined by linguistic descriptions. The difficulty to learn novel concepts can be controlled by the number of attributes or the hierarchical relationships between concepts. The diverse and controllable concepts are used to support challenging evaluation tasks, including concept classification, attribute prediction, and concept relationship recognition. In addition, we design an entailment-based concept learning method (EnC) to model the relationship among concepts. Extensive experiments demonstrate the effectiveness of EnC. The benchmark will be released to the public soon.</abstract>
      <url hash="42822e63">2023.findings-emnlp.358</url>
      <bibkey>yu-etal-2023-licon</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.358</doi>
    </paper>
    <paper id="359">
      <title><fixed-case>I</fixed-case>nterro<fixed-case>L</fixed-case>ang: Exploring <fixed-case>NLP</fixed-case> Models and Datasets through Dialogue-based Explanations</title>
      <author><first>Nils</first><last>Feldhus</last></author>
      <author><first>Qianli</first><last>Wang</last></author>
      <author><first>Tatiana</first><last>Anikina</last></author>
      <author><first>Sahil</first><last>Chopra</last></author>
      <author><first>Cennet</first><last>Oguz</last></author>
      <author><first>Sebastian</first><last>Möller</last></author>
      <pages>5399-5421</pages>
      <abstract>While recently developed NLP explainability methods let us open the black box in various ways (Madsen et al., 2022), a missing ingredient in this endeavor is an interactive tool offering a conversational interface. Such a dialogue system can help users explore datasets and models with explanations in a contextualized manner, e.g. via clarification or follow-up questions, and through a natural language interface. We adapt the conversational explanation framework TalkToModel (Slack et al., 2022) to the NLP domain, add new NLP-specific operations such as free-text rationalization, and illustrate its generalizability on three NLP tasks (dialogue act classification, question answering, hate speech detection). To recognize user queries for explanations, we evaluate fine-tuned and few-shot prompting models and implement a novel adapter-based approach. We then conduct two user studies on (1) the perceived correctness and helpfulness of the dialogues, and (2) the simulatability, i.e. how objectively helpful dialogical explanations are for humans in figuring out the model’s predicted label when it’s not shown. We found rationalization and feature attribution were helpful in explaining the model behavior. Moreover, users could more reliably predict the model outcome based on an explanation dialogue rather than one-off explanations.</abstract>
      <url hash="694a5d77">2023.findings-emnlp.359</url>
      <bibkey>feldhus-etal-2023-interrolang</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.359</doi>
    </paper>
    <paper id="360">
      <title><fixed-case>INVITE</fixed-case>: a Testbed of Automatically Generated Invalid Questions to Evaluate Large Language Models for Hallucinations</title>
      <author><first>Anil</first><last>Ramakrishna</last></author>
      <author><first>Rahul</first><last>Gupta</last></author>
      <author><first>Jens</first><last>Lehmann</last></author>
      <author><first>Morteza</first><last>Ziyadi</last></author>
      <pages>5422-5429</pages>
      <abstract>Recent advancements in Large language models (LLMs) have enabled them to hold free form conversations over multiple turns, but they exhibit a tendency to make unfounded and incorrect statements, commonly known as hallucinations. In particular, LLMs hallucinate frequently when given invalid questions, i.e. ones with incorrect assumptions. The most common approach to evaluate LLMs on hallucinations is to test them on Question Answering (QA) test sets such as TruthfulQA. However, LLMs are increasingly pretrained on massive text corpora scraped from the Internet, which may inevitably expose these test sets to the model during training, leading eventually to an overestimation of model performances on these test sets. In this work, we present an alternative framework to address this risk and to foster further research towards making LLMs robust against invalid questions. We name our framework INVITE: a testbed of automatically generated INValId questions to evaluaTE large language models for hallucinations. In each instantiation, our framework is set up to create a fresh batch of invalid questions by distorting valid facts in which subjects or objects are replaced by similar entities. We evaluate several state of the art LLMs against a testset generated by our framework and highlight its capacity to trigger hallucinations in these models.</abstract>
      <url hash="1a8c322c">2023.findings-emnlp.360</url>
      <bibkey>ramakrishna-etal-2023-invite</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.360</doi>
    </paper>
    <paper id="361">
      <title>Multimodal Automated Fact-Checking: A Survey</title>
      <author><first>Mubashara</first><last>Akhtar</last></author>
      <author><first>Michael</first><last>Schlichtkrull</last></author>
      <author><first>Zhijiang</first><last>Guo</last></author>
      <author><first>Oana</first><last>Cocarascu</last></author>
      <author><first>Elena</first><last>Simperl</last></author>
      <author><first>Andreas</first><last>Vlachos</last></author>
      <pages>5430-5448</pages>
      <abstract>Misinformation is often conveyed in multiple modalities, e.g. a miscaptioned image. Multimodal misinformation is perceived as more credible by humans, and spreads faster than its text-only counterparts. While an increasing body of research investigates automated fact-checking (AFC), previous surveys mostly focus on text. In this survey, we conceptualise a framework for AFC including subtasks unique to multimodal misinformation. Furthermore, we discuss related terms used in different communities and map them to our framework. We focus on four modalities prevalent in real-world fact-checking: text, image, audio, and video. We survey benchmarks and models, and discuss limitations and promising directions for future research</abstract>
      <url hash="b5162802">2023.findings-emnlp.361</url>
      <bibkey>akhtar-etal-2023-multimodal</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.361</doi>
    </paper>
    <paper id="362">
      <title><fixed-case>PROTEGE</fixed-case>: Prompt-based Diverse Question Generation from Web Articles</title>
      <author><first>Vinayak</first><last>Puranik</last></author>
      <author><first>Anirban</first><last>Majumder</last></author>
      <author><first>Vineet</first><last>Chaoji</last></author>
      <pages>5449-5463</pages>
      <abstract>Rich and diverse knowledge bases (KB) are foundational building blocks for online knowledge sharing communities such as StackOverflow and Quora, and applications such as conversational assistants (aka chatbots). A popular format for knowledge bases is question-answer pairs (or FAQs), where questions are designed to accurately match a multitude of queries. In this paper, we address the problem of automatic creation of such Q&amp;A-based knowledge bases from domain-specific, long-form textual content (e.g., web articles). Specifically, we consider the problem of question generation, which is the task of generating questions given a paragraph of text as input, with a goal to achieve both diversity and fidelity of the generated questions. Towards this goal we propose PROTEGE, a diverse question generation framework which consists of (1) a novel encoder-decoder based Large Language Model (LLM) architecture which can take a variety of prompts and generate a diverse set of candidate questions, and (2) a hill-climbing algorithm that maximizes a sub-modular objective function to balance diversity with fidelity. Through our experiments on three popular public Q&amp;A datasets, we demonstrate that PROTEGE improves diversity by +16% and fidelity by +8% over diverse beam search and prompt-based baselines.</abstract>
      <url hash="c107efba">2023.findings-emnlp.362</url>
      <bibkey>puranik-etal-2023-protege</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.362</doi>
    </paper>
    <paper id="363">
      <title><fixed-case>GPT</fixed-case>-4 as an Effective Zero-Shot Evaluator for Scientific Figure Captions</title>
      <author><first>Ting-Yao</first><last>Hsu</last></author>
      <author><first>Chieh-Yang</first><last>Huang</last></author>
      <author><first>Ryan</first><last>Rossi</last></author>
      <author><first>Sungchul</first><last>Kim</last></author>
      <author><first>C.</first><last>Giles</last></author>
      <author><first>Ting-Hao</first><last>Huang</last></author>
      <pages>5464-5474</pages>
      <abstract>There is growing interest in systems that generate captions for scientific figures. However, assessing these systems’ output poses a significant challenge. Human evaluation requires academic expertise and is costly, while automatic evaluation depends on often low-quality author-written captions. This paper investigates using large language models (LLMs) as a cost-effective, reference-free method for evaluating figure captions. We first constructed SCICAP-EVAL, a human evaluation dataset that contains human judgments for 3,600 scientific figure captions, both original and machine-made, for 600 arXiv figures. We then prompted LLMs like GPT-4 and GPT-3 to score (1-6) each caption based on its potential to aid reader understanding, given relevant context such as figure-mentioning paragraphs. Results show that GPT-4, used as a zero-shot evaluator, outperformed all other models and even surpassed assessments made by computer science undergraduates, achieving a Kendall correlation score of 0.401 with Ph.D. students’ rankings.</abstract>
      <url hash="0d2afb56">2023.findings-emnlp.363</url>
      <bibkey>hsu-etal-2023-gpt</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.363</doi>
    </paper>
    <paper id="364">
      <title>Mulan: A Multi-Level Alignment Model for Video Question Answering</title>
      <author><first>Yu</first><last>Fu</last></author>
      <author><first>Cong</first><last>Cao</last></author>
      <author><first>Yuling</first><last>Yang</last></author>
      <author><first>Yuhai</first><last>Lu</last></author>
      <author><first>Fangfang</first><last>Yuan</last></author>
      <author><first>Dakui</first><last>Wang</last></author>
      <author><first>Yanbing</first><last>Liu</last></author>
      <pages>5475-5489</pages>
      <abstract>Video Question Answering (VideoQA) aims to answer questions about the visual content of a video. Current methods mainly focus on improving joint representations of video and text. However, these methods pay little attention to the fine-grained semantic interaction between video and text. In this paper, we propose Mulan: a Multi-Level Alignment Model for Video Question Answering, which establishes alignment between visual and textual modalities at the object-level, frame-level, and video-level. Specifically, for object-level alignment, we propose a mask-guided visual feature encoding method and a visual-guided text description method to learn fine-grained spatial information. For frame-level alignment, we introduce the use of visual features from individual frames, combined with a caption generator, to learn overall spatial information within the scene. For video-level alignment, we propose an expandable ordinal prompt for textual descriptions, combined with visual features, to learn temporal information. Experimental results show that our method outperforms the state-of-the-art methods, even when utilizing the smallest amount of extra visual-language pre-training data and a reduced number of trainable parameters.</abstract>
      <url hash="456071b0">2023.findings-emnlp.364</url>
      <bibkey>fu-etal-2023-mulan</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.364</doi>
    </paper>
    <paper id="365">
      <title><fixed-case>HARE</fixed-case>: Explainable Hate Speech Detection with Step-by-Step Reasoning</title>
      <author><first>Yongjin</first><last>Yang</last></author>
      <author><first>Joonkee</first><last>Kim</last></author>
      <author><first>Yujin</first><last>Kim</last></author>
      <author><first>Namgyu</first><last>Ho</last></author>
      <author><first>James</first><last>Thorne</last></author>
      <author><first>Se-Young</first><last>Yun</last></author>
      <pages>5490-5505</pages>
      <abstract>With the proliferation of social media, accurate detection of hate speech has become critical to ensure safety online. To combat nuanced forms of hate speech, it is important to identify and thoroughly explain hate speech to help users understand its harmful effects. Recent benchmarks have attempted to tackle this issue by training generative models on free-text annotations of implications in hateful text. However, we find significant reasoning gaps in the existing annotations schemes, which may hinder the supervision of detection models. In this paper, we introduce a hate speech detection framework, **HARE**, which harnesses the reasoning capabilities of large language models (LLMs) to fill these gaps in explanations of hate speech, thus enabling effective supervision of detection models. Experiments on SBIC and Implicit Hate benchmarks show that our method, using model-generated data, consistently outperforms baselines, using existing free-text human annotations. Analysis demonstrates that our method enhances the explanation quality of trained models and improves generalization to unseen datasets. Our code is available at https://github.com/joonkeekim/hare-hate-speech.git.</abstract>
      <url hash="5eb1923a">2023.findings-emnlp.365</url>
      <bibkey>yang-etal-2023-hare</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.365</doi>
    </paper>
    <paper id="366">
      <title><fixed-case>R</fixed-case>e<fixed-case>LM</fixed-case>: Leveraging Language Models for Enhanced Chemical Reaction Prediction</title>
      <author><first>Yaorui</first><last>Shi</last></author>
      <author><first>An</first><last>Zhang</last></author>
      <author><first>Enzhi</first><last>Zhang</last></author>
      <author><first>Zhiyuan</first><last>Liu</last></author>
      <author><first>Xiang</first><last>Wang</last></author>
      <pages>5506-5520</pages>
      <abstract>Predicting chemical reactions, a fundamental challenge in chemistry, involves forecasting the resulting products from a given reaction process. Conventional techniques, notably those employing Graph Neural Networks (GNNs), are often limited by insufficient training data and their inability to utilize textual information, undermining their applicability in real-world applications. In this work, we propose **ReLM**, a novel framework that leverages the chemical knowledge encoded in language models (LMs) to assist GNNs, thereby enhancing the accuracy of real-world chemical reaction predictions. To further enhance the model’s robustness and interpretability, we incorporate the confidence score strategy, enabling the LMs to self-assess the reliability of their predictions. Our experimental results demonstrate that ReLM improves the performance of state-of-the-art GNN-based methods across various chemical reaction datasets, especially in out-of-distribution settings. Codes are available at https://github.com/syr-cn/ReLM.</abstract>
      <url hash="59e040a5">2023.findings-emnlp.366</url>
      <bibkey>shi-etal-2023-relm</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.366</doi>
    </paper>
    <paper id="367">
      <title>Decomposing Complex Queries for Tip-of-the-tongue Retrieval</title>
      <author><first>Kevin</first><last>Lin</last></author>
      <author><first>Kyle</first><last>Lo</last></author>
      <author><first>Joseph</first><last>Gonzalez</last></author>
      <author><first>Dan</first><last>Klein</last></author>
      <pages>5521-5533</pages>
      <abstract>When re-finding items, users who forget or are uncertain about identifying details often rely on creative strategies for expressing their information needs—complex queries that describe content elements (e.g., book characters or events), information beyond the document text (e.g., descriptions of book covers), or personal context (e.g., when they read a book). Standard retrieval models that rely on lexical or semantic overlap between query and document text are challenged in such retrieval settings, known as tip-of-the-tongue (TOT) retrieval. We introduce a simple but effective framework for handling such complex queries by decomposing the query with an LLM into individual clues routing those as subqueries to specialized retrievers, and ensembling the results. Our approach takes advantage of off-the-shelf retrievers (e.g., CLIP for retrieving images of book covers) or incorporate retriever-specific logic (e.g., date constraints). We show that our framework incorporating query decomposition into retrievers can improve gold book recall up to 6% absolute gain for Recall@5 on a new collection of 14,441 real-world query-book pairs from an online community for resolving TOT inquiries.</abstract>
      <url hash="f1d441f1">2023.findings-emnlp.367</url>
      <bibkey>lin-etal-2023-decomposing</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.367</doi>
    </paper>
    <paper id="368">
      <title>Values, Ethics, Morals? On the Use of Moral Concepts in <fixed-case>NLP</fixed-case> Research</title>
      <author><first>Karina</first><last>Vida</last></author>
      <author><first>Judith</first><last>Simon</last></author>
      <author><first>Anne</first><last>Lauscher</last></author>
      <pages>5534-5554</pages>
      <abstract>With language technology increasingly affecting individuals’ lives, many recent works have investigated the ethical aspects of NLP. Among other topics, researchers focused on the notion of morality, investigating, for example, which moral judgements language models make. However, there has been little to no discussion of the terminology and the theories underpinning those efforts and their implications. This lack is highly problematic, as it hides the works’ underlying assumptions and hinders a thorough and targeted scientific debate of morality in NLP. In this work, we address this research gap by (a) providing an overview of some important ethical concepts stemming from philosophy and (b) systematically surveying the existing literature on moral NLP w.r.t. their philosophical foundation, terminology, and data basis. For instance, we analyse what ethical theory an approach is based on, how this decision is justified, and what implications it entails. Our findings surveying 92 papers show that, for instance, most papers neither provide a clear definition of the terms they use nor adhere to definitions from philosophy. Finally, (c) we give three recommendations for future research in the field. We hope our work will lead to a more informed, careful, and sound discussion of morality in language technology.</abstract>
      <url hash="db33e122">2023.findings-emnlp.368</url>
      <bibkey>vida-etal-2023-values</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.368</doi>
    </paper>
    <paper id="369">
      <title>Self-Supervised Behavior Cloned Transformers are Path Crawlers for Text Games</title>
      <author><first>Ruoyao</first><last>Wang</last></author>
      <author><first>Peter</first><last>Jansen</last></author>
      <pages>5555-5565</pages>
      <abstract>In this work, we introduce a self-supervised behavior cloning transformer for text games, which are challenging benchmarks for multi-step reasoning in virtual environments. Traditionally, Behavior Cloning Transformers excel in such tasks but rely on supervised training data. Our approach auto-generates training data by exploring trajectories (defined by common macro-action sequences) that lead to reward within the games, while determining the generality and utility of these trajectories by rapidly training small models then evalauating their performance on unseen development games. Through empirical analysis, we show our method consistently uncovers generalizable training data, achieving about 90% performance of supervised systems across three benchmark text games.</abstract>
      <url hash="f147a82c">2023.findings-emnlp.369</url>
      <bibkey>wang-jansen-2023-self</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.369</doi>
    </paper>
    <paper id="370">
      <title>Adapting Pretrained Text-to-Text Models for Long Text Sequences</title>
      <author><first>Wenhan</first><last>Xiong</last></author>
      <author><first>Anchit</first><last>Gupta</last></author>
      <author><first>Shubham</first><last>Toshniwal</last></author>
      <author><first>Yashar</first><last>Mehdad</last></author>
      <author><first>Scott</first><last>Yih</last></author>
      <pages>5566-5578</pages>
      <abstract>We present an empirical study of adapting an existing pretrained text-to-text model for long-sequence inputs. Through a comprehensive study along three axes of the pretraining pipeline – model architecture, optimization objective, and pretraining corpus, we propose an effective recipe to build long-context models from existing short-context models. Specifically, we replace the full attention in transformers with <i>pooling-augmented blockwise attention</i>, and pretrain the model with a masked-span prediction task with spans of varying lengths. In terms of the pretraining corpus, we find that using randomly concatenated short-documents from a large open-domain corpus results in better performance than using existing long document corpora, which are typically limited in their domain coverage. With these findings, we build a long-context model that achieves competitive performance on long-text QA tasks and establishes the new state of the art on <i>five</i> long-text summarization datasets, often outperforming previous methods with larger model sizes.</abstract>
      <url hash="10af0f33">2023.findings-emnlp.370</url>
      <bibkey>xiong-etal-2023-adapting</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.370</doi>
    </paper>
    <paper id="371">
      <title>x<fixed-case>D</fixed-case>ial-Eval: A Multilingual Open-Domain Dialogue Evaluation Benchmark</title>
      <author><first>Chen</first><last>Zhang</last></author>
      <author><first>Luis</first><last>D’Haro</last></author>
      <author><first>Chengguang</first><last>Tang</last></author>
      <author><first>Ke</first><last>Shi</last></author>
      <author><first>Guohua</first><last>Tang</last></author>
      <author><first>Haizhou</first><last>Li</last></author>
      <pages>5579-5601</pages>
      <abstract>Recent advancements in reference-free learned metrics for open-domain dialogue evaluation have been driven by the progress in pre-trained language models and the availability of dialogue data with high-quality human annotations. However, current studies predominantly concentrate on English dialogues, and the generalization of these metrics to other languages has not been fully examined. This is largely due to the absence of a multilingual dialogue evaluation benchmark. To address the issue, we introduce xDial-Eval, built on top of open-source English dialogue evaluation datasets. xDial-Eval includes 12 turn-level and 6 dialogue-level English datasets, comprising 14930 annotated turns and 8691 annotated dialogues respectively. The English dialogue data are extended to nine other languages with commercial machine translation systems. On xDial-Eval, we conduct comprehensive analyses of previous BERT-based metrics and the recently-emerged large language models. Lastly, we establish strong self-supervised and multilingual baselines. In terms of average Pearson correlations over all datasets and languages, the best baseline outperforms OpenAI’s ChatGPT by absolute improvements of 6.5% and 4.6% at the turn and dialogue levels respectively, albeit with much fewer parameters. The data and code are publicly available at https://github.com/e0397123/xDial-Eval.</abstract>
      <url hash="4e85e675">2023.findings-emnlp.371</url>
      <bibkey>zhang-etal-2023-xdial</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.371</doi>
    </paper>
    <paper id="372">
      <title><fixed-case>M</fixed-case>ath<fixed-case>D</fixed-case>ial: A Dialogue Tutoring Dataset with Rich Pedagogical Properties Grounded in Math Reasoning Problems</title>
      <author><first>Jakub</first><last>Macina</last></author>
      <author><first>Nico</first><last>Daheim</last></author>
      <author><first>Sankalan</first><last>Chowdhury</last></author>
      <author><first>Tanmay</first><last>Sinha</last></author>
      <author><first>Manu</first><last>Kapur</last></author>
      <author><first>Iryna</first><last>Gurevych</last></author>
      <author><first>Mrinmaya</first><last>Sachan</last></author>
      <pages>5602-5621</pages>
      <abstract>While automatic dialogue tutors hold great potential in making education personalized and more accessible, research on such systems has been hampered by a lack of sufficiently large and high-quality datasets. Collecting such datasets remains challenging, as recording tutoring sessions raises privacy concerns and crowdsourcing leads to insufficient data quality. To address this, we propose a framework to generate such dialogues by pairing human teachers with a Large Language Model (LLM) prompted to represent common student errors. We describe how we use this framework to collect MathDial, a dataset of 3k one-to-one teacher-student tutoring dialogues grounded in multi-step math reasoning problems. While models like GPT-3 are good problem solvers, they fail at tutoring because they generate factually incorrect feedback or are prone to revealing solutions to students too early. To overcome this, we let teachers provide learning opportunities to students by guiding them using various scaffolding questions according to a taxonomy of teacher moves. We demonstrate MathDial and its extensive annotations can be used to finetune models to be more effective tutors (and not just solvers). We confirm this by automatic and human evaluation, notably in an interactive setting that measures the trade-off between student solving success and telling solutions. The dataset is released publicly.</abstract>
      <url hash="757a42f2">2023.findings-emnlp.372</url>
      <bibkey>macina-etal-2023-mathdial</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.372</doi>
    </paper>
    <paper id="373">
      <title>Towards Making the Most of <fixed-case>C</fixed-case>hat<fixed-case>GPT</fixed-case> for Machine Translation</title>
      <author><first>Keqin</first><last>Peng</last></author>
      <author><first>Liang</first><last>Ding</last></author>
      <author><first>Qihuang</first><last>Zhong</last></author>
      <author><first>Li</first><last>Shen</last></author>
      <author><first>Xuebo</first><last>Liu</last></author>
      <author><first>Min</first><last>Zhang</last></author>
      <author><first>Yuanxin</first><last>Ouyang</last></author>
      <author><first>Dacheng</first><last>Tao</last></author>
      <pages>5622-5633</pages>
      <abstract>ChatGPT shows remarkable capabilities for machine translation (MT). Several prior studies have shown that it achieves comparable results to commercial systems for high-resource languages, but lags behind in complex tasks, e.g, low-resource and distant-language-pairs translation. However, they usually adopt simple prompts which can not fully elicit the capability of ChatGPT. In this report, we aim to further mine ChatGPT’s translation ability by revisiting several aspects: temperature, task information, and domain information, and correspondingly propose two (simple but effective) prompts: Task-Specific Prompts (TSP) and Domain-Specific Prompts (DSP). We show that: 1) The performance of ChatGPT depends largely on temperature, and a lower temperature usually can achieve better performance; 2) Emphasizing the task information further improves ChatGPT’s performance, particularly in complex MT tasks; 3) Introducing domain information can elicit ChatGPT’s generalization ability and improve its performance in the specific domain; 4) ChatGPT tends to generate hallucinations for non-English-centric MT tasks, which can be partially addressed by our proposed prompts but still need to be highlighted for the MT/NLP community. We also explore the effects of advanced in-context learning strategies and find a (negative but interesting) observation: the powerful chain-of-thought prompt leads to word-by-word translation behavior, thus bringing significant translation degradation.</abstract>
      <url hash="9b60b2b5">2023.findings-emnlp.373</url>
      <bibkey>peng-etal-2023-towards</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.373</doi>
    </paper>
    <paper id="374">
      <title>Enhancing Reasoning Capabilities by Instruction Learning and Chain-of-Thoughts for Implicit Discourse Relation Recognition</title>
      <author><first>Yuxiang</first><last>Lu</last></author>
      <author><first>Yu</first><last>Hong</last></author>
      <author><first>Zhipang</first><last>Wang</last></author>
      <author><first>Guodong</first><last>Zhou</last></author>
      <pages>5634-5640</pages>
      <abstract>The aim of implicit discourse relation recognition is to comprehend the sense of connection between two arguments. In this work, we present a classification method that is solely based on generative models. Our proposed approach employs a combination of instruction templates and in-context learning to refine the generative model for effectively addressing the implicit discourse relation recognition task. Furthermore, we utilize Chain-of-Thoughts to partition the inference process into a sequence of three successive stages. This strategy enables us to fully utilize the autoregressive generative model’s potential for knowledge acquisition and inference, ultimately leading to enhanced performance on this natural language understanding task. The results of our experiments, evaluated on benchmark datasets PDTB 2.0, PDTB 3.0, and the CoNLL16 shared task, demonstrate superior performance compared to previous state-of-the-art models.</abstract>
      <url hash="30c36e37">2023.findings-emnlp.374</url>
      <bibkey>lu-etal-2023-enhancing</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.374</doi>
    </paper>
    <paper id="375">
      <title>Large-Scale and Multi-Perspective Opinion Summarization with Diverse Review Subsets</title>
      <author><first>Han</first><last>Jiang</last></author>
      <author><first>Rui</first><last>Wang</last></author>
      <author><first>Zhihua</first><last>Wei</last></author>
      <author><first>Yu</first><last>Li</last></author>
      <author><first>Xinpeng</first><last>Wang</last></author>
      <pages>5641-5656</pages>
      <abstract>Opinion summarization is expected to digest larger review sets and provide summaries from different perspectives. However, most existing solutions are deficient in epitomizing extensive reviews and offering opinion summaries from various angles due to the lack of designs for information selection. To this end, we propose SubSumm, a supervised summarization framework for large-scale multi-perspective opinion summarization. SubSumm consists of a review sampling strategy set and a two-stage training scheme. The sampling strategies take sentiment orientation and contrastive information value into consideration, with which the review subsets from different perspectives and quality levels can be selected. Subsequently, the summarizer is encouraged to learn from the sub-optimal and optimal subsets successively in order to capitalize on the massive input. Experimental results on AmaSum and Rotten Tomatoes datasets demonstrate that SubSumm is adept at generating pros, cons, and verdict summaries from hundreds of input reviews. Furthermore, our in-depth analysis verifies that the advanced selection of review subsets and the two-stage training scheme are vital to boosting the summarization performance.</abstract>
      <url hash="6b612301">2023.findings-emnlp.375</url>
      <bibkey>jiang-etal-2023-large</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.375</doi>
    </paper>
    <paper id="376">
      <title>Topic-Informed Dialogue Summarization using Topic Distribution and Prompt-based Modeling</title>
      <author><first>Jaeah</first><last>You</last></author>
      <author><first>Youngjoong</first><last>Ko</last></author>
      <pages>5657-5663</pages>
      <abstract>Dealing with multiple topics should be considered an important issue in dialogue summarization, because dialogues, unlike documents, are prone to topic drift. Thus, we propose a new dialogue summarization model that reflects dialogue topic distribution to consider all topics present in the dialogue. First, the distribution of dialogue topics is estimated by an effective topic discovery model. Then topic-informed prompt transfers estimated topic distribution information to the output of encoder and decoder vectors. Finally, the topic extractor estimates the summary topic distribution from the output context vector of decoder to distinguish its difference from the dialogue topic distribution. To consider the proportion of each topic distribution appeared in the dialogue, the extractor is trained to reduce the difference between the distributions of the dialogue and the summary. The experimental results on SAMSum and DialogSum show that our model outperforms state-of-the-art methods on ROUGE scores. The human evaluation results also show that our framework well generates comprehensive summaries.</abstract>
      <url hash="f4346bf8">2023.findings-emnlp.376</url>
      <bibkey>you-ko-2023-topic</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.376</doi>
    </paper>
    <paper id="377">
      <title>Disentangling Structure and Style: Political Bias Detection in News by Inducing Document Hierarchy</title>
      <author><first>Jiwoo</first><last>Hong</last></author>
      <author><first>Yejin</first><last>Cho</last></author>
      <author><first>Jiyoung</first><last>Han</last></author>
      <author><first>Jaemin</first><last>Jung</last></author>
      <author><first>James</first><last>Thorne</last></author>
      <pages>5664-5686</pages>
      <abstract>We address an important gap in detecting political bias in news articles. Previous works that perform document classification can be influenced by the writing style of each news outlet, leading to overfitting and limited generalizability. Our approach overcomes this limitation by considering both the sentence-level semantics and the document-level rhetorical structure, resulting in a more robust and style-agnostic approach to detecting political bias in news articles. We introduce a novel multi-head hierarchical attention model that effectively encodes the structure of long documents through a diverse ensemble of attention heads. While journalism follows a formalized rhetorical structure, the writing style may vary by news outlet. We demonstrate that our method overcomes this domain dependency and outperforms previous approaches for robustness and accuracy. Further analysis and human evaluation demonstrate the ability of our model to capture common discourse structures in journalism.</abstract>
      <url hash="97f36802">2023.findings-emnlp.377</url>
      <bibkey>hong-etal-2023-disentangling</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.377</doi>
    </paper>
    <paper id="378">
      <title>Measuring and Narrowing the Compositionality Gap in Language Models</title>
      <author><first>Ofir</first><last>Press</last></author>
      <author><first>Muru</first><last>Zhang</last></author>
      <author><first>Sewon</first><last>Min</last></author>
      <author><first>Ludwig</first><last>Schmidt</last></author>
      <author><first>Noah</first><last>Smith</last></author>
      <author><first>Mike</first><last>Lewis</last></author>
      <pages>5687-5711</pages>
      <abstract>We investigate the ability of language models to perform compositional reasoning tasks where the overall solution depends on correctly composing the answers to sub-problems. We measure how often models can correctly answer all sub-problems but not generate the overall solution, a ratio we call the compositionality gap. We evaluate this ratio by asking multi-hop questions with answers that require composing multiple facts unlikely to have been observed together during pretraining. In the GPT-3 family of models, as model size increases we show that the single-hop question answering performance improves faster than the multi-hop performance does, therefore the compositionality gap does not decrease. This surprising result suggests that while more powerful models memorize and recall more factual knowledge, they show no corresponding improvement in their ability to perform this kind of compositional reasoning. We then demonstrate how elicitive prompting (such as chain of thought) narrows the compositionality gap by reasoning explicitly instead of implicitly. We present a new method, self-ask, that further improves on chain of thought. In our method, the model explicitly asks itself (and then answers) follow-up questions before answering the initial question. We finally show that self-ask’s structured prompting lets us easily plug in a search engine to answer the follow-up questions, which additionally improves accuracy.</abstract>
      <url hash="be8a7295">2023.findings-emnlp.378</url>
      <bibkey>press-etal-2023-measuring</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.378</doi>
    </paper>
    <paper id="379">
      <title>Unsupervised Candidate Answer Extraction through Differentiable Masker-Reconstructor Model</title>
      <author><first>Zhuoer</first><last>Wang</last></author>
      <author><first>Yicheng</first><last>Wang</last></author>
      <author><first>Ziwei</first><last>Zhu</last></author>
      <author><first>James</first><last>Caverlee</last></author>
      <pages>5712-5723</pages>
      <abstract>Question generation is a widely used data augmentation approach with extensive applications, and extracting qualified candidate answers from context passages is a critical step for most question generation systems. However, existing methods for candidate answer extraction are reliant on linguistic rules or annotated data that face the partial annotation issue and challenges in generalization. To overcome these limitations, we propose a novel unsupervised candidate answer extraction approach that leverages the inherent structure of context passages through a Differentiable Masker-Reconstructor (DMR) Model with the enforcement of self-consistency for picking up salient information tokens. We curated two datasets with exhaustively-annotated answers and benchmark a comprehensive set of supervised and unsupervised candidate answer extraction methods. We demonstrate the effectiveness of the DMR model by showing its performance is superior among unsupervised methods and comparable to supervised methods.</abstract>
      <url hash="6147ccd1">2023.findings-emnlp.379</url>
      <bibkey>wang-etal-2023-unsupervised</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.379</doi>
    </paper>
    <paper id="380">
      <title><fixed-case>H</fixed-case>oney<fixed-case>B</fixed-case>ee: Progressive Instruction Finetuning of Large Language Models for Materials Science</title>
      <author><first>Yu</first><last>Song</last></author>
      <author><first>Santiago</first><last>Miret</last></author>
      <author><first>Huan</first><last>Zhang</last></author>
      <author><first>Bang</first><last>Liu</last></author>
      <pages>5724-5739</pages>
      <abstract>We propose an instruction-based process for trustworthy data curation in materials science (MatSci-Instruct), which we then apply to finetune a LLaMa-based language model targeted for materials science (HoneyBee). MatSci-Instruct helps alleviate the scarcity of relevant, high-quality materials science textual data available in the open literature, and HoneyBee is the first billion-parameter language model specialized to materials science. In MatSci-Instruct we improve the trustworthiness of generated data by prompting multiple commercially available large language models for generation with an Instructor module (e.g. Chat-GPT) and verification from an independent Verifier module (e.g. Claude). Using MatSci-Instruct, we construct a dataset of multiple tasks and measure the quality of our dataset along multiple dimensions, including accuracy against known facts, relevance to materials science, as well as completeness and reasonableness of the data. Moreover, we iteratively generate more targeted instructions and instruction-data in a finetuning-evaluation-feedback loop leading to progressively better performance for our finetuned HoneyBee models. Our evaluation on the MatSci-NLP benchmark shows HoneyBee’s outperformance of existing language models on materials science tasks and iterative improvement in successive stages of instruction-data refinement. We study the quality of HoneyBee’s language modeling through automatic evaluation and analyze case studies to further understand the model’s capabilities and limitations. Our code and relevant datasets are publicly available at https://github.com/BangLab-UdeM-Mila/NLP4MatSci-HoneyBee.</abstract>
      <url hash="0a73317e">2023.findings-emnlp.380</url>
      <bibkey>song-etal-2023-honeybee</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.380</doi>
    </paper>
    <paper id="381">
      <title>Prompt-Based Editing for Text Style Transfer</title>
      <author><first>Guoqing</first><last>Luo</last></author>
      <author><first>Yu</first><last>Han</last></author>
      <author><first>Lili</first><last>Mou</last></author>
      <author><first>Mauajama</first><last>Firdaus</last></author>
      <pages>5740-5750</pages>
      <abstract>Prompting approaches have been recently explored in text style transfer, where a textual prompt is used to query a pretrained language model (PLM) to generate style-transferred texts word by word in an autoregressive manner. However, such a generation process is less controllable and early prediction errors may affect future word predictions. In this paper, we propose a prompt-based editing approach to text style transfer. Specifically, we prompt a PLM for style classification and use the classification probability to compute a style score. Then, we perform discrete search with word-level editing to maximize a comprehensive scoring function for the style-transfer task. In this way, we transform a prompt-based generation problem into a classification one, which does not suffer from the error accumulation problem and is more controllable than the autoregressive generation of sentences. In our experiments, we performed both automatic and human evaluation on three style-transfer benchmark datasets, and show that our approach largely outperforms the existing systems that have 20 times more parameters. Additional empirical analyses further demonstrate the effectiveness of our approach.</abstract>
      <url hash="83788765">2023.findings-emnlp.381</url>
      <bibkey>luo-etal-2023-prompt</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.381</doi>
    </paper>
    <paper id="382">
      <title>Representativeness as a Forgotten Lesson for Multilingual and Code-switched Data Collection and Preparation</title>
      <author><first>A. Seza</first><last>Doğruöz</last></author>
      <author><first>Sunayana</first><last>Sitaram</last></author>
      <author><first>Zheng Xin</first><last>Yong</last></author>
      <pages>5751-5767</pages>
      <abstract>Multilingualism is widespread around the world and code-switching (CSW) is a common practice among different language pairs/tuples across locations and regions. However, there is still not much progress in building successful CSW systems, despite the recent advances in Massive Multilingual Language Models (MMLMs). We investigate the reasons behind this setback through a critical study about the existing CSW data sets (68) across language pairs in terms of the collection and preparation (e.g. transcription and annotation) stages. This in-depth analysis reveals that <b>a)</b> most CSW data involves English ignoring other language pairs/tuples <b>b)</b> there are flaws in terms of representativeness in data collection and preparation stages due to ignoring the location based, socio-demographic and register variation in CSW. In addition, lack of clarity on the data selection and filtering stages shadow the representativeness of CSW data sets. We conclude by providing a short check-list to improve the representativeness for forthcoming studies involving CSW data collection and preparation.</abstract>
      <url hash="1b206f01">2023.findings-emnlp.382</url>
      <bibkey>dogruoz-etal-2023-representativeness</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.382</doi>
    </paper>
    <paper id="383">
      <title><fixed-case>NER</fixed-case>vous About My Health: Constructing a <fixed-case>B</fixed-case>engali Medical Named Entity Recognition Dataset</title>
      <author><first>Alvi</first><last>Khan</last></author>
      <author><first>Fida</first><last>Kamal</last></author>
      <author><first>Nuzhat</first><last>Nower</last></author>
      <author><first>Tasnim</first><last>Ahmed</last></author>
      <author><first>Sabbir</first><last>Ahmed</last></author>
      <author><first>Tareque</first><last>Chowdhury</last></author>
      <pages>5768-5774</pages>
      <abstract>The ability to identify important entities in a text, known as Named Entity Recognition (NER), is useful in a large variety of downstream tasks in the biomedical domain. This is a considerably difficult task when working with Consumer Health Questions (CHQs), which consist of informal language used in day-to-day life by patients. These difficulties are amplified in the case of Bengali, which allows for a huge amount of flexibility in sentence structures and has significant variances in regional dialects. Unfortunately, the complexity of the language is not accurately reflected in the limited amount of available data, which makes it difficult to build a reliable decision-making system. To address the scarcity of data, this paper presents ‘Bangla-HealthNER’, a comprehensive dataset designed to identify named entities in health-related texts in the Bengali language. It consists of 31,783 samples sourced from a popular online public health platform, which allows it to capture the diverse range of linguistic styles and dialects used by native speakers from various regions in their day-to-day lives. The insight into this diversity in language will prove useful to any medical decision-making systems that are developed for use in real-world applications. To highlight the difficulty of the dataset, it has been benchmarked on state-of-the-art token classification models, where BanglishBERT achieved the highest performance with an F1-score of <tex-math>56.13 \pm 0.75</tex-math>%. The dataset and all relevant code used in this work have been made publicly available.</abstract>
      <url hash="6c41f2c8">2023.findings-emnlp.383</url>
      <bibkey>khan-etal-2023-nervous</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.383</doi>
    </paper>
    <paper id="384">
      <title>Sparse Black-Box Multimodal Attack for Vision-Language Adversary Generation</title>
      <author><first>Zhen</first><last>Yu</last></author>
      <author><first>Zhou</first><last>Qin</last></author>
      <author><first>Zhenhua</first><last>Chen</last></author>
      <author><first>Meihui</first><last>Lian</last></author>
      <author><first>Haojun</first><last>Fu</last></author>
      <author><first>Weigao</first><last>Wen</last></author>
      <author><first>Hui</first><last>Xue</last></author>
      <author><first>Kun</first><last>He</last></author>
      <pages>5775-5784</pages>
      <abstract>Deep neural networks have been widely applied in real-world scenarios, such as product restrictions on e-commerce and hate speech monitoring on social media, to ensure secure governance of various platforms. However, illegal merchants often deceive the detection models by adding large-scale perturbations to prohibited products, so as to earn illegal profits. Current adversarial attacks using imperceptible perturbations encounter challenges in simulating such adversarial behavior and evaluating the vulnerabilities of detection models to such perturbations. To address this issue, we propose a novel black-box multimodal attack, termed Sparse Multimodal Attack (SparseMA), which leverages sparse perturbations to simulate the adversarial behavior exhibited by illegal merchants in the black-box scenario. Moreover, SparseMA bridges the gap between images and texts by treating the separated image patches and text words uniformly in the discrete space. Extensive experiments demonstrate that SparseMA can identify the vulnerability of the model to different modalities, outperforming existing multimodal attacks and unimodal attacks. SparseMA, which is the first proposed method for black-box multimodal attacks to our knowledge, would be used as an effective tool for evaluating the robustness of multimodal models to different modalities.</abstract>
      <url hash="f00ca0c8">2023.findings-emnlp.384</url>
      <bibkey>yu-etal-2023-sparse</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.384</doi>
    </paper>
    <paper id="385">
      <title>Towards a Unified Framework for Reference Retrieval and Related Work Generation</title>
      <author><first>Zhengliang</first><last>Shi</last></author>
      <author><first>Shen</first><last>Gao</last></author>
      <author><first>Zhen</first><last>Zhang</last></author>
      <author><first>Xiuying</first><last>Chen</last></author>
      <author><first>Zhumin</first><last>Chen</last></author>
      <author><first>Pengjie</first><last>Ren</last></author>
      <author><first>Zhaochun</first><last>Ren</last></author>
      <pages>5785-5799</pages>
      <abstract>The task of related work generation aims to generate a comprehensive survey of related research topics automatically, saving time and effort for authors. Existing methods simplify this task by using human-annotated references in a large-scale scientific corpus as information sources, which is time- and cost-intensive. To this end, we propose a Unified Reference Retrieval and Related Work Generation Model (UR3WG), which combines reference retrieval and related work generation processes in a unified framework based on the large language model (LLM). Specifically, UR3WG first leverages the world knowledge of LLM to extend the abstract and generate the query for the subsequent retrieval stage. Then a lexicon-enhanced dense retrieval is proposed to search relevant references, where an importance-aware representation of the lexicon is introduced. We also propose multi-granularity contrastive learning to optimize our retriever. Since this task is not simply summarizing the main points in references, it should analyze the complex relationships and present them logically. We propose an instruction-tuning method to leverage LLM to generate related work. Extensive experiments on two wide-applied datasets demonstrate that our model outperforms the state-of-the-art baselines in both generation and retrieval metrics.</abstract>
      <url hash="37d961e8">2023.findings-emnlp.385</url>
      <bibkey>shi-etal-2023-towards</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.385</doi>
    </paper>
    <paper id="386">
      <title>Visual Storytelling with Question-Answer Plans</title>
      <author><first>Danyang</first><last>Liu</last></author>
      <author><first>Mirella</first><last>Lapata</last></author>
      <author><first>Frank</first><last>Keller</last></author>
      <pages>5800-5813</pages>
      <abstract>Visual storytelling aims to generate compelling narratives from image sequences. Existing models often focus on enhancing the representation of the image sequence, e.g., with external knowledge sources or advanced graph structures. Despite recent progress, the stories are often repetitive, illogical, and lacking in detail. To mitigate these issues, we present a novel framework which integrates visual representations with pretrained language models and planning. Our model translates the image sequence into a visual prefix, a sequence of continuous embeddings which language models can interpret. It also leverages a sequence of question-answer pairs as a blueprint plan for selecting salient visual concepts and determining how they should be assembled into a narrative. Automatic and human evaluation on the VIST benchmark demonstrates that blueprint-based models generate stories that are more coherent, interesting, and natural compared to competitive baselines and state-of-the-art systems.</abstract>
      <url hash="aa520851">2023.findings-emnlp.386</url>
      <bibkey>liu-etal-2023-visual-storytelling</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.386</doi>
    </paper>
    <paper id="387">
      <title>Investigating Online Community Engagement through Stancetaking</title>
      <author><first>Jai</first><last>Aggarwal</last></author>
      <author><first>Brian</first><last>Diep</last></author>
      <author><first>Julia</first><last>Watson</last></author>
      <author><first>Suzanne</first><last>Stevenson</last></author>
      <pages>5814-5830</pages>
      <abstract>Much work has explored lexical and semantic variation in online communities, and drawn connections to community identity and user engagement patterns. Communities also express identity through the sociolinguistic concept of stancetaking. Large-scale computational work on stancetaking has explored community similarities in their preferences for stance markers – words that serve to indicate aspects of a speaker’s stance – without considering the stance-relevant properties of the contexts in which stance markers are used. We propose representations of stance contexts for 1798 Reddit communities and show how they capture community identity patterns distinct from textual or marker similarity measures. We also relate our stance context representations to broader inter- and intra-community engagement patterns, including cross-community posting patterns and social network properties of communities. Our findings highlight the strengths of using rich properties of stance as a way of revealing community identity and engagement patterns in online multi-community spaces.</abstract>
      <url hash="4a937859">2023.findings-emnlp.387</url>
      <bibkey>aggarwal-etal-2023-investigating</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.387</doi>
    </paper>
    <paper id="388">
      <title><fixed-case>ASSERT</fixed-case>: Automated Safety Scenario Red Teaming for Evaluating the Robustness of Large Language Models</title>
      <author><first>Alex</first><last>Mei</last></author>
      <author><first>Sharon</first><last>Levy</last></author>
      <author><first>William</first><last>Wang</last></author>
      <pages>5831-5847</pages>
      <abstract>As large language models are integrated into society, robustness toward a suite of prompts is increasingly important to maintain reliability in a high-variance environment.Robustness evaluations must comprehensively encapsulate the various settings in which a user may invoke an intelligent system. This paper proposes ASSERT, Automated Safety Scenario Red Teaming, consisting of three methods – semantically aligned augmentation, target bootstrapping, and adversarial knowledge injection. For robust safety evaluation, we apply these methods in the critical domain of AI safety to algorithmically generate a test suite of prompts covering diverse robustness settings – semantic equivalence, related scenarios, and adversarial. We partition our prompts into four safety domains for a fine-grained analysis of how the domain affects model performance. Despite dedicated safeguards in existing state-of-the-art models, we find statistically significant performance differences of up to 11% in absolute classification accuracy among semantically related scenarios and error rates of up to 19% absolute error in zero-shot adversarial settings, raising concerns for users’ physical safety.</abstract>
      <url hash="e5a2884c">2023.findings-emnlp.388</url>
      <bibkey>mei-etal-2023-assert</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.388</doi>
    </paper>
    <paper id="389">
      <title>Learning to Correct Noisy Labels for Fine-Grained Entity Typing via Co-Prediction Prompt Tuning</title>
      <author><first>Minghao</first><last>Tang</last></author>
      <author><first>Yongquan</first><last>He</last></author>
      <author><first>Yongxiu</first><last>Xu</last></author>
      <author><first>Hongbo</first><last>Xu</last></author>
      <author><first>Wenyuan</first><last>Zhang</last></author>
      <author><first>Yang</first><last>Lin</last></author>
      <pages>5848-5858</pages>
      <abstract>Fine-grained entity typing (FET) is an essential task in natural language processing that aims to assign semantic types to entities in text. However, FET poses a major challenge known as the noise labeling problem, whereby current methods rely on estimating noise distribution to identify noisy labels but are confused by diverse noise distribution deviation. To address this limitation, we introduce Co-Prediction Prompt Tuning for noise correction in FET, which leverages multiple prediction results to identify and correct noisy labels. Specifically, we integrate prediction results to recall labeled labels and utilize a differentiated margin to identify inaccurate labels. Moreover, we design an optimization objective concerning divergent co-predictions during fine-tuning, ensuring that the model captures sufficient information and maintains robustness in noise identification. Experimental results on three widely-used FET datasets demonstrate that our noise correction approach significantly enhances the quality of various types of training samples, including those annotated using distant supervision, ChatGPT, and crowdsourcing.</abstract>
      <url hash="2a972141">2023.findings-emnlp.389</url>
      <bibkey>tang-etal-2023-learning-correct</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.389</doi>
    </paper>
    <paper id="390">
      <title><fixed-case>C</fixed-case>o<tex-math>^2</tex-math><fixed-case>PT</fixed-case>: Mitigating Bias in Pre-trained Language Models through Counterfactual Contrastive Prompt Tuning</title>
      <author><first>Xiangjue</first><last>Dong</last></author>
      <author><first>Ziwei</first><last>Zhu</last></author>
      <author><first>Zhuoer</first><last>Wang</last></author>
      <author><first>Maria</first><last>Teleki</last></author>
      <author><first>James</first><last>Caverlee</last></author>
      <pages>5859-5871</pages>
      <abstract>Pre-trained Language Models are widely used in many important real-world applications. However, recent studies show that these models can encode social biases from large pre-training corpora and even amplify biases in downstream applications. To address this challenge, we propose Co<tex-math>^2</tex-math>PT, an efficient and effective *debias-while-prompt tuning* method for mitigating biases via counterfactual contrastive prompt tuning on downstream tasks. Our experiments conducted on three extrinsic bias benchmarks demonstrate the effectiveness of Co<tex-math>^2</tex-math>PT on bias mitigation during the prompt tuning process and its adaptability to existing upstream debiased language models. These findings indicate the strength of Co<tex-math>^2</tex-math>PT and provide promising avenues for further enhancement in bias mitigation on downstream tasks.</abstract>
      <url hash="beb08c97">2023.findings-emnlp.390</url>
      <bibkey>dong-etal-2023-co2pt</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.390</doi>
    </paper>
    <paper id="391">
      <title>A Hierarchical Encoding-Decoding Scheme for Abstractive Multi-document Summarization</title>
      <author><first>Chenhui</first><last>Shen</last></author>
      <author><first>Liying</first><last>Cheng</last></author>
      <author><first>Xuan-Phi</first><last>Nguyen</last></author>
      <author><first>Yang</first><last>You</last></author>
      <author><first>Lidong</first><last>Bing</last></author>
      <pages>5872-5887</pages>
      <abstract>Pre-trained language models (PLMs) have achieved outstanding achievements in abstractive single-document summarization (SDS). However, such benefits may not fully extend to multi-document summarization (MDS), where the handling of cross-document information is more complex. Previous works either design new MDS architectures or apply PLMs bluntly with concatenated source documents as a reformulated SDS task. While the former does not utilize previous pre-training efforts and may not generalize well across different domains, the latter may not sufficiently attend to the intricate cross-document relationships unique to MDS tasks. Instead, we enforce hierarchy on both the encoder and decoder to better utilize a PLM to facilitate multi-document interactions for the MDS task. Across 10 MDS benchmarks from various domains, our method outperforms or is competitive with the previous best models, including those with additional MDS pre-training or with more parameters. It outperforms its corresponding PLM backbone by up to 3 Rouge-L and is favored by humans.</abstract>
      <url hash="e43ed64d">2023.findings-emnlp.391</url>
      <bibkey>shen-etal-2023-hierarchical</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.391</doi>
    </paper>
    <paper id="392">
      <title>Universal Domain Adaptation for Robust Handling of Distributional Shifts in <fixed-case>NLP</fixed-case></title>
      <author><first>Hyuhng</first><last>Kim</last></author>
      <author><first>Hyunsoo</first><last>Cho</last></author>
      <author><first>Sang-Woo</first><last>Lee</last></author>
      <author><first>Junyeob</first><last>Kim</last></author>
      <author><first>Choonghyun</first><last>Park</last></author>
      <author><first>Sang-goo</first><last>Lee</last></author>
      <author><first>Kang</first><last>Yoo</last></author>
      <author><first>Taeuk</first><last>Kim</last></author>
      <pages>5888-5905</pages>
      <abstract>When deploying machine learning systems to the wild, it is highly desirable for them to effectively leverage prior knowledge to the unfamiliar domain while also firing alarms to anomalous inputs. In order to address these requirements, Universal Domain Adaptation (UniDA) has emerged as a novel research area in computer vision, focusing on achieving both adaptation ability and robustness (i.e., the ability to detect out-of-distribution samples). While UniDA has led significant progress in computer vision, its application on language input still needs to be explored despite its feasibility. In this paper, we propose a comprehensive benchmark for natural language that offers thorough viewpoints of the model’s generalizability and robustness. Our benchmark encompasses multiple datasets with varying difficulty levels and characteristics, including temporal shifts and diverse domains. On top of our testbed, we validate existing UniDA methods from computer vision and state-of-the-art domain adaptation techniques from NLP literature, yielding valuable findings: We observe that UniDA methods originally designed for image input can be effectively transferred to the natural language domain while also underscoring the effect of adaptation difficulty in determining the model’s performance.</abstract>
      <url hash="2d0dc79b">2023.findings-emnlp.392</url>
      <bibkey>kim-etal-2023-universal</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.392</doi>
    </paper>
    <paper id="393">
      <title>Aligning Language Models to User Opinions</title>
      <author><first>EunJeong</first><last>Hwang</last></author>
      <author><first>Bodhisattwa</first><last>Majumder</last></author>
      <author><first>Niket</first><last>Tandon</last></author>
      <pages>5906-5919</pages>
      <abstract>An important aspect of developing LLMs that interact with humans is to align models’ behavior to their users. It is possible to prompt an LLM into behaving as a certain persona, especially a user group or ideological persona the model captured during its pertaining stage. But, how to best align an LLM with a specific user and not a demographic or ideological group remains an open question. Mining public opinion surveys (by PEW research), we find that the opinions of a user and their demographics and ideologies are not mutual predictors. We use this insight to align LLMs by modeling relevant past user opinions in addition to user demographics and ideology, achieving up to 7 points accuracy gains in predicting public opinions from survey questions across a broad set of topics. Our work opens up the research avenues to bring user opinions as an important ingredient in aligning language models.</abstract>
      <url hash="01271a15">2023.findings-emnlp.393</url>
      <bibkey>hwang-etal-2023-aligning</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.393</doi>
    </paper>
    <paper id="394">
      <title><fixed-case>CCSRD</fixed-case>: Content-Centric Speech Representation Disentanglement Learning for End-to-End Speech Translation</title>
      <author><first>Xiaohu</first><last>Zhao</last></author>
      <author><first>Haoran</first><last>Sun</last></author>
      <author><first>Yikun</first><last>Lei</last></author>
      <author><first>Shaolin</first><last>Zhu</last></author>
      <author><first>Deyi</first><last>Xiong</last></author>
      <pages>5920-5932</pages>
      <abstract>Deep neural networks have demonstrated their capacity in extracting features from speech inputs. However, these features may include non-linguistic speech factors such as timbre and speaker identity, which are not directly related to translation. In this paper, we propose a content-centric speech representation disentanglement learning framework for speech translation, CCSRD, which decomposes speech representations into content representations and non-linguistic representations via representation disentanglement learning. CCSRD consists of a content encoder that encodes linguistic content information from the speech input, a non-content encoder that models non-linguistic speech features, and a disentanglement module that learns disentangled representations with a cyclic reconstructor, feature reconstructor and speaker classifier trained in a multi-task learning way. Experiments on the MuST-C benchmark dataset demonstrate that CCSRD achieves an average improvement of +0.9 BLEU in two settings across five translation directions over the baseline, outperforming state-of-the-art end-to-end speech translation models and cascaded models.</abstract>
      <url hash="0afdbcc2">2023.findings-emnlp.394</url>
      <bibkey>zhao-etal-2023-ccsrd</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.394</doi>
    </paper>
    <paper id="395">
      <title>Miracle: Towards Personalized Dialogue Generation with Latent-Space Multiple Personal Attribute Control</title>
      <author><first>Zhenyi</first><last>Lu</last></author>
      <author><first>Wei</first><last>Wei</last></author>
      <author><first>Xiaoye</first><last>Qu</last></author>
      <author><first>Xian-Ling</first><last>Mao</last></author>
      <author><first>Dangyang</first><last>Chen</last></author>
      <author><first>Jixiong</first><last>Chen</last></author>
      <pages>5933-5957</pages>
      <abstract>Personalized dialogue systems aim to endow the chatbot agent with more anthropomorphic traits for human-like interactions. Previous approaches have explored explicitly user profile modeling using text descriptions, implicit derivation of user embeddings, or utilizing handicraft prompts for ChatGPT-like models. However, textual personas are limited in describing multi-faceted attributes (<i>e.g.</i>, <i>language style, inner character nuances</i>), implicit embedding suffers from personality sparsity, and handicraft prompts lack fine-grained and stable controllability. Hence, these approaches may struggle with complex personalized dialogue generation tasks that require generating controllable responses with multiple personal attributes. To this end, we propose <b>Miracle</b>, a novel personalized dialogue generation method through <b>M</b>ult<b>I</b>ple Pe<b>R</b>sonal <b>A</b>ttributes <b>C</b>ontrol within <b>L</b>atent-Space <b>E</b>nergy-based Models. ttributes <b>C</b>ontrol within <b>L</b>atent-Space <b>E</b>nergy-based Models. Specifically, our approach first disentangles complex personality into multi-faceted attributes. Subsequently, we employ a conditional variational auto-encoder to align with the dense personalized responses within a latent joint attribute space. We have also tailored a dedicated energy function and customized the ordinary differential equations sampling method to offer flexible attribute composition and precise attribute control. Extensive experiments demonstrate that Miracle outperforms several strong baselines in terms of personality controllability and response generation quality. Our dataset and code are available at <url>https://github.com/LZY-the-boys/MIRACLE</url></abstract>
      <url hash="11e83f60">2023.findings-emnlp.395</url>
      <bibkey>lu-etal-2023-miracle</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.395</doi>
    </paper>
    <paper id="396">
      <title>Towards Multilingual Interlinear Morphological Glossing</title>
      <author><first>Shu</first><last>Okabe</last></author>
      <author><first>François</first><last>Yvon</last></author>
      <pages>5958-5971</pages>
      <abstract>Interlinear Morphological Glosses are annotations produced in the context of language documentation. Their goal is to identify morphs occurring in an L1 sentence and to explicit their function and meaning, with the further support of an associated translation in L2. We study here the task of automatic glossing, aiming to provide linguists with adequate tools to facilitate this process. Our formalisation of glossing uses a latent variable Conditional Random Field (CRF), which labels the L1 morphs while simultaneously aligning them to L2 words. In experiments with several under-resourced languages, we show that this approach is both effective and data-efficient and mitigates the problem of annotating unknown morphs. We also discuss various design choices regarding the alignment process and the selection of features. We finally demonstrate that it can benefit from multilingual (pre-)training, achieving results which outperform very strong baselines.</abstract>
      <url hash="8a010fa5">2023.findings-emnlp.396</url>
      <bibkey>okabe-yvon-2023-towards</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.396</doi>
    </paper>
    <paper id="397">
      <title>Transformer Working Memory Enables Regular Language Reasoning And Natural Language Length Extrapolation</title>
      <author><first>Ta-Chung</first><last>Chi</last></author>
      <author><first>Ting-Han</first><last>Fan</last></author>
      <author><first>Alexander</first><last>Rudnicky</last></author>
      <author><first>Peter</first><last>Ramadge</last></author>
      <pages>5972-5984</pages>
      <abstract>Unlike recurrent models, conventional wisdom has it that Transformers cannot perfectly model regular languages. Inspired by the notion of working memory, we propose a new Transformer variant named RegularGPT. With its novel combination of Weight-Sharing, Adaptive-Depth, and Sliding-Dilated-Attention, RegularGPT constructs working memory along the depth dimension, thereby enabling efficient and successful modeling of regular languages such as PARITY. We further test RegularGPT on the task of natural language length extrapolation and surprisingly find that it rediscovers the local windowed attention effect deemed necessary in prior work for length extrapolation.</abstract>
      <url hash="967087eb">2023.findings-emnlp.397</url>
      <bibkey>chi-etal-2023-transformer</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.397</doi>
    </paper>
    <paper id="398">
      <title>Enhancing Conversational Search: Large Language Model-Aided Informative Query Rewriting</title>
      <author><first>Fanghua</first><last>Ye</last></author>
      <author><first>Meng</first><last>Fang</last></author>
      <author><first>Shenghui</first><last>Li</last></author>
      <author><first>Emine</first><last>Yilmaz</last></author>
      <pages>5985-6006</pages>
      <abstract>Query rewriting plays a vital role in enhancing conversational search by transforming context-dependent user queries into standalone forms. Existing approaches primarily leverage human-rewritten queries as labels to train query rewriting models. However, human rewrites may lack sufficient information for optimal retrieval performance. To overcome this limitation, we propose utilizing large language models (LLMs) as query rewriters, enabling the generation of informative query rewrites through well-designed instructions. We define four essential properties for well-formed rewrites and incorporate all of them into the instruction. In addition, we introduce the role of rewrite editors for LLMs when initial query rewrites are available, forming a “rewrite-then-edit” process. Furthermore, we propose distilling the rewriting capabilities of LLMs into smaller models to reduce rewriting latency. Our experimental evaluation on the QReCC dataset demonstrates that informative query rewrites can yield substantially improved retrieval performance compared to human rewrites, especially with sparse retrievers.</abstract>
      <url hash="dbae6471">2023.findings-emnlp.398</url>
      <bibkey>ye-etal-2023-enhancing</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.398</doi>
    </paper>
    <paper id="399">
      <title>Distilling <fixed-case>C</fixed-case>hat<fixed-case>GPT</fixed-case> for Explainable Automated Student Answer Assessment</title>
      <author><first>Jiazheng</first><last>Li</last></author>
      <author><first>Lin</first><last>Gui</last></author>
      <author><first>Yuxiang</first><last>Zhou</last></author>
      <author><first>David</first><last>West</last></author>
      <author><first>Cesare</first><last>Aloisi</last></author>
      <author><first>Yulan</first><last>He</last></author>
      <pages>6007-6026</pages>
      <abstract>Providing explainable and faithful feedback is crucial for automated student answer assessment. In this paper, we introduce a novel framework that explores using ChatGPT, a cutting-edge large language model, for the concurrent tasks of student answer scoring and rationale generation. We identify the appropriate instructions by prompting ChatGPT with different templates to collect the rationales, where inconsistent rationales are refined to align with marking standards. The refined ChatGPT outputs enable us to fine-tune a smaller language model that simultaneously assesses student answers and provides rationales. Extensive experiments on the benchmark dataset show that the proposed method improves the overall QWK score by 11% compared to ChatGPT. Furthermore, our thorough analysis and human evaluation demonstrate that the rationales generated by our proposed method are comparable to those of ChatGPT. Our approach provides a viable solution to achieve explainable automated assessment in education</abstract>
      <url hash="5c786f87">2023.findings-emnlp.399</url>
      <bibkey>li-etal-2023-distilling</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.399</doi>
    </paper>
    <paper id="400">
      <title>Grammatical Error Correction via Mixed-Grained Weighted Training</title>
      <author><first>Jiahao</first><last>Li</last></author>
      <author><first>Quan</first><last>Wang</last></author>
      <author><first>Chiwei</first><last>Zhu</last></author>
      <author><first>Zhendong</first><last>Mao</last></author>
      <author><first>Yongdong</first><last>Zhang</last></author>
      <pages>6027-6037</pages>
      <abstract>The task of Grammatical Error Correction (GEC) aims to automatically correct grammatical errors in natural texts. Almost all previous works treat annotated training data equally, but inherent discrepancies in data are neglected. In this paper, the inherent discrepancies are manifested in two aspects, namely, accuracy of data annotation and diversity of potential annotations. To this end, we propose MainGEC, which designs token-level and sentence-level training weights based on inherent discrepancies therein, and then conducts mixed-grained weighted training to improve the training effect for GEC. Empirical evaluation shows that whether in the Seq2Seq or Seq2Edit manner, MainGEC achieves consistent and significant performance improvements on two benchmark datasets, demonstrating the effectiveness and superiority of the mixed-grained weighted training. Further ablation experiments verify the effectiveness of designed weights for both granularities in MainGEC.</abstract>
      <url hash="4a40e52c">2023.findings-emnlp.400</url>
      <bibkey>li-etal-2023-grammatical</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.400</doi>
    </paper>
    <paper id="401">
      <title>A Unified Framework for Synaesthesia Analysis</title>
      <author><first>Kun</first><last>Sheng</last></author>
      <author><first>Zhongqing</first><last>Wang</last></author>
      <author><first>Qingqing</first><last>Zhao</last></author>
      <author><first>Xiaotong</first><last>Jiang</last></author>
      <author><first>Guodong</first><last>Zhou</last></author>
      <pages>6038-6048</pages>
      <abstract>Synaesthesia refers to the description of perceptions in one sensory modality through concepts from other modalities. It involves not only a linguistic phenomenon, but also a cognitive phenomenon structuring human thought and action, which makes understanding it challenging. As a means of cognition, synaesthesia is rendered by more than sensory modalities, cue and stimulus can also play an important role in expressing and understanding it. In addition, understanding synaesthesia involves many cognitive efforts, such as identifying the semantic relationship between sensory words and modalities. Therefore, we propose a unified framework focusing on annotating all kinds of synaesthetic elements and fully exploring the relationship among them. In particular, we introduce a new annotation scheme, including sensory modalities as well as their cues and stimuli, which facilitate understanding synaesthetic information collectively. We further design a structure generation model to capture the relations among synaesthetic elements and generate them jointly. Through extensive experiments, the importance of proposed dataset can be verified by the statistics and progressive performances. In addition, our proposed model yields state-of-the-art results, demonstrating its effectiveness.</abstract>
      <url hash="816c830d">2023.findings-emnlp.401</url>
      <bibkey>sheng-etal-2023-unified</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.401</doi>
    </paper>
    <paper id="402">
      <title>Domain Private Transformers for Multi-Domain Dialog Systems</title>
      <author><first>Anmol</first><last>Kabra</last></author>
      <author><first>Ethan</first><last>Elenberg</last></author>
      <pages>6049-6061</pages>
      <abstract>Large, general purpose language models have demonstrated impressive performance across many different conversational domains. While multi-domain language models achieve low overall perplexity, their outputs are not guaranteed to stay within the domain of a given input prompt. This paper proposes <i>domain privacy</i> as a novel way to quantify how likely a conditional language model will leak across domains. We also develop policy functions based on token-level domain classification, and propose an efficient fine-tuning method to improve the trained model’s domain privacy. Experiments on membership inference attacks show that our proposed method has comparable resiliency to methods adapted from recent literature on differentially private language models.</abstract>
      <url hash="c4c1e4a5">2023.findings-emnlp.402</url>
      <bibkey>kabra-elenberg-2023-domain</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.402</doi>
    </paper>
    <paper id="403">
      <title>Visual Elements Mining as Prompts for Instruction Learning for Target-Oriented Multimodal Sentiment Classification</title>
      <author><first>Bin</first><last>Yang</last></author>
      <author><first>Jinlong</first><last>Li</last></author>
      <pages>6062-6075</pages>
      <abstract>Target-oriented Multimodal Sentiment Classification (TMSC) aims to incorporate visual modality with text modality to identify the sentiment polarity towards a specific target within a sentence. To address this task, we propose a Visual Elements Mining as Prompts (VEMP) method, which describes the semantic information of visual elements with Text Symbols Embedded in the Image (TSEI), Target-aware Adjective-Noun Pairs (TANPs) and image scene caption, and then transform them into prompts for instruction learning of the model Tk-Instruct. In our VEMP, the text symbols embedded in the image may contain the textual descriptions of fine-grained visual elements, and are extracted as input TSEI; we extract adjective-noun pairs from the image and align them with the target to obtain TANPs, in which the adjectives provide emotional embellishments for the relevant target; finally, to effectively fuse these visual elements with text modality for sentiment prediction, we integrate them to construct instruction prompts for instruction-tuning Tk-Instruct which possesses powerful learning capabilities under instructions. Extensive experimental results show that our method achieves state-of-the-art performance on two benchmark datasets. And further analysis demonstrates the effectiveness of each component of our method.</abstract>
      <url hash="31267f0f">2023.findings-emnlp.403</url>
      <bibkey>yang-li-2023-visual</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.403</doi>
    </paper>
    <paper id="404">
      <title><fixed-case>NASH</fixed-case>: A Simple Unified Framework of Structured Pruning for Accelerating Encoder-Decoder Language Models</title>
      <author><first>Jongwoo</first><last>Ko</last></author>
      <author><first>Seungjoon</first><last>Park</last></author>
      <author><first>Yujin</first><last>Kim</last></author>
      <author><first>Sumyeong</first><last>Ahn</last></author>
      <author><first>Du-Seong</first><last>Chang</last></author>
      <author><first>Euijai</first><last>Ahn</last></author>
      <author><first>Se-Young</first><last>Yun</last></author>
      <pages>6076-6093</pages>
      <abstract>Structured pruning methods have proven effective in reducing the model size and accelerating inference speed in various network architectures such as Transformers. Despite the versatility of encoder-decoder models in numerous NLP tasks, the structured pruning methods on such models are relatively less explored compared to encoder-only models. In this study, we investigate the behavior of the structured pruning of the encoder-decoder models in the decoupled pruning perspective of the encoder and decoder component, respectively. Our findings highlight two insights: (1) the number of decoder layers is the dominant factor of inference speed, and (2) low sparsity in the pruned encoder network enhances generation quality. Motivated by these findings, we propose a simple and effective framework, NASH, that narrows the encoder and shortens the decoder networks of encoder-decoder models. Extensive experiments on diverse generation and inference tasks validate the effectiveness of our method in both speedup and output quality.</abstract>
      <url hash="3d5710fc">2023.findings-emnlp.404</url>
      <bibkey>ko-etal-2023-nash</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.404</doi>
    </paper>
    <paper id="405">
      <title><fixed-case>GBT</fixed-case>: Generative Boosting Training Approach for Paraphrase Identification</title>
      <author><first>Rui</first><last>Peng</last></author>
      <author><first>Zhiling</first><last>Jin</last></author>
      <author><first>Yu</first><last>Hong</last></author>
      <pages>6094-6103</pages>
      <abstract>Paraphrase Identification (PI), a task of determining whether a pair of sentences express the same meaning, is widely applied in Information Retrieval and Question Answering. Data Augmentation (DA) is proven effective in tackling the PI task. However, the majority of DA methods still suffer from two limitations: inefficiency and poor quality. In this study, we propose the Generative Boosting Training (GBT) approach for PI. GBT designs a boosting learning method for a single model based on the human learning process, utilizing seq2seq model to perform DA on misclassified instances periodically. We conduct experiments on the benchmark corpora QQP and LCQMC, towards both English and Chinese PI tasks. Experimental results show that our method yields significant improvements on a variety of Pre-trained Language Model (PLM) based baselines with good efficiency and effectiveness. It is noteworthy that a single BERT model (with a linear classifier) can outperform the state-of-the-art PI models with the boosting of GBT.</abstract>
      <url hash="2f6ae86b">2023.findings-emnlp.405</url>
      <bibkey>peng-etal-2023-gbt</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.405</doi>
    </paper>
    <paper id="406">
      <title><fixed-case>D</fixed-case>e<fixed-case>C</fixed-case>risis<fixed-case>MB</fixed-case>: Debiased Semi-Supervised Learning for Crisis Tweet Classification via Memory Bank</title>
      <author><first>Henry</first><last>Zou</last></author>
      <author><first>Yue</first><last>Zhou</last></author>
      <author><first>Weizhi</first><last>Zhang</last></author>
      <author><first>Cornelia</first><last>Caragea</last></author>
      <pages>6104-6115</pages>
      <abstract>During crisis events, people often use social media platforms such as Twitter to disseminate information about the situation, warnings, advice, and support. Emergency relief organizations leverage such information to acquire timely crisis circumstances and expedite rescue operations. While existing works utilize such information to build models for crisis event analysis, fully-supervised approaches require annotating vast amounts of data and are impractical due to limited response time. On the other hand, semi-supervised models can be biased, performing moderately well for certain classes while performing extremely poorly for others, resulting in substantially negative effects on disaster monitoring and rescue. In this paper, we first study two recent debiasing methods on semi-supervised crisis tweet classification. Then we propose a simple but effective debiasing method, DeCrisisMB, that utilizes a Memory Bank to store and perform equal sampling for generated pseudo-labels from each class at each training iteration. Extensive experiments are conducted to compare different debiasing methods’ performance and generalization ability in both in-distribution and out-of-distribution settings. The results demonstrate the superior performance of our proposed method. Our code is available at https://github.com/HenryPengZou/DeCrisisMB.</abstract>
      <url hash="c7ab2c5c">2023.findings-emnlp.406</url>
      <bibkey>zou-etal-2023-decrisismb</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.406</doi>
    </paper>
    <paper id="407">
      <title>Probing <fixed-case>LLM</fixed-case>s for hate speech detection: strengths and vulnerabilities</title>
      <author><first>Sarthak</first><last>Roy</last></author>
      <author><first>Ashish</first><last>Harshvardhan</last></author>
      <author><first>Animesh</first><last>Mukherjee</last></author>
      <author><first>Punyajoy</first><last>Saha</last></author>
      <pages>6116-6128</pages>
      <abstract>Recently efforts have been made by social media platforms as well as researchers to detect hateful or toxic language using large language models. However, none of these works aim to use explanation, additional context and victim community information in the detection process. We utilise different prompt variation, input information and evaluate large language models in zero shot setting (without adding any in-context examples). We select two large language models (GPT-3.5 and text-davinci) and three datasets - HateXplain, implicit hate and ToxicSpans. We find that on average including the target information in the pipeline improves the model performance substantially (<tex-math>\sim20-30\%</tex-math>) over the baseline across the datasets. There is also a considerable effect of adding the rationales/explanations into the pipeline (<tex-math>\sim10-20\%</tex-math>) over the baseline across the datasets. In addition, we further provide a typology of the error cases where these large language models fail to (i) classify and (ii) explain the reason for the decisions they take. Such vulnerable points automatically constitute ‘jailbreak’ prompts for these models and industry scale safeguard techniques need to be developed to make the models robust against such prompts.</abstract>
      <url hash="22bf3248">2023.findings-emnlp.407</url>
      <bibkey>roy-etal-2023-probing</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.407</doi>
    </paper>
    <paper id="408">
      <title>From Simple to Complex: A Progressive Framework for Document-level Informative Argument Extraction</title>
      <author><first>Quzhe</first><last>Huang</last></author>
      <author><first>Yanxi</first><last>Zhang</last></author>
      <author><first>Dongyan</first><last>Zhao</last></author>
      <pages>6129-6140</pages>
      <abstract>Document-level Event Argument Extraction (EAE) requires the model to extract arguments of multiple events from a single document. Considering the underlying dependencies between these events, recent efforts leverage the idea of “memory”, where the results of already predicted events are cached and can be retrieved to help the prediction of upcoming events. These methods extract events according to their appearance order in the document, however, the event that appears in the first sentence does not mean that it is the easiest to extract. Existing methods might introduce noise to the extraction of upcoming events if they rely on an incorrect prediction of previous events. In order to provide more reliable memory, we propose a simple-to-complex progressive framework for document-level EAE. Specifically, we first calculate the difficulty of each event and then, we conduct the extraction following a simple-to-complex order. In this way, the memory will store the most certain results, and the model could use these reliable sources to help the prediction of more difficult events. Experiments on WikiEvents show that our model outperforms SOTA by 1.4% in F1, indicating the proposed simple-to-complex framework is useful in the EAE task.</abstract>
      <url hash="773c5ce4">2023.findings-emnlp.408</url>
      <bibkey>huang-etal-2023-simple</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.408</doi>
    </paper>
    <paper id="409">
      <title><fixed-case>M</fixed-case>ulti<fixed-case>CMET</fixed-case>: A Novel <fixed-case>C</fixed-case>hinese Benchmark for Understanding Multimodal Metaphor</title>
      <author><first>Dongyu</first><last>Zhang</last></author>
      <author><first>Jingwei</first><last>Yu</last></author>
      <author><first>Senyuan</first><last>Jin</last></author>
      <author><first>Liang</first><last>Yang</last></author>
      <author><first>Hongfei</first><last>Lin</last></author>
      <pages>6141-6154</pages>
      <abstract>Metaphor is a pervasive aspect of human communication, and its presence in multimodal forms has become more prominent with the progress of mass media. However, there is limited research on multimodal metaphor resources beyond the English language. Furthermore, the existing work in natural language processing does not address the exploration of categorizing the source and target domains in metaphors. This omission is significant considering the extensive research conducted in the fields of cognitive linguistics, which emphasizes that a profound understanding of metaphor relies on recognizing the differences and similarities between domain categories. We, therefore, introduce MultiCMET, a multimodal Chinese metaphor dataset, consisting of 13,820 text-image pairs of advertisements with manual annotations of the occurrence of metaphors, domain categories, and sentiments metaphors convey. We also constructed a domain lexicon that encompasses categorizations of metaphorical source domains and target domains and propose a Cascading Domain Knowledge Integration (CDKI) benchmark to detect metaphors by introducing domain-specific lexical features. Experimental results demonstrate the effectiveness of CDKI. The dataset and code are publicly available.</abstract>
      <url hash="680ac78d">2023.findings-emnlp.409</url>
      <bibkey>zhang-etal-2023-multicmet</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.409</doi>
    </paper>
    <paper id="410">
      <title><fixed-case>G</fixed-case>lot<fixed-case>LID</fixed-case>: Language Identification for Low-Resource Languages</title>
      <author><first>Amir</first><last>Kargaran</last></author>
      <author><first>Ayyoob</first><last>Imani</last></author>
      <author><first>François</first><last>Yvon</last></author>
      <author><first>Hinrich</first><last>Schuetze</last></author>
      <pages>6155-6218</pages>
      <abstract>Several recent papers have published good solutions for language identification (LID) for about 300 high-resource and medium-resource languages. However, there is no LID available that (i) covers a wide range of low-resource languages, (ii) is rigorously evaluated and reliable and (iii) efficient and easy to use. Here, we publish GlotLID-M, an LID model that satisfies the desiderata of wide coverage, reliability and efficiency. It identifies 1665 languages, a large increase in coverage compared to prior work. In our experiments, GlotLID-M outperforms four baselines (CLD3, FT176, OpenLID and NLLB) when balancing F1 and false positive rate (FPR). We analyze the unique challenges that low-resource LID poses: incorrect corpus metadata, leakage from high-resource languages, difficulty separating closely related languages, handling of macrolanguage vs varieties and in general noisy data. We hope that integrating GlotLID-M into dataset creation pipelines will improve quality and enhance accessibility of NLP technology for low-resource languages and cultures. GlotLID-M model, code, and list of data sources are available: https://github.com/cisnlp/GlotLID.</abstract>
      <url hash="d231faeb">2023.findings-emnlp.410</url>
      <bibkey>kargaran-etal-2023-glotlid</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.410</doi>
    </paper>
    <paper id="411">
      <title>Finding Support Examples for In-Context Learning</title>
      <author><first>Xiaonan</first><last>Li</last></author>
      <author><first>Xipeng</first><last>Qiu</last></author>
      <pages>6219-6235</pages>
      <abstract>In-context learning is a new learning paradigm where a language model observes a few examples and directly outputs the test input’s prediction. Previous works have shown that it is sensitive to the provided examples and randomly sampled examples probably cause inferior performance. In this paper, we propose finding “support examples” for in-context learning: Given a training dataset, it aims to select one permutation of a few examples, which can well characterize the task for in-context learning and thus lead to superior performance. Although for traditional gradient-based training, there are extensive methods to find a coreset from the entire dataset, they struggle to find important in-context examples, because in-context learning occurs in the language model’s forward process without gradients or parameter updates and thus has a significant gap with traditional training. Additionally, the strong dependence among in-context examples makes it an NP-hard combinatorial optimization problem and enumerating all permutations is infeasible. Hence we propose **LENS**, a fi**L**ter-th**EN**-**S**earch method to tackle this challenge in two stages: irst we filter the dataset to obtain individually informative in-context examples. Specifically, we propose a novel metric, InfoScore, to evaluate the example’s in-context informativeness based on the language model’s feedback, and further propose a progressive filtering process to filter out uninformative examples. Then we propose diversity-guided example search which iteratively refines and evaluates the selected example permutations, to find examples that fully depict the task. The experimental results show that LENS significantly outperforms a wide range of baselines and further analyses show that each component contribute critically to the improvements and shed light on the principles of supporting examples and in-context learning.</abstract>
      <url hash="16ed3581">2023.findings-emnlp.411</url>
      <bibkey>li-qiu-2023-finding</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.411</doi>
    </paper>
    <paper id="412">
      <title>Uncovering the Root of Hate Speech: A Dataset for Identifying Hate Instigating Speech</title>
      <author><first>Hyoungjun</first><last>Park</last></author>
      <author><first>Ho</first><last>Shim</last></author>
      <author><first>Kyuhan</first><last>Lee</last></author>
      <pages>6236-6245</pages>
      <abstract>While many prior studies have applied computational approaches, such as machine learning, to detect and moderate hate speech, only scant attention has been paid to the task of identifying the underlying cause of hate speech. In this study, we introduce the concept of hate instigating speech, which refers to a specific type of textual posts on online platforms that stimulate or provoke others to engage in hate speech. The identification of hate instigating speech carries substantial practical implications for effective hate speech moderation. Rather than targeting individual instances of hate speech, by focusing on their roots, i.e., hate instigating speech, it becomes possible to significantly reduce the volume of content that requires review for moderation. Additionally, targeting hate instigating speech enables early prevention of the spread and propagation of hate speech, further enhancing the effectiveness of moderation efforts. However, several challenges hinder researchers from addressing the identification of hate instigating speech. First, there is a lack of comprehensive datasets specifically annotated for hate instigation, making it difficult to train and evaluate computational models effectively. Second, the subtle and nuanced nature of hate instigating speech (e.g., seemingly non-offensive texts serve as catalysts for triggering hate speech) makes it difficult to apply off-the-shelf machine learning models to the problem. To address these challenges, in this study, we have developed and released a multilingual dataset specifically designed for the task of identifying hate instigating speech. Specifically, it encompasses both English and Korean, allowing for a comprehensive examination of hate instigating speech across different linguistic contexts. We have applied existing machine learning models to our dataset and the results demonstrate that the extant models alone are insufficient for effectively detecting hate instigating speech. This finding highlights the need for further attention from the academic community to address this specific challenge. We expect our study and dataset to inspire researchers to explore innovative methods that can enhance the accuracy of hate instigating speech detection, ultimately contributing to more effective moderation and prevention of hate speech propagation online.</abstract>
      <url hash="2ab9749d">2023.findings-emnlp.412</url>
      <bibkey>park-etal-2023-uncovering</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.412</doi>
    </paper>
    <paper id="413">
      <title>Responsible <fixed-case>AI</fixed-case> Considerations in Text Summarization Research: A Review of Current Practices</title>
      <author><first>Yu Lu</first><last>Liu</last></author>
      <author><first>Meng</first><last>Cao</last></author>
      <author><first>Su Lin</first><last>Blodgett</last></author>
      <author><first>Jackie Chi Kit</first><last>Cheung</last></author>
      <author><first>Alexandra</first><last>Olteanu</last></author>
      <author><first>Adam</first><last>Trischler</last></author>
      <pages>6246-6261</pages>
      <abstract>AI and NLP publication venues have increasingly encouraged researchers to reflect on possible ethical considerations, adverse impacts, and other responsible AI issues their work might engender. However, for specific NLP tasks our understanding of how prevalent such issues are, or when and why these issues are likely to arise, remains limited. Focusing on text summarization—a common NLP task largely overlooked by the responsible AI community—we examine research and reporting practices in the current literature. We conduct a multi-round qualitative analysis of 333 summarization papers from the ACL Anthology published between 2020–2022. We focus on how, which, and when responsible AI issues are covered, which relevant stakeholders are considered, and mismatches between stated and realized research goals. We also discuss current evaluation practices and consider how authors discuss the limitations of both prior work and their own work. Overall, we find that relatively few papers engage with possible stakeholders or contexts of use, which limits their consideration of potential downstream adverse impacts or other responsible AI issues. Based on our findings, we make recommendations on concrete practices and research directions.</abstract>
      <url hash="cf315432">2023.findings-emnlp.413</url>
      <bibkey>liu-etal-2023-responsible</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.413</doi>
    </paper>
    <paper id="414">
      <title>Improving Speech Translation by Fusing Speech and Text</title>
      <author><first>Wenbiao</first><last>Yin</last></author>
      <author><first>Zhicheng</first><last>Liu</last></author>
      <author><first>Chengqi</first><last>Zhao</last></author>
      <author><first>Tao</first><last>Wang</last></author>
      <author><first>Jian</first><last>Tong</last></author>
      <author><first>Rong</first><last>Ye</last></author>
      <pages>6262-6273</pages>
      <abstract>In speech translation, leveraging multimodal data to improve model performance and address limitations of individual modalities has shown significant effectiveness. In this paper, we harness the complementary strengths of speech and text to improve speech translation. However, speech and text are disparate modalities, we observe three aspects of modality gap that impede their integration in a speech translation model. To tackle these gaps, we propose **Fuse**-**S**peech-**T**ext (**FuseST**), a cross-modal model which supports three distinct input modalities for translation: speech, text and fused speech-text. We leverage multiple techniques for cross-modal alignment and conduct a comprehensive analysis to assess its impact on speech translation, machine translation and fused speech-text translation. We evaluate FuseST on MuST-C, GigaST and newstest benchmark. Experiments show that the proposed FuseST achieves an average 34.0 BLEU on MuST-C En<tex-math>\rightarrow</tex-math>De/Es/Fr (vs SOTA +1.1 BLEU). Further experiments demonstrate that FuseST does not degrade on MT task, as observed in previous works. Instead, it yields an average improvement of 3.2 BLEU over the pre-trained MT model. Code is available at https://github.com/WenbiaoYin/FuseST.</abstract>
      <url hash="415eb629">2023.findings-emnlp.414</url>
      <bibkey>yin-etal-2023-improving</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.414</doi>
    </paper>
    <paper id="415">
      <title>Narrative Order Aware Story Generation via Bidirectional Pretraining Model with Optimal Transport Reward</title>
      <author><first>Zhicong</first><last>Lu</last></author>
      <author><first>Li</first><last>Jin</last></author>
      <author><first>Guangluan</first><last>Xu</last></author>
      <author><first>Linmei</first><last>Hu</last></author>
      <author><first>Nayu</first><last>Liu</last></author>
      <author><first>Xiaoyu</first><last>Li</last></author>
      <author><first>Xian</first><last>Sun</last></author>
      <author><first>Zequn</first><last>Zhang</last></author>
      <author><first>Kaiwen</first><last>Wei</last></author>
      <pages>6274-6287</pages>
      <abstract>To create a captivating story, a writer often plans a sequence of logically coherent events and ingeniously manipulates the narrative order to generate flashback in place. However, existing storytelling systems suffer from both insufficient understanding of event correlations and inadequate awareness of event temporal order (e.g., go to hospital &lt;after&gt; get ill), making it challenging to generate high-quality events that balance the logic and narrative order of story. In this paper, we propose a narrative order aware framework BPOT (Bidirectional Pretraining Model with Optimal Transport Reward) for story generation, which presents a bidirectional pretrained model to encode event correlations and pairwise event order. We also design a reinforcement learning algorithm with novel optimal transport reward to further improve the quality of generated events in the fine-tuning stage. Specifically, a narrative order aware event sequence model is pretrained with the joint learning objectives of event blank infilling and pairwise order prediction. Then, reinforcement learning with novel optimal transport reward is designed to further improve the generated event quality in the fine-tuning stage. The novel optimal transport reward captures the mappings between the generated events and the sentences in the story, effectively measuring the quality of generated events. Both automatic and manual evaluation results demonstrate the superiority of our framework in generating logically coherent stories with flashbacks.</abstract>
      <url hash="921c037e">2023.findings-emnlp.415</url>
      <bibkey>lu-etal-2023-narrative</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.415</doi>
    </paper>
    <paper id="416">
      <title>Explainable Claim Verification via Knowledge-Grounded Reasoning with Large Language Models</title>
      <author><first>Haoran</first><last>Wang</last></author>
      <author><first>Kai</first><last>Shu</last></author>
      <pages>6288-6304</pages>
      <abstract>Claim verification plays a crucial role in combating misinformation. While existing works on claim verification have shown promising results, a crucial piece of the puzzle that remains unsolved is to understand how to verify claims without relying on human-annotated data, which is expensive to create at a large scale. Additionally, it is important for models to provide comprehensive explanations that can justify their decisions and assist human fact-checkers. This paper presents First-Order-Logic-Guided Knowledge-Grounded (FOLK) Reasoning that can verify complex claims and generate explanations without the need for annotated evidence using Large Language Models (LLMs). FOLK leverages the in-context learning ability of LLMs to translate the claim into a First-Order-Logic (FOL) clause consisting of predicates, each corresponding to a sub-claim that needs to be verified. Then, FOLK performs FOL-Guided reasoning over a set of knowledge-grounded question-and-answer pairs to make veracity predictions and generate explanations to justify its decision-making process. This process makes our model highly explanatory, providing clear explanations of its reasoning process in human-readable form. Our experiment results indicate that FOLK outperforms strong baselines on three datasets encompassing various claim verification challenges. Our code and data are available.</abstract>
      <url hash="c8d17f6b">2023.findings-emnlp.416</url>
      <bibkey>wang-shu-2023-explainable</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.416</doi>
    </paper>
    <paper id="417">
      <title>Strong and Efficient Baselines for Open Domain Conversational Question Answering</title>
      <author><first>Andrei</first><last>Coman</last></author>
      <author><first>Gianni</first><last>Barlacchi</last></author>
      <author><first>Adrià</first><last>de Gispert</last></author>
      <pages>6305-6314</pages>
      <abstract>Unlike the Open Domain Question Answering (ODQA) setting, the conversational (ODConvQA) domain has received limited attention when it comes to reevaluating baselines for both efficiency and effectiveness. In this paper, we study the State-of-the-Art (SotA) Dense Passage Retrieval (DPR) retriever and Fusion-in-Decoder (FiD) reader pipeline, and show that it significantly underperforms when applied to ODConvQA tasks due to various limitations. We then propose and evaluate strong yet simple and efficient baselines, by introducing a fast reranking component between the retriever and the reader, and by performing targeted finetuning steps. Experiments on two ODConvQA tasks, namely TopiOCQA and OR-QuAC, show that our method improves the SotA results, while reducing reader’s latency by 60%. Finally, we provide new and valuable insights into the development of challenging baselines that serve as a reference for future, more intricate approaches, including those that leverage Large Language Models (LLMs).</abstract>
      <url hash="75a385be">2023.findings-emnlp.417</url>
      <bibkey>coman-etal-2023-strong</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.417</doi>
    </paper>
    <paper id="418">
      <title>Efficient Continue Training of Temporal Language Model with Structural Information</title>
      <author><first>Zhaochen</first><last>Su</last></author>
      <author><first>Juntao</first><last>Li</last></author>
      <author><first>Zikang</first><last>Zhang</last></author>
      <author><first>Zihan</first><last>Zhou</last></author>
      <author><first>Min</first><last>Zhang</last></author>
      <pages>6315-6329</pages>
      <abstract>Current language models are mainly trained on snap-shots of data gathered at a particular time, which decreases their capability to generalize over time and model language change. To model the <i>time</i> variable, existing works have explored temporal language models (e.g., TempoBERT) by directly incorporating the timestamp into the training process. While effective to some extent, these methods are limited by the superficial temporal information brought by timestamps, which fails to learn the inherent changes of linguistic components. In this paper, we empirically confirm that the performance of pre-trained language models (PLMs) is closely affiliated with syntactically changed tokens. Based on this observation, we propose a simple yet effective method named <i>
          <b>S</b>yntax-<b>G</b>uided <b>T</b>emporal <b>L</b>anguage <b>M</b>odel</i> (SG-TLM), which could learn the inherent language changes by capturing an intrinsic relationship between the <i>time</i> prefix and the tokens with salient syntactic change. Experiments on two datasets and three tasks demonstrate that our model outperforms existing temporal language models in both memorization and generalization capabilities. Extensive results further confirm the effectiveness of our approach across different model frameworks, including both encoder-only and decoder-only models (e.g., LLaMA). Our code is available at <url>https://github.com/zhaochen0110/TempoLM</url>.</abstract>
      <url hash="d6ea2b14">2023.findings-emnlp.418</url>
      <bibkey>su-etal-2023-efficient</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.418</doi>
    </paper>
    <paper id="419">
      <title>Retrieval-Augmented Parsing for Complex Graphs by Exploiting Structure and Uncertainty</title>
      <author><first>Zi</first><last>Lin</last></author>
      <author><first>Quan</first><last>Yuan</last></author>
      <author><first>Panupong</first><last>Pasupat</last></author>
      <author><first>Jeremiah</first><last>Liu</last></author>
      <author><first>Jingbo</first><last>Shang</last></author>
      <pages>6330-6345</pages>
      <abstract>Retrieval augmentation enhances generative language models by retrieving informative exemplars relevant for output prediction. However, in realistic graph parsing problems where the output space is large and complex, classic retrieval methods based on input-sentence similarity can fail to identify the most informative exemplars that target graph elements the model is most struggling about, leading to suboptimal retrieval and compromised prediction under limited retrieval budget. In this work, we improve retrieval-augmented parsing for complex graph problems by exploiting two unique sources of information (1) structural similarity and (2) model uncertainty. We propose <tex-math>\textit{\textbf{S}tructure-aware and \textbf{U}ncertainty-\textbf{G}uided \textbf{A}daptive \textbf{R}etrieval} \textbf{(SUGAR)}</tex-math> that first quantify the model uncertainty in graph prediction and identify its most uncertain subgraphs, and then retrieve exemplars based on their structural similarity with the identified uncertain subgraphs. On a suite of real-world parsing benchmarks with non-trivial graph structure (SMCalflow and E-commerce), SUGAR exhibits a strong advantage over its classic counterparts that do not leverage structure or model uncertainty.</abstract>
      <url hash="b060d05a">2023.findings-emnlp.419</url>
      <bibkey>lin-etal-2023-retrieval</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.419</doi>
    </paper>
    <paper id="420">
      <title>When it Rains, it Pours: Modeling Media Storms and the News Ecosystem</title>
      <author><first>Benjamin</first><last>Litterer</last></author>
      <author><first>David</first><last>Jurgens</last></author>
      <author><first>Dallas</first><last>Card</last></author>
      <pages>6346-6361</pages>
      <abstract>Most events in the world receive at most brief coverage by the news media. Occasionally, however, an event will trigger a media storm, with voluminous and widespread coverage lasting for weeks instead of days. In this work, we develop and apply a pairwise article similarity model, allowing us to identify story clusters in corpora covering local and national online news, and thereby create a comprehensive corpus of media storms over a nearly two year period. Using this corpus, we investigate media storms at a new level of granularity, allowing us to validate claims about storm evolution and topical distribution, and provide empirical support for previously hypothesized patterns of influence of storms on media coverage and intermedia agenda setting.</abstract>
      <url hash="aadc2a79">2023.findings-emnlp.420</url>
      <bibkey>litterer-etal-2023-rains</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.420</doi>
    </paper>
    <paper id="421">
      <title>Intra-Event and Inter-Event Dependency-Aware Graph Network for Event Argument Extraction</title>
      <author><first>Hao</first><last>Li</last></author>
      <author><first>Yanan</first><last>Cao</last></author>
      <author><first>Yubing</first><last>Ren</last></author>
      <author><first>Fang</first><last>Fang</last></author>
      <author><first>Lanxue</first><last>Zhang</last></author>
      <author><first>Yingjie</first><last>Li</last></author>
      <author><first>Shi</first><last>Wang</last></author>
      <pages>6362-6372</pages>
      <abstract>Event argument extraction is critical to various natural language processing tasks for providing structured information. Existing works usually extract the event arguments one by one, and mostly neglect to build dependency information among event argument roles, especially from the perspective of event structure. Such an approach hinders the model from learning the interactions between different roles. In this paper, we raise our research question: How to adequately model dependencies between different roles for better performance? To this end, we propose an intra-event and inter-event dependency-aware graph network, which uses the event structure as the fundamental unit to construct dependencies between roles. Specifically, we first utilize the dense intra-event graph to construct role dependencies within events, and then construct dependencies between events by retrieving similar events of the current event through the retrieval module. To further optimize dependency information and event representation, we propose a dependency interaction module and two auxiliary tasks to improve the extraction ability of the model in different scenarios. Experimental results on the ACE05, RAMS, and WikiEvents datasets show the great advantages of our proposed approach.</abstract>
      <url hash="eb072aa8">2023.findings-emnlp.421</url>
      <bibkey>li-etal-2023-intra</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.421</doi>
    </paper>
    <paper id="422">
      <title>From Relevance to Utility: Evidence Retrieval with Feedback for Fact Verification</title>
      <author><first>Hengran</first><last>Zhang</last></author>
      <author><first>Ruqing</first><last>Zhang</last></author>
      <author><first>Jiafeng</first><last>Guo</last></author>
      <author><first>Maarten</first><last>de Rijke</last></author>
      <author><first>Yixing</first><last>Fan</last></author>
      <author><first>Xueqi</first><last>Cheng</last></author>
      <pages>6373-6384</pages>
      <abstract>Retrieval-enhanced methods have become a primary approach in fact verification (FV); it requires reasoning over multiple retrieved pieces of evidence to verify the integrity of a claim. To retrieve evidence, existing work often employs off-the-shelf retrieval models whose design is based on the probability ranking principle. We argue that, rather than relevance, for FV we need to focus on the utility that a claim verifier derives from the retrieved evidence. We introduce the <tex-math>\textbf{feedback-based evidence retriever} (FER)</tex-math> that optimizes the evidence retrieval process by incorporating feedback from the claim verifier. As a feedback signal we use the divergence in utility between how effectively the verifier utilizes the retrieved evidence and the ground-truth evidence to produce the final claim label. Empirical studies demonstrate the superiority of FER over prevailing baselines.</abstract>
      <url hash="d436dc30">2023.findings-emnlp.422</url>
      <bibkey>zhang-etal-2023-relevance</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.422</doi>
    </paper>
    <paper id="423">
      <title>How to Train Your Dragon: Diverse Augmentation Towards Generalizable Dense Retrieval</title>
      <author><first>Sheng-Chieh</first><last>Lin</last></author>
      <author><first>Akari</first><last>Asai</last></author>
      <author><first>Minghan</first><last>Li</last></author>
      <author><first>Barlas</first><last>Oguz</last></author>
      <author><first>Jimmy</first><last>Lin</last></author>
      <author><first>Yashar</first><last>Mehdad</last></author>
      <author><first>Wen-tau</first><last>Yih</last></author>
      <author><first>Xilun</first><last>Chen</last></author>
      <pages>6385-6400</pages>
      <abstract>Various techniques have been developed in recent years to improve dense retrieval (DR), such as unsupervised contrastive learning and pseudo-query generation. Existing DRs, however, often suffer from effectiveness tradeoffs between supervised and zero-shot retrieval, which some argue was due to the limited model capacity. We contradict this hypothesis and show that a generalizable DR can be trained to achieve high accuracy in both supervised and zero-shot retrieval without increasing model size. In particular, we systematically examine the contrastive learning of DRs, under the framework of Data Augmentation (DA). Our study shows that common DA practices such as query augmentation with generative models and pseudo-relevance label creation using a cross-encoder, are often inefficient and sub-optimal. We hence propose a new DA approach with diverse queries and sources of supervision to progressively train a generalizable DR. As a result, DRAGON, our Dense Retriever trained with diverse AuGmentatiON, is the first BERT-base-sized DR to achieve state-of-the-art effectiveness in both supervised and zero-shot evaluations and even competes with models using more complex late interaction.</abstract>
      <url hash="9cbcc8d4">2023.findings-emnlp.423</url>
      <bibkey>lin-etal-2023-train</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.423</doi>
    </paper>
    <paper id="424">
      <title>Discovering Highly Influential Shortcut Reasoning: An Automated Template-Free Approach</title>
      <author><first>Daichi</first><last>Haraguchi</last></author>
      <author><first>Kiyoaki</first><last>Shirai</last></author>
      <author><first>Naoya</first><last>Inoue</last></author>
      <author><first>Natthawut</first><last>Kertkeidkachorn</last></author>
      <pages>6401-6407</pages>
      <abstract>Shortcut reasoning is an irrational process of inference, which degrades the robustness of an NLP model. While a number of previous work has tackled the identification of shortcut reasoning, there are still two major limitations: (i) a method for quantifying the severity of the discovered shortcut reasoning is not provided; (ii) certain types of shortcut reasoning may be missed. To address these issues, we propose a novel method for identifying shortcut reasoning. The proposed method quantifies the severity of the shortcut reasoning by leveraging out-of-distribution data and does not make any assumptions about the type of tokens triggering the shortcut reasoning. Our experiments on Natural Language Inference and Sentiment Analysis demonstrate that our framework successfully discovers known and unknown shortcut reasoning in the previous work.</abstract>
      <url hash="2d8d6d79">2023.findings-emnlp.424</url>
      <bibkey>haraguchi-etal-2023-discovering</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.424</doi>
    </paper>
    <paper id="425">
      <title>Schema-adaptable Knowledge Graph Construction</title>
      <author><first>Hongbin</first><last>Ye</last></author>
      <author><first>Honghao</first><last>Gui</last></author>
      <author><first>Xin</first><last>Xu</last></author>
      <author><first>Xi</first><last>Chen</last></author>
      <author><first>Huajun</first><last>Chen</last></author>
      <author><first>Ningyu</first><last>Zhang</last></author>
      <pages>6408-6431</pages>
      <abstract>Conventional Knowledge Graph Construction (KGC) approaches typically follow the static information extraction paradigm with a closed set of pre-defined schema. As a result, such approaches fall short when applied to dynamic scenarios or domains, whereas a new type of knowledge emerges. This necessitates a system that can handle evolving schema automatically to extract information for KGC. To address this need, we propose a new task called schema-adaptable KGC, which aims to continually extract entity, relation, and event based on a dynamically changing schema graph without re-training. We first split and convert existing datasets based on three principles to build a benchmark, i.e., horizontal schema expansion, vertical schema expansion, and hybrid schema expansion; then investigate the schema-adaptable performance of several well-known approaches such as Text2Event, TANL, UIE and GPT-3.5. We further propose a simple yet effective baseline dubbed AdaKGC, which contains schema-enriched prefix instructor and schema-conditioned dynamic decoding to better handle evolving schema. Comprehensive experimental results illustrate that AdaKGC can outperform baselines but still have room for improvement. We hope the proposed work can deliver benefits to the community.</abstract>
      <url hash="213113ea">2023.findings-emnlp.425</url>
      <bibkey>ye-etal-2023-schema</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.425</doi>
    </paper>
    <paper id="426">
      <title>Evaluating the Knowledge Base Completion Potential of <fixed-case>GPT</fixed-case></title>
      <author><first>Blerta</first><last>Veseli</last></author>
      <author><first>Simon</first><last>Razniewski</last></author>
      <author><first>Jan-Christoph</first><last>Kalo</last></author>
      <author><first>Gerhard</first><last>Weikum</last></author>
      <pages>6432-6443</pages>
      <abstract>Structured knowledge bases (KBs) are an asset for search engines and other applications but are inevitably incomplete. Language models (LMs) have been proposed for unsupervised knowledge base completion (KBC), yet, their ability to do this at scale and with high accuracy remains an open question. Prior experimental studies mostly fall short because they only evaluate on popular subjects, or sample already existing facts from KBs. In this work, we perform a careful evaluation of GPT’s potential to complete the largest public KB: Wikidata. We find that, despite their size and capabilities, models like GPT-3, ChatGPT and GPT-4 do not achieve fully convincing results on this task. Nonetheless, it provides solid improvements over earlier approaches with smaller LMs. In particular, we show that it is feasible to extend Wikidata by 27M facts at 90% precision.</abstract>
      <url hash="7b1753d2">2023.findings-emnlp.426</url>
      <bibkey>veseli-etal-2023-evaluating</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.426</doi>
    </paper>
    <paper id="427">
      <title><fixed-case>C</fixed-case>onic10<fixed-case>K</fixed-case>: A Challenging Math Problem Understanding and Reasoning Dataset</title>
      <author><first>Haoyi</first><last>Wu</last></author>
      <author><first>Wenyang</first><last>Hui</last></author>
      <author><first>Yezeng</first><last>Chen</last></author>
      <author><first>Weiqi</first><last>Wu</last></author>
      <author><first>Kewei</first><last>Tu</last></author>
      <author><first>Yi</first><last>Zhou</last></author>
      <pages>6444-6458</pages>
      <abstract>Mathematical understanding and reasoning are crucial tasks for assessing the capabilities of artificial intelligence (AI). However, existing benchmarks either require just a few steps of reasoning, or only contain a small amount of data in one specific topic, making it hard to analyse AI’s behaviour with reference to different problems within a specific topic in detail. In this work, we propose Conic10K, a challenging math problem dataset on conic sections in Chinese senior high school education. Our dataset contains various problems with different reasoning depths, while only the knowledge from conic sections is required. Since the dataset only involves a narrow range of knowledge, it is easy to separately analyse the knowledge a model possesses and the reasoning ability it has. For each problem, we provide a high-quality formal representation, the reasoning steps, and the final solution. Experiments show that existing large language models, including GPT-4, exhibit weak performance on complex reasoning. We hope that our findings could inspire more advanced techniques for precise natural language understanding and reasoning. Our dataset and codes are available at https://github.com/whyNLP/Conic10K.</abstract>
      <url hash="1e09efa2">2023.findings-emnlp.427</url>
      <bibkey>wu-etal-2023-conic10k</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.427</doi>
    </paper>
    <paper id="428">
      <title><fixed-case>D</fixed-case>ep<fixed-case>W</fixed-case>i<fixed-case>GNN</fixed-case>: A Depth-wise Graph Neural Network for Multi-hop Spatial Reasoning in Text</title>
      <author><first>Shuaiyi</first><last>Li</last></author>
      <author><first>Yang</first><last>Deng</last></author>
      <author><first>Wai</first><last>Lam</last></author>
      <pages>6459-6471</pages>
      <abstract>Spatial reasoning in text plays a crucial role in various real-world applications. Existing approaches for spatial reasoning typically infer spatial relations from pure text, which overlook the gap between natural language and symbolic structures. Graph neural networks (GNNs) have showcased exceptional proficiency in inducing and aggregating symbolic structures. However, classical GNNs face challenges in handling multi-hop spatial reasoning due to the over-smoothing issue, i.e., the performance decreases substantially as the number of graph layers increases. To cope with these challenges, we propose a novel Depth-Wise Graph Neural Network (DepWiGNN). Specifically, we design a novel node memory scheme and aggregate the information over the depth dimension instead of the breadth dimension of the graph, which empowers the ability to collect long dependencies without stacking multiple layers. Experimental results on two challenging multi-hop spatial reasoning datasets show that DepWiGNN outperforms existing spatial reasoning methods. The comparisons with the other three GNNs further demonstrate its superiority in capturing long dependency in the graph.</abstract>
      <url hash="efb8bf19">2023.findings-emnlp.428</url>
      <bibkey>li-etal-2023-depwignn</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.428</doi>
    </paper>
    <paper id="429">
      <title><fixed-case>TK</fixed-case>-<fixed-case>KNN</fixed-case>: A Balanced Distance-Based Pseudo Labeling Approach for Semi-Supervised Intent Classification</title>
      <author><first>Nicholas</first><last>Botzer</last></author>
      <author><first>David</first><last>Vazquez</last></author>
      <author><first>Tim</first><last>Weninger</last></author>
      <author><first>Issam</first><last>Laradji</last></author>
      <pages>6472-6484</pages>
      <abstract>The ability to detect intent in dialogue systems has become increasingly important in modern technology. These systems often generate a large amount of unlabeled data, and manually labeling this data requires substantial human effort. Semi-supervised methods attempt to remedy this cost by using a model trained on a few labeled examples and then by assigning pseudo-labels to further a subset of unlabeled examples that has a model prediction confidence higher than a certain threshold. However, one particularly perilous consequence of these methods is the risk of picking an imbalanced set of examples across classes, which could lead to poor labels. In the present work, we describe Top-K K-Nearest Neighbor (TK-KNN), which uses a more robust pseudo-labeling approach based on distance in the embedding space while maintaining a balanced set of pseudo-labeled examples across classes through a ranking-based approach. Experiments on several datasets show that TK-KNN outperforms existing models, particularly when labeled data is scarce on popular datasets such as CLINC150 and Banking77.</abstract>
      <url hash="d76c0572">2023.findings-emnlp.429</url>
      <bibkey>botzer-etal-2023-tk</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.429</doi>
    </paper>
    <paper id="430">
      <title>Late Fusion of Transformers for Sentiment Analysis of Code-Switched Data</title>
      <author><first>Gagan</first><last>Sharma</last></author>
      <author><first>R</first><last>Chinmay</last></author>
      <author><first>Raksha</first><last>Sharma</last></author>
      <pages>6485-6490</pages>
      <abstract>Code-switching is a common phenomenon in multilingual communities and is often used on social media. However, sentiment analysis of code-switched data is a challenging yet less explored area of research. This paper aims to develop a sentiment analysis system for code-switched data. In this paper, we present a novel approach combining two transformers using logits of their output and feeding them to a neural network for classification. We show the efficacy of our approach using two benchmark datasets, viz., English-Hindi (En-Hi), and English-Spanish (En-Es) availed by Microsoft GLUECoS. Our approach results in an F1 score of 73.66% for En-Es and 61.24% for En-Hi, significantly higher than the best model reported for the GLUECoS benchmark dataset.</abstract>
      <url hash="0582ff5c">2023.findings-emnlp.430</url>
      <bibkey>sharma-etal-2023-late</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.430</doi>
    </paper>
    <paper id="431">
      <title>Inductive Relation Inference of Knowledge Graph Enhanced by Ontology Information</title>
      <author><first>Wentao</first><last>Zhou</last></author>
      <author><first>Jun</first><last>Zhao</last></author>
      <author><first>Tao</first><last>Gui</last></author>
      <author><first>Qi</first><last>Zhang</last></author>
      <author><first>Xuanjing</first><last>Huang</last></author>
      <pages>6491-6502</pages>
      <abstract>The inductive inference of the knowledge graph aims to complete the potential relations between the new unknown entities in the graph. Most existing methods are based on entity-independent features such as graph structure information and relationship information to inference. However, the neighborhood of these new entities is often too sparse to obtain enough information to build these features effectively. In this work, we propose a knowledge graph inductive inference method that fuses ontology information. Based on the enclosing subgraph, we bring in feature embeddings of concepts corresponding to entities to learn the semantic information implicit in the ontology. Considering that the ontology information of entities may be missing, we build a type constraint regular loss to explicitly model the semantic connections between entities and concepts, and thus capture the missing concepts of entities. Experimental results show that our approach significantly outperforms large language models like ChatGPT on two benchmark datasets, YAGO21K-610 and DB45K-165, and improves the MRR metrics by 15.4% and 44.1%, respectively, when compared with the state-of-the-art methods.</abstract>
      <url hash="844c70e8">2023.findings-emnlp.431</url>
      <bibkey>zhou-etal-2023-inductive</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.431</doi>
    </paper>
    <paper id="432">
      <title>Dynamic Stance: Modeling Discussions by Labeling the Interactions</title>
      <author><first>Blanca</first><last>Figueras</last></author>
      <author><first>Irene</first><last>Baucells</last></author>
      <author><first>Tommaso</first><last>Caselli</last></author>
      <pages>6503-6515</pages>
      <abstract>Stance detection is an increasingly popular task that has been mainly modeled as a static task, by assigning the expressed attitude of a text toward a given topic. Such a framing presents limitations, with trained systems showing poor generalization capabilities and being strongly topic-dependent. In this work, we propose modeling stance as a dynamic task, by focusing on the interactions between a message and their replies. For this purpose, we present a new annotation scheme that enables the categorization of all kinds of textual interactions. As a result, we have created a new corpus, the Dynamic Stance Corpus (DySC), consisting of three datasets in two middle-resourced languages: Catalan and Dutch. Our data analysis further supports our modeling decisions, empirically showing differences between the annotation of stance in static and dynamic contexts. We fine-tuned a series of monolingual and multilingual models on DySC, showing portability across topics and languages.</abstract>
      <url hash="8e729ba4">2023.findings-emnlp.432</url>
      <bibkey>figueras-etal-2023-dynamic</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.432</doi>
    </paper>
    <paper id="433">
      <title>Harnessing the Power of Large Language Models for Empathetic Response Generation: Empirical Investigations and Improvements</title>
      <author><first>Yushan</first><last>Qian</last></author>
      <author><first>Weinan</first><last>Zhang</last></author>
      <author><first>Ting</first><last>Liu</last></author>
      <pages>6516-6528</pages>
      <abstract>Empathetic dialogue is an indispensable part of building harmonious social relationships and contributes to the development of a helpful AI. Previous approaches are mainly based on fine small-scale language models. With the advent of ChatGPT, the application effect of large language models (LLMs) in this field has attracted great attention. This work empirically investigates the performance of LLMs in generating empathetic responses and proposes three improvement methods of semantically similar in-context learning, two-stage interactive generation, and combination with the knowledge base. Extensive experiments show that LLMs can significantly benefit from our proposed methods and is able to achieve state-of-the-art performance in both automatic and human evaluations. Additionally, we explore the possibility of GPT-4 simulating human evaluators.</abstract>
      <url hash="2e2ca61a">2023.findings-emnlp.433</url>
      <bibkey>qian-etal-2023-harnessing</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.433</doi>
    </paper>
    <paper id="434">
      <title><fixed-case>GPT</fixed-case> Deciphering Fedspeak: Quantifying Dissent Among Hawks and Doves</title>
      <author><first>Denis</first><last>Peskoff</last></author>
      <author><first>Adam</first><last>Visokay</last></author>
      <author><first>Sander</first><last>Schulhoff</last></author>
      <author><first>Benjamin</first><last>Wachspress</last></author>
      <author><first>Alan</first><last>Blinder</last></author>
      <author><first>Brandon</first><last>Stewart</last></author>
      <pages>6529-6539</pages>
      <abstract>Markets and policymakers around the world hang on the consequential monetary policy decisions made by the Federal Open Market Committee (FOMC). Publicly available textual documentation of their meetings provides insight into members’ attitudes about the economy. We use GPT-4 to quantify dissent among members on the topic of inflation. We find that transcripts and minutes reflect the diversity of member views about the macroeconomic outlook in a way that is lost or omitted from the public statements. In fact, diverging opinions that shed light upon the committee’s “true” attitudes are almost entirely omitted from the final statements. Hence, we argue that forecasting FOMC sentiment based solely on statements will not sufficiently reflect dissent among the hawks and doves.</abstract>
      <url hash="c998ae09">2023.findings-emnlp.434</url>
      <bibkey>peskoff-etal-2023-gpt</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.434</doi>
    </paper>
    <paper id="435">
      <title><fixed-case>D</fixed-case>ialog<fixed-case>QAE</fixed-case>: N-to-N Question Answer Pair Extraction from Customer Service Chatlog</title>
      <author><first>Xin</first><last>Zheng</last></author>
      <author><first>Tianyu</first><last>Liu</last></author>
      <author><first>Haoran</first><last>Meng</last></author>
      <author><first>Xu</first><last>Wang</last></author>
      <author><first>Yufan</first><last>Jiang</last></author>
      <author><first>Mengliang</first><last>Rao</last></author>
      <author><first>Binghuai</first><last>Lin</last></author>
      <author><first>Yunbo</first><last>Cao</last></author>
      <author><first>Zhifang</first><last>Sui</last></author>
      <pages>6540-6558</pages>
      <abstract>Harvesting question-answer (QA) pairs from customer service chatlog in the wild is an efficient way to enrich the knowledge base for customer service chatbots in the cold start or continuous integration scenarios. Prior work attempts to obtain 1-to-1 QA pairs from growing customer service chatlog, which fails to integrate the incomplete utterances from the dialog context for composite QA retrieval. In this paper, we propose N-to-N QA extraction task in which the derived questions and corresponding answers might be separated across different utterances. We introduce a suite of generative/discriminative tagging based methods with end-to-end and two-stage variants that perform well on 5 customer service datasets and for the first time setup a benchmark for N-to-N DialogQAE with utterance and session level evaluation metrics. With a deep dive into extracted QA pairs, we find that the relations between and inside the QA pairs can be indicators to analyze the dialogue structure, e.g. information seeking, clarification, barge-in and elaboration. We also show that the proposed models can adapt to different domains and languages, and reduce the labor cost of knowledge accumulation in the real-world product dialogue platform.</abstract>
      <url hash="5624ef27">2023.findings-emnlp.435</url>
      <bibkey>zheng-etal-2023-dialogqae</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.435</doi>
    </paper>
    <paper id="436">
      <title>Inverse Reinforcement Learning for Text Summarization</title>
      <author><first>Yu</first><last>Fu</last></author>
      <author><first>Deyi</first><last>Xiong</last></author>
      <author><first>Yue</first><last>Dong</last></author>
      <pages>6559-6570</pages>
      <abstract>We introduce inverse reinforcement learning (IRL) as an effective paradigm for training abstractive summarization models, imitating human summarization behaviors. Our IRL model estimates the reward function using a suite of important sub-rewards for summarization and concurrently optimizes the policy network. Experimental results across datasets in different domains (CNN/DailyMail and WikiHow) and various model sizes (BART-base and BART-large) demonstrate the superiority of our proposed IRL model for summarization over MLE and RL baselines. The resulting summaries exhibit greater similarity to human-crafted gold references, outperforming MLE and RL baselines on metrics such as ROUGE, coverage, novelty, compression ratio, factuality, and human evaluations.</abstract>
      <url hash="b50b06a2">2023.findings-emnlp.436</url>
      <bibkey>fu-etal-2023-inverse</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.436</doi>
    </paper>
    <paper id="437">
      <title><fixed-case>MM</fixed-case>-Reasoner: A Multi-Modal Knowledge-Aware Framework for Knowledge-Based Visual Question Answering</title>
      <author><first>Mahmoud</first><last>Khademi</last></author>
      <author><first>Ziyi</first><last>Yang</last></author>
      <author><first>Felipe</first><last>Frujeri</last></author>
      <author><first>Chenguang</first><last>Zhu</last></author>
      <pages>6571-6581</pages>
      <abstract>Thanks to the strong reasoning capabilities of Large Language Models (LLMs), recent approaches to knowledge-based visual question answering (KVQA) utilize LLMs with a global caption of an input image to answer a question. However, these approaches may miss key visual information that is not captured by the caption. Moreover, they cannot fully utilize the visual information required to answer the question. To address these issues, we introduce a new framework called Multi-Modal Knowledge-Aware Reasoner (MM-Reasoner) for KVQA. MM-Reasoner first utilizes a set of vision APIs, such as dense captioners, object detectors, and OCR, to extract detailed information from the image in textual format. Then, it prompts an LLM to extract query-specific knowledge from the extracted textual information to provide a rich representation that contains external knowledge, commonsense, explicit supporting facts, and rationales required for reasoning. Finally, the knowledge, query, and visual input are used to fine-tune a Vision-Language Model (VLM). At test time, MM-Reasoner uses the potential answers predicted by the VLM to iteratively update and optimize the prompt, refining its answer. Empirical studies show that MM-Reasoner achieves state-of-the-art performance on several KVQA datasets.</abstract>
      <url hash="112d14f6">2023.findings-emnlp.437</url>
      <bibkey>khademi-etal-2023-mm</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.437</doi>
    </paper>
    <paper id="438">
      <title>Toward Joint Language Modeling for Speech Units and Text</title>
      <author><first>Ju-Chieh</first><last>Chou</last></author>
      <author><first>Chung-Ming</first><last>Chien</last></author>
      <author><first>Wei-Ning</first><last>Hsu</last></author>
      <author><first>Karen</first><last>Livescu</last></author>
      <author><first>Arun</first><last>Babu</last></author>
      <author><first>Alexis</first><last>Conneau</last></author>
      <author><first>Alexei</first><last>Baevski</last></author>
      <author><first>Michael</first><last>Auli</last></author>
      <pages>6582-6593</pages>
      <abstract>Speech and text are two major forms of human language. The research community has been focusing on mapping speech to text or vice versa for many years. However, in the field of language modeling, very little effort has been made to model them jointly. In light of this, we explore joint language modeling for speech units and text. Specifically, we compare different speech tokenizers to transform continuous speech signals into discrete units and use different methods to construct mixed speech-text data. We introduce automatic metrics to evaluate how well the joint LM mixes speech and text. We also fine-tune the LM on downstream spoken language understanding (SLU) tasks with different modalities (speech or text) and test its performance to assess the model’s learning of shared representations. Our results show that by mixing speech units and text with our proposed mixing techniques, the joint LM improves over a speech-only baseline on SLU tasks and shows zero-shot cross-modal transferability.</abstract>
      <url hash="75a00b88">2023.findings-emnlp.438</url>
      <bibkey>chou-etal-2023-toward</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.438</doi>
    </paper>
    <paper id="439">
      <title>From Chaos to Clarity: Claim Normalization to Empower Fact-Checking</title>
      <author><first>Megha</first><last>Sundriyal</last></author>
      <author><first>Tanmoy</first><last>Chakraborty</last></author>
      <author><first>Preslav</first><last>Nakov</last></author>
      <pages>6594-6609</pages>
      <abstract>With the proliferation of social media platforms, users are exposed to vast information, including posts containing misleading claims. However, the pervasive noise inherent in these posts presents a challenge in identifying precise and prominent claims that require verification. Extracting the core assertions from such posts is arduous and time-consuming. We introduce a novel task, called Claim Normalization (<tex-math>\textit{aka ClaimNorm}</tex-math>) that aims to decompose complex and noisy social media posts into more straightforward and understandable forms, termed <tex-math>\textit{normalized claims}</tex-math>. We propose <tex-math>\texttt{CACN}</tex-math> , a pioneering approach that leverages chain-of-thought and claim check-worthiness estimation, mimicking human reasoning processes, to comprehend intricate claims. Moreover, we capitalize on large language models’ powerful in-context learning abilities to provide guidance and improve the claim normalization process. To evaluate the effectiveness of our proposed model, we meticulously compile a comprehensive real-world dataset, <tex-math>\texttt{CLAN}</tex-math>, comprising more than <tex-math>6k</tex-math> instances of social media posts alongside their respective normalized claims. Experimentation demonstrates that <tex-math>\texttt{CACN}</tex-math> outperforms several baselines across various evaluation measures. A rigorous error analysis validates <tex-math>\texttt{CACN}</tex-math>‘s capabilities and pitfalls. We release our dataset and code at https://github.com/LCS2-IIITD/CACN-EMNLP-2023.</abstract>
      <url hash="341b7cda">2023.findings-emnlp.439</url>
      <bibkey>sundriyal-etal-2023-chaos</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.439</doi>
    </paper>
    <paper id="440">
      <title>Mitigating Biases in Hate Speech Detection from A Causal Perspective</title>
      <author><first>Zhehao</first><last>Zhang</last></author>
      <author><first>Jiaao</first><last>Chen</last></author>
      <author><first>Diyi</first><last>Yang</last></author>
      <pages>6610-6625</pages>
      <abstract>Nowadays, many hate speech detectors are built to automatically detect hateful content. However, their training sets are sometimes skewed towards certain stereotypes (e.g., race or religion-related). As a result, the detectors are prone to depend on some shortcuts for predictions. Previous works mainly focus on token-level analysis and heavily rely on human experts’ annotations to identify spurious correlations, which is not only costly but also incapable of discovering higher-level artifacts. In this work, we use grammar induction to find grammar patterns for hate speech and analyze this phenomenon from a causal perspective. Concretely, we categorize and verify different biases based on their spuriousness and influence on the model prediction. Then, we propose two mitigation approaches including Multi-Task Intervention and Data-Specific Intervention based on these confounders. Experiments conducted on 9 hate speech datasets demonstrate the effectiveness of our approaches.</abstract>
      <url hash="6ec740cb">2023.findings-emnlp.440</url>
      <bibkey>zhang-etal-2023-mitigating</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.440</doi>
    </paper>
    <paper id="441">
      <title>Unmasking the Hidden Meaning: Bridging Implicit and Explicit Hate Speech Embedding Representations</title>
      <author><first>Nicolas</first><last>Ocampo</last></author>
      <author><first>Elena</first><last>Cabrio</last></author>
      <author><first>Serena</first><last>Villata</last></author>
      <pages>6626-6637</pages>
      <abstract>Research on automatic hate speech (HS) detection has mainly focused on identifying explicit forms of hateful expressions on user-generated content. Recently, a few works have started to investigate methods to address more implicit and subtle abusive content. However, despite these efforts, automated systems still struggle to correctly recognize implicit and more veiled forms of HS. As these systems heavily rely on proper textual representations for classification, it is crucial to investigate the differences in embedding implicit and explicit messages. Our contribution to address this challenging task is fourfold. First, we present a comparative analysis of transformer-based models, evaluating their performance across five datasets containing implicit HS messages. Second, we examine the embedding representations of implicit messages across different targets, gaining insight into how veiled cases are encoded. Third, we compare and link explicit and implicit hateful messages across these datasets through their targets, enforcing the relation between explicitness and implicitness and obtaining more meaningful embedding representations. Lastly, we show how these newer representation maintains high performance on HS labels, while improving classification in borderline cases.</abstract>
      <url hash="3b8b1c96">2023.findings-emnlp.441</url>
      <bibkey>ocampo-etal-2023-unmasking</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.441</doi>
    </paper>
    <paper id="442">
      <title><fixed-case>P</fixed-case>erturb<fixed-case>S</fixed-case>core: Connecting Discrete and Continuous Perturbations in <fixed-case>NLP</fixed-case></title>
      <author><first>Linyang</first><last>Li</last></author>
      <author><first>Ke</first><last>Ren</last></author>
      <author><first>Yunfan</first><last>Shao</last></author>
      <author><first>Pengyu</first><last>Wang</last></author>
      <author><first>Xipeng</first><last>Qiu</last></author>
      <pages>6638-6648</pages>
      <abstract>With the rapid development of neural network applications in NLP, model robustness problem is gaining more attention. Different from computer vision, the discrete nature of texts makes it more challenging to explore robustness in NLP. Therefore, in this paper, we aim to connect discrete perturbations with continuous perturbations, therefore we can use such connections as a bridge to help understand discrete perturbations in NLP models. Specifically, we first explore how to connect and measure the correlation between discrete perturbations and continuous perturbations. Then we design a regression task as a PerturbScore to learn the correlation automatically. Through experimental results, we find that we can build a connection between discrete and continuous perturbations and use the proposed PerturbScore to learn such correlation, surpassing previous methods used in discrete perturbation measuring. Further, the proposed PerturbScore can be well generalized to different datasets, perturbation methods, indicating that we can use it as a powerful tool to study model robustness in NLP.</abstract>
      <url hash="527118e8">2023.findings-emnlp.442</url>
      <bibkey>li-etal-2023-perturbscore</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.442</doi>
    </paper>
    <paper id="443">
      <title><fixed-case>I</fixed-case>nstructo<fixed-case>R</fixed-case>: Instructing Unsupervised Conversational Dense Retrieval with Large Language Models</title>
      <author><first>Zhuoran</first><last>Jin</last></author>
      <author><first>Pengfei</first><last>Cao</last></author>
      <author><first>Yubo</first><last>Chen</last></author>
      <author><first>Kang</first><last>Liu</last></author>
      <author><first>Jun</first><last>Zhao</last></author>
      <pages>6649-6675</pages>
      <abstract>Compared to traditional single-turn ad-hoc retrieval, conversational retrieval needs to handle the multi-turn conversation and understand the user’s real query intent. However, most existing methods simply fine-tune the pre-trained ad-hoc retriever on limited supervised data, making it challenging for the retriever to fully grasp the entirety of the conversation. In this paper, we find that large language models (LLMs) can accurately discover the user’s query intent from the complex conversation context and provide the supervised signal to instruct the retriever in an unsupervised manner. Therefore, we propose a novel method termed InstructoR to Instruct unsupervised conversational dense Retrieval with LLMs. We design an unsupervised training framework that employs LLMs to estimate the session-passage relevance score as the soft label to guide the retriever’s training. Specially, we devise three instructing strategies from context, query and response perspectives to calculate the relevance score more precisely, including conversational retrieval as conversation generation, question rewrite as latent variable and question response as posterior guide. Experimental results show InstructoR can bring significant improvements across various ad-hoc retrievers, even surpassing the current supervised state-of-the-art method. We also demonstrate the effectiveness of our method under low-resource and zero-shot settings. Our code is publicly available at https://github.com/jinzhuoran/InstructoR/.</abstract>
      <url hash="ce020f05">2023.findings-emnlp.443</url>
      <bibkey>jin-etal-2023-instructor</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.443</doi>
    </paper>
    <paper id="444">
      <title>The Iron(ic) Melting Pot: Reviewing Human Evaluation in Humour, Irony and Sarcasm Generation</title>
      <author><first>Tyler</first><last>Loakman</last></author>
      <author><first>Aaron</first><last>Maladry</last></author>
      <author><first>Chenghua</first><last>Lin</last></author>
      <pages>6676-6689</pages>
      <abstract>Human evaluation in often considered to be the gold standard method of evaluating a Natural Language Generation system. However, whilst its importance is accepted by the community at large, the quality of its execution is often brought into question. In this position paper, we argue that the generation of more esoteric forms of language - humour, irony and sarcasm - constitutes a subdomain where the characteristics of selected evaluator panels are of utmost importance, and every effort should be made to report demographic characteristics wherever possible, in the interest of transparency and replicability. We support these claims with an overview of each language form and an analysis of examples in terms of how their interpretation is affected by different participant variables. We additionally perform a critical survey of recent works in NLG to assess how well evaluation procedures are reported in this subdomain, and note a severe lack of open reporting of evaluator demographic information, and a significant reliance on crowdsourcing platforms for recruitment.</abstract>
      <url hash="7400e99f">2023.findings-emnlp.444</url>
      <bibkey>loakman-etal-2023-iron</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.444</doi>
    </paper>
    <paper id="445">
      <title><fixed-case>INGENIOUS</fixed-case>: Using Informative Data Subsets for Efficient Pre-Training of Language Models</title>
      <author><first>H S V N S Kowndinya</first><last>Renduchintala</last></author>
      <author><first>Krishnateja</first><last>Killamsetty</last></author>
      <author><first>Sumit</first><last>Bhatia</last></author>
      <author><first>Milan</first><last>Aggarwal</last></author>
      <author><first>Ganesh</first><last>Ramakrishnan</last></author>
      <author><first>Rishabh</first><last>Iyer</last></author>
      <author><first>Balaji</first><last>Krishnamurthy</last></author>
      <pages>6690-6705</pages>
      <abstract>A salient characteristic of pre-trained language models (PTLMs) is a remarkable improvement in their generalization capability and emergence of new capabilities with increasing model capacity and pre-training dataset size. Consequently, we are witnessing the development of enormous models pushing the state-of-the-art. It is, however, imperative to realize that this inevitably leads to prohibitively long training times, extortionate computing costs, and a detrimental environmental impact. Significant efforts are underway to make PTLM training more efficient through innovations in model architectures, training pipelines, and loss function design, with scant attention being paid to optimizing the utility of training data. The key question that we ask is whether it is possible to train PTLMs by employing only highly informative subsets of the training data while maintaining downstream performance? Building upon the recent progress in informative data subset selection, we show how we can employ submodular optimization to select highly representative subsets of the training corpora and demonstrate that the proposed framework can be applied to efficiently train multiple PTLMs (BERT, BioBERT, GPT-2) using only a fraction of data. Further, we perform a rigorous empirical evaluation to show that the resulting models achieve up to ~99% of the performance of the fully-trained models. We made our framework publicly available at <url>https://github.com/Efficient-AI/ingenious</url>.</abstract>
      <url hash="9800c7d8">2023.findings-emnlp.445</url>
      <bibkey>renduchintala-etal-2023-ingenious</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.445</doi>
    </paper>
    <paper id="446">
      <title>Towards General Error Diagnosis via Behavioral Testing in Machine Translation</title>
      <author><first>Junjie</first><last>Wu</last></author>
      <author><first>Lemao</first><last>Liu</last></author>
      <author><first>Dit-Yan</first><last>Yeung</last></author>
      <pages>6706-6720</pages>
      <abstract>Behavioral testing offers a crucial means of diagnosing linguistic errors and assessing capabilities of NLP models. However, applying behavioral testing to machine translation (MT) systems is challenging as it generally requires human efforts to craft references for evaluating the translation quality of such systems on newly generated test cases. Existing works in behavioral testing of MT systems circumvent this by evaluating translation quality without references, but this restricts diagnosis to specific types of errors, such as incorrect translation of single numeric or currency words. In order to diagnose general errors, this paper proposes a new Bilingual Translation Pair Generation based Behavior Testing (BTPGBT) framework for conducting behavioral testing of MT systems. The core idea of BTPGBT is to employ a novel bilingual translation pair generation (BTPG) approach that automates the construction of high-quality test cases and their pseudoreferences. Experimental results on various MT systems demonstrate that BTPGBT could provide comprehensive and accurate behavioral testing results for general error diagnosis, which further leads to several insightful findings. Our code and data are available at https: //github.com/wujunjie1998/BTPGBT.</abstract>
      <url hash="86195de4">2023.findings-emnlp.446</url>
      <bibkey>wu-etal-2023-towards-general</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.446</doi>
    </paper>
    <paper id="447">
      <title>Retrieval-Augmented Few-shot Text Classification</title>
      <author><first>Guoxin</first><last>Yu</last></author>
      <author><first>Lemao</first><last>Liu</last></author>
      <author><first>Haiyun</first><last>Jiang</last></author>
      <author><first>Shuming</first><last>Shi</last></author>
      <author><first>Xiang</first><last>Ao</last></author>
      <pages>6721-6735</pages>
      <abstract>Retrieval-augmented methods are successful in the standard scenario where the retrieval space is sufficient; whereas in the few-shot scenario with limited retrieval space, this paper shows it is non-trivial to put them into practice. First, it is impossible to retrieve semantically similar examples by using an off-the-shelf metric and it is crucial to learn a task-specific retrieval metric; Second, our preliminary experiments demonstrate that it is difficult to optimize a plausible metric by minimizing the standard cross-entropy loss. The in-depth analyses quantitatively show minimizing cross-entropy loss suffers from the weak supervision signals and the severe gradient vanishing issue during the optimization. To address these issues, we introduce two novel training objectives, namely EM-L and R-L, which provide more task-specific guidance to the retrieval metric by the EM algorithm and a ranking-based loss, respectively. Extensive experiments on 10 datasets prove the superiority of the proposed retrieval augmented methods on the performance.</abstract>
      <url hash="1dc1f88a">2023.findings-emnlp.447</url>
      <bibkey>yu-etal-2023-retrieval</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.447</doi>
    </paper>
    <paper id="448">
      <title>Temporal Extrapolation and Knowledge Transfer for Lifelong Temporal Knowledge Graph Reasoning</title>
      <author><first>Zhongwu</first><last>Chen</last></author>
      <author><first>Chengjin</first><last>Xu</last></author>
      <author><first>Fenglong</first><last>Su</last></author>
      <author><first>Zhen</first><last>Huang</last></author>
      <author><first>Yong</first><last>Dou</last></author>
      <pages>6736-6746</pages>
      <abstract>Real-world Temporal Knowledge Graphs keep growing with time and new entities and facts emerge continually, necessitating a model that can extrapolate to future timestamps and transfer knowledge for new components. Therefore, our work first dives into this more realistic issue, lifelong TKG reasoning, where existing methods can only address part of the challenges. Specifically, we formulate lifelong TKG reasoning as a temporal-path-based reinforcement learning (RL) framework. Then, we add temporal displacement into the action space of RL to extrapolate for the future and further propose a temporal-rule-based reward shaping to guide the training. To transfer and update knowledge, we design a new edge-aware message passing module, where the embeddings of new entities and edges are inductive. We conduct extensive experiments on three newly constructed benchmarks for lifelong TKG reasoning. Experimental results show the outperforming effectiveness of our model against all well-adapted baselines.</abstract>
      <url hash="c501492b">2023.findings-emnlp.448</url>
      <bibkey>chen-etal-2023-temporal</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.448</doi>
    </paper>
    <paper id="449">
      <title>Comparing Prompt-Based and Standard Fine-Tuning for <fixed-case>U</fixed-case>rdu Text Classification</title>
      <author><first>Faizad</first><last>Ullah</last></author>
      <author><first>Ubaid</first><last>Azam</last></author>
      <author><first>Ali</first><last>Faheem</last></author>
      <author><first>Faisal</first><last>Kamiran</last></author>
      <author><first>Asim</first><last>Karim</last></author>
      <pages>6747-6754</pages>
      <abstract>Recent advancements in natural language processing have demonstrated the efficacy of pre-trained language models for various downstream tasks through prompt-based fine-tuning. In contrast to standard fine-tuning, which relies solely on labeled examples, prompt-based fine-tuning combines a few labeled examples (few shot) with guidance through prompts tailored for the specific language and task. For low-resource languages, where labeled examples are limited, prompt-based fine-tuning appears to be a promising alternative. In this paper, we compare prompt-based and standard fine-tuning for the popular task of text classification in Urdu and Roman Urdu languages. We conduct experiments using five datasets, covering different domains, and pre-trained multilingual transformers. The results reveal that significant improvement of up to 13% in accuracy is achieved by prompt-based fine-tuning over standard fine-tuning approaches. This suggests the potential of prompt-based fine-tuning as a valuable approach for low-resource languages with limited labeled data.</abstract>
      <url hash="e4225a04">2023.findings-emnlp.449</url>
      <bibkey>ullah-etal-2023-comparing</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.449</doi>
    </paper>
    <paper id="450">
      <title>Explore the Way: Exploring Reasoning Path by Bridging Entities for Effective Cross-Document Relation Extraction</title>
      <author><first>Junyoung</first><last>Son</last></author>
      <author><first>Jinsung</first><last>Kim</last></author>
      <author><first>Jungwoo</first><last>Lim</last></author>
      <author><first>Yoonna</first><last>Jang</last></author>
      <author><first>Heuiseok</first><last>Lim</last></author>
      <pages>6755-6761</pages>
      <abstract>Cross-document relation extraction (CodRED) task aims to infer the relation between two entities mentioned in different documents within a reasoning path. Previous studies have concentrated on merely capturing implicit relations between the entities. However, humans usually utilize explicit information chains such as hyperlinks or additional searches to find the relations between two entities. Inspired by this, we propose Path wIth expLOraTion (PILOT) that provides the enhanced reasoning path by exploring the explicit clue information within the documents. PILOT finds the bridging entities which directly guide the paths between the entities and then employs them as stepstones to navigate desirable paths. We show that models with PILOT outperform the baselines in the CodRED task. Furthermore, we offer a variety of analyses to verify the validity of the reasoning paths constructed through PILOT, including evaluations using large language models such as ChatGPT.</abstract>
      <url hash="83d8ae25">2023.findings-emnlp.450</url>
      <bibkey>son-etal-2023-explore</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.450</doi>
    </paper>
    <paper id="451">
      <title>The student becomes the master: Outperforming <fixed-case>GPT</fixed-case>3 on Scientific Factual Error Correction</title>
      <author><first>Dhananjay</first><last>Ashok</last></author>
      <author><first>Atharva</first><last>Kulkarni</last></author>
      <author><first>Hai</first><last>Pham</last></author>
      <author><first>Barnabas</first><last>Poczos</last></author>
      <pages>6762-6778</pages>
      <abstract>Due to the prohibitively high cost of creating error correction datasets, most Factual Claim Correction methods rely on a powerful verification model to guide the correction process. This leads to a significant drop in performance in domains like Scientific Claim Correction, where good verification models do not always exist. In this work we introduce SciFix, a claim correction system that does not require a verifier but is able to outperform existing methods by a considerable margin — achieving correction accuracy of 84% on the SciFact dataset, 77% on SciFact-Open and 72.75% on the CovidFact dataset, compared to next best accuracies of 7.6%, 5% and 15% on the same datasets respectively. Our method leverages the power of prompting with LLMs during training to create a richly annotated dataset that can be used for fully supervised training and regularization. We additionally use a claim-aware decoding procedure to improve the quality of corrected claims. Our method outperforms the very LLM that was used to generate the annotated dataset — with FewShot Prompting on GPT3.5 achieving 58%, 61% and 64% on the respective datasets, a consistently lower correction accuracy, despite using nearly 800 times as many parameters as our model.</abstract>
      <url hash="849d8d52">2023.findings-emnlp.451</url>
      <bibkey>ashok-etal-2023-student</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.451</doi>
    </paper>
    <paper id="452">
      <title>Leveraging Structured Information for Explainable Multi-hop Question Answering and Reasoning</title>
      <author><first>Ruosen</first><last>Li</last></author>
      <author><first>Xinya</first><last>Du</last></author>
      <pages>6779-6789</pages>
      <abstract>Neural models, including large language models (LLMs), achieve superior performance on multi-hop question-answering. To elicit reasoning capabilities from LLMs, recent works propose using the chain-of-thought (CoT) mechanism to generate both the reasoning chain and the answer, which enhances the model’s capabilities in conducting multi-hop reasoning. However, several challenges still remain: such as struggling with inaccurate reasoning, hallucinations, and lack of interpretability. On the other hand, information extraction (IE) identifies entities, relations, and events grounded to the text. The extracted structured information can be easily interpreted by humans and machines (Grishman, 2019). In this work, we investigate constructing and leveraging extracted semantic structures (graphs) for multi-hop question answering, especially the reasoning process. Empirical results and human evaluations show that our framework: generates more faithful reasoning chains and substantially improves the QA performance on two benchmark datasets. Moreover, the extracted structures themselves naturally provide grounded explanations that are preferred by humans, as compared to the generated reasoning chains and saliency-based explanations.</abstract>
      <url hash="c494ce03">2023.findings-emnlp.452</url>
      <bibkey>li-du-2023-leveraging</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.452</doi>
    </paper>
    <paper id="453">
      <title>Hierarchical Catalogue Generation for Literature Review: A Benchmark</title>
      <author><first>Kun</first><last>Zhu</last></author>
      <author><first>Xiaocheng</first><last>Feng</last></author>
      <author><first>Xiachong</first><last>Feng</last></author>
      <author><first>Yingsheng</first><last>Wu</last></author>
      <author><first>Bing</first><last>Qin</last></author>
      <pages>6790-6804</pages>
      <abstract>Scientific literature review generation aims to extract and organize important information from an abundant collection of reference papers and produces corresponding reviews while lacking a clear and logical hierarchy. We observe that a high-quality catalogue-guided generation process can effectively alleviate this problem. Therefore, we present an atomic and challenging task named Hierarchical Catalogue Generation for Literature Review as the first step for review generation, which aims to produce a hierarchical catalogue of a review paper given various references. We construct a novel English Hierarchical Catalogues of Literature Reviews Dataset with 7.6k literature review catalogues and 389k reference papers. To accurately assess the model performance, we design two evaluation metrics for informativeness and similarity to ground truth from semantics and structure. Our extensive analyses verify the high quality of our dataset and the effectiveness of our evaluation metrics. We further benchmark diverse experiments on state-of-the-art summarization models like BART and large language models like ChatGPT to evaluate their capabilities. We further discuss potential directions for this task to motivate future research.</abstract>
      <url hash="6edb1f55">2023.findings-emnlp.453</url>
      <bibkey>zhu-etal-2023-hierarchical</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.453</doi>
    </paper>
    <paper id="454">
      <title><fixed-case>MCC</fixed-case>-<fixed-case>KD</fixed-case>: Multi-<fixed-case>C</fixed-case>o<fixed-case>T</fixed-case> Consistent Knowledge Distillation</title>
      <author><first>Hongzhan</first><last>Chen</last></author>
      <author><first>Siyue</first><last>Wu</last></author>
      <author><first>Xiaojun</first><last>Quan</last></author>
      <author><first>Rui</first><last>Wang</last></author>
      <author><first>Ming</first><last>Yan</last></author>
      <author><first>Ji</first><last>Zhang</last></author>
      <pages>6805-6820</pages>
      <abstract>Large language models (LLMs) have showcased remarkable capabilities in complex reasoning through chain of thought (CoT) prompting. Recently, there has been a growing interest in transferring these reasoning abilities from LLMs to smaller models. However, achieving both the diversity and consistency in rationales presents a challenge. In this paper, we focus on enhancing these two aspects and propose Multi-CoT Consistent Knowledge Distillation (MCC-KD) to efficiently distill the reasoning capabilities. In MCC-KD, we generate multiple rationales for each question and enforce consistency among their predictions by minimizing the bidirectional KL-divergence between the answer distributions. We conduct comprehensive experiments to investigate the effectiveness of MCC-KD with different model architectures (LLaMA/FlanT5) and various model scales (3B/7B/11B/13B) on both mathematical reasoning and commonsense reasoning benchmarks. The empirical results demonstrate that MCC-KD achieves superior performance on in-distribution datasets and exhibits a strong generalization ability on out-of-distribution datasets.</abstract>
      <url hash="6f963606">2023.findings-emnlp.454</url>
      <bibkey>chen-etal-2023-mcc</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.454</doi>
    </paper>
    <paper id="455">
      <title>An Empirical Study of Frame Selection for Text-to-Video Retrieval</title>
      <author><first>Mengxia</first><last>Wu</last></author>
      <author><first>Min</first><last>Cao</last></author>
      <author><first>Yang</first><last>Bai</last></author>
      <author><first>Ziyin</first><last>Zeng</last></author>
      <author><first>Chen</first><last>Chen</last></author>
      <author><first>Liqiang</first><last>Nie</last></author>
      <author><first>Min</first><last>Zhang</last></author>
      <pages>6821-6832</pages>
      <abstract>Text-to-video retrieval (TVR) aims to find the most relevant video in a large video gallery given a query text. The intricate and abundant context of the video challenges the performance and efficiency of TVR. To handle the serialized video contexts, existing methods typically select a subset of frames within a video to represent the video content for TVR. How to select the most representative frames is a crucial issue, whereby the selected frames are required to not only retain the semantic information of the video but also promote retrieval efficiency by excluding temporally redundant frames. In this paper, we make the first empirical study of frame selection for TVR. We systemically classify existing frame selection methods into text-free and text-guided ones, under which we detailedly analyze six different frame selections in terms of effectiveness and efficiency. Among them, two frame selections are first developed in this paper. According to the comprehensive analysis on multiple TVR benchmarks, we empirically conclude that the TVR with proper frame selections can significantly improve the retrieval efficiency without sacrificing the retrieval performance.</abstract>
      <url hash="32c864e6">2023.findings-emnlp.455</url>
      <bibkey>wu-etal-2023-empirical</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.455</doi>
    </paper>
    <paper id="456">
      <title>Conditional Natural Language Inference</title>
      <author><first>Youngwoo</first><last>Kim</last></author>
      <author><first>Razieh</first><last>Rahimi</last></author>
      <author><first>James</first><last>Allan</last></author>
      <pages>6833-6851</pages>
      <abstract>To properly explain sentence pairs that provide contradictory (different) information for different conditions, we introduce the task of conditional natural language inference (Cond-NLI) and focus on automatically extracting contradictory aspects and their conditions from a sentence pair. Cond-NLI can help to provide a full spectrum of information, such as when there are multiple answers to a question each addressing a specific condition, or reviews with different opinions for different conditions. We show that widely-used feature-attribution explanation models are not suitable for finding conditions, especially when sentences are long and are written independently. We propose a simple yet effective model for the original NLI task that can successfully extract conditions while not requiring token-level annotations. Our model enhances the interpretability of the NLI task while maintaining comparable accuracy. To evaluate models for the Cond-NLI, we build and release a token-level annotated dataset BioClaim which contains potentially contradictory claims from the biomedical domain. Our experiments show that our proposed model outperforms the full cross-encoder and other baselines in extracting conditions. It also performs on-par with GPT-3 which has an order of magnitude more parameters and trained on a huge amount of data.</abstract>
      <url hash="f5a6eac1">2023.findings-emnlp.456</url>
      <bibkey>kim-etal-2023-conditional</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.456</doi>
    </paper>
    <paper id="457">
      <title>Contrastive Distant Supervision for Debiased and Denoised Machine Reading Comprehension</title>
      <author><first>Ning</first><last>Bian</last></author>
      <author><first>Hongyu</first><last>Lin</last></author>
      <author><first>Xianpei</first><last>Han</last></author>
      <author><first>Ben</first><last>He</last></author>
      <author><first>Le</first><last>Sun</last></author>
      <pages>6852-6863</pages>
      <abstract>Distant Supervision (DS) is a promising learning approach for MRC by leveraging easily-obtained question-answer pairs. Unfortunately, the heuristically annotated dataset will inevitably lead to mislabeled instances, resulting in answer bias and context noise problems. To learn debiased and denoised MRC models, this paper proposes the Contrastive Distant Supervision algorithm – CDS, which can learn to distinguish confusing and noisy instances via confidence-aware contrastive learning. Specifically, to eliminate answer bias, CDS samples counterfactual negative instances, which ensures that MRC models must take both answer information and question-context interaction into consideration. To denoise distantly annotated contexts, CDS samples confusing negative instances to increase the margin between correct and mislabeled instances. We further propose a confidence-aware contrastive loss to model and leverage the uncertainty of all DS instances during learning. Experimental results show that CDS is effective and can even outperform supervised MRC models without manual annotations.</abstract>
      <url hash="52eecf9a">2023.findings-emnlp.457</url>
      <bibkey>bian-etal-2023-contrastive</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.457</doi>
    </paper>
    <paper id="458">
      <title><fixed-case>KEPLET</fixed-case>: Knowledge-Enhanced Pretrained Language Model with Topic Entity Awareness</title>
      <author><first>Yichuan</first><last>Li</last></author>
      <author><first>Jialong</first><last>Han</last></author>
      <author><first>Kyumin</first><last>Lee</last></author>
      <author><first>Chengyuan</first><last>Ma</last></author>
      <author><first>Benjamin</first><last>Yao</last></author>
      <author><first>Xiaohu</first><last>Liu</last></author>
      <pages>6864-6876</pages>
      <abstract>In recent years, Pre-trained Language Models (PLMs) have shown their superiority by pre-training on unstructured text corpus and then fine-tuning on downstream tasks. On entity-rich textual resources like Wikipedia, Knowledge-Enhanced PLMs (KEPLMs) incorporate the interactions between tokens and mentioned entities in pre-training, and are thus more effective on entity-centric tasks such as entity linking and relation classification. Although exploiting Wikipedia’s rich structures to some extent, conventional KEPLMs still neglect a unique layout of the corpus where each Wikipedia page is around a topic entity (identified by the page URL and shown in the page title). In this paper, we demonstrate that KEPLMs without incorporating the topic entities will lead to insufficient entity interaction and biased (relation) word semantics. We thus propose KEPLET, a novel Knowledge-Énhanced Pre-trained LanguagE model with Topic entity awareness. In an end-to-end manner, KEPLET identifies where to add the topic entity’s information in a Wikipedia sentence, fuses such information into token and mentioned entities representations, and supervises the network learning, through which it takes topic entities back into consideration. Experiments demonstrated the generality and superiority of KEPLET which was applied to two representative KEPLMs, achieving significant improvements on four entity-centric tasks.</abstract>
      <url hash="114aac79">2023.findings-emnlp.458</url>
      <bibkey>li-etal-2023-keplet</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.458</doi>
    </paper>
    <paper id="459">
      <title>Revisiting Large Language Models as Zero-shot Relation Extractors</title>
      <author><first>Guozheng</first><last>Li</last></author>
      <author><first>Peng</first><last>Wang</last></author>
      <author><first>Wenjun</first><last>Ke</last></author>
      <pages>6877-6892</pages>
      <abstract>Relation extraction (RE) consistently involves a certain degree of labeled or unlabeled data even if under zero-shot setting. Recent studies have shown that large language models (LLMs) transfer well to new tasks out-of-the-box simply given a natural language prompt, which provides the possibility of extracting relations from text without any data and parameter tuning. This work focuses on the study of exploring LLMs, such as ChatGPT, as zero-shot relation extractors. On the one hand, we analyze the drawbacks of existing RE prompts and attempt to incorporate recent prompt techniques such as chain-of-thought (CoT) to improve zero-shot RE. We propose the summarize-and-ask (SumAsk) prompting, a simple prompt recursively using LLMs to transform RE inputs to the effective question answering (QA) format. On the other hand, we conduct comprehensive experiments on various benchmarks and settings to investigate the capabilities of LLMs on zero-shot RE. Specifically, we have the following findings: (i) SumAsk consistently and significantly improves LLMs performance on different model sizes, benchmarks and settings; (ii) Zero-shot prompting with ChatGPT achieves competitive or superior results compared with zero-shot and fully supervised methods; (iii) LLMs deliver promising performance in extracting overlapping relations; (iv) The performance varies greatly regarding different relations. Different from small language models, LLMs are effective in handling challenge none-of-the-above (NoTA) relation.</abstract>
      <url hash="4d3147c5">2023.findings-emnlp.459</url>
      <bibkey>li-etal-2023-revisiting-large</bibkey>
      <revision id="1" href="2023.findings-emnlp.459v1" hash="a1a85139"/>
      <revision id="2" href="2023.findings-emnlp.459v2" hash="4d3147c5" date="2023-12-11">Updated Acknowledgement.</revision>
    </paper>
    <paper id="460">
      <title>Multi-Stage Pre-training Enhanced by <fixed-case>C</fixed-case>hat<fixed-case>GPT</fixed-case> for Multi-Scenario Multi-Domain Dialogue Summarization</title>
      <author><first>Weixiao</first><last>Zhou</last></author>
      <author><first>Gengyao</first><last>Li</last></author>
      <author><first>Xianfu</first><last>Cheng</last></author>
      <author><first>Xinnian</first><last>Liang</last></author>
      <author><first>Junnan</first><last>Zhu</last></author>
      <author><first>Feifei</first><last>Zhai</last></author>
      <author><first>Zhoujun</first><last>Li</last></author>
      <pages>6893-6908</pages>
      <abstract>Dialogue summarization involves a wide range of scenarios and domains. However, existing methods generally only apply to specific scenarios or domains. In this study, we propose a new pre-trained model specifically designed for multi-scenario multi-domain dialogue summarization. It adopts a multi-stage pre-training strategy to reduce the gap between the pre-training objective and fine-tuning objective. Specifically, we first conduct domain-aware pre-training using large-scale multi-scenario multi-domain dialogue data to enhance the adaptability of our pre-trained model. Then, we conduct task-oriented pre-training using large-scale multi-scenario multi-domain “dialogue-summary” parallel data annotated by ChatGPT to enhance the dialogue summarization ability of our pre-trained model. Experimental results on three dialogue summarization datasets from different scenarios and domains indicate that our pre-trained model significantly outperforms previous state-of-the-art models in full fine-tuning, zero-shot, and few-shot settings.</abstract>
      <url hash="3c949e3b">2023.findings-emnlp.460</url>
      <bibkey>zhou-etal-2023-multi</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.460</doi>
    </paper>
    <paper id="461">
      <title>Towards large language model-based personal agents in the enterprise: Current trends and open problems</title>
      <author><first>Vinod</first><last>Muthusamy</last></author>
      <author><first>Yara</first><last>Rizk</last></author>
      <author><first>Kiran</first><last>Kate</last></author>
      <author><first>Praveen</first><last>Venkateswaran</last></author>
      <author><first>Vatche</first><last>Isahagian</last></author>
      <author><first>Ashu</first><last>Gulati</last></author>
      <author><first>Parijat</first><last>Dube</last></author>
      <pages>6909-6921</pages>
      <abstract>There is an emerging trend to use large language models (LLMs) to reason about complex goals and orchestrate a set of pluggable tools or APIs to accomplish a goal. This functionality could, among other use cases, be used to build personal assistants for knowledge workers. While there are impressive demos of LLMs being used as autonomous agents or for tool composition, these solutions are not ready mission-critical enterprise settings. For example, they are brittle to input changes, and can produce inconsistent results for the same inputs. These use cases have many open problems in an exciting area of NLP research, such as trust and explainability, consistency and reproducibility, adherence to guardrails and policies, best practices for composable tool design, and the need for new metrics and benchmarks. This vision paper illustrates some examples of LLM-based autonomous agents that reason and compose tools, highlights cases where they fail, surveys some of the recent efforts in this space, and lays out the research challenges to make these solutions viable for enterprises.</abstract>
      <url hash="f6da2e80">2023.findings-emnlp.461</url>
      <bibkey>muthusamy-etal-2023-towards</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.461</doi>
    </paper>
    <paper id="462">
      <title><fixed-case>CREATOR</fixed-case>: Tool Creation for Disentangling Abstract and Concrete Reasoning of Large Language Models</title>
      <author><first>Cheng</first><last>Qian</last></author>
      <author><first>Chi</first><last>Han</last></author>
      <author><first>Yi</first><last>Fung</last></author>
      <author><first>Yujia</first><last>Qin</last></author>
      <author><first>Zhiyuan</first><last>Liu</last></author>
      <author><first>Heng</first><last>Ji</last></author>
      <pages>6922-6939</pages>
      <abstract>Large Language Models (LLMs) have made significant progress in utilizing tools, but their ability is limited by API availability and the instability of implicit reasoning, particularly when both planning and execution are involved. To overcome these limitations, we propose CREATOR, a novel framework that enables LLMs to create their own tools using documentation and code realization. CREATOR disentangles abstract tool creation and concrete decision execution, resulting in improved performance. We evaluate CREATOR on MATH and TabMWP benchmarks, respectively consisting of challenging math competition problems and diverse tabular contents. Remarkably, CREATOR outperforms existing chain-of-thought, program-of-thought, and tool-using baselines. Additionally, we introduce the Creation Challenge dataset, featuring 2K diverse questions, to emphasize the necessity and benefits of LLMs’ tool creation ability. Further research demonstrates that leveraging LLMs as tool creators facilitates knowledge transfer, and LLMs exhibit varying levels of tool creation abilities, enabling them to adapt to diverse situations. The tool creation ability revolutionizes the LLM’s problem-solving paradigm, driving us closer to the next frontier of artificial intelligence.</abstract>
      <url hash="53e48f03">2023.findings-emnlp.462</url>
      <bibkey>qian-etal-2023-creator</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.462</doi>
    </paper>
    <paper id="463">
      <title>Query-based Image Captioning from Multi-context 360<tex-math>cdegree</tex-math> Images</title>
      <author><first>Koki</first><last>Maeda</last></author>
      <author><first>Shuhei</first><last>Kurita</last></author>
      <author><first>Taiki</first><last>Miyanishi</last></author>
      <author><first>Naoaki</first><last>Okazaki</last></author>
      <pages>6940-6954</pages>
      <abstract>A 360-degree image captures the entire scene without the limitations of a camera’s field of view, which makes it difficult to describe all the contexts in a single caption. We propose a novel task called Query-based Image Captioning (QuIC) for 360-degree images, where a query (words or short phrases) specifies the context to describe. This task is more challenging than the conventional image captioning task, which describes salient objects in images, as it requires fine-grained scene understanding to select the contents consistent with user’s intent based on the query. We construct a dataset for the new task that comprises 3,940 360-degree images and 18,459 pairs of queries and captions annotated manually. Experiments demonstrate that fine-tuning image captioning models further on our dataset can generate more diverse and controllable captions from multiple contexts of 360-degree images.</abstract>
      <url hash="ccdece92">2023.findings-emnlp.463</url>
      <bibkey>maeda-etal-2023-query</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.463</doi>
    </paper>
    <paper id="464">
      <title>Auto Search Indexer for End-to-End Document Retrieval</title>
      <author><first>Tianchi</first><last>Yang</last></author>
      <author><first>Minghui</first><last>Song</last></author>
      <author><first>Zihan</first><last>Zhang</last></author>
      <author><first>Haizhen</first><last>Huang</last></author>
      <author><first>Weiwei</first><last>Deng</last></author>
      <author><first>Feng</first><last>Sun</last></author>
      <author><first>Qi</first><last>Zhang</last></author>
      <pages>6955-6970</pages>
      <abstract>Generative retrieval, which is a new advanced paradigm for document retrieval, has recently attracted research interests, since it encodes all documents into the model and directly generates the retrieved documents. However, its power is still underutilized since it heavily relies on the “preprocessed” document identifiers (docids), thus limiting its retrieval performance and ability to retrieve new documents. In this paper, we propose a novel fully end-to-end retrieval paradigm. It can not only end-to-end learn the best docids for existing and new documents automatically via a semantic indexing module, but also perform end-to-end document retrieval via an encoder-decoder-based generative model, namely Auto Search Indexer (ASI). Besides, we design a reparameterization mechanism to combine the above two modules into a joint optimization framework. Extensive experimental results demonstrate the superiority of our model over advanced baselines on both public and industrial datasets and also verify the ability to deal with new documents.</abstract>
      <url hash="5aca0984">2023.findings-emnlp.464</url>
      <bibkey>yang-etal-2023-auto</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.464</doi>
    </paper>
    <paper id="465">
      <title>‘Person’ == Light-skinned, Western Man, and Sexualization of Women of Color: Stereotypes in Stable Diffusion</title>
      <author><first>Sourojit</first><last>Ghosh</last></author>
      <author><first>Aylin</first><last>Caliskan</last></author>
      <pages>6971-6985</pages>
      <abstract>We study stereotypes embedded within one of the most popular text-to-image generators: Stable Diffusion. We answer the question: what stereotypes of gender and nationality/continental identity does Stable Diffusion display in the absence of such information i.e. what gender and nationality/continental identity is assigned to ‘a person,’ or to ‘a person from Asia.’ Using CLIP-cosine similarity for zero-shot classification of images generated by CLIP-based Stable Diffusion v2.1 verified by manual examination, we chronicle results from 136 prompts (50 results/prompt) of front-facing images of faces from 6 different continents, 27 countries and 3 genders. We observe how Stable Diffusion results of ‘a person’ without any additional gender/nationality information correspond closest to images of men (avg. similarity 0.64) and least with persons of nonbinary gender (avg. similarity 0.41), and to persons from Europe/North America (avg. similarities 0.71 and 0.68, respectively) over Africa/Asia (avg. similarities 0.43 and 0.41, respectively), pointing towards Stable Diffusion having a concerning representation of personhood to be a European/North American man. We also show continental stereotypes and resultant harms e.g. a person from Oceania is deemed to be Australian/New Zealander (avg. similarities 0.77 and 0.74, respectively) over Papua New Guinean (avg. similarity 0.31), pointing to the erasure of Indigenous Oceanic peoples, who form a majority over descendants of colonizers both in Papua New Guinea and in Oceania overall. Finally, we unexpectedly observe a pattern of sexualization of women, specifically Latin American, Mexican, Indian and Egyptian women, confirmed through an NSFW detector and verified by manual examination. This demonstrates how Stable Diffusion perpetuates Western fetishization of women of color through objectification in media, which if left unchecked will worsen this stereotypical representation. All code and relevant data will be made publicly available.</abstract>
      <url hash="30f825cf">2023.findings-emnlp.465</url>
      <bibkey>ghosh-caliskan-2023-person</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.465</doi>
    </paper>
    <paper id="466">
      <title>Task-Attentive Transformer Architecture for Continual Learning of Vision-and-Language Tasks Using Knowledge Distillation</title>
      <author><first>Yuliang</first><last>Cai</last></author>
      <author><first>Jesse</first><last>Thomason</last></author>
      <author><first>Mohammad</first><last>Rostami</last></author>
      <pages>6986-7000</pages>
      <abstract>The size and the computational load of fine-tuning large-scale pre-trained neural network are becoming two major obstacles in adopting machine learning in many applications. Continual learning (CL) can serve as a remedy through enabling knowledge-transfer across sequentially arriving tasks which relaxes the need to fine-tune all network weights from scratch. However, existing CL algorithms primarily consider learning unimodal vision-only or language-only tasks. We develop a transformer-based CL architecture for learning bimodal vision-and-language tasks based on increasing the number of the learnable parameters dynamically and using knowledge distillation. The new additional parameters are used to specialize the network for each task. Our approach enables sharing information between the tasks while addressing the challenge of catastrophic forgetting. Our approach is scalable learning to a large number of tasks because it requires little memory and time overhead. Our model reaches state-of-the-art performance on challenging vision-and-language tasks.</abstract>
      <url hash="08a53090">2023.findings-emnlp.466</url>
      <bibkey>cai-etal-2023-task</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.466</doi>
    </paper>
    <paper id="467">
      <title>Evaluating Verifiability in Generative Search Engines</title>
      <author><first>Nelson</first><last>Liu</last></author>
      <author><first>Tianyi</first><last>Zhang</last></author>
      <author><first>Percy</first><last>Liang</last></author>
      <pages>7001-7025</pages>
      <abstract>Generative search engines directly generate responses to user queries, along with in-line citations. A prerequisite trait of a trustworthy generative search engine is verifiability, i.e., systems should cite comprehensively (high citation recall; all statements are fully supported by citations) and accurately (high citation precision; every cite supports its associated statement). We conduct human evaluation to audit four popular generative search engines—Bing Chat, NeevaAI, perplexity.ai, and YouChat—across a diverse set of queries from a variety of sources (e.g., historical Google user queries, dynamically-collected open-ended questions on Reddit, etc.). We find that responses from existing generative search engines are fluent and appear informative, but frequently contain unsupported statements and inaccurate citations: on average, a mere 51.5% of generated sentences are fully supported by citations and only 74.5% of citations support their associated sentence. We believe that these results are concerningly low for systems that may serve as a primary tool for information-seeking users, especially given their facade of trustworthiness. We hope that our results further motivate the development of trustworthy generative search engines and help researchers and users better understand the shortcomings of existing commercial systems.</abstract>
      <url hash="27d349b4">2023.findings-emnlp.467</url>
      <bibkey>liu-etal-2023-evaluating</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.467</doi>
    </paper>
    <paper id="468">
      <title>Enhancing Abstractiveness of Summarization Models through Calibrated Distillation</title>
      <author><first>Hwanjun</first><last>Song</last></author>
      <author><first>Igor</first><last>Shalyminov</last></author>
      <author><first>Hang</first><last>Su</last></author>
      <author><first>Siffi</first><last>Singh</last></author>
      <author><first>Kaisheng</first><last>Yao</last></author>
      <author><first>Saab</first><last>Mansour</last></author>
      <pages>7026-7036</pages>
      <abstract>In this paper, we propose a novel approach named DisCal to enhance the level of abstractiveness (measured by n-gram overlap) without sacrificing the informativeness (measured by ROUGE) of generated summaries. DisCal exposes diverse pseudo summaries with two supervision to the student model. Firstly, the best pseudo summary is identified in terms of abstractiveness and informativeness and used for sequence-level distillation. Secondly, their ranks are used to ensure the student model to assign higher prediction scores to summaries with higher ranks. Our experiments show that DisCal outperforms prior methods in abstractive summarization distillation, producing highly abstractive and informative summaries.</abstract>
      <url hash="23cad024">2023.findings-emnlp.468</url>
      <bibkey>song-etal-2023-enhancing</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.468</doi>
    </paper>
    <paper id="469">
      <title>Visually Grounded Continual Language Learning with Selective Specialization</title>
      <author><first>Kyra</first><last>Ahrens</last></author>
      <author><first>Lennart</first><last>Bengtson</last></author>
      <author><first>Jae</first><last>Hee Lee</last></author>
      <author><first>Stefan</first><last>Wermter</last></author>
      <pages>7037-7054</pages>
      <abstract>A desirable trait of an artificial agent acting in the visual world is to continually learn a sequence of language-informed tasks while striking a balance between sufficiently specializing in each task and building a generalized knowledge for transfer. Selective specialization, i.e., a careful selection of model components to specialize in each task, is a strategy to provide control over this trade-off. However, the design of selection strategies requires insights on the role of each model component in learning rather specialized or generalizable representations, which poses a gap in current research. Thus, our aim with this work is to provide an extensive analysis of selection strategies for visually grounded continual language learning. Due to the lack of suitable benchmarks for this purpose, we introduce two novel diagnostic datasets that provide enough control and flexibility for a thorough model analysis. We assess various heuristics for module specialization strategies as well as quantifiable measures for two different types of model architectures. Finally, we design conceptually simple approaches based on our analysis that outperform common continual learning baselines. Our results demonstrate the need for further efforts towards better aligning continual learning algorithms with the learning behaviors of individual model parts.</abstract>
      <url hash="d5d0e97f">2023.findings-emnlp.469</url>
      <bibkey>ahrens-etal-2023-visually</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.469</doi>
    </paper>
    <paper id="470">
      <title><fixed-case>R</fixed-case>o<fixed-case>MQA</fixed-case>: A Benchmark for Robust, Multi-evidence, Multi-answer Question Answering</title>
      <author><first>Victor</first><last>Zhong</last></author>
      <author><first>Weijia</first><last>Shi</last></author>
      <author><first>Wen-tau</first><last>Yih</last></author>
      <author><first>Luke</first><last>Zettlemoyer</last></author>
      <pages>7055-7067</pages>
      <abstract>We introduce RoMQA, the first benchmark for robust, multi-evidence, multi-answer question answering (QA). RoMQA contains clusters of questions that are derived from related constraints mined from the Wikidata knowledge graph. RoMQA evaluates robustness of QA models to varying constraints by measuring worst-case performance within each question cluster. Compared to prior QA datasets, RoMQA has more human-written questions that require reasoning over more evidence text and have, on average, many more correct answers. In addition, human annotators rate RoMQA questions as more natural or likely to be asked by people. We evaluate state-of-the-art large language models in zero-shot, few-shot, and fine-tuning settings, and find that RoMQA is challenging: zeroshot and few-shot models perform similarly to naive baselines, while supervised retrieval methods perform well below gold evidence upper bounds. Moreover, existing models are not robust to variations in question constraints, but can be made more robust by tuning on clusters of related questions. Our results show that RoMQA is a challenging benchmark for large language models, and provides a quantifiable test to build more robust QA methods.</abstract>
      <url hash="e5eb53b5">2023.findings-emnlp.470</url>
      <bibkey>zhong-etal-2023-romqa</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.470</doi>
    </paper>
    <paper id="471">
      <title>Leveraging Multiple Teachers for Test-Time Adaptation of Language-Guided Classifiers</title>
      <author><first>Kangda</first><last>Wei</last></author>
      <author><first>Sayan</first><last>Ghosh</last></author>
      <author><first>Rakesh</first><last>Menon</last></author>
      <author><first>Shashank</first><last>Srivastava</last></author>
      <pages>7068-7088</pages>
      <abstract>Recent approaches have explored language- guided classifiers capable of classifying examples from novel tasks when provided with task-specific natural language explanations, instructions or prompts (Sanh et al., 2022; R. Menon et al., 2022). While these classifiers can generalize in zero-shot settings, their task performance often varies substantially between different language explanations in unpredictable ways (Lu et al., 2022; Gonen et al., 2022). Also, current approaches fail to leverage unlabeled examples that may be available in many scenarios. Here, we introduce TALC, a framework that uses data programming to adapt a language-guided classifier for a new task during inference when provided with explanations from multiple teachers and unlabeled test examples. Our results show that TALC consistently outperforms a competitive baseline from prior work by an impressive 9.3% (relative improvement). Further, we demonstrate the robustness of TALC to variations in the quality and quantity of provided explanations, highlighting its potential in scenarios where learning from multiple teachers or a crowd is involved. Our code is available at: https://github.com/WeiKangda/TALC.git.</abstract>
      <url hash="18702718">2023.findings-emnlp.471</url>
      <bibkey>wei-etal-2023-leveraging</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.471</doi>
    </paper>
    <paper id="472">
      <title>Summarizing Multiple Documents with Conversational Structure for Meta-Review Generation</title>
      <author><first>Miao</first><last>Li</last></author>
      <author><first>Eduard</first><last>Hovy</last></author>
      <author><first>Jey</first><last>Lau</last></author>
      <pages>7089-7112</pages>
      <abstract>We present PeerSum, a novel dataset for generating meta-reviews of scientific papers. The meta-reviews can be interpreted as abstractive summaries of reviews, multi-turn discussions and the paper abstract. These source documents have a rich inter-document relationship with an explicit hierarchical conversational structure, cross-references and (occasionally) conflicting information. To introduce the structural inductive bias into pre-trained language models, we introduce RAMMER (Relationship-aware Multi-task Meta-review Generator), a model that uses sparse attention based on the conversational structure and a multi-task training objective that predicts metadata features (e.g., review ratings). Our experimental results show that RAMMER outperforms other strong baseline models in terms of a suite of automatic evaluation metrics. Further analyses, however, reveal that RAMMER and other models struggle to handle conflicts in source documents, suggesting meta-review generation is a challenging task and a promising avenue for further research.</abstract>
      <url hash="407267d5">2023.findings-emnlp.472</url>
      <bibkey>li-etal-2023-summarizing</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.472</doi>
    </paper>
    <paper id="473">
      <title><fixed-case>VIPHY</fixed-case>: Probing “Visible” Physical Commonsense Knowledge</title>
      <author><first>Shikhar</first><last>Singh</last></author>
      <author><first>Ehsan</first><last>Qasemi</last></author>
      <author><first>Muhao</first><last>Chen</last></author>
      <pages>7113-7128</pages>
      <abstract>Vision-language models (VLMs) have shown remarkable performance on visual reasoning tasks (e.g. attributes, location). While such tasks measure the requisite knowledge to ground and reason over a given visual instance, they do not, however, measure the ability of VLMs to retain and generalize such knowledge. In this work, we evaluate VLMs’ ability to acquire “visible” physical knowledge – the information that is easily accessible from images of static scenes, particularly along the dimensions of object color, size, and space. We build an automatic pipeline to derive a comprehensive knowledge resource for calibrating and probing these models. Our results indicate a severe gap between model and human performance across all three dimensions. Furthermore, we demonstrate that a caption pretrained LM significantly outperforms VLMs on both size and spatial tasks – highlighting that despite sufficient access to ground language with visual modality, they struggle to retain such knowledge.</abstract>
      <url hash="90106e93">2023.findings-emnlp.473</url>
      <bibkey>singh-etal-2023-viphy</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.473</doi>
    </paper>
    <paper id="474">
      <title>Two Directions for Clinical Data Generation with Large Language Models: Data-to-Label and Label-to-Data</title>
      <author><first>Rumeng</first><last>Li</last></author>
      <author><first>Xun</first><last>Wang</last></author>
      <author><first>Hong</first><last>Yu</last></author>
      <pages>7129-7143</pages>
      <abstract>Large language models (LLMs) can generate natural language texts for various domains and tasks, but their potential for clinical text mining, a domain with scarce, sensitive, and imbalanced medical data, is under-explored. We investigate whether LLMs can augment clinical data for detecting Alzheimer’s Disease (AD)-related signs and symptoms from electronic health records (EHRs), a challenging task that requires high expertise. We create a novel pragmatic taxonomy for AD sign and symptom progression based on expert knowledge and generated three datasets: (1) a gold dataset annotated by human experts on longitudinal EHRs of AD patients; (2) a silver dataset created by the data-to-label method, which labels sentences from a public EHR collection with AD-related signs and symptoms; and (3) a bronze dataset created by the label-to-data method which generates sentences with AD-related signs and symptoms based on the label definition. We train a system to detect AD-related signs and symptoms from EHRs. We find that the silver and bronze datasets improves the system performance, outperforming the system using only the gold dataset. This shows that LLMs can generate synthetic clinical data for a complex task by incorporating expert knowledge, and our label-to-data method can produce datasets that are free of sensitive information, while maintaining acceptable quality.</abstract>
      <url hash="5fe15580">2023.findings-emnlp.474</url>
      <bibkey>li-etal-2023-two</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.474</doi>
    </paper>
    <paper id="475">
      <title>Stylized Dialogue Generation with Feature-Guided Knowledge Augmentation</title>
      <author><first>Jinpeng</first><last>Li</last></author>
      <author><first>Zekai</first><last>Zhang</last></author>
      <author><first>Xiuying</first><last>Chen</last></author>
      <author><first>Dongyan</first><last>Zhao</last></author>
      <author><first>Rui</first><last>Yan</last></author>
      <pages>7144-7157</pages>
      <abstract>Stylized dialogue generation systems aim to produce coherent and context-aware dialogues while effectively emulating the desired style. Generating stylized dialogue is valuable yet challenging due to the scarce parallel data. Existing methods often synthesize pseudo data through back translation, yet suffer from noisy and context-agnostic style signals caused by insufficient guidance on target style features. To address this, we propose the knowledge-augmented stylized dialogue generation model, which includes a feature-guided style knowledge selection module that utilizes context and response features. Specifically, we retrieve dialogue-related style sentences from style corpus to explicitly provide clear style signals. We design a feature-guided selection module with response-related contrastive learning and style responsiveness Kullback-Leibler losses to enhance generation at both semantic and stylized levels. Our approach demonstrates satisfactory performance on two public stylized dialogue benchmarks in both automatic and human evaluations.</abstract>
      <url hash="c555c31a">2023.findings-emnlp.475</url>
      <bibkey>li-etal-2023-stylized</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.475</doi>
    </paper>
    <paper id="476">
      <title>Probing <fixed-case>LLM</fixed-case>s for Joint Encoding of Linguistic Categories</title>
      <author><first>Giulio</first><last>Starace</last></author>
      <author><first>Konstantinos</first><last>Papakostas</last></author>
      <author><first>Rochelle</first><last>Choenni</last></author>
      <author><first>Apostolos</first><last>Panagiotopoulos</last></author>
      <author><first>Matteo</first><last>Rosati</last></author>
      <author><first>Alina</first><last>Leidinger</last></author>
      <author><first>Ekaterina</first><last>Shutova</last></author>
      <pages>7158-7179</pages>
      <abstract>Large Language Models (LLMs) exhibit impressive performance on a range of NLP tasks, due to the general-purpose linguistic knowledge acquired during pretraining. Existing model interpretability research (Tenney et al., 2019) suggests that a linguistic hierarchy emerges in the LLM layers, with lower layers better suited to solving syntactic tasks and higher layers employed for semantic processing. Yet, little is known about how encodings of different linguistic phenomena interact within the models and to what extent processing of linguistically-related categories relies on the same, shared model representations. In this paper, we propose a framework for testing the joint encoding of linguistic categories in LLMs. Focusing on syntax, we find evidence of joint encoding both at the same (related part-of-speech (POS) classes) and different (POS classes and related syntactic dependency relations) levels of linguistic hierarchy. Our cross-lingual experiments show that the same patterns hold across languages in multilingual LLMs.</abstract>
      <url hash="94ec2f05">2023.findings-emnlp.476</url>
      <bibkey>starace-etal-2023-probing</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.476</doi>
    </paper>
    <paper id="477">
      <title>On Robustness of Finetuned Transformer-based <fixed-case>NLP</fixed-case> Models</title>
      <author><first>Pavan Kalyan Reddy</first><last>Neerudu</last></author>
      <author><first>Subba</first><last>Oota</last></author>
      <author><first>Mounika</first><last>Marreddy</last></author>
      <author><first>Venkateswara</first><last>Kagita</last></author>
      <author><first>Manish</first><last>Gupta</last></author>
      <pages>7180-7195</pages>
      <abstract>Transformer-based pretrained models like BERT, GPT-2 and T5 have been finetuned for a large number of natural language processing (NLP) tasks, and have been shown to be very effective. However, while finetuning, what changes across layers in these models with respect to pretrained checkpoints is under-studied. Further, how robust are these models to perturbations in input text? Does the robustness vary depending on the NLP task for which the models have been finetuned? While there exists some work on studying robustness of BERT finetuned for a few NLP tasks, there is no rigorous study which compares this robustness across encoder only, decoder only and encoder-decoder models. In this paper, we characterize changes between pretrained and finetuned language model representations across layers using two metrics: CKA and STIR. Further, we study the robustness of three language models (BERT, GPT-2 and T5) with eight different text perturbations on classification tasks from General Language Understanding Evaluation (GLUE) benchmark, and generation tasks like summarization, free-form generation and question generation. GPT-2 representations are more robust than BERT and T5 across multiple types of input perturbation. Although models exhibit good robustness broadly, dropping nouns, verbs or changing characters are the most impactful. Overall, this study provides valuable insights into perturbation-specific weaknesses of popular Transformer-based models which should be kept in mind when passing inputs.</abstract>
      <url hash="9bb1adfd">2023.findings-emnlp.477</url>
      <bibkey>neerudu-etal-2023-robustness</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.477</doi>
    </paper>
    <paper id="478">
      <title>Measuring and Mitigating Constraint Violations of In-Context Learning for Utterance-to-<fixed-case>API</fixed-case> Semantic Parsing</title>
      <author><first>Shufan</first><last>Wang</last></author>
      <author><first>Sébastien</first><last>Jean</last></author>
      <author><first>Sailik</first><last>Sengupta</last></author>
      <author><first>James</first><last>Gung</last></author>
      <author><first>Nikolaos</first><last>Pappas</last></author>
      <author><first>Yi</first><last>Zhang</last></author>
      <pages>7196-7207</pages>
      <abstract>In executable task-oriented semantic parsing, the system aims to translate users’ utterances in natural language to machine-interpretable programs (API calls) that can be executed according to pre-defined API specifications. With the popularity of Large Language Models (LLMs), in-context learning offers a strong baseline for such scenarios, especially in data-limited regimes. However, LLMs are known to hallucinate and therefore pose a formidable challenge in constraining generated content. Thus, it remains uncertain if LLMs can effectively perform task-oriented utterance-to-API generation, where respecting the API’s structural and task-specific constraints is crucial. In this work, we seek to measure, analyze and mitigate such constraints violations. First, we identify the categories of various constraints in obtaining API-semantics from task-oriented utterances, and define fine-grained metrics that complement traditional ones. Second, we leverage these metrics to conduct a detailed error analysis of constraints violations seen in state-of-the-art LLMs, which motivates us to investigate two popular mitigation strategies– Semantic-Retrieval of Demonstrations (SRD) and API-aware Constrained Decoding (API-CD). Our experiments show that these strategies are effective at reducing constraints violations and improving the quality of the generated API calls, but require careful consideration given their implementation complexity and latency.</abstract>
      <url hash="615bdbc9">2023.findings-emnlp.478</url>
      <bibkey>wang-etal-2023-measuring</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.478</doi>
    </paper>
    <paper id="479">
      <title>Entity Disambiguation on a Tight Labeling Budget</title>
      <author><first>Audi</first><last>Primadhanty</last></author>
      <author><first>Ariadna</first><last>Quattoni</last></author>
      <pages>7208-7215</pages>
      <abstract>Many real-world NLP applications face the challenge of training an entity disambiguation model for a specific domain with a small labeling budget. In this setting there is often access to a large unlabeled pool of documents. It is then natural to ask the question: which samples should be selected for annotation? In this paper we propose a solution that combines feature diversity with low rank correction. Our sampling strategy is formulated in the context of bilinear tensor models. Our experiments show that the proposed approach can significantly reduce the amount of labeled data necessary to achieve a given performance.</abstract>
      <url hash="5d7f3c6c">2023.findings-emnlp.479</url>
      <bibkey>primadhanty-quattoni-2023-entity</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.479</doi>
    </paper>
    <paper id="480">
      <title>Topic-<fixed-case>DPR</fixed-case>: Topic-based Prompts for Dense Passage Retrieval</title>
      <author><first>Qingfa</first><last>Xiao</last></author>
      <author><first>Shuangyin</first><last>Li</last></author>
      <author><first>Lei</first><last>Chen</last></author>
      <pages>7216-7225</pages>
      <abstract>Prompt-based learning’s efficacy across numerous natural language processing tasks has led to its integration into dense passage retrieval. Prior research has mainly focused on enhancing the semantic understanding of pre-trained language models by optimizing a single vector as a continuous prompt. This approach, however, leads to a semantic space collapse; identical semantic information seeps into all representations, causing their distributions to converge in a restricted region. This hinders differentiation between relevant and irrelevant passages during dense retrieval. To tackle this issue, we present Topic-DPR, a dense passage retrieval model that uses topic-based prompts. Unlike the single prompt method, multiple topic-based prompts are established over a probabilistic simplex and optimized simultaneously through contrastive learning. This encourages representations to align with their topic distributions, improving space uniformity. Furthermore, we introduce a novel positive and negative sampling strategy, leveraging semi-structured data to boost dense retrieval efficiency. Experimental results from two datasets affirm that our method surpasses previous state-of-the-art retrieval techniques.</abstract>
      <url hash="973e3987">2023.findings-emnlp.480</url>
      <bibkey>xiao-etal-2023-topic</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.480</doi>
    </paper>
    <paper id="481">
      <title>Quantifying the Dialect Gap and its Correlates Across Languages</title>
      <author><first>Anjali</first><last>Kantharuban</last></author>
      <author><first>Ivan</first><last>Vulić</last></author>
      <author><first>Anna</first><last>Korhonen</last></author>
      <pages>7226-7245</pages>
      <abstract>Historically, researchers and consumers have noticed a decrease in quality when applying NLP tools to minority variants of languages (i.e. Puerto Rican Spanish or Swiss German), but studies exploring this have been limited to a select few languages. Additionally, past studies have mainly been conducted in a monolingual context, so cross-linguistic trends have not been identified and tied to external factors. In this work, we conduct a comprehensive evaluation of the most influential, state-of-the-art large language models (LLMs) across two high-use applications, machine translation and automatic speech recognition, to assess their functionality on the regional dialects of several high- and low-resource languages. Additionally, we analyze how the regional dialect gap is correlated with economic, social, and linguistic factors. The impact of training data, including related factors like dataset size and its construction procedure, is shown to be significant but not consistent across models or languages, meaning a one-size-fits-all approach cannot be taken in solving the dialect gap. This work will lay the foundation for furthering the field of dialectal NLP by laying out evident disparities and identifying possible pathways for addressing them through mindful data collection.</abstract>
      <url hash="c45932d8">2023.findings-emnlp.481</url>
      <bibkey>kantharuban-etal-2023-quantifying</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.481</doi>
    </paper>
    <paper id="482">
      <title><fixed-case>RECAL</fixed-case>: Sample-Relation Guided Confidence Calibration over Tabular Data</title>
      <author><first>Wang</first><last>HaoTian</last></author>
      <author><first>Zhen</first><last>Zhang</last></author>
      <author><first>Mengting</first><last>Hu</last></author>
      <author><first>Qichao</first><last>Wang</last></author>
      <author><first>Liang</first><last>Chen</last></author>
      <author><first>Yatao</first><last>Bian</last></author>
      <author><first>Bingzhe</first><last>Wu</last></author>
      <pages>7246-7257</pages>
      <abstract>Tabular-format data is widely adopted in various real-world applications. Various machine learning models have achieved remarkable success in both industrial applications and data-science competitions. Despite these successes, most current machine learning methods for tabular data lack accurate confidence estimation, which is needed by some high-risk sensitive applications such as credit modeling and financial fraud detection. In this paper, we study the confidence estimation of machine learning models applied to tabular data. The key finding of our paper is that a real-world tabular dataset typically contains implicit sample relations, and this can further help to obtain a more accurate estimation. To this end, we introduce a general post-training confidence calibration framework named RECAL to calibrate the predictive confidence of current machine learning models by employing graph neural networks to model the relations between different samples. We perform extensive experiments on tabular datasets with both implicit and explicit graph structures and show that RECAL can significantly improve the calibration quality compared to the conventional method without considering the sample relations.</abstract>
      <url hash="383ceac6">2023.findings-emnlp.482</url>
      <bibkey>haotian-etal-2023-recal</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.482</doi>
    </paper>
    <paper id="483">
      <title>Parameter-Efficient Cross-lingual Transfer of Vision and Language Models via Translation-based Alignment</title>
      <author><first>Zhen</first><last>Zhang</last></author>
      <author><first>Jialu</first><last>Wang</last></author>
      <author><first>Xin</first><last>Wang</last></author>
      <pages>7258-7268</pages>
      <abstract>Pre-trained vision and language models such as CLIP have witnessed remarkable success in connecting images and texts with a primary focus on English texts. Despite recent efforts to extend CLIP to support other languages, disparities in performance among different languages have been observed due to uneven resource availability. Additionally, current cross-lingual transfer methods of those pre-trained models would consume excessive resources for a large number of languages. Therefore, we propose a new parameter-efficient cross-lingual transfer learning framework that utilizes a translation-based alignment method to mitigate multilingual disparities and explores parameter-efficient fine-tuning methods for parameter-efficient cross-lingual transfer. Extensive experiments on XTD and Multi30K datasets, covering 11 languages under zero-shot, few-shot, and full-dataset learning scenarios, show that our framework significantly reduces the multilingual disparities among languages and improves cross-lingual transfer results, especially in low-resource scenarios, while only keeping and fine-tuning an extremely small number of parameters compared to the full model (e.g., Our framework only requires 0.16% additional parameters of a full-model for each language in the few-shot learning scenario).</abstract>
      <url hash="d6dbc43c">2023.findings-emnlp.483</url>
      <bibkey>zhang-etal-2023-parameter</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.483</doi>
    </paper>
    <paper id="484">
      <title>Lexical Repetitions Lead to Rote Learning: Unveiling the Impact of Lexical Overlap in Train and Test Reference Summaries</title>
      <author><first>Prafulla</first><last>Choubey</last></author>
      <author><first>Alexander</first><last>Fabbri</last></author>
      <author><first>Caiming</first><last>Xiong</last></author>
      <author><first>Chien-Sheng</first><last>Wu</last></author>
      <pages>7269-7283</pages>
      <abstract>Ideal summarization models should generalize to novel summary-worthy content without remembering reference training summaries by rote. However, a single average performance score on the entire test set is inadequate in determining such model competencies. We propose a fine-grained evaluation protocol by partitioning a test set based on the lexical similarity of reference test summaries with training summaries. We observe up to a 5x (1.2x) difference in ROUGE-2 (entity recall) scores between the subsets with the lowest and highest similarity. Next, we show that such training repetitions also make a model vulnerable to rote learning, reproducing data artifacts such as factual errors, especially when reference test summaries are lexically close to training summaries. Consequently, we propose to limit lexical repetitions in training summaries during both supervised fine-tuning and likelihood calibration stages to improve the performance on novel test cases while retaining average performance. Our automatic and human evaluations on novel test subsets and recent news articles show that limiting lexical repetitions in training summaries can prevent rote learning and improve generalization.</abstract>
      <url hash="d6171494">2023.findings-emnlp.484</url>
      <bibkey>choubey-etal-2023-lexical</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.484</doi>
    </paper>
    <paper id="485">
      <title>Pseudointelligence: A Unifying Lens on Language Model Evaluation</title>
      <author><first>Shikhar</first><last>Murty</last></author>
      <author><first>Orr</first><last>Paradise</last></author>
      <author><first>Pratyusha</first><last>Sharma</last></author>
      <pages>7284-7290</pages>
      <abstract>With large language models surpassing human performance on an increasing number of benchmarks, we must take a principled approach for targeted evaluation of model capabilities. Inspired by pseudorandomness, we propose pseudointelligence, which captures the maxim that “(perceived) intelligence lies in the eye of the beholder.” That is, that claims of intelligence are meaningful only when their evaluator is taken into account. Concretely, we propose a complexity-theoretic framework of model evaluation cast as a dynamic interaction between a model and a learned evaluator. We demonstrate that this framework can be used to reason about two case studies in language model evaluation, as well as analyze existing evaluation methods.</abstract>
      <url hash="714a6718">2023.findings-emnlp.485</url>
      <bibkey>murty-etal-2023-pseudointelligence</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.485</doi>
    </paper>
    <paper id="486">
      <title><fixed-case>GDA</fixed-case>: Grammar-based Data Augmentation for Text Classification using Slot Information</title>
      <author><first>Joonghyuk</first><last>Hahn</last></author>
      <author><first>Hyunjoon</first><last>Cheon</last></author>
      <author><first>Elizabeth</first><last>Orwig</last></author>
      <author><first>Su-Hyeon</first><last>Kim</last></author>
      <author><first>Sang-Ki</first><last>Ko</last></author>
      <author><first>Yo-Sub</first><last>Han</last></author>
      <pages>7291-7306</pages>
      <abstract>Recent studies propose various data augmentation approaches to resolve the low-resource problem in natural language processing tasks. Data augmentation is a successful solution to this problem and recent strategies give variation on sentence structures to boost performance. However, these approaches can potentially lead to semantic errors and produce semantically noisy data due to the unregulated variation of sentence structures. In an effort to combat these semantic errors, we leverage slot information, the representation of the context of keywords from a sentence, and form a data augmentation strategy which we propose, called GDA. Our strategy employs algorithms that construct and manipulate rules of context-aware grammar, utilizing this slot information. The algorithms extract recurrent patterns by distinguishing words with slots and form the “rules of grammar”—a set of injective relations between a sentence’s semantics and its syntactical structure—to augment the dataset. The augmentation is done in an automated manner with the constructed rules and thus, GDA is explainable and reliable without any human intervention. We evaluate GDA with state-of-the-art data augmentation techniques, including those using pre-trained language models, and the result illustrates that GDA outperforms all other data augmentation methods by 19.38%. Extensive experiments show that GDA is an effective data augmentation strategy that incorporates word semantics for more accurate and diverse data.</abstract>
      <url hash="ae3cada1">2023.findings-emnlp.486</url>
      <bibkey>hahn-etal-2023-gda</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.486</doi>
    </paper>
    <paper id="487">
      <title>Implicit Sense-labeled Connective Recognition as Text Generation</title>
      <author><first>Yui</first><last>Oka</last></author>
      <author><first>Tsutomu</first><last>Hirao</last></author>
      <pages>7307-7313</pages>
      <abstract>Implicit Discourse Relation Recognition (IDRR) involves identifying the sense label of an implicit connective between adjacent text spans. This has traditionally been approached as a classification task. However, some downstream tasks require more than just a sense label as well as the specific connective used. This paper presents Implicit Sense-labeled Connective Recognition (ISCR), which identifies the implicit connectives and their sense labels between adjacent text spans. ISCR can be treated as a classification task, but a large number of potential categories, sense labels, and uneven distribution of instances among them make this difficult. Instead, this paper handles the task as a text-generation task, using an encoder-decoder model to generate both connectives and their sense labels. Here, we explore a classification method and three kinds of text-generation methods. From our evaluation results on PDTB-3.0, we found that our method outperforms the conventional classification-based method.</abstract>
      <url hash="b0868acb">2023.findings-emnlp.487</url>
      <bibkey>oka-hirao-2023-implicit</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.487</doi>
    </paper>
    <paper id="488">
      <title><fixed-case>VISTA</fixed-case>: Visual-Textual Knowledge Graph Representation Learning</title>
      <author><first>Jaejun</first><last>Lee</last></author>
      <author><first>Chanyoung</first><last>Chung</last></author>
      <author><first>Hochang</first><last>Lee</last></author>
      <author><first>Sungho</first><last>Jo</last></author>
      <author><first>Joyce</first><last>Whang</last></author>
      <pages>7314-7328</pages>
      <abstract>Knowledge graphs represent human knowledge using triplets composed of entities and relations. While most existing knowledge graph embedding methods only consider the structure of a knowledge graph, a few recently proposed multimodal methods utilize images or text descriptions of entities in a knowledge graph. In this paper, we propose visual-textual knowledge graphs (VTKGs), where not only entities but also triplets can be explained using images, and both entities and relations can accompany text descriptions. By compiling visually expressible commonsense knowledge, we construct new benchmark datasets where triplets themselves are explained by images, and the meanings of entities and relations are described using text. We propose VISTA, a knowledge graph representation learning method for VTKGs, which incorporates the visual and textual representations of entities and relations using entity encoding, relation encoding, and triplet decoding transformers. Experiments show that VISTA outperforms state-of-the-art knowledge graph completion methods in real-world VTKGs.</abstract>
      <url hash="ef95533f">2023.findings-emnlp.488</url>
      <bibkey>lee-etal-2023-vista</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.488</doi>
    </paper>
    <paper id="489">
      <title>Dynamic Stashing Quantization for Efficient Transformer Training</title>
      <author><first>Guo</first><last>Yang</last></author>
      <author><first>Daniel</first><last>Lo</last></author>
      <author><first>Robert</first><last>Mullins</last></author>
      <author><first>Yiren</first><last>Zhao</last></author>
      <pages>7329-7336</pages>
      <abstract>Large Language Models (LLMs) have demonstrated impressive performance on a range of Natural Language Processing (NLP) tasks. Unfortunately, the immense amount of computations and memory accesses required for LLM training makes them prohibitively expensive in terms of hardware cost, and thus challenging to deploy in use cases such as on-device learning. In this paper, motivated by the observation that LLM training is memory-bound, we propose a novel dynamic quantization strategy, termed Dynamic Stashing Quantization (DSQ), that puts a special focus on reducing the memory operations, but also enjoys the other benefits of low precision training, such as the reduced arithmetic cost. We conduct a thorough study on two translation tasks (trained-from-scratch) and three classification tasks (fine-tuning). DSQ reduces the amount of arithmetic operations by <tex-math>20.95\times</tex-math> and the number of DRAM operations by <tex-math>2.55\times</tex-math> on IWSLT17 compared to the standard 16-bit fixed-point, which is widely used in on-device learning.</abstract>
      <url hash="630cb331">2023.findings-emnlp.489</url>
      <bibkey>yang-etal-2023-dynamic</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.489</doi>
    </paper>
    <paper id="490">
      <title>A Comprehensive Evaluation of Large Language Models on Legal Judgment Prediction</title>
      <author><first>Ruihao</first><last>Shui</last></author>
      <author><first>Yixin</first><last>Cao</last></author>
      <author><first>Xiang</first><last>Wang</last></author>
      <author><first>Tat-Seng</first><last>Chua</last></author>
      <pages>7337-7348</pages>
      <abstract>Large language models (LLMs) have demonstrated great potential for domain-specific applications, such as the law domain. However, recent disputes over GPT-4’s law evaluation raise questions concerning their performance in real-world legal tasks. To systematically investigate their competency in the law, we design practical baseline solutions based on LLMs and test on the task of legal judgment prediction. In our solutions, LLMs can work alone to answer open questions or coordinate with an information retrieval (IR) system to learn from similar cases or solve simplified multi-choice questions. We show that similar cases and multi-choice options, namely label candidates, included in prompts can help LLMs recall domain knowledge that is critical for expertise legal reasoning. We additionally present an intriguing paradox wherein an IR system surpasses the performance of LLM+IR due to limited gains acquired by weaker LLMs from powerful IR systems. In such case, the role of LLMs becomes redundant. Our evaluation pipeline can be easily extended into other tasks to facilitate evaluations in other domains. Code is available at https://github.com/srhthu/LM-CompEval-Legal</abstract>
      <url hash="95387d51">2023.findings-emnlp.490</url>
      <bibkey>shui-etal-2023-comprehensive</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.490</doi>
    </paper>
    <paper id="491">
      <title>A Lightweight Method to Generate Unanswerable Questions in <fixed-case>E</fixed-case>nglish</title>
      <author><first>Vagrant</first><last>Gautam</last></author>
      <author><first>Miaoran</first><last>Zhang</last></author>
      <author><first>Dietrich</first><last>Klakow</last></author>
      <pages>7349-7360</pages>
      <abstract>If a question cannot be answered with the available information, robust systems for question answering (QA) should know *not* to answer. One way to build QA models that do this is with additional training data comprised of unanswerable questions, created either by employing annotators or through automated methods for unanswerable question generation. To show that the model complexity of existing automated approaches is not justified, we examine a simpler data augmentation method for unanswerable question generation in English: performing antonym and entity swaps on answerable questions. Compared to the prior state-of-the-art, data generated with our training-free and lightweight strategy results in better models (+1.6 F1 points on SQuAD 2.0 data with BERT-large), and has higher human-judged relatedness and readability. We quantify the raw benefits of our approach compared to no augmentation across multiple encoder models, using different amounts of generated data, and also on TydiQA-MinSpan data (+9.3 F1 points with BERT-large). Our results establish swaps as a simple but strong baseline for future work.</abstract>
      <url hash="4f3af96e">2023.findings-emnlp.491</url>
      <bibkey>gautam-etal-2023-lightweight</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.491</doi>
    </paper>
    <paper id="492">
      <title>Automatic Evaluate Dialogue Appropriateness by Using Dialogue Act</title>
      <author><first>Bao</first><last>Chen</last></author>
      <author><first>Yuanjie</first><last>Wang</last></author>
      <author><first>Zeming</first><last>Liu</last></author>
      <author><first>Yuhang</first><last>Guo</last></author>
      <pages>7361-7372</pages>
      <abstract>Evaluation of dialogue systems requires assessing various aspects, among which appropriateness holds significance as a core element of communicative language competence. However, current evaluations heavily rely on human judgments, which are time-consuming, labor-intensive, prone to biases, and lacking objectivity. In this paper, we introduce Dialogue Act Appropriateness (DAA), a novel method that utilizes the underlying patterns of dialogue act transitions to evaluate the appropriateness of chatbot responses. We learn transition patterns from human-human dialogue corpora, evaluating chatbot appropriateness by measuring the similarity of their transition patterns to those observed in human-human dialogues. To validate DAA, we annotate a test dataset by manually evaluating the appropriateness of dialogues from multiple chatbot systems. The experimental results demonstrate a strong correlation between our evaluation metric and human ratings, establishing the reliability of DAA as a measure of dialogue appropriateness.</abstract>
      <url hash="eb0607bb">2023.findings-emnlp.492</url>
      <bibkey>chen-etal-2023-automatic</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.492</doi>
    </paper>
    <paper id="493">
      <title><fixed-case>T</fixed-case>ab<fixed-case>P</fixed-case>rompt: Graph-based Pre-training and Prompting for Few-shot Table Understanding</title>
      <author><first>Rihui</first><last>Jin</last></author>
      <author><first>Jianan</first><last>Wang</last></author>
      <author><first>Wei</first><last>Tan</last></author>
      <author><first>Yongrui</first><last>Chen</last></author>
      <author><first>Guilin</first><last>Qi</last></author>
      <author><first>Wang</first><last>Hao</last></author>
      <pages>7373-7383</pages>
      <abstract>Table Understanding (TU) is a crucial aspect of information extraction that enables machines to comprehend the semantics behind tabular data. However, existing methods of TU cannot deal with the scarcity of labeled tabular data. In addition, these methods primarily focus on the textual content within the table, disregarding the inherent topological information of the table. This can lead to a misunderstanding of the tabular semantics. In this paper, we propose TabPrompt, a new framework to tackle the above challenges. Prompt-based learning has gained popularity due to its exceptional performance in few-shot learning. Thus, we introduce prompt-based learning to handle few-shot TU. Furthermore, Graph Contrastive Learning (Graph CL) demonstrates remarkable capabilities in capturing topological information, making Graph Neural Networks an ideal method for encoding tables. Hence, we develop a novel Graph CL method tailored to tabular data. This method serves as the pretext task during the pre-training phase, allowing the generation of vector representations that incorporate the table’s topological information. The experimental results of outperforming all strong baselines demonstrate the strength of our method in few-shot table understanding tasks.</abstract>
      <url hash="83f5ef52">2023.findings-emnlp.493</url>
      <bibkey>jin-etal-2023-tabprompt</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.493</doi>
    </paper>
    <paper id="494">
      <title>Towards Formality-Aware Neural Machine Translation by Leveraging Context Information</title>
      <author><first>Dohee</first><last>Kim</last></author>
      <author><first>Yujin</first><last>Baek</last></author>
      <author><first>Soyoung</first><last>Yang</last></author>
      <author><first>Jaegul</first><last>Choo</last></author>
      <pages>7384-7392</pages>
      <abstract>Formality is one of the most important linguistic properties to determine the naturalness of translation. Although a target-side context contains formality-related tokens, the sparsity within the context makes it difficult for context-aware neural machine translation (NMT) models to properly discern them. In this paper, we introduce a novel training method to explicitly inform the NMT model by pinpointing key informative tokens using a formality classifier. Given a target context, the formality classifier guides the model to concentrate on the formality-related tokens within the context. Additionally, we modify the standard cross-entropy loss, especially toward the formality-related tokens obtained from the classifier. Experimental results show that our approaches not only improve overall translation quality but also reflect the appropriate formality from the target context.</abstract>
      <url hash="a1105e0f">2023.findings-emnlp.494</url>
      <bibkey>kim-etal-2023-towards</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.494</doi>
    </paper>
    <paper id="495">
      <title>Improving <fixed-case>S</fixed-case>eq2<fixed-case>S</fixed-case>eq Grammatical Error Correction via Decoding Interventions</title>
      <author><first>Houquan</first><last>Zhou</last></author>
      <author><first>Yumeng</first><last>Liu</last></author>
      <author><first>Zhenghua</first><last>Li</last></author>
      <author><first>Min</first><last>Zhang</last></author>
      <author><first>Bo</first><last>Zhang</last></author>
      <author><first>Chen</first><last>Li</last></author>
      <author><first>Ji</first><last>Zhang</last></author>
      <author><first>Fei</first><last>Huang</last></author>
      <pages>7393-7405</pages>
      <abstract>The sequence-to-sequence (Seq2Seq) approach has recently been widely used in grammatical error correction (GEC) and shows promising performance. However, the Seq2Seq GEC approach still suffers from two issues. First, a Seq2Seq GEC model can only be trained on parallel data, which, in GEC task, is often noisy and limited in quantity. Second, the decoder of a Seq2Seq GEC model lacks an explicit awareness of the correctness of the token being generated. In this paper, we propose a unified decoding intervention framework that employs an external critic to assess the appropriateness of the token to be generated incrementally, and then dynamically influence the choice of the next token. We discover and investigate two types of critics: a pre-trained left-to-right language model critic and an incremental target-side grammatical error detector critic. Through extensive experiments on English and Chinese datasets, our framework consistently outperforms strong baselines and achieves results competitive with state-of-the-art methods.</abstract>
      <url hash="55a4abc9">2023.findings-emnlp.495</url>
      <bibkey>zhou-etal-2023-improving-seq2seq</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.495</doi>
    </paper>
    <paper id="496">
      <title>Exploring the Potential of Large Language Models in Generating Code-Tracing Questions for Introductory Programming Courses</title>
      <author><first>Aysa</first><last>Fan</last></author>
      <author><first>Haoran</first><last>Zhang</last></author>
      <author><first>Luc</first><last>Paquette</last></author>
      <author><first>Rui</first><last>Zhang</last></author>
      <pages>7406-7421</pages>
      <abstract>In this paper, we explore the application of large language models (LLMs) for generating code-tracing questions in introductory programming courses. We designed targeted prompts for GPT4, guiding it to generate code-tracing questions based on code snippets and descriptions. We established a set of human evaluation metrics to assess the quality of questions produced by the model compared to those created by human experts. Our analysis provides insights into the capabilities and potential of LLMs in generating diverse code-tracing questions. Additionally, we present a unique dataset of human and LLM-generated tracing questions, serving as a valuable resource for both the education and NLP research communities. This work contributes to the ongoing dialogue on the potential uses of LLMs in educational settings.</abstract>
      <url hash="250c392a">2023.findings-emnlp.496</url>
      <bibkey>fan-etal-2023-exploring</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.496</doi>
    </paper>
    <paper id="497">
      <title>Learning Easily Updated General Purpose Text Representations with Adaptable Task-Specific Prefix</title>
      <author><first>Kuan-Hao</first><last>Huang</last></author>
      <author><first>Liang</first><last>Tan</last></author>
      <author><first>Rui</first><last>Hou</last></author>
      <author><first>Sinong</first><last>Wang</last></author>
      <author><first>Amjad</first><last>Almahairi</last></author>
      <author><first>Ruty</first><last>Rinott</last></author>
      <pages>7422-7430</pages>
      <abstract>Many real-world applications require making multiple predictions from the same text. Fine-tuning a large pre-trained language model for each downstream task causes computational burdens in the inference time due to several times of forward passes. To amortize the computational cost, freezing the language model and building lightweight models for downstream tasks based on fixed text representations are common solutions. Accordingly, how to learn fixed but general text representations that can generalize well to unseen downstream tasks becomes a challenge. Previous works have shown that the generalizability of representations can be improved by fine-tuning the pre-trained language model with some source tasks in a multi-tasking way. In this work, we propose a prefix-based method to learn the fixed text representations with source tasks. We learn a task-specific prefix for each source task independently and combine them to get the final representations. Our experimental results show that prefix-based training performs better than multi-tasking training and can update the text representations at a smaller computational cost than multi-tasking training.</abstract>
      <url hash="caec0b0f">2023.findings-emnlp.497</url>
      <bibkey>huang-etal-2023-learning-easily</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.497</doi>
    </paper>
    <paper id="498">
      <title>Good Meta-tasks Make A Better Cross-lingual Meta-transfer Learning for Low-resource Languages</title>
      <author><first>Linjuan</first><last>Wu</last></author>
      <author><first>Zongyi</first><last>Guo</last></author>
      <author><first>Baoliang</first><last>Cui</last></author>
      <author><first>Haihong</first><last>Tang</last></author>
      <author><first>Weiming</first><last>Lu</last></author>
      <pages>7431-7446</pages>
      <abstract>Model-agnostic meta-learning has garnered attention as a promising technique for enhancing few-shot cross-lingual transfer learning in low-resource scenarios. However, little attention was paid to the impact of data selection strategies on this cross-lingual meta-transfer method, particularly the sampling of cross-lingual meta-training data (i.e. meta-tasks) at the syntactic level to reduce language gaps. In this paper, we propose a Meta-Task Collector-based Cross-lingual Meta-Transfer framework (MeTaCo-XMT) to adapt different data selection strategies to construct meta-tasks for meta-transfer learning. Syntactic differences have an effect on transfer performance, so we consider a syntactic similarity sampling strategy and propose a syntactic distance metric model consisting of a syntactic encoder block based on the pre-trained model and a distance metric block using Word Move’s Distance (WMD). Additionally, we conduct experiments with three different data selection strategies to instantiate our framework and analyze their performance impact. Experimental results on two multilingual NLP datasets, Wikiann and TydiQA, demonstrate the significant superiority of our approach compared to existing strong baselines.</abstract>
      <url hash="43d1e470">2023.findings-emnlp.498</url>
      <bibkey>wu-etal-2023-good</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.498</doi>
    </paper>
    <paper id="499">
      <title>Reasoning Makes Good Annotators : An Automatic Task-specific Rules Distilling Framework for Low-resource Relation Extraction</title>
      <author><first>Yilin</first><last>Lu</last></author>
      <author><first>Juncheng</first><last>Li</last></author>
      <author><first>Xiaoqiang</first><last>Wang</last></author>
      <author><first>Haochen</first><last>Shi</last></author>
      <author><first>Tao</first><last>Chen</last></author>
      <author><first>Siliang</first><last>Tang</last></author>
      <pages>7447-7457</pages>
      <abstract>Relation extraction is often challenged by insufficient labeled data. Previous methods exploit knowledge from unlabeled data by generating pseudo labels in a self-training pipeline, which suffers a gradual drift problem. Logic rules, a transferable and explainable form of expert knowledge, have achieved promising success by improving the model with weak labels. But manually writing comprehensive rules set is challenging and tedious. To alleviate the human labor of writing high-quality rules, in this work, we propose ARIA, an Automatic task-specific Rules distilling framework. Specifically, we guide the pre-trained language model to reason rules as experts and compose them into robust compound rules for data labeling. Besides, ARIA could continuously enrich the rules set to power the labeling ability by discovering reliable model-labeled data for distinguishable rules generation. Experiments on two public datasets demonstrate the effectiveness of ARIA in a low-resource scenario.</abstract>
      <url hash="88307051">2023.findings-emnlp.499</url>
      <bibkey>lu-etal-2023-reasoning</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.499</doi>
    </paper>
    <paper id="500">
      <title>Co-training and Co-distillation for Quality Improvement and Compression of Language Models</title>
      <author><first>Hayeon</first><last>Lee</last></author>
      <author><first>Rui</first><last>Hou</last></author>
      <author><first>Jongpil</first><last>Kim</last></author>
      <author><first>Davis</first><last>Liang</last></author>
      <author><first>Hongbo</first><last>Zhang</last></author>
      <author><first>Sung</first><last>Hwang</last></author>
      <author><first>Alexander</first><last>Min</last></author>
      <pages>7458-7467</pages>
      <abstract>Knowledge Distillation (KD) compresses computationally expensive pre-trained language models (PLMs) by transferring their knowledge to smaller models, allowing their use in resource-constrained or real-time settings. However, most smaller models fail to surpass the performance of the original larger model, resulting in sacrificing performance to improve inference speed. To address this issue, we propose Co-Training and Co-Distillation (CTCD), a novel framework that improves performance and inference speed together by co-training two models while mutually distilling knowledge. The CTCD framework successfully achieves this based on two significant findings: 1) Distilling knowledge from the smaller model to the larger model during co-training improves the performance of the larger model. 2) The enhanced performance of the larger model further boosts the performance of the smaller model. The CTCD framework shows promise as it can be combined with existing techniques like architecture design or data augmentation, replacing one-way KD methods, to achieve further performance improvement. Extensive ablation studies demonstrate the effectiveness of CTCD, and the small model distilled by CTCD outperforms the original larger model by a significant margin of 1.66 on the GLUE benchmark.</abstract>
      <url hash="7762c326">2023.findings-emnlp.500</url>
      <bibkey>lee-etal-2023-co</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.500</doi>
    </paper>
    <paper id="501">
      <title><fixed-case>R</fixed-case>ead<fixed-case>P</fixed-case>rompt: A Readable Prompting Method for Reliable Knowledge Probing</title>
      <author><first>Zezhong</first><last>Wang</last></author>
      <author><first>Luyao</first><last>Ye</last></author>
      <author><first>Hongru</first><last>Wang</last></author>
      <author><first>Wai-Chung</first><last>Kwan</last></author>
      <author><first>David</first><last>Ho</last></author>
      <author><first>Kam-Fai</first><last>Wong</last></author>
      <pages>7468-7479</pages>
      <abstract>Knowledge probing is a task to assess the knowledge encoded within pre-trained language models (PLMs) by having the PLM complete prompts such as “Italy is located in __,”. The model’s prediction precision serves as a lower bound for the amount of knowledge it contains. Subsequent works explore training a series of vectors as prompts to guide PLMs towards more accurate predictions. However, these methods compromise the readability of the prompts. We cannot directly understand these prompts from their literal meaning, making it difficult to verify whether they are correct. Consequently, the credibility of probing results derived from these prompts is diminished. To address the issue, we propose a novel method called ReadPrompt, which aims to identify meaningful sentences to serve as prompts. Experiments show that ReadPrompt achieves state-of-the-art performance on the current knowledge probing benchmark. Moreover, since the prompt is readable, we discovered a misalignment between constructed prompts and knowledge, which is also present in current prompting methods verified by an attack experiment. We claim that the probing outcomes of the current prompting methods are unreliable that overestimate the knowledge contained within PLMs.</abstract>
      <url hash="5f48a99b">2023.findings-emnlp.501</url>
      <bibkey>wang-etal-2023-readprompt</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.501</doi>
    </paper>
    <paper id="502">
      <title>Coherent Entity Disambiguation via Modeling Topic and Categorical Dependency</title>
      <author><first>Zilin</first><last>Xiao</last></author>
      <author><first>Linjun</first><last>Shou</last></author>
      <author><first>Xingyao</first><last>Zhang</last></author>
      <author><first>Jie</first><last>Wu</last></author>
      <author><first>Ming</first><last>Gong</last></author>
      <author><first>Daxin</first><last>Jiang</last></author>
      <pages>7480-7492</pages>
      <abstract>Previous entity disambiguation (ED) methods adopt a discriminative paradigm, where prediction is made based on matching scores between mention context and candidate entities using length-limited encoders. However, these methods often struggle to capture explicit discourse-level dependencies, resulting in incoherent predictions at the abstract level (e.g. topic or category). We propose CoherentED, an ED system equipped with novel designs aimed at enhancing the coherence of entity predictions. Our method first introduces an unsupervised variational autoencoder (VAE) to extract latent topic vectors of context sentences. This approach not only allows the encoder to handle longer documents more effectively, conserves valuable input space, but also keeps a topic-level coherence. Additionally, we incorporate an external category memory, enabling the system to retrieve relevant categories for undecided mentions. By employing step-by-step entity decisions, this design facilitates the modeling of entity-entity interactions, thereby maintaining maximum coherence at the category level. We achieve new state-of-the-art results on popular ED benchmarks, with an average improvement of 1.3 F1 points. Our model demonstrates particularly outstanding performance on challenging long-text scenarios.</abstract>
      <url hash="49ca9e73">2023.findings-emnlp.502</url>
      <bibkey>xiao-etal-2023-coherent</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.502</doi>
    </paper>
    <paper id="503">
      <title>How Predictable Are Large Language Model Capabilities? A Case Study on <fixed-case>BIG</fixed-case>-bench</title>
      <author><first>Qinyuan</first><last>Ye</last></author>
      <author><first>Harvey</first><last>Fu</last></author>
      <author><first>Xiang</first><last>Ren</last></author>
      <author><first>Robin</first><last>Jia</last></author>
      <pages>7493-7517</pages>
      <abstract>We investigate the predictability of large language model (LLM) capabilities: given records of past experiments using different model families, numbers of parameters, tasks, and numbers of in-context examples, can we accurately predict LLM performance on new experiment configurations? Answering this question has practical implications for LLM users (e.g., deciding which models to try), developers (e.g., prioritizing evaluation on representative tasks), and the research community (e.g., identifying hard-to-predict capabilities that warrant further investigation). We study the performance prediction problem on experiment records from BIG-bench. On a random train-test split, an MLP-based predictor achieves an <tex-math>R^2</tex-math> score greater than 95%, indicating the presence of learnable patterns within the experiment records. We then formulate the problem of searching for “small-bench,” an informative subset of BIG-bench tasks from which the performance on the full set can be maximally recovered. We find a subset as informative as BIG-bench Hard for evaluating new model families, while being <tex-math>3\times</tex-math> smaller. Additionally, we find competitive subsets by clustering task representations learned by our MLP-based predictor and selecting tasks close to cluster centroids, highlighting the importance of task diversity in constructing “small-bench.”</abstract>
      <url hash="07fda26c">2023.findings-emnlp.503</url>
      <bibkey>ye-etal-2023-predictable</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.503</doi>
    </paper>
    <paper id="504">
      <title><fixed-case>POSQA</fixed-case>: Probe the World Models of <fixed-case>LLM</fixed-case>s with Size Comparisons</title>
      <author><first>Chang</first><last>Shu</last></author>
      <author><first>Jiuzhou</first><last>Han</last></author>
      <author><first>Fangyu</first><last>Liu</last></author>
      <author><first>Ehsan</first><last>Shareghi</last></author>
      <author><first>Nigel</first><last>Collier</last></author>
      <pages>7518-7531</pages>
      <abstract>Embodied language comprehension emphasizes that language understanding is not solely a matter of mental processing in the brain but also involves interactions with the physical and social environment. With the explosive growth of Large Language Models (LLMs) and their already ubiquitous presence in our daily lives, it is becoming increasingly necessary to verify their real-world understanding. Inspired by cognitive theories, we propose POSQA: a Physical Object Size Question Answering dataset with simple size comparison questions to examine the extremity and analyze the potential mechanisms of the embodied comprehension of the latest LLMs. We show that even the largest LLMs today perform poorly under the zero-shot setting. We then push their limits with advanced prompting techniques and external knowledge augmentation. Furthermore, we investigate whether their real-world comprehension primarily derives from contextual information or internal weights and analyse the impact of prompt formats and report bias of different objects. Our results show that real-world understanding that LLMs shaped from textual data can be vulnerable to deception and confusion by the surface form of prompts, which makes it less aligned with human behaviours.</abstract>
      <url hash="fc848765">2023.findings-emnlp.504</url>
      <bibkey>shu-etal-2023-posqa</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.504</doi>
    </paper>
    <paper id="505">
      <title>Hierarchical Fusion for Online Multimodal Dialog Act Classification</title>
      <author><first>Md Messal Monem</first><last>Miah</last></author>
      <author><first>Adarsh</first><last>Pyarelal</last></author>
      <author><first>Ruihong</first><last>Huang</last></author>
      <pages>7532-7545</pages>
      <abstract>We propose a framework for online multimodal dialog act (DA) classification based on raw audio and ASR-generated transcriptions of current and past utterances. Existing multimodal DA classification approaches are limited by ineffective audio modeling and late-stage fusion. We showcase significant improvements in multimodal DA classification by integrating modalities at a more granular level and incorporating recent advancements in large language and audio models for audio feature extraction. We further investigate the effectiveness of self-attention and cross-attention mechanisms in modeling utterances and dialogs for DA classification. We achieve a substantial increase of 3 percentage points in the F1 score relative to current state-of-the-art models on two prominent DA classification datasets, MRDA and EMOTyDA.</abstract>
      <url hash="60a1e81c">2023.findings-emnlp.505</url>
      <bibkey>miah-etal-2023-hierarchical</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.505</doi>
    </paper>
    <paper id="506">
      <title><fixed-case>STEER</fixed-case>: Unified Style Transfer with Expert Reinforcement</title>
      <author><first>Skyler</first><last>Hallinan</last></author>
      <author><first>Faeze</first><last>Brahman</last></author>
      <author><first>Ximing</first><last>Lu</last></author>
      <author><first>Jaehun</first><last>Jung</last></author>
      <author><first>Sean</first><last>Welleck</last></author>
      <author><first>Yejin</first><last>Choi</last></author>
      <pages>7546-7562</pages>
      <abstract>While text style transfer has many applications across natural language processing, the core premise of transferring from a single source style is unrealistic in a real-world setting. In this work, we focus on arbitrary style transfer: rewriting a text from an arbitrary, unknown style to a target style. We propose STEER: Unified Style Transfer with Expert Reinforcement, a unified frame-work developed to overcome the challenge of limited parallel data for style transfer. STEER involves automatically generating a corpus of style-transfer pairs using a product of experts during decoding. The generated offline data is then used to pre-train an initial policy before switching to online, off-policy reinforcement learning for further improvements via fine-grained reward signals. STEER is unified and can transfer to multiple target styles from an arbitrary, unknown source style, making it particularly flexible and efficient. Experimental results on a challenging dataset with text from a diverse set of styles demonstrate state-of-the-art results compared to competitive baselines. Remarkably, STEER outperforms the 175B parameter instruction-tuned GPT-3 on overall style transfer quality, despite being 226 times smaller in size. We also show STEER is robust, maintaining its style transfer capabilities on out-of-domain data, and surpassing nearly all baselines across various styles. The success of our method highlights the potential of RL algorithms when augmented with controllable decoding to overcome the challenge of limited data supervision.</abstract>
      <url hash="6f7bbec7">2023.findings-emnlp.506</url>
      <bibkey>hallinan-etal-2023-steer</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.506</doi>
    </paper>
    <paper id="507">
      <title>Enhancing Argument Structure Extraction with Efficient Leverage of Contextual Information</title>
      <author><first>Yun</first><last>Luo</last></author>
      <author><first>Zhen</first><last>Yang</last></author>
      <author><first>Fandong</first><last>Meng</last></author>
      <author><first>Yingjie</first><last>Li</last></author>
      <author><first>Jie</first><last>Zhou</last></author>
      <author><first>Yue</first><last>Zhang</last></author>
      <pages>7563-7571</pages>
      <abstract>Argument structure extraction (ASE) aims to identify the discourse structure of arguments within documents. Previous research has demonstrated that contextual information is crucial for developing an effective ASE model. However, we observe that merely concatenating sentences in a contextual window does not fully utilize contextual information and can sometimes lead to excessive attention on less informative sentences. To tackle this challenge, we propose an Efficient Context-aware ASE model (ECASE) that fully exploits contextual information by enhancing modeling capacity and augmenting training data. Specifically, we introduce a sequence-attention module and distance-weighted similarity loss to aggregate contextual information and argumentative information. Additionally, we augment the training data by randomly masking discourse markers and sentences, which reduces the model’s reliance on specific words or less informative sentences. Our experiments on five datasets from various domains demonstrate that our model achieves state-of-the-art performance. Furthermore, ablation studies confirm the effectiveness of each module in our model.</abstract>
      <url hash="e6cd19b6">2023.findings-emnlp.507</url>
      <bibkey>luo-etal-2023-enhancing</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.507</doi>
    </paper>
    <paper id="508">
      <title>Examining Inter-Consistency of Large Language Models Collaboration: An In-depth Analysis via Debate</title>
      <author><first>Kai</first><last>Xiong</last></author>
      <author><first>Xiao</first><last>Ding</last></author>
      <author><first>Yixin</first><last>Cao</last></author>
      <author><first>Ting</first><last>Liu</last></author>
      <author><first>Bing</first><last>Qin</last></author>
      <pages>7572-7590</pages>
      <abstract>Large Language Models (LLMs) have shown impressive capabilities in various applications, but they still face various inconsistency issues. Existing works primarily focus on the inconsistency issues within a single LLM, while we complementarily explore the inter-consistency among multiple LLMs for collaboration. To examine whether LLMs can collaborate effectively to achieve a consensus for a shared goal, we focus on commonsense reasoning, and introduce a formal debate framework (FORD) to conduct a three-stage debate among LLMs with real-world scenarios alignment: fair debate, mismatched debate, and roundtable debate. Through extensive experiments on various datasets, LLMs can effectively collaborate to reach a consensus despite noticeable inter-inconsistencies, but imbalances in their abilities can lead to domination by superior LLMs. Leveraging a more advanced LLM like GPT-4 as an authoritative judge can boost collaboration performance. Our work contributes to understanding the inter-consistency among LLMs and lays the foundation for developing future collaboration methods. Codes and data are available at https://github.com/Waste-Wood/FORD.</abstract>
      <url hash="53bd1090">2023.findings-emnlp.508</url>
      <bibkey>xiong-etal-2023-examining</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.508</doi>
    </paper>
    <paper id="509">
      <title>Culturally Aware Natural Language Inference</title>
      <author><first>Jing</first><last>Huang</last></author>
      <author><first>Diyi</first><last>Yang</last></author>
      <pages>7591-7609</pages>
      <abstract>Humans produce and consume language in a particular cultural context, which includes knowledge about specific norms and practices. A listener’s awareness of the cultural context is critical for interpreting the speaker’s meaning. A simple expression like *I didn’t leave a tip* implies a strong sense of dissatisfaction when tipping is assumed to be the norm. As NLP systems reach users from different cultures, achieving culturally aware language understanding becomes increasingly important. However, current research has focused on building cultural knowledge bases without studying how such knowledge leads to contextualized interpretations of texts. In this work, we operationalize cultural variations in language understanding through a natural language inference (NLI) task that surfaces cultural variations as label disagreement between annotators from different cultural groups. We introduce the first Culturally Aware Natural Language Inference (CALI) dataset with 2.7K premise-hypothesis pairs annotated by two cultural groups located in the U.S. and India. With CALI, we categorize how cultural norms affect language understanding and present an evaluation framework to assess at which levels large language models are culturally aware. Our dataset is available at https://github.com/SALT-NLP/CulturallyAwareNLI.</abstract>
      <url hash="94779fc2">2023.findings-emnlp.509</url>
      <bibkey>huang-yang-2023-culturally</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.509</doi>
    </paper>
    <paper id="510">
      <title>End-to-End Autoregressive Retrieval via Bootstrapping for Smart Reply Systems</title>
      <author><first>Benjamin</first><last>Towle</last></author>
      <author><first>Ke</first><last>Zhou</last></author>
      <pages>7610-7622</pages>
      <abstract>Reply suggestion systems represent a staple component of many instant messaging and email systems. However, the requirement to produce sets of replies, rather than individual replies, makes the task poorly suited for out-of-the-box retrieval architectures, which only consider individual message-reply similarity. As a result, these system often rely on additional post-processing modules to diversify the outputs. However, these approaches are ultimately bottlenecked by the performance of the initial retriever, which in practice struggles to present a sufficiently diverse range of options to the downstream diversification module, leading to the suggestions being less relevant to the user. In this paper, we consider a novel approach that radically simplifies this pipeline through an autoregressive text-to-text retrieval model, that learns the smart reply task end-to-end from a dataset of (message, reply set) pairs obtained via bootstrapping. Empirical results show this method consistently outperforms a range of state-of-the-art baselines across three datasets, corresponding to a 5.1%-17.9% improvement in relevance, and a 0.5%-63.1% improvement in diversity compared to the best baseline approach. We make our code publicly available.</abstract>
      <url hash="3b9808ac">2023.findings-emnlp.510</url>
      <bibkey>towle-zhou-2023-end</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.510</doi>
    </paper>
    <paper id="511">
      <title>Evaluating Dependencies in Fact Editing for Language Models: Specificity and Implication Awareness</title>
      <author><first>Zichao</first><last>Li</last></author>
      <author><first>Ines</first><last>Arous</last></author>
      <author><first>Siva</first><last>Reddy</last></author>
      <author><first>Jackie</first><last>Cheung</last></author>
      <pages>7623-7636</pages>
      <abstract>The potential of using a large language model (LLM) as a knowledge base (KB) has sparked significant interest. To maintain the knowledge acquired by LLMs, we need to ensure that the editing of learned facts respects internal logical constraints, which are known as dependency of knowledge. Existing work on editing LLMs has partially addressed the issue of dependency, when the editing of a fact should apply to its lexical variations without disrupting irrelevant ones. However, they neglect the dependency between a fact and its logical implications. We propose an evaluation protocol with an accompanying question-answering dataset, StandUp, that provides a comprehensive assessment of the editing process considering the above notions of dependency. Our protocol involves setting up a controlled environment in which we edit facts and monitor their impact on LLMs, along with their implications based on If-Then rules. Extensive experiments on StandUp show that existing knowledge editing methods are sensitive to the surface form of knowledge, and that they have limited performance in inferring the implications of edited facts.</abstract>
      <url hash="0ce0035f">2023.findings-emnlp.511</url>
      <bibkey>li-etal-2023-evaluating-dependencies</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.511</doi>
    </paper>
    <paper id="512">
      <title>Effects of Human Adversarial and Affable Samples on <fixed-case>BERT</fixed-case> Generalization</title>
      <author><first>Aparna</first><last>Elangovan</last></author>
      <author><first>Estrid</first><last>He</last></author>
      <author><first>Yuan</first><last>Li</last></author>
      <author><first>Karin</first><last>Verspoor</last></author>
      <pages>7637-7649</pages>
      <abstract>BERT-based models have had strong performance on leaderboards, yet have been demonstrably worse in real-world settings requiring generalization. Limited quantities of training data is considered a key impediment to achieving generalizability in machine learning. In this paper, we examine the impact of training data quality, not quantity, on a model’s generalizability. We consider two characteristics of training data: the portion of human-adversarial (h-adversarial), i.e. sample pairs with seemingly minor differences but different ground-truth labels, and human-affable (h-affable) training samples, i.e. sample pairs with minor differences but the same ground-truth label. We find that for a fixed size of training samples, as a rule of thumb, having 10-30% h-adversarial instances improves the precision, and therefore F1, by up to 20 points in the tasks of text classification and relation extraction. Increasing h-adversarials beyond this range can result in performance plateaus or even degradation. In contrast, h-affables may not contribute to a model’s generalizability and may even degrade generalization performance.</abstract>
      <url hash="a1402183">2023.findings-emnlp.512</url>
      <bibkey>elangovan-etal-2023-effects</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.512</doi>
    </paper>
    <paper id="513">
      <title>Logic Unveils Truth, While Disguise Obscures It: Transition Logic Augmented Response Selection for Multi-Turn Dialogue</title>
      <author><first>Tingchen</first><last>Fu</last></author>
      <author><first>Xueliang</first><last>Zhao</last></author>
      <author><first>Lemao</first><last>Liu</last></author>
      <author><first>Rui</first><last>Yan</last></author>
      <pages>7650-7661</pages>
      <abstract>Multi-turn response selection aims to retrieve a response for a dialogue context from a candidate pool and negative sampling is the key to its retrieval performance. However, previous methods of negative samples tend to yield false negatives due to the one-to-many property in open-domain dialogue, which is detrimental to the optimization process. To deal with the problem, we propose a sequential variational ladder auto-encoder to capture the diverse one-to-many transition pattern of multiple characteristics in open-domain dialogue. The learned transition logic thus assists in identifying potential positives in disguise. Meanwhile, we propose a TRIGGER framework to adjust negative sampling in the training process such that the scope of false negatives dynamically updates according to the model capacity. Extensive experiments on two benchmarks verify the effectiveness of our approach.</abstract>
      <url hash="3df46388">2023.findings-emnlp.513</url>
      <bibkey>fu-etal-2023-logic</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.513</doi>
    </paper>
    <paper id="514">
      <title>Are Language Models Worse than Humans at Following Prompts? It’s Complicated</title>
      <author><first>Albert</first><last>Webson</last></author>
      <author><first>Alyssa</first><last>Loo</last></author>
      <author><first>Qinan</first><last>Yu</last></author>
      <author><first>Ellie</first><last>Pavlick</last></author>
      <pages>7662-7686</pages>
      <abstract>Prompts have been the center of progress in advancing language models’ zero-shot and few-shot performance. However, recent work finds that models can perform surprisingly well when given intentionally irrelevant or misleading prompts. Such results may be interpreted as evidence that model behavior is not “human like’. In this study, we challenge a central assumption in such work: that humans would perform badly when given pathological instructions. We find that humans are able to reliably ignore irrelevant instructions and thus, like models, perform well on the underlying task despite an apparent lack of signal regarding the task they are being asked to do. However, when given deliberately misleading instructions, humans follow the instructions faithfully, whereas models do not. Thus, our conclusion is mixed with respect to prior work. We argue against the earlier claim that high performance with irrelevant prompts constitutes evidence against models’ instruction understanding, but we reinforce the claim that models’ failure to follow misleading instructions raises concerns. More broadly, we caution that future research should not idealize human behaviors as a monolith and should not train or evaluate models to mimic assumptions about these behaviors without first validating humans’ behaviors empirically.</abstract>
      <url hash="98f1c63e">2023.findings-emnlp.514</url>
      <bibkey>webson-etal-2023-language</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.514</doi>
    </paper>
    <paper id="515">
      <title>A Sequence-to-Structure Approach to Document-level Targeted Sentiment Analysis</title>
      <author><first>Nan</first><last>Song</last></author>
      <author><first>Hongjie</first><last>Cai</last></author>
      <author><first>Rui</first><last>Xia</last></author>
      <author><first>Jianfei</first><last>Yu</last></author>
      <author><first>Zhen</first><last>Wu</last></author>
      <author><first>Xinyu</first><last>Dai</last></author>
      <pages>7687-7698</pages>
      <abstract>Most previous studies on aspect-based sentiment analysis (ABSA) were carried out at the sentence level, while the research of document-level ABSA has not received enough attention. In this work, we focus on the document-level targeted sentiment analysis task, which aims to extract the opinion targets consisting of multi-level entities from a review document and predict their sentiments. We propose a Sequence-to-Structure (Seq2Struct) approach to address the task, which is able to explicitly model the hierarchical structure among multiple opinion targets in a document, and capture the long-distance dependencies among affiliated entities across sentences. In addition to the existing Seq2Seq approach, we further construct four strong baselines with different pretrained models. Experimental results on six domains show that our Seq2Struct approach outperforms all the baselines significantly. Aside from the performance advantage in outputting the multi-level target-sentiment pairs, our approach has another significant advantage - it can explicitly display the hierarchical structure of the opinion targets within a document. Our source code is publicly released at https://github.com/NUSTM/Doc-TSA-Seq2Struct.</abstract>
      <url hash="13ee7d71">2023.findings-emnlp.515</url>
      <bibkey>song-etal-2023-sequence</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.515</doi>
    </paper>
    <paper id="516">
      <title>Generating Extractive Answers: Gated Recurrent Memory Reader for Conversational Question Answering</title>
      <author><first>Xuanyu</first><last>Zhang</last></author>
      <author><first>Qing</first><last>Yang</last></author>
      <pages>7699-7704</pages>
      <abstract>Conversational question answering (CQA) is a more complicated task than traditional single-turn machine reading comprehension (MRC). Different from large language models (LLMs) like ChatGPT, the models of CQA need to extract answers from given contents to answer follow-up questions according to conversation history. In this paper, we propose a novel architecture, i.e., Gated Recurrent Memory Reader (GRMR), which integrates traditional extractive MRC models into a generalized sequence-to-sequence framework. After the passage is encoded, the decoder will generate the extractive answers turn by turn. Different from previous models that concatenate the previous questions and answers as context superficially and redundantly, our model can use less storage space and consider historical memory deeply and selectively. Experiments on the Conversational Question Answering (CoQA) dataset show that our model achieves comparable results to most models with the least space occupancy.</abstract>
      <url hash="4ad5e239">2023.findings-emnlp.516</url>
      <bibkey>zhang-yang-2023-generating</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.516</doi>
    </paper>
    <paper id="517">
      <title><fixed-case>T</fixed-case>ext2<fixed-case>T</fixed-case>ree: Aligning Text Representation to the Label Tree Hierarchy for Imbalanced Medical Classification</title>
      <author><first>Jiahuan</first><last>Yan</last></author>
      <author><first>Haojun</first><last>Gao</last></author>
      <author><first>Zhang</first><last>Kai</last></author>
      <author><first>Weize</first><last>Liu</last></author>
      <author><first>Danny</first><last>Chen</last></author>
      <author><first>Jian</first><last>Wu</last></author>
      <author><first>Jintai</first><last>Chen</last></author>
      <pages>7705-7720</pages>
      <abstract>Deep learning approaches exhibit promising performances on various text tasks. However, they are still struggling on medical text classification since samples are often extremely imbalanced and scarce. Different from existing mainstream approaches that focus on supplementary semantics with external medical information, this paper aims to rethink the data challenges in medical texts and present a novel framework-agnostic algorithm called Text2Tree that only utilizes internal label hierarchy in training deep learning models. We embed the ICD code tree structure of labels into cascade attention modules for learning hierarchy-aware label representations. Two new learning schemes, Similarity Surrogate Learning (SSL) and Dissimilarity Mixup Learning (DML), are devised to boost text classification by reusing and distinguishing samples of other labels following the label representation hierarchy, respectively. Experiments on authoritative public datasets and real-world medical records show that our approach stably achieves superior performances over classical and advanced imbalanced classification methods. Our code is available at https://github.com/jyansir/Text2Tree.</abstract>
      <url hash="b381e217">2023.findings-emnlp.517</url>
      <bibkey>yan-etal-2023-text2tree</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.517</doi>
    </paper>
    <paper id="518">
      <title>Impact of Co-occurrence on Factual Knowledge of Large Language Models</title>
      <author><first>Cheongwoong</first><last>Kang</last></author>
      <author><first>Jaesik</first><last>Choi</last></author>
      <pages>7721-7735</pages>
      <abstract>Large language models (LLMs) often make factually incorrect responses despite their success in various applications. In this paper, we hypothesize that relying heavily on simple co-occurrence statistics of the pre-training corpora is one of the main factors that cause factual errors. Our results reveal that LLMs are vulnerable to the co-occurrence bias, defined as preferring frequently co-occurred words over the correct answer. Consequently, LLMs struggle to recall facts whose subject and object rarely co-occur in the pre-training dataset although they are seen during finetuning. We show that co-occurrence bias remains despite scaling up model sizes or finetuning. Therefore, we suggest finetuning on a debiased dataset to mitigate the bias by filtering out biased samples whose subject-object co-occurrence count is high. Although debiased finetuning allows LLMs to memorize rare facts in the training set, it is not effective in recalling rare facts unseen during finetuning. Further research in mitigation will help build reliable language models by preventing potential errors. The code is available at https://github.com/CheongWoong/impact_of_cooccurrence.</abstract>
      <url hash="83384fe6">2023.findings-emnlp.518</url>
      <bibkey>kang-choi-2023-impact</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.518</doi>
    </paper>
    <paper id="519">
      <title><fixed-case>CTQS</fixed-case>corer: Combining Multiple Features for In-context Example Selection for Machine Translation</title>
      <author><first>Aswanth</first><last>M</last></author>
      <author><first>Ratish</first><last>Puduppully</last></author>
      <author><first>Raj</first><last>Dabre</last></author>
      <author><first>Anoop</first><last>Kunchukuttan</last></author>
      <pages>7736-7752</pages>
      <abstract>Large language models have demonstrated the capability to perform on machine translation when the input is prompted with a few examples (in-context learning). Translation quality depends on various features of the selected examples, such as their quality and relevance, but previous work has predominantly focused on individual features in isolation. In this paper, we propose a general framework for combining different features influencing example selection. We learn a regression model, CTQ Scorer (Contextual Translation Quality), that selects examples based on multiple features in order to maximize the translation quality. On multiple language pairs and language models, we show that CTQ Scorer helps significantly outperform random selection as well as strong single-factor baselines reported in the literature. We also see an improvement of over 2.5 COMET points on average with respect to a strong BM25 retrieval-based baseline.</abstract>
      <url hash="eaac4288">2023.findings-emnlp.519</url>
      <bibkey>m-etal-2023-ctqscorer</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.519</doi>
    </paper>
    <paper id="520">
      <title>Swap and Predict – Predicting the Semantic Changes in Words across Corpora by Context Swapping</title>
      <author><first>Taichi</first><last>Aida</last></author>
      <author><first>Danushka</first><last>Bollegala</last></author>
      <pages>7753-7772</pages>
      <abstract>Meanings of words change over time and across domains. Detecting the semantic changes of words is an important task for various NLP applications that must make time-sensitive predictions. We consider the problem of predicting whether a given target word, <tex-math>w</tex-math>, changes its meaning between two different text corpora, <tex-math>\mathcal{C}_1</tex-math> and <tex-math>\mathcal{C}_2</tex-math>. For this purpose, we propose <tex-math>\textit{Swapping-based Semantic Change Detection}</tex-math> (SSCD), an unsupervised method that randomly swaps contexts between <tex-math>\mathcal{C}_1</tex-math> and <tex-math>\mathcal{C}_2</tex-math> where <tex-math>w</tex-math> occurs. We then look at the distribution of contextualised word embeddings of <tex-math>w</tex-math>, obtained from a pretrained masked language model (MLM), representing the meaning of <tex-math>w</tex-math> in its occurrence contexts in <tex-math>\mathcal{C}_1</tex-math> and <tex-math>\mathcal{C}_2</tex-math>. Intuitively, if the meaning of <tex-math>w</tex-math> does not change between <tex-math>\mathcal{C}_1</tex-math> and <tex-math>\mathcal{C}_2</tex-math>, we would expect the distributions of contextualised word embeddings of <tex-math>w</tex-math> to remain the same before and after this random swapping process. Despite its simplicity, we demonstrate that even by using pretrained MLMs without any fine-tuning, our proposed context swapping method accurately predicts the semantic changes of words in four languages (English, German, Swedish, and Latin) and across different time spans (over 50 years and about five years). Moreover, our method achieves significant performance improvements compared to strong baselines for the English semantic change prediction task. Source code is available at https://github.com/a1da4/svp-swap .</abstract>
      <url hash="50b4cadb">2023.findings-emnlp.520</url>
      <bibkey>aida-bollegala-2023-swap</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.520</doi>
    </paper>
    <paper id="521">
      <title>Beyond Layout Embedding: Layout Attention with <fixed-case>G</fixed-case>aussian Biases for Structured Document Understanding</title>
      <author><first>Xi</first><last>Zhu</last></author>
      <author><first>Xue</first><last>Han</last></author>
      <author><first>Shuyuan</first><last>Peng</last></author>
      <author><first>Shuo</first><last>Lei</last></author>
      <author><first>Chao</first><last>Deng</last></author>
      <author><first>Junlan</first><last>Feng</last></author>
      <pages>7773-7784</pages>
      <abstract>Effectively encoding layout information is a central problem in structured document understanding. Most existing methods rely heavily on millions of trainable parameters to learn the layout features of each word from Cartesian coordinates. However, two unresolved questions remain: (1) Is the Cartesian coordinate system the optimal choice for layout modeling? (2) Are massive learnable parameters truly necessary for layout representation? In this paper, we address these questions by proposing Layout Attention with Gaussian Biases (LAGaBi): Firstly, we find that polar coordinates provide a superior choice over Cartesian coordinates as they offer a measurement of both distance and angle between word pairs, capturing relative positions more effectively. Furthermore, by feeding the distances and angles into 2-D Gaussian kernels, we model intuitive inductive layout biases, i.e., the words closer within a document should receive more attention, which will act as the attention biases to revise the textual attention distribution. LAGaBi is model-agnostic and language-independent, which can be applied to a range of transformer-based models, such as the text pre-training models from the BERT series and the LayoutLM series that incorporate visual features. Experimental results on three widely used benchmarks demonstrate that, despite reducing the number of layout parameters from millions to 48, LAGaBi achieves competitive or even superior performance.</abstract>
      <url hash="26713624">2023.findings-emnlp.521</url>
      <bibkey>zhu-etal-2023-beyond-layout</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.521</doi>
    </paper>
    <paper id="522">
      <title><fixed-case>ESPVR</fixed-case>: Entity Spans Position Visual Regions for Multimodal Named Entity Recognition</title>
      <author><first>Xiujiao</first><last>Li</last></author>
      <author><first>Guanglu</first><last>Sun</last></author>
      <author><first>Xinyu</first><last>Liu</last></author>
      <pages>7785-7794</pages>
      <abstract>Multimodal Named Entity Recognition (MNER) uses visual information to improve the performance of text-only Named Entity Recognition (NER). However, existing methods for acquiring local visual information suffer from certain limitations: (1) using an attention-based method to extract visual regions related to the text from visual regions obtained through convolutional architectures (e.g., ResNet), attention is distracted by the entire image, rather than being fully focused on the visual regions most relevant to the text; (2) using an object detection-based (e.g., Mask R-CNN) method to detect visual object regions related to the text, object detection has a limited range of recognition categories. Moreover, the visual regions obtained by object detection may not correspond to the entities in the text. In summary, the goal of these methods is not to extract the most relevant visual regions for the entities in the text. The visual regions obtained by these methods may be redundant or insufficient for the entities in the text. In this paper, we propose an Entity Spans Position Visual Regions (ESPVR) module to obtain the most relevant visual regions corresponding to the entities in the text. Experiments show that our proposed approach can achieve the SOTA on Twitter-2017 and competitive results on Twitter-2015.</abstract>
      <url hash="8bbc759a">2023.findings-emnlp.522</url>
      <bibkey>li-etal-2023-espvr</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.522</doi>
    </paper>
    <paper id="523">
      <title>Flatness-Aware Prompt Selection Improves Accuracy and Sample Efficiency</title>
      <author><first>Lingfeng</first><last>Shen</last></author>
      <author><first>Weiting</first><last>Tan</last></author>
      <author><first>Boyuan</first><last>Zheng</last></author>
      <author><first>Daniel</first><last>Khashabi</last></author>
      <pages>7795-7817</pages>
      <abstract>With growing capabilities of large language models, prompting them has become the dominant way to access them. This has motivated the development of strategies for automatically selecting effective language prompts. In this paper, we introduce **pFlat** (prompt flatness), a new metric to quantify the expected utility of a language prompt. This metric is inspired by *flatness* regularization in statistical learning that quantifies the robustness of the model towards its parameter perturbations. We provide theoretical foundations for this metric and its relationship with other prompt selection metrics, providing a comprehensive understanding of existing methods. Empirically, we show that combining **pFlat** with existing metrics improves both performance and sample efficiency. Our metric outperforms the previous prompt selection metrics with an average increase of 10% in Pearson correlation across 6 classification benchmarks, and the prompt selected by our metric gains 5% higher accuracy than previous metrics across the benchmarks.</abstract>
      <url hash="41efc51b">2023.findings-emnlp.523</url>
      <bibkey>shen-etal-2023-flatness</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.523</doi>
    </paper>
    <paper id="524">
      <title>Detecting Erroneously Recognized Handwritten Byzantine Text</title>
      <author><first>John</first><last>Pavlopoulos</last></author>
      <author><first>Vasiliki</first><last>Kougia</last></author>
      <author><first>Paraskevi</first><last>Platanou</last></author>
      <author><first>Holger</first><last>Essler</last></author>
      <pages>7818-7828</pages>
      <abstract>Handwritten text recognition (HTR) yields textual output that comprises errors, which are considerably more compared to that of recognised printed (OCRed) text. Post-correcting methods can eliminate such errors but may also introduce errors. In this study, we investigate the issues arising from this reality in Byzantine Greek. We investigate the properties of the texts that lead post-correction systems to this adversarial behaviour and we experiment with text classification systems that learn to detect incorrect recognition output. A large masked language model, pre-trained in modern and fine-tuned in Byzantine Greek, achieves an Average Precision score of 95%. The score improves to 97% when using a model that is pre-trained in modern and then in ancient Greek, the two language forms Byzantine Greek combines elements from. A century-based analysis shows that the advantage of the classifier that is further-pre-trained in ancient Greek concerns texts of older centuries. The application of this classifier before a neural post-corrector on HTRed text reduced significantly the post-correction mistakes.</abstract>
      <url hash="df4b3b49">2023.findings-emnlp.524</url>
      <bibkey>pavlopoulos-etal-2023-detecting</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.524</doi>
    </paper>
    <paper id="525">
      <title>Improving Factual Consistency for Knowledge-Grounded Dialogue Systems via Knowledge Enhancement and Alignment</title>
      <author><first>Boyang</first><last>Xue</last></author>
      <author><first>Weichao</first><last>Wang</last></author>
      <author><first>Hongru</first><last>Wang</last></author>
      <author><first>Fei</first><last>Mi</last></author>
      <author><first>Rui</first><last>Wang</last></author>
      <author><first>Yasheng</first><last>Wang</last></author>
      <author><first>Lifeng</first><last>Shang</last></author>
      <author><first>Xin</first><last>Jiang</last></author>
      <author><first>Qun</first><last>Liu</last></author>
      <author><first>Kam-Fai</first><last>Wong</last></author>
      <pages>7829-7844</pages>
      <abstract>Pretrained language models (PLMs) based knowledge-grounded dialogue systems are prone to generate responses that are factually inconsistent with the provided knowledge source. In such inconsistent responses, the dialogue models fail to accurately express the external factual knowledge they rely upon. Inspired by previous work which identified that feedforward networks (FFNs) within Transformers are responsible for factual knowledge expressions, we investigate two methods to efficiently improve the factual expression capability of FFNs by knowledge enhancement and alignment respectively. We first propose K-Dial, which explicitly introduces extended FFNs in Transformers to enhance factual knowledge expressions given the specific patterns of knowledge-grounded dialogue inputs. Additionally, we apply the reinforcement learning for factual consistency (RLFC) method to implicitly adjust FFNs’ expressions in responses by aligning with gold knowledge for the factual consistency preference. To comprehensively assess the factual consistency and dialogue quality of responses, we employ extensive automatic measures and human evaluations including sophisticated fine-grained NLI-based metrics. Experimental results on WoW and CMU_DoG datasets demonstrate that our methods efficiently enhance the ability of the FFN module to convey factual knowledge, validating the efficacy of improving factual consistency for knowledge-grounded dialogue systems.</abstract>
      <url hash="fca9ba8c">2023.findings-emnlp.525</url>
      <bibkey>xue-etal-2023-improving</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.525</doi>
    </paper>
    <paper id="526">
      <title><fixed-case>TRIP</fixed-case>: Accelerating Document-level Multilingual Pre-training via Triangular Document-level Pre-training on Parallel Data Triplets</title>
      <author><first>Hongyuan</first><last>Lu</last></author>
      <author><first>Haoyang</first><last>Huang</last></author>
      <author><first>Shuming</first><last>Ma</last></author>
      <author><first>Dongdong</first><last>Zhang</last></author>
      <author><first>Wai</first><last>Lam</last></author>
      <author><first>Zhaochuan</first><last>Gao</last></author>
      <author><first>Anthony</first><last>Aue</last></author>
      <author><first>Arul</first><last>Menezes</last></author>
      <author><first>Furu</first><last>Wei</last></author>
      <pages>7845-7858</pages>
      <abstract>Despite the success of multilingual sequence-to-sequence pre-training, most existing approaches rely on document-level monolingual corpora in many different languages, sentence-level bilingual corpora, and sometimes synthetic document-level bilingual corpora. This hampers the performance with cross-lingual document-level tasks such as document-level translation. Hence, we propose to mine and leverage document-level trilingual parallel corpora to improve sequence-to-sequence multilingual pre-training. We present <b>Tri</b>angular Document-level <b>P</b>re-training (<b>TRIP</b>) as the first in the field to accelerate the conventional monolingual and bilingual objectives into a trilingual objective with a novel method called Grafting. Experiments show that TRIP achieves several strong state-of-the-art (SOTA) scores on three multilingual document-level machine translation benchmarks and one cross-lingual abstractive summarization benchmark, including consistent improvements by up to 3.11 d-BLEU points and 8.9 ROUGE-L points.</abstract>
      <url hash="cc5875bc">2023.findings-emnlp.526</url>
      <bibkey>lu-etal-2023-trip</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.526</doi>
    </paper>
    <paper id="527">
      <title>Frequency Balanced Datasets Lead to Better Language Models</title>
      <author><first>Rodolfo</first><last>Zevallos</last></author>
      <author><first>Mireia</first><last>Farrús</last></author>
      <author><first>Núria</first><last>Bel</last></author>
      <pages>7859-7872</pages>
      <abstract>This paper reports on the experiments aimed to improve our understanding of the role of the amount of data required for training attention-based transformer language models. Specifically, we investigate the impact of reducing the immense amounts of required pre-training data through sampling strategies that identify and reduce high-frequency tokens as different studies have indicated that the existence of very high-frequency tokens in pre-training data might bias learning, causing undesired effects. In this light, we describe our sampling algorithm that iteratively assesses token frequencies and removes sentences that contain still high-frequency tokens, eventually delivering a balanced, linguistically correct dataset. We evaluate the results in terms of model perplexity and fine-tuning linguistic probing tasks, NLP downstream tasks as well as more semantic SuperGlue tasks. The results show that pre-training with the resulting balanced dataset allows reducing up to three times the pre-training data.</abstract>
      <url hash="da139af9">2023.findings-emnlp.527</url>
      <bibkey>zevallos-etal-2023-frequency</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.527</doi>
    </paper>
    <paper id="528">
      <title>Uncertainty-aware Parameter-Efficient Self-training for Semi-supervised Language Understanding</title>
      <author><first>Jianing</first><last>Wang</last></author>
      <author><first>Qiushi</first><last>Sun</last></author>
      <author><first>Nuo</first><last>Chen</last></author>
      <author><first>Chengyu</first><last>Wang</last></author>
      <author><first>Jun</first><last>Huang</last></author>
      <author><first>Ming</first><last>Gao</last></author>
      <author><first>Xiang</first><last>Li</last></author>
      <pages>7873-7884</pages>
      <abstract>The recent success of large pre-trained language models (PLMs) heavily hinges on massive labeled data, which typically produces inferior performance in low-resource scenarios. To remedy this dilemma, we study self-training as one of the predominant semi-supervised learning (SSL) approaches, which utilizes large-scale unlabeled data to generate synthetic examples. However, too many noisy labels will hurt the model performance, and the self-training procedure requires multiple training iterations making it more expensive if all the model parameters of the PLM are updated. This paper presents UPET, a novel Uncertainty-aware Parameter-Efficient self-Training framework to effectively and efficiently address the labeled data scarcity issue. Specifically, we incorporate Monte Carlo (MC) dropout in Bayesian neural network (BNN) to perform uncertainty estimation for the teacher model and then judiciously select reliable pseudo-labeled examples based on confidence and certainty. During the student training, we introduce multiple parameter-efficient learning (PEL) paradigms that allow optimizes only a small percentage of parameters. We also propose a novel Easy-Hard Contrastive Tuning to enhance the robustness and generalization. Extensive experiments over multiple downstream tasks demonstrate that UPET achieves a substantial improvement in terms of performance and efficiency. Our codes and data are released at https: //github.com/wjn1996/UPET.</abstract>
      <url hash="fbdbb005">2023.findings-emnlp.528</url>
      <bibkey>wang-etal-2023-uncertainty</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.528</doi>
    </paper>
    <paper id="529">
      <title><fixed-case>TR</fixed-case>-Rules: Rule-based Model for Link Forecasting on Temporal Knowledge Graph Considering Temporal Redundancy</title>
      <author><first>Ningyuan</first><last>Li</last></author>
      <author><first>Haihong</first><last>E</last></author>
      <author><first>Shi</first><last>Li</last></author>
      <author><first>Mingzhi</first><last>Sun</last></author>
      <author><first>Tianyu</first><last>Yao</last></author>
      <author><first>Meina</first><last>Song</last></author>
      <author><first>Yong</first><last>Wang</last></author>
      <author><first>Haoran</first><last>Luo</last></author>
      <pages>7885-7894</pages>
      <abstract>Temporal knowledge graph (TKG) has been proved to be an effective way for modeling dynamic facts in real world. Many efforts have been devoted into predicting future events i.e. extrapolation, on TKGs. Recently, rule-based knowledge graph completion methods which are considered to be more interpretable than embedding-based methods, have been transferred to temporal knowledge graph extrapolation. However, rule-based models suffer from temporal redundancy when leveraged under dynamic settings, which results in inaccurate rule confidence calculation. In this paper, we define the problem of temporal redundancy and propose TR-Rules which solves the temporal redundancy issues through a simple but effective strategy. Besides, to capture more information lurking in TKGs, apart from cyclic rules, TR-Rules also mines and properly leverages acyclic rules, which has not been explored by existing models. Experimental results on three benchmarks show that TR-Rules achieves state-of-the-art performance. Ablation study shows the impact of temporal redundancy and demonstrates the performance of acyclic rules is much more promising due to its higher sensitivity to the number of sampled walks during learning stage.</abstract>
      <url hash="e3cfadb2">2023.findings-emnlp.529</url>
      <bibkey>li-etal-2023-tr</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.529</doi>
    </paper>
    <paper id="530">
      <title>On the Transferability of Visually Grounded <fixed-case>PCFG</fixed-case>s</title>
      <author><first>Yanpeng</first><last>Zhao</last></author>
      <author><first>Ivan</first><last>Titov</last></author>
      <pages>7895-7910</pages>
      <abstract>There has been a significant surge of interest in visually grounded grammar induction in recent times. While a variety of models have been developed for the task and have demonstrated impressive performance, they have not been evaluated on text domains that are different from the training domain, so it is unclear if the improvements brought by visual groundings are transferable. Our study aims to fill this gap and assess the degree of transferability. We start by extending VC-PCFG (short for Visually-grounded Compound PCFG [[Zhao and Titov, 2020](https://aclanthology.org/2020.emnlp-main.354/)]) in such a way that it can transfer across text domains. We consider a zero-shot transfer learning setting where a model is trained on the source domain and is directly applied to target domains, without any further training. Our experimental results suggest that: the benefits from using visual groundings transfer to text in a domain similar to the training domain but fail to transfer to remote domains. Further, we conduct data and result analysis; we find that the lexicon overlap between the source domain and the target domain is the most important factor in the transferability of VC-PCFG.</abstract>
      <url hash="d4414c63">2023.findings-emnlp.530</url>
      <bibkey>zhao-titov-2023-transferability</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.530</doi>
    </paper>
    <paper id="531">
      <title>Analysis of Style-Shifting on Social Media: Using Neural Language Model Conditioned by Social Meanings</title>
      <author><first>Seiya</first><last>Kawano</last></author>
      <author><first>Shota</first><last>Kanezaki</last></author>
      <author><first>Angel Fernando</first><last>Garcia Contreras</last></author>
      <author><first>Akishige</first><last>Yuguchi</last></author>
      <author><first>Marie</first><last>Katsurai</last></author>
      <author><first>Koichiro</first><last>Yoshino</last></author>
      <pages>7911-7921</pages>
      <abstract>In this paper, we propose a novel framework for evaluating style-shifting in social media conversations. Our proposed framework captures changes in an individual’s conversational style based on surprisals predicted by a personalized neural language model for individuals. Our personalized language model integrates not only the linguistic contents of conversations but also non-linguistic factors, such as social meanings, including group membership, personal attributes, and individual beliefs. We incorporate these factors directly or implicitly into our model, leveraging large, pre-trained language models and feature vectors derived from a relationship graph on social media. Compared to existing models, our personalized language model demonstrated superior performance in predicting an individual’s language in a test set. Furthermore, an analysis of style-shifting utilizing our proposed metric based on our personalized neural language model reveals a correlation between our metric and various conversation factors as well as human evaluation of style-shifting.</abstract>
      <url hash="ed717454">2023.findings-emnlp.531</url>
      <bibkey>kawano-etal-2023-analysis</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.531</doi>
    </paper>
    <paper id="532">
      <title>Linguistic Compression in Single-Sentence Human-Written Summaries</title>
      <author><first>Fangcong</first><last>Yin</last></author>
      <author><first>Marten</first><last>van Schijndel</last></author>
      <pages>7922-7935</pages>
      <abstract>Summarizing texts involves significant cognitive efforts to compress information. While advances in automatic summarization systems have drawn attention from the NLP and linguistics communities to this topic, there is a lack of computational studies of linguistic patterns in human-written summaries. This work presents a large-scale corpus study of human-written single-sentence summaries. We analyzed the linguistic compression patterns from source documents to summaries at different granularities, and we found that summaries are generally written with morphological expansion, increased lexical diversity, and similar positional arrangements of specific words compared to the source across different genres. We also studied how linguistic compressions of different factors affect reader judgments of quality through a human study, with the results showing that the use of morphological and syntactic changes by summary writers matches reader preferences while lexical diversity and word specificity preferences are not aligned between summary writers and readers.</abstract>
      <url hash="808d54a0">2023.findings-emnlp.532</url>
      <bibkey>yin-van-schijndel-2023-linguistic</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.532</doi>
    </paper>
    <paper id="533">
      <title><fixed-case>MCLF</fixed-case>: A Multi-grained Contrastive Learning Framework for <fixed-case>ASR</fixed-case>-robust Spoken Language Understanding</title>
      <author><first>Zhiqi</first><last>Huang</last></author>
      <author><first>Dongsheng</first><last>Chen</last></author>
      <author><first>Zhihong</first><last>Zhu</last></author>
      <author><first>Xuxin</first><last>Cheng</last></author>
      <pages>7936-7949</pages>
      <abstract>Enhancing the robustness towards Automatic Speech Recognition (ASR) errors is of great importance for Spoken Language Understanding (SLU). Trending ASR-robust SLU systems have witnessed impressive improvements through global contrastive learning. However, although most ASR errors occur only at local positions of utterances, they can easily lead to severe semantic changes, and utterance-level classification or comparison is difficult to distinguish such differences. To address the problem, we propose a two-stage multi-grained contrastive learning framework dubbed MCLF. Technically, we first adapt the pre-trained language models to downstream SLU datasets via the proposed multi-grained contrastive learning objective and then fine-tune it on the corresponding dataset. Besides, to facilitate contrastive learning in the pre-training stage, we explore several data augmentation methods to expand the training data. Experimental results and detailed analyses on four datasets and four BERT-like backbone models demonstrate the effectiveness of our approach.</abstract>
      <url hash="94e00e12">2023.findings-emnlp.533</url>
      <bibkey>huang-etal-2023-mclf</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.533</doi>
    </paper>
    <paper id="534">
      <title>Beyond Candidates : Adaptive Dialogue Agent Utilizing Persona and Knowledge</title>
      <author><first>Jungwoo</first><last>Lim</last></author>
      <author><first>Myunghoon</first><last>Kang</last></author>
      <author><first>Jinsung</first><last>Kim</last></author>
      <author><first>Jeongwook</first><last>Kim</last></author>
      <author><first>Yuna</first><last>Hur</last></author>
      <author><first>Heuiseok</first><last>Lim</last></author>
      <pages>7950-7963</pages>
      <abstract>To build ultimate dialogue agents, previous studies suggest models that ground both persona and knowledge. However, applying the dialogue system directly to the usual conversation is still limited because the system requires a complete sentence-formed persona and knowledge candidate sets from the given dataset. In contrast to the dialogue setting in the dataset, humans utilize semantic concepts in their minds rather than a set of pre-defined candidate sentences. Following this manner of human dialogue, we suggest an adaptive dialogue system that is applicable to situations where complete sentence-formed candidates are not given. Our model generates consistent and relevant persona descriptions and identifies relevant knowledge for engaging and knowledgeable responses, even with fragmentary information. We show that our model outperforms previous baselines that utilize persona and knowledge candidate sentences and conduct the human evaluation on the machine-generated responses. In addition, we conduct ablation studies to demonstrate the effectiveness of each component of our model. Furthermore, we apply our model to other dialogue datasets that only ground knowledge or persona to showcase its adaptability. Our code is available at https://github.com/dlawjddn803/BeCand.</abstract>
      <url hash="121e5f48">2023.findings-emnlp.534</url>
      <bibkey>lim-etal-2023-beyond</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.534</doi>
    </paper>
    <paper id="535">
      <title><fixed-case>S</fixed-case>mart<fixed-case>S</fixed-case>pan<fixed-case>NER</fixed-case>: Making <fixed-case>S</fixed-case>pan<fixed-case>NER</fixed-case> Robust in Low Resource Scenarios</title>
      <author><first>Min</first><last>Zhang</last></author>
      <author><first>Xiaosong</first><last>Qiao</last></author>
      <author><first>Yanqing</first><last>Zhao</last></author>
      <author><first>Shimin</first><last>Tao</last></author>
      <author><first>Hao</first><last>Yang</last></author>
      <pages>7964-7976</pages>
      <abstract>Named Entity Recognition (NER) is one of the most fundamental tasks in natural language processing. Span-level prediction (SpanNER) is more naturally suitable for nested NER than sequence labeling (SeqLab). However, according to our experiments, the SpanNER method is more sensitive to the amount of training data, i.e., the F1 score of SpanNER drops much more than that of SeqLab when the amount of training data drops. In order to improve the robustness of SpanNER in low resource scenarios, we propose a simple and effective method SmartSpanNER, which introduces a Named Entity Head (NEH) prediction task to SpanNER and performs multi-task learning together with the task of span classification. Experimental results demonstrate that the robustness of SpanNER could be greatly improved by SmartSpanNER in low resource scenarios constructed on the CoNLL03, Few-NERD, GENIA and ACE05 standard benchmark datasets.</abstract>
      <url hash="0a9d8ff4">2023.findings-emnlp.535</url>
      <bibkey>zhang-etal-2023-smartspanner</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.535</doi>
    </paper>
    <paper id="536">
      <title><fixed-case>Z</fixed-case>ero<fixed-case>SCROLLS</fixed-case>: A Zero-Shot Benchmark for Long Text Understanding</title>
      <author><first>Uri</first><last>Shaham</last></author>
      <author><first>Maor</first><last>Ivgi</last></author>
      <author><first>Avia</first><last>Efrat</last></author>
      <author><first>Jonathan</first><last>Berant</last></author>
      <author><first>Omer</first><last>Levy</last></author>
      <pages>7977-7989</pages>
      <abstract>We introduce ZeroSCROLLS, a zero-shot benchmark for natural language understanding over long texts, which contains only test and small validation sets, without training data. We adapt six tasks from the SCROLLS benchmark, and add four new datasets, including two novel information fusing tasks, such as aggregating the percentage of positive reviews. Using ZeroSCROLLS, we conduct a comprehensive evaluation of both open-source and closed large language models, finding that Claude outperforms ChatGPT, and that GPT-4 achieves the highest average score. However, there is still room for improvement on multiple open challenges in ZeroSCROLLS, such as aggregation tasks, where models struggle to pass the naive baseline. As the state of the art is a moving target, we invite researchers to evaluate their ideas on the live ZeroSCROLLS leaderboard.</abstract>
      <url hash="c44d56ee">2023.findings-emnlp.536</url>
      <bibkey>shaham-etal-2023-zeroscrolls</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.536</doi>
    </paper>
    <paper id="537">
      <title>Data Selection Curriculum for Abstractive Text Summarization</title>
      <author><first>Shichao</first><last>Sun</last></author>
      <author><first>Ruifeng</first><last>Yuan</last></author>
      <author><first>Jianfei</first><last>He</last></author>
      <author><first>Ziqiang</first><last>Cao</last></author>
      <author><first>Wenjie</first><last>Li</last></author>
      <author><first>Xiaohua</first><last>Jia</last></author>
      <pages>7990-7995</pages>
      <abstract>Abstractive Text Summarization (ATS) models are commonly trained using large-scale data that is randomly shuffled. However, the impact of data selection and data ordering on ATS models remains a relatively unexplored research area, where a significant challenge lies in accurately assessing the learning difficulty of each training instance. This study introduces a Data Selection Curriculum (DSC) scoring system that incorporates both the difficulty of improving ATS model via an instance and the expected performance on this instance. By selectively excluding excessively simple and overly complex instances, the training efficiency can be optimized. Furthermore, curriculum learning is integrated to accelerate convergence and improve performance by gradually increasing the learning difficulty, inspired by human learners. Experimental results on the CNN/DailyMail dataset demonstrate that our approach surpasses potent baselines, utilizing a mere 20% of the available instances.</abstract>
      <url hash="58412071">2023.findings-emnlp.537</url>
      <bibkey>sun-etal-2023-data</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.537</doi>
    </paper>
    <paper id="538">
      <title><fixed-case>R</fixed-case>omanization-based Large-scale Adaptation of Multilingual Language Models</title>
      <author><first>Sukannya</first><last>Purkayastha</last></author>
      <author><first>Sebastian</first><last>Ruder</last></author>
      <author><first>Jonas</first><last>Pfeiffer</last></author>
      <author><first>Iryna</first><last>Gurevych</last></author>
      <author><first>Ivan</first><last>Vulić</last></author>
      <pages>7996-8005</pages>
      <abstract>Large multilingual pretrained language models (mPLMs) have become the de facto state of the art for cross-lingual transfer in NLP. However, their large-scale deployment to many languages, besides pretraining data scarcity, is also hindered by the increase in vocabulary size and limitations in their parameter budget. In order to boost the capacity of mPLMs to deal with low-resource and unseen languages, we explore the potential of leveraging transliteration on a massive scale. In particular, we explore the UROMAN transliteration tool, which provides mappings from UTF-8 to Latin characters for all the writing systems, enabling inexpensive romanization for virtually any language. We first focus on establishing how UROMAN compares against other language-specific and manually curated transliterators for adapting multilingual PLMs. We then study and compare a plethora of data- and parameter-efficient strategies for adapting the mPLMs to romanized and non-romanized corpora of 14 diverse low-resource languages. Our results reveal that UROMAN-based transliteration can offer strong performance for many languages, with particular gains achieved in the most challenging setups: on languages with unseen scripts and with limited training data without any vocabulary augmentation. Further analyses reveal that an improved tokenizer based on romanized data can even outperform non-transliteration-based methods in the majority of languages.</abstract>
      <url hash="182a2666">2023.findings-emnlp.538</url>
      <bibkey>purkayastha-etal-2023-romanization</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.538</doi>
    </paper>
    <paper id="539">
      <title>Measuring bias in Instruction-Following models with <fixed-case>P</fixed-case>-<fixed-case>AT</fixed-case></title>
      <author><first>Dario</first><last>Onorati</last></author>
      <author><first>Elena</first><last>Ruzzetti</last></author>
      <author><first>Davide</first><last>Venditti</last></author>
      <author><first>Leonardo</first><last>Ranaldi</last></author>
      <author><first>Fabio</first><last>Zanzotto</last></author>
      <pages>8006-8034</pages>
      <abstract>Instruction-Following Language Models (IFLMs) are promising and versatile tools for solving many downstream, information-seeking tasks. Given their success, there is an urgent need to have a shared resource to determine whether existing and new IFLMs are prone to produce biased language interactions. In this paper, we propose Prompt Association Test (P-AT): a new resource for testing the presence of social biases in IFLMs. P-AT stems from WEAT (Caliskan et al., 2017) and generalizes the notion of measuring social biases to IFLMs. Basically, we cast WEAT word tests in promptized classification tasks, and we associate a metric - the bias score. Our resource consists of 2310 prompts. We then experimented with several families of IFLMs discovering gender and race biases in all the analyzed models. We expect P-AT to be an important tool for quantifying bias across different dimensions and, therefore, for encouraging the creation of fairer IFLMs before their distortions have consequences in the real world.</abstract>
      <url hash="9910fde5">2023.findings-emnlp.539</url>
      <bibkey>onorati-etal-2023-measuring</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.539</doi>
    </paper>
    <paper id="540">
      <title>Open-ended Commonsense Reasoning with Unrestricted Answer Candidates</title>
      <author><first>Chen</first><last>Ling</last></author>
      <author><first>Xuchao</first><last>Zhang</last></author>
      <author><first>Xujiang</first><last>Zhao</last></author>
      <author><first>Yanchi</first><last>Liu</last></author>
      <author><first>Wei</first><last>Cheng</last></author>
      <author><first>Mika</first><last>Oishi</last></author>
      <author><first>Takao</first><last>Osaki</last></author>
      <author><first>Katsushi</first><last>Matsuda</last></author>
      <author><first>Haifeng</first><last>Chen</last></author>
      <author><first>Liang</first><last>Zhao</last></author>
      <pages>8035-8047</pages>
      <abstract>Open-ended Commonsense Reasoning is defined as solving a commonsense question without providing 1) a short list of answer candidates and 2) a pre-defined answer scope. Conventional ways of formulating the commonsense question into a question-answering form or utilizing external knowledge to learn retrieval-based methods are less applicable in the open-ended setting due to an inherent challenge. Without pre-defining an answer scope or a few candidates, open-ended commonsense reasoning entails predicting answers by searching over an extremely large searching space. Moreover, most questions require implicit multi-hop reasoning, which presents even more challenges to our problem. In this work, we leverage pre-trained language models to iteratively retrieve reasoning paths on the external knowledge base, which does not require task-specific supervision. The reasoning paths can help to identify the most precise answer to the commonsense question. We conduct experiments on two commonsense benchmark datasets. Compared to other approaches, our proposed method achieves better performance both quantitatively and qualitatively.</abstract>
      <url hash="ecfcfd87">2023.findings-emnlp.540</url>
      <bibkey>ling-etal-2023-open</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.540</doi>
    </paper>
    <paper id="541">
      <title>Speaking Style Conversion in the Waveform Domain Using Discrete Self-Supervised Units</title>
      <author><first>Gallil</first><last>Maimon</last></author>
      <author><first>Yossi</first><last>Adi</last></author>
      <pages>8048-8061</pages>
      <abstract>We introduce DISSC, a novel, lightweight method that converts the rhythm, pitch contour and timbre of a recording to a target speaker in a textless manner. Unlike DISSC, most voice conversion (VC) methods focus primarily on timbre, and ignore people’s unique speaking style (prosody). The proposed approach uses a pretrained, self-supervised model for encoding speech to discrete units, which makes it simple, effective, and fast to train. All conversion modules are only trained on reconstruction like tasks, thus suitable for any-to-many VC with no paired data. We introduce a suite of quantitative and qualitative evaluation metrics for this setup, and empirically demonstrate that DISSC significantly outperforms the evaluated baselines. Code and samples are available at https://pages.cs.huji.ac.il/adiyoss-lab/dissc/.</abstract>
      <url hash="2ed8e1e3">2023.findings-emnlp.541</url>
      <bibkey>maimon-adi-2023-speaking</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.541</doi>
    </paper>
    <paper id="542">
      <title>Knowledge-Selective Pretraining for Attribute Value Extraction</title>
      <author><first>Hui</first><last>Liu</last></author>
      <author><first>Qingyu</first><last>Yin</last></author>
      <author><first>Zhengyang</first><last>Wang</last></author>
      <author><first>Chenwei</first><last>Zhang</last></author>
      <author><first>Haoming</first><last>Jiang</last></author>
      <author><first>Yifan</first><last>Gao</last></author>
      <author><first>Zheng</first><last>Li</last></author>
      <author><first>Xian</first><last>Li</last></author>
      <author><first>Chao</first><last>Zhang</last></author>
      <author><first>Bing</first><last>Yin</last></author>
      <author><first>William</first><last>Wang</last></author>
      <author><first>Xiaodan</first><last>Zhu</last></author>
      <pages>8062-8074</pages>
      <abstract>Attribute Value Extraction (AVE) aims to retrieve the values of attributes from the product profiles. The state-of-the-art methods tackle the AVE task through a question-answering (QA) paradigm, where the value is predicted from the context (i.e. product profile) given a query (i.e. attributes). Despite of the substantial advancements that have been made, the performance of existing methods on rare attributes is still far from satisfaction, and they cannot be easily extended to unseen attributes due to the poor generalization ability. In this work, we propose to leverage pretraining and transfer learning to address the aforementioned weaknesses. We first collect the product information from various E-commerce stores and retrieve a large number of (profile, attribute, value) triples, which will be used as the pretraining corpus. To more effectively utilize the retrieved corpus, we further design a Knowledge-Selective Framework (KSelF) based on query expansion that can be closely combined with the pretraining corpus to boost the performance. Meanwhile, considering the public AE-pub dataset contains considerable noise, we construct and contribute a larger benchmark EC-AVE collected from E-commerce websites. We conduct evaluation on both of these datasets. The experimental results demonstrate that our proposed KSelF achieves new state-of-the-art performance without pretraining. When incorporated with the pretraining corpus, the performance of KSelF can be further improved, particularly on the attributes with limited training resources.</abstract>
      <url hash="f8fde29c">2023.findings-emnlp.542</url>
      <bibkey>liu-etal-2023-knowledge</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.542</doi>
    </paper>
    <paper id="543">
      <title>New Datasets and Controllable Iterative Data Augmentation Method for Code-switching <fixed-case>ASR</fixed-case> Error Correction</title>
      <author><first>Zhaohong</first><last>Wan</last></author>
      <author><first>Xiaojun</first><last>Wan</last></author>
      <author><first>Wei</first><last>Peng</last></author>
      <author><first>Rongjun</first><last>Li</last></author>
      <pages>8075-8087</pages>
      <abstract>With the wide use of automatic speech recognition(ASR) systems, researchers pay more attention to the ASR error correction task to improve the quality of recognition results. In particular, ASR in bilingual or multilingual settings, namely code-switching ASR, has greater challenges and research value. In this paper, we first present code-switching ASR correction datasets obtained from solid ASR systems and automatic annotators. The datasets contain Chinese-English code-switching dialogues of bilingual speakers in Singapore, Malaysia, and Hong Kong. Based on this task, we propose a controllable iterative (CI) data augmentation method for improving the performance of mainstream ASR error correction systems. With a small amount of training data, our proposed method has the ability to iteratively produce abundant pseudo parallel data from the monolingual corpus for Chinese-English code-switching ASR correction. Results of experiments show that our method achieves the best performance compared with the rule-based, back-translation-based data augmentation methods and large language model ChatGPT.</abstract>
      <url hash="7fcc2e33">2023.findings-emnlp.543</url>
      <bibkey>wan-etal-2023-new</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.543</doi>
    </paper>
    <paper id="544">
      <title>Efficient k-<fixed-case>NN</fixed-case> Search with Cross-Encoders using Adaptive Multi-Round <fixed-case>CUR</fixed-case> Decomposition</title>
      <author><first>Nishant</first><last>Yadav</last></author>
      <author><first>Nicholas</first><last>Monath</last></author>
      <author><first>Manzil</first><last>Zaheer</last></author>
      <author><first>Andrew</first><last>McCallum</last></author>
      <pages>8088-8103</pages>
      <abstract>Cross-encoder models, which jointly encode and score a query-item pair, are prohibitively expensive for direct k-nearest neighbor (k-NN) search. Consequently, k-NN search typically employs a fast approximate retrieval (e.g. using BM25 or dual-encoder vectors), followed by reranking with a cross-encoder; however, the retrieval approximation often has detrimental recall regret. This problem is tackled by ANNCUR (Yadav et al., 2022), a recent work that employs a cross-encoder only, making search efficient using a relatively small number of anchor items, and a CUR matrix factorization. While ANNCUR’s one-time selection of anchors tends to approximate the cross-encoder distances on average, doing so forfeits the capacity to accurately estimate distances to items near the query, leading to regret in the crucial end-task: recall of top-k items. In this paper, we propose ADACUR, a method that adaptively, iteratively, and efficiently minimizes the approximation error for the practically important top-k neighbors. It does so by iteratively performing k-NN search using the anchors available so far, then adding these retrieved nearest neighbors to the anchor set for the next round. Empirically, on multiple datasets, in comparison to previous traditional and state-of-the-art methods such as ANNCUR and dual-encoder-based retrieve-and-rerank, our proposed approach ADACUR consistently reduces recall error—by up to 70% on the important k = 1 setting—while using no more compute than its competitors.</abstract>
      <url hash="613815c6">2023.findings-emnlp.544</url>
      <bibkey>yadav-etal-2023-efficient</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.544</doi>
    </paper>
    <paper id="545">
      <title>Isotropic Representation Can Improve Zero-Shot Cross-Lingual Transfer on Multilingual Language Models</title>
      <author><first>Yixin</first><last>Ji</last></author>
      <author><first>Jikai</first><last>Wang</last></author>
      <author><first>Juntao</first><last>Li</last></author>
      <author><first>Hai</first><last>Ye</last></author>
      <author><first>Min</first><last>Zhang</last></author>
      <pages>8104-8118</pages>
      <abstract>With the development of multilingual pre-trained language models (mPLMs), zero-shot cross-lingual transfer shows great potential. To further improve the performance of cross-lingual transfer, many studies have explored representation misalignment caused by morphological differences but neglected the misalignment caused by the anisotropic distribution of contextual representations. In this work, we propose enhanced isotropy and constrained code-switching for zero-shot cross-lingual transfer to alleviate the problem of misalignment caused by the anisotropic representations and maintain syntactic structural knowledge. Extensive experiments on three zero-shot cross-lingual transfer tasks demonstrate that our method gains significant improvements over strong mPLM backbones and further improves the state-of-the-art methods.</abstract>
      <url hash="bd0e8db5">2023.findings-emnlp.545</url>
      <bibkey>ji-etal-2023-isotropic</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.545</doi>
    </paper>
    <paper id="546">
      <title>Blackbird language matrices (<fixed-case>BLM</fixed-case>), a new task for rule-like generalization in neural networks: Can Large Language Models pass the test?</title>
      <author><first>Paola</first><last>Merlo</last></author>
      <pages>8119-8152</pages>
      <abstract>How do we evaluate Large Language Models (LLMs) and determine the aspects and limits of their intelligent behaviour? It is currently conjectured that shortcomings of LLMs in multi-linguality and reasoning are due to a lack of ability to generalize. It has been argued that, instead, humans are better at generalization because they have a tendency at extracting rules from complex data. We propose a method to evaluate LLMs ability to rule-based generalization. When exposed to tests of analytic intelligence, for example the visual RAVEN IQ test, human problem-solvers identify the relevant objects in the picture and their relevant attributes and reason based on rules applied to them. Based on the induced rules, they are able to provide a generalisation and a solution to the test. An analogous language task has recently been proposed (called BLM) for LLM. In this paper, we argue that we can use this task to investigate what linguistic reasoning LLM develop, by asking them to solve some simple variants of the BLM task. We find that current state-of-the-art generative models, such as ChatGPT, can handle the task in the sense that they easily understand the instructions and can provide step-by-step reasoning that shows that it can solve two of the main cognitive hurdles: correspondence finding (object and attribute identification) and item novelty. However, overall they cannot find the correct answer, even with considerable help. In particular, they never identify the structure of the problem, exhibiting, we hypothesize, a lack of goal and subgoal management abilities, an ability that has been argued to measure differential abilities in humans. We argue that this finding supports the usefulness of the task as a method to test the limits and specific properties of generalisation ability in Large Language Models, providing an intrinsic evaluation method inspired by tests of human intelligence.</abstract>
      <url hash="5255aac1">2023.findings-emnlp.546</url>
      <bibkey>merlo-2023-blackbird</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.546</doi>
    </paper>
    <paper id="547">
      <title><fixed-case>D</fixed-case>istill<fixed-case>CSE</fixed-case>: Distilled Contrastive Learning for Sentence Embeddings</title>
      <author><first>Jiahao</first><last>Xu</last></author>
      <author><first>Wei</first><last>Shao</last></author>
      <author><first>Lihui</first><last>Chen</last></author>
      <author><first>Lemao</first><last>Liu</last></author>
      <pages>8153-8165</pages>
      <abstract>This paper proposes the DistillCSE framework, which performs contrastive learning under the self-training paradigm with knowledge distillation. The potential advantage of DistillCSE is its self-enhancing feature: using a base model to provide additional supervision signals, a stronger model may be learned through knowledge distillation. However, the vanilla DistillCSE through the standard implementation of knowledge distillation only achieves marginal improvements. The quantitative analyses demonstrate its reason that the standard knowledge distillation exhibits a relatively large variance of the teacher model’s logits due to the essence of contrastive learning. To mitigate the issue induced by high variance, this paper accordingly proposed two simple yet effective solutions for knowledge distillation: a Group-P shuffling strategy as an implicit regularization and the averaging logits from multiple teacher components. Experiments on standard benchmarks demonstrate that the proposed DistillCSE outperforms many strong baseline methods and yields a new state-of-the-art performance.</abstract>
      <url hash="61f46092">2023.findings-emnlp.547</url>
      <bibkey>xu-etal-2023-distillcse</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.547</doi>
    </paper>
    <paper id="548">
      <title><fixed-case>GSAP</fixed-case>-<fixed-case>NER</fixed-case>: A Novel Task, Corpus, and Baseline for Scholarly Entity Extraction Focused on Machine Learning Models and Datasets</title>
      <author><first>Wolfgang</first><last>Otto</last></author>
      <author><first>Matthäus</first><last>Zloch</last></author>
      <author><first>Lu</first><last>Gan</last></author>
      <author><first>Saurav</first><last>Karmakar</last></author>
      <author><first>Stefan</first><last>Dietze</last></author>
      <pages>8166-8176</pages>
      <abstract>Named Entity Recognition (NER) models play a crucial role in various NLP tasks, including information extraction (IE) and text understanding. In academic writing, references to machine learning models and datasets are fundamental components of various computer science publications and necessitate accurate models for identification. Despite the advancements in NER, existing ground truth datasets do not treat fine-grained types like ML model and model architecture as separate entity types, and consequently, baseline models cannot recognize them as such. In this paper, we release a corpus of 100 manually annotated full-text scientific publications and a first baseline model for 10 entity types centered around ML models and datasets. In order to provide a nuanced understanding of how ML models and datasets are mentioned and utilized, our dataset also contains annotations for informal mentions like “our BERT-based model” or “an image CNN”. You can find the ground truth dataset and code to replicate model training at https://data.gesis.org/gsap/gsap-ner.</abstract>
      <url hash="a767abf8">2023.findings-emnlp.548</url>
      <bibkey>otto-etal-2023-gsap</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.548</doi>
    </paper>
    <paper id="549">
      <title>Open Domain Multi-document Summarization: A Comprehensive Study of Model Brittleness under Retrieval</title>
      <author><first>John</first><last>Giorgi</last></author>
      <author><first>Luca</first><last>Soldaini</last></author>
      <author><first>Bo</first><last>Wang</last></author>
      <author><first>Gary</first><last>Bader</last></author>
      <author><first>Kyle</first><last>Lo</last></author>
      <author><first>Lucy</first><last>Wang</last></author>
      <author><first>Arman</first><last>Cohan</last></author>
      <pages>8177-8199</pages>
      <abstract>Multi-document summarization (MDS) assumes a set of topic-related documents are provided as input. In practice, this document set is not always available; it would need to be retrieved given an information need, i.e. a question or topic statement, a setting we dub “open-domain’ MDS. We study this more challenging setting by formalizing the task and bootstrapping it using existing datasets, retrievers and summarizers. Via extensive automatic and human evaluation, we determine: (1) state-of-the-art summarizers suffer large reductions in performance when applied to open-domain MDS, (2) additional training in the open-domain setting can reduce this sensitivity to imperfect retrieval, and (3) summarizers are insensitive to the retrieval of duplicate documents and the order of retrieved documents, but highly sensitive to other errors, like the retrieval of irrelevant documents. Based on our results, we provide practical guidelines to enable future work on open-domain MDS, e.g. how to choose the number of retrieved documents to summarize. Our results suggest that new retrieval and summarization methods and annotated resources for training and evaluation are necessary for further progress in the open-domain setting.</abstract>
      <url hash="087582f4">2023.findings-emnlp.549</url>
      <bibkey>giorgi-etal-2023-open</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.549</doi>
    </paper>
    <paper id="550">
      <title>Few-shot Unified Question Answering: Tuning Models or Prompts?</title>
      <author><first>Srijan</first><last>Bansal</last></author>
      <author><first>Semih</first><last>Yavuz</last></author>
      <author><first>Bo</first><last>Pang</last></author>
      <author><first>Meghana</first><last>Bhat</last></author>
      <author><first>Yingbo</first><last>Zhou</last></author>
      <pages>8200-8220</pages>
      <abstract>Question-answering (QA) tasks often investigate specific question types, knowledge domains, or reasoning skills, leading to specialized models catering to specific categories of QA tasks. While recent research has explored the idea of unified QA models, such models are usually explored for high-resource scenarios and require re-training to extend their capabilities. To overcome these drawbacks, the paper explores the potential of two paradigms of tuning, model, and prompts, for unified QA under a low-resource setting. The paper provides an exhaustive analysis of their applicability using 16 QA datasets, revealing that prompt tuning can perform as well as model tuning in a few-shot setting with a good initialization. The study also shows that parameter-sharing results in superior few-shot performance, simple knowledge transfer techniques for prompt initialization can be effective, and prompt tuning achieves a significant performance boost from pre-training in a low-resource regime. The research offers insights into the advantages and limitations of prompt tuning for unified QA in a few-shot setting, contributing to the development of effective and efficient systems in low-resource scenarios.</abstract>
      <url hash="3ce3b04e">2023.findings-emnlp.550</url>
      <bibkey>bansal-etal-2023-shot</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.550</doi>
    </paper>
    <paper id="551">
      <title>Finding Common Ground: Annotating and Predicting Common Ground in Spoken Conversations</title>
      <author><first>Magdalena</first><last>Markowska</last></author>
      <author><first>Mohammad</first><last>Taghizadeh</last></author>
      <author><first>Adil</first><last>Soubki</last></author>
      <author><first>Seyed</first><last>Mirroshandel</last></author>
      <author><first>Owen</first><last>Rambow</last></author>
      <pages>8221-8233</pages>
      <abstract>When we communicate with other humans, we do not simply generate a sequence of words. Rather, we use our cognitive state (beliefs, desires, intentions) and our model of the audience’s cognitive state to create utterances that affect the audience’s cognitive state in the intended manner. An important part of cognitive state is the common ground, which is the content the speaker believes, and the speaker believes the audience believes, and so on. While much attention has been paid to common ground in cognitive science, there has not been much work in natural language processing. In this paper, we introduce a new annotation and corpus to capture common ground. We then describe some initial experiments extracting propositions from dialog and tracking their status in the common ground from the perspective of each speaker.</abstract>
      <url hash="fa18c26f">2023.findings-emnlp.551</url>
      <bibkey>markowska-etal-2023-finding</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.551</doi>
    </paper>
    <paper id="552">
      <title>Getting <fixed-case>M</fixed-case>o<fixed-case>RE</fixed-case> out of Mixture of Language Model Reasoning Experts</title>
      <author><first>Chenglei</first><last>Si</last></author>
      <author><first>Weijia</first><last>Shi</last></author>
      <author><first>Chen</first><last>Zhao</last></author>
      <author><first>Luke</first><last>Zettlemoyer</last></author>
      <author><first>Jordan</first><last>Boyd-Graber</last></author>
      <pages>8234-8249</pages>
      <abstract>While recent large language models (LLMs) improve on various question answering (QA) datasets, it remains difficult for a single model to generalize across question types that require distinct reasoning abilities. We provide empirical evidence that state-of-the-art LLMs suffer from poor generalizability on reasoning types beyond those seen in the prompt. To remedy this, we propose a Mixture-of-Reasoning-Experts (MORE) framework that ensembles diverse specialized language models. We specialize the backbone language model with prompts optimized for different reasoning categories, including factual, multihop, mathematical, and commonsense reasoning. Our key insight is to leverage agreement among the specialized experts to select the best answer for each question, or to abstain from answering. This gives MORE higher accuracy than any single specialized model on a collection of 12 QA datasets from four reasoning types. Beyond generalizability, the interpretable design of MORE improves selective question answering results compared to baselines without incorporating inter-expert agreement. This framework is also more interpretable and useful to human consumers of QA outputs. Our human study confirms that presenting expert predictions and the answer selection process helps annotators more accurately calibrate when to trust the system’s output. We release all code and data to facilitate future work.</abstract>
      <url hash="876e3198">2023.findings-emnlp.552</url>
      <bibkey>si-etal-2023-getting</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.552</doi>
    </paper>
    <paper id="553">
      <title>“You Are An Expert Linguistic Annotator”: Limits of <fixed-case>LLM</fixed-case>s as Analyzers of <fixed-case>A</fixed-case>bstract <fixed-case>M</fixed-case>eaning <fixed-case>R</fixed-case>epresentation</title>
      <author><first>Allyson</first><last>Ettinger</last></author>
      <author><first>Jena</first><last>Hwang</last></author>
      <author><first>Valentina</first><last>Pyatkin</last></author>
      <author><first>Chandra</first><last>Bhagavatula</last></author>
      <author><first>Yejin</first><last>Choi</last></author>
      <pages>8250-8263</pages>
      <abstract>Large language models (LLMs) demonstrate an amazing proficiency and fluency in the <tex-math>\textit{use}</tex-math> of language. Does that mean that they have also acquired insightful linguistic knowledge <tex-math>\textit{about}</tex-math> the language, to an extent that they can serve as an “expert linguistic annotator’? In this paper, we examine the successes and limitations of the GPT-3, ChatGPT, and GPT-4 models, focusing on the Abstract Meaning Representation (AMR) parsing formalism (Banarescu et al., 2013), which provides rich graphical representations of sentence meaning structure while abstracting away from surface forms. We compare models’ analysis of this semantic structure across two settings: 1) direct production of AMR parses based on zero- and few-shot examples, and 2) indirect partial reconstruction of AMR via metalinguistic natural language queries (e.g., “Identify the primary event of this sentence, and the predicate corresponding to that event.”). Across these settings, we find that models can reliably reproduce the basic format of AMR, as well as some core event, argument, and modifier structure<tex-math>-</tex-math>however, model outputs are prone to frequent and major errors, and holistic analysis of parse acceptability shows that even with few-shot demonstrations, models have virtually 0% success in producing fully accurate parses. Eliciting responses in natural language produces similar patterns of errors. Overall, our findings indicate that these models out-of-the-box can accurately identify some core aspects of semantic structure, but there remain key limitations in their ability to support fully accurate semantic analyses or parses.</abstract>
      <url hash="4129fc4d">2023.findings-emnlp.553</url>
      <bibkey>ettinger-etal-2023-expert</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.553</doi>
    </paper>
    <paper id="554">
      <title>Zero-Shot Data Maps. Efficient Dataset Cartography Without Model Training</title>
      <author><first>Angelo</first><last>Basile</last></author>
      <author><first>Marc</first><last>Franco-Salvador</last></author>
      <author><first>Paolo</first><last>Rosso</last></author>
      <pages>8264-8277</pages>
      <abstract>Data Maps (Swayamdipta, et al. 2020) have emerged as a powerful tool for diagnosing large annotated datasets. Given a model fitted on a dataset, these maps show each data instance from the dataset in a 2-dimensional space defined by a) the model’s confidence in the true class and b) the variability of this confidence. In previous work, confidence and variability are usually computed using training dynamics, which requires the fitting of a strong model to the dataset. In this paper, we introduce a novel approach: Zero-Shot Data Maps based on fast bi-encoder networks. For each data point, confidence on the true label and variability are computed over the members of an ensemble of zero-shot models constructed with different — but semantically equivalent — label descriptions, i.e., textual representations of each class in a given label space. We conduct a comparative analysis of maps compiled using traditional training dynamics and our proposed zero-shot models across various datasets. Our findings reveal that Zero-Shot Data Maps generally match those produced by the traditional method while delivering up to a 14x speedup. The code is available [here](https://github.com/symanto-research/zeroshot-cartography).</abstract>
      <url hash="d5b55e2f">2023.findings-emnlp.554</url>
      <bibkey>basile-etal-2023-zero</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.554</doi>
    </paper>
    <paper id="555">
      <title>Isotropy-Enhanced Conditional Masked Language Models</title>
      <author><first>Pei</first><last>Guo</last></author>
      <author><first>Yisheng</first><last>Xiao</last></author>
      <author><first>Juntao</first><last>Li</last></author>
      <author><first>Yixin</first><last>Ji</last></author>
      <author><first>Min</first><last>Zhang</last></author>
      <pages>8278-8289</pages>
      <abstract>Non-autoregressive models have been widely used for various text generation tasks to accelerate the inference process but at the cost of generation quality to some extent. To achieve a good balance between inference speedup and generation quality, iterative NAR models like CMLM and Disco are proposed. Researchers have made much follow-up progress based on them, and some recent iterative models can achieve very promising performance while maintaining significant speedup. In this paper, we give more insights into iterative NAR models by exploring the anisotropic problem, i.e., the representations of distinct predicted target tokens are similar and indiscriminative. Upon the confirmation of the anisotropic problem in iterative NAR models, we first analyze the effectiveness of the contrastive learning method and further propose the Look Neighbors strategy to enhance the learning of token representations during training. Experiments on 4 WMT datasets show that our methods consistently improve the performance as well as alleviate the anisotropic problem of the conditional masked language model, even outperforming the current SoTA result on WMT14 EN <tex-math>\rightarrow</tex-math> DE.</abstract>
      <url hash="04d3d65c">2023.findings-emnlp.555</url>
      <bibkey>guo-etal-2023-isotropy</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.555</doi>
    </paper>
    <paper id="556">
      <title>Scaling Law for Document Neural Machine Translation</title>
      <author><first>Zhang</first><last>Zhuocheng</last></author>
      <author><first>Shuhao</first><last>Gu</last></author>
      <author><first>Min</first><last>Zhang</last></author>
      <author><first>Yang</first><last>Feng</last></author>
      <pages>8290-8303</pages>
      <abstract>The scaling laws of language models have played a significant role in advancing large language models. In order to promote the development of document translation, we systematically examine the scaling laws in this field. In this paper, we carry out an in-depth analysis of the influence of three factors on translation quality: model scale, data scale, and sequence length. Our findings reveal that increasing sequence length effectively enhances model performance when model size is limited. However, sequence length cannot be infinitely extended; it must be suitably aligned with the model scale and corpus volume. Further research shows that providing adequate context can effectively enhance the translation quality of a document’s initial portion. Nonetheless, exposure bias remains the primary factor hindering further improvement in translation quality for the latter half of the document.</abstract>
      <url hash="29dd00d3">2023.findings-emnlp.556</url>
      <bibkey>zhuocheng-etal-2023-scaling</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.556</doi>
    </paper>
    <paper id="557">
      <title>Automatic Pronunciation Assessment - A Review</title>
      <author><first>Yassine</first><last>Kheir</last></author>
      <author><first>Ahmed</first><last>Ali</last></author>
      <author><first>Shammur</first><last>Chowdhury</last></author>
      <pages>8304-8324</pages>
      <abstract>Pronunciation assessment and its application in computer-aided pronunciation training (CAPT) have seen impressive progress in recent years. With the rapid growth in language processing and deep learning over the past few years, there is a need for an updated review. In this paper, we review methods employed in pronunciation assessment for both phonemic and prosodic. We categorize the main challenges observed in prominent research trends, and highlight existing limitations, and available resources. This is followed by a discussion of the remaining challenges and possible directions for future work.</abstract>
      <url hash="027d0eb1">2023.findings-emnlp.557</url>
      <bibkey>kheir-etal-2023-automatic</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.557</doi>
    </paper>
    <paper id="558">
      <title>Segmented Recurrent Transformer: An Efficient Sequence-to-Sequence Model</title>
      <author><first>Yinghan</first><last>Long</last></author>
      <author><first>Sayeed</first><last>Chowdhury</last></author>
      <author><first>Kaushik</first><last>Roy</last></author>
      <pages>8325-8337</pages>
      <abstract>Transformers have shown dominant performance across a range of domains including language and vision. However, their computational cost grows quadratically with the sequence length, making their usage prohibitive for resource-constrained applications. To counter this, our approach is to divide the whole sequence into segments and apply attention to the individual segments. We propose a segmented recurrent transformer (SRformer) that combines segmented (local) attention with recurrent attention. The loss caused by reducing the attention window length is compensated by aggregating information across segments with recurrent attention. SRformer leverages Recurrent Accumulate-and-Fire (RAF) neurons’ inherent memory to update the cumulative product of keys and values. The segmented attention and lightweight RAF neurons ensure the efficiency of the proposed transformer. Such an approach leads to models with sequential processing capability at a lower computation/memory cost. We apply the proposed method to T5 and BART transformers. The modified models are tested on summarization datasets including CNN-dailymail, XSUM, ArXiv, and MediaSUM. Notably, using segmented inputs of varied sizes, the proposed model achieves 6-22% higher ROUGE1 scores than a segmented transformer and outperforms other recurrent transformer approaches. Furthermore, compared to full attention, the proposed model reduces the computational complexity of cross attention by around 40%.</abstract>
      <url hash="afa5da74">2023.findings-emnlp.558</url>
      <bibkey>long-etal-2023-segmented</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.558</doi>
    </paper>
    <paper id="559">
      <title><fixed-case>PUNR</fixed-case>: Pre-training with User Behavior Modeling for News Recommendation</title>
      <author><first>Guangyuan</first><last>Ma</last></author>
      <author><first>Hongtao</first><last>Liu</last></author>
      <author><first>Xing</first><last>W</last></author>
      <author><first>Wanhui</first><last>Qian</last></author>
      <author><first>Zhepeng</first><last>Lv</last></author>
      <author><first>Qing</first><last>Yang</last></author>
      <author><first>Songlin</first><last>Hu</last></author>
      <pages>8338-8347</pages>
      <abstract>News recommendation aims to predict click behaviors based on user behaviors. How to effectively model the user representations is the key to recommending preferred news. Existing works are mostly focused on improvements in the supervised fine-tuning stage. However, there is still a lack of PLM-based unsupervised pre-training methods optimized for user representations. In this work, we propose an unsupervised pre-training paradigm with two tasks, i.e. user behavior masking and user behavior generation, both towards effective user behavior modeling. Firstly, we introduce the user behavior masking pre-training task to recover the masked user behaviors based on their contextual behaviors. In this way, the model could capture a much stronger and more comprehensive user news reading pattern. Besides, we incorporate a novel auxiliary user behavior generation pre-training task to enhance the user representation vector derived from the user encoder. We use the above pre-trained user modeling encoder to obtain news and user representations in downstream fine-tuning. Evaluations on the real-world news benchmark show significant performance improvements over existing baselines.</abstract>
      <url hash="e82aaef5">2023.findings-emnlp.559</url>
      <bibkey>ma-etal-2023-punr</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.559</doi>
    </paper>
    <paper id="560">
      <title><fixed-case>M</fixed-case>onte <fixed-case>C</fixed-case>arlo Thought Search: Large Language Model Querying for Complex Scientific Reasoning in Catalyst Design</title>
      <author><first>Henry</first><last>Sprueill</last></author>
      <author><first>Carl</first><last>Edwards</last></author>
      <author><first>Mariefel</first><last>Olarte</last></author>
      <author><first>Udishnu</first><last>Sanyal</last></author>
      <author><first>Heng</first><last>Ji</last></author>
      <author><first>Sutanay</first><last>Choudhury</last></author>
      <pages>8348-8365</pages>
      <abstract>Discovering novel catalysts requires complex reasoning involving multiple chemical properties and resultant trade-offs, leading to a combinatorial growth in the search space. While large language models (LLM) have demonstrated novel capabilities for chemistry through complex instruction following capabilities and high quality reasoning, a goal-driven combinatorial search using LLMs has not been explored in detail. In this work, we present a Monte Carlo Tree Search-based approach that improves beyond state-of-the-art chain-of-thought prompting variants to augment scientific reasoning. We introduce two new reasoning datasets: 1) a curation of computational chemistry simulations, and 2) diverse questions written by catalysis researchers for reasoning about novel chemical conversion processes. We improve over the best baseline by 25.8% and find that our approach can augment scientist’s reasoning and discovery process with novel insights.</abstract>
      <url hash="a74f772e">2023.findings-emnlp.560</url>
      <bibkey>sprueill-etal-2023-monte</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.560</doi>
    </paper>
    <paper id="561">
      <title>Measure Children’s Mindreading Ability with Machine Reading</title>
      <author><first>Yuliang</first><last>Yan</last></author>
      <author><first>Xiaohua</first><last>Wang</last></author>
      <author><first>Xiang</first><last>Zhou</last></author>
      <author><first>Xiaoqing</first><last>Zheng</last></author>
      <author><first>Xuanjing</first><last>Huang</last></author>
      <pages>8366-8375</pages>
      <abstract>Recently, much research in psychology has benefited from the advances in machine learning techniques. Some recent studies showed that it is possible to build automated scoring models for children’s mindreading. These models were trained on a set of manually-labeled question-response pairs, which were collected by asking children to answer one or two questions after a short story is told or a video clip is played. However, existing models did not take the features of the stories and video clips into account when scoring, which obviously will reduce the accuracy of the scoring models. Furthermore, considering that different psychological tests may contain the same questions, this approach cannot be extended to other related psychological test datasets. In this study, we proposed a multi-modal learning framework to leverage the features extracted from the stories and videos related to the questions being asked during the children’s mindreading evaluation. Experimental results show that the scores produced by the proposed models agree well with those graded by human experts, highlighting the potential of the proposed network architecture for practical automated children’s mindreading scoring systems.</abstract>
      <url hash="d29a64a2">2023.findings-emnlp.561</url>
      <bibkey>yan-etal-2023-measure</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.561</doi>
    </paper>
    <paper id="562">
      <title>Crosslingual Transfer Learning for Low-Resource Languages Based on Multilingual Colexification Graphs</title>
      <author><first>Yihong</first><last>Liu</last></author>
      <author><first>Haotian</first><last>Ye</last></author>
      <author><first>Leonie</first><last>Weissweiler</last></author>
      <author><first>Renhao</first><last>Pei</last></author>
      <author><first>Hinrich</first><last>Schuetze</last></author>
      <pages>8376-8401</pages>
      <abstract>In comparative linguistics, colexification refers to the phenomenon of a lexical form conveying two or more distinct meanings. Existing work on colexification patterns relies on annotated word lists, limiting scalability and usefulness in NLP. In contrast, we identify colexification patterns of more than 2,000 concepts across 1,335 languages directly from an unannotated parallel corpus. We then propose simple and effective methods to build multilingual graphs from the colexification patterns: <b>ColexNet</b> and <b>ColexNet+</b>. ColexNet’s nodes are concepts and its edges are colexifications. In ColexNet+, concept nodes are additionally linked through intermediate nodes, each representing an ngram in one of 1,334 languages. We use ColexNet+ to train <tex-math>\overrightarrow{\mbox{ColexNet+}}</tex-math>, high-quality multilingual embeddings that are well-suited for transfer learning. In our experiments, we first show that ColexNet achieves high recall on CLICS, a dataset of crosslingual colexifications. We then evaluate <tex-math>\overrightarrow{\mbox{ColexNet+}}</tex-math> on roundtrip translation, sentence retrieval and sentence classification and show that our embeddings surpass several transfer learning baselines. This demonstrates the benefits of using colexification as a source of information in multilingual NLP.</abstract>
      <url hash="2231b927">2023.findings-emnlp.562</url>
      <bibkey>liu-etal-2023-crosslingual-transfer</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.562</doi>
    </paper>
    <paper id="563">
      <title>Injecting structural hints: Using language models to study inductive biases in language learning</title>
      <author><first>Isabel</first><last>Papadimitriou</last></author>
      <author><first>Dan</first><last>Jurafsky</last></author>
      <pages>8402-8413</pages>
      <abstract>Both humans and transformer language models are able to learn language without explicit structural supervision. What cognitive inductive biases make this learning possible? Here, we examine the effect of different inductive learning biases by actively controlling the inductive biases of artificial learners: we structurally bias models by pretraining on synthetic formally-structured data, and evaluate these structural biases by fine-tuning on three typologically-distant human languages: English, Japanese, and Basque. We investigate the effect on downstream language perplexity of three types of inductive bias: 1) recursive, hierarchical processing 2) unrestricted token-token dependencies that can’t be modeled by context-free grammars, and 3) a Zipfian power-law vocabulary distribution. We show that complex, non-context-free interactions between tokens form the best inductive biases. Our study leverages the capabilities of transformer models to run controlled language learning experiments that are not possible to run on humans, and surfaces hypotheses about the structures that facilitate language learning in both humans and machines.</abstract>
      <url hash="e8d86429">2023.findings-emnlp.563</url>
      <bibkey>papadimitriou-jurafsky-2023-injecting</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.563</doi>
    </paper>
    <paper id="564">
      <title>Machine Reading Comprehension using Case-based Reasoning</title>
      <author><first>Dung</first><last>Thai</last></author>
      <author><first>Dhruv</first><last>Agarwal</last></author>
      <author><first>Mudit</first><last>Chaudhary</last></author>
      <author><first>Wenlong</first><last>Zhao</last></author>
      <author><first>Rajarshi</first><last>Das</last></author>
      <author><first>Jay-Yoon</first><last>Lee</last></author>
      <author><first>Hannaneh</first><last>Hajishirzi</last></author>
      <author><first>Manzil</first><last>Zaheer</last></author>
      <author><first>Andrew</first><last>McCallum</last></author>
      <pages>8414-8428</pages>
      <abstract>We present an accurate and interpretable method for answer extraction in machine reading comprehension that is reminiscent of case-based reasoning (CBR) from classical AI. Our method (CBR-MRC) builds upon the hypothesis that contextualized answers to similar questions share semantic similarities with each other. Given a test question, CBR-MRC first retrieves a set of similar cases from a nonparametric memory and then predicts an answer by selecting the span in the test context that is most similar to the contextualized representations of answers in the retrieved cases. The semi-parametric nature of our approach allows it to attribute a prediction to the specific set of evidence cases, making it a desirable choice for building reliable and debuggable QA systems. We show that CBR-MRC provides high accuracy comparable with large reader models and outperforms baselines by 11.5 and 8.4 EM on NaturalQuestions and NewsQA, respectively. Further, we demonstrate the ability of CBR-MRC in identifying not just the correct answer tokens but also the span with the most relevant supporting evidence. Lastly, we observe that contexts for certain question types show higher lexical diversity than others and find that CBR-MRC is robust to these variations while performance using fully-parametric methods drops.</abstract>
      <url hash="4cc7aabc">2023.findings-emnlp.564</url>
      <bibkey>thai-etal-2023-machine</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.564</doi>
    </paper>
    <paper id="565">
      <title>Unleashing the Power of Language Models in Text-Attributed Graph</title>
      <author><first>Haoyu</first><last>Kuang</last></author>
      <author><first>Jiarong</first><last>Xu</last></author>
      <author><first>Haozhe</first><last>Zhang</last></author>
      <author><first>Zuyu</first><last>Zhao</last></author>
      <author><first>Qi</first><last>Zhang</last></author>
      <author><first>Xuanjing</first><last>Huang</last></author>
      <author><first>Zhongyu</first><last>Wei</last></author>
      <pages>8429-8441</pages>
      <abstract>Representation learning on graph has been demonstrated to be a powerful tool for solving real-world problems. Text-attributed graph carries both semantic and structural information among different types of graphs. Existing works have paved the way for knowledge extraction of this type of data by leveraging language models or graph neural networks or combination of them. However, these works suffer from issues like underutilization of relationships between nodes or words or unaffordable memory cost. In this paper, we propose a Node Representation Update Pre-training Architecture based on Co-modeling Text and Graph (NRUP). In NRUP, we construct a hierarchical text-attributed graph that incorporates both original nodes and word nodes. Meanwhile, we apply four self-supervised tasks for different level of constructed graph. We further design the pre-training framework to update the features of nodes during training epochs. We conduct the experiment on the benchmark dataset ogbn-arxiv. Our method achieves outperformance compared to baselines, fully demonstrating its validity and generalization.</abstract>
      <url hash="f4ceee4b">2023.findings-emnlp.565</url>
      <bibkey>kuang-etal-2023-unleashing</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.565</doi>
    </paper>
    <paper id="566">
      <title>Locally Differentially Private Document Generation Using Zero Shot Prompting</title>
      <author><first>Saiteja</first><last>Utpala</last></author>
      <author><first>Sara</first><last>Hooker</last></author>
      <author><first>Pin-Yu</first><last>Chen</last></author>
      <pages>8442-8457</pages>
      <abstract>Numerous studies have highlighted the privacy risks associated with large language models. Our research offers a unique perspective by demonstrating that pretrained large language models can effectively contribute to privacy preservation. We propose a locally differentially private mechanism called DP-Prompt, which leverages the power of pretrained large language models and zero-shot prompting to counter author de-anonymization attacks while minimizing the impact on downstream utility. When DP-Prompt is used with a powerful language model like ChatGPT (gpt-3.5), we observe a notable reduction in the success rate of de-anonymization attacks, showing that it surpasses existing approaches by a considerable margin despite its simpler design. For instance, in the case of the IMDB dataset, DP-Prompt (with ChatGPT) perfectly recovers the clean sentiment F1 score while achieving a 46% reduction in author identification F1 score against static attackers and a 26% reduction against adaptive attackers. We conduct extensive experiments across six open-source large language models, ranging up to 7 billion parameters, to analyze various effects of the privacy-utility tradeoff.</abstract>
      <url hash="2833e111">2023.findings-emnlp.566</url>
      <bibkey>utpala-etal-2023-locally</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.566</doi>
    </paper>
    <paper id="567">
      <title>Contrastive Deterministic Autoencoders For Language Modeling</title>
      <author><first>Amur</first><last>Ghose</last></author>
      <author><first>Pascal</first><last>Poupart</last></author>
      <pages>8458-8476</pages>
      <abstract>Variational autoencoders (VAEs) are a popular family of generative models with wide applicability. Training VAEs, especially for text, often runs into the issue of posterior collapse, resulting in loss of representation quality. Deterministic autoencoders avoid this issue, and have been explored particularly well for images. It is however unclear how to best modify a deterministic model designed for images into a successful one for text. We show that with suitable adaptations, we can significantly improve on batch-normed VAEs (BN-VAEs), a strong benchmark for language modeling with VAEs, by replacing them with analogous deterministic models. We employ techniques from contrastive learning to control the entropy of the aggregate posterior of these models to make it Gaussian. The resulting models skip reparametrization steps in VAE modeling and avoid posterior collapse, while outperforming a broad range of VAE models on text generation and downstream tasks from representations. These improvements are shown to be consistent across both LSTM and Transformer-based VAE architectures. Appropriate comparisons to BERT/GPT-2 based results are also included. We also qualitatively examine the latent space through interpolation to supplement the quantitative aspects of the model.</abstract>
      <url hash="fd877aea">2023.findings-emnlp.567</url>
      <bibkey>ghose-poupart-2023-contrastive</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.567</doi>
    </paper>
    <paper id="568">
      <title><fixed-case>CH</fixed-case>i<fixed-case>LL</fixed-case>: Zero-shot Custom Interpretable Feature Extraction from Clinical Notes with Large Language Models</title>
      <author><first>Denis</first><last>McInerney</last></author>
      <author><first>Geoffrey</first><last>Young</last></author>
      <author><first>Jan-Willem</first><last>van de Meent</last></author>
      <author><first>Byron</first><last>Wallace</last></author>
      <pages>8477-8494</pages>
      <abstract>We propose CHiLL (Crafting High-Level Latents), an approach for natural-language specification of features for linear models. CHiLL prompts LLMs with expert-crafted queries to generate interpretable features from health records. The resulting noisy labels are then used to train a simple linear classifier. Generating features based on queries to an LLM can empower physicians to use their domain expertise to craft features that are clinically meaningful for a downstream task of interest, without having to manually extract these from raw EHR. We are motivated by a real-world risk prediction task, but as a reproducible proxy, we use MIMIC-III and MIMIC-CXR data and standard predictive tasks (e.g., 30-day readmission) to evaluate this approach. We find that linear models using automatically extracted features are comparably performant to models using reference features, and provide greater interpretability than linear models using “Bag-of-Words” features. We verify that learned feature weights align well with clinical expectations.</abstract>
      <url hash="8771a209">2023.findings-emnlp.568</url>
      <bibkey>mcinerney-etal-2023-chill</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.568</doi>
    </paper>
    <paper id="569">
      <title>Guiding <fixed-case>LLM</fixed-case> to Fool Itself: Automatically Manipulating Machine Reading Comprehension Shortcut Triggers</title>
      <author><first>Mosh</first><last>Levy</last></author>
      <author><first>Shauli</first><last>Ravfogel</last></author>
      <author><first>Yoav</first><last>Goldberg</last></author>
      <pages>8495-8505</pages>
      <abstract>Recent applications of LLMs in Machine Reading Comprehension (MRC) systems have shown impressive results, but the use of shortcuts, mechanisms triggered by features spuriously correlated to the true label, has emerged as a potential threat to their reliability. We analyze the problem from two angles: LLMs as editors, guided to edit text to mislead LLMs; and LLMs as readers, who answer questions based on the edited text. We introduce a framework that guides an editor to add potential shortcuts-triggers to samples. Using GPT4 as the editor, we find it can successfully edit trigger shortcut in samples that fool LLMs. Analysing LLMs as readers, we observe that even capable LLMs can be deceived using shortcut knowledge. Strikingly, we discover that GPT4 can be deceived by its own edits (15% drop in F1). Our findings highlight inherent vulnerabilities of LLMs to shortcut manipulations. We publish ShortcutQA, a curated dataset generated by our framework for future research.</abstract>
      <url hash="0b858114">2023.findings-emnlp.569</url>
      <bibkey>levy-etal-2023-guiding</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.569</doi>
    </paper>
    <paper id="570">
      <title>Large Language Models Meet Harry Potter: A Dataset for Aligning Dialogue Agents with Characters</title>
      <author><first>Nuo</first><last>Chen</last></author>
      <author><first>Yan</first><last>Wang</last></author>
      <author><first>Haiyun</first><last>Jiang</last></author>
      <author><first>Deng</first><last>Cai</last></author>
      <author><first>Yuhan</first><last>Li</last></author>
      <author><first>Ziyang</first><last>Chen</last></author>
      <author><first>Longyue</first><last>Wang</last></author>
      <author><first>Jia</first><last>Li</last></author>
      <pages>8506-8520</pages>
      <abstract>In recent years, Dialogue-style Large Language Models (LLMs) such as ChatGPT and GPT4 have demonstrated immense potential in constructing open-domain dialogue agents. However, aligning these agents with specific characters or individuals remains a considerable challenge due to the complexities of character representation and the lack of comprehensive annotations. In this paper, we introduce the Harry Potter Dialogue (HPD) dataset, designed to advance the study of dialogue agents and character alignment. The dataset encompasses all dialogue sessions (in both English and Chinese) from the Harry Potter series and is annotated with vital background information, including dialogue scenes, speakers, character relationships, and attributes. These extensive annotations may empower LLMs to unlock character-driven dialogue capabilities. Furthermore, it can serve as a universal benchmark for evaluating how well can a LLM aligning with a specific character. We benchmark LLMs on HPD using both fine-tuning and in-context learning settings. Evaluation results reveal that although there is substantial room for improvement in generating high-quality, character-aligned responses, the proposed dataset is valuable in guiding models toward responses that better align with the character of Harry Potter.</abstract>
      <url hash="c48c71a9">2023.findings-emnlp.570</url>
      <bibkey>chen-etal-2023-large</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.570</doi>
    </paper>
    <paper id="571">
      <title>Quick Back-Translation for Unsupervised Machine Translation</title>
      <author><first>Benjamin</first><last>Brimacombe</last></author>
      <author><first>Jiawei</first><last>Zhou</last></author>
      <pages>8521-8534</pages>
      <abstract>The field of unsupervised machine translation has seen significant advancement from the marriage of the Transformer and the back-translation algorithm. The Transformer is a powerful generative model, and back-translation leverages Transformer’s high-quality translations for iterative self-improvement. However, the Transformer is encumbered by the run-time of autoregressive inference during back-translation, and back-translation is limited by a lack of synthetic data efficiency. We propose a two-for-one improvement to Transformer back-translation: Quick Back-Translation (QBT). QBT re-purposes the encoder as a generative model, and uses encoder-generated sequences to train the decoder in conjunction with the original autoregressive back-translation step, improving data throughput and utilization. Experiments on various WMT benchmarks demonstrate that a relatively small number of refining steps of QBT improve current unsupervised machine translation models, and that QBT dramatically outperforms standard back-translation only method in terms of training efficiency for comparable translation qualities.</abstract>
      <url hash="1f9723be">2023.findings-emnlp.571</url>
      <bibkey>brimacombe-zhou-2023-quick</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.571</doi>
    </paper>
    <paper id="572">
      <title><fixed-case>SIR</fixed-case>-<fixed-case>ABSC</fixed-case>: Incorporating Syntax into <fixed-case>R</fixed-case>o<fixed-case>BERT</fixed-case>a-based Sentiment Analysis Models with a Special Aggregator Token</title>
      <author><first>Ikhyun</first><last>Cho</last></author>
      <author><first>Yoonhwa</first><last>Jung</last></author>
      <author><first>Julia</first><last>Hockenmaier</last></author>
      <pages>8535-8550</pages>
      <abstract>We present a simple, but effective method to incorporate syntactic dependency information directly into transformer-based language models (e.g. RoBERTa) for tasks such as Aspect-Based Sentiment Classification (ABSC), where the desired output depends on specific input tokens. In contrast to prior approaches to ABSC that capture syntax by combining language models with graph neural networks over dependency trees, our model, Syntax-Integrated RoBERTa for ABSC (SIR-ABSC) incorporates syntax directly into the language model by using a novel aggregator token. Yet, SIR-ABSC outperforms these more complex models, yielding new state-of-the-art results on ABSC.</abstract>
      <url hash="3eb7c03c">2023.findings-emnlp.572</url>
      <bibkey>cho-etal-2023-sir</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.572</doi>
    </paper>
    <paper id="573">
      <title>Citance-Contextualized Summarization of Scientific Papers</title>
      <author><first>Shahbaz</first><last>Syed</last></author>
      <author><first>Ahmad</first><last>Hakimi</last></author>
      <author><first>Khalid</first><last>Al-Khatib</last></author>
      <author><first>Martin</first><last>Potthast</last></author>
      <pages>8551-8568</pages>
      <abstract>Current approaches to automatic summarization of scientific papers generate informative summaries in the form of abstracts. However, abstracts are not intended to show the relationship between a paper and the references cited in it. We propose a new contextualized summarization approach that can generate an informative summary conditioned on a given sentence containing the citation of a reference (a so-called “citance”). This summary outlines content of the cited paper relevant to the citation location. Thus, our approach extracts and models the citances of a paper, retrieves relevant passages from cited papers, and generates abstractive summaries tailored to each citance. We evaluate our approach using **Webis-Context-SciSumm-2023**, a new dataset containing 540K computer science papers and 4.6M citances therein.</abstract>
      <url hash="80390b97">2023.findings-emnlp.573</url>
      <bibkey>syed-etal-2023-citance</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.573</doi>
    </paper>
    <paper id="574">
      <title><fixed-case>S</fixed-case>eg<fixed-case>A</fixed-case>ugment: Maximizing the Utility of Speech Translation Data with Segmentation-based Augmentations</title>
      <author><first>Ioannis</first><last>Tsiamas</last></author>
      <author><first>José</first><last>Fonollosa</last></author>
      <author><first>Marta</first><last>Costa-jussà</last></author>
      <pages>8569-8588</pages>
      <abstract>End-to-end Speech Translation is hindered by a lack of available data resources. While most of them are based on documents, a sentence-level version is available, which is however single and static, potentially impeding the usefulness of the data. We propose a new data augmentation strategy, SegAugment, to address this issue by generating multiple alternative sentence-level versions of a dataset. Our method utilizes an Audio Segmentation system, which re-segments the speech of each document with different length constraints, after which we obtain the target text via alignment methods. Experiments demonstrate consistent gains across eight language pairs in MuST-C, with an average increase of 2.5 BLEU points, and up to 5 BLEU for low-resource scenarios in mTEDx. Furthermore, when combined with a strong system, SegAugment obtains state-of-the-art results in MuST-C. Finally, we show that the proposed method can also successfully augment sentence-level datasets, and that it enables Speech Translation models to close the gap between the manual and automatic segmentation at inference time.</abstract>
      <url hash="8ce23080">2023.findings-emnlp.574</url>
      <bibkey>tsiamas-etal-2023-segaugment</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.574</doi>
    </paper>
    <paper id="575">
      <title>Intersectional Stereotypes in Large Language Models: Dataset and Analysis</title>
      <author><first>Weicheng</first><last>Ma</last></author>
      <author><first>Brian</first><last>Chiang</last></author>
      <author><first>Tong</first><last>Wu</last></author>
      <author><first>Lili</first><last>Wang</last></author>
      <author><first>Soroush</first><last>Vosoughi</last></author>
      <pages>8589-8597</pages>
      <abstract>Despite many stereotypes targeting intersectional demographic groups, prior studies on stereotypes within Large Language Models (LLMs) primarily focus on broader, individual categories. This research bridges this gap by introducing a novel dataset of intersectional stereotypes, curated with the assistance of the ChatGPT model and manually validated. Moreover, this paper offers a comprehensive analysis of intersectional stereotype propagation in three contemporary LLMs by leveraging this dataset. The findings underscore the urgency of focusing on intersectional biases in ongoing efforts to reduce stereotype prevalence in LLMs.</abstract>
      <url hash="180f97a1">2023.findings-emnlp.575</url>
      <bibkey>ma-etal-2023-intersectional</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.575</doi>
    </paper>
    <paper id="576">
      <title>Dataset Bias Mitigation in Multiple-Choice Visual Question Answering and Beyond</title>
      <author><first>Zhecan</first><last>Wang</last></author>
      <author><first>Long</first><last>Chen</last></author>
      <author><first>Haoxuan</first><last>You</last></author>
      <author><first>Keyang</first><last>Xu</last></author>
      <author><first>Yicheng</first><last>He</last></author>
      <author><first>Wenhao</first><last>Li</last></author>
      <author><first>Noel</first><last>Codella</last></author>
      <author><first>Kai-Wei</first><last>Chang</last></author>
      <author><first>Shih-Fu</first><last>Chang</last></author>
      <pages>8598-8617</pages>
      <abstract>Vision-language (VL) understanding tasks evaluate models’ comprehension of complex visual scenes through multiple-choice questions. However, we have identified two dataset biases that models can exploit as shortcuts to resolve various VL tasks correctly without proper understanding. The first type of dataset bias is Unbalanced Matching bias, where the correct answer overlaps the question and image more than the incorrect answers. The second type of dataset bias is Distractor Similarity bias, where incorrect answers are overly dissimilar to the correct answer but significantly similar to other incorrect answers within the same sample. To address these dataset biases, we first propose Adversarial Data Synthesis (ADS) to generate synthetic training and debiased evaluation data. We then introduce Intra-sample Counterfactual Training (ICT) to assist models in utilizing the synthesized training data, particularly the counterfactual data, via focusing on intra-sample differentiation. Extensive experiments demonstrate the effectiveness of ADS and ICT in consistently improving model performance across different benchmarks, even in domain-shifted scenarios.</abstract>
      <url hash="73da184d">2023.findings-emnlp.576</url>
      <bibkey>wang-etal-2023-dataset</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.576</doi>
    </paper>
    <paper id="577">
      <title>The Intended Uses of Automated Fact-Checking Artefacts: Why, How and Who</title>
      <author><first>Michael</first><last>Schlichtkrull</last></author>
      <author><first>Nedjma</first><last>Ousidhoum</last></author>
      <author><first>Andreas</first><last>Vlachos</last></author>
      <pages>8618-8642</pages>
      <abstract>Automated fact-checking is often presented as an epistemic tool that fact-checkers, social media consumers, and other stakeholders can use to fight misinformation. Nevertheless, few papers thoroughly discuss <i>how</i>. We document this by analysing 100 highly-cited papers, and annotating epistemic elements related to intended use, i.e., means, ends, and stakeholders. We find that narratives leaving out some of these aspects are common, that many papers propose inconsistent means and ends, and that the feasibility of suggested strategies rarely has empirical backing. We argue that this vagueness actively hinders the technology from reaching its goals, as it encourages overclaiming, limits criticism, and prevents stakeholder feedback. Accordingly, we provide several recommendations for thinking and writing about the use of fact-checking artefacts.</abstract>
      <url hash="83b2ddee">2023.findings-emnlp.577</url>
      <bibkey>schlichtkrull-etal-2023-intended</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.577</doi>
    </paper>
    <paper id="578">
      <title>Retrieval-based Knowledge Transfer: An Effective Approach for Extreme Large Language Model Compression</title>
      <author><first>Jiduan</first><last>Liu</last></author>
      <author><first>Jiahao</first><last>Liu</last></author>
      <author><first>Qifan</first><last>Wang</last></author>
      <author><first>Jingang</first><last>Wang</last></author>
      <author><first>Xunliang</first><last>Cai</last></author>
      <author><first>Dongyan</first><last>Zhao</last></author>
      <author><first>Ran</first><last>Wang</last></author>
      <author><first>Rui</first><last>Yan</last></author>
      <pages>8643-8657</pages>
      <abstract>Large-scale pre-trained language models (LLMs) have demonstrated exceptional performance in various natural language processing (NLP) tasks. However, the massive size of these models poses huge challenges for their deployment in real-world applications. While numerous model compression techniques have been proposed, most of them are not well-suited for achieving extreme model compression when there is a significant gap in model scale. In this paper, we introduce a novel compression paradigm called Retrieval-based Knowledge Transfer (RetriKT), which effectively transfers the knowledge of LLMs to extremely small-scale models (e.g., 1%). In particular, our approach extracts knowledge from LLMs to construct a knowledge store, from which the small-scale model can retrieve relevant information and leverage it for effective inference. To improve the quality of the model, soft prompt tuning and Proximal Policy Optimization (PPO) reinforcement learning techniques are employed. Extensive experiments are conducted on low-resource tasks from SuperGLUE and GLUE benchmarks. The results demonstrate that the proposed approach significantly enhances the performance of small-scale models by leveraging the knowledge from LLMs.</abstract>
      <url hash="4387cddb">2023.findings-emnlp.578</url>
      <bibkey>liu-etal-2023-retrieval</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.578</doi>
    </paper>
    <paper id="579">
      <title><fixed-case>COUNT</fixed-case>: <fixed-case>CO</fixed-case>ntrastive <fixed-case>UN</fixed-case>likelihood Text Style Transfer for Text Detoxification</title>
      <author><first>Mohammad Mahdi Abdollah</first><last>Pour</last></author>
      <author><first>Parsa</first><last>Farinneya</last></author>
      <author><first>Manasa</first><last>Bharadwaj</last></author>
      <author><first>Nikhil</first><last>Verma</last></author>
      <author><first>Ali</first><last>Pesaranghader</last></author>
      <author><first>Scott</first><last>Sanner</last></author>
      <pages>8658-8666</pages>
      <abstract>Offensive and toxic text on social media platforms can lead to polarization and divisiveness within online communities and hinders constructive dialogue. Text detoxification is a crucial task in natural language processing to ensure the generation of non-toxic and safe text. Text detoxification is a special case of the Text Style Transfer (TST) problem, where an input text is rephrased to an output text that preserves its content while modifying the style (in this case to a more neutral, non-toxic style). State-of-the-art methods for detoxification use supervised training of encoder-decoder models to produce gold-standard outputs with a standard likelihood-based objective. However, it can be hard for these models to deviate from their pretrained auto-encoder identity mapping. While previous methods have used unlikelihood-based losses to penalize input-to-output copying of toxic content, these methods also unfortunately penalize non-toxic content in the input that would be fine to preserve in the output. To address these issues, we introduce a novel contrastive unlikelihood objective (COUNT) that directly contrasts the gold standard rephrasing with the identity input-to-output mapping to effectively isolate and focus learning on non-toxic style transfer. We benchmark COUNT on two parallel datasets, ParaDetox and APPDIA, showing that it achieves significant improvements in jointly combined fluency, content preservation, and detoxification (i.e., the highest “J” score).</abstract>
      <url hash="c9f2250b">2023.findings-emnlp.579</url>
      <bibkey>pour-etal-2023-count</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.579</doi>
    </paper>
    <paper id="580">
      <title><fixed-case>KICGPT</fixed-case>: Large Language Model with Knowledge in Context for Knowledge Graph Completion</title>
      <author><first>Yanbin</first><last>Wei</last></author>
      <author><first>Qiushi</first><last>Huang</last></author>
      <author><first>Yu</first><last>Zhang</last></author>
      <author><first>James</first><last>Kwok</last></author>
      <pages>8667-8683</pages>
      <abstract>Knowledge Graph Completion (KGC) is crucial for addressing knowledge graph incompleteness and supporting downstream applications. Many models have been proposed for KGC and they can be categorized into two main classes, including triple-based and test-based approaches. Triple-based methods struggle with long-tail entities due to limited structural information and imbalanced distributions of entities. Text-based methods alleviate this issue but require costly training for language models and specific finetuning for knowledge graphs, which limits their efficiency. To alleviate the limitations in the two approaches, in this paper, we propose KICGPT, a framework that integrates a large language model (LLM) and a triple-based KGC retriever, to alleviate the long-tail problem without incurring additional training overhead. In the proposed KICGPT model, we propose an in-context learning strategy called Knowledge Prompt, which encodes structural knowledge into demonstrations to guide LLM. Empirical results on benchmark datasets demonstrate the effectiveness of the proposed KICGPT model with lighter training overhead and no finetuning.</abstract>
      <url hash="e22a30ee">2023.findings-emnlp.580</url>
      <bibkey>wei-etal-2023-kicgpt</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.580</doi>
    </paper>
    <paper id="581">
      <title>Show, Write, and Retrieve: Entity-aware Article Generation and Retrieval</title>
      <author><first>Zhongping</first><last>Zhang</last></author>
      <author><first>Yiwen</first><last>Gu</last></author>
      <author><first>Bryan</first><last>Plummer</last></author>
      <pages>8684-8704</pages>
      <abstract>Article comprehension is an important challenge in natural language processing with many applications such as article generation or image-to-article retrieval. Prior work typically encodes all tokens in articles uniformly using pretrained language models. However, in many applications, such as understanding news stories, these articles are based on real-world events and may reference many named entities that are difficult to accurately recognize and predict by language models. To address this challenge, we propose an ENtity-aware article GeneratIoN and rEtrieval (ENGINE) framework, to explicitly incorporate named entities into language models. ENGINE has two main components: a named-entity extraction module to extract named entities from both metadata and embedded images associated with articles, and an entity-aware mechanism that enhances the model’s ability to recognize and predict entity names. We conducted experiments on three public datasets: GoodNews, VisualNews, and WikiText, where our results demonstrate that our model can boost both article generation and article retrieval performance, with a 4-5 perplexity improvement in article generation and a 3-4% boost in recall@1 in article retrieval. We release our implementation at [this http URL](https://github.com/Zhongping-Zhang/ENGINE).</abstract>
      <url hash="db730145">2023.findings-emnlp.581</url>
      <bibkey>zhang-etal-2023-show</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.581</doi>
    </paper>
    <paper id="582">
      <title>A Language Model with Limited Memory Capacity Captures Interference in Human Sentence Processing</title>
      <author><first>William</first><last>Timkey</last></author>
      <author><first>Tal</first><last>Linzen</last></author>
      <pages>8705-8720</pages>
      <abstract>Two of the central factors believed to underpin human sentence processing difficulty are expectations and retrieval from working memory. A recent attempt to create a unified cognitive model integrating these two factors have relied on the parallels between the self-attention mechanism of transformer language models and cue-based retrieval theories of working memory in human sentence processing (Ryu and Lewis 2021). While the authors show that attention patterns in specialized attention heads of GPT-2 are consistent with a key prediction of cue-based retrieval models, similarity-based interference effects, their method requires the identification of syntactically specialized attention heads, and makes an cognitively implausible implicit assumption that hundreds of memory retrieval operations take place in parallel. In the present work, we develop a recurrent neural language model with a single self-attention head, which more closely parallels the memory system assumed by cognitive theories. We show that our model’s single attention head can capture semantic and syntactic interference effects observed in human experiments.</abstract>
      <url hash="3738dda0">2023.findings-emnlp.582</url>
      <bibkey>timkey-linzen-2023-language</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.582</doi>
    </paper>
    <paper id="583">
      <title>Annotations Are Not All You Need: A Cross-modal Knowledge Transfer Network for Unsupervised Temporal Sentence Grounding</title>
      <author><first>Xiang</first><last>Fang</last></author>
      <author><first>Daizong</first><last>Liu</last></author>
      <author><first>Wanlong</first><last>Fang</last></author>
      <author><first>Pan</first><last>Zhou</last></author>
      <author><first>Yu</first><last>Cheng</last></author>
      <author><first>Keke</first><last>Tang</last></author>
      <author><first>Kai</first><last>Zou</last></author>
      <pages>8721-8733</pages>
      <abstract>This paper addresses the task of temporal sentence grounding (TSG). Although many respectable works have made decent achievements in this important topic, they severely rely on massive expensive video-query paired annotations, which require a tremendous amount of human effort to collect in real-world applications. To this end, in this paper, we target a more practical but challenging TSG setting: unsupervised temporal sentence grounding, where both paired video-query and segment boundary annotations are unavailable during the network training. Considering that some other cross-modal tasks provide many easily available yet cheap labels, we tend to collect and transfer their simple cross-modal alignment knowledge into our complex scenarios: 1) We first explore the entity-aware object-guided appearance knowledge from the paired Image-Noun task, and adapt them into each independent video frame; 2) Then, we extract the event-aware action representation from the paired Video-Verb task, and further refine the action representation into more practical but complicated real-world cases by a newly proposed copy-paste approach; 3) By modulating and transferring both appearance and action knowledge into our challenging unsupervised task, our model can directly utilize this general knowledge to correlate videos and queries, and accurately retrieve the relevant segment without training. Extensive experiments on two challenging datasets (ActivityNet Captions and Charades-STA) show our effectiveness, outperforming existing unsupervised methods and even competitively beating supervised works.</abstract>
      <url hash="4158eac0">2023.findings-emnlp.583</url>
      <bibkey>fang-etal-2023-annotations</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.583</doi>
    </paper>
    <paper id="584">
      <title>Parameter Efficient Multi-task Fine-tuning by Learning to Transfer Token-wise Prompts</title>
      <author><first>Muling</first><last>Wu</last></author>
      <author><first>Wenhao</first><last>Liu</last></author>
      <author><first>Jianhan</first><last>Xu</last></author>
      <author><first>Changze</first><last>Lv</last></author>
      <author><first>Zixuan</first><last>Ling</last></author>
      <author><first>Tianlong</first><last>Li</last></author>
      <author><first>Longtao</first><last>Huang</last></author>
      <author><first>Xiaoqing</first><last>Zheng</last></author>
      <author><first>Xuanjing</first><last>Huang</last></author>
      <pages>8734-8746</pages>
      <abstract>Prompt tuning has been proven to be successful on various tasks by incorporating a small number of trainable parameters while freezing large pre-trained language models (PLMs). However, it is still unsettled how to generate more proper prompts for any individual examples and how to extend prompt tuning to multi-task learning scenarios by leveraging cross-task features. To address these challenges, we propose a token-wise prompt tuning (TPT), in which a bank of finer-grained soft prompt tokens is built for multi-task learning by memory network. The tokens are retrieved from the bank against an input example and assembled to an instance-dependent prompt. Extensive experimental results on 14 datasets demonstrated that the models enhanced by our TPT performed far better than full parameter fine-tuned models and achieved state-of-the-art by tuning only 0.035% parameters.</abstract>
      <url hash="29bdd9d3">2023.findings-emnlp.584</url>
      <bibkey>wu-etal-2023-parameter</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.584</doi>
    </paper>
    <paper id="585">
      <title>A Rewriting Approach for Gender Inclusivity in <fixed-case>P</fixed-case>ortuguese</title>
      <author><first>Leonor</first><last>Veloso</last></author>
      <author><first>Luisa</first><last>Coheur</last></author>
      <author><first>Rui</first><last>Ribeiro</last></author>
      <pages>8747-8759</pages>
      <abstract>In recent years, there has been a notable rise in research interest regarding the integration of gender-inclusive and gender-neutral language in natural language processing models. A specific area of focus that has gained practical and academic significant interest is gender-neutral rewriting, which involves converting binary-gendered text to its gender-neutral counterpart. However, current approaches to gender-neutral rewriting for gendered languages tend to rely on large datasets, which may not be an option for languages with fewer resources, such as Portuguese. In this paper, we present a rule-based and a neural-based tool for gender-neutral rewriting for Portuguese, a heavily gendered Romance language whose morphology creates different challenges from the ones tackled by other gender-neutral rewriters. Our neural approach relies on fine-tuning large multilingual machine translation models on examples generated by the rule-based model. We evaluate both models on texts from different sources and contexts. We provide the first Portuguese dataset explicitly containing gender-neutral language and neopronouns, as well as a manually annotated golden collection of 500 sentences that allows for evaluation of future work.</abstract>
      <url hash="d16996e3">2023.findings-emnlp.585</url>
      <bibkey>veloso-etal-2023-rewriting</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.585</doi>
    </paper>
    <paper id="586">
      <title><fixed-case>EARA</fixed-case>: Improving Biomedical Semantic Textual Similarity with Entity-Aligned Attention and Retrieval Augmentation</title>
      <author><first>Ying</first><last>Xiong</last></author>
      <author><first>Xin</first><last>Yang</last></author>
      <author><first>Linjing</first><last>Liu</last></author>
      <author><first>Ka-Chun</first><last>Wong</last></author>
      <author><first>Qingcai</first><last>Chen</last></author>
      <author><first>Yang</first><last>Xiang</last></author>
      <author><first>Buzhou</first><last>Tang</last></author>
      <pages>8760-8771</pages>
      <abstract>Measuring Semantic Textual Similarity (STS) is a fundamental task in biomedical text processing, which aims at quantifying the similarity between two input biomedical sentences. Unfortunately, the STS datasets in the biomedical domain are relatively smaller but more complex in semantics than common domain, often leading to overfitting issues and insufficient text representation even based on Pre-trained Language Models (PLMs) due to too many biomedical entities. In this paper, we propose EARA, an entity-aligned, attention-based and retrieval-augmented PLMs. Our proposed EARA first aligns the same type of fine-grained entity information in each sentence pair with an entity alignment matrix. Then, EARA regularizes the attention mechanism with an entity alignment matrix with an auxiliary loss. Finally, we add a retrieval module that retrieves similar instances to expand the scope of entity pairs and improve the model’s generalization. The comprehensive experiments reflect that EARA can achieve state-of-the-art performance on both in-domain and out-of-domain datasets. Source code is available.</abstract>
      <url hash="672542b1">2023.findings-emnlp.586</url>
      <bibkey>xiong-etal-2023-eara</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.586</doi>
    </paper>
    <paper id="587">
      <title>Neuro-Symbolic Sentiment Analysis with Dynamic Word Sense Disambiguation</title>
      <author><first>Xulang</first><last>Zhang</last></author>
      <author><first>Rui</first><last>Mao</last></author>
      <author><first>Kai</first><last>He</last></author>
      <author><first>Erik</first><last>Cambria</last></author>
      <pages>8772-8783</pages>
      <abstract>Sentiment analysis is a task that highly depends on the understanding of word senses. Traditional neural network models are black boxes that represent word senses as vectors that are uninterpretable for humans. On the other hand, the application of Word Sense Disambiguation (WSD) systems in downstream tasks poses challenges regarding i) which words need to be disambiguated, and ii) how to model explicit word senses into easily understandable terms for a downstream model. This work proposes a neurosymbolic framework that incorporates WSD by identifying and paraphrasing ambiguous words to improve the accuracy of sentiment predictions. The framework allows us to understand which words are paraphrased into which semantically unequivocal words, thus enabling a downstream task model to gain both accuracy and interpretability. To better fine-tune a lexical substitution model for WSD on a downstream task without ground-truth word sense labels, we leverage dynamic rewarding to jointly train sentiment analysis and lexical substitution models. Our framework proves to effectively improve the performance of sentiment analysis on corpora from different domains.</abstract>
      <url hash="7286f1f5">2023.findings-emnlp.587</url>
      <bibkey>zhang-etal-2023-neuro</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.587</doi>
    </paper>
    <paper id="588">
      <title>Role of Context in Unsupervised Sentence Representation Learning: the Case of Dialog Act Modeling</title>
      <author><first>Rastislav</first><last>Hronsky</last></author>
      <author><first>Emmanuel</first><last>Keuleers</last></author>
      <pages>8784-8792</pages>
      <abstract>Unsupervised learning of word representations involves capturing the contextual information surrounding word occurrences, which can be grounded in the observation that word form is largely disconnected from word meaning. While there are fewer reasons to believe that the same holds for sentences, learning through context has been carried over to learning representations of word sequences. However, this work pays minimal to no attention to the role of context in inferring sentence representations. In this article, we present a dialog act tag probing task designed to explicitly compare content-, and context-oriented sentence representations inferred on utterances of telephone conversations (SwDA). Our results suggest that there is no clear benefit of context-based sentence representations over content-based sentence representations. However, there is a very clear benefit of increasing the dimensionality of the sentence vectors in nearly all approaches.</abstract>
      <url hash="e8432294">2023.findings-emnlp.588</url>
      <bibkey>hronsky-keuleers-2023-role</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.588</doi>
    </paper>
    <paper id="589">
      <title><fixed-case>CLMSM</fixed-case>: A Multi-Task Learning Framework for Pre-training on Procedural Text</title>
      <author><first>Abhilash</first><last>Nandy</last></author>
      <author><first>Manav</first><last>Kapadnis</last></author>
      <author><first>Pawan</first><last>Goyal</last></author>
      <author><first>Niloy</first><last>Ganguly</last></author>
      <pages>8793-8806</pages>
      <abstract>In this paper, we propose ***CLMSM***, a domain-specific, continual pre-training framework, that learns from a large set of procedural recipes. ***CLMSM*** uses a Multi-Task Learning Framework to optimize two objectives - a) Contrastive Learning using hard triplets to learn fine-grained differences across entities in the procedures, and b) a novel Mask-Step Modelling objective to learn step-wise context of a procedure. We test the performance of ***CLMSM*** on the downstream tasks of tracking entities and aligning actions between two procedures on three datasets, one of which is an open-domain dataset not conforming with the pre-training dataset. We show that ***CLMSM*** not only outperforms baselines on recipes (in-domain) but is also able to generalize to open-domain procedural NLP tasks.</abstract>
      <url hash="72fced69">2023.findings-emnlp.589</url>
      <bibkey>nandy-etal-2023-clmsm</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.589</doi>
    </paper>
    <paper id="590">
      <title>Open-source Large Language Models are Strong Zero-shot Query Likelihood Models for Document Ranking</title>
      <author><first>Shengyao</first><last>Zhuang</last></author>
      <author><first>Bing</first><last>Liu</last></author>
      <author><first>Bevan</first><last>Koopman</last></author>
      <author><first>Guido</first><last>Zuccon</last></author>
      <pages>8807-8817</pages>
      <abstract>In the field of information retrieval, Query Likelihood Models (QLMs) rank documents based on the probability of generating the query given the content of a document. Recently, advanced large language models (LLMs) have emerged as effective QLMs, showcasing promising ranking capabilities. This paper focuses on investigating the genuine zero-shot ranking effectiveness of recent LLMs, which are solely pre-trained on unstructured text data without supervised instruction fine-tuning. Our findings reveal the robust zero-shot ranking ability of such LLMs, highlighting that additional instruction fine-tuning may hinder effectiveness unless a question generation task is present in the fine-tuning dataset. Furthermore, we introduce a novel state-of-the-art ranking system that integrates LLM-based QLMs with a hybrid zero-shot retriever, demonstrating exceptional effectiveness in both zero-shot and few-shot scenarios. We make our codebase publicly available at https://github.com/ielab/llm-qlm.</abstract>
      <url hash="9cb42642">2023.findings-emnlp.590</url>
      <bibkey>zhuang-etal-2023-open</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.590</doi>
    </paper>
    <paper id="591">
      <title>On General Language Understanding</title>
      <author><first>David</first><last>Schlangen</last></author>
      <pages>8818-8825</pages>
      <abstract>Natural Language Processing prides itself to be an empirically-minded, if not outright empiricist field, and yet lately it seems to get itself into essentialist debates on issues of meaning and measurement (“Do Large Language Models Understand Language, And If So, How Much?”). This is not by accident: Here, as everywhere, the evidence underspecifies the understanding. As a remedy, this paper sketches the outlines of a model of understanding, which can ground questions of the adequacy of current methods of measurement of model quality. The paper makes three claims: A) That different language use situation types have different characteristics, B) That language understanding is a multifaceted phenomenon, bringing together individualistic and social processes, and C) That the choice of Understanding Indicator marks the limits of benchmarking, and the beginnings of considerations of the ethics of NLP use.</abstract>
      <url hash="7f33ce5c">2023.findings-emnlp.591</url>
      <bibkey>schlangen-2023-general</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.591</doi>
    </paper>
    <paper id="592">
      <title><fixed-case>USB</fixed-case>: A Unified Summarization Benchmark Across Tasks and Domains</title>
      <author><first>Kundan</first><last>Krishna</last></author>
      <author><first>Prakhar</first><last>Gupta</last></author>
      <author><first>Sanjana</first><last>Ramprasad</last></author>
      <author><first>Byron</first><last>Wallace</last></author>
      <author><first>Jeffrey</first><last>Bigham</last></author>
      <author><first>Zachary</first><last>Lipton</last></author>
      <pages>8826-8845</pages>
      <abstract>While the NLP community has produced numerous summarization benchmarks, none provide the rich annotations required to simultaneously address many important problems related to control and reliability. We introduce a Wikipedia-derived benchmark, complemented by a rich set of crowd-sourced annotations, that supports 8 interrelated tasks: (i) extractive summarization; (ii) abstractive summarization; (iii) topic-based summarization; (iv) compressing selected sentences into a one-line summary; (v) surfacing evidence for a summary sentence; (vi) predicting the factual accuracy of a summary sentence; (vii) identifying unsubstantiated spans in a summary sentence; (viii) correcting factual errors in summaries. We compare various methods on this benchmark and discover that on multiple tasks, moderately-sized fine-tuned models consistently outperform much larger few-shot prompted language models. For factuality-related tasks, we also evaluate existing heuristics to create training data and find that training on them results in worse performance than training on <tex-math>20\times</tex-math> less human-labeled data. Our articles draw from 6 domains, facilitating cross-domain analysis. On some tasks, the amount of training data matters more than the domain where it comes from, while for other tasks training specifically on data from the target domain, even if limited, is more beneficial.</abstract>
      <url hash="003b801f">2023.findings-emnlp.592</url>
      <bibkey>krishna-etal-2023-usb</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.592</doi>
    </paper>
    <paper id="593">
      <title>tag<fixed-case>E</fixed-case>: Enabling an Embodied Agent to Understand Human Instructions</title>
      <author><first>Chayan</first><last>Sarkar</last></author>
      <author><first>Avik</first><last>Mitra</last></author>
      <author><first>Pradip</first><last>Pramanick</last></author>
      <author><first>Tapas</first><last>Nayak</last></author>
      <pages>8846-8857</pages>
      <abstract>Natural language serves as the primary mode of communication when an intelligent agent with a physical presence engages with human beings. While a plethora of research focuses on natural language understanding (NLU), encompassing endeavors such as sentiment analysis, intent prediction, question answering, and summarization, the scope of NLU directed at situations necessitating tangible actions by an embodied agent remains limited. The inherent ambiguity and incompleteness inherent in natural language present challenges for intelligent agents striving to decipher human intention. To tackle this predicament head-on, we introduce a novel system known as task and argument grounding for Embodied agents (tagE). At its core, our system employs an inventive neural network model designed to extract a series of tasks from complex task instructions expressed in natural language. Our proposed model adopts an encoder-decoder framework enriched with nested decoding to effectively extract tasks and their corresponding arguments from these intricate instructions. These extracted tasks are then mapped (or grounded) to the robot’s established collection of skills, while the arguments find grounding in objects present within the environment. To facilitate the training and evaluation of our system, we have curated a dataset featuring complex instructions. The results of our experiments underscore the prowess of our approach, as it outperforms robust baseline models.</abstract>
      <url hash="d2d983e5">2023.findings-emnlp.593</url>
      <bibkey>sarkar-etal-2023-tage</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.593</doi>
    </paper>
    <paper id="594">
      <title>Instances and Labels: Hierarchy-aware Joint Supervised Contrastive Learning for Hierarchical Multi-Label Text Classification</title>
      <author><first>Simon Chi Lok</first><last>Yu</last></author>
      <author><first>Jie</first><last>He</last></author>
      <author><first>Victor</first><last>Basulto</last></author>
      <author><first>Jeff</first><last>Pan</last></author>
      <pages>8858-8875</pages>
      <abstract>Hierarchical multi-label text classification (HMTC) aims at utilizing a label hierarchy in multi-label classification. Recent approaches to HMTC deal with the problem of imposing an overconstrained premise on the output space by using contrastive learning on generated samples in a semi-supervised manner to bring text and label embeddings closer. However, the generation of samples tends to introduce noise as it ignores the correlation between similar samples in the same batch. One solution to this issue is supervised contrastive learning, but it remains an underexplored topic in HMTC due to its complex structured labels. To overcome this challenge, we propose **HJCL**, a **H**ierarchy-aware **J**oint Supervised **C**ontrastive **L**earning method that bridges the gap between supervised contrastive learning and HMTC. Specifically, we employ both instance-wise and label-wise contrastive learning techniques and carefully construct batches to fulfill the contrastive learning objective. Extensive experiments on four multi-path HMTC datasets demonstrate that HJCLachieves promising results and the effectiveness of Contrastive Learning on HMTC. Code and data are available at https://github.com/simonucl/HJCL.</abstract>
      <url hash="927a1be9">2023.findings-emnlp.594</url>
      <bibkey>yu-etal-2023-instances</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.594</doi>
    </paper>
    <paper id="595">
      <title>Uncovering Limitations in Text-to-Image Generation: A Contrastive Approach with Structured Semantic Alignment</title>
      <author><first>Qianyu</first><last>Feng</last></author>
      <author><first>Yulei</first><last>Sui</last></author>
      <author><first>Hongyu</first><last>Zhang</last></author>
      <pages>8876-8888</pages>
      <abstract>Despite significant advancements in text-to-image generation models, they still face challenges when it comes to producing highly detailed or complex images based on textual descriptions. In order to explore these limitations, we propose a Structured Semantic Alignment (SSA) method for evaluating text-to-image generation models. SSA focuses on learning structured semantic embeddings across different modalities and aligning them in a joint space. The method employs the following steps to achieve its objective: (i) Generating mutated prompts by substituting words with semantically equivalent or nonequivalent alternatives while preserving the original syntax; (ii) Representing the sentence structure through parsing trees obtained via syntax parsing; (iii) Learning fine-grained structured embeddings that project semantic features from different modalities into a shared embedding space; (iv) Evaluating the semantic consistency between the structured text embeddings and the corresponding visual embeddings. Through experiments conducted on various benchmarks, we have demonstrated that SSA offers improved measurement of semantic consistency of text-to-image generation models. Additionally, it unveils a wide range of generation errors including under-generation, incorrect constituency, incorrect dependency, and semantic confusion. By uncovering these biases and limitations embedded within the models, our proposed method provides valuable insights into their shortcomings when applied to real-world scenarios.</abstract>
      <url hash="e1713449">2023.findings-emnlp.595</url>
      <bibkey>feng-etal-2023-uncovering</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.595</doi>
    </paper>
    <paper id="596">
      <title>An Intent-based and Annotation-free Method for Duplicate Question Detection in <fixed-case>CQA</fixed-case> Forums</title>
      <author><first>Yubo</first><last>Shu</last></author>
      <author><first>Hansu</first><last>Gu</last></author>
      <author><first>Peng</first><last>Zhang</last></author>
      <author><first>Tun</first><last>Lu</last></author>
      <author><first>Ning</first><last>Gu</last></author>
      <pages>8889-8899</pages>
      <abstract>With the advent of large language models (LLMs), Community Question Answering (CQA) forums offer well-curated questions and answers that can be utilized for instruction-tuning, effectively training LLMs to be aligned with human intents. However, the issue of duplicate questions arises as the volume of content within CQA continues to grow, posing a threat to content quality. Recent research highlights the benefits of detecting and eliminating duplicate content. It not only enhances the LLMs’ ability to generalize across diverse intents but also improves the efficiency of training data utilization while addressing concerns related to information leakage. However, existing methods for detecting duplicate questions in CQA typically rely on generic text-pair matching models, overlooking the intent behind the questions. In this paper, we propose a novel intent-based duplication detector named Intent-DQD that comprehensively leverages intent information to address the problem of duplicate question detection in CQA. Intent-DQD first leverages the characteristics in CQA forums and extracts training labels to recognize and match intents without human annotation. Intent-DQD then effectively aggregates intent-level relations and establishes question-level relations to enable intent-aware duplication detection. Experimental results on fifteen distinct domains from both CQADupStack and Stack Overflow datasets demonstrate the effectiveness of Intent-DQD. Reproducible codes and datasets will be released upon publication of the paper.</abstract>
      <url hash="2ce3e57d">2023.findings-emnlp.596</url>
      <bibkey>shu-etal-2023-intent</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.596</doi>
    </paper>
    <paper id="597">
      <title>Accelerating Multiple Intent Detection and Slot Filling via Targeted Knowledge Distillation</title>
      <author><first>Xuxin</first><last>Cheng</last></author>
      <author><first>Zhihong</first><last>Zhu</last></author>
      <author><first>Wanshi</first><last>Xu</last></author>
      <author><first>Yaowei</first><last>Li</last></author>
      <author><first>Hongxiang</first><last>Li</last></author>
      <author><first>Yuexian</first><last>Zou</last></author>
      <pages>8900-8910</pages>
      <abstract>Recent non-autoregressive Spoken Language Understanding (SLU) models have attracted increasing attention because of their encouraging inference speed. However, most of existing methods (1) suffer from the multi-modality problem since they have little prior knowledge about the reference during inference; (2) fail to achieve a satisfactory inference speed limited by their complex frameworks. To tackle these issues, in this paper, we propose a <tex-math>\textbf{T}</tex-math>argeted <tex-math>\textbf{K}</tex-math>nowledge <tex-math>\textbf{D}</tex-math>istillation <tex-math>\textbf{F}</tex-math>ramework (TKDF) for multi-intent SLU, which utilizes the knowledge distillation method to improve the performance. Specifically, we first train an SLU model as the teacher model, which has higher accuracy while slower inference speed. Then we introduce an evaluator and apply a curriculum learning strategy to select proper targets for the student model. Experiment results on two public multi-intent datasets show that our approach can realize a flexible trade-off between inference speed and accuracy, achieving comparable performance to the state-of-the-art models while speeding up by over 4.5 times. More encouragingly, further analysis shows that distilling only 4% of the original data can help the student model outperform its counterpart trained on the original data by about 14.6% in terms of overall accuracy on MixATIS dataset.</abstract>
      <url hash="38008b68">2023.findings-emnlp.597</url>
      <bibkey>cheng-etal-2023-accelerating</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.597</doi>
    </paper>
    <paper id="598">
      <title>Type-Aware Decomposed Framework for Few-Shot Named Entity Recognition</title>
      <author><first>Yongqi</first><last>Li</last></author>
      <author><first>Yu</first><last>Yu</last></author>
      <author><first>Tieyun</first><last>Qian</last></author>
      <pages>8911-8927</pages>
      <abstract>Despite the recent success achieved by several two-stage prototypical networks in few-shot named entity recognition (NER) task, the over-detected false spans at span detection stage and the inaccurate and unstable prototypes at type classification stage remain to be challenging problems. In this paper, we propose a novel Type-Aware Decomposed framework, namely TadNER, to solve these problems. We first present a type-aware span filtering strategy to filter out false spans by removing those semantically far away from type names. We then present a type-aware contrastive learning strategy to construct more accurate and stable prototypes by jointly exploiting support samples and type names as references. Extensive experiments on various benchmarks prove that our proposed TadNER framework yields a new state-of-the-art performance.</abstract>
      <url hash="9aa7c265">2023.findings-emnlp.598</url>
      <bibkey>li-etal-2023-type-aware</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.598</doi>
    </paper>
    <paper id="599">
      <title>A Closer Look into Using Large Language Models for Automatic Evaluation</title>
      <author><first>Cheng-Han</first><last>Chiang</last></author>
      <author><first>Hung-yi</first><last>Lee</last></author>
      <pages>8928-8942</pages>
      <abstract>Using large language models (LLMs) to evaluate text quality has recently gained popularity. Some existing prior works explore the idea of using LLMs for evaluation, while they differ in some details of the evaluation process. In this paper, we analyze *LLM evaluation* and *G-Eval*, and we discuss how those details in the evaluation process change how well the ratings given by LLMs correlate with human ratings. We find that the auto Chain-of-Thought (CoT) used in G-Eval does not always make G-Eval more aligned with human ratings. We also show that forcing the LLM to output only a numeric rating, as in G-Eval, is suboptimal. Last, we reveal that asking the LLM to explain its own ratings consistently improves the correlation between the ChatGPT and human ratings and pushes state-of-the-art (SoTA) correlations on two meta-evaluation datasets.</abstract>
      <url hash="d7c9f088">2023.findings-emnlp.599</url>
      <bibkey>chiang-lee-2023-closer</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.599</doi>
    </paper>
    <paper id="600">
      <title>Connecting the Dots: What Graph-Based Text Representations Work Best for Text Classification using Graph Neural Networks?</title>
      <author><first>Margarita</first><last>Bugueño</last></author>
      <author><first>Gerard</first><last>de Melo</last></author>
      <pages>8943-8960</pages>
      <abstract>Given the success of Graph Neural Networks (GNNs) for structure-aware machine learning, many studies have explored their use for text classification, but mostly in specific domains with limited data characteristics. Moreover, some strategies prior to GNNs relied on graph mining and classical machine learning, making it difficult to assess their effectiveness in modern settings. This work extensively investigates graph representation methods for text classification, identifying practical implications and open challenges. We compare different graph construction schemes using a variety of GNN architectures and setups across five datasets, encompassing short and long documents as well as unbalanced scenarios in diverse domains. Two Transformer-based large language models are also included to complement the study. The results show that i) although the effectiveness of graphs depends on the textual input features and domain, simple graph constructions perform better the longer the documents are, ii) graph representations are especially beneficial for longer documents, outperforming Transformer-based models, iii) graph methods are particularly efficient for solving the task.</abstract>
      <url hash="aae5a56f">2023.findings-emnlp.600</url>
      <bibkey>bugueno-de-melo-2023-connecting</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.600</doi>
    </paper>
    <paper id="601">
      <title>Natural Language Annotations for Reasoning about Program Semantics</title>
      <author><first>Marco</first><last>Zocca</last></author>
      <pages>8961-8966</pages>
      <abstract>By grounding natural language inference in code (and vice versa), researchers aim to create programming assistants that explain their work, are “coachable” and can surface any gaps in their reasoning. Can we deduce automatically interesting properties of programs from their syntax and common-sense annotations alone, without resorting to static analysis? How much of program logic and behaviour can be captured in natural language? To stimulate research in this direction and attempt to answer these questions we propose HTL, a dataset and protocol for annotating programs with natural language predicates at a finer granularity than code comments and without relying on internal compiler representations. The dataset is available at the following address: https://doi.org/10.5281/zenodo.7893113 .</abstract>
      <url hash="fdcb8f1f">2023.findings-emnlp.601</url>
      <bibkey>zocca-2023-natural</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.601</doi>
    </paper>
    <paper id="602">
      <title>Pre-trained Speech Processing Models Contain Human-Like Biases that Propagate to Speech Emotion Recognition</title>
      <author><first>Isaac</first><last>Slaughter</last></author>
      <author><first>Craig</first><last>Greenberg</last></author>
      <author><first>Reva</first><last>Schwartz</last></author>
      <author><first>Aylin</first><last>Caliskan</last></author>
      <pages>8967-8989</pages>
      <abstract>Previous work has established that a person’s demographics and speech style affect how well speech processing models perform for them. But where does this bias come from? In this work, we present the Speech Embedding Association Test (SpEAT), a method for detecting bias in one type of model used for many speech tasks: pre-trained models. The SpEAT is inspired by word embedding association tests in natural language processing, which quantify intrinsic bias in a model’s representations of different concepts, such as race or valence—something’s pleasantness or unpleasantness—and capture the extent to which a model trained on large-scale socio-cultural data has learned human-like biases. Using the SpEAT, we test for six types of bias in 16 English speech models (including 4 models also trained on multilingual data), which come from the wav2vec 2.0, HuBERT, WavLM, and Whisper model families. We find that 14 or more models reveal positive valence (pleasantness) associations with abled people over disabled people, with European-Americans over African-Americans, with females over males, with U.S. accented speakers over non-U.S. accented speakers, and with younger people over older people. Beyond establishing that pre-trained speech models contain these biases, we also show that they can have real world effects. We compare biases found in pre-trained models to biases in downstream models adapted to the task of Speech Emotion Recognition (SER) and find that in 66 of the 96 tests performed (69%), the group that is more associated with positive valence as indicated by the SpEAT also tends to be predicted as speaking with higher valence by the downstream model. Our work provides evidence that, like text and image-based models, pre-trained speech based-models frequently learn human-like biases when trained on large-scale socio-cultural datasets. Our work also shows that bias found in pre-trained models can propagate to the downstream task of SER.</abstract>
      <url hash="c17db80d">2023.findings-emnlp.602</url>
      <bibkey>slaughter-etal-2023-pre</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.602</doi>
    </paper>
    <paper id="603">
      <title>Text Classification via Large Language Models</title>
      <author><first>Xiaofei</first><last>Sun</last></author>
      <author><first>Xiaoya</first><last>Li</last></author>
      <author><first>Jiwei</first><last>Li</last></author>
      <author><first>Fei</first><last>Wu</last></author>
      <author><first>Shangwei</first><last>Guo</last></author>
      <author><first>Tianwei</first><last>Zhang</last></author>
      <author><first>Guoyin</first><last>Wang</last></author>
      <pages>8990-9005</pages>
      <abstract>Despite the remarkable success of large-scale Language Models (LLMs) such as GPT-3, their performances still significantly underperform fine-tuned models in the task of text classification.This is due to (1) the lack of reasoning ability in addressing complex linguistic phenomena (e.g., intensification, contrast, irony etc); (2) limited number of tokens allowed in in-context learning. In this paper, we introduce <b>C</b>lue <b>A</b>nd <b>R</b>easoning <b>P</b>rompting (CARP). CARP adopts a progressive reasoning strategy tailored to addressing the complex linguistic phenomena involved in text classification: CARP first prompts LLMs to find superficial clues (e.g., keywords, tones, semantic relations, references, etc), based on which a diagnostic reasoning process is induced for final decisions. To further address the limited-token issue, CARP uses a fine-tuned model on the supervised dataset for <tex-math>k</tex-math>NN demonstration search in the in-context learning, allowing the model to take the advantage of both LLM’s generalization ability and the task-specific evidence provided by the full labeled dataset. Remarkably, CARP yields new SOTA performances on 4 out of 5 widely-used text-classification benchmarks, 97.39 (+1.24) on SST-2, 96.40 (+0.72) on AGNews, 98.78 (+0.25) on R8 and 96.95 (+0.6) on R52, and a performance comparable to SOTA on MR (92.39 v.s. 93.3). More importantly, we find that CARP delivers impressive abilities on low-resource and domain-adaptation setups. Specifically, using 16 examples per class, CARP achieves comparable performances to supervised models with 1,024 examples per class.</abstract>
      <url hash="448f46d7">2023.findings-emnlp.603</url>
      <bibkey>sun-etal-2023-text</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.603</doi>
    </paper>
    <paper id="604">
      <title>On Task-personalized Multimodal Few-shot Learning for Visually-rich Document Entity Retrieval</title>
      <author><first>Jiayi</first><last>Chen</last></author>
      <author><first>Hanjun</first><last>Dai</last></author>
      <author><first>Bo</first><last>Dai</last></author>
      <author><first>Aidong</first><last>Zhang</last></author>
      <author><first>Wei</first><last>Wei</last></author>
      <pages>9006-9025</pages>
      <abstract>Visually-rich document entity retrieval (VDER), which extracts key information (e.g. date, address) from document images like invoices and receipts, has become an important topic in industrial NLP applications. The emergence of new document types at a constant pace, each with its unique entity types, presents a unique challenge: many documents contain unseen entity types that occur only a couple of times. Addressing this challenge requires models to have the ability of learning entities in a few-shot manner. However, prior works for Few-shot VDER mainly address the problem at the document level with a predefined global entity space, which doesn’t account for the entity-level few-shot scenario: target entity types are locally personalized by each task and entity occurrences vary significantly among documents. To address this unexplored scenario, this paper studies a novel entity-level few-shot VDER task. The challenges lie in the uniqueness of the label space for each task and the increased complexity of out-of-distribution (OOD) contents. To tackle this novel task, we present a task-aware meta-learning based framework, with a central focus on achieving effective task personalization that distinguishes between in-task and out-of-task distribution. Specifically, we adopt a hierarchical decoder (HC) and employ contrastive learning (ContrastProtoNet) to achieve this goal. Furthermore, we introduce a new dataset, FewVEX, to boost future research in the field of entity-level few-shot VDER. Experimental results demonstrate our approaches significantly improve the robustness of popular meta-learning baselines.</abstract>
      <url hash="4f159b99">2023.findings-emnlp.604</url>
      <bibkey>chen-etal-2023-task</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.604</doi>
    </paper>
    <paper id="605">
      <title>Semi-Structured Object Sequence Encoders</title>
      <author><first>Rudra</first><last>Murthy</last></author>
      <author><first>Riyaz</first><last>Bhat</last></author>
      <author><first>Chulaka</first><last>Gunasekara</last></author>
      <author><first>Siva</first><last>Patel</last></author>
      <author><first>Hui</first><last>Wan</last></author>
      <author><first>Tejas</first><last>Dhamecha</last></author>
      <author><first>Danish</first><last>Contractor</last></author>
      <author><first>Marina</first><last>Danilevsky</last></author>
      <pages>9026-9039</pages>
      <abstract>In this paper we explore the task of modeling semi-structured object sequences; in particular, we focus our attention on the problem of developing a structure-aware input representation for such sequences. Examples of such data include user activity on websites, machine logs, and many others. This type of data is often represented as a sequence of sets of key-value pairs over time and can present modeling challenges due to an ever-increasing sequence length. We propose a two-part approach, which first considers each key independently and encodes a representation of its values over time; we then self-attend over these value-aware key representations to accomplish a downstream task. This allows us to operate on longer object sequences than existing methods. We introduce a novel shared-attention-head architecture between the two modules and present an innovative training schedule that interleaves the training of both modules with shared weights for some attention heads. Our experiments on multiple prediction tasks using real-world data demonstrate that our approach outperforms a unified network with hierarchical encoding, as well as other methods including a <i>record-centric</i> representation and a <i>flattened</i> representation of the sequence.</abstract>
      <url hash="d1dbbe40">2023.findings-emnlp.605</url>
      <bibkey>murthy-etal-2023-semi</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.605</doi>
    </paper>
    <paper id="606">
      <title><fixed-case>D</fixed-case>e<fixed-case>T</fixed-case>i<fixed-case>ME</fixed-case>: Diffusion-Enhanced Topic Modeling using Encoder-decoder based <fixed-case>LLM</fixed-case></title>
      <author><first>Weijie</first><last>Xu</last></author>
      <author><first>Wenxiang</first><last>Hu</last></author>
      <author><first>Fanyou</first><last>Wu</last></author>
      <author><first>Srinivasan</first><last>Sengamedu</last></author>
      <pages>9040-9057</pages>
      <abstract>In the burgeoning field of natural language processing, Neural Topic Models (NTMs) and Large Language Models (LLMs) have emerged as areas of significant research interest. Despite this, NTMs primarily utilize contextual embeddings from LLMs, which are not optimal for clustering or capable for topic generation. Our study addresses this gap by introducing a novel framework named Diffusion-Enhanced Topic Modeling using Encoder-Decoder-based LLMs (DeTiME). DeTiME leverages Encoder-Decoder-based LLMs to produce highly clusterable embeddings that could generate topics that exhibit both superior clusterability and enhanced semantic coherence compared to existing methods. Additionally, by exploiting the power of diffusion, our framework also provides the capability to generate content relevant to the identified topics. This dual functionality allows users to efficiently produce highly clustered topics and related content simultaneously. DeTiME’s potential extends to generating clustered embeddings as well. Notably, our proposed framework proves to be efficient to train and exhibits high adaptability, demonstrating its potential for a wide array of applications.</abstract>
      <url hash="f8b4f5d2">2023.findings-emnlp.606</url>
      <bibkey>xu-etal-2023-detime</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.606</doi>
    </paper>
    <paper id="607">
      <title>Energy and Carbon Considerations of Fine-Tuning <fixed-case>BERT</fixed-case></title>
      <author><first>Xiaorong</first><last>Wang</last></author>
      <author><first>Clara</first><last>Na</last></author>
      <author><first>Emma</first><last>Strubell</last></author>
      <author><first>Sorelle</first><last>Friedler</last></author>
      <author><first>Sasha</first><last>Luccioni</last></author>
      <pages>9058-9069</pages>
      <abstract>Despite the popularity of the pre-train then fine-tune paradigm in the NLP community, existing work quantifying energy costs and associated carbon emissions has largely focused on language model pre-training. Although a single pre-training run draws substantially more energy than fine-tuning, fine-tuning is performed more frequently by many more individual actors, and thus must be accounted for when considering the energy and carbon footprint of NLP. In order to better characterize the role of fine-tuning in the landscape of energy and carbon emissions in NLP, we perform a careful empirical study of the computational costs of fine-tuning across tasks, datasets, hardware infrastructure and measurement modalities. Our experimental results allow us to place fine-tuning energy and carbon costs into perspective with respect to pre-training and inference, and outline recommendations to NLP researchers and practitioners who wish to improve their fine-tuning energy efficiency.</abstract>
      <url hash="23e3981c">2023.findings-emnlp.607</url>
      <bibkey>wang-etal-2023-energy</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.607</doi>
    </paper>
    <paper id="608">
      <title>Democratizing <fixed-case>LLM</fixed-case>s: An Exploration of Cost-Performance Trade-offs in Self-Refined Open-Source Models</title>
      <author><first>Sumuk</first><last>Shashidhar</last></author>
      <author><first>Abhinav</first><last>Chinta</last></author>
      <author><first>Vaibhav</first><last>Sahai</last></author>
      <author><first>Zhenhailong</first><last>Wang</last></author>
      <author><first>Heng</first><last>Ji</last></author>
      <pages>9070-9084</pages>
      <abstract>The dominance of proprietary LLMs has led to restricted access and raised information privacy concerns. The SoTA open-source alternatives are crucial for information-sensitive and high-volume applications but often lag behind in performance. To address this gap, we propose (1) A generalized variant of iterative self-critique and self-refinement devoid of external influence. (2) A novel ranking metric - Performance, Refinement, and Inference Cost Score (PeRFICS) - to find the optimal model for a given task considering refined performance and cost. Our experiments show that SoTA open source models of varying sizes from 7B - 65B, on average, improve 8.2% from their baseline performance. Strikingly, even models with extremely small memory footprints, such as Vicuna-7B, show a 11.74% improvement overall and up to a 25.39% improvement in high-creativity, open ended tasks on the Vicuna benchmark. Vicuna-13B takes it a step further and outperforms ChatGPT post-refinement. This work has profound implications for resource-constrained and information-sensitive environments seeking to leverage LLMs without incurring prohibitive costs, compromising on performance and privacy. The domain-agnostic self-refinement process coupled with our novel ranking metric facilitates informed decision-making in model selection, thereby reducing costs and democratizing access to high-performing language models, as evidenced by three case studies on personal computing, gaming and enterprise solutions.</abstract>
      <url hash="cd3e8ad2">2023.findings-emnlp.608</url>
      <bibkey>shashidhar-etal-2023-democratizing</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.608</doi>
    </paper>
    <paper id="609">
      <title><fixed-case>C</fixed-case>hinese Metaphorical Relation Extraction: Dataset and Models</title>
      <author><first>Guihua</first><last>Chen</last></author>
      <author><first>Tiantian</first><last>Wu</last></author>
      <author><first>MiaoMiao</first><last>Cheng</last></author>
      <author><first>Xu</first><last>Han</last></author>
      <author><first>Jiefu</first><last>Gong</last></author>
      <author><first>Shijin</first><last>Wang</last></author>
      <author><first>Wei</first><last>Song</last></author>
      <pages>9085-9095</pages>
      <abstract>Metaphor identification is usually formulated as a sequence labeling or a syntactically related word-pair classification problem. In this paper, we propose a novel formulation of metaphor identification as a relation extraction problem. We introduce metaphorical relations, which are links between two spans, a target span and a source-related span, which are realized in sentences. Based on spans, we can use more flexible and precise text units beyond single words for capturing the properties of the target and the source. We create a dataset for Chinese metaphorical relation extraction, with more than 4,200 sentences annotated with metaphorical relations, corresponding target/source-related spans, and fine-grained span types. We develop a span-based end-to-end model for metaphorical relation extraction and demonstrate its effectiveness. We expect that metaphorical relation extraction can serve as a bridge for connecting linguistic and conceptual metaphor processing. The dataset is at https://github.com/cnunlp/CMRE.</abstract>
      <url hash="70e5dad4">2023.findings-emnlp.609</url>
      <bibkey>chen-etal-2023-chinese</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.609</doi>
    </paper>
    <paper id="610">
      <title>Example-based Hypernetworks for Multi-source Adaptation to Unseen Domains</title>
      <author><first>Tomer</first><last>Volk</last></author>
      <author><first>Eyal</first><last>Ben-David</last></author>
      <author><first>Ohad</first><last>Amosy</last></author>
      <author><first>Gal</first><last>Chechik</last></author>
      <author><first>Roi</first><last>Reichart</last></author>
      <pages>9096-9113</pages>
      <abstract>As Natural Language Processing (NLP) algorithms continually achieve new milestones, out-of-distribution generalization remains a significant challenge. This paper addresses the issue of multi-source adaptation for unfamiliar domains: We leverage labeled data from multiple source domains to generalize to unknown target domains at training. Our innovative framework employs example-based Hypernetwork adaptation: a T5 encoder-decoder initially generates a unique signature from an input example, embedding it within the source domains’ semantic space. This signature is subsequently utilized by a Hypernetwork to generate the task classifier’s weights. In an advanced version, the signature also enriches the input example’s representation. We evaluated our method across two tasks—sentiment classification and natural language inference—in 29 adaptation scenarios, where it outpaced established algorithms. We also compare our finetuned architecture to few-shot GPT-3, demonstrating its effectiveness in essential use cases. To the best of our knowledge, this marks the first application of Hypernetworks to the adaptation for unknown domains.</abstract>
      <url hash="5f31149c">2023.findings-emnlp.610</url>
      <bibkey>volk-etal-2023-example</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.610</doi>
    </paper>
    <paper id="611">
      <title>Beneath the Surface: Unveiling Harmful Memes with Multimodal Reasoning Distilled from Large Language Models</title>
      <author><first>Hongzhan</first><last>Lin</last></author>
      <author><first>Ziyang</first><last>Luo</last></author>
      <author><first>Jing</first><last>Ma</last></author>
      <author><first>Long</first><last>Chen</last></author>
      <pages>9114-9128</pages>
      <abstract>The age of social media is rife with memes. Understanding and detecting harmful memes pose a significant challenge due to their implicit meaning that is not explicitly conveyed through the surface text and image. However, existing harmful meme detection approaches only recognize superficial harm-indicative signals in an end-to-end classification manner but ignore in-depth cognition of the meme text and image. In this paper, we attempt to detect harmful memes based on advanced reasoning over the interplay of multimodal information in memes. Inspired by the success of Large Language Models (LLMs) on complex reasoning, we first conduct abductive reasoning with LLMs. Then we propose a novel generative framework to learn reasonable thoughts from LLMs for better multimodal fusion and lightweight fine-tuning, which consists of two training stages: 1) Distill multimodal reasoning knowledge from LLMs; and 2) Fine-tune the generative framework to infer harmfulness. Extensive experiments conducted on three meme datasets demonstrate that our proposed approach achieves superior performance than state-of-the-art methods on the harmful meme detection task.</abstract>
      <url hash="b9e22b5b">2023.findings-emnlp.611</url>
      <bibkey>lin-etal-2023-beneath</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.611</doi>
    </paper>
    <paper id="612">
      <title>Domain Adaptation for Conversational Query Production with the <fixed-case>RAG</fixed-case> Model Feedback</title>
      <author><first>Ante</first><last>Wang</last></author>
      <author><first>Linfeng</first><last>Song</last></author>
      <author><first>Ge</first><last>Xu</last></author>
      <author><first>Jinsong</first><last>Su</last></author>
      <pages>9129-9141</pages>
      <abstract>Conversational query production is an emerging fundamental task for the dialogue system, where search queries are generated to explore the vast and continually updating knowledge from a search engine. To accelerate this line of research, previous studies have released several datasets with human-annotated search queries. However, the limited annotations still can not cover conversations of various domains. To solve this challenge, we propose a novel domain adaptation framework. It is inspired by a weakly supervised learning algorithm from previous work that guides a model using reinforcement learning with BM25 scores as feedback. Though effective, it is fragile facing noisy content on webpages from a commercial search engine and variance in conversations because of ignoring deep semantic information of dialogue contexts. Thus, we improve the algorithm by taking the advance of retrieval-augmented generation (RAG) and exploring several practical techniques such as knowledge distillation for stable training. We conduct experiments in multiple settings across different languages. Guided by the RAG model feedback, our model is more robust and performs significantly better especially in a more challenging setting over strong baselines.</abstract>
      <url hash="acac0fc5">2023.findings-emnlp.612</url>
      <bibkey>wang-etal-2023-domain</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.612</doi>
    </paper>
    <paper id="613">
      <title><fixed-case>LEGO</fixed-case>: A Multi-agent Collaborative Framework with Role-playing and Iterative Feedback for Causality Explanation Generation</title>
      <author><first>Zhitao</first><last>He</last></author>
      <author><first>Pengfei</first><last>Cao</last></author>
      <author><first>Yubo</first><last>Chen</last></author>
      <author><first>Kang</first><last>Liu</last></author>
      <author><first>Ruopeng</first><last>Li</last></author>
      <author><first>Mengshu</first><last>Sun</last></author>
      <author><first>Jun</first><last>Zhao</last></author>
      <pages>9142-9163</pages>
      <abstract>Causality Explanation Generation refers to generate an explanation in natural language given an initial cause-effect pair. It demands rigorous explicit rationales to demonstrate the acquisition of implicit commonsense knowledge, which is unlikely to be easily memorized, making it challenging for large language models since they are often suffering from spurious causal associations when they encounter the content that does not exist in their memory. In this work, we introduce LEGO, a Multi-agent Collaborative Framework with Role-playing and Iterative Feedback for causality explanation generation. Specifically, we treat LLM as character malleable LEGO block and utilize role-playing to assign specific roles to five LLMs. We firstly devise a Fine-grained World Knowledge Integration Module to augment information about tasks for alleviating the phenomenon of spurious causal associations. Then, we leverage an Iterative Feedback and Refinement Module to improve the generated explanation by multi-aspect feedback. Extensive experiments on widely used WIKIWHY and e-CARE datasets show the superiority of our multi-agent framework in terms of reasoning about the causality among cause and effect.</abstract>
      <url hash="73158c13">2023.findings-emnlp.613</url>
      <bibkey>he-etal-2023-lego</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.613</doi>
    </paper>
    <paper id="614">
      <title>Ranking <fixed-case>LLM</fixed-case>-Generated Loop Invariants for Program Verification</title>
      <author><first>Saikat</first><last>Chakraborty</last></author>
      <author><first>Shuvendu</first><last>Lahiri</last></author>
      <author><first>Sarah</first><last>Fakhoury</last></author>
      <author><first>Akash</first><last>Lal</last></author>
      <author><first>Madanlal</first><last>Musuvathi</last></author>
      <author><first>Aseem</first><last>Rastogi</last></author>
      <author><first>Aditya</first><last>Senthilnathan</last></author>
      <author><first>Rahul</first><last>Sharma</last></author>
      <author><first>Nikhil</first><last>Swamy</last></author>
      <pages>9164-9175</pages>
      <abstract>Synthesizing inductive loop invariants is fundamental to automating program verification. In this work we observe that Large Language Models (such as gpt-3.5 or gpt-4) are capable of synthesizing loop invariants for a class of programs in a 0-shot setting, yet require several samples to generate the correct invariants. This can lead to a large number a calls to a program verifier to establish an invariant. To address this issue, we propose a re-ranking approach for the generated results of LLMs. We have designed a ranker that can distinguish between correct inductive invariants and incorrect attempts based on the problem definition. The ranker is optimized as a contrastive ranker. Experimental results demonstrate that this re-ranking mechanism significantly improves the ranking of correct invariants among the generated candidates, leading to a notable reduction in the number of calls to a verifier.</abstract>
      <url hash="68225a9a">2023.findings-emnlp.614</url>
      <bibkey>chakraborty-etal-2023-ranking</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.614</doi>
    </paper>
    <paper id="615">
      <title><fixed-case>W</fixed-case>ord<fixed-case>N</fixed-case>et Is All You Need: A Surprisingly Effective Unsupervised Method for Graded Lexical Entailment</title>
      <author><first>Joseph</first><last>Renner</last></author>
      <author><first>Pascal</first><last>Denis</last></author>
      <author><first>Rémi</first><last>Gilleron</last></author>
      <pages>9176-9182</pages>
      <abstract>We propose a simple unsupervised approach which exclusively relies on WordNet (Miller,1995) for predicting graded lexical entailment (GLE) in English. Inspired by the seminal work of Resnik (1995), our method models GLE as the sum of two information-theoretic scores: a symmetric semantic similarity score and an asymmetric specificity loss score, both exploiting the hierarchical synset structure of WordNet. Our approach also includes a simple disambiguation mechanism to handle polysemy in a given word pair. Despite its simplicity, our method achieves performance above the state of the art (Spearman <tex-math>\rho</tex-math> = 0.75) on HyperLex (Vulic et al., 2017), the largest GLE dataset, outperforming all previous methods, including specialized word embeddings approaches that use WordNet as weak supervision.</abstract>
      <url hash="a1b2bc01">2023.findings-emnlp.615</url>
      <bibkey>renner-etal-2023-wordnet</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.615</doi>
    </paper>
    <paper id="616">
      <title>Knowledge Corpus Error in Question Answering</title>
      <author><first>Yejoon</first><last>Lee</last></author>
      <author><first>Philhoon</first><last>Oh</last></author>
      <author><first>James</first><last>Thorne</last></author>
      <pages>9183-9197</pages>
      <abstract>Recent works in open-domain question answering (QA) have explored generating context passages from large language models (LLMs), replacing the traditional retrieval step in the QA pipeline. However, it is not well understood why generated passages can be more effective than retrieved ones. This study revisits the conventional formulation of QA and introduces the concept of <tex-math>\textit{knowledge corpus error}</tex-math>. This error arises when the knowledge corpus used for retrieval is only a subset of the entire string space, potentially excluding more helpful passages that exist outside the corpus. LLMs may mitigate this shortcoming by generating passages in a larger space. We come up with an experiment of paraphrasing human-annotated gold context using LLMs to observe knowledge corpus error empirically. Our results across three QA benchmarks reveal an increased performance (10% - 13%) when using paraphrased passage, indicating a signal for the existence of knowledge corpus error.</abstract>
      <url hash="fbaa7acf">2023.findings-emnlp.616</url>
      <bibkey>lee-etal-2023-knowledge</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.616</doi>
    </paper>
    <paper id="617">
      <title>Epsilon Sampling Rocks: Investigating Sampling Strategies for Minimum <fixed-case>B</fixed-case>ayes Risk Decoding for Machine Translation</title>
      <author><first>Markus</first><last>Freitag</last></author>
      <author><first>Behrooz</first><last>Ghorbani</last></author>
      <author><first>Patrick</first><last>Fernandes</last></author>
      <pages>9198-9209</pages>
      <abstract>Recent advances in machine translation (MT) have shown that Minimum Bayes Risk (MBR) decoding can be a powerful alternative to beam search decoding, especially when combined with neural-based utility functions. However, the performance of MBR decoding depends heavily on how and how many candidates are sampled from the model. In this paper, we explore how different sampling approaches for generating candidate lists for MBR decoding affect performance. We evaluate popular sampling approaches, such as ancestral, nucleus, and top-k sampling. Based on our insights into their limitations, we experiment with the recently proposed epsilon-sampling approach, which prunes away all tokens with a probability smaller than epsilon, ensuring that each token in a sample receives a fair probability mass. Through extensive human evaluations, we demonstrate that MBR decoding based on epsilon-sampling significantly outperforms not only beam search decoding, but also MBR decoding with all other tested sampling methods across four language pairs.</abstract>
      <url hash="66b8b630">2023.findings-emnlp.617</url>
      <bibkey>freitag-etal-2023-epsilon</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.617</doi>
    </paper>
    <paper id="618">
      <title>The language of prompting: What linguistic properties make a prompt successful?</title>
      <author><first>Alina</first><last>Leidinger</last></author>
      <author><first>Robert</first><last>van Rooij</last></author>
      <author><first>Ekaterina</first><last>Shutova</last></author>
      <pages>9210-9232</pages>
      <abstract>The latest generation of LLMs can be prompted to achieve impressive zero-shot or few-shot performance in many NLP tasks. However, since performance is highly sensitive to the choice of prompts, considerable effort has been devoted to crowd-sourcing prompts or designing methods for prompt optimisation. Yet, we still lack a systematic understanding of how linguistic properties of prompts correlate with the task performance. In this work, we investigate how LLMs of different sizes, pre-trained and instruction-tuned, perform on prompts that are semantically equivalent, but vary in linguistic structure. We investigate both grammatical properties such as mood, tense, aspect and modality, as well as lexico-semantic variation through the use of synonyms. Our findings contradict the common assumption that LLMs achieve optimal performance on prompts which reflect language use in pretraining or instruction-tuning data. Prompts transfer poorly between datasets or models, and performance cannot generally be explained by perplexity, word frequency, word sense ambiguity or prompt length. Based on our results, we put forward a proposal for a more robust and comprehensive evaluation standard for prompting research.</abstract>
      <url hash="96fe3456">2023.findings-emnlp.618</url>
      <bibkey>leidinger-etal-2023-language</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.618</doi>
    </paper>
    <paper id="619">
      <title>When and Why Does Bias Mitigation Work?</title>
      <author><first>Abhilasha</first><last>Ravichander</last></author>
      <author><first>Joe</first><last>Stacey</last></author>
      <author><first>Marek</first><last>Rei</last></author>
      <pages>9233-9247</pages>
      <abstract>Neural models have been shown to exploit shallow surface features to perform language understanding tasks, rather than learning the deeper language understanding and reasoning skills that practitioners desire. Previous work has developed debiasing techniques to pressure models away from spurious features or artifacts in datasets, with the goal of having models instead learn useful, task-relevant representations. However, what do models actually learn as a result of such debiasing procedures? In this work, we evaluate three model debiasing strategies, and through a set of carefully designed tests we show how debiasing can actually increase the model’s reliance on hidden biases, instead of learning robust features that help it solve a task. Further, we demonstrate how even debiasing models against all shallow features in a dataset may still not help models address NLP tasks. As a result, we suggest that debiasing existing models may not be sufficient for many language understanding tasks, and future work should consider new learning paradigms, to address complex challenges such as commonsense reasoning and inference.</abstract>
      <url hash="81e3daae">2023.findings-emnlp.619</url>
      <bibkey>ravichander-etal-2023-bias</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.619</doi>
    </paper>
    <paper id="620">
      <title>Enhancing Retrieval-Augmented Large Language Models with Iterative Retrieval-Generation Synergy</title>
      <author><first>Zhihong</first><last>Shao</last></author>
      <author><first>Yeyun</first><last>Gong</last></author>
      <author><first>Yelong</first><last>Shen</last></author>
      <author><first>Minlie</first><last>Huang</last></author>
      <author><first>Nan</first><last>Duan</last></author>
      <author><first>Weizhu</first><last>Chen</last></author>
      <pages>9248-9274</pages>
      <abstract>Retrieval-augmented generation has raise extensive attention as it is promising to address the limitations of large language models including outdated knowledge and hallucinations. However, retrievers struggle to capture relevance, especially for queries with complex information needs. Recent work has proposed to improve relevance modeling by having large language models actively involved in retrieval, i.e., to guide retrieval with generation. In this paper, we show that strong performance can be achieved by a method we call Iter-RetGen, which synergizes retrieval and generation in an iterative manner: a model’s response to a task input shows what might be needed to finish the task, and thus can serve as an informative context for retrieving more relevant knowledge which in turn helps generate a better response in another iteration. Compared with recent work which interleaves retrieval with generation when completing a single output, Iter-RetGen processes all retrieved knowledge as a whole and largely preserves the flexibility in generation without structural constraints. We evaluate Iter-RetGen on multi-hop question answering, fact verification, and commonsense reasoning, and show that it can flexibly leverage parametric knowledge and non-parametric knowledge, and is superior to or competitive with state-of-the-art retrieval-augmented baselines while causing fewer overheads of retrieval and generation. We can further improve performance via generation-augmented retrieval adaptation.</abstract>
      <url hash="a793fadd">2023.findings-emnlp.620</url>
      <bibkey>shao-etal-2023-enhancing</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.620</doi>
    </paper>
    <paper id="621">
      <title>Dynamic Low-rank Estimation for Transformer-based Language Models</title>
      <author><first>Ting</first><last>Hua</last></author>
      <author><first>Xiao</first><last>Li</last></author>
      <author><first>Shangqian</first><last>Gao</last></author>
      <author><first>Yen-Chang</first><last>Hsu</last></author>
      <author><first>Yilin</first><last>Shen</last></author>
      <author><first>Hongxia</first><last>Jin</last></author>
      <pages>9275-9287</pages>
      <abstract>Matrix decomposition methods, such as Singular Value Decomposition (SVD) and its importance-weighted variants, have been widely used for compressing Transformer-based language models. While importance-weighted decomposition methods alleviate the strong assumption of equal importance for each parameter in SVD, they still rely on two fundamental assumptions: 1) unchanged importance distribution during further fine-tuning, 2) equal importance across weight matrices in different layers. Furthermore, these methods necessitate a well-trained task-specific model as the starting point and require additional fine-tuning after compression. In this work, we proposed RankDyna, a matrix decomposition method that enables dynamic rank resource allocation among matrices across different layers during the training process. Starting from a general pre-trained model, RankDyna accomplishes the dual goals of compression and adaptation to the downstream task, all within a single round of fine-tuning. The extensive evaluations demonstrate that RankDyna can outperform current SOTA methods under various parameter budget levels, and the advantage of RankDyna is further enhanced with higher compression rates.</abstract>
      <url hash="f8f7f184">2023.findings-emnlp.621</url>
      <bibkey>hua-etal-2023-dynamic</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.621</doi>
    </paper>
    <paper id="622">
      <title>Non-parallel Accent Transfer based on Fine-grained Controllable Accent Modelling</title>
      <author><first>Linqin</first><last>Wang</last></author>
      <author><first>Zhengtao</first><last>Yu</last></author>
      <author><first>Yuanzhang</first><last>Yang</last></author>
      <author><first>Shengxiang</first><last>Gao</last></author>
      <author><first>Cunli</first><last>Mao</last></author>
      <author><first>Yuxin</first><last>Huang</last></author>
      <pages>9288-9298</pages>
      <abstract>Existing accent transfer works rely on parallel data or speech recognition models. This paper focuses on the practical application of accent transfer and aims to implement accent transfer using non-parallel datasets. The study has encountered the challenge of speech representation disentanglement and modeling accents. In our accent modeling transfer framework, we manage to solve these problems by two proposed methods. First, we learn the suprasegmental information associated with tone to finely model the accents in terms of tone and rhythm. Second, we propose to use mutual information learning to disentangle the accent features and control the accent of the generated speech during the inference time. Experiments show that the proposed framework attains superior performance to the baseline models in terms of accentedness and audio quality.</abstract>
      <url hash="21e7a4e4">2023.findings-emnlp.622</url>
      <bibkey>wang-etal-2023-non</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.622</doi>
    </paper>
    <paper id="623">
      <title>Compositional Generalization for Data-to-Text Generation</title>
      <author><first>Xinnuo</first><last>Xu</last></author>
      <author><first>Ivan</first><last>Titov</last></author>
      <author><first>Mirella</first><last>Lapata</last></author>
      <pages>9299-9317</pages>
      <abstract>Data-to-text generation involves transforming structured data, often represented as predicate-argument tuples, into coherent textual descriptions. Despite recent advances, systems still struggle when confronted with unseen combinations of predicates, producing unfaithful descriptions (e.g.,hallucinations or omissions). We refer to this issue as compositional generalisation, and it encouraged us to create a benchmark for assessing the performance of different approaches on this specific problem. Furthermore, we propose a novel model that addresses compositional generalization by clustering predicates into groups. Our model generates text in a sentence-by-sentence manner, relying on one cluster of predicates at a time. This approach significantly outperforms T5-baselines across all evaluation metrics. Notably, it achieved a 31% improvement over T5 in terms of a metric focused on maintaining faithfulness to the input.</abstract>
      <url hash="0dbccdb6">2023.findings-emnlp.623</url>
      <bibkey>xu-etal-2023-compositional</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.623</doi>
    </paper>
    <paper id="624">
      <title>In-Context Learning Creates Task Vectors</title>
      <author><first>Roee</first><last>Hendel</last></author>
      <author><first>Mor</first><last>Geva</last></author>
      <author><first>Amir</first><last>Globerson</last></author>
      <pages>9318-9333</pages>
      <abstract>In-context learning (ICL) in Large Language Models (LLMs) has emerged as a powerful new learning paradigm. However, its underlying mechanism is still not well understood. In particular, it is challenging to map it to the “standard’ machine learning framework, where one uses a training set <tex-math>S</tex-math> to find a best-fitting function <tex-math>f(x)</tex-math> in some hypothesis class. Here we make progress on this problem by showing that the functions learned by ICL often have a very simple structure: they correspond to the transformer LLM whose only inputs are the query <tex-math>x</tex-math> and a single “task vector’ calculated from the training set. Thus, ICL can be seen as compressing <tex-math>S</tex-math> into a single task vector <tex-math>\boldsymbol{\theta}(S)</tex-math> and then using this task vector to modulate the transformer to produce the output. We support the above claim via comprehensive experiments across a range of models and tasks.</abstract>
      <url hash="38ffc1eb">2023.findings-emnlp.624</url>
      <bibkey>hendel-etal-2023-context</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.624</doi>
    </paper>
    <paper id="625">
      <title><fixed-case>T</fixed-case>alk<fixed-case>U</fixed-case>p: Paving the Way for Understanding Empowering Language</title>
      <author><first>Lucille</first><last>Njoo</last></author>
      <author><first>Chan</first><last>Park</last></author>
      <author><first>Octavia</first><last>Stappart</last></author>
      <author><first>Marvin</first><last>Thielk</last></author>
      <author><first>Yi</first><last>Chu</last></author>
      <author><first>Yulia</first><last>Tsvetkov</last></author>
      <pages>9334-9354</pages>
      <abstract>Empowering language is important in many real-world contexts, from education to workplace dynamics to healthcare. Though language technologies are growing more prevalent in these contexts, empowerment has seldom been studied in NLP, and moreover, it is inherently challenging to operationalize because of its implicit nature. This work builds from linguistic and social psychology literature to explore what characterizes empowering language. We then crowdsource a novel dataset of Reddit posts labeled for empowerment, reasons why these posts are empowering to readers, and the social relationships between posters and readers. Our preliminary analyses show that this dataset, which we call TalkUp, can be used to train language models that capture empowering and disempowering language. More broadly, TalkUp provides an avenue to explore implication, presuppositions, and how social context influences the meaning of language.</abstract>
      <url hash="c633167f">2023.findings-emnlp.625</url>
      <bibkey>njoo-etal-2023-talkup</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.625</doi>
    </paper>
    <paper id="626">
      <title>Unifying Text, Tables, and Images for Multimodal Question Answering</title>
      <author><first>Haohao</first><last>Luo</last></author>
      <author><first>Ying</first><last>Shen</last></author>
      <author><first>Yang</first><last>Deng</last></author>
      <pages>9355-9367</pages>
      <abstract>Multimodal question answering (MMQA), which aims to derive the answer from multiple knowledge modalities (e.g., text, tables, and images), has received increasing attention due to its board applications. Current approaches to MMQA often rely on single-modal or bi-modal QA models, which limits their ability to effectively integrate information across all modalities and leverage the power of pre-trained language models. To address these limitations, we propose a novel framework called UniMMQA, which unifies three different input modalities into a text-to-text format by employing position-enhanced table linearization and diversified image captioning techniques. Additionally, we enhance cross-modal reasoning by incorporating a multimodal rationale generator, which produces textual descriptions of cross-modal relations for adaptation into the text-to-text generation process. Experimental results on three MMQA benchmark datasets show the superiority of UniMMQA in both supervised and unsupervised settings.</abstract>
      <url hash="11252074">2023.findings-emnlp.626</url>
      <bibkey>luo-etal-2023-unifying</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.626</doi>
    </paper>
    <paper id="627">
      <title>Unsupervised Lexical Simplification with Context Augmentation</title>
      <author><first>Takashi</first><last>Wada</last></author>
      <author><first>Timothy</first><last>Baldwin</last></author>
      <author><first>Jey</first><last>Lau</last></author>
      <pages>9368-9379</pages>
      <abstract>We propose a new unsupervised lexical simplification method that uses only monolingual data and pre-trained language models. Given a target word and its context, our method generates substitutes based on the target context and also additional contexts sampled from monolingual data. We conduct experiments in English, Portuguese, and Spanish on the TSAR-2022 shared task, and show that our model substantially outperforms other unsupervised systems across all languages. We also establish a new state-of-the-art by ensembling our model with GPT-3.5. Lastly, we evaluate our model on the SWORDS lexical substitution data set, achieving a state-of-the-art result.</abstract>
      <url hash="93851212">2023.findings-emnlp.627</url>
      <bibkey>wada-etal-2023-unsupervised-lexical</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.627</doi>
    </paper>
    <paper id="628">
      <title>m<fixed-case>L</fixed-case>ong<fixed-case>T</fixed-case>5: A Multilingual and Efficient Text-To-Text Transformer for Longer Sequences</title>
      <author><first>David</first><last>Uthus</last></author>
      <author><first>Santiago</first><last>Ontanon</last></author>
      <author><first>Joshua</first><last>Ainslie</last></author>
      <author><first>Mandy</first><last>Guo</last></author>
      <pages>9380-9386</pages>
      <abstract>We present our work on developing a multilingual, efficient text-to-text transformer that is suitable for handling long inputs. This model, called mLongT5, builds upon the architecture of LongT5, while leveraging the multilingual datasets used for pretraining mT5 and the pretraining tasks of UL2. We evaluate this model on a variety of multilingual summarization and question-answering tasks, and the results show stronger performance for mLongT5 when compared to existing multilingual models such as mBART or M-BERT.</abstract>
      <url hash="bbce8eb7">2023.findings-emnlp.628</url>
      <bibkey>uthus-etal-2023-mlongt5</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.628</doi>
    </paper>
    <paper id="629">
      <title>Multilingual Lottery Tickets to Pretrain Language Models</title>
      <author><first>Jaeseong</first><last>Lee</last></author>
      <author><first>Seung-won</first><last>Hwang</last></author>
      <pages>9387-9398</pages>
      <abstract>The curse of multilinguality in training multilingual pretrained language models (mPLMs) refers to the negative interference between languages, especially when the capacity is limited. While increasing the capacity may appear intuitive for overcoming this curse, it negatively affects both training and inference costs. Our distinction is pursuing the competing goals of reducing negative interference, while keeping capacity per each language more or less the same. Specifically, we first scale the model to reduce interference, then search for a per-language subnetwork, or a lottery ticket, with comparable performance to the full model. According to lottery ticket hypothesis, this scale-then-find-ticket approach alleviates interfering signals as in the scaled model, but redistributes parameters to keep the parameters reduced. Finally, to avoid the cost of multiple retraining for searching multilingual tickets, we explore zero-shot neural architecture search (NAS) methods. We investigate the most appropriate zero-shot NAS method to find multilingual tickets. Our proposed multilingual tickets reduce the inference cost of models for each languages, while boosting the performances. The ticket search cost is negligible and tickets found qualitatively preserve linguistic similarity. Our code is publicly available.</abstract>
      <url hash="7e03514d">2023.findings-emnlp.629</url>
      <bibkey>lee-hwang-2023-multilingual</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.629</doi>
    </paper>
    <paper id="630">
      <title>Target-Aware Spatio-Temporal Reasoning via Answering Questions in Dynamic Audio-Visual Scenarios</title>
      <author><first>Yuanyuan</first><last>Jiang</last></author>
      <author><first>Jianqin</first><last>Yin</last></author>
      <pages>9399-9409</pages>
      <abstract>Audio-visual question answering (AVQA) is a challenging task that requires multistep spatio-temporal reasoning over multimodal contexts. Recent works rely on elaborate target-agnostic parsing of audio-visual scenes for spatial grounding while mistreating audio and video as separate entities for temporal grounding. This paper proposes a new target-aware joint spatio-temporal grounding network for AVQA. It consists of two key components: the target-aware spatial grounding module (TSG) and the single-stream joint audio-visual temporal grounding module (JTG). The TSG can focus on audio-visual cues relevant to the query subject by utilizing explicit semantics from the question. Unlike previous two-stream temporal grounding modules that required an additional audio-visual fusion module, JTG incorporates audio-visual fusion and question-aware temporal grounding into one module with a simpler single-stream architecture. The temporal synchronization between audio and video in the JTG is facilitated by our proposed cross-modal synchrony loss (CSL). Extensive experiments verified the effectiveness of our proposed method over existing state-of-the-art methods.</abstract>
      <url hash="656f8bb8">2023.findings-emnlp.630</url>
      <bibkey>jiang-yin-2023-target</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.630</doi>
    </paper>
    <paper id="631">
      <title><fixed-case>KG</fixed-case>-<fixed-case>GPT</fixed-case>: A General Framework for Reasoning on Knowledge Graphs Using Large Language Models</title>
      <author><first>Jiho</first><last>Kim</last></author>
      <author><first>Yeonsu</first><last>Kwon</last></author>
      <author><first>Yohan</first><last>Jo</last></author>
      <author><first>Edward</first><last>Choi</last></author>
      <pages>9410-9421</pages>
      <abstract>While large language models (LLMs) have made considerable advancements in understanding and generating unstructured text, their application in structured data remains underexplored. Particularly, using LLMs for complex reasoning tasks on knowledge graphs (KGs) remains largely untouched. To address this, we propose KG-GPT, a multi-purpose framework leveraging LLMs for tasks employing KGs. KG-GPT comprises three steps: Sentence Segmentation, Graph Retrieval, and Inference, each aimed at partitioning sentences, retrieving relevant graph components, and deriving logical conclusions, respectively. We evaluate KG-GPT using KG-based fact verification and KGQA benchmarks, with the model showing competitive and robust performance, even outperforming several fully-supervised models. Our work, therefore, marks a significant step in unifying structured and unstructured data processing within the realm of LLMs.</abstract>
      <url hash="ea42746d">2023.findings-emnlp.631</url>
      <bibkey>kim-etal-2023-kg</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.631</doi>
    </paper>
    <paper id="632">
      <title>Breaking the Language Barrier: Improving Cross-Lingual Reasoning with Structured Self-Attention</title>
      <author><first>Negar</first><last>Foroutan</last></author>
      <author><first>Mohammadreza</first><last>Banaei</last></author>
      <author><first>Karl</first><last>Aberer</last></author>
      <author><first>Antoine</first><last>Bosselut</last></author>
      <pages>9422-9442</pages>
      <abstract>In this work, we study whether multilingual language models (MultiLMs) can transfer logical reasoning abilities to other languages when they are fine-tuned for reasoning in a different language. We evaluate the cross-lingual reasoning abilities of MultiLMs in two schemes: (1) where the language of the context and the question remain the same in the new languages that are tested (i.e., the reasoning is still monolingual, but the model must transfer the learned reasoning ability across languages), and (2) where the language of the context and the question is different (which we term code-switched reasoning). On two logical reasoning datasets, RuleTaker and LeapOfThought, we demonstrate that although MultiLMs can transfer reasoning ability across languages in a monolingual setting, they struggle to transfer reasoning abilities in a code-switched setting. Following this observation, we propose a novel attention mechanism that uses a dedicated set of parameters to encourage cross-lingual attention in code-switched sequences, which improves the reasoning performance by up to 14% and 4% on the RuleTaker and LeapOfThought datasets, respectively.</abstract>
      <url hash="90a2c3d3">2023.findings-emnlp.632</url>
      <bibkey>foroutan-etal-2023-breaking</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.632</doi>
    </paper>
    <paper id="633">
      <title><fixed-case>CITB</fixed-case>: A Benchmark for Continual Instruction Tuning</title>
      <author><first>Zihan</first><last>Zhang</last></author>
      <author><first>Meng</first><last>Fang</last></author>
      <author><first>Ling</first><last>Chen</last></author>
      <author><first>Mohammad-Reza</first><last>Namazi-Rad</last></author>
      <pages>9443-9455</pages>
      <abstract>Continual learning (CL) is a paradigm that aims to replicate the human ability to learn and accumulate knowledge continually without forgetting previous knowledge and transferring it to new tasks. Recent instruction tuning (IT) involves fine-tuning models to make them more adaptable to solving NLP tasks in general. However, it is still uncertain how instruction tuning works in the context of CL tasks. This challenging yet practical problem is formulated as Continual Instruction Tuning (CIT). In this work, we establish a CIT benchmark consisting of learning and evaluation protocols. We curate two long dialogue task streams of different types, InstrDialog and InstrDialog++, to study various CL methods systematically. Our experiments show that existing CL methods do not effectively leverage the rich natural language instructions, and fine-tuning an instruction-tuned model sequentially can yield similar or better results. We further explore different aspects that might affect the learning of CIT. We hope this benchmark will facilitate more research in this direction.</abstract>
      <url hash="d76746e3">2023.findings-emnlp.633</url>
      <bibkey>zhang-etal-2023-citb</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.633</doi>
    </paper>
    <paper id="634">
      <title>Mixture-of-Linguistic-Experts Adapters for Improving and Interpreting Pre-trained Language Models</title>
      <author><first>Raymond</first><last>Li</last></author>
      <author><first>Gabriel</first><last>Murray</last></author>
      <author><first>Giuseppe</first><last>Carenini</last></author>
      <pages>9456-9469</pages>
      <abstract>In this work, we propose a method that combines two popular research areas by injecting linguistic structures into pre-trained language models in the parameter-efficient fine-tuning (PEFT) setting. In our approach, parallel adapter modules encoding different linguistic structures are combined using a novel Mixture-of-Linguistic-Experts architecture, where Gumbel-Softmax gates are used to determine the importance of these modules at each layer of the model. To reduce the number of parameters, we first train the model for a fixed small number of steps before pruning the experts based on their important scores. Our experiment results with three different pre-trained models show that our approach can outperform state-of-the-art PEFT methods with a comparable number of parameters. In addition, we provide additional analysis to examine the experts selected by each model at each layer to provide insights for future studies.</abstract>
      <url hash="14edf77e">2023.findings-emnlp.634</url>
      <bibkey>li-etal-2023-mixture</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.634</doi>
    </paper>
    <paper id="635">
      <title>Towards Better Representations for Multi-Label Text Classification with Multi-granularity Information</title>
      <author><first>Fangfang</first><last>Li</last></author>
      <author><first>Puzhen</first><last>Su</last></author>
      <author><first>Junwen</first><last>Duan</last></author>
      <author><first>Weidong</first><last>Xiao</last></author>
      <pages>9470-9480</pages>
      <abstract>Multi-label text classification (MLTC) aims to assign multiple labels to a given text. Previous works have focused on text representation learning and label correlations modeling using pre-trained language models (PLMs). However, studies have shown that PLMs generate word frequency-oriented text representations, causing texts with different labels to be closely distributed in a narrow region, which is difficult to classify. To address this, we present a novel framework <tex-math>\textbf{CL}</tex-math>(<tex-math>\underline{C}</tex-math>ontrastive <tex-math>\underline{L}</tex-math>earning)-<tex-math>\textbf{MIL}</tex-math> (<tex-math>\underline{M}</tex-math>ulti-granularity <tex-math>\underline{I}</tex-math>nformation <tex-math>\underline{L}</tex-math>earning) to refine the text representation for MLTC task. We first use contrastive learning to generate uniform initial text representation and incorporate label frequency implicitly. Then, we design a multi-task learning module to integrate multi-granularity (diverse text-labels correlations, label-label relations and label frequency) information into text representations, enhancing their discriminative ability. Experimental results demonstrate the complementarity of the modules in CL-MIL, improving the quality of text representations and yielding stable and competitive improvements for MLTC.</abstract>
      <url hash="95d6ce21">2023.findings-emnlp.635</url>
      <bibkey>li-etal-2023-towards-better</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.635</doi>
    </paper>
    <paper id="636">
      <title><fixed-case>PCMID</fixed-case>: Multi-Intent Detection through Supervised Prototypical Contrastive Learning</title>
      <author><first>Yurun</first><last>Song</last></author>
      <author><first>Junchen</first><last>Zhao</last></author>
      <author><first>Spencer</first><last>Koehler</last></author>
      <author><first>Amir</first><last>Abdullah</last></author>
      <author><first>Ian</first><last>Harris</last></author>
      <pages>9481-9495</pages>
      <abstract>Intent detection is a major task in Natural Language Understanding (NLU) and is the component of dialogue systems for interpreting users’ intentions based on their utterances. Many works have explored detecting intents by assuming that each utterance represents only a single intent. Such systems have achieved very good results; however, intent detection is a far more challenging task in typical real-world scenarios, where each user utterance can be highly complex and express multiple intents. Therefore, in this paper, we propose PCMID, a novel Multi-Intent Detection framework enabled by Prototypical Contrastive Learning under a supervised setting. The PCMID model can learn multiple semantic representations of a given user utterance under the context of different intent labels in an optimized semantic space. Our experiments show that PCMID achieves the current state-of-the-art performance on both multiple public benchmark datasets and a private real-world dataset for the multi-intent detection task.</abstract>
      <url hash="a72b8d08">2023.findings-emnlp.636</url>
      <bibkey>song-etal-2023-pcmid</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.636</doi>
    </paper>
    <paper id="637">
      <title>Is <fixed-case>GPT</fixed-case>-4 a Good Data Analyst?</title>
      <author><first>Liying</first><last>Cheng</last></author>
      <author><first>Xingxuan</first><last>Li</last></author>
      <author><first>Lidong</first><last>Bing</last></author>
      <pages>9496-9514</pages>
      <abstract>As large language models (LLMs) have demonstrated their powerful capabilities in plenty of domains and tasks, including context understanding, code generation, language generation, data storytelling, etc., many data analysts may raise concerns if their jobs will be replaced by artificial intelligence (AI). This controversial topic has drawn great attention in public. However, we are still at a stage of divergent opinions without any definitive conclusion. Motivated by this, we raise the research question of “is GPT-4 a good data analyst?” in this work and aim to answer it by conducting head-to-head comparative studies. In detail, we regard GPT-4 as a data analyst to perform end-to-end data analysis with databases from a wide range of domains. We propose a framework to tackle the problems by carefully designing the prompts for GPT-4 to conduct experiments. We also design several task-specific evaluation metrics to systematically compare the performance between several professional human data analysts and GPT-4. Experimental results show that GPT-4 can achieve comparable performance to humans. We also provide in-depth discussions about our results to shed light on further studies before reaching the conclusion that GPT-4 can replace data analysts.</abstract>
      <url hash="a6cb5e8c">2023.findings-emnlp.637</url>
      <bibkey>cheng-etal-2023-gpt</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.637</doi>
    </paper>
    <paper id="638">
      <title><fixed-case>D</fixed-case>iffusion<fixed-case>R</fixed-case>et: Diffusion-Enhanced Generative Retriever using Constrained Decoding</title>
      <author><first>Shanbao</first><last>Qiao</last></author>
      <author><first>Xuebing</first><last>Liu</last></author>
      <author><first>Seung-Hoon</first><last>Na</last></author>
      <pages>9515-9529</pages>
      <abstract>Generative retrieval, which maps from a query to its relevant document identifiers (docids), has recently emerged as a new information retrieval (IR) paradigm, however, having suffered from 1) the <tex-math>\textit{lack of the intermediate reasoning step}</tex-math>, caused by the manner of merely using a query to perform the hierarchical classification, and 2) the <tex-math>\textit{pretrain-finetune discrepancy}</tex-math>, which comes from the use of the artificial symbols of docids. To address these limitations, we propose the novel approach of using the document generation from a query as an intermediate step before the retrieval, thus presenting <tex-math>\underline{diffusion}</tex-math>-enhanced generative <tex-math>\underline{ret}</tex-math>rieval (<tex-math>\textbf{DiffusionRet}</tex-math>), which consists of two processing steps: 1) the <tex-math>\textit{diffusion-based document generation}</tex-math>, which employs the sequence-to-sequence diffusion model to produce a pseudo document sample from a query, being expected to semantically close to a relevant document; 2) <tex-math>\textit{N-gram-based generative retrieval}</tex-math>, which use another sequence-to-sequence model to generate n-grams that appear in the collection index for linking a generated sample to an original document. Experiment results on MS MARCO and Natural Questions dataset show that the proposed DiffusionRet significantly outperforms all the existing generative retrieval methods and leads to the state-of-the-art performances, even with much smaller number of parameters.</abstract>
      <url hash="1462e285">2023.findings-emnlp.638</url>
      <bibkey>qiao-etal-2023-diffusionret</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.638</doi>
    </paper>
    <paper id="639">
      <title>Estimating Large Language Model Capabilities without Labeled Test Data</title>
      <author><first>Harvey</first><last>Fu</last></author>
      <author><first>Qinyuan</first><last>Ye</last></author>
      <author><first>Albert</first><last>Xu</last></author>
      <author><first>Xiang</first><last>Ren</last></author>
      <author><first>Robin</first><last>Jia</last></author>
      <pages>9530-9546</pages>
      <abstract>Large Language Models (LLMs) have exhibited an impressive ability to perform in-context learning (ICL) from only a few examples, but the success of ICL varies widely from task to task. Thus, it is important to quickly determine whether ICL is applicable to a new task, but directly evaluating ICL accuracy can be expensive in situations where test data is expensive to annotate—the exact situations where ICL is most appealing. In this paper, we propose the task of ICL accuracy estimation, in which we predict the accuracy of an LLM when doing in-context learning on a new task given only unlabeled test data for that task. To perform ICL accuracy estimation, we propose a method that trains a meta-model using LLM confidence scores as features. We compare our method to several strong accuracy estimation baselines on a new benchmark that covers 4 LLMs and 3 task collections. The meta-model improves over all baselines across 7 out of 12 settings and achieves the same estimation performance as directly evaluating on 40 collected labeled test examples per task. At the same time, no existing approach provides an accurate and reliable ICL accuracy estimation in every setting, highlighting the need for better ways to measure the uncertainty of LLM predictions.</abstract>
      <url hash="1a2a03c0">2023.findings-emnlp.639</url>
      <bibkey>fu-etal-2023-estimating</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.639</doi>
    </paper>
    <paper id="640">
      <title>A Novel Contrastive Learning Method for Clickbait Detection on <fixed-case>R</fixed-case>o<fixed-case>C</fixed-case>li<fixed-case>C</fixed-case>o: A <fixed-case>R</fixed-case>omanian Clickbait Corpus of News Articles</title>
      <author><first>Daria</first><last>Broscoteanu</last></author>
      <author><first>Radu</first><last>Ionescu</last></author>
      <pages>9547-9555</pages>
      <abstract>To increase revenue, news websites often resort to using deceptive news titles, luring users into clicking on the title and reading the full news. Clickbait detection is the task that aims to automatically detect this form of false advertisement and avoid wasting the precious time of online users. Despite the importance of the task, to the best of our knowledge, there is no publicly available clickbait corpus for the Romanian language. To this end, we introduce a novel Romanian Clickbait Corpus (RoCliCo) comprising 8,313 news samples which are manually annotated with clickbait and non-clickbait labels. Furthermore, we conduct experiments with four machine learning methods, ranging from handcrafted models to recurrent and transformer-based neural networks, to establish a line-up of competitive baselines. We also carry out experiments with a weighted voting ensemble. Among the considered baselines, we propose a novel BERT-based contrastive learning model that learns to encode news titles and contents into a deep metric space such that titles and contents of non-clickbait news have high cosine similarity, while titles and contents of clickbait news have low cosine similarity. Our data set and code to reproduce the baselines are publicly available for download at https://github.com/dariabroscoteanu/RoCliCo.</abstract>
      <url hash="ba86130c">2023.findings-emnlp.640</url>
      <bibkey>broscoteanu-ionescu-2023-novel</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.640</doi>
    </paper>
    <paper id="641">
      <title>Large Language Models as Source Planner for Personalized Knowledge-grounded Dialogues</title>
      <author><first>Hongru</first><last>Wang</last></author>
      <author><first>Minda</first><last>Hu</last></author>
      <author><first>Yang</first><last>Deng</last></author>
      <author><first>Rui</first><last>Wang</last></author>
      <author><first>Fei</first><last>Mi</last></author>
      <author><first>Weichao</first><last>Wang</last></author>
      <author><first>Yasheng</first><last>Wang</last></author>
      <author><first>Wai-Chung</first><last>Kwan</last></author>
      <author><first>Irwin</first><last>King</last></author>
      <author><first>Kam-Fai</first><last>Wong</last></author>
      <pages>9556-9569</pages>
      <abstract>Open-domain dialogue system usually requires different sources of knowledge to generate more informative and evidential responses. However, existing knowledge-grounded dialogue systems either focus on a single knowledge source or overlook the dependency between multiple sources of knowledge, which may result in generating inconsistent or even paradoxical responses. To incorporate multiple knowledge sources and dependencies between them, we propose SAFARI, a novel framework that leverages the exceptional capabilities of large language models (LLMs) in planning, understanding, and incorporating under both supervised and unsupervised settings. Specifically, SAFARI decouples the knowledge grounding into multiple sources and response generation, which allows easy extension to various knowledge sources including the possibility of not using any sources. To study the problem, we construct a personalized knowledge-grounded dialogue dataset Knowledge Behind Persona (KBP), which is the first to consider the dependency between persona and implicit knowledge. Experimental results on the KBP dataset demonstrate that the SAFARI framework can effectively produce persona-consistent and knowledge-enhanced responses.</abstract>
      <url hash="c75ba749">2023.findings-emnlp.641</url>
      <bibkey>wang-etal-2023-large</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.641</doi>
    </paper>
    <paper id="642">
      <title>Toxicity in Multilingual Machine Translation at Scale</title>
      <author><first>Marta</first><last>Costa-jussà</last></author>
      <author><first>Eric</first><last>Smith</last></author>
      <author><first>Christophe</first><last>Ropers</last></author>
      <author><first>Daniel</first><last>Licht</last></author>
      <author><first>Jean</first><last>Maillard</last></author>
      <author><first>Javier</first><last>Ferrando</last></author>
      <author><first>Carlos</first><last>Escolano</last></author>
      <pages>9570-9586</pages>
      <abstract>Machine Translation systems can produce different types of errors, some of which are characterized as critical or catastrophic due to the specific negative impact that they can have on users. In this paper we focus on one type of critical error: added toxicity. We evaluate and analyze added toxicity when translating a large evaluation dataset (HOLISTICBIAS, over 472k sentences, covering 13 demographic axes) from English into 164 languages. An automatic toxicity evaluation shows that added toxicity across languages varies from 0% to 5%. The output languages with the most added toxicity tend to be low-resource ones, and the demographic axes with the most added toxicity include sexual orientation, gender and sex, and ability. We also perform human evaluation on a subset of 8 translation directions, confirming the prevalence of true added toxicity. We use a measurement of the amount of source contribution to the translation, where a low source contribution implies hallucination, to interpret what causes toxicity. Making use of the input attributions allows us to explain toxicity, because the source contributions significantly correlate with toxicity for 84% of languages studied. Given our findings, our recommendations to reduce added toxicity are to curate training data to avoid mistranslations, mitigate hallucination and check unstable translations.</abstract>
      <url hash="c67e113f">2023.findings-emnlp.642</url>
      <bibkey>costa-jussa-etal-2023-toxicity</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.642</doi>
    </paper>
    <paper id="643">
      <title>Conversational Recommender System and Large Language Model Are Made for Each Other in <fixed-case>E</fixed-case>-commerce Pre-sales Dialogue</title>
      <author><first>Yuanxing</first><last>Liu</last></author>
      <author><first>Weinan</first><last>Zhang</last></author>
      <author><first>Yifan</first><last>Chen</last></author>
      <author><first>Yuchi</first><last>Zhang</last></author>
      <author><first>Haopeng</first><last>Bai</last></author>
      <author><first>Fan</first><last>Feng</last></author>
      <author><first>Hengbin</first><last>Cui</last></author>
      <author><first>Yongbin</first><last>Li</last></author>
      <author><first>Wanxiang</first><last>Che</last></author>
      <pages>9587-9605</pages>
      <abstract>E-commerce pre-sales dialogue aims to understand and elicit user needs and preferences for the items they are seeking so as to provide appropriate recommendations. Conversational recommender systems (CRSs) learn user representation and provide accurate recommendations based on dialogue context, but rely on external knowledge. Large language models (LLMs) generate responses that mimic pre-sales dialogues after fine-tuning, but lack domain-specific knowledge for accurate recommendations. Intuitively, the strengths of LLM and CRS in E-commerce pre-sales dialogues are complementary, yet no previous work has explored this. This paper investigates the effectiveness of combining LLM and CRS in E-commerce pre-sales dialogues, proposing two collaboration methods: CRS assisting LLM and LLM assisting CRS. We conduct extensive experiments on a real-world dataset of E-commerce pre-sales dialogues. We analyze the impact of two collaborative approaches with two CRSs and two LLMs on four tasks of E-commerce pre-sales dialogue. We find that collaborations between CRS and LLM can be very effective in some cases.</abstract>
      <url hash="36b6fb84">2023.findings-emnlp.643</url>
      <bibkey>liu-etal-2023-conversational</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.643</doi>
    </paper>
    <paper id="644">
      <title><fixed-case>VIP</fixed-case>5: Towards Multimodal Foundation Models for Recommendation</title>
      <author><first>Shijie</first><last>Geng</last></author>
      <author><first>Juntao</first><last>Tan</last></author>
      <author><first>Shuchang</first><last>Liu</last></author>
      <author><first>Zuohui</first><last>Fu</last></author>
      <author><first>Yongfeng</first><last>Zhang</last></author>
      <pages>9606-9620</pages>
      <abstract>Computer Vision (CV), Natural Language Processing (NLP), and Recommender Systems (RecSys) are three prominent AI applications that have traditionally developed independently, resulting in disparate modeling and engineering methodologies. This has impeded the ability for these fields to directly benefit from each other’s advancements. With the recent development of foundation models, large language models have emerged as a potential general-purpose interface for unifying different modalities and problem formulations. In light of this, we propose the development of a multimodal foundation model (MFM) considering visual, textual, and personalization modalities under the P5 recommendation paradigm, thus named VIP5 (Visual P5), to unify various modalities and recommendation tasks. This will enable the processing of multiple modalities in a shared architecture for improved recommendations. To achieve this, we introduce multimodal personalized prompts to accommodate multiple modalities under a shared format. Additionally, we propose a parameter-efficient training method for foundation models, which involves freezing the P5 backbone and fine-tuning lightweight adapters, resulting in improved recommendation performance and increased efficiency in terms of training time and memory usage. Code and data of VIP5 are available at https://github.com/jeykigung/VIP5.</abstract>
      <url hash="8eddd824">2023.findings-emnlp.644</url>
      <bibkey>geng-etal-2023-vip5</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.644</doi>
    </paper>
    <paper id="645">
      <title>A Spectral Viewpoint on Continual Relation Extraction</title>
      <author id="huy-nguyen-bcl"><first>Huy</first><last>Nguyen</last></author>
      <author><first>Chien</first><last>Nguyen</last></author>
      <author><first>Linh</first><last>Ngo</last></author>
      <author><first>Anh</first><last>Luu</last></author>
      <author><first>Thien</first><last>Nguyen</last></author>
      <pages>9621-9629</pages>
      <abstract>Continual Relation Extraction (CRE) aims to continuously train a model to learn new relations while preserving its ability on previously learned relations. Similar to other continual learning problems, in CRE, models experience representation shift, where learned deep space changes in the continual learning process, which leads to the downgrade in the performance of the old tasks. In this work, we will provide an insight into this phenomenon under the spectral viewpoint. Our key argument is that, for each class shape, if its eigenvectors (or spectral components) do not change much, the shape is well-preserved. We then conduct a spectral experiment and show that, for the shape of each class, the eigenvectors with larger eigenvalue are more preserved after learning new tasks which means these vectors are good at keeping class shapes. Based on this analysis, we propose a simple yet effective class-wise regularization that improve the eigenvalues in the representation learning. We observe that our proposed regularization leads to an increase in the eigenvalues. Extensive experiments on two benchmark datasets, FewRel and TACRED, show the effectiveness of our proposed method with significant improvement in performance compared to the state-of-the-art models. Further analyses also verify our hypothesis that larger eigenvalues lead to better performance and vice versa.</abstract>
      <url hash="e20b8bdc">2023.findings-emnlp.645</url>
      <bibkey>nguyen-etal-2023-spectral</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.645</doi>
    </paper>
    <paper id="646">
      <title>Learning to Follow Object-Centric Image Editing Instructions Faithfully</title>
      <author><first>Tuhin</first><last>Chakrabarty</last></author>
      <author><first>Kanishk</first><last>Singh</last></author>
      <author><first>Arkadiy</first><last>Saakyan</last></author>
      <author><first>Smaranda</first><last>Muresan</last></author>
      <pages>9630-9646</pages>
      <abstract>Natural language instructions are a powerful interface for editing the outputs of text-to-image diffusion models. However, several challenges need to be addressed: 1) underspecification (the need to model the implicit meaning of instructions) 2) grounding (the need to localize where the edit has to be performed), 3) faithfulness (the need to preserve the elements of the image not affected by the edit instruction). Current approaches focusing on image editing with natural language instructions rely on automatically generated paired data, which, as shown in our investigation, is noisy and sometimes nonsensical, exacerbating the above issues. Building on recent advances in segmentation, Chain-of-Thought prompting, and visual question answering, we significantly improve the quality of the paired data. In addition, we enhance the supervision signal by highlighting parts of the image that need to be changed by the instruction. The model fine-tuned on the improved data is capable of performing fine-grained object-centric edits better than state-of-the-art baselines, mitigating the problems outlined above, as shown by automatic and human evaluations. Moreover, our model is capable of generalizing to domains unseen during training, such as visual metaphors.</abstract>
      <url hash="6874da53">2023.findings-emnlp.646</url>
      <bibkey>chakrabarty-etal-2023-learning</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.646</doi>
    </paper>
    <paper id="647">
      <title>Zero-shot Topical Text Classification with <fixed-case>LLM</fixed-case>s - an Experimental Study</title>
      <author><first>Shai</first><last>Gretz</last></author>
      <author><first>Alon</first><last>Halfon</last></author>
      <author><first>Ilya</first><last>Shnayderman</last></author>
      <author><first>Orith</first><last>Toledo-Ronen</last></author>
      <author><first>Artem</first><last>Spector</last></author>
      <author><first>Lena</first><last>Dankin</last></author>
      <author><first>Yannis</first><last>Katsis</last></author>
      <author><first>Ofir</first><last>Arviv</last></author>
      <author><first>Yoav</first><last>Katz</last></author>
      <author><first>Noam</first><last>Slonim</last></author>
      <author><first>Liat</first><last>Ein-Dor</last></author>
      <pages>9647-9676</pages>
      <abstract>Topical Text Classification (TTC) is an ancient, yet timely research area in natural language processing, with many practical applications. The recent dramatic advancements in large LMs raise the question of how well these models can perform in this task in a zero-shot scenario. Here, we share a first comprehensive study, comparing the zero-shot performance of a variety of LMs over TTC23, a large benchmark collection of 23 publicly available TTC datasets, covering a wide range of domains and styles. In addition, we leverage this new TTC benchmark to create LMs that are specialized in TTC, by fine-tuning these LMs over a subset of the datasets and evaluating their performance over the remaining, held-out datasets. We show that the TTC-specialized LMs obtain the top performance on our benchmark, by a significant margin. Our code and model are made available for the community. We hope that the results presented in this work will serve as a useful guide for practitioners interested in topical text classification.</abstract>
      <url hash="cdb0bf5c">2023.findings-emnlp.647</url>
      <bibkey>gretz-etal-2023-zero</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.647</doi>
    </paper>
    <paper id="648">
      <title>Are Personalized Stochastic Parrots More Dangerous? Evaluating Persona Biases in Dialogue Systems</title>
      <author><first>Yixin</first><last>Wan</last></author>
      <author><first>Jieyu</first><last>Zhao</last></author>
      <author><first>Aman</first><last>Chadha</last></author>
      <author><first>Nanyun</first><last>Peng</last></author>
      <author><first>Kai-Wei</first><last>Chang</last></author>
      <pages>9677-9705</pages>
      <abstract>Recent advancements in Large Language Models empower them to follow freeform instructions, including imitating generic or specific demographic personas in conversations. We define generic personas to represent demographic groups, such as “an Asian person”, whereas specific personas may take the form of specific popular Asian names like “Yumi”. While the adoption of personas enriches user experiences by making dialogue systems more engaging and approachable, it also casts a shadow of potential risk by exacerbating social biases within model responses, thereby causing societal harm through interactions with users. In this paper, we systematically study “persona biases”, which we define to be the sensitivity of dialogue models’ harmful behaviors contingent upon the personas they adopt. We categorize persona biases into biases in harmful expression and harmful agreement, and establish a comprehensive evaluation framework to measure persona biases in five aspects: Offensiveness, Toxic Continuation, Regard, Stereotype Agreement, and Toxic Agreement. Additionally, we propose to investigate persona biases by experimenting with UNIVERSALPERSONA, a systematically constructed persona dataset encompassing various types of both generic and specific model personas. Through benchmarking on four different models- including Blender, ChatGPT, Alpaca, and Vicuna- our study uncovers significant persona biases in dialogue systems. Our findings also underscore the pressing need to revisit the use of personas in dialogue agents to ensure safe application.</abstract>
      <url hash="2374fd17">2023.findings-emnlp.648</url>
      <bibkey>wan-etal-2023-personalized</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.648</doi>
    </paper>
    <paper id="649">
      <title>A Black-Box Attack on Code Models via Representation Nearest Neighbor Search</title>
      <author><first>Jie</first><last>Zhang</last></author>
      <author><first>Wei</first><last>Ma</last></author>
      <author><first>Qiang</first><last>Hu</last></author>
      <author><first>Shangqing</first><last>Liu</last></author>
      <author><first>Xiaofei</first><last>Xie</last></author>
      <author><first>Yves</first><last>Le Traon</last></author>
      <author id="yang-liu"><first>Yang</first><last>Liu</last></author>
      <pages>9706-9716</pages>
      <abstract>Existing methods for generating adversarial code examples face several challenges: limted availability of substitute variables, high verification costs for these substitutes, and the creation of adversarial samples with noticeable perturbations. To address these concerns, our proposed approach, RNNS, uses a search seed based on historical attacks to find potential adversarial substitutes. Rather than directly using the discrete substitutes, they are mapped to a continuous vector space using a pre-trained variable name encoder. Based on the vector representation, RNNS predicts and selects better substitutes for attacks. We evaluated the performance of RNNS across six coding tasks encompassing three programming languages: Java, Python, and C. We employed three pre-trained code models (CodeBERT, GraphCodeBERT, and CodeT5) that resulted in a cumulative of 18 victim models. The results demonstrate that RNNS outperforms baselines in terms of ASR and QT. Furthermore, the perturbation of adversarial examples introduced by RNNS is smaller compared to the baselines in terms of the number of replaced variables and the change in variable length. Lastly, our experiments indicate that RNNS is efficient in attacking defended models and can be employed for adversarial training.</abstract>
      <url hash="9d98d1e4">2023.findings-emnlp.649</url>
      <bibkey>zhang-etal-2023-black</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.649</doi>
    </paper>
    <paper id="650">
      <title>How Well Do Text Embedding Models Understand Syntax?</title>
      <author><first>Yan</first><last>Zhang</last></author>
      <author><first>Zhaopeng</first><last>Feng</last></author>
      <author><first>Zhiyang</first><last>Teng</last></author>
      <author><first>Zuozhu</first><last>Liu</last></author>
      <author><first>Haizhou</first><last>Li</last></author>
      <pages>9717-9728</pages>
      <abstract>Text embedding models have significantly contributed to advancements in natural language processing by adeptly capturing semantic properties of textual data. However, the ability of these models to generalize across a wide range of syntactic contexts remains under-explored. In this paper, we first develop an evaluation set, named SR, to scrutinize the capability for syntax understanding of text embedding models from two crucial syntactic aspects: Structural heuristics, and Relational understanding among concepts, as revealed by the performance gaps in previous studies. Our findings reveal that existing text embedding models have not sufficiently addressed these syntactic understanding challenges, and such ineffectiveness becomes even more apparent when evaluated against existing benchmark datasets. Furthermore, we conduct rigorous analysis to unearth factors that lead to such limitations and examine why previous evaluations fail to detect such ineffectiveness. Lastly, we propose strategies to augment the generalization ability of text embedding models in diverse syntactic scenarios. This study serves to highlight the hurdles associated with syntactic generalization and provides pragmatic guidance for boosting model performance across varied syntactic contexts.</abstract>
      <url hash="7289a3bd">2023.findings-emnlp.650</url>
      <bibkey>zhang-etal-2023-well</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.650</doi>
    </paper>
    <paper id="651">
      <title><fixed-case>CASSI</fixed-case>: Contextual and Semantic Structure-based Interpolation Augmentation for Low-Resource <fixed-case>NER</fixed-case></title>
      <author><first>Tanmay</first><last>Surana</last></author>
      <author><first>Thi-Nga</first><last>Ho</last></author>
      <author><first>Kyaw</first><last>Tun</last></author>
      <author><first>Eng Siong</first><last>Chng</last></author>
      <pages>9729-9742</pages>
      <abstract>While text augmentation methods have been successful in improving performance in the low-resource setting, they suffer from annotation corruption for a token-level task like NER. Moreover, existing methods cannot reliably add context diversity to the dataset, which has been shown to be crucial for low-resource NER. In this work, we propose Contextual and Semantic Structure-based Interpolation (CASSI), a novel augmentation scheme that generates high-quality contextually diverse augmentations while avoiding annotation corruption by structurally combining a pair of semantically similar sentences to generate a new sentence while maintaining semantic correctness and fluency. To accomplish this, we generate candidate augmentations by performing multiple dependency parsing-based exchanges in a pair of semantically similar sentences that are filtered via scoring with a pretrained Masked Language Model and a metric to promote specificity. Experiments show that CASSI consistently outperforms existing methods at multiple low resource levels, in multiple languages, and for noisy and clean text.</abstract>
      <url hash="b996052a">2023.findings-emnlp.651</url>
      <bibkey>surana-etal-2023-cassi</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.651</doi>
    </paper>
    <paper id="652">
      <title><fixed-case>NEWTON</fixed-case>: Are Large Language Models Capable of Physical Reasoning?</title>
      <author><first>Yi</first><last>Wang</last></author>
      <author><first>Jiafei</first><last>Duan</last></author>
      <author><first>Dieter</first><last>Fox</last></author>
      <author><first>Siddhartha</first><last>Srinivasa</last></author>
      <pages>9743-9758</pages>
      <abstract>Large Language Models (LLMs), through their contextualized representations, have been empirically proven to encapsulate syntactic, semantic, word sense, and common-sense knowledge. However, there has been limited exploration of their physical reasoning abilities, specifically concerning the crucial attributes for comprehending everyday objects. To address this gap, we introduce NEWTON, a repository and benchmark for evaluating the physics reasoning skills of LLMs. Further, to enable domain-specific adaptation of this benchmark, we present a pipeline to enable researchers to generate a variant of this benchmark that has been customized to the objects and attributes relevant for their application. The NEWTON repository comprises a collection of 2800 object-attribute pairs, providing the foundation for generating infinite-scale assessment templates. The NEWTON benchmark consists of 160K QA questions, curated using the NEWTON repository to investigate the physical reasoning capabilities of several mainstream language models across foundational, explicit, and implicit reasoning tasks. Through extensive empirical analysis, our results highlight the capabilities of LLMs for physical reasoning. We find that LLMs like GPT-4 demonstrate strong reasoning capabilities in scenario-based tasks but exhibit less consistency in object-attribute reasoning compared to humans (50% vs. 84%). Furthermore, the NEWTON platform demonstrates its potential for evaluating and enhancing language models, paving the way for their integration into physically grounded settings, such as robotic manipulation. Project site: https://newtonreasoning.github.io</abstract>
      <url hash="63b6ad44">2023.findings-emnlp.652</url>
      <bibkey>wang-etal-2023-newton</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.652</doi>
    </paper>
    <paper id="653">
      <title>Beyond Denouncing Hate: Strategies for Countering Implied Biases and Stereotypes in Language</title>
      <author><first>Jimin</first><last>Mun</last></author>
      <author><first>Emily</first><last>Allaway</last></author>
      <author><first>Akhila</first><last>Yerukola</last></author>
      <author><first>Laura</first><last>Vianna</last></author>
      <author><first>Sarah-Jane</first><last>Leslie</last></author>
      <author><first>Maarten</first><last>Sap</last></author>
      <pages>9759-9777</pages>
      <abstract>Counterspeech, i.e., responses to counteract potential harms of hateful speech, has become an increasingly popular solution to address online hate speech without censorship. However, properly countering hateful language requires countering and dispelling the underlying inaccurate stereotypes implied by such language. In this work, we draw from psychology and philosophy literature to craft six psychologically inspired strategies to challenge the underlying stereotypical implications of hateful language. We first examine the convincingness of each of these strategies through a user study, and then compare their usages in both human- and machine-generated counterspeech datasets. Our results show that human-written counterspeech uses countering strategies that are more specific to the implied stereotype (e.g., counter examples to the stereotype, external factors about the stereotype’s origins), whereas machine-generated counterspeech uses less specific strategies (e.g., generally denouncing the hatefulness of speech). Furthermore, machine generated counterspeech often employs strategies that humans deem less convincing compared to human-produced counterspeech. Our findings point to the importance of accounting for the underlying stereotypical implications of speech when generating counterspeech and for better machine reasoning about anti-stereotypical examples.</abstract>
      <url hash="abd35f9f">2023.findings-emnlp.653</url>
      <bibkey>mun-etal-2023-beyond</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.653</doi>
    </paper>
    <paper id="654">
      <title>On the Calibration of Large Language Models and Alignment</title>
      <author><first>Chiwei</first><last>Zhu</last></author>
      <author><first>Benfeng</first><last>Xu</last></author>
      <author><first>Quan</first><last>Wang</last></author>
      <author><first>Yongdong</first><last>Zhang</last></author>
      <author><first>Zhendong</first><last>Mao</last></author>
      <pages>9778-9795</pages>
      <abstract>As large language models attract increasing attention and find widespread application, concurrent challenges of reliability also arise at the same time. Confidence calibration, an effective analysis method for gauging the reliability of deep models, serves as a crucial tool for assessing and improving their reliability. However, such investigation has been comparatively underexplored. In this work, we conduct a systematic examination of the calibration of aligned language models throughout the entire construction process, including pretraining and alignment training. At each stage, we investigate how different training settings, such as parameter scales and training data, affect model calibration. To thoroughly assess model calibration, we evaluate models on three most concerned aspects: generation, factuality and understanding. Our work sheds light on whether popular LLMs are well-calibrated and how the training process influences model calibration.</abstract>
      <url hash="71faee2b">2023.findings-emnlp.654</url>
      <bibkey>zhu-etal-2023-calibration</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.654</doi>
    </paper>
    <paper id="655">
      <title><fixed-case>TCRA</fixed-case>-<fixed-case>LLM</fixed-case>: Token Compression Retrieval Augmented Large Language Model for Inference Cost Reduction</title>
      <author><first>Junyi</first><last>Liu</last></author>
      <author><first>Liangzhi</first><last>Li</last></author>
      <author><first>Tong</first><last>Xiang</last></author>
      <author><first>Bowen</first><last>Wang</last></author>
      <author><first>Yiming</first><last>Qian</last></author>
      <pages>9796-9810</pages>
      <abstract>Since ChatGPT released its API for public use, the number of applications built on top of commercial large language models (LLMs) increase exponentially. One popular usage of such models is leveraging its in-context learning ability and generating responses given user queries leveraging knowledge obtained by retrieval augmentation. One problem of deploying commercial retrieval-augmented LLMs is the cost due to the additionally retrieved context that largely increases the input token size of the LLMs. To mitigate this, we propose a token compression scheme that includes two methods: summarization compression and semantic compression. The first method applies a T5-based model that is fine-tuned by datasets generated using self-instruct containing samples with varying lengths and reduce token size by doing summarization. The second method further compresses the token size by removing words with lower impact on the semantic. In order to adequately evaluate the effectiveness of the proposed methods, we propose and utilize a dataset called Food-Recommendation DB (FRDB) focusing on food recommendation for women around pregnancy period or infants. Our summarization compression can reduce 65% of the retrieval token size with further 0.3% improvement on the accuracy; semantic compression provides a more flexible way to trade-off the token size with performance, for which we can reduce the token size by 20% with only 1.6% of accuracy drop.</abstract>
      <url hash="39a1b1bb">2023.findings-emnlp.655</url>
      <bibkey>liu-etal-2023-tcra</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.655</doi>
    </paper>
    <paper id="656">
      <title>Identifying Conspiracy Theories News based on Event Relation Graph</title>
      <author><first>Yuanyuan</first><last>Lei</last></author>
      <author><first>Ruihong</first><last>Huang</last></author>
      <pages>9811-9822</pages>
      <abstract>Conspiracy theories, as a type of misinformation, are narratives that explains an event or situation in an irrational or malicious manner. While most previous work examined conspiracy theory in social media short texts, limited attention was put on such misinformation in long news documents. In this paper, we aim to identify whether a news article contains conspiracy theories. We observe that a conspiracy story can be made up by mixing uncorrelated events together, or by presenting an unusual distribution of relations between events. Achieving a contextualized understanding of events in a story is essential for detecting conspiracy theories. Thus, we propose to incorporate an event relation graph for each article, in which events are nodes, and four common types of event relations, coreference, temporal, causal, and subevent relations, are considered as edges. Then, we integrate the event relation graph into conspiracy theory identification in two ways: an event-aware language model is developed to augment the basic language model with the knowledge of events and event relations via soft labels; further, a heterogeneous graph attention network is designed to derive a graph embedding based on hard labels. Experiments on a large benchmark dataset show that our approach based on event relation graph improves both precision and recall of conspiracy theory identification, and generalizes well for new unseen media sources.</abstract>
      <url hash="dfe6d73d">2023.findings-emnlp.656</url>
      <bibkey>lei-huang-2023-identifying</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.656</doi>
    </paper>
    <paper id="657">
      <title>Salespeople vs <fixed-case>S</fixed-case>ales<fixed-case>B</fixed-case>ot: Exploring the Role of Educational Value in Conversational Recommender Systems</title>
      <author><first>Lidiya</first><last>Murakhovs’ka</last></author>
      <author><first>Philippe</first><last>Laban</last></author>
      <author><first>Tian</first><last>Xie</last></author>
      <author><first>Caiming</first><last>Xiong</last></author>
      <author><first>Chien-Sheng</first><last>Wu</last></author>
      <pages>9823-9838</pages>
      <abstract>Making big purchases requires consumers to research or consult a salesperson to gain domain expertise. However, existing conversational recommender systems (CRS) often overlook users’ lack of background knowledge, focusing solely on gathering preferences. In this work, we define a new problem space for conversational agents that aim to provide both product recommendations and educational value through mixed-type mixed-initiative dialog. We introduce SalesOps, a framework that facilitates the simulation and evaluation of such systems by leveraging recent advancements in large language models (LLMs). We build SalesBot and ShopperBot, a pair of LLM-powered agents that can simulate either side of the framework. A comprehensive human study compares SalesBot against professional salespeople, revealing that although SalesBot approaches professional performance in terms of fluency and informativeness, it lags behind in recommendation quality. We emphasize the distinct limitations both face in providing truthful information, highlighting the challenges of ensuring faithfulness in the CRS context. We release our code and make all data available.</abstract>
      <url hash="887c4755">2023.findings-emnlp.657</url>
      <bibkey>murakhovska-etal-2023-salespeople</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.657</doi>
    </paper>
    <paper id="658">
      <title>Dynamic Open-book Prompt for Conversational Recommender System</title>
      <author><first>Xuan</first><last>Ma</last></author>
      <author><first>Tieyun</first><last>Qian</last></author>
      <author><first>Ke</first><last>Sun</last></author>
      <pages>9839-9849</pages>
      <abstract>Conversational Recommender System (CRS) aims to deliver personalized recommendations through interactive dialogues. Recent advances in prompt learning have shed light on this task. However, the performance of existing methods is confined by the limited context within ongoing conversations. Moreover, these methods utilize training samples only for prompt parameter training. The constructed prompt lacks the ability to refer to the training data during inference, which exacerbates the problem of limited context. To solve this problem, we propose a novel Dynamic Open-book Prompt approach, where the open book stores users’ experiences in historical data, and we dynamically construct the prompt to memorize the user’s current utterance and selectively retrieve relevant contexts from the open book. Specifically, we first build an item-recommendation graph from the open book and convolute on the graph to form a base prompt which contains more information besides the finite dialogue. Then, we enhance the representation learning process of the prompt by tailoring similar contexts in the graph into the prompt to meet the user’s current need. This ensures the prompt provides targeted suggestions that are both informed and contextually relevant. Extensive experimental results on the ReDial dataset demonstrate the significant improvements achieved by our proposed model over the state-of-the-art methods. Our code and data are available at https://github.com/NLPWM-WHU/DOP.</abstract>
      <url hash="12965d71">2023.findings-emnlp.658</url>
      <bibkey>ma-etal-2023-dynamic</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.658</doi>
    </paper>
    <paper id="659">
      <title>Auto-Instruct: Automatic Instruction Generation and Ranking for Black-Box Language Models</title>
      <author><first>Zhihan</first><last>Zhang</last></author>
      <author><first>Shuohang</first><last>Wang</last></author>
      <author><first>Wenhao</first><last>Yu</last></author>
      <author><first>Yichong</first><last>Xu</last></author>
      <author><first>Dan</first><last>Iter</last></author>
      <author><first>Qingkai</first><last>Zeng</last></author>
      <author id="yang-liu-edinburgh"><first>Yang</first><last>Liu</last></author>
      <author><first>Chenguang</first><last>Zhu</last></author>
      <author><first>Meng</first><last>Jiang</last></author>
      <pages>9850-9867</pages>
      <abstract>Large language models (LLMs) can perform a wide range of tasks by following natural language instructions, without the necessity of task-specific fine-tuning. Unfortunately, the performance of LLMs is greatly influenced by the quality of these instructions, and manually writing effective instructions for each task is a laborious and subjective process. In this paper, we introduce Auto-Instruct, a novel method to automatically improve the quality of instructions provided to LLMs. Our method leverages the inherent generative ability of LLMs to produce diverse candidate instructions for a given task, and then ranks them using a scoring model trained on a variety of 575 existing NLP tasks. In experiments on 118 out-of-domain tasks, Auto-Instruct surpasses both human-written instructions and existing baselines of LLM-generated instructions. Furthermore, our method exhibits notable generalizability even with other LLMs that are not incorporated into its training process.</abstract>
      <url hash="656c3fbd">2023.findings-emnlp.659</url>
      <bibkey>zhang-etal-2023-auto</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.659</doi>
    </paper>
    <paper id="660">
      <title><fixed-case>D</fixed-case>iffu<fixed-case>S</fixed-case>eq-v2: Bridging Discrete and Continuous Text Spaces for Accelerated <fixed-case>S</fixed-case>eq2<fixed-case>S</fixed-case>eq Diffusion Models</title>
      <author><first>Shansan</first><last>Gong</last></author>
      <author><first>Mukai</first><last>Li</last></author>
      <author><first>Jiangtao</first><last>Feng</last></author>
      <author><first>Zhiyong</first><last>Wu</last></author>
      <author><first>Lingpeng</first><last>Kong</last></author>
      <pages>9868-9875</pages>
      <abstract>Diffusion models have gained prominence in generating high-quality sequences of text. Nevertheless, current approaches predominantly represent discrete text within a continuous diffusion space, which incurs substantial computational overhead during training and results in slower sampling speeds. In this paper, we introduce a soft absorbing state that facilitates the diffusion model in learning to reconstruct discrete mutations based on the underlying Gaussian space, thereby enhancing its capacity to recover conditional signals. During the sampling phase, we employ state-of-the-art ODE solvers within the continuous space to expedite the sampling process. Comprehensive experimental evaluations reveal that our proposed method effectively accelerates the training convergence by 4x and generates samples of similar quality 800x faster, rendering it significantly closer to practical application.</abstract>
      <url hash="1a35e246">2023.findings-emnlp.660</url>
      <bibkey>gong-etal-2023-diffuseq</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.660</doi>
    </paper>
    <paper id="661">
      <title><fixed-case>M</fixed-case>2<fixed-case>C</fixed-case>: Towards Automatic Multimodal Manga Complement</title>
      <author><first>Hongcheng</first><last>Guo</last></author>
      <author><first>Boyang</first><last>Wang</last></author>
      <author><first>Jiaqi</first><last>Bai</last></author>
      <author><first>Jiaheng</first><last>Liu</last></author>
      <author><first>Jian</first><last>Yang</last></author>
      <author><first>Zhoujun</first><last>Li</last></author>
      <pages>9876-9882</pages>
      <abstract>Multimodal manga analysis focuses on enhancing manga understanding with visual and textual features, which has attracted considerable attention from both natural language processing and computer vision communities. Currently, most comics are hand-drawn and prone to problems such as missing pages, text contamination, and text aging, resulting in missing comic text content and seriously hindering human comprehension. In other words, the Multimodal Manga Complement (<b>M2C</b>) task has not been investigated, which aims to handle the aforementioned issues by providing a shared semantic space for vision and language understanding. To this end, we first propose the Multimodal Manga Complement task by establishing a new M2C benchmark dataset covering two languages. First, we design a manga argumentation method called MCoT to mine event knowledge in comics with large language models. Then, an effective baseline FVP-M<tex-math>^{2}</tex-math> using fine-grained visual prompts is proposed to support manga complement. Extensive experimental results show the effectiveness of FVP-M<tex-math>^{2}</tex-math> method for Multimodal Mange Complement.</abstract>
      <url hash="a9beca94">2023.findings-emnlp.661</url>
      <bibkey>guo-etal-2023-m2c</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.661</doi>
    </paper>
    <paper id="662">
      <title>Learn Your Tokens: Word-Pooled Tokenization for Language Modeling</title>
      <author><first>Avijit</first><last>Thawani</last></author>
      <author><first>Saurabh</first><last>Ghanekar</last></author>
      <author><first>Xiaoyuan</first><last>Zhu</last></author>
      <author><first>Jay</first><last>Pujara</last></author>
      <pages>9883-9893</pages>
      <abstract>Language models typically tokenize text into subwords, using a deterministic, hand-engineered heuristic of combining characters into longer surface-level strings such as ‘ing’ or whole words. Recent literature has repeatedly shown the limitations of such a tokenization strategy, particularly for documents not written in English and for representing numbers. On the other extreme, byte/character-level language models are much less restricted but suffer from increased sequence description lengths and a subsequent quadratic expansion in self-attention computation. Recent attempts to compress and limit these context lengths with fixed size convolutions is helpful but completely ignores the word boundary. This paper considers an alternative ‘learn your tokens’ scheme which utilizes the word boundary to pool bytes/characters into word representations, which are fed to the primary language model, before again decoding individual characters/bytes per word in parallel. We find that our moderately expressive and moderately fast end-to-end tokenizer outperform by over ‘300%‘ both subwords and byte/character models over the intrinsic language modeling metric of next-word prediction across datasets. It particularly outshines on rare words, outperforming by a factor of 30! We extensively study the language modeling setup for all three categories of tokenizers and theoretically analyze how our end-to-end models can also be a strong trade-off in efficiency and robustness.</abstract>
      <url hash="738dba5a">2023.findings-emnlp.662</url>
      <bibkey>thawani-etal-2023-learn</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.662</doi>
    </paper>
    <paper id="663">
      <title>Towards Detecting Contextual Real-Time Toxicity for In-Game Chat</title>
      <author><first>Zachary</first><last>Yang</last></author>
      <author><first>Nicolas</first><last>Grenon-Godbout</last></author>
      <author><first>Reihaneh</first><last>Rabbany</last></author>
      <pages>9894-9906</pages>
      <abstract>Real-time toxicity detection in online environments poses a significant challenge, due to the increasing prevalence of social media and gaming platforms. We introduce ToxBuster, a simple and scalable model that reliably detects toxic content in real-time for a line of chat by including chat history and metadata. ToxBuster consistently outperforms conventional toxicity models across popular multiplayer games, including Rainbow Six Siege, For Honor, and DOTA 2. We conduct an ablation study to assess the importance of each model component and explore ToxBuster’s transferability across the datasets. Furthermore, we showcase ToxBuster’s efficacy in post-game moderation, successfully flagging 82.1% of chat-reported players at a precision level of 90.0%. Additionally, we show how an additional 6% of unreported toxic players can be proactively moderated.</abstract>
      <url hash="37202b65">2023.findings-emnlp.663</url>
      <bibkey>yang-etal-2023-towards-detecting</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.663</doi>
    </paper>
    <paper id="664">
      <title><fixed-case>JWS</fixed-case>ign: A Highly Multilingual Corpus of <fixed-case>B</fixed-case>ible Translations for more Diversity in Sign Language Processing</title>
      <author><first>Shester</first><last>Gueuwou</last></author>
      <author><first>Sophie</first><last>Siake</last></author>
      <author><first>Colin</first><last>Leong</last></author>
      <author><first>Mathias</first><last>Müller</last></author>
      <pages>9907-9927</pages>
      <abstract>Advancements in sign language processing have been hindered by a lack of sufficient data, impeding progress in recognition, translation, and production tasks. The absence of comprehensive sign language datasets across the world’s sign languages has widened the gap in this field, resulting in a few sign languages being studied more than others, making this research area extremely skewed mostly towards sign languages from high-income countries. In this work we introduce a new large and highly multilingual dataset for sign language translation: JWSign. The dataset consists of 2,530 hours of Bible translations in 98 sign languages, featuring more than 1,500 individual signers. On this dataset, we report neural machine translation experiments. Apart from bilingual baseline systems, we also train multilingual systems, including some that take into account the typological relatedness of signed or spoken languages. Our experiments highlight that multilingual systems are superior to bilingual baselines, and that in higher-resource scenarios, clustering language pairs that are related improves translation quality.</abstract>
      <url hash="2b873834">2023.findings-emnlp.664</url>
      <bibkey>gueuwou-etal-2023-jwsign</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.664</doi>
    </paper>
    <paper id="665">
      <title>Do Stochastic Parrots have Feelings Too? Improving Neural Detection of Synthetic Text via Emotion Recognition</title>
      <author><first>Alan</first><last>Cowap</last></author>
      <author><first>Yvette</first><last>Graham</last></author>
      <author><first>Jennifer</first><last>Foster</last></author>
      <pages>9928-9946</pages>
      <abstract>Recent developments in generative AI have shone a spotlight on high-performance synthetic text generation technologies. The now wide availability and ease of use of such models highlights the urgent need to provide equally powerful technologies capable of identifying synthetic text. With this in mind, we draw inspiration from psychological studies which suggest that people can be driven by emotion and encode emotion in the text they compose. We hypothesize that pretrained language models (PLMs) have an affective deficit because they lack such an emotional driver when generating text and consequently may generate synthetic text which has affective incoherence i.e. lacking the kind of emotional coherence present in human-authored text. We subsequently develop an emotionally aware detector by fine-tuning a PLM on emotion. Experiment results indicate that our emotionally-aware detector achieves improvements across a range of synthetic text generators, various sized models, datasets, and domains. Finally, we compare our emotionally-aware synthetic text detector to ChatGPT in the task of identification of its own output and show substantial gains, reinforcing the potential of emotion as a signal to identify synthetic text. Code, models, and datasets are available at https: //github.com/alanagiasi/emoPLMsynth</abstract>
      <url hash="87adf2b3">2023.findings-emnlp.665</url>
      <bibkey>cowap-etal-2023-stochastic</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.665</doi>
    </paper>
    <paper id="666">
      <title>Variator: Accelerating Pre-trained Models with Plug-and-Play Compression Modules</title>
      <author><first>Chaojun</first><last>Xiao</last></author>
      <author><first>Yuqi</first><last>Luo</last></author>
      <author><first>Wenbin</first><last>Zhang</last></author>
      <author><first>Pengle</first><last>Zhang</last></author>
      <author><first>Xu</first><last>Han</last></author>
      <author><first>Yankai</first><last>Lin</last></author>
      <author><first>Zhengyan</first><last>Zhang</last></author>
      <author><first>Ruobing</first><last>Xie</last></author>
      <author><first>Zhiyuan</first><last>Liu</last></author>
      <author><first>Maosong</first><last>Sun</last></author>
      <author><first>Jie</first><last>Zhou</last></author>
      <pages>9947-9959</pages>
      <abstract>Large language models (LLMs) have achieved remarkable results on NLP tasks but at the expense of huge parameter sizes and the consequent computational costs. In this paper, we propose Variator, a parameter-efficient acceleration method that enhances computational efficiency through plug-and-play compression plugins. Compression plugins are designed to reduce the sequence length via compressing multiple hidden vectors into one and trained with original LLMs frozen. Different from traditional model acceleration methods, which compress LLMs to smaller sizes, Variator offers two distinct advantages: (1) In real-world applications, the plug-and-play nature of our compression plugins enables dynamic selection of different compression plugins with varying acceleration ratios based on the current workload. (2) The compression plugin comprises a few compact neural network layers with minimal parameters, significantly saving storage and memory overhead, particularly in scenarios with a growing number of tasks. We validate the effectiveness of Variator on seven datasets. Experimental results show that Variator can save 53% computational costs using only 0.9% additional parameters with a performance drop of less than 2%. Moreover, when the model scales to billions of parameters, Variator matches the strong performance of uncompressed LLMs. Our code and checkpoints will be released to facilitate future work.</abstract>
      <url hash="d88d6624">2023.findings-emnlp.666</url>
      <bibkey>xiao-etal-2023-variator</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.666</doi>
    </paper>
    <paper id="667">
      <title><fixed-case>P</fixed-case>ivot<fixed-case>FEC</fixed-case>: Enhancing Few-shot Factual Error Correction with a Pivot Task Approach using Large Language Models</title>
      <author><first>Xingwei</first><last>He</last></author>
      <author><first>A-Long</first><last>Jin</last></author>
      <author><first>Jun</first><last>Ma</last></author>
      <author><first>Yuan</first><last>Yuan</last></author>
      <author><first>Siu</first><last>Yiu</last></author>
      <pages>9960-9976</pages>
      <abstract>Factual Error Correction (FEC) aims to rectify false claims by making minimal revisions to align them more accurately with supporting evidence. However, the lack of datasets containing false claims and their corresponding corrections has impeded progress in this field. Existing distantly supervised models typically employ the mask-then-correct paradigm, where a masker identifies problematic spans in false claims, followed by a corrector to predict the masked portions. Unfortunately, accurately identifying errors in claims is challenging, leading to issues like over-erasure and incorrect masking. To overcome these challenges, we present PivotFEC, a method that enhances few-shot FEC with a pivot task approach using large language models (LLMs). Specifically, we introduce a pivot task called factual error injection, which leverages LLMs (e.g., ChatGPT) to intentionally generate text containing factual errors under few-shot settings; then, the generated text with factual errors can be used to train the FEC corrector. Our experiments on a public dataset demonstrate the effectiveness of PivotFEC in two significant ways: Firstly, it improves the widely-adopted SARI metrics by 11.3 compared to the best-performing distantly supervised methods. Secondly, it outperforms its few-shot counterpart (i.e., LLMs are directly used to solve FEC) by 7.9 points in SARI, validating the efficacy of our proposed pivot task.</abstract>
      <url hash="2b3fc6cf">2023.findings-emnlp.667</url>
      <bibkey>he-etal-2023-pivotfec</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.667</doi>
    </paper>
    <paper id="668">
      <title>Semantic Similarity Covariance Matrix Shrinkage</title>
      <author><first>Guillaume</first><last>Becquin</last></author>
      <author><first>Saher</first><last>Esmeir</last></author>
      <pages>9977-9992</pages>
      <abstract>An accurate estimation of the covariance matrix is a critical component of many applications in finance, including portfolio optimization. The sample covariance suffers from the curse of dimensionality when the number of observations is in the same order or lower than the number of variables. This tends to be the case in portfolio optimization, where a portfolio manager can choose between thousands of stocks using historical daily returns to guide their investment decisions. To address this issue, past works proposed linear covariance shrinkage to regularize the estimated matrix. While effective, the proposed methods relied solely on historical price data and thus ignored company fundamental data. In this work, we propose to utilise semantic similarity derived from textual descriptions or knowledge graphs to improve the covariance estimation. Rather than using the semantic similarity directly as a biased estimator to the covariance, we employ it as a shrinkage target. The resulting covariance estimators leverage both semantic similarity and recent price history, and can be readily adapted to a broad range of financial securities. The effectiveness of the approach is demonstrated for a period including diverse market conditions and compared with the covariance shrinkage prior art.</abstract>
      <url hash="2e191d1a">2023.findings-emnlp.668</url>
      <bibkey>becquin-esmeir-2023-semantic</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.668</doi>
    </paper>
    <paper id="669">
      <title><fixed-case>LLM</fixed-case>-in-the-loop: Leveraging Large Language Model for Thematic Analysis</title>
      <author><first>Shih-Chieh</first><last>Dai</last></author>
      <author><first>Aiping</first><last>Xiong</last></author>
      <author><first>Lun-Wei</first><last>Ku</last></author>
      <pages>9993-10001</pages>
      <abstract>Thematic analysis (TA) has been widely used for analyzing qualitative data in many disciplines and fields. To ensure reliable analysis, the same piece of data is typically assigned to at least two human coders. Moreover, to produce meaningful and useful analysis, human coders develop and deepen their data interpretation and coding over multiple iterations, making TA labor-intensive and time-consuming. Recently the emerging field of large language models (LLMs) research has shown that LLMs have the potential replicate human-like behavior in various tasks: in particular, LLMs outperform crowd workers on text-annotation tasks, suggesting an opportunity to leverage LLMs on TA. We propose a human–LLM collaboration framework (i.e., LLM-in-the-loop) to conduct TA with in-context learning (ICL). This framework provides the prompt to frame discussions with a LLM (e.g., GPT-3.5) to generate the final codebook for TA. We demonstrate the utility of this framework using survey datasets on the aspects of the music listening experience and the usage of a password manager. Results of the two case studies show that the proposed framework yields similar coding quality to that of human coders but reduces TA’s labor and time demands.</abstract>
      <url hash="55dca442">2023.findings-emnlp.669</url>
      <bibkey>dai-etal-2023-llm</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.669</doi>
    </paper>
    <paper id="670">
      <title><fixed-case>LLM</fixed-case> aided semi-supervision for efficient Extractive Dialog Summarization</title>
      <author><first>Nishant</first><last>Mishra</last></author>
      <author><first>Gaurav</first><last>Sahu</last></author>
      <author><first>Iacer</first><last>Calixto</last></author>
      <author><first>Ameen</first><last>Abu-Hanna</last></author>
      <author><first>Issam</first><last>Laradji</last></author>
      <pages>10002-10009</pages>
      <abstract>Generating high-quality summaries for chat dialogs often requires large labeled datasets. We propose a method to efficiently use unlabeled data for extractive summarization of customer-agent dialogs. In our method, we frame summarization as a question-answering problem and use state-of-the-art large language models (LLMs) to generate pseudo-labels for a dialog. We then use these pseudo-labels to fine-tune a chat summarization model, effectively transferring knowledge from the large LLM into a smaller specialized model. We demonstrate our method on the TWEETSUMM dataset, and show that using 10% of the original labelled data set we can achieve 65.9/57.0/61.0 ROUGE-1/-2/-L, whereas the current state-of-the-art trained on the entire training data set obtains 65.16/55.81/64.37 ROUGE-1/-2/-L. In other words, in the worst case (i.e., ROUGE-L) we still effectively retain 94.7% of the performance while using only 10% of the data.</abstract>
      <url hash="9175a69b">2023.findings-emnlp.670</url>
      <bibkey>mishra-etal-2023-llm</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.670</doi>
    </paper>
    <paper id="671">
      <title>Investigating Multilingual Coreference Resolution by Universal Annotations</title>
      <author><first>Haixia</first><last>Chai</last></author>
      <author><first>Michael</first><last>Strube</last></author>
      <pages>10010-10024</pages>
      <abstract>Multilingual coreference resolution (MCR) has been a long-standing and challenging task. With the newly proposed multilingual coreference dataset, CorefUD (Nedoluzhko et al., 2022), we conduct an investigation into the task by using its harmonized universal morphosyntactic and coreference annotations. First, we study coreference by examining the ground truth data at different linguistic levels, namely mention, entity and document levels, and across different genres, to gain insights into the characteristics of coreference across multiple languages. Second, we perform an error analysis of the most challenging cases that the SotA system fails to resolve in the CRAC 2022 shared task using the universal annotations. Last, based on this analysis, we extract features from universal morphosyntactic annotations and integrate these features into a baseline system to assess their potential benefits for the MCR task. Our results show that our best configuration of features improves the baseline by 0.9% F1 score.</abstract>
      <url hash="aad75714">2023.findings-emnlp.671</url>
      <bibkey>chai-strube-2023-investigating</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.671</doi>
    </paper>
    <paper id="672">
      <title><fixed-case>F</fixed-case>act<fixed-case>S</fixed-case>potter: Evaluating the Factual Faithfulness of Graph-to-Text Generation</title>
      <author><first>Kun</first><last>Zhang</last></author>
      <author><first>Oana</first><last>Balalau</last></author>
      <author><first>Ioana</first><last>Manolescu</last></author>
      <pages>10025-10042</pages>
      <abstract>Graph-to-text (G2T) generation takes a graph as input and aims to generate a fluent and faith- ful textual representation of the information in the graph. The task has many applications, such as dialogue generation and question an- swering. In this work, we investigate to what extent the G2T generation problem is solved for previously studied datasets, and how pro- posed metrics perform when comparing generated texts. To help address their limitations, we propose a new metric that correctly identifies factual faithfulness, i.e., given a triple (subject, predicate, object), it decides if the triple is present in a generated text. We show that our metric FactSpotter achieves the highest correlation with human annotations on data correct- ness, data coverage, and relevance. In addition, FactSpotter can be used as a plug-in feature to improve the factual faithfulness of existing models. Finally, we investigate if existing G2T datasets are still challenging for state-of-the-art models. Our code is available online: https://github.com/guihuzhang/FactSpotter.</abstract>
      <url hash="9d0fac1f">2023.findings-emnlp.672</url>
      <bibkey>zhang-etal-2023-factspotter</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.672</doi>
    </paper>
    <paper id="673">
      <title><fixed-case>L</fixed-case>ayout<fixed-case>DIT</fixed-case>: Layout-Aware End-to-End Document Image Translation with Multi-Step Conductive Decoder</title>
      <author><first>Zhiyang</first><last>Zhang</last></author>
      <author><first>Yaping</first><last>Zhang</last></author>
      <author><first>Yupu</first><last>Liang</last></author>
      <author><first>Lu</first><last>Xiang</last></author>
      <author><first>Yang</first><last>Zhao</last></author>
      <author><first>Yu</first><last>Zhou</last></author>
      <author><first>Chengqing</first><last>Zong</last></author>
      <pages>10043-10053</pages>
      <abstract>Document image translation (DIT) aims to translate text embedded in images from one language to another. It is a challenging task that needs to understand visual layout with text semantics simultaneously. However, existing methods struggle to capture the crucial visual layout in real-world complex document images. In this work, we make the first attempt to incorporate layout knowledge into DIT in an end-to-end way. Specifically, we propose a novel Layout-aware end-to-end Document Image Translation (LayoutDIT) with multi-step conductive decoder. A layout-aware encoder is first introduced to model visual layout relations with raw OCR results. Then a novel multi-step conductive decoder is unified with hidden states conduction across three step-decoders to achieve the document translation step by step. Benefiting from the layout-aware end-to-end joint training, our LayoutDIT outperforms state-of-the-art methods with better parameter efficiency. Besides, we create a new multi-domain document image translation dataset to validate the model’s generalization. Extensive experiments show that LayoutDIT has a good generalization in diverse and complex layout scenes.</abstract>
      <url hash="556f2226">2023.findings-emnlp.673</url>
      <bibkey>zhang-etal-2023-layoutdit</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.673</doi>
    </paper>
    <paper id="674">
      <title>Balaur: Language Model Pretraining with Lexical Semantic Relations</title>
      <author><first>Andrei</first><last>Mircea</last></author>
      <author><first>Jackie</first><last>Cheung</last></author>
      <pages>10054-10070</pages>
      <abstract>Lexical semantic relations (LSRs) characterize meaning relationships between words and play an important role in systematic generalization on lexical inference tasks. Notably, several tasks that require knowledge of hypernymy still pose a challenge for pretrained language models (LMs) such as BERT, underscoring the need to better align their linguistic behavior with our knowledge of LSRs. In this paper, we propose Balaur, a model that addresses this challenge by modeling LSRs directly in the LM’s hidden states throughout pretraining. Motivating our approach is the hypothesis that the internal representations of LMs can provide an interface to their observable linguistic behavior, and that by controlling one we can influence the other. We validate our hypothesis and demonstrate that Balaur generally improves the performance of large transformer-based LMs on a comprehensive set of hypernymy-informed tasks, as well as on the original LM objective. Code and data are made available at https://github.com/mirandrom/balaur</abstract>
      <url hash="36faf2b6">2023.findings-emnlp.674</url>
      <bibkey>mircea-cheung-2023-balaur</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.674</doi>
    </paper>
    <paper id="675">
      <title>Exploring In-Context Learning for Knowledge Grounded Dialog Generation</title>
      <author><first>Qinyu</first><last>Chen</last></author>
      <author><first>Wenhao</first><last>Wu</last></author>
      <author><first>Sujian</first><last>Li</last></author>
      <pages>10071-10081</pages>
      <abstract>Large neural-based dialog generation models have been applied in many real-life scenarios, yet they are prone to hallucination and tend to produce factually inaccurate outputs which raise great concerns. To alleviate this problem, we propose a plug-and-play retrieval-based framework IKA, which leverages in-context learning and retrieval techniques to enhance LLMs on knowledge grounded dialog generation. We design thorough experiments on a large-scale knowledge graph with 1M+ facts to investigate the effectiveness and generalization of our framework. Experiments show that our method surpasses previous training-based SOTA by a large margin, specifically 46.67% in BLEU4, 26.01% in ROUGE-L, 122.90% in BARTScore and 30.50% in Entity Coverage F1. Further analysis show promising abilities of LLMs to perform knowledge-intensive tasks, which is previously considered weak and understudied.</abstract>
      <url hash="408e9b52">2023.findings-emnlp.675</url>
      <bibkey>chen-etal-2023-exploring-context</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.675</doi>
    </paper>
    <paper id="676">
      <title>Towards Enhancing Relational Rules for Knowledge Graph Link Prediction</title>
      <author><first>Shuhan</first><last>Wu</last></author>
      <author><first>Huaiyu</first><last>Wan</last></author>
      <author><first>Wei</first><last>Chen</last></author>
      <author><first>Yuting</first><last>Wu</last></author>
      <author><first>Junfeng</first><last>Shen</last></author>
      <author><first>Youfang</first><last>Lin</last></author>
      <pages>10082-10097</pages>
      <abstract>Graph neural networks (GNNs) have shown promising performance for knowledge graph reasoning. A recent variant of GNN called progressive relational graph neural network (PRGNN), utilizes relational rules to infer missing knowledge in relational digraphs and achieves notable results. However, during reasoning with PRGNN, two important properties are often overlooked: (1) the sequentiality of relation composition, where the order of combining different relations affects the semantics of the relational rules, and (2) the lagged entity information propagation, where the transmission speed of required information lags behind the appearance speed of new entities. Ignoring these properties leads to incorrect relational rule learning and decreased reasoning accuracy. To address these issues, we propose a novel knowledge graph reasoning approach, the Relational rUle eNhanced Graph Neural Network (RUN-GNN). Specifically, RUN-GNN employs a query related fusion gate unit to model the sequentiality of relation composition and utilizes a buffering update mechanism to alleviate the negative effect of lagged entity information propagation, resulting in higher-quality relational rule learning. Experimental results on multiple datasets demonstrate the superiority of RUN-GNN is superior on both transductive and inductive link prediction tasks.</abstract>
      <url hash="da3c0ee5">2023.findings-emnlp.676</url>
      <bibkey>wu-etal-2023-towards-enhancing</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.676</doi>
    </paper>
    <paper id="677">
      <title>Are <fixed-case>NLP</fixed-case> Models Good at Tracing Thoughts: An Overview of Narrative Understanding</title>
      <author><first>Lixing</first><last>Zhu</last></author>
      <author><first>Runcong</first><last>Zhao</last></author>
      <author><first>Lin</first><last>Gui</last></author>
      <author><first>Yulan</first><last>He</last></author>
      <pages>10098-10121</pages>
      <abstract>Narrative understanding involves capturing the author’s cognitive processes, providing insights into their knowledge, intentions, beliefs, and desires. Although large language models (LLMs) excel in generating grammatically coherent text, their ability to comprehend the author’s thoughts remains uncertain. This limitation hinders the practical applications of narrative understanding. In this paper, we conduct a comprehensive survey of narrative understanding tasks, thoroughly examining their key features, definitions, taxonomy, associated datasets, training objectives, evaluation metrics, and limitations. Furthermore, we explore the potential of expanding the capabilities of modularized LLMs to address novel narrative understanding tasks. By framing narrative understanding as the retrieval of the author’s imaginative cues that outline the narrative structure, our study introduces a fresh perspective on enhancing narrative comprehension.</abstract>
      <url hash="6c56546f">2023.findings-emnlp.677</url>
      <bibkey>zhu-etal-2023-nlp</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.677</doi>
    </paper>
    <paper id="678">
      <title>Who is Speaking? Speaker-Aware Multiparty Dialogue Act Classification</title>
      <author><first>Ayesha</first><last>Qamar</last></author>
      <author><first>Adarsh</first><last>Pyarelal</last></author>
      <author><first>Ruihong</first><last>Huang</last></author>
      <pages>10122-10135</pages>
      <abstract>Utterances do not occur in isolation in dialogues; it is essential to have the information of who the speaker of an utterance is to be able to recover the speaker’s intention with respect to the surrounding context. Beyond simply capturing speaker switches, identifying how speakers interact with each other in a dialogue is crucial to understanding conversational flow. This becomes increasingly important and simultaneously difficult to model when more than two interlocutors take part in a conversation. To overcome this challenge, we propose to explicitly add speaker awareness to each utterance representation. To that end, we use a graph neural network to model how each speaker is behaving within the local context of a conversation. The speaker representations learned this way are then used to update their respective utterance representations. We experiment with both multiparticipant and dyadic conversations on the MRDA and SwDA datasets and show the effectiveness of our approach.</abstract>
      <url hash="87d7f69b">2023.findings-emnlp.678</url>
      <bibkey>qamar-etal-2023-speaking</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.678</doi>
    </paper>
    <paper id="679">
      <title>Demystifying Prompts in Language Models via Perplexity Estimation</title>
      <author><first>Hila</first><last>Gonen</last></author>
      <author><first>Srini</first><last>Iyer</last></author>
      <author><first>Terra</first><last>Blevins</last></author>
      <author><first>Noah</first><last>Smith</last></author>
      <author><first>Luke</first><last>Zettlemoyer</last></author>
      <pages>10136-10148</pages>
      <abstract>Language models can be prompted to perform a wide variety of tasks with zero- and few-shot in-context learning. However, performance varies significantly with the choice of prompt, and we do not yet understand why this happens. In this paper, we analyze the factors that contribute to this variance and establish a new empirical hypothesis: the performance of a prompt is predicted by the extent to which the model is familiar with the language it contains. Over a wide range of tasks, we show that the lower the perplexity of the prompt, the better it is able to perform the task, when considering reasonable prompts that are related to it. As part of our analysis, we also devise a method to automatically extend a small seed set of manually written prompts by paraphrasing with GPT3 and backtranslation. This larger set allows us to verify that perplexity is a strong predictor of the success of a prompt and we show that the lowest perplexity prompts are consistently effective.</abstract>
      <url hash="b32fe2ea">2023.findings-emnlp.679</url>
      <bibkey>gonen-etal-2023-demystifying</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.679</doi>
    </paper>
    <paper id="680">
      <title><fixed-case>C</fixed-case>2<fixed-case>D</fixed-case>2 Dataset: A Resource for the Cognitive Distortion Analysis and Its Impact on Mental Health</title>
      <author><first>Bichen</first><last>Wang</last></author>
      <author><first>Pengfei</first><last>Deng</last></author>
      <author><first>Yanyan</first><last>Zhao</last></author>
      <author><first>Bing</first><last>Qin</last></author>
      <pages>10149-10160</pages>
      <abstract>Cognitive distortions refer to patterns of irrational thinking that can lead to distorted perceptions of reality and mental health problems in individuals. Despite previous attempts to detect cognitive distortion through language, progress has been slow due to the lack of appropriate data. In this paper, we present the C2D2 dataset, the first expert-supervised <b>C</b>hinese <b>C</b>ognitive <b>D</b>istortion <b>D</b>ataset, which contains 7,500 cognitive distortion thoughts in everyday life scenes. Additionally, we examine the presence of cognitive distortions in social media texts shared by individuals diagnosed with mental disorders, providing insights into the association between cognitive distortions and mental health conditions. We propose that incorporating information about users’ cognitive distortions can enhance the performance of existing models mental disorder detection. We contribute to a better understanding of how cognitive distortions appear in individuals’ language and their impact on mental health.</abstract>
      <url hash="9e01eee0">2023.findings-emnlp.680</url>
      <bibkey>wang-etal-2023-c2d2</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.680</doi>
    </paper>
    <paper id="681">
      <title><fixed-case>M</fixed-case>ix<fixed-case>E</fixed-case>dit: Revisiting Data Augmentation and Beyond for Grammatical Error Correction</title>
      <author><first>Jingheng</first><last>Ye</last></author>
      <author><first>Yinghui</first><last>Li</last></author>
      <author><first>Yangning</first><last>Li</last></author>
      <author><first>Hai-Tao</first><last>Zheng</last></author>
      <pages>10161-10175</pages>
      <abstract>Data Augmentation through generating pseudo data has been proven effective in mitigating the challenge of data scarcity in the field of Grammatical Error Correction (GEC). Various augmentation strategies have been widely explored, most of which are motivated by two heuristics, i.e., increasing the distribution similarity and diversity of pseudo data. However, the underlying mechanism responsible for the effectiveness of these strategies remains poorly understood. In this paper, we aim to clarify how data augmentation improves GEC models. To this end, we introduce two interpretable and computationally efficient measures: Affinity and Diversity. Our findings indicate that an excellent GEC data augmentation strategy characterized by high Affinity and appropriate Diversity can better improve the performance of GEC models. Based on this observation, we propose MixEdit, a data augmentation approach that strategically and dynamically augments realistic data, without requiring extra monolingual corpora. To verify the correctness of our findings and the effectiveness of the proposed MixEdit, we conduct experiments on mainstream English and Chinese GEC datasets. The results show that MixEdit substantially improves GEC models and is complementary to traditional data augmentation methods. All the source codes of MixEdit are released at https://github.com/THUKElab/MixEdit.</abstract>
      <url hash="db27f6c8">2023.findings-emnlp.681</url>
      <bibkey>ye-etal-2023-mixedit</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.681</doi>
    </paper>
    <paper id="682">
      <title><fixed-case>CCE</fixed-case>val: A Representative Evaluation Benchmark for the <fixed-case>C</fixed-case>hinese-centric Multilingual Machine Translation</title>
      <author><first>Lianzhang</first><last>Lou</last></author>
      <author><first>Xi</first><last>Yin</last></author>
      <author><first>Yutao</first><last>Xie</last></author>
      <author><first>Yang</first><last>Xiang</last></author>
      <pages>10176-10184</pages>
      <abstract>The Chinese-centric Multilingual Machine Translation (MMT) has gained more importance recently due to increasing demands from international business development and cross-cultural exchanges. However, an important factor that limits the progress of this area is the lack of highly representative and high-quality evaluation benchmarks. To fill this gap, we propose CCEval, an impartial and representative Chinese-centric MMT evaluation dataset. This benchmark dataset consists of 2500 Chinese sentences we meticulously selected and processed, and covers more diverse linguistic features as compared to other MMT evaluation benchmarks. These sentences have been translated into 11 languages of various resource levels by professional translators via a rigorously controlled process pipeline to ensure their high quality. We conduct experiments to demonstrate our sampling methodology’s effectiveness in constructing evaluation datasets strongly correlated with human evaluations. The resulting dataset enables better assessments of the Chinese-centric MMT quality. Our CCEval benchmark dataset is available at https://bright.pcl.ac.cn/en/offlineTasks.</abstract>
      <url hash="32f7bea0">2023.findings-emnlp.682</url>
      <bibkey>lou-etal-2023-cceval</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.682</doi>
    </paper>
    <paper id="683">
      <title><fixed-case>ROME</fixed-case>: Evaluating Pre-trained Vision-Language Models on Reasoning beyond Visual Common Sense</title>
      <author><first>Kankan</first><last>Zhou</last></author>
      <author><first>Eason</first><last>Lai</last></author>
      <author><first>Wei Bin Au</first><last>Yeong</last></author>
      <author><first>Kyriakos</first><last>Mouratidis</last></author>
      <author><first>Jing</first><last>Jiang</last></author>
      <pages>10185-10197</pages>
      <abstract>Humans possess a strong capability for reasoning beyond common sense. For example, given an unconventional image of a goldfish laying on the table next to an empty fishbowl, a human would effortlessly determine that the fish is not inside the fishbowl. The case, however, may be different for a vision-language model, whose reasoning could gravitate towards the common scenario that the fish is inside the bowl, despite the visual input. In this paper, we introduce a novel probing dataset named ROME (reasoning beyond commonsense knowledge) to evaluate whether the state-of-the-art pre-trained vision-language models have the reasoning capability to correctly interpret counter-intuitive content. ROME contains images that defy commonsense knowledge with regards to color, shape, material, size and positional relation. Experiments on the state-of-the-art pre-trained vision-language models reveal that most of these models are still largely incapable of interpreting counter-intuitive scenarios. We hope that ROME will spur further investigations on reasoning beyond commonsense knowledge in vision-language research.</abstract>
      <url hash="d4569d84">2023.findings-emnlp.683</url>
      <bibkey>zhou-etal-2023-rome</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.683</doi>
    </paper>
    <paper id="684">
      <title>Automatic Analysis of Substantiation in Scientific Peer Reviews</title>
      <author><first>Yanzhu</first><last>Guo</last></author>
      <author><first>Guokan</first><last>Shang</last></author>
      <author><first>Virgile</first><last>Rennard</last></author>
      <author><first>Michalis</first><last>Vazirgiannis</last></author>
      <author><first>Chloé</first><last>Clavel</last></author>
      <pages>10198-10216</pages>
      <abstract>With the increasing amount of problematic peer reviews in top AI conferences, the community is urgently in need of automatic quality control measures. In this paper, we restrict our attention to substantiation — one popular quality aspect indicating whether the claims in a review are sufficiently supported by evidence — and provide a solution automatizing this evaluation process. To achieve this goal, we first formulate the problem as claim-evidence pair extraction in scientific peer reviews, and collect SubstanReview, the first annotated dataset for this task. SubstanReview consists of 550 reviews from NLP conferences annotated by domain experts. On the basis of this dataset, we train an argument mining system to automatically analyze the level of substantiation in peer reviews. We also perform data analysis on the SubstanReview dataset to obtain meaningful insights on peer reviewing quality in NLP conferences over recent years. The dataset is available at https://github.com/YanzhuGuo/SubstanReview.</abstract>
      <url hash="1338ac34">2023.findings-emnlp.684</url>
      <bibkey>guo-etal-2023-automatic</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.684</doi>
    </paper>
    <paper id="685">
      <title>Hierarchical Prompting Assists Large Language Model on Web Navigation</title>
      <author><first>Robert</first><last>Lo</last></author>
      <author><first>Abishek</first><last>Sridhar</last></author>
      <author><first>Frank</first><last>Xu</last></author>
      <author><first>Hao</first><last>Zhu</last></author>
      <author><first>Shuyan</first><last>Zhou</last></author>
      <pages>10217-10244</pages>
      <abstract>Large language models (LLMs) struggle on processing complicated observations in interactive decision making. To alleviate this issue, we propose a simple hierarchical prompting approach. Diverging from previous prompting approaches that always put the full observation (a web page) to the prompt, we propose to first construct an action-aware observation which is more condensed and relevant with a dedicated Summarizer prompt. The Actor prompt then predicts the next action based on the summarized history. While our method has broad applicability, we particularly demonstrate its efficacy in the complex domain of web navigation where a full observation often contains redundant and irrelevant information. Our approach outperforms the previous state-of-the-art prompting mechanism with the same LLM by 6.2% on task success rate, demonstrating its potential on interactive decision making tasks with long observation traces.</abstract>
      <url hash="1d863950">2023.findings-emnlp.685</url>
      <bibkey>lo-etal-2023-hierarchical</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.685</doi>
    </paper>
    <paper id="686">
      <title>Can Large Language Models Fix Data Annotation Errors? An Empirical Study Using Debatepedia for Query-Focused Text Summarization</title>
      <author><first>Md Tahmid Rahman</first><last>Laskar</last></author>
      <author><first>Mizanur</first><last>Rahman</last></author>
      <author><first>Israt</first><last>Jahan</last></author>
      <author><first>Enamul</first><last>Hoque</last></author>
      <author><first>Jimmy</first><last>Huang</last></author>
      <pages>10245-10255</pages>
      <abstract>Debatepedia is a publicly available dataset consisting of arguments and counter-arguments on controversial topics that has been widely used for the single-document query-focused abstractive summarization task in recent years. However, it has been recently found that this dataset is limited by noise and even most queries in this dataset do not have any relevance to the respective document. In this paper, we study whether large language models (LLMs) can be utilized to clean the Debatepedia dataset to make it suitable for query-focused abstractive summarization. More specifically, we harness the language generation capabilities of two LLMs, namely, ChatGPT and PaLM to regenerate its queries. Based on our experiments, we find that solely depending on large language models for query correction may not be very useful for data cleaning. However, we observe that leveraging a rule-based approach for data sampling followed by query regeneration using LLMs (especially ChatGPT) for the sampled instances may ensure a higher quality version of this dataset suitable for the development of more generalized query-focused text summarization models.</abstract>
      <url hash="31d9f04b">2023.findings-emnlp.686</url>
      <bibkey>laskar-etal-2023-large</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.686</doi>
    </paper>
    <paper id="687">
      <title><fixed-case>TSTR</fixed-case>: Target Similarity Tuning Meets the Real World</title>
      <author><first>Anirudh</first><last>Khatry</last></author>
      <author><first>Sumit</first><last>Gulwani</last></author>
      <author><first>Priyanshu</first><last>Gupta</last></author>
      <author><first>Vu</first><last>Le</last></author>
      <author><first>Mukul</first><last>Singh</last></author>
      <author><first>Ananya</first><last>Singha</last></author>
      <author><first>Gust</first><last>Verbruggen</last></author>
      <pages>10256-10261</pages>
      <abstract>Target similarity tuning (TST) is a method of selecting relevant examples in natural language (NL) to code generation through large language models (LLMs) to improve performance. Its goal is to adapt a sentence embedding model to have the similarity between two NL inputs match the similarity between their associated code outputs. In this paper, we propose different methods to apply and improve TST in the real world. First, we replace the sentence transformer with embeddings from a larger model, which reduces sensitivity to the language distribution and thus provides more flexibility in synthetic generation of examples, and we train a tiny model that transforms these embeddings to a space where embedding similarity matches code similarity, which allows the model to remain a black box and only requires a few matrix multiplications at inference time. Second, we how to efficiently select a smaller number of training examples to train the TST model. Third, we introduce a ranking-based evaluation for TST that does not require end-to-end code generation experiments, which can be expensive to perform.</abstract>
      <url hash="4ddb2324">2023.findings-emnlp.687</url>
      <bibkey>khatry-etal-2023-tstr</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.687</doi>
    </paper>
    <paper id="688">
      <title><fixed-case>R</fixed-case>eal<fixed-case>B</fixed-case>ehavior: A Framework for Faithfully Characterizing Foundation Models’ Human-like Behavior Mechanisms</title>
      <author><first>Enyu</first><last>Zhou</last></author>
      <author><first>Rui</first><last>Zheng</last></author>
      <author><first>Zhiheng</first><last>Xi</last></author>
      <author><first>Songyang</first><last>Gao</last></author>
      <author><first>Xiaoran</first><last>Fan</last></author>
      <author><first>Zichu</first><last>Fei</last></author>
      <author><first>Jingting</first><last>Ye</last></author>
      <author><first>Tao</first><last>Gui</last></author>
      <author><first>Qi</first><last>Zhang</last></author>
      <author><first>Xuanjing</first><last>Huang</last></author>
      <pages>10262-10274</pages>
      <abstract>Reports of human-like behaviors in foundation models are growing, with psychological theories providing enduring tools to investigate these behaviors. However, current research tends to directly apply these human-oriented tools without verifying the faithfulness of their outcomes. In this paper, we introduce a framework, RealBehavior, which is designed to characterize the humanoid behaviors of models faithfully. Beyond simply measuring behaviors, our framework assesses the faithfulness of results based on reproducibility, internal and external consistency, and generalizability. Our findings suggest that a simple application of psychological tools cannot faithfully characterize all human-like behaviors. Moreover, we discuss the impacts of aligning models with human and social values, arguing for the necessity of diversifying alignment objectives to prevent the creation of models with restricted characteristics.</abstract>
      <url hash="609d7e8a">2023.findings-emnlp.688</url>
      <bibkey>zhou-etal-2023-realbehavior</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.688</doi>
    </paper>
    <paper id="689">
      <title>Unraveling Downstream Gender Bias from Large Language Models: A Study on <fixed-case>AI</fixed-case> Educational Writing Assistance</title>
      <author><first>Thiemo</first><last>Wambsganss</last></author>
      <author><first>Xiaotian</first><last>Su</last></author>
      <author><first>Vinitra</first><last>Swamy</last></author>
      <author><first>Seyed</first><last>Neshaei</last></author>
      <author><first>Roman</first><last>Rietsche</last></author>
      <author><first>Tanja</first><last>Käser</last></author>
      <pages>10275-10288</pages>
      <abstract>Large Language Models (LLMs) are increasingly utilized in educational tasks such as providing writing suggestions to students. Despite their potential, LLMs are known to harbor inherent biases which may negatively impact learners. Previous studies have investigated bias in models and data representations separately, neglecting the potential impact of LLM bias on human writing. In this paper, we investigate how bias transfers through an AI writing support pipeline. We conduct a large-scale user study with 231 students writing business case peer reviews in German. Students are divided into five groups with different levels of writing support: one in-classroom group with recommender system feature-based suggestions and four groups recruited from Prolific – a control group with no assistance, two groups with suggestions from fine-tuned GPT-2 and GPT-3 models, and one group with suggestions from pre-trained GPT-3.5. Using GenBit gender bias analysis and Word Embedding Association Tests (WEAT), we evaluate the gender bias at various stages of the pipeline: in reviews written by students, in suggestions generated by the models, and in model embeddings directly. Our results demonstrate that there is no significant difference in gender bias between the resulting peer reviews of groups with and without LLM suggestions. Our research is therefore optimistic about the use of AI writing support in the classroom, showcasing a context where bias in LLMs does not transfer to students’ responses.</abstract>
      <url hash="e4d97cb8">2023.findings-emnlp.689</url>
      <bibkey>wambsganss-etal-2023-unraveling</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.689</doi>
    </paper>
    <paper id="690">
      <title><fixed-case>VERVE</fixed-case>: Template-based <fixed-case>R</fixed-case>eflecti<fixed-case>VE</fixed-case> Rewriting for <fixed-case>M</fixed-case>oti<fixed-case>V</fixed-case>ational <fixed-case>I</fixed-case>nt<fixed-case>E</fixed-case>rviewing</title>
      <author><first>Do</first><last>Min</last></author>
      <author><first>Veronica</first><last>Perez-Rosas</last></author>
      <author><first>Ken</first><last>Resnicow</last></author>
      <author><first>Rada</first><last>Mihalcea</last></author>
      <pages>10289-10302</pages>
      <abstract>Reflective listening is a fundamental skill that counselors must acquire to achieve proficiency in motivational interviewing (MI). It involves responding in a manner that acknowledges and explores the meaning of what the client has expressed in the conversation. In this work, we introduce the task of counseling response rewriting, which transforms non-reflective statements into reflective responses. We introduce VERVE, a template-based rewriting system with paraphrase-augmented training and adaptive template updating. VERVE first creates a template by identifying and filtering out tokens that are not relevant to reflections and constructs a reflective response using the template. Paraphrase-augmented training allows the model to learn less-strict fillings of masked spans, and adaptive template updating helps discover effective templates for rewriting without significantly removing the original content. Using both automatic and human evaluations, we compare our method against text rewriting baselines and show that our framework is effective in turning non-reflective statements into more reflective responses while achieving a good content preservation-reflection style trade-off.</abstract>
      <url hash="f0736a74">2023.findings-emnlp.690</url>
      <bibkey>min-etal-2023-verve</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.690</doi>
    </paper>
    <paper id="691">
      <title>Self-Knowledge Guided Retrieval Augmentation for Large Language Models</title>
      <author><first>Yile</first><last>Wang</last></author>
      <author><first>Peng</first><last>Li</last></author>
      <author><first>Maosong</first><last>Sun</last></author>
      <author id="yang-liu"><first>Yang</first><last>Liu</last></author>
      <pages>10303-10315</pages>
      <abstract>Large language models (LLMs) have shown superior performance without task-specific fine-tuning. Despite the success, the knowledge stored in the parameters of LLMs could still be incomplete and difficult to update due to the computational costs. As complementary, retrieval-based methods can offer non-parametric world knowledge and improve the performance on tasks such as question answering. However, we find that the retrieved knowledge does not always help and even has a negative impact on original responses occasionally. To better make use of both internal knowledge and external world knowledge, we investigate eliciting the model’s ability to recognize what they know and do not know (which is also called “self-knowledge”) and propose Self-Knowledge guided Retrieval augmentation (SKR), a simple yet effective method which can let LLMs refer to the questions they have previously encountered and adaptively call for external resources when dealing with new questions. We evaluate SKR on multiple datasets and demonstrate that it outperforms chain-of-thought based and fully retrieval-based methods by using either InstructGPT or ChatGPT.</abstract>
      <url hash="a999a538">2023.findings-emnlp.691</url>
      <bibkey>wang-etal-2023-self-knowledge</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.691</doi>
    </paper>
    <paper id="692">
      <title>Pretraining Language Models with Text-Attributed Heterogeneous Graphs</title>
      <author><first>Tao</first><last>Zou</last></author>
      <author><first>Le</first><last>Yu</last></author>
      <author><first>Yifei</first><last>Huang</last></author>
      <author><first>Leilei</first><last>Sun</last></author>
      <author><first>Bowen</first><last>Du</last></author>
      <pages>10316-10333</pages>
      <abstract>In many real-world scenarios (e.g., academic networks, social platforms), different types of entities are not only associated with texts but also connected by various relationships, which can be abstracted as Text-Attributed Heterogeneous Graphs (TAHGs). Current pretraining tasks for Language Models (LMs) primarily focus on separately learning the textual information of each entity and overlook the crucial aspect of capturing topological connections among entities in TAHGs. In this paper, we present a new pretraining framework for LMs that explicitly considers the topological and heterogeneous information in TAHGs. Firstly, we define a context graph as neighborhoods of a target node within specific orders and propose a topology-aware pretraining task to predict nodes involved in the context graph by jointly optimizing an LM and an auxiliary heterogeneous graph neural network. Secondly, based on the observation that some nodes are text-rich while others have little text, we devise a text augmentation strategy to enrich textless nodes with their neighbors’ texts for handling the imbalance issue. We conduct link prediction and node classification tasks on three datasets from various domains. Experimental results demonstrate the superiority of our approach over existing methods and the rationality of each design. Our code is available at https://github.com/Hope-Rita/THLM.</abstract>
      <url hash="ba8ec688">2023.findings-emnlp.692</url>
      <bibkey>zou-etal-2023-pretraining</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.692</doi>
    </paper>
    <paper id="693">
      <title><fixed-case>CR</fixed-case>e<fixed-case>TIHC</fixed-case>: Designing Causal Reasoning Tasks about Temporal Interventions and Hallucinated Confoundings</title>
      <author><first>Changwoo</first><last>Chun</last></author>
      <author><first>SongEun</first><last>Lee</last></author>
      <author><first>Jaehyung</first><last>Seo</last></author>
      <author><first>Heuiseok</first><last>Lim</last></author>
      <pages>10334-10343</pages>
      <abstract>Large language models (LLMs) have demonstrated impressive capabilities in natural language processing. However, their ability to establish causal relationships, particularly in the context of temporal interventions and language hallucinations, remains challenging. This paper presents <b>CReTIHC</b>, a novel dataset designed to test and enhance the causal reasoning abilities of LLMs. The dataset is constructed using a unique approach that incorporates elements of verbal hallucinations and temporal interventions through the reengineering of existing causal inference datasets. This transformation creates complex scenarios that push LLMs to critically evaluate the information presented and identify cause-and-effect relationships. The CReTIHC dataset serves as a pioneering tool for improving LLM’s causal inference capabilities, paving the way for a more nuanced understanding of causal relationships in natural language processing (NLP) tasks. The whole dataset is publicly accessible at: (https://github.com/ChangwooChun/CReTIHC)</abstract>
      <url hash="ce39d040">2023.findings-emnlp.693</url>
      <bibkey>chun-etal-2023-cretihc</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.693</doi>
    </paper>
    <paper id="694">
      <title>On the Dimensionality of Sentence Embeddings</title>
      <author><first>Hongwei</first><last>Wang</last></author>
      <author><first>Hongming</first><last>Zhang</last></author>
      <author><first>Dong</first><last>Yu</last></author>
      <pages>10344-10354</pages>
      <abstract>Learning sentence embeddings is a fundamental problem in natural language processing. While existing research primarily focuses on enhancing the quality of sentence embeddings, the exploration of sentence embedding dimensions is limited. Here we present a comprehensive and empirical analysis of the dimensionality of sentence embeddings. First, we demonstrate that the optimal dimension of sentence embeddings is usually smaller than the default value. Subsequently, to compress the dimension of sentence embeddings with minimum performance degradation, we identify two components contributing to the overall performance loss: the encoder’s performance loss and the pooler’s performance loss. Therefore, we propose a two-step training method for sentence representation learning models, wherein the encoder and the pooler are optimized separately to mitigate the overall performance loss in low-dimension scenarios. Experimental results on seven STS tasks and seven sentence classification tasks demonstrate that our method significantly improves the performance of low-dimensional sentence embeddings.</abstract>
      <url hash="d5e0d295">2023.findings-emnlp.694</url>
      <bibkey>wang-etal-2023-dimensionality</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.694</doi>
    </paper>
    <paper id="695">
      <title>Pit One Against Many: Leveraging Attention-head Embeddings for Parameter-efficient Multi-head Attention</title>
      <author><first>Huiyin</first><last>Xue</last></author>
      <author><first>Nikolaos</first><last>Aletras</last></author>
      <pages>10355-10373</pages>
      <abstract>Scaling pre-trained language models has resulted in large performance gains in various natural language processing tasks but comes with a large cost in memory requirements. Inspired by the position embeddings in transformers, we aim to simplify and reduce the memory footprint of the multi-head attention (MHA) mechanism. We propose an alternative module that uses only a single shared projection matrix and multiple head embeddings (MHE), i.e. one per head. We empirically demonstrate that our MHE attention is substantially more memory efficient compared to alternative attention mechanisms while achieving high predictive performance retention ratio to vanilla MHA on several downstream tasks. MHE attention only requires a negligible fraction of additional parameters (<tex-math>3nd</tex-math>, where <tex-math>n</tex-math> is the number of attention heads and <tex-math>d</tex-math> the size of the head embeddings) compared to a single-head attention, while MHA requires <tex-math>(3n^2-3n)d^2-3nd</tex-math> additional parameters.</abstract>
      <url hash="ca290e91">2023.findings-emnlp.695</url>
      <bibkey>xue-aletras-2023-pit</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.695</doi>
    </paper>
    <paper id="696">
      <title>Entity-Based Evaluation of Political Bias in Automatic Summarization</title>
      <author><first>Karen</first><last>Zhou</last></author>
      <author><first>Chenhao</first><last>Tan</last></author>
      <pages>10374-10386</pages>
      <abstract>Growing literature has shown that NLP systems may encode social biases; however, the *political* bias of summarization models remains relatively unknown. In this work, we use an entity replacement method to investigate the portrayal of politicians in automatically generated summaries of news articles. We develop an entity-based computational framework to assess the sensitivities of several extractive and abstractive summarizers to the politicians Donald Trump and Joe Biden. We find consistent differences in these summaries upon entity replacement, such as reduced emphasis of Trump’s presence in the context of the same article and a more individualistic representation of Trump with respect to the collective US government (i.e., administration). These summary dissimilarities are most prominent when the entity is heavily featured in the source article. Our characterization provides a foundation for future studies of bias in summarization and for normative discussions on the ideal qualities of automatic summaries.</abstract>
      <url hash="7b027631">2023.findings-emnlp.696</url>
      <bibkey>zhou-tan-2023-entity</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.696</doi>
    </paper>
    <paper id="697">
      <title><fixed-case>S</fixed-case>tyle<fixed-case>BART</fixed-case>: Decorate Pretrained Model with Style Adapters for Unsupervised Stylistic Headline Generation</title>
      <author><first>Hanqing</first><last>Wang</last></author>
      <author><first>Yajing</first><last>Luo</last></author>
      <author><first>Boya</first><last>Xiong</last></author>
      <author><first>Guanhua</first><last>Chen</last></author>
      <author><first>Yun</first><last>Chen</last></author>
      <pages>10387-10399</pages>
      <abstract>Stylistic headline generation is the task to generate a headline that not only summarizes the content of an article, but also reflects a desired style that attracts users. As style-specific article-headline pairs are scarce, previous researches focus on unsupervised approaches with a standard headline generation dataset and mono-style corpora. In this work, we follow this line and propose StyleBART, an unsupervised approach for stylistic headline generation. Our method decorates the pretrained BART model with adapters that are responsible for different styles and allows the generation of headlines with diverse styles by simply switching the adapters. Different from previous works, StyleBART separates the task of style learning and headline generation, making it possible to freely combine the base model and the style adapters during inference. We further propose an inverse paraphrasing task to enhance the style adapters. Extensive automatic and human evaluations show that StyleBART achieves new state-of-the-art performance in the unsupervised stylistic headline generation task, producing high-quality headlines with the desired style.</abstract>
      <url hash="fdc91e10">2023.findings-emnlp.697</url>
      <bibkey>wang-etal-2023-stylebart</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.697</doi>
    </paper>
    <paper id="698">
      <title><fixed-case>RSVP</fixed-case>: Customer Intent Detection via Agent Response Contrastive and Generative Pre-Training</title>
      <author><first>Yu-Chien</first><last>Tang</last></author>
      <author><first>Wei-Yao</first><last>Wang</last></author>
      <author><first>An-Zi</first><last>Yen</last></author>
      <author><first>Wen-Chih</first><last>Peng</last></author>
      <pages>10400-10412</pages>
      <abstract>The dialogue systems in customer services have been developed with neural models to provide users with precise answers and round-the-clock support in task-oriented conversations by detecting customer intents based on their utterances. Existing intent detection approaches have highly relied on adaptively pre-training language models with large-scale datasets, yet the predominant cost of data collection may hinder their superiority. In addition, they neglect the information within the conversational responses of the agents, which have a lower collection cost, but are significant to customer intent as agents must tailor their replies based on the customers’ intent. In this paper, we propose RSVP, a self-supervised framework dedicated to task-oriented dialogues, which utilizes agent responses for pre-training in a two-stage manner. Specifically, we introduce two pre-training tasks to incorporate the relations of utterance-response pairs: 1) Response Retrieval by selecting a correct response from a batch of candidates, and 2) Response Generation by mimicking agents to generate the response to a given utterance. Our benchmark results for two real-world customer service datasets show that RSVP significantly outperforms the state-of-the-art baselines by 4.95% for accuracy, 3.4% for MRR@3, and 2.75% for MRR@5 on average. Extensive case studies are investigated to show the validity of incorporating agent responses into the pre-training stage.</abstract>
      <url hash="1984cab6">2023.findings-emnlp.698</url>
      <bibkey>tang-etal-2023-rsvp</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.698</doi>
    </paper>
    <paper id="699">
      <title>Improving Low-resource Question Answering by Augmenting Question Information</title>
      <author><first>Andong</first><last>Chen</last></author>
      <author><first>Yuan</first><last>Sun</last></author>
      <author><first>Xiaobing</first><last>Zhao</last></author>
      <author><first>Rosella</first><last>Galindo Esparza</last></author>
      <author><first>Kehai</first><last>Chen</last></author>
      <author><first>Yang</first><last>Xiang</last></author>
      <author><first>Tiejun</first><last>Zhao</last></author>
      <author><first>Min</first><last>Zhang</last></author>
      <pages>10413-10420</pages>
      <abstract>In the era of large models, low-resource question-answering tasks lag, emphasizing the importance of data augmentation - a key research avenue in natural language processing. The main challenges include leveraging the large model’s internal knowledge for data augmentation, determining which QA data component - the question, passage, or answer - benefits most from augmentation, and retaining consistency in the augmented content without inducing excessive noise. To tackle these, we introduce PQQ, an innovative approach for question data augmentation consisting of Prompt Answer, Question Generation, and Question Filter. Our experiments reveal that ChatGPT underperforms on the experimental data, yet our PQQ method excels beyond existing augmentation strategies. Further, its universal applicability is validated through successful tests on high-resource QA tasks like SQUAD1.1 and TriviaQA.</abstract>
      <url hash="3dba510c">2023.findings-emnlp.699</url>
      <bibkey>chen-etal-2023-improving-low</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.699</doi>
    </paper>
    <paper id="700">
      <title><fixed-case>I</fixed-case>nstruct<fixed-case>S</fixed-case>afety: A Unified Framework for Building Multidimensional and Explainable Safety Detector through Instruction Tuning</title>
      <author><first>Zhexin</first><last>Zhang</last></author>
      <author><first>Jiale</first><last>Cheng</last></author>
      <author><first>Hao</first><last>Sun</last></author>
      <author><first>Jiawen</first><last>Deng</last></author>
      <author><first>Minlie</first><last>Huang</last></author>
      <pages>10421-10436</pages>
      <abstract>Safety detection has been an increasingly important topic in recent years and it has become even more necessary to develop reliable safety detection systems with the rapid development of large language models. However, currently available safety detection systems have limitations in terms of their versatility and interpretability. In this paper, we first introduce InstructSafety, a safety detection framework that unifies 7 common sub-tasks for safety detection. These tasks are unified into a similar form through different instructions. We then conduct a comprehensive survey of existing safety detection datasets and process 39 human-annotated datasets for instruction tuning. We also construct adversarial samples to enhance the model’s robustness. After fine-tuning Flan-T5 on the collected data, we have developed Safety-Flan-T5, a multidimensional and explainable safety detector. We conduct comprehensive experiments on a variety of datasets and tasks, and demonstrate the strong performance of Safety-Flan-T5 in comparison to supervised baselines and served APIs (Perspective API, ChatGPT and InstructGPT). We will release the processed data, fine-tuned Safety-Flan-T5 and related code for public use.</abstract>
      <url hash="0b79bf1c">2023.findings-emnlp.700</url>
      <bibkey>zhang-etal-2023-instructsafety</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.700</doi>
    </paper>
    <paper id="701">
      <title>“A Tale of Two Movements’: Identifying and Comparing Perspectives in #<fixed-case>B</fixed-case>lack<fixed-case>L</fixed-case>ives<fixed-case>M</fixed-case>atter and #<fixed-case>B</fixed-case>lue<fixed-case>L</fixed-case>ives<fixed-case>M</fixed-case>atter Movements-related Tweets using Weakly Supervised Graph-based Structured Prediction</title>
      <author><first>Shamik</first><last>Roy</last></author>
      <author><first>Dan</first><last>Goldwasser</last></author>
      <pages>10437-10467</pages>
      <abstract>Social media has become a major driver of social change, by facilitating the formation of online social movements. Automatically understanding the perspectives driving the movement and the voices opposing it, is a challenging task as annotated data is difficult to obtain. We propose a weakly supervised graph-based approach that explicitly models perspectives in #BackLivesMatter-related tweets. Our proposed approach utilizes a social-linguistic representation of the data. We convert the text to a graph by breaking it into structured elements and connect it with the social network of authors, then structured prediction is done over the elements for identifying perspectives. Our approach uses a small seed set of labeled examples. We experiment with large language models for generating artificial training examples, compare them to manual annotation, and find that it achieves comparable performance. We perform quantitative and qualitative analyses using a human-annotated test set. Our model outperforms multitask baselines by a large margin, successfully characterizing the perspectives supporting and opposing #BLM.</abstract>
      <url hash="55715495">2023.findings-emnlp.701</url>
      <bibkey>roy-goldwasser-2023-tale</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.701</doi>
    </paper>
    <paper id="702">
      <title><fixed-case>C</fixed-case>luster<fixed-case>P</fixed-case>rompt: Cluster Semantic Enhanced Prompt Learning for New Intent Discovery</title>
      <author><first>Jinggui</first><last>Liang</last></author>
      <author><first>Lizi</first><last>Liao</last></author>
      <pages>10468-10481</pages>
      <abstract>The discovery of new intent categories from user utterances is a crucial task in expanding agent skills. The key lies in how to efficiently solicit semantic evidence from utterances and properly transfer knowledge from existing intents to new intents. However, previous methods laid too much emphasis on relations among utterances or clusters for transfer learning, while paying less attention to the usage of semantics. As a result, these methods suffer from in-domain over-fitting and often generate meaningless new intent clusters due to data distortion. In this paper, we present a novel approach called Cluster Semantic Enhanced Prompt Learning (CsePL) for discovering new intents. Our method leverages two-level contrastive learning with label semantic alignment to learn meaningful representations of intent clusters. These learned intent representations are then utilized as soft prompt initializations for discriminating new intents, reducing the dominance of existing intents. Extensive experiments conducted on three public datasets demonstrate the superiority of our proposed method. It not only outperforms existing methods but also suggests meaningful intent labels and enables early detection of new intents.</abstract>
      <url hash="db14a498">2023.findings-emnlp.702</url>
      <bibkey>liang-liao-2023-clusterprompt</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.702</doi>
    </paper>
    <paper id="703">
      <title>Investigating the Effect of Pre-finetuning <fixed-case>BERT</fixed-case> Models on <fixed-case>NLI</fixed-case> Involving Presuppositions</title>
      <author><first>Jad</first><last>Kabbara</last></author>
      <author><first>Jackie</first><last>Cheung</last></author>
      <pages>10482-10494</pages>
      <abstract>We explore the connection between presupposition, discourse and sarcasm and propose to leverage that connection in a transfer learning scenario with the goal of improving the performance of NLI models on cases involving presupposition. We exploit advances in training transformer-based models that show that pre-finetuning—–i.e., finetuning the model on an additional task or dataset before the actual finetuning phase—–can help these models, in some cases, achieve a higher performance on a given downstream task. Building on those advances and that aforementioned connection, we propose pre-finetuning NLI models on carefully chosen tasks in an attempt to improve their performance on NLI cases involving presupposition. We notice that, indeed, pre-finetuning on those tasks leads to performance improvements. Furthermore, we run several diagnostic tests to understand whether these gains are merely a byproduct of additional training data. The results show that, while additional training data seems to be helping on its own in some cases, the choice of the tasks plays a role in the performance improvements.</abstract>
      <url hash="ed2d748b">2023.findings-emnlp.703</url>
      <bibkey>kabbara-cheung-2023-investigating</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.703</doi>
    </paper>
    <paper id="704">
      <title><fixed-case>MRRL</fixed-case>: Modifying the Reference via Reinforcement Learning for Non-Autoregressive Joint Multiple Intent Detection and Slot Filling</title>
      <author><first>Xuxin</first><last>Cheng</last></author>
      <author><first>Zhihong</first><last>Zhu</last></author>
      <author><first>Bowen</first><last>Cao</last></author>
      <author><first>Qichen</first><last>Ye</last></author>
      <author><first>Yuexian</first><last>Zou</last></author>
      <pages>10495-10505</pages>
      <abstract>With the rise of non-autoregressive approach, some non-autoregressive models for joint multiple intent detection and slot filling have obtained the promising inference speed. However, most existing SLU models (1) suffer from the multi-modality problem that leads to reference intents and slots may not be suitable for training; (2) lack of alignment between the correct predictions of the two tasks, which extremely limits the overall accuracy. Therefore, in this paper, we propose <tex-math>\textbf{M}</tex-math>odifying the <tex-math>\textbf{R}</tex-math>eference via <tex-math>\textbf{R}</tex-math>einforcement <tex-math>\textbf{L}</tex-math>earning (MRRL), a novel method for multiple intent detection and slot filling, which introduces a modifier and employs reinforcement learning. Specifically, we try to provide the better training target for the non-autoregressive SLU model via modifying the reference based on the output of the non-autoregressive SLU model, and propose a suitability reward to ensure that the output of the modifier module could fit well with the output of the non-autoregressive SLU model and does not deviate too far from the reference. In addition, we also propose a compromise reward to realize a flexible trade-off between the two subtasks. Experiments on two multi-intent datasets and non-autoregressive baselines demonstrate that our MRRL could consistently improve the performance of baselines. More encouragingly, our best variant achieves new state-of-the-art results, outperforming the previous best approach by 3.6 overall accuracy on MixATIS dataset.</abstract>
      <url hash="445b5a82">2023.findings-emnlp.704</url>
      <bibkey>cheng-etal-2023-mrrl</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.704</doi>
    </paper>
    <paper id="705">
      <title><fixed-case>D</fixed-case>emo<fixed-case>NSF</fixed-case>: A Multi-task Demonstration-based Generative Framework for Noisy Slot Filling Task</title>
      <author><first>Guanting</first><last>Dong</last></author>
      <author><first>Tingfeng</first><last>Hui</last></author>
      <author><first>Zhuoma</first><last>GongQue</last></author>
      <author><first>Jinxu</first><last>Zhao</last></author>
      <author><first>Daichi</first><last>Guo</last></author>
      <author><first>Gang</first><last>Zhao</last></author>
      <author><first>Keqing</first><last>He</last></author>
      <author><first>Weiran</first><last>Xu</last></author>
      <pages>10506-10518</pages>
      <abstract>Recently, prompt-based generative frameworks have shown impressive capabilities in sequence labeling tasks. However, in practical dialogue scenarios, relying solely on simplistic templates and traditional corpora presents a challenge for these methods in generalizing to unknown input perturbations. To address this gap, we propose a multi-task demonstration-based generative framework for noisy slot filling, named DemoNSF. Specifically, we introduce three noisy auxiliary tasks, namely noisy recovery (NR), random mask (RM), and hybrid discrimination (HD), to implicitly capture semantic structural information of input perturbations at different granularities. In the downstream main task, we design a noisy demonstration construction strategy for the generative framework, which explicitly incorporates task-specific information and perturbed distribution during training and inference. Experiments on two benchmarks demonstrate that DemoNSF outperforms all baseline methods and achieves strong generalization. Further analysis provides empirical guidance for the practical application of generative frameworks. Our code is released at https://github.com/dongguanting/Demo-NSF.</abstract>
      <url hash="55425c80">2023.findings-emnlp.705</url>
      <bibkey>dong-etal-2023-demonsf</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.705</doi>
    </paper>
    <paper id="706">
      <title><fixed-case>SHARCS</fixed-case>: Efficient Transformers Through Routing with Dynamic Width Sub-networks</title>
      <author><first>Mohammadreza</first><last>Salehi</last></author>
      <author><first>Sachin</first><last>Mehta</last></author>
      <author><first>Aditya</first><last>Kusupati</last></author>
      <author><first>Ali</first><last>Farhadi</last></author>
      <author><first>Hannaneh</first><last>Hajishirzi</last></author>
      <pages>10519-10532</pages>
      <abstract>We introduce SHARCS for adaptive inference that takes into account the hardness of input samples. SHARCS can train a router on any transformer network, enabling the model to direct different samples to sub-networks with varying widths. Our experiments demonstrate that: (1) SHARCS outperforms or complements existing per-sample adaptive inference methods across various classification tasks in terms of accuracy vs. FLOPs; (2) SHARCS generalizes across different architectures and can be even applied to compressed and efficient transformer encoders to further improve their efficiency; (3) SHARCS can provide a 2 times inference speed up at an insignificant drop in accuracy.</abstract>
      <url hash="99931aa3">2023.findings-emnlp.706</url>
      <bibkey>salehi-etal-2023-sharcs</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.706</doi>
    </paper>
    <paper id="707">
      <title>Always the Best Fit: Adaptive Domain Gap Filling from Causal Perspective for Few-Shot Relation Extraction</title>
      <author><first>Ge</first><last>Bai</last></author>
      <author><first>Chenji</first><last>Lu</last></author>
      <author><first>Jiaxiang</first><last>Geng</last></author>
      <author><first>Shilong</first><last>Li</last></author>
      <author><first>Yidong</first><last>Shi</last></author>
      <author><first>Xiyan</first><last>Liu</last></author>
      <author><first>Ying</first><last>Liu</last></author>
      <author><first>Zhang</first><last>Zhang</last></author>
      <author><first>Ruifang</first><last>Liu</last></author>
      <pages>10533-10542</pages>
      <abstract>Cross-domain Relation Extraction aims to transfer knowledge from a source domain to a different target domain to address low-resource challenges. However, the semantic gap caused by data bias between domains is a major challenge, especially in few-shot scenarios. Previous work has mainly focused on transferring knowledge between domains through shared feature representations without analyzing the impact of each factor that may produce data bias based on the characteristics of each domain. This work takes a causal perspective and proposes a new framework CausalGF. By constructing a unified structural causal model, we estimating the causal effects of factors such as syntactic structure, label distribution,and entities on the outcome. CausalGF calculates the causal effects among the factors and adjusts them dynamically based on domain characteristics, enabling adaptive gap filling. Our experiments show that our approach better fills the domain gap, yielding significantly better results on the cross-domain few-shot relation extraction task.</abstract>
      <url hash="a0c672f1">2023.findings-emnlp.707</url>
      <bibkey>bai-etal-2023-always</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.707</doi>
    </paper>
    <paper id="708">
      <title><fixed-case>MEGC</fixed-case>lass: Extremely Weakly Supervised Text Classification via Mutually-Enhancing Text Granularities</title>
      <author><first>Priyanka</first><last>Kargupta</last></author>
      <author><first>Tanay</first><last>Komarlu</last></author>
      <author><first>Susik</first><last>Yoon</last></author>
      <author><first>Xuan</first><last>Wang</last></author>
      <author><first>Jiawei</first><last>Han</last></author>
      <pages>10543-10558</pages>
      <abstract>Text classification is essential for organizing unstructured text. Traditional methods rely on human annotations or, more recently, a set of class seed words for supervision, which can be costly, particularly for specialized or emerging domains. To address this, using class surface names alone as extremely weak supervision has been proposed. However, existing approaches treat different levels of text granularity (documents, sentences, or words) independently, disregarding inter-granularity class disagreements and the context identifiable exclusively through joint extraction. In order to tackle these issues, we introduce MEGClass, an extremely weakly-supervised text classification method that leverages Mutually-Enhancing Text Granularities. MEGClass utilizes coarse- and fine-grained context signals obtained by jointly considering a document’s most class-indicative words and sentences. This approach enables the learning of a contextualized document representation that captures the most discriminative class indicators. By preserving the heterogeneity of potential classes, MEGClass can select the most informative class-indicative documents as iterative feedback to enhance the initial word-based class representations and ultimately fine-tune a pre-trained text classifier. Extensive experiments on seven benchmark datasets demonstrate that MEGClass outperforms other weakly and extremely weakly supervised methods.</abstract>
      <url hash="00ddac74">2023.findings-emnlp.708</url>
      <bibkey>kargupta-etal-2023-megclass</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.708</doi>
    </paper>
    <paper id="709">
      <title>Causal Inference from Text: Unveiling Interactions between Variables</title>
      <author><first>Yuxiang</first><last>Zhou</last></author>
      <author><first>Yulan</first><last>He</last></author>
      <pages>10559-10571</pages>
      <abstract>Adjusting for latent covariates is crucial for estimating causal effects from observational textual data. Most existing methods only account for confounding covariates that affect both treatment and outcome, potentially leading to biased causal effects. This bias arises from insufficient consideration of non-confounding covariates, which are relevant only to either the treatment or the outcome. In this work, we aim to mitigate the bias by unveiling interactions between different variables to disentangle the non-confounding covariates when estimating causal effects from text. The disentangling process ensures covariates only contribute to their respective objectives, enabling independence between variables. Additionally, we impose a constraint to balance representations from the treated group and control group to alleviate selection bias. We conduct experiments on two different treatment factors under various scenarios, and the proposed model significantly outperforms recent strong baselines. Furthermore, our thorough analysis on earnings call transcripts demonstrates that our model can effectively disentangle the variables, and further investigations into real-world scenarios provide guidance for investors to make informed decisions.</abstract>
      <url hash="ff4d985a">2023.findings-emnlp.709</url>
      <bibkey>zhou-he-2023-causal</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.709</doi>
      <revision id="1" href="2023.findings-emnlp.709v1" hash="a3bf9dcd"/>
      <revision id="2" href="2023.findings-emnlp.709v2" hash="ff4d985a" date="2023-12-31">Corrects the tick mark typo in Table 2.</revision>
    </paper>
    <paper id="710">
      <title>Large Language Model Is Not a Good Few-shot Information Extractor, but a Good Reranker for Hard Samples!</title>
      <author><first>Yubo</first><last>Ma</last></author>
      <author><first>Yixin</first><last>Cao</last></author>
      <author><first>Yong</first><last>Hong</last></author>
      <author><first>Aixin</first><last>Sun</last></author>
      <pages>10572-10601</pages>
      <abstract>Large Language Models (LLMs) have made remarkable strides in various tasks. Whether LLMs are competitive few-shot solvers for information extraction (IE) tasks, however, remains an open problem. In this work, we aim to provide a thorough answer to this question. Through extensive experiments on nine datasets across four IE tasks, we demonstrate that current advanced LLMs consistently exhibit inferior performance, higher latency, and increased budget requirements compared to fine-tuned SLMs under most settings. Therefore, we conclude that LLMs are not effective few-shot information extractors in general. Nonetheless, we illustrate that with appropriate prompting strategies, LLMs can effectively complement SLMs and tackle challenging samples that SLMs struggle with. And moreover, we propose an adaptive filter-then-rerank paradigm to combine the strengths of LLMs and SLMs. In this paradigm, SLMs serve as filters and LLMs serve as rerankers. By prompting LLMs to rerank a small portion of difficult samples identified by SLMs, our preliminary system consistently achieves promising improvements (2.4% F1-gain on average) on various IE tasks, with an acceptable time and cost investment.</abstract>
      <url hash="2273cba1">2023.findings-emnlp.710</url>
      <bibkey>ma-etal-2023-large</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.710</doi>
    </paper>
    <paper id="711">
      <title>Prompting and Evaluating Large Language Models for Proactive Dialogues: Clarification, Target-guided, and Non-collaboration</title>
      <author><first>Yang</first><last>Deng</last></author>
      <author><first>Lizi</first><last>Liao</last></author>
      <author><first>Liang</first><last>Chen</last></author>
      <author><first>Hongru</first><last>Wang</last></author>
      <author><first>Wenqiang</first><last>Lei</last></author>
      <author><first>Tat-Seng</first><last>Chua</last></author>
      <pages>10602-10621</pages>
      <abstract>Conversational systems based on Large Language Models (LLMs), such as ChatGPT, show exceptional proficiency in context understanding and response generation. However, they still possess limitations, such as failing to ask clarifying questions to ambiguous queries or refuse users’ unreasonable requests, both of which are considered as key aspects of a conversational agent’s proactivity. This raises the question of whether LLM-based conversational systems are equipped to handle proactive dialogue problems. In this work, we conduct a comprehensive analysis of LLM-based conversational systems, specifically focusing on three key aspects of proactive dialogues: clarification, target-guided, and non-collaborative dialogues. To trigger the proactivity of LLMs, we propose the Proactive Chain-of-Thought prompting scheme, which augments LLMs with the goal planning capability over descriptive reasoning chains. Empirical findings are discussed to promote future studies on LLM-based proactive dialogue systems.</abstract>
      <url hash="236dc7ca">2023.findings-emnlp.711</url>
      <bibkey>deng-etal-2023-prompting</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.711</doi>
    </paper>
    <paper id="712">
      <title>Ecologically Valid Explanations for Label Variation in <fixed-case>NLI</fixed-case></title>
      <author><first>Nan-Jiang</first><last>Jiang</last></author>
      <author><first>Chenhao</first><last>Tan</last></author>
      <author><first>Marie-Catherine</first><last>de Marneffe</last></author>
      <pages>10622-10633</pages>
      <abstract>Human label variation, or annotation disagreement, exists in many natural language processing (NLP) tasks, including natural language inference (NLI). To gain direct evidence of how NLI label variation arises, we build LiveNLI, an English dataset of 1,415 ecologically valid explanations (annotators explain the NLI labels they chose) for 122 MNLI items (at least 10 explanations per item). The LiveNLI explanations confirm that people can systematically vary on their interpretation and highlight within-label variation: annotators sometimes choose the same label for different reasons. This suggests that explanations are crucial for navigating label interpretations in general. We few-shot prompt large language models to generate explanations but the results are inconsistent: they sometimes produces valid and informative explanations, but it also generates implausible ones that do not support the label, highlighting directions for improvement.</abstract>
      <url hash="05472d6b">2023.findings-emnlp.712</url>
      <bibkey>jiang-etal-2023-ecologically</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.712</doi>
    </paper>
    <paper id="713">
      <title>A Benchmark for Semi-Inductive Link Prediction in Knowledge Graphs</title>
      <author><first>Adrian</first><last>Kochsiek</last></author>
      <author><first>Rainer</first><last>Gemulla</last></author>
      <pages>10634-10643</pages>
      <abstract>Semi-inductive link prediction (LP) in knowledge graphs (KG) is the task of predicting facts for new, previously unseen entities based on context information. Although new entities can be integrated by retraining the model from scratch in principle, such an approach is infeasible for large-scale KGs, where retraining is expensive and new entities may arise frequently. In this paper, we propose and describe a large-scale benchmark to evaluate semi-inductive LP models. The benchmark is based on and extends Wikidata5M: It provides transductive, k-shot, and 0-shot LP tasks, each varying the available information from (i) only KG structure, to (ii) including textual mentions, and (iii) detailed descriptions of the entities. We report on a small study of recent approaches and found that semi-inductive LP performance is far from transductive performance on long-tail entities throughout all experiments. The benchmark provides a test bed for further research into integrating context and textual information in semi-inductive LP models.</abstract>
      <url hash="761ec8bd">2023.findings-emnlp.713</url>
      <bibkey>kochsiek-gemulla-2023-benchmark</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.713</doi>
    </paper>
    <paper id="714">
      <title><fixed-case>S</fixed-case>umm<fixed-case>I</fixed-case>t: Iterative Text Summarization via <fixed-case>C</fixed-case>hat<fixed-case>GPT</fixed-case></title>
      <author><first>Haopeng</first><last>Zhang</last></author>
      <author><first>Xiao</first><last>Liu</last></author>
      <author><first>Jiawei</first><last>Zhang</last></author>
      <pages>10644-10657</pages>
      <abstract>Existing text summarization systems have made significant progress in recent years, but typically generate summaries in a single step. The one-shot summarization setting is sometimes inadequate, however, as the generated summary may contain hallucinations or overlook important details related to the reader’s interests. In this paper, we address this limitation by proposing SummIt, an iterative text summarization framework based on large language models like ChatGPT. Our framework enables the model to refine the generated summary iteratively through self-evaluation and feedback, closely resembling the iterative process humans undertake when drafting and revising summaries. Furthermore, we explore the potential benefits of integrating knowledge and topic extractors into the framework to enhance summary faithfulness and controllability. We evaluate the performance of our framework on three benchmark summarization datasets through empirical and qualitative analyses. We also conduct a human evaluation to validate the effectiveness of the model’s refinements and find a potential issue of over-correction.</abstract>
      <url hash="c80823e9">2023.findings-emnlp.714</url>
      <bibkey>zhang-etal-2023-summit</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.714</doi>
    </paper>
    <paper id="715">
      <title>Orthogonal Subspace Learning for Language Model Continual Learning</title>
      <author><first>Xiao</first><last>Wang</last></author>
      <author><first>Tianze</first><last>Chen</last></author>
      <author><first>Qiming</first><last>Ge</last></author>
      <author><first>Han</first><last>Xia</last></author>
      <author><first>Rong</first><last>Bao</last></author>
      <author><first>Rui</first><last>Zheng</last></author>
      <author><first>Qi</first><last>Zhang</last></author>
      <author><first>Tao</first><last>Gui</last></author>
      <author><first>Xuanjing</first><last>Huang</last></author>
      <pages>10658-10671</pages>
      <abstract>Benefiting from massive corpora and advanced hardware, large language models (LLMs) exhibit remarkable capabilities in language understanding and generation. However, their performance degrades in scenarios where multiple tasks are encountered sequentially, also known as catastrophic forgetting. In this paper, we propose orthogonal low-rank adaptation (O-LoRA), a simple and efficient approach for continual learning in language models, effectively mitigating catastrophic forgetting while learning new tasks. Specifically, O-LoRA learns tasks in different (low-rank) vector subspaces that are kept orthogonal to each other in order to minimize interference. Our method induces only marginal additional parameter costs and requires no user data storage for replay. Experimental results on continual learning benchmarks show that our method outperforms state-of-the-art methods. Furthermore, compared to previous approaches, our method excels in preserving the generalization ability of LLMs on unseen tasks.</abstract>
      <url hash="9dda0a07">2023.findings-emnlp.715</url>
      <bibkey>wang-etal-2023-orthogonal</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.715</doi>
    </paper>
    <paper id="716">
      <title>Attention-Enhancing Backdoor Attacks Against <fixed-case>BERT</fixed-case>-based Models</title>
      <author><first>Weimin</first><last>Lyu</last></author>
      <author><first>Songzhu</first><last>Zheng</last></author>
      <author><first>Lu</first><last>Pang</last></author>
      <author><first>Haibin</first><last>Ling</last></author>
      <author><first>Chao</first><last>Chen</last></author>
      <pages>10672-10690</pages>
      <abstract>Recent studies have revealed that Backdoor Attacks can threaten the safety of natural language processing (NLP) models. Investigating the strategies of backdoor attacks will help to understand the model’s vulnerability. Most existing textual backdoor attacks focus on generating stealthy triggers or modifying model weights. In this paper, we directly target the interior structure of neural networks and the backdoor mechanism. We propose a novel Trojan Attention Loss (TAL), which enhances the Trojan behavior by directly manipulating the attention patterns. Our loss can be applied to different attacking methods to boost their attack efficacy in terms of attack successful rates and poisoning rates. It applies to not only traditional dirty-label attacks, but also the more challenging clean-label attacks. We validate our method on different backbone models (BERT, RoBERTa, and DistilBERT) and various tasks (Sentiment Analysis, Toxic Detection, and Topic Classification).</abstract>
      <url hash="13ae4323">2023.findings-emnlp.716</url>
      <bibkey>lyu-etal-2023-attention</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.716</doi>
    </paper>
    <paper id="717">
      <title>Hi-<fixed-case>T</fixed-case>o<fixed-case>M</fixed-case>: A Benchmark for Evaluating Higher-Order Theory of Mind Reasoning in Large Language Models</title>
      <author><first>Yufan</first><last>Wu</last></author>
      <author><first>Yinghui</first><last>He</last></author>
      <author><first>Yilin</first><last>Jia</last></author>
      <author><first>Rada</first><last>Mihalcea</last></author>
      <author><first>Yulong</first><last>Chen</last></author>
      <author><first>Naihao</first><last>Deng</last></author>
      <pages>10691-10706</pages>
      <abstract>Theory of Mind (ToM) is the ability to reason about one’s own and others’ mental states. ToM plays a critical role in the development of intelligence, language understanding, and cognitive processes. While previous work has primarily focused on first and second-order ToM, we explore higher-order ToM, which involves recursive reasoning on others’ beliefs. %We also incorporate a new deception mechanism in ToM reasoning. We introduce Hi-ToM, a Higher Order Theory of Mind benchmark. Our experimental evaluation using various Large Language Models (LLMs) indicates a decline in performance on higher-order ToM tasks, demonstrating the limitations of current LLMs. We conduct a thorough analysis of different failure cases of LLMs, and share our thoughts on the implications of our findings on the future of NLP.</abstract>
      <url hash="f1ced51e">2023.findings-emnlp.717</url>
      <bibkey>wu-etal-2023-hi</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.717</doi>
    </paper>
    <paper id="718">
      <title>Image and Text: Fighting the same Battle? Super Resolution Learning for Imbalanced Text Classification</title>
      <author><first>Romain</first><last>Meunier</last></author>
      <author><first>Benamara</first><last>Farah</last></author>
      <author><first>Véronique</first><last>Moriceau</last></author>
      <author><first>Patricia</first><last>Stolf</last></author>
      <pages>10707-10720</pages>
      <abstract>In this paper, we propose SRL4NLP, a new approach for data augmentation by drawing an analogy between image and text processing: Super-resolution learning. This method is based on using high-resolution images to overcome the problem of low resolution images. While this technique is a common usage in image processing when images have a low resolution or are too noisy, it has never been used in NLP. We therefore propose the first adaptation of this method for text classification and evaluate its effectiveness on urgency detection from tweets posted in crisis situations, a very challenging task where messages are scarce and highly imbalanced. We show that this strategy is efficient when compared to competitive state-of-the-art data augmentation techniques on several benchmarks datasets in two languages.</abstract>
      <url hash="18540246">2023.findings-emnlp.718</url>
      <bibkey>meunier-etal-2023-image</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.718</doi>
    </paper>
    <paper id="719">
      <title><fixed-case>SELFOOD</fixed-case>: Self-Supervised Out-Of-Distribution Detection via Learning to Rank</title>
      <author><first>Dheeraj</first><last>Mekala</last></author>
      <author><first>Adithya</first><last>Samavedhi</last></author>
      <author><first>Chengyu</first><last>Dong</last></author>
      <author><first>Jingbo</first><last>Shang</last></author>
      <pages>10721-10734</pages>
      <abstract>Deep neural classifiers trained with cross-entropy loss (CE loss) often suffer from poor calibration, necessitating the task of out-of-distribution (OOD) detection. Traditional supervised OOD detection methods require expensive manual annotation of in-distribution and OOD samples. To address the annotation bottleneck, we introduce SELFOOD, a self-supervised OOD detection method that requires only in-distribution samples as supervision. We cast OOD detection as an inter-document intra-label (IDIL) ranking problem and train the classifier with our pairwise ranking loss, referred to as IDIL loss. Specifically, given a set of in-distribution documents and their labels, for each label, we train the classifier to rank the softmax scores of documents belonging to that label to be higher than the scores of documents that belong to other labels. Unlike CE loss, our IDIL loss function reaches zero when the desired confidence ranking is achieved and gradients are backpropagated to decrease probabilities associated with incorrect labels rather than continuously increasing the probability of the correct label. Extensive experiments with several classifiers on multiple classification datasets demonstrate the effectiveness of our method in both coarse- and fine-grained settings.</abstract>
      <url hash="f90e39f8">2023.findings-emnlp.719</url>
      <bibkey>mekala-etal-2023-selfood</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.719</doi>
    </paper>
    <paper id="720">
      <title>Mind the Gap Between Conversations for Improved Long-Term Dialogue Generation</title>
      <author><first>Qiang</first><last>Zhang</last></author>
      <author><first>Jason</first><last>Naradowsky</last></author>
      <author><first>Yusuke</first><last>Miyao</last></author>
      <pages>10735-10762</pages>
      <abstract>Knowing how to end and resume conversations over time is a natural part of communication, allowing for discussions to span weeks, months, or years. The duration of gaps between conversations dictates which topics are relevant and which questions to ask, and dialogue systems which do not explicitly model time may generate responses that are unnatural. In this work we explore the idea of making dialogue models aware of time, and present GapChat, a multi-session dialogue dataset in which the time between each session varies. While the dataset is constructed in real-time, progress on events in speakers’ lives is simulated in order to create realistic dialogues occurring across a long timespan. We expose time information to the model and compare different representations of time and event progress. In human evaluation we show that time-aware models perform better in metrics that judge the relevance of the chosen topics and the information gained from the conversation.</abstract>
      <url hash="9b211be3">2023.findings-emnlp.720</url>
      <bibkey>zhang-etal-2023-mind</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.720</doi>
    </paper>
    <paper id="721">
      <title>A Structure-Aware Generative Adversarial Network for Bilingual Lexicon Induction</title>
      <author><first>Bocheng</first><last>Han</last></author>
      <author><first>Qian</first><last>Tao</last></author>
      <author><first>Lusi</first><last>Li</last></author>
      <author><first>Zhihao</first><last>Xiong</last></author>
      <pages>10763-10775</pages>
      <abstract>Bilingual lexicon induction (BLI) is the task of inducing word translations with a learned mapping function that aligns monolingual word embedding spaces in two different languages. However, most previous methods treat word embeddings as isolated entities and fail to jointly consider both the intra-space and inter-space topological relations between words. This limitation makes it challenging to align words from embedding spaces with distinct topological structures, especially when the assumption of isomorphism may not hold. To this end, we propose a novel approach called the Structure-Aware Generative Adversarial Network (SA-GAN) model to explicitly capture multiple topological structure information to achieve accurate BLI. Our model first incorporates two lightweight graph convolutional networks (GCNs) to leverage intra-space topological correlations between words for generating source and target embeddings. We then employ a GAN model to explore inter-space topological structures by learning a global mapping function that initially maps the source embeddings to the target embedding space. To further align the coarse-grained structures, we develop a pair-wised local mapping (PLM) strategy that enables word-specific transformations in an unsupervised manner. Extensive experiments conducted on public datasets, including languages with both distant and close etymological relationships, demonstrate the effectiveness of our proposed SA-GAN model.</abstract>
      <url hash="84ba3079">2023.findings-emnlp.721</url>
      <bibkey>han-etal-2023-structure</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.721</doi>
    </paper>
    <paper id="722">
      <title><fixed-case>NLP</fixed-case> Evaluation in trouble: On the Need to Measure <fixed-case>LLM</fixed-case> Data Contamination for each Benchmark</title>
      <author><first>Oscar</first><last>Sainz</last></author>
      <author><first>Jon</first><last>Campos</last></author>
      <author><first>Iker</first><last>García-Ferrero</last></author>
      <author><first>Julen</first><last>Etxaniz</last></author>
      <author><first>Oier Lopez</first><last>de Lacalle</last></author>
      <author><first>Eneko</first><last>Agirre</last></author>
      <pages>10776-10787</pages>
      <abstract>In this position paper we argue that the classical evaluation on Natural Language Processing (NLP) tasks using annotated benchmarks is in trouble. The worst kind of data contamination happens when a Large Language Model (LLM) is trained on the test split of a benchmark, and then evaluated in the same benchmark. The extent of the problem is unknown, as it is not straightforward to measure. Contamination causes an overestimation of the performance of a contaminated model in a target benchmark and associated task with respect to their non-contaminated counterparts. The consequences can be very harmful, with wrong scientific conclusions being published while other correct ones are discarded. This position paper defines different levels of data contamination and argues for a community effort, including the development of automatic and semi-automatic measures to detect when data from a benchmark was exposed to a model, and suggestions for flagging papers with conclusions that are compromised by data contamination.</abstract>
      <url hash="ef0461c9">2023.findings-emnlp.722</url>
      <bibkey>sainz-etal-2023-nlp</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.722</doi>
    </paper>
    <paper id="723">
      <title>Improving Pacing in Long-Form Story Planning</title>
      <author><first>Yichen</first><last>Wang</last></author>
      <author><first>Kevin</first><last>Yang</last></author>
      <author><first>Xiaoming</first><last>Liu</last></author>
      <author><first>Dan</first><last>Klein</last></author>
      <pages>10788-10845</pages>
      <abstract>Existing LLM-based systems for writing long-form stories or story outlines frequently suffer from unnatural pacing, whether glossing over important events or over-elaborating on insignificant details, resulting in a jarring experience for the reader. We propose a **CONC**rete **O**utline **C**on**T**rol (CONCOCT) system to improve pacing when automatically generating story outlines. We first train a *concreteness evaluator* to judge which of two events is more concrete (low-level-detailed). This evaluator can then be used to control pacing in hierarchical outline generation; in this work, we explore a *vaguest-first* expansion procedure that aims for uniform pacing. We further use the evaluator to filter new outline items based on predicted concreteness. Compared to a baseline hierarchical outline generator, humans judge CONCOCT’s pacing to be more consistent over 57% of the time across multiple outline lengths; the gains also translate to downstream stories. All code, data, and models are open-sourced.</abstract>
      <url hash="8a98f871">2023.findings-emnlp.723</url>
      <bibkey>wang-etal-2023-improving-pacing</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.723</doi>
    </paper>
    <paper id="724">
      <title>Argument mining as a multi-hop generative machine reading comprehension task</title>
      <author><first>Boyang</first><last>Liu</last></author>
      <author><first>Viktor</first><last>Schlegel</last></author>
      <author><first>Riza</first><last>Batista-Navarro</last></author>
      <author><first>Sophia</first><last>Ananiadou</last></author>
      <pages>10846-10858</pages>
      <abstract>Argument mining (AM) is a natural language processing task that aims to generate an argumentative graph given an unstructured argumentative text. An argumentative graph that consists of argumentative components and argumentative relations contains completed information of an argument and exhibits the logic of an argument. As the argument structure of an argumentative text can be regarded as an answer to a “why” question, the whole argument structure is therefore similar to the “chain of thought” concept, i.e., the sequence of ideas that lead to a specific conclusion for a given argument (Wei et al., 2022). For argumentative texts in the same specific genre, the “chain of thought” of such texts is usually similar, i.e., in a student essay, there is usually a major claim supported by several claims, and then a number of premises which are related to the claims are included (Eger et al., 2017). In this paper, we propose a new perspective which transfers the argument mining task into a multi-hop reading comprehension task, allowing the model to learn the argument structure as a “chain of thought”. We perform a comprehensive evaluation of our approach on two AM benchmarks and find that we surpass SOTA results. A detailed analysis shows that specifically the “chain of thought” information is helpful for the argument mining task.</abstract>
      <url hash="b63bc119">2023.findings-emnlp.724</url>
      <bibkey>liu-etal-2023-argument</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.724</doi>
    </paper>
    <paper id="725">
      <title><fixed-case>H</fixed-case>uatuo<fixed-case>GPT</fixed-case>, Towards Taming Language Model to Be a Doctor</title>
      <author><first>Hongbo</first><last>Zhang</last></author>
      <author><first>Junying</first><last>Chen</last></author>
      <author><first>Feng</first><last>Jiang</last></author>
      <author><first>Fei</first><last>Yu</last></author>
      <author><first>Zhihong</first><last>Chen</last></author>
      <author><first>Guiming</first><last>Chen</last></author>
      <author><first>Jianquan</first><last>Li</last></author>
      <author><first>Xiangbo</first><last>Wu</last></author>
      <author><first>Zhang</first><last>Zhiyi</last></author>
      <author><first>Qingying</first><last>Xiao</last></author>
      <author><first>Xiang</first><last>Wan</last></author>
      <author><first>Benyou</first><last>Wang</last></author>
      <author><first>Haizhou</first><last>Li</last></author>
      <pages>10859-10885</pages>
      <abstract>In this paper, we present HuatuoGPT, a Large Language Model (LLM) for medical consultation. The core recipe of HuatuoGPT is to leverage both distilled data from **ChatGPT** and real-world data from **doctors** in the supervised fine-tuning stage. This is not only because purely using **ChatGPT**-distilled data might cause ‘model collapse’, but also because real-world data from **doctors** would be complementary to **ChatGPT**-distilled data. The responses from ChatGPT are usually detailed, well-presented, fluent, and instruction-followed, but it cannot perform like a doctor in many aspects, e.g. for interactive diagnosis. Therefore, the extra doctors’ data could tame a distilled language model to perform like doctors. To synergize the strengths of both data sources, we introduce RLMF (Reinforcement Learning from Mixed Feedback) where a reward model is trained to align the language model with the merits that both sources (ChatGPT and doctors) bring. Experimental results (in GPT-4 evaluation, human evaluation, and medical benchmark datasets) demonstrate that HuatuoGPT achieves state-of-the-art results in performing medical consultation among open-source LLMs. It is worth noting that by using additional real-world data and RLMF, the distilled language model (i.e., HuatuoGPT) outperforms its teacher model (i.e., ChatGPT) in most cases.</abstract>
      <url hash="c4acaf4f">2023.findings-emnlp.725</url>
      <bibkey>zhang-etal-2023-huatuogpt</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.725</doi>
    </paper>
    <paper id="726">
      <title>Debias <fixed-case>NLU</fixed-case> Datasets via Training-free Perturbations</title>
      <author><first>Qi</first><last>Guo</last></author>
      <author><first>Yuanhang</first><last>Tang</last></author>
      <author><first>Yawen</first><last>Ouyang</last></author>
      <author><first>Zhen</first><last>Wu</last></author>
      <author><first>Xinyu</first><last>Dai</last></author>
      <pages>10886-10901</pages>
      <abstract>Several recent studies have shown that advanced models for natural language understanding (NLU) are prone to capture biased features that are independent of the task but spuriously correlated to labels. Such models often perform well on in-distribution (ID) datasets but fail to generalize to out-of-distribution (OOD) datasets. Existing solutions can be separated into two orthogonal approaches: model-centric methods and data-centric methods. Model-centric methods improve OOD performance at the expense of ID performance. Data-centric strategies usually boost both of them via data-level manipulations such as generative data augmentation. However, the high cost of fine-tuning a generator to produce valid samples limits the potential of such approaches. To address this issue, we propose PDD, a framework that conducts training-free Perturbations on samples containing biased features to Debias NLU Datasets. PDD works by iteratively conducting perturbations via pre-trained mask language models (MLM). PDD exhibits the advantage of low cost by adopting a training-free perturbation strategy and further improves the label consistency by utilizing label information during perturbations. Extensive experiments demonstrate that PDD shows competitive performance with previous state-of-the-art debiasing strategies. When combined with the model-centric debiasing methods, PDD establishes a new state-of-the-art.</abstract>
      <url hash="b20c2d37">2023.findings-emnlp.726</url>
      <bibkey>guo-etal-2023-debias</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.726</doi>
    </paper>
    <paper id="727">
      <title>Aspect-to-Scope Oriented Multi-view Contrastive Learning for Aspect-based Sentiment Analysis</title>
      <author><first>Heyan</first><last>Chai</last></author>
      <author><first>Ziyi</first><last>Yao</last></author>
      <author><first>Siyu</first><last>Tang</last></author>
      <author><first>Ye</first><last>Wang</last></author>
      <author><first>Liqiang</first><last>Nie</last></author>
      <author><first>Binxing</first><last>Fang</last></author>
      <author><first>Qing</first><last>Liao</last></author>
      <pages>10902-10913</pages>
      <abstract>Aspect-based sentiment analysis (ABSA) aims to align aspects and corresponding sentiment expressions, so as to identify the sentiment polarities of specific aspects. Most existing ABSA methods focus on mining syntactic or semantic information, which still suffers from noisy interference introduced by the attention mechanism and dependency tree when multiple aspects exist in a sentence. To address these issues, in this paper, we revisit ABSA from a novel perspective by proposing a novel scope-assisted multi-view graph contrastive learning framework. It not only mitigates noisy interference for better locating aspect and its corresponding sentiment opinion with aspect-specific scope, but also captures the correlation and difference between sentiment polarities and syntactic/semantic information. Extensive experiments on five benchmark datasets show that our proposed approach substantially outperforms state-of-the-art methods and verifies the effectiveness and robustness of our model.</abstract>
      <url hash="720bf8ef">2023.findings-emnlp.727</url>
      <bibkey>chai-etal-2023-aspect</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.727</doi>
    </paper>
    <paper id="728">
      <title>Robustness of Named-Entity Replacements for In-Context Learning</title>
      <author><first>Saeed</first><last>Goodarzi</last></author>
      <author><first>Nikhil</first><last>Kagita</last></author>
      <author><first>Dennis</first><last>Minn</last></author>
      <author><first>Shufan</first><last>Wang</last></author>
      <author><first>Roberto</first><last>Dessi</last></author>
      <author><first>Shubham</first><last>Toshniwal</last></author>
      <author><first>Adina</first><last>Williams</last></author>
      <author><first>Jack</first><last>Lanchantin</last></author>
      <author><first>Koustuv</first><last>Sinha</last></author>
      <pages>10914-10931</pages>
      <abstract>A key feature of modern large language models (LLMs) is their ability to perform in-context learning, a prompting technique where query- answer demonstrations are shown before the final query. This allows for generalization to novel distributions at inference time where the LLM can learn new rules without parameter updates. However, the choice of demonstrations and their relationship to a particular query can have a profound impact on model accuracy, raising concerns about the true in-context generalization capabilities (Zhao et al., 2021). In this work, we explore the robustness of the in-context learning paradigm by focusing on entities. In particular, we seek to understand the robustness of LLM in-context learning with respect to named entity replacements. We discover a significant variance in downstream performance based on the choice of the named entities, across three popular reasoning tasks and two popular LLMs. Specifically, model accuracy on the test sets can fluctuate between -2.7 to +8.0 points depending on the choice of named entity replacements. Our analysis exposes the sensitivity of LLM in-context learning with respect to named entities, and offers a simple recipe to improve test performance by hyper-parameter tuning the named entities for a given dataset. Code and datasets for reproducing the results are publicly available.</abstract>
      <url hash="84f3347b">2023.findings-emnlp.728</url>
      <bibkey>goodarzi-etal-2023-robustness</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.728</doi>
    </paper>
    <paper id="729">
      <title>Contrastive Learning-based Sentence Encoders Implicitly Weight Informative Words</title>
      <author><first>Hiroto</first><last>Kurita</last></author>
      <author><first>Goro</first><last>Kobayashi</last></author>
      <author><first>Sho</first><last>Yokoi</last></author>
      <author><first>Kentaro</first><last>Inui</last></author>
      <pages>10932-10947</pages>
      <abstract>The performance of sentence encoders can be significantly improved through the simple practice of fine-tuning using contrastive loss. A natural question arises: what characteristics do models acquire during contrastive learning? This paper theoretically and experimentally shows that contrastive-based sentence encoders implicitly weight words based on information-theoretic quantities; that is, more informative words receive greater weight, while others receive less. The theory states that, in the lower bound of the optimal value of the contrastive learning objective, the norm of word embedding reflects the information gain associated with the distribution of surrounding words. We also conduct comprehensive experiments using various models, multiple datasets, two methods to measure the implicit weighting of models (Integrated Gradients and SHAP), and two information-theoretic quantities (information gain and self-information). The results provide empirical evidence that contrastive fine-tuning emphasizes informative words.</abstract>
      <url hash="5bf3bebe">2023.findings-emnlp.729</url>
      <bibkey>kurita-etal-2023-contrastive</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.729</doi>
    </paper>
    <paper id="730">
      <title>Legally Enforceable Hate Speech Detection for Public Forums</title>
      <author><first>Chu</first><last>Luo</last></author>
      <author><first>Rohan</first><last>Bhambhoria</last></author>
      <author><first>Samuel</first><last>Dahan</last></author>
      <author><first>Xiaodan</first><last>Zhu</last></author>
      <pages>10948-10963</pages>
      <abstract>Hate speech causes widespread and deep-seated societal issues. Proper enforcement of hate speech laws is key for protecting groups of people against harmful and discriminatory language. However, determining what constitutes hate speech is a complex task that is highly open to subjective interpretations. Existing works do not align their systems with enforceable definitions of hate speech, which can make their outputs inconsistent with the goals of regulators. This research introduces a new perspective and task for enforceable hate speech detection centred around legal definitions, and a dataset annotated on violations of eleven possible definitions by legal experts. Given the challenge of identifying clear, legally enforceable instances of hate speech, we augment the dataset with expert-generated samples and an automatically mined challenge set. We experiment with grounding the model decision in these definitions using zero-shot and few-shot prompting. We then report results on several large language models (LLMs). With this task definition, automatic hate speech detection can be more closely aligned to enforceable laws, and hence assist in more rigorous enforcement of legal protections against harmful speech in public forums.</abstract>
      <url hash="3c7e56ec">2023.findings-emnlp.730</url>
      <bibkey>luo-etal-2023-legally</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.730</doi>
    </paper>
    <paper id="731">
      <title><fixed-case>C</fixed-case>on<fixed-case>P</fixed-case>rompt: Pre-training a Language Model with Machine-Generated Data for Implicit Hate Speech Detection</title>
      <author><first>Youngwook</first><last>Kim</last></author>
      <author><first>Shinwoo</first><last>Park</last></author>
      <author><first>Youngsoo</first><last>Namgoong</last></author>
      <author><first>Yo-Sub</first><last>Han</last></author>
      <pages>10964-10980</pages>
      <abstract>Implicit hate speech detection is a challenging task in text classification since no explicit cues (e.g., swear words) exist in the text. While some pre-trained language models have been developed for hate speech detection, they are not specialized in implicit hate speech. Recently, an implicit hate speech dataset with a massive number of samples has been proposed by controlling machine generation. We propose a pre-training approach, ConPrompt, to fully leverage such machine-generated data. Specifically, given a machine-generated statement, we use example statements of its origin prompt as positive samples for contrastive learning. Through pre-training with ConPrompt, we present ToxiGen-ConPrompt, a pre-trained language model for implicit hate speech detection. We conduct extensive experiments on several implicit hate speech datasets and show the superior generalization ability of ToxiGen-ConPrompt compared to other pre-trained models. Additionally, we empirically show that ConPrompt is effective in mitigating identity term bias, demonstrating that it not only makes a model more generalizable but also reduces unintended bias. We analyze the representation quality of ToxiGen-ConPrompt and show its ability to consider target group and toxicity, which are desirable features in terms of implicit hate speeches.</abstract>
      <url hash="8e979e75">2023.findings-emnlp.731</url>
      <bibkey>kim-etal-2023-conprompt</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.731</doi>
    </paper>
    <paper id="732">
      <title>Incorporating Syntactic Knowledge into Pre-trained Language Model using Optimization for Overcoming Catastrophic Forgetting</title>
      <author><first>Ran</first><last>Iwamoto</last></author>
      <author><first>Issei</first><last>Yoshida</last></author>
      <author><first>Hiroshi</first><last>Kanayama</last></author>
      <author><first>Takuya</first><last>Ohko</last></author>
      <author><first>Masayasu</first><last>Muraoka</last></author>
      <pages>10981-10993</pages>
      <abstract>Syntactic knowledge is invaluable information for many tasks which handle complex or long sentences, but typical pre-trained language models do not contain sufficient syntactic knowledge. Thus it results in failures in downstream tasks that require syntactic knowledge. In this paper, we explore additional training to incorporate syntactic knowledge to a language model. We designed four pre-training tasks that learn different syntactic perspectives. For adding new syntactic knowledge and keeping a good balance between the original and additional knowledge, we addressed the problem of catastrophic forgetting that prevents the model from keeping semantic information when the model learns additional syntactic knowledge. We demonstrated that additional syntactic training produced consistent performance gains while clearly avoiding catastrophic forgetting.</abstract>
      <url hash="4af22ee3">2023.findings-emnlp.732</url>
      <bibkey>iwamoto-etal-2023-incorporating</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.732</doi>
    </paper>
    <paper id="733">
      <title>Toward Human Readable Prompt Tuning: Kubrick’s The Shining is a good movie, and a good prompt too?</title>
      <author><first>Weijia</first><last>Shi</last></author>
      <author><first>Xiaochuang</first><last>Han</last></author>
      <author><first>Hila</first><last>Gonen</last></author>
      <author><first>Ari</first><last>Holtzman</last></author>
      <author><first>Yulia</first><last>Tsvetkov</last></author>
      <author><first>Luke</first><last>Zettlemoyer</last></author>
      <pages>10994-11005</pages>
      <abstract>Large language models can perform downstream tasks in a zero-shot fashion, given natural language prompts that specify the desired behavior. Such prompts are typically hand engineered, but can also be learned with gradient-based methods from labeled data. However, it is underexplored what factors make the prompts effective, especially when the prompts are in natural language. In this paper, we investigate common attributes shared by effective prompts in classification problems. We first propose a human readable prompt tuning method (FluentPrompt) based on Langevin dynamics that incorporates a fluency constraint to find a distribution of effective and fluent prompts. Our analysis reveals that effective prompts are topically related to the task domain and calibrate the prior probability of output labels. Based on these findings, we also propose a method for generating prompts using only unlabeled data, outperforming strong baselines by an average of 7.0% accuracy across three tasks.</abstract>
      <url hash="44aaa698">2023.findings-emnlp.733</url>
      <bibkey>shi-etal-2023-toward</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.733</doi>
    </paper>
    <paper id="734">
      <title>Chain-of-Thought Reasoning in Tabular Language Models</title>
      <author><first>Mingyu</first><last>Zheng</last></author>
      <author><first>Hao</first><last>Yang</last></author>
      <author><first>Wenbin</first><last>Jiang</last></author>
      <author><first>Zheng</first><last>Lin</last></author>
      <author><first>Yajuan</first><last>Lyu</last></author>
      <author><first>Qiaoqiao</first><last>She</last></author>
      <author><first>Weiping</first><last>Wang</last></author>
      <pages>11006-11019</pages>
      <abstract>Tabular mathematical reasoning task requires models to perform multi-step operations including information look-up and numerical calculation, based on heterogeneous data from tables and questions. Existing solutions tend to extend chain-of-thought (CoT) reasoning into powerful large language models (LLMs) to promote multi-hop mathematical reasoning. However, such LLM-based approaches are not a viable solution in the scenario of privatization deployment or limited resources. To address this problem, we revisit small-scale tabular language models (TaLMs) and extend chain-of-thought reasoning into TaLMs for the first time. Specifically, we propose a novel framework, TaCo, which coordinates two TaLMs responsible for CoT generation and answer inference, respectively. Besides, our framework can be combined with an external calculator to enhance accurate numerical calculation. On the TABMWP dataset, TaCo outperforms the state-of-the-art ChatGPT by 9.55% (82.60%<tex-math>\rightarrow</tex-math>92.15% in accuracy) with much less parameters (0.8B). The code will be released along with the paper.</abstract>
      <url hash="971af2ed">2023.findings-emnlp.734</url>
      <bibkey>zheng-etal-2023-chain</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.734</doi>
    </paper>
    <paper id="735">
      <title>Diffusion Language Model with Query-Document Relevance for Query-Focused Summarization</title>
      <author><first>Shaoyao</first><last>Huang</last></author>
      <author><first>Luozheng</first><last>Qin</last></author>
      <author><first>Ziqiang</first><last>Cao</last></author>
      <pages>11020-11030</pages>
      <abstract>Query-Focused Summarization (QFS) aims to generate summaries from source documents that can answer specific queries. Although the QFS task has gained increasing attention recently, its development is constrained by the fact that mainstream QFS models are BART variants, which are autoregressive and suffer from long-term dependencies and exposure bias. To address these problems, we adopt a diffusion language model that performs well in non-autoregressive scenarios to effectively resolve issues related to autoregressive methods. However, QFS requires guidance from queries to generate adequate summaries, while diffusion language models have limited sensitivity to queries. In this paper, we propose QFS-DLM, a non-autoregressive diffusion language model that incorporates query-document fragment relevance and query-document global relevance to enhance the adaptability of QFS tasks. Firstly, we extract key fragments from documents based on queries and assign higher weights to them, thereby emphasizing crucial and continuous information within the document. Secondly, we calculate global relevance scores between queries and documents, and then integrate these scores into the model’s loss function, enabling the model to prefer high-quality data and distance itself from low-quality data. Overall, our method achieves state-of-the-art performance on Debatepedia and PubMedQA datasets in ROUGE scores, GPT-4, and human evaluations.</abstract>
      <url hash="096d480f">2023.findings-emnlp.735</url>
      <bibkey>huang-etal-2023-diffusion</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.735</doi>
    </paper>
    <paper id="736">
      <title>Grounded and well-rounded: a methodological approach to the study of cross-modal and cross-lingual grounding</title>
      <author><first>Timothee</first><last>Mickus</last></author>
      <author><first>Elaine</first><last>Zosa</last></author>
      <author><first>Denis</first><last>Paperno</last></author>
      <pages>11031-11042</pages>
      <abstract>Grounding has been argued to be a crucial component towards the development of more complete and truly semantically competent artificial intelligence systems. Literature has divided into two camps: While some argue that grounding allows for qualitatively different generalizations, others believe it can be compensated by mono-modal data quantity. Limited empirical evidence has emerged for or against either position, which we argue is due to the methodological challenges that come with studying grounding and its effects on NLP systems. In this paper, we establish a methodological framework for studying what the effects are—if any—of providing models with richer input sources than text-only. The crux of it lies in the construction of comparable samples of populations of models trained on different input modalities, so that we can tease apart the qualitative effects of different input sources from quantifiable model performances. Experiments using this framework reveal qualitative differences in model behavior between cross-modally grounded, cross-lingually grounded, and ungrounded models, which we measure both at a global dataset level as well as for specific word representations, depending on how concrete their semantics is.</abstract>
      <url hash="c5d6a9e1">2023.findings-emnlp.736</url>
      <bibkey>mickus-etal-2023-grounded</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.736</doi>
    </paper>
    <paper id="737">
      <title><fixed-case>EMO</fixed-case>-<fixed-case>KNOW</fixed-case>: A Large Scale Dataset on Emotion-Cause</title>
      <author><first>Mia</first><last>Nguyen</last></author>
      <author><first>Yasith</first><last>Samaradivakara</last></author>
      <author><first>Prasanth</first><last>Sasikumar</last></author>
      <author><first>Chitralekha</first><last>Gupta</last></author>
      <author><first>Suranga</first><last>Nanayakkara</last></author>
      <pages>11043-11051</pages>
      <abstract>Emotion-Cause analysis has attracted the attention of researchers in recent years. However, most existing datasets are limited in size and number of emotion categories. They often focus on extracting parts of the document that contain the emotion cause and fail to provide more abstractive, generalizable root cause. To bridge this gap, we introduce a large-scale dataset of emotion causes, derived from 9.8 million cleaned tweets over 15 years. We describe our curation process, which includes a comprehensive pipeline for data gathering, cleaning, labeling, and validation, ensuring the dataset’s reliability and richness. We extract emotion labels and provide abstractive summarization of the events causing emotions. The final dataset comprises over 700,000 tweets with corresponding emotion-cause pairs spanning 48 emotion classes, validated by human evaluators. The novelty of our dataset stems from its broad spectrum of emotion classes and the abstractive emotion cause that facilitates the development of an emotion-cause knowledge graph for nuanced reasoning. Our dataset will enable the design of emotion-aware systems that account for the diverse emotional responses of different people for the same event.</abstract>
      <url hash="08f3b3df">2023.findings-emnlp.737</url>
      <bibkey>nguyen-etal-2023-emo</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.737</doi>
    </paper>
    <paper id="738">
      <title>Boosting Inference Efficiency: Unleashing the Power of Parameter-Shared Pre-trained Language Models</title>
      <author><first>Weize</first><last>Chen</last></author>
      <author><first>Xiaoyue</first><last>Xu</last></author>
      <author><first>Xu</first><last>Han</last></author>
      <author><first>Yankai</first><last>Lin</last></author>
      <author><first>Ruobing</first><last>Xie</last></author>
      <author><first>Zhiyuan</first><last>Liu</last></author>
      <author><first>Maosong</first><last>Sun</last></author>
      <author><first>Jie</first><last>Zhou</last></author>
      <pages>11052-11067</pages>
      <abstract>Parameter-shared pre-trained language models (PLMs) have emerged as a successful approach in resource-constrained environments, enabling substantial reductions in model storage and memory costs without significant performance compromise. However, it is important to note that parameter sharing does not alleviate computational burdens associated with inference, thus impeding its practicality in situations characterized by limited stringent latency requirements or computational resources. Building upon neural ordinary differential equations (ODEs), we introduce a straightforward technique to enhance the inference efficiency of parameter-shared PLMs. Additionally, we propose a simple pre-training technique that leads to fully or partially shared models capable of achieving even greater inference acceleration. The experimental results demonstrate the effectiveness of our methods on both autoregressive and autoencoding PLMs, providing novel insights into more efficient utilization of parameter-shared models in resource-constrained settings.</abstract>
      <url hash="b1d4b378">2023.findings-emnlp.738</url>
      <bibkey>chen-etal-2023-boosting-inference</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.738</doi>
    </paper>
    <paper id="739">
      <title>Natural Response Generation for <fixed-case>C</fixed-case>hinese Reading Comprehension</title>
      <author><first>Nuo</first><last>Chen</last></author>
      <author><first>Hongguang</first><last>Li</last></author>
      <author><first>Yinan</first><last>Bao</last></author>
      <author><first>Baoyuan</first><last>Wang</last></author>
      <author><first>Jia</first><last>Li</last></author>
      <pages>11068-11081</pages>
      <abstract>Machine reading comprehension (MRC) is an important area of conversation agents and draws a lot of attention. However, there is a notable limitation to current MRC benchmarks: The labeled answers are mostly either spans extracted from the target corpus or the choices of the given candidates, ignoring the natural aspect of high-quality responses. As a result, MRC models trained on these datasets can not generate human-like responses in real QA scenarios. To this end, we construct a new dataset called <b>Penguin</b> to promote the research of MRC, providing a training and test bed for natural response generation to real scenarios. Concretely, Penguin consists of 200k training data with high-quality fluent, and well-informed responses. Penguin is the first benchmark towards natural response generation in Chinese MRC on a relatively large scale. To address the challenges in Penguin, we develop two strong baselines: end-to-end and two-stage frameworks. Following that, we further design <i>Prompt-BART</i>: fine-tuning the pre-trained generative language models with a mixture of prefix prompts in Penguin. Extensive experiments validated the effectiveness of this design.</abstract>
      <url hash="f0e22a14">2023.findings-emnlp.739</url>
      <bibkey>chen-etal-2023-natural</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.739</doi>
    </paper>
    <paper id="740">
      <title>Treepiece: Faster Semantic Parsing via Tree Tokenization</title>
      <author><first>Sid</first><last>Wang</last></author>
      <author><first>Akshat</first><last>Shrivastava</last></author>
      <author><first>Aleksandr</first><last>Livshits</last></author>
      <pages>11082-11092</pages>
      <abstract><i>Autoregressive</i> (AR) encoder-decoder neural networks have proved successful in many NLP problems, including <i>Semantic Parsing</i> – a task that translates natural language to machine-readable <i>parse trees</i>. However, the sequential prediction process of AR models can be slow. To accelerate AR for semantic parsing, we introduce a new technique called <i>TreePiece</i> that tokenizes a parse tree into subtrees and generates one subtree per decoding step. On TOPv2 benchmark, TreePiece shows 4.6 times faster decoding speed than standard AR, and comparable speed but significantly higher accuracy compared to <i>Non-Autoregressive</i> (NAR).</abstract>
      <url hash="bbc937d5">2023.findings-emnlp.740</url>
      <bibkey>wang-etal-2023-treepiece</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.740</doi>
    </paper>
    <paper id="741">
      <title>Semantic Parsing by Large Language Models for Intricate Updating Strategies of Zero-Shot Dialogue State Tracking</title>
      <author><first>Yuxiang</first><last>Wu</last></author>
      <author><first>Guanting</first><last>Dong</last></author>
      <author><first>Weiran</first><last>Xu</last></author>
      <pages>11093-11099</pages>
      <abstract>Zero-shot Dialogue State Tracking (DST) addresses the challenge of acquiring and annotating task-oriented dialogues, which can be time-consuming and costly. However, DST extends beyond simple slot-filling and requires effective updating strategies for tracking dialogue state as conversations progress. In this paper, we propose ParsingDST, a new In-Context Learning (ICL) method, to introduce additional intricate updating strategies in zero-shot DST. Our approach reformulates the DST task by leveraging powerful Large Language Models (LLMs) and translating the original dialogue text to JSON through semantic parsing as an intermediate state. We also design a novel framework that includes more modules to ensure the effectiveness of updating strategies in the text-to-JSON process. Experimental results demonstrate that our approach outperforms existing zero-shot DST methods on MultiWOZ, exhibiting significant improvements in Joint Goal Accuracy (JGA) and slot accuracy compared to existing ICL methods.</abstract>
      <url hash="b636b415">2023.findings-emnlp.741</url>
      <bibkey>wu-etal-2023-semantic</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.741</doi>
    </paper>
    <paper id="742">
      <title>Mitigating Framing Bias with Polarity Minimization Loss</title>
      <author><first>Yejin</first><last>Bang</last></author>
      <author><first>Nayeon</first><last>Lee</last></author>
      <author><first>Pascale</first><last>Fung</last></author>
      <pages>11100-11110</pages>
      <abstract>Framing bias plays a significant role in exacerbating political polarization by distorting the perception of actual events. Media outlets with divergent political stances often use polarized language in their reporting of the same event. We propose a new loss function that encourages the model to minimize the polarity difference between the polarized input articles to reduce framing bias. Specifically, our loss is designed to jointly optimize the model to map polarity ends bidirectionally. Our experimental results demonstrate that incorporating the proposed polarity minimization loss leads to a substantial reduction in framing bias when compared to a BART-based multi-document summarization model. Notably, we find that the effectiveness of this approach is most pronounced when the model is trained to minimize the polarity loss associated with informational framing bias (i.e., skewed selection of information to report).</abstract>
      <url hash="97c73326">2023.findings-emnlp.742</url>
      <bibkey>bang-etal-2023-mitigating</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.742</doi>
    </paper>
    <paper id="743">
      <title>Is <fixed-case>C</fixed-case>hat<fixed-case>GPT</fixed-case> a Good Causal Reasoner? A Comprehensive Evaluation</title>
      <author><first>Jinglong</first><last>Gao</last></author>
      <author><first>Xiao</first><last>Ding</last></author>
      <author><first>Bing</first><last>Qin</last></author>
      <author><first>Ting</first><last>Liu</last></author>
      <pages>11111-11126</pages>
      <abstract>Causal reasoning ability is crucial for numerous NLP applications. Despite the impressive emerging ability of ChatGPT in various NLP tasks, it is unclear how well ChatGPT performs in causal reasoning. In this paper, we conduct the first comprehensive evaluation of the ChatGPT’s causal reasoning capabilities. Experiments show that ChatGPT is not a good causal reasoner, but a good causal interpreter. Besides, ChatGPT has a serious hallucination on causal reasoning, possibly due to the reporting biases between causal and non-causal relationships in natural language, as well as ChatGPT’s upgrading processes, such as RLHF. The In-Context Learning (ICL) and Chain-of-Thought (COT) techniques can further exacerbate such causal hallucination. Additionally, the causal reasoning ability of ChatGPT is sensitive to the words used to express the causal concept in prompts, and close-ended prompts perform better than open-ended prompts. For events in sentences, ChatGPT excels at capturing explicit causality rather than implicit causality, and performs better in sentences with lower event density and smaller lexical distance between events.</abstract>
      <url hash="43e1e7b8">2023.findings-emnlp.743</url>
      <bibkey>gao-etal-2023-chatgpt</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.743</doi>
    </paper>
    <paper id="744">
      <title>Steering Large Language Models for Machine Translation with Finetuning and In-Context Learning</title>
      <author><first>Duarte</first><last>Alves</last></author>
      <author><first>Nuno</first><last>Guerreiro</last></author>
      <author><first>João</first><last>Alves</last></author>
      <author><first>José</first><last>Pombal</last></author>
      <author><first>Ricardo</first><last>Rei</last></author>
      <author><first>José</first><last>de Souza</last></author>
      <author><first>Pierre</first><last>Colombo</last></author>
      <author><first>Andre</first><last>Martins</last></author>
      <pages>11127-11148</pages>
      <abstract>Large language models (LLMs) are a promising avenue for machine translation (MT). However, current LLM-based MT systems are brittle: their effectiveness highly depends on the choice of few-shot examples and they often require extra post-processing due to overgeneration. Alternatives such as finetuning on translation instructions are computationally expensive and may weaken in-context learning capabilities, due to overspecialization. In this paper, we provide a closer look at this problem. We start by showing that adapter-based finetuning with LoRA matches the performance of traditional finetuning while reducing the number of training parameters by a factor of 50. This method also outperforms few-shot prompting and eliminates the need for post-processing or in-context examples. However, we show that finetuning generally degrades few-shot performance, hindering adaptation capabilities. Finally, to obtain the best of both worlds, we propose a simple approach that incorporates few-shot examples during finetuning. Experiments on 10 language pairs show that our proposed approach recovers the original few-shot capabilities while keeping the added benefits of finetuning.</abstract>
      <url hash="206d3e33">2023.findings-emnlp.744</url>
      <bibkey>alves-etal-2023-steering</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.744</doi>
    </paper>
    <paper id="745">
      <title>How Many Demonstrations Do You Need for In-context Learning?</title>
      <author><first>Jiuhai</first><last>Chen</last></author>
      <author><first>Lichang</first><last>Chen</last></author>
      <author><first>Chen</first><last>Zhu</last></author>
      <author><first>Tianyi</first><last>Zhou</last></author>
      <pages>11149-11159</pages>
      <abstract>Large language models (LLMs) are capable to perform complex reasoning by in-context learning (ICL) when provided with a few input-output demonstrations (demos) and more powerful when intermediate reasoning steps (chain of thoughts (CoT)) of the demos are given. Is it necessary to use multi-demo in ICL? In this paper, we study ICL using fewer demos for each test query on the tasks in (Wei et al., 2022). Surprisingly, we do not observe significant degradation when using only one randomly chosen demo. To study this phenomenon, for each test query, we categorize demos into “positive demos” leading to the correct answer, and “negative demos” resulting in wrong answers. Our analysis reveals an inherent bias in those widely studied datasets and the redundancy of demos: most demos are positive for a majority of test queries, which explains the good performance of ICL with one random demo. Moreover, ICL (with and w/o CoT) using only one positive demo significantly outperforms multi-demo ICL adopted by most previous works, indicating the weakness of LLMs in finding positive demo(s) for input queries, which is difficult to evaluate on the biased datasets. Furthermore, we observe a counterintuitive behavior of ICL using multi-demo, i.e., its accuracy degrades(improves) when given more positive(negative) demos. This implies that ICL can be easily misguided by interference among demos and their spurious correlations. Our analyses highlight several fundamental challenges that need to be addressed in LLMs training, ICL, and benchmark design.</abstract>
      <url hash="91913926">2023.findings-emnlp.745</url>
      <bibkey>chen-etal-2023-many</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.745</doi>
    </paper>
    <paper id="746">
      <title>Improving word mover’s distance by leveraging self-attention matrix</title>
      <author><first>Hiroaki</first><last>Yamagiwa</last></author>
      <author><first>Sho</first><last>Yokoi</last></author>
      <author><first>Hidetoshi</first><last>Shimodaira</last></author>
      <pages>11160-11183</pages>
      <abstract>Measuring the semantic similarity between two sentences is still an important task. The word mover’s distance (WMD) computes the similarity via the optimal alignment between the sets of word embeddings. However, WMD does not utilize word order, making it challenging to distinguish sentences with significant overlaps of similar words, even if they are semantically very different. Here, we attempt to improve WMD by incorporating the sentence structure represented by BERT’s self-attention matrix (SAM). The proposed method is based on the Fused Gromov-Wasserstein distance, which simultaneously considers the similarity of the word embedding and the SAM for calculating the optimal transport between two sentences. Experiments demonstrate the proposed method enhances WMD and its variants in paraphrase identification with near-equivalent performance in semantic textual similarity.</abstract>
      <url hash="3275046a">2023.findings-emnlp.746</url>
      <bibkey>yamagiwa-etal-2023-improving</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.746</doi>
    </paper>
    <paper id="747">
      <title>Improving Span Representation by Efficient Span-Level Attention</title>
      <author><first>Pengyu</first><last>Ji</last></author>
      <author><first>Songlin</first><last>Yang</last></author>
      <author><first>Kewei</first><last>Tu</last></author>
      <pages>11184-11192</pages>
      <abstract>High-quality span representations are crucial to natural language processing tasks involving span prediction and classification. Most existing methods derive a span representation by aggregation of token representations within the span. In contrast, we aim to improve span representations by considering span-span interactions as well as more comprehensive span-token interactions. Specifically, we introduce layers of span-level attention on top of a normal token-level transformer encoder. Given that attention between all span pairs results in <tex-math>O(n^4)</tex-math> complexity (<tex-math>n</tex-math> being the sentence length) and not all span interactions are intuitively meaningful, we restrict the range of spans that a given span could attend to, thereby reducing overall complexity to <tex-math>O(n^3)</tex-math>. We conduct experiments on various span-related tasks and show superior performance of our model surpassing baseline models. Our code is publicly available at <url>https://github.com/jipy0222/Span-Level-Attention</url>.</abstract>
      <url hash="5cfaf799">2023.findings-emnlp.747</url>
      <bibkey>ji-etal-2023-improving</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.747</doi>
    </paper>
    <paper id="748">
      <title>Long-Horizon Dialogue Understanding for Role Identification in the Game of Avalon with Large Language Models</title>
      <author><first>Simon</first><last>Stepputtis</last></author>
      <author><first>Joseph</first><last>Campbell</last></author>
      <author><first>Yaqi</first><last>Xie</last></author>
      <author><first>Zhengyang</first><last>Qi</last></author>
      <author><first>Wenxin</first><last>Zhang</last></author>
      <author><first>Ruiyi</first><last>Wang</last></author>
      <author><first>Sanketh</first><last>Rangreji</last></author>
      <author><first>Charles</first><last>Lewis</last></author>
      <author><first>Katia</first><last>Sycara</last></author>
      <pages>11193-11208</pages>
      <abstract>Deception and persuasion play a critical role in long-horizon dialogues between multiple parties, especially when the interests, goals, and motivations of the participants are not aligned. Such complex tasks pose challenges for current Large Language Models (LLM) as deception and persuasion can easily mislead them, especially in long-horizon multi-party dialogues. To this end, we explore the game of Avalon: The Resistance, a social deduction game in which players must determine each other’s hidden identities to complete their team’s objective. We introduce an online testbed and a dataset containing 20 carefully collected and labeled games among human players that exhibit long-horizon deception in a cooperative-competitive setting. We discuss the capabilities of LLMs to utilize deceptive long-horizon conversations between six human players to determine each player’s goal and motivation. Particularly, we discuss the multimodal integration of the chat between the players and the game’s state that grounds the conversation, providing further insights into the true player identities. We find that even current state-of-the-art LLMs do not reach human performance, making our dataset a compelling benchmark to investigate the decision-making and language-processing capabilities of LLMs. Our dataset and online testbed can be found at our project website: https://sstepput.github.io/Avalon-NLU/</abstract>
      <url hash="6a575172">2023.findings-emnlp.748</url>
      <bibkey>stepputtis-etal-2023-long</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.748</doi>
    </paper>
    <paper id="749">
      <title>Improving Sequential Model Editing with Fact Retrieval</title>
      <author><first>Xiaoqi</first><last>Han</last></author>
      <author><first>Ru</first><last>Li</last></author>
      <author><first>Hongye</first><last>Tan</last></author>
      <author><first>Wang</first><last>Yuanlong</last></author>
      <author><first>Qinghua</first><last>Chai</last></author>
      <author><first>Jeff</first><last>Pan</last></author>
      <pages>11209-11224</pages>
      <abstract>The task of sequential model editing is to fix erroneous knowledge in Pre-trained Language Models (PLMs) efficiently, precisely and continuously. Although existing methods can deal with a small number of modifications, these methods experience a performance decline or require additional annotated data, when the number of edits increases. In this paper, we propose a <tex-math>\textbf{R}</tex-math>etrieval <tex-math>\textbf{A}</tex-math>ugmented <tex-math>\textbf{S}</tex-math>equential Model <tex-math>\textbf{E}</tex-math>diting framework (<tex-math>\textbf{RASE}</tex-math>) that leverages factual information to enhance editing generalization and to guide the identification of edits by retrieving related facts from the fact-patch memory we constructed. Our main findings are: (i) State-of-the-art models can hardly correct massive mistakes stably and efficiently; (ii) Even if we scale up to thousands of edits, RASE can significantly enhance editing generalization and maintain consistent performance and efficiency; (iii) RASE can edit large-scale PLMs and increase the performance of different editors. Moreover, it can integrate with ChatGPT and further improve performance. Our code and data are available at: https://github.com/sev777/RASE.</abstract>
      <url hash="3630ef10">2023.findings-emnlp.749</url>
      <bibkey>han-etal-2023-improving</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.749</doi>
    </paper>
    <paper id="750">
      <title>Battle of the Large Language Models: Dolly vs <fixed-case>LL</fixed-case>a<fixed-case>MA</fixed-case> vs Vicuna vs Guanaco vs Bard vs <fixed-case>C</fixed-case>hat<fixed-case>GPT</fixed-case> - A Text-to-<fixed-case>SQL</fixed-case> Parsing Comparison</title>
      <author><first>Shuo</first><last>Sun</last></author>
      <author><first>Yuchen</first><last>Zhang</last></author>
      <author><first>Jiahuan</first><last>Yan</last></author>
      <author><first>Yuze</first><last>Gao</last></author>
      <author><first>Donovan</first><last>Ong</last></author>
      <author><first>Bin</first><last>Chen</last></author>
      <author><first>Jian</first><last>Su</last></author>
      <pages>11225-11238</pages>
      <abstract>The success of ChatGPT has ignited an AI race, with researchers striving to develop new large language models (LLMs) that can match or surpass the language understanding and generation abilities of commercial ones. In recent times, a number of models have emerged, claiming performance near that of GPT-3.5 or GPT-4 through various instruction-tuning methods. As practitioners of Text-to-SQL parsing, we are grateful for their valuable contributions to open-source research. However, it is important to approach these claims with a sense of scrutiny and ascertain the actual effectiveness of these models. Therefore, we pit six popular large language models against each other, systematically evaluating their Text-to-SQL parsing capability on nine benchmark datasets with five different prompting strategies, covering both zero-shot and few-shot scenarios. Regrettably, the open-sourced models fell significantly short of the performance achieved by closed-source models like GPT-3.5, highlighting the need for further work to bridge the performance gap between these models.</abstract>
      <url hash="692fb1de">2023.findings-emnlp.750</url>
      <bibkey>sun-etal-2023-battle</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.750</doi>
    </paper>
    <paper id="751">
      <title><fixed-case>KB</fixed-case>io<fixed-case>XLM</fixed-case>: A Knowledge-anchored Biomedical Multilingual Pretrained Language Model</title>
      <author><first>Lei</first><last>Geng</last></author>
      <author><first>Xu</first><last>Yan</last></author>
      <author><first>Ziqiang</first><last>Cao</last></author>
      <author><first>Juntao</first><last>Li</last></author>
      <author><first>Wenjie</first><last>Li</last></author>
      <author><first>Sujian</first><last>Li</last></author>
      <author><first>Xinjie</first><last>Zhou</last></author>
      <author><first>Yang</first><last>Yang</last></author>
      <author><first>Jun</first><last>Zhang</last></author>
      <pages>11239-11250</pages>
      <abstract>Most biomedical pretrained language models are monolingual and cannot handle the growing cross-lingual requirements. The scarcity of non-English domain corpora, not to mention parallel data, poses a significant hurdle in training multilingual biomedical models. Since knowledge forms the core of domain-specific corpora and can be translated into various languages accurately, we propose a model called KBioXLM, which transforms the multilingual pretrained model XLM-R into the biomedical domain using a knowledge-anchored approach. We achieve a biomedical multilingual corpus by incorporating three granularity knowledge alignments (entity, fact, and passage levels) into monolingual corpora. Then we design three corresponding training tasks (entity masking, relation masking, and passage relation prediction) and continue training on top of the XLM-R model to enhance its domain cross-lingual ability. To validate the effectiveness of our model, we translate the English benchmarks of multiple tasks into Chinese. Experimental results demonstrate that our model significantly outperforms monolingual and multilingual pretrained models in cross-lingual zero-shot and few-shot scenarios, achieving improvements of up to 10+ points.</abstract>
      <url hash="c6e83671">2023.findings-emnlp.751</url>
      <bibkey>geng-etal-2023-kbioxlm</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.751</doi>
    </paper>
    <paper id="752">
      <title>Words, Subwords, and Morphemes: What Really Matters in the Surprisal-Reading Time Relationship?</title>
      <author><first>Sathvik</first><last>Nair</last></author>
      <author><first>Philip</first><last>Resnik</last></author>
      <pages>11251-11260</pages>
      <abstract>An important assumption that comes with using LLMs on psycholinguistic data has gone unverified. LLM-based predictions are based on subword tokenization, not decomposition of words into morphemes. Does that matter? We carefully test this by comparing surprisal estimates using orthographic, morphological, and BPE tokenization against reading time data. Our results replicate previous findings and provide evidence that *in the aggregate*, predictions using BPE tokenization do not suffer relative to morphological and orthographic segmentation. However, a finer-grained analysis points to potential issues with relying on BPE-based tokenization, as well as providing promising results involving morphologically-aware surprisal estimates and suggesting a new method for evaluating morphological prediction.</abstract>
      <url hash="ca121539">2023.findings-emnlp.752</url>
      <bibkey>nair-resnik-2023-words</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.752</doi>
    </paper>
    <paper id="753">
      <title>A Zero-Shot Language Agent for Computer Control with Structured Reflection</title>
      <author><first>Tao</first><last>Li</last></author>
      <author><first>Gang</first><last>Li</last></author>
      <author><first>Zhiwei</first><last>Deng</last></author>
      <author><first>Bryan</first><last>Wang</last></author>
      <author><first>Yang</first><last>Li</last></author>
      <pages>11261-11274</pages>
      <abstract>Large language models (LLMs) have shown increasing capacity at planning and executing a high-level goal in a live computer environment (e.g. MiniWoB++). To perform a task, recent works often require a model to learn from trace examples of the task via either supervised learning or few/many-shot prompting. Without these trace examples, it remains a challenge how an agent can autonomously learn and improve its control on a computer, which limits the ability of an agent to perform a new task. We approach this problem with a zero-shot agent that requires no given expert traces. Our agent plans for executable actions on a partially observed environment, and iteratively progresses a task by identifying and learning from its mistakes via self-reflection and structured thought management. On the easy tasks of MiniWoB++, we show that our zero-shot agent often outperforms recent SoTAs, with more efficient reasoning. For tasks with more complexity, our reflective agent performs on par with prior best models, even though previous works had the advantages of accessing expert traces or additional screen information.</abstract>
      <url hash="d3693763">2023.findings-emnlp.753</url>
      <bibkey>li-etal-2023-zero</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.753</doi>
    </paper>
    <paper id="754">
      <title><fixed-case>S</fixed-case>teer<fixed-case>LM</fixed-case>: Attribute Conditioned <fixed-case>SFT</fixed-case> as an (User-Steerable) Alternative to <fixed-case>RLHF</fixed-case></title>
      <author><first>Yi</first><last>Dong</last></author>
      <author><first>Zhilin</first><last>Wang</last></author>
      <author><first>Makesh</first><last>Sreedhar</last></author>
      <author><first>Xianchao</first><last>Wu</last></author>
      <author><first>Oleksii</first><last>Kuchaiev</last></author>
      <pages>11275-11288</pages>
      <abstract>Model alignment with human preferences is an essential step in making Large Language Models (LLMs) helpful and consistent with human values. It typically consists of supervised fine-tuning (SFT) and reinforcement learning from human feedback (RLHF) stages. However, RLHF faces inherent limitations stemming from a complex training setup and its tendency to align the model with implicit values that end users cannot control at run-time. Moreover, reward models in RLHF stage commonly rely on single-dimensional feedback as opposed to explicit, multifaceted signals that indicate attributes such as helpfulness, humor, and toxicity. To address these limitations, we propose SteerLM, a supervised fine-tuning method that empowers end-users to control responses during inference. SteerLM conditions responses to conform to an explicitly defined multi-dimensional set of attributes, thereby empowering a steerable AI capable of generating helpful and high-quality responses while maintaining customizability. Experiments show that SteerLM trained on open source datasets generates responses that are preferred by human and automatic evaluators to many state-of-the-art baselines trained with RLHF while being much easier to train. Try SteerLM at https://huggingface.co/nvidia/SteerLM-llama2-13B</abstract>
      <url hash="53cef711">2023.findings-emnlp.754</url>
      <bibkey>dong-etal-2023-steerlm</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.754</doi>
    </paper>
    <paper id="755">
      <title><fixed-case>I</fixed-case>deal<fixed-case>GPT</fixed-case>: Iteratively Decomposing Vision and Language Reasoning via Large Language Models</title>
      <author><first>Haoxuan</first><last>You</last></author>
      <author><first>Rui</first><last>Sun</last></author>
      <author><first>Zhecan</first><last>Wang</last></author>
      <author><first>Long</first><last>Chen</last></author>
      <author><first>Gengyu</first><last>Wang</last></author>
      <author><first>Hammad</first><last>Ayyubi</last></author>
      <author><first>Kai-Wei</first><last>Chang</last></author>
      <author><first>Shih-Fu</first><last>Chang</last></author>
      <pages>11289-11303</pages>
      <abstract>The field of vision-and-language (VL) understanding has made unprecedented progress with end-to-end large pre-trained VL models (VLMs). However, they still fall short in zero-shot reasoning tasks that require multi-step inferencing. To achieve this goal, previous works resort to a divide-and-conquer pipeline. In this paper, we argue that previous efforts have several inherent shortcomings: 1) They rely on domain-specific sub-question decomposing models. 2) They force models to predict the final answer even if the sub-questions or sub-answers provide insufficient information. We address these limitations via IdealGPT, a framework that iteratively decomposes VL reasoning using large language models (LLMs). Specifically, IdealGPT utilizes an LLM to generate sub-questions, a VLM to provide corresponding sub-answers, and another LLM to reason to achieve the final answer. These three modules perform the divide-and-conquer procedure iteratively until the model is confident about the final answer to the main question. We evaluate IdealGPT on multiple challenging VL reasoning tasks under a zero-shot setting. In particular, our IdealGPT outperforms the best existing GPT-4-like models by an absolute 10% on VCR and 15% on SNLI-VE. Code is available at https://github.com/Hxyou/IdealGPT.</abstract>
      <url hash="ad943552">2023.findings-emnlp.755</url>
      <bibkey>you-etal-2023-idealgpt</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.755</doi>
    </paper>
    <paper id="756">
      <title><fixed-case>GRI</fixed-case>: Graph-based Relative Isomorphism of Word Embedding Spaces</title>
      <author><first>Muhammad</first><last>Ali</last></author>
      <author><first>Yan</first><last>Hu</last></author>
      <author><first>Jianbin</first><last>Qin</last></author>
      <author><first>Di</first><last>Wang</last></author>
      <pages>11304-11313</pages>
      <abstract>Automated construction of bi-lingual dictionaries using monolingual embedding spaces is a core challenge in machine translation. The end performance of these dictionaries relies on the geometric similarity of individual spaces, i.e., their degree of isomorphism. Existing attempts aimed at controlling the relative isomorphism of different spaces fail to incorporate the impact of lexically different but semantically related words in the training objective. To address this, we propose GRI that combines the distributional training objectives with attentive graph convolutions to unanimously consider the impact of lexical variations of semantically similar words required to define/compute the relative isomorphism of multiple spaces. Exper imental evaluation shows that GRI outperforms the existing research by improving the average P@1 by a relative score of upto 63.6%.</abstract>
      <url hash="9e977623">2023.findings-emnlp.756</url>
      <bibkey>ali-etal-2023-gri</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.756</doi>
    </paper>
    <paper id="757">
      <title><fixed-case>P</fixed-case>ersona<fixed-case>LM</fixed-case>: Language Model Personalization via Domain-distributed Span Aggregated K-Nearest N-gram Retrieval Augmentation</title>
      <author><first>Puneet</first><last>Mathur</last></author>
      <author><first>Zhe</first><last>Liu</last></author>
      <author><first>Ke</first><last>Li</last></author>
      <author><first>Yingyi</first><last>Ma</last></author>
      <author><first>Gil</first><last>Keren</last></author>
      <author><first>Zeeshan</first><last>Ahmed</last></author>
      <author><first>Dinesh</first><last>Manocha</last></author>
      <author><first>Xuedong</first><last>Zhang</last></author>
      <pages>11314-11328</pages>
      <abstract>We introduce PersonaLM - Domain-distributed Span-Aggregated K-nearest N-gram retrieval augmentation to improve language modeling for Automatic Speech Recognition (ASR) personalization. PersonaLM leverages contextually similar n-gram word frequencies for recognizing rare word patterns associated with unseen domains. It aggregates the next-word probability distribution based on the relative importance of different domains to the input query. To achieve this, we propose a Span Aggregated Group-Contrastive Neural (SCAN) retriever that learns to rank external domains/users by utilizing a group-wise contrastive span loss that pulls together span representations belonging to the same group while pushing away spans from unrelated groups in the semantic space. We propose ASAP benchmark for ASR LM personalization that consists of three user-specific speech-to-text tasks for meetings, TED talks, and financial earnings calls. Extensive experiments show that PersonaLM significantly outperforms strong baselines with a 10-16% improvement in perplexity and a 5-8% reduction in Word Error Rates on popular Wikitext-103, UserLibri, and our ASAP dataset. We further demonstrate the usefulness of the SCAN retriever for improving user-personalized text generation and classification by retrieving relevant context for zero-shot prompting and few-shot fine-tuning of LLMs by 7-12% on the LAMP benchmark.</abstract>
      <url hash="7621b4dc">2023.findings-emnlp.757</url>
      <bibkey>mathur-etal-2023-personalm</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.757</doi>
    </paper>
    <paper id="758">
      <title>Scaling Vision-Language Models with Sparse Mixture of Experts</title>
      <author><first>Sheng</first><last>Shen</last></author>
      <author><first>Zhewei</first><last>Yao</last></author>
      <author><first>Chunyuan</first><last>Li</last></author>
      <author><first>Trevor</first><last>Darrell</last></author>
      <author><first>Kurt</first><last>Keutzer</last></author>
      <author><first>Yuxiong</first><last>He</last></author>
      <pages>11329-11344</pages>
      <abstract>The field of natural language processing (NLP) has made significant strides in recent years, particularly in the development of large-scale vision-language models (VLMs). These models aim to bridge the gap between text and visual information, enabling a more comprehensive understanding of multimedia data. However, as these models become larger and more complex, they also become more challenging to train and deploy. One approach to addressing this challenge is the use of sparsely-gated mixture-of-experts (MoE) techniques, which divide the model into smaller, specialized sub-models that can jointly solve a task. In this paper, we explore the effectiveness of MoE in scaling vision-language models, demonstrating its potential to achieve state-of-the-art performance on a range of benchmarks over dense models of equivalent computational cost. Our research offers valuable insights into stabilizing the training of MoE models, understanding the impact of MoE on model interpretability, and balancing the trade-offs between compute performance when scaling VLMs. We hope our work will inspire further research into the use of MoE for scaling large-scale vision-language models and other multimodal machine learning applications.</abstract>
      <url hash="f001bc84">2023.findings-emnlp.758</url>
      <bibkey>shen-etal-2023-scaling</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.758</doi>
    </paper>
    <paper id="759">
      <title>Aspect-Category Enhanced Learning with a Neural Coherence Model for Implicit Sentiment Analysis</title>
      <author><first>Jin</first><last>Cui</last></author>
      <author><first>Fumiyo</first><last>Fukumoto</last></author>
      <author><first>Xinfeng</first><last>Wang</last></author>
      <author><first>Yoshimi</first><last>Suzuki</last></author>
      <author><first>Jiyi</first><last>Li</last></author>
      <author><first>Wanzeng</first><last>Kong</last></author>
      <pages>11345-11358</pages>
      <abstract>Aspect-based sentiment analysis (ABSA) has been widely studied since the explosive growth of social networking services. However, the recognition of implicit sentiments that do not contain obvious opinion words remains less explored. In this paper, we propose aspect-category enhanced learning with a neural coherence model (ELCoM). It captures document-level coherence by using contrastive learning, and sentence-level by a hypergraph to mine opinions from explicit sentences to aid implicit sentiment classification. To address the issue of sentences with different sentiment polarities in the same category, we perform cross-category enhancement to offset the impact of anomalous nodes in the hypergraph and obtain sentence representations with enhanced aspect-category. Extensive experiments on benchmark datasets show that the ELCoM achieves state-of-the-art performance. Our source codes and data are released at <url>https://github.com/cuijin-23/ELCoM</url>.</abstract>
      <url hash="3a04f1b1">2023.findings-emnlp.759</url>
      <bibkey>cui-etal-2023-aspect</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.759</doi>
    </paper>
    <paper id="760">
      <title>End-to-end Adversarial Sample Generation for Data Augmentation</title>
      <author><first>Tianyuan</first><last>Liu</last></author>
      <author><first>Yuqing</first><last>Sun</last></author>
      <pages>11359-11368</pages>
      <abstract>Adversarial samples pose a significant challenge to neural inference models. In this paper, we propose a novel enhancing approach A3 for the robustness of the neural NLP models, which combines the adversarial training and data augmentation. We propose an adversarial sample generator that consists of a conditioned paraphrasing model and a condition generator. The latter aims to generate conditions which guides the paraphrasing model to generate adversarial samples. A pretrained discriminator is introduced to help the adversarial sample generator adapt to the data characteristics for different tasks. We adopt a weighted loss to incorporate the generated adversarial samples with the original samples for augmented training. Compared to existing methods, our approach is much efficient since the generation process is independent to the target model and the generated samples are reusable for different models. Experimental results on several tasks show that our approach improves the overall performance of the trained model. Specially, the enhanced model is robust for various attacking techniques.</abstract>
      <url hash="dc087feb">2023.findings-emnlp.760</url>
      <bibkey>liu-sun-2023-end</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.760</doi>
    </paper>
    <paper id="761">
      <title><fixed-case>Q</fixed-case>uery2<fixed-case>T</fixed-case>riple: Unified Query Encoding for Answering Diverse Complex Queries over Knowledge Graphs</title>
      <author><first>Yao</first><last>Xu</last></author>
      <author><first>Shizhu</first><last>He</last></author>
      <author><first>Cunguang</first><last>Wang</last></author>
      <author><first>Li</first><last>Cai</last></author>
      <author><first>Kang</first><last>Liu</last></author>
      <author><first>Jun</first><last>Zhao</last></author>
      <pages>11369-11382</pages>
      <abstract>Complex Query Answering (CQA) is a challenge task of Knowledge Graph (KG). Due to the incompleteness of KGs, query embedding (QE) methods have been proposed to encode queries and entities into the same embedding space, and treat logical operators as neural set operators to obtain answers. However, these methods train KG embeddings and neural set operators concurrently on both simple (one-hop) and complex (multi-hop and logical) queries, which causes performance degradation on simple queries and low training efficiency. In this paper, we propose Query to Triple (Q2T), a novel approach that decouples the training for simple and complex queries. Q2T divides the training into two stages: (1) Pre-training the neural link predictor on simple queries to predict tail entities based on the head entity and relation. (2) Training the query encoder on complex queries to encode diverse complex queries into a unified triple form that can be efficiently solved by the pretrained link predictor. Our proposed Q2T is not only efficient to train, but also modular, thus easily adaptable to various neural link predictors that have been studied well. Extensive experiments demonstrate that, even without explicit modeling for neural set operators, Q2T still achieves state-of-the-art performance on diverse complex queries over three public benchmarks.</abstract>
      <url hash="c41c9caa">2023.findings-emnlp.761</url>
      <bibkey>xu-etal-2023-query2triple</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.761</doi>
    </paper>
    <paper id="762">
      <title>Self-<fixed-case>P</fixed-case>olish: Enhance Reasoning in Large Language Models via Problem Refinement</title>
      <author><first>Zhiheng</first><last>Xi</last></author>
      <author><first>Senjie</first><last>Jin</last></author>
      <author><first>Yuhao</first><last>Zhou</last></author>
      <author><first>Rui</first><last>Zheng</last></author>
      <author><first>Songyang</first><last>Gao</last></author>
      <author><first>Jia</first><last>Liu</last></author>
      <author><first>Tao</first><last>Gui</last></author>
      <author><first>Qi</first><last>Zhang</last></author>
      <author><first>Xuanjing</first><last>Huang</last></author>
      <pages>11383-11406</pages>
      <abstract>To enhance the multi-step reasoning capabilities of large language models, researchers have extensively explored prompting methods, notably the Chain-of-Thought (CoT) method which explicitly elicits human-like rationales. However, they have inadvertently overlooked the potential of enhancing model reasoning performance by formulating higher-quality problems. In this work, we start from the problem side and propose Self-Polish (SP), a novel method that facilitates the model’s reasoning by guiding it to progressively refine the given problems to be more comprehensible and solvable. We also explore several automatic prompting varients and propose the Self-Polish prompt bank for the community. SP is orthogonal to all other prompting methods of answer/reasoning side like CoT, allowing for seamless integration with state-of-the-art techniques for further improvement. Thorough experiments show that the proposed method attains notable and consistent effectiveness on five reasoning benchmarks across different models. Furthermore, our method also showcases impressive performance on robustness evaluation. Codes and prompts are available at https://github.com/WooooDyy/Self-Polish.</abstract>
      <url hash="c73f6ae8">2023.findings-emnlp.762</url>
      <bibkey>xi-etal-2023-self</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.762</doi>
    </paper>
    <paper id="763">
      <title>Breaking through Deterministic Barriers: Randomized Pruning Mask Generation and Selection</title>
      <author><first>Jianwei</first><last>Li</last></author>
      <author><first>Weizhi</first><last>Gao</last></author>
      <author><first>Qi</first><last>Lei</last></author>
      <author><first>Dongkuan</first><last>Xu</last></author>
      <pages>11407-11423</pages>
      <abstract>It is widely acknowledged that large and sparse models have higher accuracy than small and dense models under the same model size constraints. This motivates us to train a large model and then remove its redundant neurons or weights by pruning. Most existing works pruned the networks in a deterministic way, the performance of which solely depends on a single pruning criterion and thus lacks variety. Instead, in this paper, we propose a model pruning strategy that first generates several pruning masks in a designed random way. Subsequently, along with an effective mask-selection rule, the optimal mask is chosen from the pool of mask candidates. To further enhance efficiency, we introduce an early mask evaluation strategy, mitigating the overhead associated with training multiple masks. Our extensive experiments demonstrate that this approach achieves state-of-the-art performance across eight datasets from GLUE, particularly excelling at high levels of sparsity.</abstract>
      <url hash="36cf46ca">2023.findings-emnlp.763</url>
      <bibkey>li-etal-2023-breaking</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.763</doi>
    </paper>
    <paper id="764">
      <title>Eyes Show the Way: Modelling Gaze Behaviour for Hallucination Detection</title>
      <author><first>Kishan</first><last>Maharaj</last></author>
      <author><first>Ashita</first><last>Saxena</last></author>
      <author><first>Raja</first><last>Kumar</last></author>
      <author><first>Abhijit</first><last>Mishra</last></author>
      <author><first>Pushpak</first><last>Bhattacharyya</last></author>
      <pages>11424-11438</pages>
      <abstract>Detecting hallucinations in natural language processing (NLP) is a critical undertaking that demands a deep understanding of both the semantic and pragmatic aspects of languages. Cognitive approaches that leverage users’ behavioural signals, such as gaze, have demonstrated effectiveness in addressing NLP tasks with similar linguistic complexities. However, their potential in the context of hallucination detection remains largely unexplored. In this paper, we propose a novel cognitive approach for hallucination detection that leverages gaze signals from humans. We first collect and introduce an eye tracking corpus (IITB-HGC: IITB-Hallucination Gaze corpus) consisting of 500 instances, annotated by five annotators for hallucination detection. Our analysis reveals that humans selectively attend to relevant parts of the text based on distributional similarity, similar to the attention bias phenomenon in psychology. We identify two attention strategies employed by humans: global attention, which focuses on the most informative sentence, and local attention, which focuses on important words within a sentence. Leveraging these insights, we propose a novel cognitive framework for hallucination detection that incorporates these attention biases. Experimental evaluations on the FactCC dataset demonstrate the efficacy of our approach, obtaining a balanced accuracy of 87.1%. Our study highlights the potential of gaze-based approaches in addressing the task of hallucination detection and sheds light on the cognitive processes employed by humans in identifying inconsistencies.</abstract>
      <url hash="79c899d5">2023.findings-emnlp.764</url>
      <bibkey>maharaj-etal-2023-eyes</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.764</doi>
    </paper>
    <paper id="765">
      <title>Noisy Pair Corrector for Dense Retrieval</title>
      <author><first>Hang</first><last>Zhang</last></author>
      <author><first>Yeyun</first><last>Gong</last></author>
      <author><first>Xingwei</first><last>He</last></author>
      <author><first>Dayiheng</first><last>Liu</last></author>
      <author><first>Daya</first><last>Guo</last></author>
      <author><first>Jiancheng</first><last>Lv</last></author>
      <author><first>Jian</first><last>Guo</last></author>
      <pages>11439-11451</pages>
      <abstract>Most dense retrieval models contain an implicit assumption: the training query-document pairs are exactly matched. Since it is expensive to annotate the corpus manually, training pairs in real-world applications are usually collected automatically, which inevitably introduces mismatched-pair noise. In this paper, we explore an interesting and challenging problem in dense retrieval, how to train an effective model with mismatched-pair noise. To solve this problem, we propose a novel approach called Noisy Pair Corrector (NPC), which consists of a detection module and a correction module. The detection module estimates noise pairs by calculating the perplexity between annotated positive and easy negative documents. The correction module utilizes an exponential moving average (EMA) model to provide a soft supervised signal, aiding in mitigating the effects of noise. We conduct experiments on text-retrieval benchmarks Natural Question and TriviaQA, code-search benchmarks StaQC and SO-DS. Experimental results show that NPC achieves excellent performance in handling both synthetic and realistic noise.</abstract>
      <url hash="1df28b96">2023.findings-emnlp.765</url>
      <bibkey>zhang-etal-2023-noisy</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.765</doi>
    </paper>
    <paper id="766">
      <title>Enhancing Accessible Communication: from <fixed-case>E</fixed-case>uropean <fixed-case>P</fixed-case>ortuguese to <fixed-case>P</fixed-case>ortuguese <fixed-case>S</fixed-case>ign <fixed-case>L</fixed-case>anguage</title>
      <author><first>Catarina</first><last>Sousa</last></author>
      <author><first>Luisa</first><last>Coheur</last></author>
      <author><first>Mara</first><last>Moita</last></author>
      <pages>11452-11460</pages>
      <abstract>Portuguese Sign Language (LGP) is the official language in deaf education in Portugal. Current approaches in developing a translation system between European Portuguese and LGP rely on hand-crafted rules. In this paper, we present a fully automatic corpora-driven rule-based machine translation system between European Portuguese and LGP glosses, and also two neural machine translation models. We also contribute with the LGP-5-Domain corpus, composed of five different text domains, built with the help of our rule-based system, and used to train the neural models. In addition, we provide a gold collection, annotated by LGP experts, that can be used for future evaluations. Compared with the only similar available translation system, PE2LGP, results are always improved with the new rule-based model, which competes for the highest scores with one of the neural models.</abstract>
      <url hash="3e99354f">2023.findings-emnlp.766</url>
      <bibkey>sousa-etal-2023-enhancing</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.766</doi>
    </paper>
    <paper id="767">
      <title>Diversifying language models for lesser-studied languages and language-usage contexts: A case of second language <fixed-case>K</fixed-case>orean</title>
      <author><first>Hakyung</first><last>Sung</last></author>
      <author><first>Gyu-Ho</first><last>Shin</last></author>
      <pages>11461-11473</pages>
      <abstract>This study investigates the extent to which currently available morpheme parsers/taggers apply to lesser-studied languages and language-usage contexts, with a focus on second language (L2) Korean. We pursue this inquiry by (1) training a neural-network model (pre-trained on first language [L1] Korean data) on varying L2 datasets and (2) measuring its morpheme parsing/POS tagging performance on L2 test sets from both the same and different sources of the L2 train sets. Results show that the L2 trained models generally excel in domain-specific tokenization and POS tagging compared to the L1 pre-trained baseline model. Interestingly, increasing the size of the L2 training data does not lead to improving model performance consistently.</abstract>
      <url hash="5c20c2b6">2023.findings-emnlp.767</url>
      <bibkey>sung-shin-2023-diversifying</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.767</doi>
    </paper>
    <paper id="768">
      <title>Improving generalization in large langue model by learning prefix subspaces</title>
      <author><first>Louis</first><last>Falissard</last></author>
      <author><first>Vincent</first><last>Guigue</last></author>
      <author><first>Laure</first><last>Soulier</last></author>
      <pages>11474-11483</pages>
      <abstract>This article focuses on large language models (LLMs) fine-tuning in the scarce data regime (also known as “few-shot learning setting”). We propose a method to increase the generalization capabilities of LLMs based on neural network subspaces. This optimization method, recently introduced in computer vision, aims to improve model generalization by identifying wider local optima through the joint optimization of an entire simplex of models in parameter space. Although this property would be highly beneficial in the context of training large language models in the “few-shot learning” setting, its adaptation to massive, pretrained transformers poses some challenges. First, their considerable number of parameters make it difficult to train several model jointly, and second, their deterministic parameter initialisation schemes make them unfit to the subspace method as originaly proposed. We show in this paper that its application to “Parameter Efficient Fine-Tuning” (PEFT) methods, however, is relatively natural, and we propose to apply it to prefix-tuning, by learning entire simplexes of continous prefixes. We test our method on a variant of the GLUE benchmark adapted to the few-shot learning setting, and show that both our contributions (learning prefix simplexes, and non-deterministic validation metric inference) jointly lead to a gain in average performances compared to state of the art methods.</abstract>
      <url hash="536d1ba6">2023.findings-emnlp.768</url>
      <bibkey>falissard-etal-2023-improving</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.768</doi>
    </paper>
    <paper id="769">
      <title>Domain Adaptation for Sentiment Analysis Using Robust Internal Representations</title>
      <author><first>Mohammad</first><last>Rostami</last></author>
      <author><first>Digbalay</first><last>Bose</last></author>
      <author><first>Shrikanth</first><last>Narayanan</last></author>
      <author><first>Aram</first><last>Galstyan</last></author>
      <pages>11484-11498</pages>
      <abstract>Sentiment analysis is a costly yet necessary task for enterprises to study the opinions of their customers to improve their products and to determine optimal marketing strategies. Due to the existence of a wide range of domains across different products and services, cross-domain sentiment analysis methods have received significant attention. These methods mitigate the domain gap between different applications by training cross-domain generalizable classifiers which relax the need for data annotation for each domain. We develop a domain adaptation method which induces large margins between data representations that belong to different classes in an embedding space. This embedding space is trained to be domain-agnostic by matching the data distributions across the domains. Large interclass margins in the source domain help to reduce the effect of “domain shift” in the target domain. Theoretical and empirical analysis are provided to demonstrate that the proposed method is effective.</abstract>
      <url hash="2ed85734">2023.findings-emnlp.769</url>
      <bibkey>rostami-etal-2023-domain</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.769</doi>
    </paper>
    <paper id="770">
      <title><fixed-case>K</fixed-case>e<fixed-case>FVP</fixed-case>: Knowledge-enhanced Financial Volatility Prediction</title>
      <author><first>Hao</first><last>Niu</last></author>
      <author><first>Yun</first><last>Xiong</last></author>
      <author><first>Xiaosu</first><last>Wang</last></author>
      <author><first>Wenjing</first><last>Yu</last></author>
      <author><first>Yao</first><last>Zhang</last></author>
      <author><first>Weizu</first><last>Yang</last></author>
      <pages>11499-11513</pages>
      <abstract>Financial volatility prediction is vital for indicating a company’s risk profile. Transcripts of companies’ earnings calls are important unstructured data sources to be utilized to access companies’ performance and risk profiles. However, current works ignore the role of financial metrics knowledge (such as EBIT, EPS, and ROI) in transcripts, which is crucial for understanding companies’ performance, and little consideration is given to integrating text and price information. In this work, we statistic common financial metrics and make a special dataset based on these metrics. Then, we introduce a knowledge-enhanced financial volatility prediction method (KeFVP) to inject knowledge of financial metrics into text comprehension by knowledge-enhanced adaptive pre-training (KePt) and effectively incorporating text and price information by introducing a conditional time series prediction module. We conduct extensive experiments on three real-world public datasets, and the results indicate that KeFVP is effective and outperforms all the state-of-the-art methods.</abstract>
      <url hash="788517be">2023.findings-emnlp.770</url>
      <bibkey>niu-etal-2023-kefvp</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.770</doi>
    </paper>
    <paper id="771">
      <title>A Frustratingly Easy Plug-and-Play Detection-and-Reasoning Module for <fixed-case>C</fixed-case>hinese Spelling Check</title>
      <author><first>Haojing</first><last>Huang</last></author>
      <author><first>Jingheng</first><last>Ye</last></author>
      <author><first>Qingyu</first><last>Zhou</last></author>
      <author><first>Yinghui</first><last>Li</last></author>
      <author><first>Yangning</first><last>Li</last></author>
      <author><first>Feng</first><last>Zhou</last></author>
      <author><first>Hai-Tao</first><last>Zheng</last></author>
      <pages>11514-11525</pages>
      <abstract>In recent years, Chinese Spelling Check (CSC) has been greatly improved by designing task-specific pre-training methods or introducing auxiliary tasks, which mostly solve this task in an end-to-end fashion. In this paper, we propose to decompose the CSC workflow into detection, reasoning, and searching subtasks so that the rich external knowledge about the Chinese language can be leveraged more directly and efficiently. Specifically, we design a plug-and-play detection-and-reasoning module that is compatible with existing SOTA non-autoregressive CSC models to further boost their performance. We find that the detection-and-reasoning module trained for one model can also benefit other models. We also study the primary interpretability provided by the task decomposition. Extensive experiments and detailed analyses demonstrate the effectiveness and competitiveness of the proposed module.</abstract>
      <url hash="f0997ca4">2023.findings-emnlp.771</url>
      <bibkey>huang-etal-2023-frustratingly</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.771</doi>
    </paper>
    <paper id="772">
      <title>Asking Clarification Questions to Handle Ambiguity in Open-Domain <fixed-case>QA</fixed-case></title>
      <author><first>Dongryeol</first><last>Lee</last></author>
      <author><first>Segwang</first><last>Kim</last></author>
      <author><first>Minwoo</first><last>Lee</last></author>
      <author><first>Hwanhee</first><last>Lee</last></author>
      <author><first>Joonsuk</first><last>Park</last></author>
      <author><first>Sang-Woo</first><last>Lee</last></author>
      <author><first>Kyomin</first><last>Jung</last></author>
      <pages>11526-11544</pages>
      <abstract>Ambiguous questions persist in open-domain question answering, because formulating a precise question with a unique answer is often challenging. Previous works have tackled this issue by asking disambiguated questions for all possible interpretations of the ambiguous question. Instead, we propose to ask a clarification question, where the user’s response will help identify the interpretation that best aligns with the user’s intention. We first present CAmbigNQ, a dataset consisting of 5,653 ambiguous questions, each with relevant passages, possible answers, and a clarification question. The clarification questions were efficiently created by generating them using InstructGPT and manually revising them as necessary. We then define a pipeline of three tasks—(1) ambiguity detection, (2) clarification question generation, and (3) clarification-based QA. In the process, we adopt or design appropriate evaluation metrics to facilitate sound research. Lastly, we achieve F1 of 61.3, 25.1, and 40.5 on the three tasks, demonstrating the need for further improvements while providing competitive baselines for future work.</abstract>
      <url hash="aa265cf1">2023.findings-emnlp.772</url>
      <bibkey>lee-etal-2023-asking</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.772</doi>
    </paper>
    <paper id="773">
      <title>Addressing the Length Bias Challenge in Document-Level Neural Machine Translation</title>
      <author><first>Zhang</first><last>Zhuocheng</last></author>
      <author><first>Shuhao</first><last>Gu</last></author>
      <author><first>Min</first><last>Zhang</last></author>
      <author><first>Yang</first><last>Feng</last></author>
      <pages>11545-11556</pages>
      <abstract>Document-level neural machine translation (DNMT) has shown promising results by incorporating context information through increased maximum lengths of source and target sentences. However, this approach also introduces a length bias problem, whereby DNMT suffers from significant translation quality degradation when decoding sentences that are much shorter or longer than the maximum sentence length during training, i.e., the length bias problem. To prevent the model from neglecting shorter sentences, we sample the training data to ensure a more uniform distribution across different sentence lengths while progressively increasing the maximum sentence length during training. Additionally, we introduce a length-normalized attention mechanism to aid the model in focusing on target information, mitigating the issue of attention divergence when processing longer sentences. Furthermore, during the decoding stage of DNMT, we propose a sliding decoding strategy that limits the length of target sentences to not exceed the maximum length encountered during training. The experimental results indicate that our method can achieve state-of-the-art results on several open datasets, and further analysis shows that our method can significantly alleviate the length bias problem.</abstract>
      <url hash="95b056da">2023.findings-emnlp.773</url>
      <bibkey>zhuocheng-etal-2023-addressing</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.773</doi>
    </paper>
    <paper id="774">
      <title><fixed-case>E</fixed-case>con<fixed-case>BERT</fixed-case>a: Towards Robust Extraction of Named Entities in Economics</title>
      <author><first>Karim</first><last>Lasri</last></author>
      <author><first>Pedro Vitor Quinta</first><last>de Castro</last></author>
      <author><first>Mona</first><last>Schirmer</last></author>
      <author><first>Luis Eduardo</first><last>San Martin</last></author>
      <author><first>Linxi</first><last>Wang</last></author>
      <author><first>Tomáš</first><last>Dulka</last></author>
      <author><first>Haaya</first><last>Naushan</last></author>
      <author><first>John</first><last>Pougué-Biyong</last></author>
      <author><first>Arianna</first><last>Legovini</last></author>
      <author><first>Samuel</first><last>Fraiberger</last></author>
      <pages>11557-11577</pages>
      <abstract>Adapting general-purpose language models has proven to be effective in tackling downstream tasks within specific domains. In this paper, we address the task of extracting entities from the economics literature on impact evaluation. To this end, we release EconBERTa, a large language model pretrained on scientific publications in economics, and ECON-IE, a new expert-annotated dataset of economics abstracts for Named Entity Recognition (NER). We find that EconBERTa reaches state-of-the-art performance on our downstream NER task. Additionally, we extensively analyze the model’s generalization capacities, finding that most errors correspond to detecting only a subspan of an entity or failure to extrapolate to longer sequences. This limitation is primarily due to an inability to detect part-of-speech sequences unseen during training, and this effect diminishes when the number of unique instances in the training set increases. Examining the generalization abilities of domain-specific language models paves the way towards improving the robustness of NER models for causal knowledge extraction.</abstract>
      <url hash="1d44ddcc">2023.findings-emnlp.774</url>
      <bibkey>lasri-etal-2023-econberta</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.774</doi>
    </paper>
    <paper id="775">
      <title>Consonant is all you need: a compact representation of <fixed-case>E</fixed-case>nglish text for efficient <fixed-case>NLP</fixed-case></title>
      <author><first>Maged</first><last>Al-shaibani</last></author>
      <author><first>Irfan</first><last>Ahmad</last></author>
      <pages>11578-11588</pages>
      <abstract>In natural language processing (NLP), the representation of text plays a crucial role in various tasks such as language modeling, sentiment analysis, and machine translation. The standard approach is to represent text in the same way as we, as humans, read and write. In this paper, we propose a novel approach to represent text with only consonants which presents a compact representation of English text that offers improved efficiency without sacrificing performance. We exploit the fact that consonants are more discriminative than vowels and by representing text using consonants, we can significantly reduce the overall memory and compute footprint required for storing and processing textual data. We present two alternative representations: ‘consonants-only’, where we completely remove the vowels from the text, and ‘masked-vowels’, where we mask all the vowels into one special symbol. To evaluate our approaches, we conducted experiments on various NLP tasks, including text classification, part-of-speech (POS) tagging, named-entity recognition (NER), and neural machine translation (NMT), in addition to language modeling. Our results demonstrate that the proposed consonant-based representation achieves comparable performance compared to the standard text representation while requiring significantly fewer computational resources. Furthermore, we show that our representation can be seamlessly integrated with existing NLP models and frameworks, providing a practical solution for efficient text processing. Last but not the least, we present a technique to retrieve the vowel information from our processed text representation keeping in mind the need to reproduce text in human readable form in some NLP applications.</abstract>
      <url hash="9734125b">2023.findings-emnlp.775</url>
      <bibkey>al-shaibani-ahmad-2023-consonant</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.775</doi>
    </paper>
    <paper id="776">
      <title>Detrimental Contexts in Open-Domain Question Answering</title>
      <author><first>Philhoon</first><last>Oh</last></author>
      <author><first>James</first><last>Thorne</last></author>
      <pages>11589-11605</pages>
      <abstract>For knowledge intensive NLP tasks, it has been widely accepted that accessing more information is a contributing factor to improvements in the model’s end-to-end performance. However, counter-intuitively, too much context can have a negative impact on the model when evaluated on common question answering (QA) datasets. In this paper, we analyze how passages can have a detrimental effect on retrieve-then-read architectures used in question answering. Our empirical evidence indicates that the current read architecture does not fully leverage the retrieved passages and significantly degrades its performance when using the whole passages compared to utilizing subsets of them. Our findings demonstrate that model accuracy can be improved by 10% on two popular QA datasets by filtering out detrimental passages. Additionally, these outcomes are attained by utilizing existing retrieval methods without further training or data. We further highlight the challenges associated with identifying the detrimental passages. First, even with the correct context, the model can make an incorrect prediction, posing a challenge in determining which passages are most influential. Second, evaluation typically considers lexical matching, which is not robust to variations of correct answers. Despite these limitations, our experimental results underscore the pivotal role of identifying and removing these detrimental passages for the context-efficient retrieve-then-read pipeline.</abstract>
      <url hash="10b66fb1">2023.findings-emnlp.776</url>
      <bibkey>oh-thorne-2023-detrimental</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.776</doi>
    </paper>
    <paper id="777">
      <title><fixed-case>PMI</fixed-case>ndia<fixed-case>S</fixed-case>um: Multilingual and Cross-lingual Headline Summarization for Languages in <fixed-case>I</fixed-case>ndia</title>
      <author><first>Ashok</first><last>Urlana</last></author>
      <author><first>Pinzhen</first><last>Chen</last></author>
      <author><first>Zheng</first><last>Zhao</last></author>
      <author><first>Shay</first><last>Cohen</last></author>
      <author><first>Manish</first><last>Shrivastava</last></author>
      <author><first>Barry</first><last>Haddow</last></author>
      <pages>11606-11628</pages>
      <abstract>This paper introduces PMIndiaSum, a multilingual and massively parallel summarization corpus focused on languages in India. Our corpus provides a training and testing ground for four language families, 14 languages, and the largest to date with 196 language pairs. We detail our construction workflow including data acquisition, processing, and quality assurance. Furthermore, we publish benchmarks for monolingual, cross-lingual, and multilingual summarization by fine-tuning, prompting, as well as translate-and-summarize. Experimental results confirm the crucial role of our data in aiding summarization between Indian languages. Our dataset is publicly available and can be freely modified and re-distributed.</abstract>
      <url hash="a42d8bfb">2023.findings-emnlp.777</url>
      <bibkey>urlana-etal-2023-pmindiasum</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.777</doi>
    </paper>
    <paper id="778">
      <title>Beyond Labels: Empowering Human Annotators with Natural Language Explanations through a Novel Active-Learning Architecture</title>
      <author><first>Bingsheng</first><last>Yao</last></author>
      <author><first>Ishan</first><last>Jindal</last></author>
      <author><first>Lucian</first><last>Popa</last></author>
      <author><first>Yannis</first><last>Katsis</last></author>
      <author><first>Sayan</first><last>Ghosh</last></author>
      <author><first>Lihong</first><last>He</last></author>
      <author><first>Yuxuan</first><last>Lu</last></author>
      <author><first>Shashank</first><last>Srivastava</last></author>
      <author><first>Yunyao</first><last>Li</last></author>
      <author><first>James</first><last>Hendler</last></author>
      <author><first>Dakuo</first><last>Wang</last></author>
      <pages>11629-11643</pages>
      <abstract>Real-world domain experts (e.g., doctors) rarely annotate only a decision label in their day-to-day workflow without providing explanations. Yet, existing low-resource learning techniques, such as Active Learning (AL), that aim to support human annotators mostly focus on the label while neglecting the natural language explanation of a data point. This work proposes a novel AL architecture to support experts’ real-world need for label and explanation annotations in low-resource scenarios. Our AL architecture leverages an explanation-generation model to produce explanations guided by human explanations, a prediction model that utilizes generated explanations toward prediction faithfully, and a novel data diversity-based AL sampling strategy that benefits from the explanation annotations. Automated and human evaluations demonstrate the effectiveness of incorporating explanations into AL sampling and the improved human annotation efficiency and trustworthiness with our AL architecture. Additional ablation studies illustrate the potential of our AL architecture for transfer learning, generalizability, and integration with large language models (LLMs). While LLMs exhibit exceptional explanation-generation capabilities for relatively simple tasks, their effectiveness in complex real-world tasks warrants further in-depth study.</abstract>
      <url hash="f820b3e4">2023.findings-emnlp.778</url>
      <bibkey>yao-etal-2023-beyond</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.778</doi>
    </paper>
    <paper id="779">
      <title>Decoding Stumpers: Large Language Models vs. Human Problem-Solvers</title>
      <author><first>Alon</first><last>Goldstein</last></author>
      <author><first>Miriam</first><last>Havin</last></author>
      <author><first>Roi</first><last>Reichart</last></author>
      <author><first>Ariel</first><last>Goldstein</last></author>
      <pages>11644-11653</pages>
      <abstract>This paper investigates the problem-solving capabilities of Large Language Models (LLMs) by evaluating their performance on stumpers, unique single-step intuition problems that pose challenges for human solvers but are easily verifiable. We compare the performance of four state-of-the-art LLMs (Davinci-2, Davinci-3, GPT-3.5-Turbo, GPT-4) to human participants. Our findings reveal that the new-generation LLMs excel in solving stumpers and surpass human performance. However, humans exhibit superior skills in verifying solutions to the same problems. This research enhances our understanding of LLMs’ cognitive abilities and provides insights for enhancing their problem-solving potential across various domains.</abstract>
      <url hash="9b5394a6">2023.findings-emnlp.779</url>
      <bibkey>goldstein-etal-2023-decoding</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.779</doi>
    </paper>
    <paper id="780">
      <title>Efficient Cross-Task Prompt Tuning for Few-Shot Conversational Emotion Recognition</title>
      <author><first>Yige</first><last>Xu</last></author>
      <author><first>Zhiwei</first><last>Zeng</last></author>
      <author><first>Zhiqi</first><last>Shen</last></author>
      <pages>11654-11666</pages>
      <abstract>Emotion Recognition in Conversation (ERC) has been widely studied due to its importance in developing emotion-aware empathetic machines. The rise of pre-trained language models (PLMs) has further pushed the limit of ERC performance. However, most recent works on ERC using PLMs are heavily data-driven, and requires fine-tuning the entire PLMs. To improve both sample and computational efficiency, we propose a derivative-free optimization method called Cross-Task Prompt Tuning (CTPT) for few-shot conversational emotion recognition. Unlike existing methods that learn independent knowledge from individual tasks, CTPT leverages sharable cross-task knowledge by exploiting external knowledge from other source tasks to improve learning performance under the few-shot setting. Moreover, CTPT only needs to optimize a vector under the low intrinsic dimensionality without gradient, which is highly parameter-efficient compared with existing approaches. Experiments on five different contextual conversation datasets demonstrate that our CTPT method has superior results on both few-shot scenarios and zero-shot transfers.</abstract>
      <url hash="dc652b57">2023.findings-emnlp.780</url>
      <bibkey>xu-etal-2023-efficient</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.780</doi>
    </paper>
    <paper id="781">
      <title><fixed-case>SYMPTOMIFY</fixed-case>: Transforming Symptom Annotations with Language Model Knowledge Harvesting</title>
      <author><first>Bosung</first><last>Kim</last></author>
      <author><first>Ndapa</first><last>Nakashole</last></author>
      <pages>11667-11681</pages>
      <abstract>Given the high-stakes nature of healthcare decision-making, we aim to improve the efficiency of human annotators rather than replacing them with fully automated solutions. We introduce a new comprehensive resource, SYMPTOMIFY, a dataset of annotated vaccine adverse reaction reports detailing individual vaccine reactions. The dataset, consisting of over 800k reports, surpasses previous datasets in size. Notably, it features reasoning-based explanations alongside background knowledge obtained via language model knowledge harvesting. We evaluate performance across various methods and learning paradigms, paving the way for future comparisons and benchmarking.</abstract>
      <url hash="2cd013cd">2023.findings-emnlp.781</url>
      <bibkey>kim-nakashole-2023-symptomify</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.781</doi>
    </paper>
    <paper id="782">
      <title><fixed-case>T</fixed-case>oken<fixed-case>D</fixed-case>rop + <fixed-case>B</fixed-case>ucket<fixed-case>S</fixed-case>ampler: Towards Efficient Padding-free Fine-tuning of Language Models</title>
      <author><first>Amrit</first><last>Nagarajan</last></author>
      <author><first>Anand</first><last>Raghunathan</last></author>
      <pages>11682-11695</pages>
      <abstract>The great success of Language Models (LMs) for various Natural Language Processing (NLP) tasks is accompanied by computational challenges during both pre-training and fine-tuning. Pre-training has attracted significant attention due to its huge computational footprint. We focus on the fine-tuning of pre-trained LMs, which is expected to be performed much more frequently as the pre-trained models are adapted to downstream tasks. During fine-tuning, the presence of variable-length input sequences necessitates the use of padding tokens when batching sequences. These padding tokens lead to ineffectual computations, adversely impacting the efficiency of fine-tuning. We also observe that LMs memorize the limited task-specific training data despite the use of known regularization methods. Based on these insights, we present TokenDrop + BucketSampler, a framework that simultaneously improves efficiency and accuracy of LM fine-tuning. BucketSampler generates batches of samples with lower variance in sequence lengths to reduce the number of padding tokens, but does so without the accompanying accuracy drop seen in previous approaches. TokenDrop is a new regularizer that prunes a random subset of insignificant tokens from each input sequence in every epoch to prevent overfitting. TokenDrop drops more tokens from the longer sequences in each batch to further reduce variance in input lengths and the need for padding. TokenDrop + BucketSampler accelerates fine-tuning on diverse downstream tasks by up to 10.61X, while also producing models that are up to 1.17% more accurate compared to conventional fine-tuning. Code is available at https://github.com/amrnag/TokenDrop-BucketSampler. .</abstract>
      <url hash="f36e6a34">2023.findings-emnlp.782</url>
      <bibkey>nagarajan-raghunathan-2023-tokendrop</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.782</doi>
    </paper>
    <paper id="783">
      <title>Unified Representation for Non-compositional and Compositional Expressions</title>
      <author><first>Ziheng</first><last>Zeng</last></author>
      <author><first>Suma</first><last>Bhat</last></author>
      <pages>11696-11710</pages>
      <abstract>Accurate processing of non-compositional language relies on generating good representations for such expressions. In this work, we study the representation of language non-compositionality by proposing a language model, PIER+, that builds on BART and can create semantically meaningful and contextually appropriate representations for English potentially idiomatic expressions (PIEs). PIEs are characterized by their non-compositionality and contextual ambiguity in their literal and idiomatic interpretations. Via intrinsic evaluation on embedding quality and extrinsic evaluation on PIE processing and NLU tasks, we show that representations generated by PIER+ result in 33% higher homogeneity score for embedding clustering than BART, whereas 3.12% and 3.29% gains in accuracy and sequence accuracy for PIE sense classification and span detection compared to the state-of-the-art IE representation model, GIEA. These gains are achieved without sacrificing PIER+’s performance on NLU tasks (+/- 1% accuracy) compared to BART.</abstract>
      <url hash="771e9195">2023.findings-emnlp.783</url>
      <bibkey>zeng-bhat-2023-unified</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.783</doi>
    </paper>
    <paper id="784">
      <title>Context Quality Matters in Training Fusion-in-Decoder for Extractive Open-Domain Question Answering</title>
      <author><first>Kosuke</first><last>Akimoto</last></author>
      <author><first>Kunihiro</first><last>Takeoka</last></author>
      <author><first>Masafumi</first><last>Oyamada</last></author>
      <pages>11711-11729</pages>
      <abstract>Retrieval-augmented generation models augment knowledge encoded in a language model by providing additional relevant external knowledge (context) during generation. Although it has been shown that the quantity and quality of context impact the performance of retrieval-augmented generation models during inference, limited research explores how these characteristics affect model training. This paper explores how context quantity and quality during model training affect the performance of Fusion-in-Decoder (FiD), the state-of-the-art retrieval-augmented generation model, in extractive open-domain question answering tasks. Experimental results suggest that FiD models overfit to context quality during training and show suboptimal performance when evaluated on different context quality. Through the experimental results, we also reveal FiD models trained with different context quality have different cross-attention distribution patterns. Specifically, as context quality during training increases, FiD models tend to attend more uniformly to each passage in context. Finally, based on these observations, we propose a method to mitigate overfitting to specific context quality by introducing bias to the cross-attention distribution, which we demonstrate to be effective in improving the performance of FiD models on different context quality.</abstract>
      <url hash="987e4dac">2023.findings-emnlp.784</url>
      <bibkey>akimoto-etal-2023-context</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.784</doi>
    </paper>
    <paper id="785">
      <title>Error Detection for Text-to-<fixed-case>SQL</fixed-case> Semantic Parsing</title>
      <author><first>Shijie</first><last>Chen</last></author>
      <author><first>Ziru</first><last>Chen</last></author>
      <author><first>Huan</first><last>Sun</last></author>
      <author><first>Yu</first><last>Su</last></author>
      <pages>11730-11743</pages>
      <abstract>Despite remarkable progress in text-to-SQL semantic parsing in recent years, the performance of existing parsers is still far from perfect. Specifically, modern text-to-SQL parsers based on deep learning are often over-confident, thus casting doubt on their trustworthiness when deployed for real use. In this paper, we propose a parser-independent error detection model for text-to-SQL semantic parsing. Using a language model of code as its bedrock, we enhance our error detection model with graph neural networks that learn structural features of both natural language questions and SQL queries. We train our model on realistic parsing errors collected from a cross-domain setting, which leads to stronger generalization ability. Experiments with three strong text-to-SQL parsers featuring different decoding mechanisms show that our approach outperforms parser-dependent uncertainty metrics. Our model could also effectively improve the performance and usability of text-to-SQL semantic parsers regardless of their architectures.</abstract>
      <url hash="bab155a0">2023.findings-emnlp.785</url>
      <bibkey>chen-etal-2023-error</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.785</doi>
    </paper>
    <paper id="786">
      <title>Ultra-Fine Entity Typing with Prior Knowledge about Labels: A Simple Clustering Based Strategy</title>
      <author><first>Na</first><last>Li</last></author>
      <author><first>Zied</first><last>Bouraoui</last></author>
      <author><first>Steven</first><last>Schockaert</last></author>
      <pages>11744-11756</pages>
      <abstract>Ultra-fine entity typing (UFET) is the task of inferring the semantic types from a large set of fine-grained candidates that apply to a given entity mention. This task is especially challenging because we only have a small number of training examples for many types, even with distant supervision strategies. State-of-the-art models, therefore, have to rely on prior knowledge about the type labels in some way. In this paper, we show that the performance of existing methods can be improved using a simple technique: we use pre-trained label embeddings to cluster the labels into semantic domains and then treat these domains as additional types. We show that this strategy consistently leads to improved results as long as high-quality label embeddings are used. Furthermore, we use the label clusters as part of a simple post-processing technique, which results in further performance gains. Both strategies treat the UFET model as a black box and can thus straightforwardly be used to improve a wide range of existing models.</abstract>
      <url hash="3a0cc9d4">2023.findings-emnlp.786</url>
      <bibkey>li-etal-2023-ultra</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.786</doi>
    </paper>
    <paper id="787">
      <title>Multilingual Coarse Political Stance Classification of Media. The Editorial Line of a <fixed-case>C</fixed-case>hat<fixed-case>GPT</fixed-case> and Bard Newspaper</title>
      <author><first>Cristina</first><last>España-Bonet</last></author>
      <pages>11757-11777</pages>
      <abstract>Neutrality is difficult to achieve and, in politics, subjective. Traditional media typically adopt an editorial line that can be used by their potential readers as an indicator of the media bias. Several platforms currently rate news outlets according to their political bias. The editorial line and the ratings help readers in gathering a balanced view of news. But in the advent of instruction-following language models, tasks such as writing a newspaper article can be delegated to computers. Without imposing a biased persona, where would an AI-based news outlet lie within the bias ratings? In this work, we use the ratings of authentic news outlets to create a multilingual corpus of news with coarse stance annotations (Left and Right) along with automatically extracted topic annotations. We show that classifiers trained on this data are able to identify the editorial line of most unseen newspapers in English, German, Spanish and Catalan. We then apply the classifiers to 101 newspaper-like articles written by ChatGPT and Bard in the 4 languages at different time periods. We observe that, similarly to traditional newspapers, ChatGPT editorial line evolves with time and, being a data-driven system, the stance of the generated articles differs among languages.</abstract>
      <url hash="7848392b">2023.findings-emnlp.787</url>
      <bibkey>espana-bonet-2023-multilingual</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.787</doi>
    </paper>
    <paper id="788">
      <title>Do “<fixed-case>E</fixed-case>nglish” Named Entity Recognizers Work Well on Global Englishes?</title>
      <author><first>Alexander</first><last>Shan</last></author>
      <author><first>John</first><last>Bauer</last></author>
      <author><first>Riley</first><last>Carlson</last></author>
      <author><first>Christopher</first><last>Manning</last></author>
      <pages>11778-11791</pages>
      <abstract>The vast majority of the popular English named entity recognition (NER) datasets contain American or British English data, despite the existence of many global varieties of English. As such, it is unclear whether they generalize for analyzing use of English globally. To test this, we build a newswire dataset, the Worldwide English NER Dataset, to analyze NER model performance on low-resource English variants from around the world. We test widely used NER toolkits and transformer models, including models using the pre-trained contextual models RoBERTa and ELECTRA, on three datasets: a commonly used British English newswire dataset, CoNLL 2003, a more American focused dataset OntoNotes, and our global dataset. All models trained on the CoNLL or OntoNotes datasets experienced significant performance drops—over 10 F1 in some cases—when tested on the Worldwide English dataset. Upon examination of region-specific errors, we observe the greatest performance drops for Oceania and Africa, while Asia and the Middle East had comparatively strong performance. Lastly, we find that a combined model trained on the Worldwide dataset and either CoNLL or OntoNotes lost only 1-2 F1 on both test sets.</abstract>
      <url hash="7f4928d2">2023.findings-emnlp.788</url>
      <bibkey>shan-etal-2023-english</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.788</doi>
    </paper>
    <paper id="789">
      <title>Affective and Dynamic Beam Search for Story Generation</title>
      <author><first>Tenghao</first><last>Huang</last></author>
      <author><first>Ehsan</first><last>Qasemi</last></author>
      <author><first>Bangzheng</first><last>Li</last></author>
      <author><first>He</first><last>Wang</last></author>
      <author><first>Faeze</first><last>Brahman</last></author>
      <author><first>Muhao</first><last>Chen</last></author>
      <author><first>Snigdha</first><last>Chaturvedi</last></author>
      <pages>11792-11806</pages>
      <abstract>Storytelling’s captivating potential makes it a fascinating research area, with implications for entertainment, education, therapy, and cognitive studies. In this paper, we propose Affective Story Generator (AffGen) for generating interesting narratives. AffGen introduces ‘intriguing twists’ in narratives by employing two novel techniques—Dynamic Beam Sizing and Affective Reranking. Dynamic Beam Sizing encourages less predictable, more captivating word choices using a contextual multi-arm bandit model. Affective Reranking prioritizes sentence candidates based on affect intensity. Our empirical evaluations, both automatic and human, demonstrate AffGen’s superior performance over existing baselines in generating affectively charged and interesting narratives. Our ablation study and analysis provide insights into the strengths and weaknesses of AffGen.</abstract>
      <url hash="bc420209">2023.findings-emnlp.789</url>
      <bibkey>huang-etal-2023-affective</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.789</doi>
    </paper>
    <paper id="790">
      <title>Multiview Clickbait Detection via Jointly Modeling Subjective and Objective Preference</title>
      <author><first>Chongyang</first><last>Shi</last></author>
      <author><first>Yijun</first><last>Yin</last></author>
      <author><first>Qi</first><last>Zhang</last></author>
      <author><first>Liang</first><last>Xiao</last></author>
      <author><first>Usman</first><last>Naseem</last></author>
      <author><first>Shoujin</first><last>Wang</last></author>
      <author><first>Liang</first><last>Hu</last></author>
      <pages>11807-11816</pages>
      <abstract>Clickbait posts tend to spread inaccurate or misleading information to manipulate people’s attention and emotions, which greatly harms the credibility of social media. Existing clickbait detection models rely on analyzing the objective semantics in posts or correlating posts with article content only. However, these models fail to identify and exploit the manipulation intention of clickbait from a user’s subjective perspective, leading to limited capability to explore comprehensive clues of clickbait. To address such a issue, we propose a multiview clickbait detection model, named MCDM, to model subjective and objective preferences simultaneously. MCDM introduces two novel complementary modules for modeling subjective feeling and objective content relevance, respectively. The subjective feeling module adopts a user-centric approach to capture subjective features of posts, such as language patterns and emotional inclinations. The objective module explores news elements from posts and models article content correlations to capture objective clues for clickbait detection. Extensive experimental results on two real-world datasets show that our proposed MCDM outperforms state-of-the-art approaches for clickbait detection, verifying the effectiveness of integrating subjective and objective preferences for detecting clickbait.</abstract>
      <url hash="b9ed0511">2023.findings-emnlp.790</url>
      <bibkey>shi-etal-2023-multiview</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.790</doi>
    </paper>
    <paper id="791">
      <title>Let’s Synthesize Step by Step: Iterative Dataset Synthesis with Large Language Models by Extrapolating Errors from Small Models</title>
      <author><first>Ruida</first><last>Wang</last></author>
      <author><first>Wangchunshu</first><last>Zhou</last></author>
      <author><first>Mrinmaya</first><last>Sachan</last></author>
      <pages>11817-11831</pages>
      <abstract>*Data Synthesis* is a promising way to train a small model with very little labeled data. One approach for data synthesis is to leverage the rich knowledge from large language models to synthesize pseudo training examples for small models, making it possible to achieve both data and compute efficiency at the same time. However, a key challenge in data synthesis is that the synthesized dataset often suffers from a large distributional discrepancy from the *real task* data distribution. Thus, in this paper, we propose *Synthesis Step by Step* (**S3**), a data synthesis framework that shrinks this distribution gap by iteratively extrapolating the errors made by a small model trained on the synthesized dataset on a small real-world validation dataset using a large language model. Extensive experiments on multiple NLP tasks show that our approach improves the performance of a small model by reducing the gap between the synthetic dataset and the real data, resulting in significant improvement compared to several baselines: 9.48% improvement compared to ZeroGen and 2.73% compared to GoldGen, and at most 15.17% improvement compared to the small model trained on human-annotated data.</abstract>
      <url hash="9d467228">2023.findings-emnlp.791</url>
      <bibkey>wang-etal-2023-lets</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.791</doi>
    </paper>
    <paper id="792">
      <title>Identifying <fixed-case>Early Maladaptive Schemas</fixed-case> from Mental Health Question Texts</title>
      <author><first>Sujatha</first><last>Gollapalli</last></author>
      <author><first>Beng</first><last>Ang</last></author>
      <author><first>See-Kiong</first><last>Ng</last></author>
      <pages>11832-11843</pages>
      <abstract>In Psychotherapy, maladaptive schemas– negative perceptions that an individual has of the self, others, or the world that endure despite objective reality–often lead to resistance to treatments and relapse of mental health issues such as depression, anxiety, panic attacks etc. Identification of early maladaptive schemas (EMS) is thus a crucial step during Schema Therapy-based counseling sessions, where patients go through a detailed and lengthy EMS questionnaire. However, such an approach is not practical in ‘offline’ counseling scenarios, such as community QA forums which are gaining popularity for people seeking mental health support. In this paper, we investigate both LLM (Large Language Models) and non-LLM approaches for identifying EMS labels using resources from Schema Therapy. Our evaluation indicates that recent LLMs can be effective for identifying EMS but their predictions lack explainability and are too sensitive to precise ‘prompts’. Both LLM and non-LLM methods are unable to reliably address the null cases, i.e. cases with no EMS labels. However, we posit that the two approaches show complementary properties and together, they can be used to further devise techniques for EMS identification.</abstract>
      <url hash="e247edb0">2023.findings-emnlp.792</url>
      <bibkey>gollapalli-etal-2023-identifying</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.792</doi>
    </paper>
    <paper id="793">
      <title>Re-<fixed-case>V</fixed-case>i<fixed-case>LM</fixed-case>: Retrieval-Augmented Visual Language Model for Zero and Few-Shot Image Captioning</title>
      <author><first>Zhuolin</first><last>Yang</last></author>
      <author><first>Wei</first><last>Ping</last></author>
      <author><first>Zihan</first><last>Liu</last></author>
      <author><first>Vijay</first><last>Korthikanti</last></author>
      <author><first>Weili</first><last>Nie</last></author>
      <author><first>De-An</first><last>Huang</last></author>
      <author><first>Linxi</first><last>Fan</last></author>
      <author><first>Zhiding</first><last>Yu</last></author>
      <author><first>Shiyi</first><last>Lan</last></author>
      <author id="bo-li"><first>Bo</first><last>Li</last></author>
      <author><first>Mohammad</first><last>Shoeybi</last></author>
      <author><first>Ming-Yu</first><last>Liu</last></author>
      <author><first>Yuke</first><last>Zhu</last></author>
      <author><first>Bryan</first><last>Catanzaro</last></author>
      <author><first>Chaowei</first><last>Xiao</last></author>
      <author><first>Anima</first><last>Anandkumar</last></author>
      <pages>11844-11857</pages>
      <abstract>Augmenting pretrained language models (LMs) with a vision encoder (e.g., Flamingo) has obtained state-of-the-art results in image-to-text generation. However, these models store all the knowledge within their parameters, thus often requiring enormous model parameters to model the abundant visual concepts and very rich text descriptions. Additionally, they are inefficient in incorporating new data, requiring a computational-expensive fine-tuning process. In this work, we introduce a Retrieval-augmented Visual Language Model, Re-ViLM, built upon the Flamingo, that supports retrieving the relevant knowledge from the external database for zero and in-context few-shot image-to-text generations. By storing certain knowledge explicitly in the external database, our approach reduces the number of model parameters and can easily accommodate new data during evaluation by simply updating the database. We also construct an interleaved image and text data that facilitates in-context few-shot learning capabilities.We demonstrate that Re-ViLM significantly boosts performance for image-to-text generation tasks, especially for zero-shot and few-shot generation in out-of-domain settings with 4x less parameters compared with baseline methods.</abstract>
      <url hash="7104755c">2023.findings-emnlp.793</url>
      <bibkey>yang-etal-2023-vilm</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.793</doi>
    </paper>
    <paper id="794">
      <title>Syntax Matters: Towards Spoken Language Understanding via Syntax-Aware Attention</title>
      <author><first>Yifeng</first><last>Xie</last></author>
      <author><first>Zhihong</first><last>Zhu</last></author>
      <author><first>Xuxin</first><last>Cheng</last></author>
      <author><first>Zhiqi</first><last>Huang</last></author>
      <author><first>Dongsheng</first><last>Chen</last></author>
      <pages>11858-11864</pages>
      <abstract>Spoken Language Understanding (SLU), a crucial component of task-oriented dialogue systems, has consistently garnered attention from both academic and industrial communities. Although incorporating syntactic information into models has the potential to enhance the comprehension of user utterances and yield impressive results, its application in SLU systems remains largely unexplored. In this paper, we propose a carefully designed model termed Syntax-aware attention (SAT) to enhance SLU, where attention scopes are constrained based on relationships within the syntactic structure. Experimental results on three datasets show that our model achieves substantial improvements and excellent performance. Moreover, SAT can be integrated into other BERT-based language models to further boost their performance.</abstract>
      <url hash="1922ed70">2023.findings-emnlp.794</url>
      <bibkey>xie-etal-2023-syntax</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.794</doi>
    </paper>
    <paper id="795">
      <title>Can <fixed-case>C</fixed-case>hat<fixed-case>GPT</fixed-case> Defend its Belief in Truth? Evaluating <fixed-case>LLM</fixed-case> Reasoning via Debate</title>
      <author><first>Boshi</first><last>Wang</last></author>
      <author><first>Xiang</first><last>Yue</last></author>
      <author><first>Huan</first><last>Sun</last></author>
      <pages>11865-11881</pages>
      <abstract>Large language models (LLMs) such as ChatGPT and GPT-4 have shown impressive performance in complex reasoning tasks. However, it is difficult to know whether the models are reasoning based on deep understandings of truth and logic, or leveraging their memorized patterns in a relatively superficial way. In this work, we explore testing LLMs’ reasoning by engaging with them in a debate-like conversation, where given a question, the LLM and the user need to discuss to make the correct decision starting from opposing arguments. Upon mitigating the Clever Hans effect, our task requires the LLM to not only achieve the correct answer on its own, but also be able to hold and defend its belief instead of blindly believing or getting misled by the user’s (invalid) arguments and critiques, thus testing in greater depth whether the LLM grasps the essence of the reasoning required to solve the problem. Across a range of complex reasoning benchmarks spanning math, commonsense, logic and BIG-Bench tasks, we find that despite their impressive performance as reported in existing work on generating correct step-by-step solutions in the beginning, LLMs like ChatGPT cannot maintain their beliefs in truth for a significant portion of examples when challenged by oftentimes absurdly invalid arguments. Our work points to danger zones of model alignment, and also suggests more careful treatments and interpretations of the recent findings that LLMs can improve their responses based on feedback.</abstract>
      <url hash="6f2839a7">2023.findings-emnlp.795</url>
      <bibkey>wang-etal-2023-chatgpt-defend</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.795</doi>
    </paper>
    <paper id="796">
      <title>Using In-Context Learning to Improve Dialogue Safety</title>
      <author><first>Nicholas</first><last>Meade</last></author>
      <author><first>Spandana</first><last>Gella</last></author>
      <author><first>Devamanyu</first><last>Hazarika</last></author>
      <author><first>Prakhar</first><last>Gupta</last></author>
      <author><first>Di</first><last>Jin</last></author>
      <author><first>Siva</first><last>Reddy</last></author>
      <author id="yang-liu"><first>Yang</first><last>Liu</last></author>
      <author><first>Dilek</first><last>Hakkani-Tur</last></author>
      <pages>11882-11910</pages>
      <abstract>While large neural-based conversational models have become increasingly proficient dialogue agents, recent work has highlighted safety issues with these systems. For example, these systems can be goaded into generating toxic content, often perpetuating social biases or stereotypes. We investigate a retrieval-based approach for reducing bias and toxicity in responses from chatbots. It uses in-context learning to steer a model towards safer generations. Concretely, to generate a response to an unsafe dialogue context, we retrieve demonstrations of safe responses to similar dialogue contexts. We find our method performs competitively with existing approaches to dialogue safety without requiring training. We also show, using automatic and human evaluation, that reductions in toxicity obtained using our approach are not at the cost engagingness or coherency. Finally, we note our method can be used in compliment to existing dialogue safety approaches, such as RLHF.</abstract>
      <url hash="331bf588">2023.findings-emnlp.796</url>
      <bibkey>meade-etal-2023-using</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.796</doi>
    </paper>
    <paper id="797">
      <title><fixed-case>HEAR</fixed-case>: Hearing Enhanced Audio Response for Video-grounded Dialogue</title>
      <author><first>Sunjae</first><last>Yoon</last></author>
      <author><first>Dahyun</first><last>Kim</last></author>
      <author><first>Eunseop</first><last>Yoon</last></author>
      <author><first>Hee</first><last>Yoon</last></author>
      <author><first>Junyeong</first><last>Kim</last></author>
      <author><first>Chang</first><last>Yoo</last></author>
      <pages>11911-11924</pages>
      <abstract>Video-grounded Dialogue (VGD) aims to answer questions regarding a given multi-modal input comprising video, audio, and dialogue history. Although there have been numerous efforts in developing VGD systems to improve the quality of their responses, existing systems are competent only to incorporate the information in the video and text and tend to struggle in extracting the necessary information from the audio when generating appropriate responses to the question. The VGD system seems to be deaf, and thus, we coin this symptom of current systems’ ignoring audio data as a deaf response. To overcome the deaf response problem, Hearing Enhanced Audio Response (HEAR) framework is proposed to perform sensible listening by selectively attending to audio whenever the question requires it. The HEAR framework enhances the accuracy and audibility of VGD systems in a model-agnostic manner. HEAR is validated on VGD datasets (i.e., AVSD@DSTC7 and AVSD@DSTC8) and shows effectiveness with various VGD systems.</abstract>
      <url hash="e4febbf5">2023.findings-emnlp.797</url>
      <bibkey>yoon-etal-2023-hear</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.797</doi>
    </paper>
    <paper id="798">
      <title>Improving Consistency for Text Summarization with Energy Functions</title>
      <author><first>Qi</first><last>Zeng</last></author>
      <author><first>Qingyu</first><last>Yin</last></author>
      <author><first>Zheng</first><last>Li</last></author>
      <author><first>Yifan</first><last>Gao</last></author>
      <author><first>Sreyashi</first><last>Nag</last></author>
      <author><first>Zhengyang</first><last>Wang</last></author>
      <author><first>Bing</first><last>Yin</last></author>
      <author><first>Heng</first><last>Ji</last></author>
      <author><first>Chao</first><last>Zhang</last></author>
      <pages>11925-11931</pages>
      <abstract>Current abstractive summarization models often generate inconsistent content, i.e. texts that are not directly inferable from the source document, are not consistent with respect to world knowledge, or are self-contradictory. These inconsistencies motivate a new consistency taxonomy that we define as faithfulness, factuality, and self-supportiveness. However, most recent work on reducing inconsistency in document summarization only focuses on faithfulness detection and correction while ignoring other inconsistency phenomena, which limits the model’s scalability. To improve the general consistency we introduce EnergySum, where we apply the Residual Energy-based Model by designing energy scorers that reflect each type of consistency. These energy scores are utilized in candidate re-ranking during the sampling process. Experiments on XSUM and CNN/DM datasets show that EnergySum mitigates the trade-off between accuracy and consistency.</abstract>
      <url hash="34caa7f4">2023.findings-emnlp.798</url>
      <bibkey>zeng-etal-2023-improving</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.798</doi>
    </paper>
    <paper id="799">
      <title>Defining a New <fixed-case>NLP</fixed-case> Playground</title>
      <author><first>Sha</first><last>Li</last></author>
      <author><first>Chi</first><last>Han</last></author>
      <author><first>Pengfei</first><last>Yu</last></author>
      <author><first>Carl</first><last>Edwards</last></author>
      <author><first>Manling</first><last>Li</last></author>
      <author><first>Xingyao</first><last>Wang</last></author>
      <author><first>Yi</first><last>Fung</last></author>
      <author><first>Charles</first><last>Yu</last></author>
      <author><first>Joel</first><last>Tetreault</last></author>
      <author><first>Eduard</first><last>Hovy</last></author>
      <author><first>Heng</first><last>Ji</last></author>
      <pages>11932-11951</pages>
      <abstract>The recent explosion of performance of large language models (LLMs) has changed the field of Natural Language Processing (NLP) more abruptly and seismically than any other shift in the field’s 80 year history. This has resulted in concerns that the field will become homogenized and resource-intensive. This new status quo has put many academic researchers, especially PhD students, at a disadvantage. This paper aims to define a new NLP playground by proposing 20+ PhD-dissertation-worthy research directions, covering theoretical analysis, new and challenging problems, learning paradigms and interdisciplinary applications.</abstract>
      <url hash="9e6719a1">2023.findings-emnlp.799</url>
      <bibkey>li-etal-2023-defining</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.799</doi>
    </paper>
    <paper id="800">
      <title><fixed-case>UPTON</fixed-case>: Preventing Authorship Leakage from Public Text Release via Data Poisoning</title>
      <author><first>Ziyao</first><last>Wang</last></author>
      <author><first>Thai</first><last>Le</last></author>
      <author><first>Dongwon</first><last>Lee</last></author>
      <pages>11952-11965</pages>
      <abstract>Consider a scenario where an author (e.g., activist, whistle-blower) with many public writings wishes to write “anonymously” when attackers may have already built an authorship attribution (AA) model based off of public writings including those of the author. To enable her wish, we ask a question “can one make the publicly released writings, T , unattributable so that AA models trained on T cannot attribute its authorship well?” Toward this question, we present a novel solution, UPTON, that exploits black-box data poisoning methods to weaken the authorship features in training samples and make released texts unlearnable. It is different from previous obfuscation works (e.g., adversarial attacks that modify test samples or backdoor works that only change the model outputs when triggering words occur). Using four authorship datasets (IMDb10, IMDb64, Enron and WJO), we present empirical validation where UPTON successfully downgrades the accuracy of AA models to the impractical level (e.g., ~ 35%) while keeping texts still readable (e.g., &gt; 0.9 in BERTScore). UPTON remains effective to AA models that are already trained on available clean writings of authors.</abstract>
      <url hash="b27981b0">2023.findings-emnlp.800</url>
      <bibkey>wang-etal-2023-upton</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.800</doi>
    </paper>
    <paper id="801">
      <title><fixed-case>IAE</fixed-case>val: A Comprehensive Evaluation of Instance Attribution on Natural Language Understanding</title>
      <author><first>Peijian</first><last>Gu</last></author>
      <author><first>Yaozong</first><last>Shen</last></author>
      <author><first>Lijie</first><last>Wang</last></author>
      <author><first>Quan</first><last>Wang</last></author>
      <author><first>Hua</first><last>Wu</last></author>
      <author><first>Zhendong</first><last>Mao</last></author>
      <pages>11966-11977</pages>
      <abstract>Instance attribution (IA) aims to identify the training instances leading to the prediction of a test example, helping researchers understand the dataset better and optimize data processing. While many IA methods have been proposed recently, how to evaluate them still remains open. Previous evaluations of IA only focus on one or two dimensions and are not comprehensive. In this work, we introduce IAEval for IA methods, a systematic and comprehensive evaluation scheme covering four significant requirements: sufficiency, completeness, stability and plausibility. We elaborately design novel metrics to measure these requirements for the first time. Three representative IA methods are evaluated under IAEval on four natural language understanding datasets. Extensive experiments confirmed the effectiveness of IAEval and exhibited its ability to provide comprehensive comparison among IA methods. With IAEval, researchers can choose the most suitable IA methods for applications like model debugging.</abstract>
      <url hash="42b22692">2023.findings-emnlp.801</url>
      <bibkey>gu-etal-2023-iaeval</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.801</doi>
    </paper>
    <paper id="802">
      <title>Scene Graph Enhanced Pseudo-Labeling for Referring Expression Comprehension</title>
      <author><first>Cantao</first><last>Wu</last></author>
      <author><first>Yi</first><last>Cai</last></author>
      <author><first>Liuwu</first><last>Li</last></author>
      <author><first>Jiexin</first><last>Wang</last></author>
      <pages>11978-11990</pages>
      <abstract>Referring Expression Comprehension (ReC) is a task that involves localizing objects in images based on natural language expressions. Most ReC methods typically approach the task as a supervised learning problem. However, the need for costly annotations, such as clear image-text pairs or region-text pairs, hinders the scalability of existing approaches. In this work, we propose a novel scene graph-based framework that automatically generates high-quality pseudo region-query pairs. Our method harnesses scene graphs to capture the relationships between objects in images and generate expressions enriched with relation information. To ensure accurate mapping between visual regions and text, we introduce an external module that employs a calibration algorithm to filter out ambiguous queries. Additionally, we employ a rewriter module to enhance the diversity of our generated pseudo queries through rewriting. Extensive experiments demonstrate that our method outperforms previous pseudo-labeling methods by about 10%, 12%, and 11% on RefCOCO, RefCOCO+, and RefCOCOg, respectively. Furthermore, it surpasses the state-of-the-art unsupervised approach by more than 15% on the RefCOCO dataset.</abstract>
      <url hash="68ff92ee">2023.findings-emnlp.802</url>
      <bibkey>wu-etal-2023-scene</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.802</doi>
    </paper>
    <paper id="803">
      <title>Noisy Self-Training with Synthetic Queries for Dense Retrieval</title>
      <author><first>Fan</first><last>Jiang</last></author>
      <author><first>Tom</first><last>Drummond</last></author>
      <author><first>Trevor</first><last>Cohn</last></author>
      <pages>11991-12008</pages>
      <abstract>Although existing neural retrieval models reveal promising results when training data is abundant and the performance keeps improving as training data increases, collecting high-quality annotated data is prohibitively costly. To this end, we introduce a novel noisy self-training framework combined with synthetic queries, showing that neural retrievers can be improved in a self-evolution manner with no reliance on any external models. Experimental results show that our method improves consistently over existing methods on both general-domain (e.g., MS-MARCO) and out-of-domain (i.e., BEIR) retrieval benchmarks. Extra analysis on low-resource settings reveals that our method is data efficient and outperforms competitive baselines, with as little as 30% of labelled training data. Further extending the framework for reranker training demonstrates that the proposed method is general and yields additional gains on tasks of diverse domains.</abstract>
      <url hash="9dc5ce06">2023.findings-emnlp.803</url>
      <bibkey>jiang-etal-2023-noisy</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.803</doi>
    </paper>
    <paper id="804">
      <title>Leveraging <fixed-case>GPT</fixed-case>-4 for Automatic Translation Post-Editing</title>
      <author><first>Vikas</first><last>Raunak</last></author>
      <author><first>Amr</first><last>Sharaf</last></author>
      <author><first>Yiren</first><last>Wang</last></author>
      <author><first>Hany</first><last>Awadalla</last></author>
      <author><first>Arul</first><last>Menezes</last></author>
      <pages>12009-12024</pages>
      <abstract>While Neural Machine Translation (NMT) represents the leading approach to Machine Translation (MT), the outputs of NMT models still require translation post-editing to rectify errors and enhance quality under critical settings. In this work, we formalize the task of direct translation post-editing with Large Language Models (LLMs) and explore the use of GPT-4 to automatically post-edit NMT outputs across several language pairs. Our results demonstrate that GPT-4 is adept at translation post-editing, producing meaningful and trustworthy edits to translations that help improve its general quality as well as remove different classes of major errors in translations. In particular, human evaluations on assessing edit trustworthiness show that GPT-4 exhibits a large improvement over the prior state-of-the-art LLM. Notably, we improve upon state-of-the-art performance on WMT-22 English-Chinese, English-German, Chinese-English and German-English language pairs using GPT-4 based post-editing, as evaluated by state-of-the-art MT quality metrics. However, we also show that GPT-4 could produce hallucinated edits, thereby urging caution in its use as an expert translation post-editor.</abstract>
      <url hash="9a823aed">2023.findings-emnlp.804</url>
      <bibkey>raunak-etal-2023-leveraging</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.804</doi>
    </paper>
    <paper id="805">
      <title>Uniform Complexity for Text Generation</title>
      <author><first>Joseph Marvin</first><last>Imperial</last></author>
      <author><first>Harish Tayyar</first><last>Madabushi</last></author>
      <pages>12025-12046</pages>
      <abstract>Large language models (LLMs) have shown promising results in a wide array of generative NLP tasks, such as summarization and machine translation. In the context of narrative generation, however, existing models still do not capture factors that contribute to producing consistent text. For instance, it is logical that a piece of text or a story should be uniformly readable throughout and that this form of complexity should be controllable. As such, if the complexity of an input text prompt is rated first-grade reading level in the Flesch Reading Ease test, then the generated text continuing the plot should also be within this range of complexity. With this in mind, we introduce Uniform Complexity for Text Generation (UCTG), a new benchmark test which raises the challenge of making generative models observe uniform linguistic properties with respect to prompts. We experiment with over 150+ linguistically and cognitively motivated features for evaluating text complexity in humans and generative models. From our results, we find that models such as GPT-2 struggle to preserve the complexity of input prompts used in its generations, even if finetuned with professionally written texts.</abstract>
      <url hash="1d6fc8a6">2023.findings-emnlp.805</url>
      <bibkey>imperial-madabushi-2023-uniform</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.805</doi>
    </paper>
    <paper id="806">
      <title>Cue-<fixed-case>C</fixed-case>o<fixed-case>T</fixed-case>: Chain-of-thought Prompting for Responding to In-depth Dialogue Questions with <fixed-case>LLM</fixed-case>s</title>
      <author><first>Hongru</first><last>Wang</last></author>
      <author><first>Rui</first><last>Wang</last></author>
      <author><first>Fei</first><last>Mi</last></author>
      <author><first>Yang</first><last>Deng</last></author>
      <author><first>Zezhong</first><last>Wang</last></author>
      <author><first>Bin</first><last>Liang</last></author>
      <author><first>Ruifeng</first><last>Xu</last></author>
      <author><first>Kam-Fai</first><last>Wong</last></author>
      <pages>12047-12064</pages>
      <abstract>Large Language Models (LLMs), such as ChatGPT, greatly empower dialogue systems with strong language understanding and generation capabilities. However, most of the previous works prompt the LLMs to directly generate a response based on the dialogue context, overlooking the underlying linguistic cues about the user status exhibited in the context. Such in-depth dialogue scenarios are challenging for existing LLMs to figure out the user’s hidden needs and respond satisfactorily through a single-step inference. To this end, we propose a novel linguistic cue-based chain-of-thoughts (Cue-CoT), which enhances the LLMs inference with an intermediate reasoning step to find cues exhibited in the dialogue, aiming to provide a more personalized and engaging response. To evaluate the approach, we build a benchmark with in-depth dialogue questions, consisting of 6 datasets in both Chinese and English, targeting 3 major linguistic cues during the conversation: personality, emotion, and psychology. We conducted experiments on the proposed benchmark with 5 LLMs under both zero-shot and one-shot settings. Empirical results demonstrate our proposed Cue-CoT method outperforms standard prompting methods in terms of both helpfulness and acceptability on all datasets.</abstract>
      <url hash="6b608d0f">2023.findings-emnlp.806</url>
      <bibkey>wang-etal-2023-cue</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.806</doi>
    </paper>
    <paper id="807">
      <title><fixed-case>CONTRASTE</fixed-case>: Supervised Contrastive Pre-training With Aspect-based Prompts For Aspect Sentiment Triplet Extraction</title>
      <author><first>Rajdeep</first><last>Mukherjee</last></author>
      <author><first>Nithish</first><last>Kannen</last></author>
      <author><first>Saurabh</first><last>Pandey</last></author>
      <author><first>Pawan</first><last>Goyal</last></author>
      <pages>12065-12080</pages>
      <abstract>Existing works on Aspect Sentiment Triplet Extraction (ASTE) explicitly focus on developing more efficient fine-tuning techniques for the task. Instead, our motivation is to come up with a generic approach that can improve the downstream performances of multiple ABSA tasks simultaneously. Towards this, we present CONTRASTE, a novel pre-training strategy using CONTRastive learning to enhance the ASTE performance. While we primarily focus on ASTE, we also demonstrate the advantage of our proposed technique on other ABSA tasks such as ACOS, TASD, and AESC. Given a sentence and its associated (aspect, opinion, sentiment) triplets, first, we design aspect-based prompts with corresponding sentiments masked. We then (pre)train an encoder-decoder model by applying contrastive learning on the decoder-generated aspect-aware sentiment representations of the masked terms. For fine-tuning the model weights thus obtained, we then propose a novel multi-task approach where the base encoder-decoder model is combined with two complementary modules, a tagging-based Opinion Term Detector, and a regression-based Triplet Count Estimator. Exhaustive experiments on four benchmark datasets and a detailed ablation study establish the importance of each of our proposed components as we achieve new state-of-the-art ASTE results.</abstract>
      <url hash="b11cbfcb">2023.findings-emnlp.807</url>
      <bibkey>mukherjee-etal-2023-contraste</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.807</doi>
    </paper>
    <paper id="808">
      <title>Towards Anytime Fine-tuning: Continually Pre-trained Language Models with Hypernetwork Prompts</title>
      <author><first>Gangwei</first><last>Jiang</last></author>
      <author><first>Caigao</first><last>Jiang</last></author>
      <author><first>Siqiao</first><last>Xue</last></author>
      <author><first>James</first><last>Zhang</last></author>
      <author><first>Jun</first><last>Zhou</last></author>
      <author><first>Defu</first><last>Lian</last></author>
      <author><first>Ying</first><last>Wei</last></author>
      <pages>12081-12095</pages>
      <abstract>Continual pre-training has been urgent for adapting a pre-trained model to a multitude of domains and tasks in the fast-evolving world. In practice, a continually pre-trained model is expected to demonstrate not only greater capacity when fine-tuned on pre-trained domains but also a non-decreasing performance on unseen ones. In this work, we first investigate such anytime fine-tuning effectiveness of existing continual pre-training approaches, concluding with unanimously decreased performance on unseen domains. To this end, we propose a prompt-guided continual pre-training method, where we train a hypernetwork to generate domain-specific prompts by both agreement and disagreement losses. The agreement loss maximally preserves the generalization of a pre-trained model to new domains, and the disagreement one guards the exclusiveness of the generated hidden states for each domain. Remarkably, prompts by the hypernetwork alleviate the domain identity when fine-tuning and promote knowledge transfer across domains. Our method achieved improvements of 3.57% and 3.4% on two real-world datasets (including domain shift and temporal shift), respectively, demonstrating its efficacy.</abstract>
      <url hash="d1ed4c8c">2023.findings-emnlp.808</url>
      <bibkey>jiang-etal-2023-towards</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.808</doi>
    </paper>
    <paper id="809">
      <title>Language Guided Visual Question Answering: Elevate Your Multimodal Language Model Using Knowledge-Enriched Prompts</title>
      <author><first>Deepanway</first><last>Ghosal</last></author>
      <author><first>Navonil</first><last>Majumder</last></author>
      <author><first>Roy</first><last>Lee</last></author>
      <author><first>Rada</first><last>Mihalcea</last></author>
      <author><first>Soujanya</first><last>Poria</last></author>
      <pages>12096-12102</pages>
      <abstract>Visual question answering (VQA) is the task of answering questions about an image. The task assumes an understanding of both the image and the question to provide a natural language answer. VQA has gained popularity in recent years due to its potential applications in a wide range of fields, including robotics, education, and healthcare. In this paper, we focus on knowledge-augmented VQA, where answering the question requires commonsense knowledge, world knowledge, and reasoning about ideas and concepts not present in the image. We propose a multimodal framework that uses language guidance (LG) in the form of rationales, image captions, scene graphs, etc to answer questions more accurately. We benchmark our method on the multi-choice question-answering task of the A-OKVQA, Science-QA, VSR, and IconQA datasets using CLIP and BLIP models. We show that the use of language guidance is a simple but powerful and effective strategy for visual question answering. Our language guidance improves the performance of CLIP by 7.6% and BLIP-2 by 4.8% in the challenging A-OKVQA dataset. We also observe consistent improvement in performance on the Science-QA, VSR, and IconQA datasets when using the proposed language guidances. The implementation of LG-VQA is publicly available at https://github.com/declare-lab/LG-VQA.</abstract>
      <url hash="61908000">2023.findings-emnlp.809</url>
      <bibkey>ghosal-etal-2023-language</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.809</doi>
    </paper>
    <paper id="810">
      <title><fixed-case>XLS</fixed-case>-<fixed-case>R</fixed-case> fine-tuning on noisy word boundaries for unsupervised speech segmentation into words</title>
      <author><first>Robin</first><last>Algayres</last></author>
      <author><first>Pablo</first><last>Diego-Simon</last></author>
      <author><first>Benoît</first><last>Sagot</last></author>
      <author><first>Emmanuel</first><last>Dupoux</last></author>
      <pages>12103-12112</pages>
      <abstract>Due to the absence of explicit word boundaries in the speech stream, the task of segmenting spoken sentences into word units without text supervision is particularly challenging. In this work, we leverage the most recent self-supervised speech models that have proved to quickly adapt to new tasks through fine-tuning, even in low resource conditions. Taking inspiration from semi-supervised learning, we fine-tune an XLS-R model to predict word boundaries themselves produced by top-tier speech segmentation systems: DPDP, VG-HuBERT and DP-Parse. Once XLS-R is fine-tuned, it is used to infer new word boundary labels that are used in turn for another fine-tuning step. Our method consistently improves the performance of each system and set a new state-of-the-art that is, on average 130% higher than the previous one as measured by the F1 score on correctly discovered word tokens on five corpora featuring different languages. Finally, our system can segment speech from languages unseen during fine-tuning in a zero-shot fashion.</abstract>
      <url hash="a28ccc1d">2023.findings-emnlp.810</url>
      <bibkey>algayres-etal-2023-xls</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.810</doi>
    </paper>
    <paper id="811">
      <title>Automatic Prompt Augmentation and Selection with Chain-of-Thought from Labeled Data</title>
      <author><first>Kashun</first><last>Shum</last></author>
      <author><first>Shizhe</first><last>Diao</last></author>
      <author><first>Tong</first><last>Zhang</last></author>
      <pages>12113-12139</pages>
      <abstract>Chain-of-thought (CoT) advances the reasoning abilities of large language models (LLMs) and achieves superior performance in complex reasoning tasks. However, most CoT studies rely on carefully designed human-annotated rational chains to prompt LLMs, posing challenges for real-world applications where labeled data is available without rational chains. This paper proposes a new strategy, AutomateCoT (Automatic Prompt Augmentation and Selection with Chain-of-Thought), that can bypass human engineering of CoT by automatically augmenting rational chains from a small labeled dataset, and then pruning low-quality chains to construct a candidate pool of machinegenerated rationale chains based on the labels. Finally, it selects the optimal combination of several rationale chains from the pool for CoT prompting by employing a variance-reduced policy gradient strategy to estimate the significance of each example. Automate-CoT enables a quick adaptation of the CoT technique to different tasks. Experimental results demonstrate the effectiveness of our method, where competitive results are achieved on arithmetic reasoning (+2.7%), commonsense reasoning (+3.4%), symbolic reasoning (+3.2%), and non-reasoning tasks (+2.5%).</abstract>
      <url hash="714a3e0e">2023.findings-emnlp.811</url>
      <bibkey>shum-etal-2023-automatic</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.811</doi>
    </paper>
    <paper id="812">
      <title>What Makes it Ok to Set a Fire? Iterative Self-distillation of Contexts and Rationales for Disambiguating Defeasible Social and Moral Situations</title>
      <author><first>Kavel</first><last>Rao</last></author>
      <author><first>Liwei</first><last>Jiang</last></author>
      <author><first>Valentina</first><last>Pyatkin</last></author>
      <author><first>Yuling</first><last>Gu</last></author>
      <author><first>Niket</first><last>Tandon</last></author>
      <author><first>Nouha</first><last>Dziri</last></author>
      <author><first>Faeze</first><last>Brahman</last></author>
      <author><first>Yejin</first><last>Choi</last></author>
      <pages>12140-12159</pages>
      <abstract>Moral or ethical judgments rely heavily on the specific contexts in which they occur. Understanding varying shades of defeasible contextualizations (i.e., additional information that strengthens or attenuates the moral acceptability of an action) is critical to accurately represent the subtlety and intricacy of grounded human moral judgment in real-life scenarios. We introduce defeasible moral reasoning: a task to provide grounded contexts that make an action more or less morally acceptable, along with commonsense rationales that justify the reasoning. To elicit high-quality task data, we take an iterative self-distillation approach that starts from a small amount of unstructured seed knowledge from GPT-3 and then alternates between (1) self-distillation from student models; (2) targeted filtering with a critic model trained by human judgment (to boost validity) and NLI (to boost diversity); (3) self-imitation learning (to amplify the desired data quality). This process yields a student model that produces defeasible contexts with improved validity, diversity, and defeasibility. From this model we distill a high-quality dataset, <tex-math>\delta</tex-math>-Rules-of-Thumb, of 1.2M entries of contextualizations and rationales for 115K defeasible moral actions rated highly by human annotators 85.9% to 99.8% of the time. Using <tex-math>\delta</tex-math>-RoT we obtain a final student model that wins over all intermediate student models by a notable margin.</abstract>
      <url hash="db2f785f">2023.findings-emnlp.812</url>
      <bibkey>rao-etal-2023-makes</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.812</doi>
    </paper>
    <paper id="813">
      <title>An Empirical Study on Multiple Knowledge from <fixed-case>C</fixed-case>hat<fixed-case>GPT</fixed-case> for Emotion Recognition in Conversations</title>
      <author><first>Geng</first><last>Tu</last></author>
      <author><first>Bin</first><last>Liang</last></author>
      <author><first>Bing</first><last>Qin</last></author>
      <author><first>Kam-Fai</first><last>Wong</last></author>
      <author><first>Ruifeng</first><last>Xu</last></author>
      <pages>12160-12173</pages>
      <abstract>Multiple knowledge (e.g., co-reference, topics, emotional causes, etc) has been demonstrated effective for emotion detection. However, exploring this knowledge in Emotion Recognition in Conversations (ERC) is currently a blank slate due to the lack of annotated data and the high cost involved in obtaining such knowledge. Fortunately, the emergence of Large Language Models (LLMs) holds promise in filling this void. Therefore, we propose a Multiple Knowledge Fusion Model (MKFM) to effectively integrate such knowledge generated by LLMs for ERC and empirically study its impact on the model. Experimental results on three public datasets have demonstrated the effectiveness of multiple knowledge for ERC. Furthermore, we conduct a detailed analysis of the contribution and complementarity of this knowledge.</abstract>
      <url hash="d6edace5">2023.findings-emnlp.813</url>
      <bibkey>tu-etal-2023-empirical</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.813</doi>
    </paper>
    <paper id="814">
      <title>Exploiting Contrastive Learning and Numerical Evidence for Confusing Legal Judgment Prediction</title>
      <author><first>Leilei</first><last>Gan</last></author>
      <author><first>Baokui</first><last>Li</last></author>
      <author><first>Kun</first><last>Kuang</last></author>
      <author><first>Yating</first><last>Zhang</last></author>
      <author><first>Lei</first><last>Wang</last></author>
      <author><first>Anh</first><last>Luu</last></author>
      <author><first>Yi</first><last>Yang</last></author>
      <author><first>Fei</first><last>Wu</last></author>
      <pages>12174-12185</pages>
      <abstract>Given the fact description text of a legal case, legal judgment prediction (LJP) aims to predict the case’s charge, applicable law article, and term of penalty. A core problem of LJP is distinguishing confusing legal cases where only subtle text differences exist. Previous studies fail to distinguish different classification errors with a standard cross-entropy classification loss and ignore the numbers in the fact description for predicting the term of penalty. To tackle these issues, in this work, first, in order to exploit the numbers in legal cases for predicting the term of penalty of certain charges, we enhance the representation of the fact description with extracted crime amounts which are encoded by a pre-trained numeracy model. Second, we propose a moco-based supervised contrastive learning to learn distinguishable representations and explore the best strategy to construct positive example pairs to benefit all three subtasks of LJP simultaneously. Extensive experiments on real-world datasets show that the proposed method achieves new state-of-the-art results, particularly for confusing legal cases. Ablation studies also demonstrate the effectiveness of each component.</abstract>
      <url hash="d361d616">2023.findings-emnlp.814</url>
      <bibkey>gan-etal-2023-exploiting</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.814</doi>
    </paper>
    <paper id="815">
      <title>One For All &amp; All For One: Bypassing Hyperparameter Tuning with Model Averaging for Cross-Lingual Transfer</title>
      <author><first>Fabian David</first><last>Schmidt</last></author>
      <author><first>Ivan</first><last>Vulić</last></author>
      <author><first>Goran</first><last>Glavaš</last></author>
      <pages>12186-12193</pages>
      <abstract>Multilingual language models enable zero-shot cross-lingual transfer (ZS-XLT): fine-tuned on sizable source-language task data, they perform the task in target languages without labeled instances. The effectiveness of ZS-XLT hinges on the linguistic proximity between languages and the amount of pretraining data for a language. Because of this, model selection based on source-language validation is unreliable: it picks model snapshots with suboptimal target-language performance. As a remedy, some work optimizes ZS-XLT by extensively tuning hyperparameters: the follow-up work then routinely struggles to replicate the original results. Other work searches over narrower hyperparameter grids, reporting substantially lower performance. In this work, we therefore propose an unsupervised evaluation protocol for ZS-XLT that decouples performance maximization from hyperparameter tuning. As a robust and more transparent alternative to extensive hyperparameter tuning, we propose to accumulatively average snapshots from different runs into a single model. We run broad ZS-XLT experiments on both higher-level semantic tasks (NLI, extractive QA) and a lower-level token classification task (NER) and find that conventional model selection based on source-language validation quickly plateaus to suboptimal ZS-XLT performance. On the other hand, our accumulative run-by-run averaging of models trained with different hyperparameters boosts ZS-XLT performance and closely correlates with “oracle” ZS-XLT, i.e., model selection based on target-language validation performance.</abstract>
      <url hash="2c6c2244">2023.findings-emnlp.815</url>
      <bibkey>schmidt-etal-2023-one</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.815</doi>
    </paper>
    <paper id="816">
      <title>Dimensions of Online Conflict: Towards Modeling Agonism</title>
      <author><first>Matt</first><last>Canute</last></author>
      <author><first>Mali</first><last>Jin</last></author>
      <author><first>Hannah</first><last>Holtzclaw</last></author>
      <author><first>Alberto</first><last>Lusoli</last></author>
      <author><first>Philippa</first><last>Adams</last></author>
      <author><first>Mugdha</first><last>Pandya</last></author>
      <author><first>Maite</first><last>Taboada</last></author>
      <author><first>Diana</first><last>Maynard</last></author>
      <author><first>Wendy Hui Kyong</first><last>Chun</last></author>
      <pages>12194-12209</pages>
      <abstract>Agonism plays a vital role in democratic dialogue by fostering diverse perspectives and robust discussions. Within the realm of online conflict there is another type: hateful antagonism, which undermines constructive dialogue. Detecting conflict online is central to platform moderation and monetization. It is also vital for democratic dialogue, but only when it takes the form of agonism. To model these two types of conflict, we collected Twitter conversations related to trending controversial topics. We introduce a comprehensive annotation schema for labelling different dimensions of conflict in the conversations, such as the source of conflict, the target, and the rhetorical strategies deployed. Using this schema, we annotated approximately 4,000 conversations with multiple labels. We then train both logistic regression and transformer-based models on the dataset, incorporating context from the conversation, including the number of participants and the structure of the interactions. Results show that contextual labels are helpful in identifying conflict and make the models robust to variations in topic. Our research contributes a conceptualization of different dimensions of conflict, a richly annotated dataset, and promising results that can contribute to content moderation.</abstract>
      <url hash="dd407376">2023.findings-emnlp.816</url>
      <bibkey>canute-etal-2023-dimensions</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.816</doi>
    </paper>
    <paper id="817">
      <title>Learning under Label Proportions for Text Classification</title>
      <author><first>Jatin</first><last>Chauhan</last></author>
      <author><first>Xiaoxuan</first><last>Wang</last></author>
      <author><first>Wei</first><last>Wang</last></author>
      <pages>12210-12223</pages>
      <abstract>We present one of the preliminary NLP works under the challenging setup of Learning from Label Proportions (LLP), where the data is provided in an aggregate form called bags and only the proportion of samples in each class as the ground truth. This setup is inline with the desired characteristics of training models under Privacy settings and Weakly supervision. By characterizing some irregularities of the most widely used baseline technique DLLP, we propose a novel formulation that is also robust. This is accompanied with a learnability result that provides a generalization bound under LLP. Combining this formulation with a self-supervised objective, our method achieves better results as compared to the baselines in almost 87% of the experimental configurations which include large scale models for both long and short range texts across multiple metrics.</abstract>
      <url hash="8991ea6f">2023.findings-emnlp.817</url>
      <bibkey>chauhan-etal-2023-learning</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.817</doi>
    </paper>
    <paper id="818">
      <title><fixed-case>M</fixed-case>eta<fixed-case>R</fixed-case>e<fixed-case>V</fixed-case>ision: Meta-Learning with Retrieval for Visually Grounded Compositional Concept Acquisition</title>
      <author><first>Guangyue</first><last>Xu</last></author>
      <author><first>Parisa</first><last>Kordjamshidi</last></author>
      <author><first>Joyce</first><last>Chai</last></author>
      <pages>12224-12236</pages>
      <abstract>Humans have the ability to learn novel compositional concepts by recalling primitive concepts acquired from past experience and generalizing these primitive concepts to novel compositions. Inspired by the above human’s compositional learning procedure, in this paper, we propose MetaReVision, a retrievalenhanced meta-learning model to solve the visually grounded compositional concept learning problem. The proposed MetaReVision consists of a retrieval module and a meta-learning module which are designed to incorporate retrieved primitive concepts as supporting set to meta-train visual-language models for grounded compositional concept recognition. Through meta-learning from episodes constructed by the retriever, MetaReVision learns a generic compositional representation that can be fast updated to recognize novel composi tional concepts. We create CompCOCO and CompFlickr to benchmark the grounded compositional concept learning. Our experimental results show MetaReVision outperforms other competitive baselines and the retrieval module does plays an important role in this compositional learning process.</abstract>
      <url hash="b21a2711">2023.findings-emnlp.818</url>
      <bibkey>xu-etal-2023-metarevision</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.818</doi>
    </paper>
    <paper id="819">
      <title><fixed-case>PR</fixed-case>-<fixed-case>MCS</fixed-case>: Perturbation Robust Metric for <fixed-case>M</fixed-case>ulti<fixed-case>L</fixed-case>ingual Image Captioning</title>
      <author><first>Yongil</first><last>Kim</last></author>
      <author><first>Yerin</first><last>Hwang</last></author>
      <author><first>Hyeongu</first><last>Yun</last></author>
      <author><first>Seunghyun</first><last>Yoon</last></author>
      <author><first>Trung</first><last>Bui</last></author>
      <author><first>Kyomin</first><last>Jung</last></author>
      <pages>12237-12258</pages>
      <abstract>Vulnerability to lexical perturbation is a critical weakness of automatic evaluation metrics for image captioning. This paper proposes Perturbation Robust Multi-Lingual CLIPScore(PR-MCS), which exhibits robustness to such perturbations, as a novel reference-free image captioning metric applicable to multiple languages. To achieve perturbation robustness, we fine-tune the text encoder of CLIP with our language-agnostic method to distinguish the perturbed text from the original text. To verify the robustness of PR-MCS, we introduce a new fine-grained evaluation dataset consisting of detailed captions, critical objects, and the relationships between the objects for 3,000 images in five languages. In our experiments, PR-MCS significantly outperforms baseline metrics in capturing lexical noise of all various perturbation types in all five languages, while maintaining a strong correlation with human judgments.</abstract>
      <url hash="73a2104c">2023.findings-emnlp.819</url>
      <bibkey>kim-etal-2023-pr</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.819</doi>
    </paper>
    <paper id="820">
      <title>Pre-training Multi-task Contrastive Learning Models for Scientific Literature Understanding</title>
      <author><first>Yu</first><last>Zhang</last></author>
      <author><first>Hao</first><last>Cheng</last></author>
      <author><first>Zhihong</first><last>Shen</last></author>
      <author><first>Xiaodong</first><last>Liu</last></author>
      <author><first>Ye-Yi</first><last>Wang</last></author>
      <author><first>Jianfeng</first><last>Gao</last></author>
      <pages>12259-12275</pages>
      <abstract>Scientific literature understanding tasks have gained significant attention due to their potential to accelerate scientific discovery. Pre-trained language models (LMs) have shown effectiveness in these tasks, especially when tuned via contrastive learning. However, jointly utilizing pre-training data across multiple heterogeneous tasks (e.g., extreme multi-label paper classification, citation prediction, and literature search) remains largely unexplored. To bridge this gap, we propose a multi-task contrastive learning framework, SciMult, with a focus on facilitating common knowledge sharing across different scientific literature understanding tasks while preventing task-specific skills from interfering with each other. To be specific, we explore two techniques – task-aware specialization and instruction tuning. The former adopts a Mixture-of-Experts Transformer architecture with task-aware sub-layers; the latter prepends task-specific instructions to the input text so as to produce task-aware outputs. Extensive experiments on a comprehensive collection of benchmark datasets verify the effectiveness of our task-aware specialization strategy, where we outperform state-of-the-art scientific pre-trained LMs. Code, datasets, and pre-trained models can be found at https://scimult.github.io/.</abstract>
      <url hash="be968ebb">2023.findings-emnlp.820</url>
      <bibkey>zhang-etal-2023-pre</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.820</doi>
    </paper>
    <paper id="821">
      <title><fixed-case>BLM</fixed-case>-s/l<fixed-case>E</fixed-case>: A structured dataset of <fixed-case>E</fixed-case>nglish spray-load verb alternations for testing generalization in <fixed-case>LLM</fixed-case>s</title>
      <author><first>Giuseppe</first><last>Samo</last></author>
      <author><first>Vivi</first><last>Nastase</last></author>
      <author><first>Chunyang</first><last>Jiang</last></author>
      <author><first>Paola</first><last>Merlo</last></author>
      <pages>12276-12287</pages>
      <abstract>Current NLP models appear to be achieving performance comparable to human capabilities on well-established benchmarks. New benchmarks are now necessary to test deeper layers of understanding of natural languages by these models. Blackbird’s Language Matrices are a recently developed framework that draws inspiration from tests of human analytic intelligence. The BLM task has revealed that successful performances in previously studied linguistic problems do not yet stem from a deep understanding of the generative factors that define these problems. In this study, we define a new BLM task for predicate-argument structure, and develop a structured dataset for its investigation, concentrating on the spray-load verb alternations in English, as a case study. The context sentences include one alternant from the spray-load alternation and the target sentence is the other alternant, to be chosen among a minimally contrastive and adversarial set of answers. We describe the generation process of the dataset and the reasoning behind the generating rules. The dataset aims to facilitate investigations into how verb information is encoded in sentence embeddings and how models generalize to the complex properties of argument structures. Benchmarking experiments conducted on the dataset and qualitative error analysis on the answer set reveal the inherent challenges associated with the problem even for current high-performing representations.</abstract>
      <url hash="f96a978e">2023.findings-emnlp.821</url>
      <bibkey>samo-etal-2023-blm</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.821</doi>
    </paper>
    <paper id="822">
      <title>Efficiently Enhancing Zero-Shot Performance of Instruction Following Model via Retrieval of Soft Prompt</title>
      <author><first>Seonghyeon</first><last>Ye</last></author>
      <author><first>Joel</first><last>Jang</last></author>
      <author><first>Doyoung</first><last>Kim</last></author>
      <author><first>Yongrae</first><last>Jo</last></author>
      <author><first>Minjoon</first><last>Seo</last></author>
      <pages>12288-12309</pages>
      <abstract>Enhancing the zero-shot performance of instruction-following models requires heavy computation, either by scaling the total number of training datasets or the model size. In this work, we explore how retrieval of soft prompts obtained through prompt tuning can efficiently assist hard prompts in zero-shot task generalization. Specifically, we train soft prompt embeddings for each prompt through prompt tuning, store the samples of the training instances mapped with the prompt embeddings, and retrieve the corresponding prompt embedding of the training instance closest to the query instance during inference. While only adding 0.007% additional parameters, retrieval of soft prompt enhances the performance of T0 on unseen tasks by outperforming it on 10 out of 11 datasets as well as improving the mean accuracy of T0 on BIG-bench benchmark by 2.39% points. Also, we report an interesting finding that retrieving source embeddings trained on similar answer choice formats is more important than those on similar task types.</abstract>
      <url hash="23587427">2023.findings-emnlp.822</url>
      <bibkey>ye-etal-2023-efficiently</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.822</doi>
    </paper>
    <paper id="823">
      <title>Geographical Erasure in Language Generation</title>
      <author><first>Pola</first><last>Schwöbel</last></author>
      <author><first>Jacek</first><last>Golebiowski</last></author>
      <author><first>Michele</first><last>Donini</last></author>
      <author><first>Cedric</first><last>Archambeau</last></author>
      <author><first>Danish</first><last>Pruthi</last></author>
      <pages>12310-12324</pages>
      <abstract>Large language models (LLMs) encode vast amounts of world knowledge. However, since these models are trained on large swaths of internet data, they are at risk of inordinately capturing information about dominant groups. This imbalance can propagate into generated language. In this work, we study and operationalise a form of geographical erasure wherein language models underpredict certain countries. We demonstrate consistent instances of erasure across a range of LLMs. We discover that erasure strongly correlates with low frequencies of country mentions in the training corpus. Lastly, we mitigate erasure by finetuning using a custom objective.</abstract>
      <url hash="a4f8e72e">2023.findings-emnlp.823</url>
      <bibkey>schwobel-etal-2023-geographical</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.823</doi>
    </paper>
    <paper id="824">
      <title>Can Foundation Models Watch, Talk and Guide You Step by Step to Make a Cake?</title>
      <author><first>Yuwei</first><last>Bao</last></author>
      <author><first>Keunwoo</first><last>Yu</last></author>
      <author><first>Yichi</first><last>Zhang</last></author>
      <author><first>Shane</first><last>Storks</last></author>
      <author><first>Itamar</first><last>Bar-Yossef</last></author>
      <author><first>Alex</first><last>de la Iglesia</last></author>
      <author><first>Megan</first><last>Su</last></author>
      <author><first>Xiao</first><last>Zheng</last></author>
      <author><first>Joyce</first><last>Chai</last></author>
      <pages>12325-12341</pages>
      <abstract>Despite tremendous advances in AI, it remains a significant challenge to develop interactive task guidance systems that can offer situated, personalized guidance and assist humans in various tasks. These systems need to have a sophisticated understanding of the user as well as the environment, and make timely accurate decisions on when and what to say. To address this issue, we created a new multimodal benchmark dataset, Watch, Talk and Guide (WTaG) based on natural interaction between a human user and a human instructor. We further proposed two tasks: User and Environment Understanding, and Instructor Decision Making. We leveraged several foundation models to study to what extent these models can be quickly adapted to perceptually enabled task guidance. Our quantitative, qualitative, and human evaluation results show that these models can demonstrate fair performances in some cases with no task-specific training, but a fast and reliable adaptation remains a significant challenge. Our benchmark and baselines will provide a stepping stone for future work on situated task guidance.</abstract>
      <url hash="e37184cf">2023.findings-emnlp.824</url>
      <bibkey>bao-etal-2023-foundation</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.824</doi>
    </paper>
    <paper id="825">
      <title>Scaling Laws vs Model Architectures: How does Inductive Bias Influence Scaling?</title>
      <author><first>Yi</first><last>Tay</last></author>
      <author><first>Mostafa</first><last>Dehghani</last></author>
      <author><first>Samira</first><last>Abnar</last></author>
      <author><first>Hyung</first><last>Chung</last></author>
      <author><first>William</first><last>Fedus</last></author>
      <author><first>Jinfeng</first><last>Rao</last></author>
      <author><first>Sharan</first><last>Narang</last></author>
      <author><first>Vinh</first><last>Tran</last></author>
      <author><first>Dani</first><last>Yogatama</last></author>
      <author><first>Donald</first><last>Metzler</last></author>
      <pages>12342-12364</pages>
      <abstract>There have been a lot of interest in the scaling properties of Transformer models. However, not much has been done on the front of investigating the effect of scaling properties of different inductive biases and model architectures. Do model architectures scale differently? If so, how does inductive bias affect scaling behaviour? How does this influence upstream (pretraining) and downstream (transfer)? This paper conducts a systematic study of scaling behaviour of ten diverse model architectures such as Transformers, Switch Transformers, Universal Transformers, Dynamic convolutions, Performers, and recently proposed MLP-Mixers. Via extensive experiments, we show that (1) architecture is an indeed an important consideration when performing scaling and (2) the best performing model can fluctuate at different scales. We believe that the findings outlined in this work has significant implications to how model architectures are currently evaluated in the community.</abstract>
      <url hash="a76a3759">2023.findings-emnlp.825</url>
      <bibkey>tay-etal-2023-scaling</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.825</doi>
    </paper>
    <paper id="826">
      <title>Not All Languages Are Created Equal in <fixed-case>LLM</fixed-case>s: Improving Multilingual Capability by Cross-Lingual-Thought Prompting</title>
      <author><first>Haoyang</first><last>Huang</last></author>
      <author><first>Tianyi</first><last>Tang</last></author>
      <author><first>Dongdong</first><last>Zhang</last></author>
      <author><first>Xin</first><last>Zhao</last></author>
      <author><first>Ting</first><last>Song</last></author>
      <author><first>Yan</first><last>Xia</last></author>
      <author><first>Furu</first><last>Wei</last></author>
      <pages>12365-12394</pages>
      <abstract>Large language models (LLMs) demonstrate impressive multilingual capability, but their performance varies substantially across different languages. In this work, we introduce a simple yet effective method, called cross-lingual-thought prompting (XLT), to systematically improve the multilingual capability of LLMs. Specifically, XLT is a generic template prompt that stimulates cross-lingual and logical reasoning skills to enhance task performance across languages. We conduct comprehensive evaluations on 7 typical benchmarks related to reasoning, understanding, and generation tasks, covering both high-resource and low-resource languages. Experimental results show that XLT not only remarkably enhances the performance of various multilingual tasks but also significantly reduces the gap between the average performance and the best performance of each task in different languages. Notably, XLT brings over 10 points of average improvement in arithmetic reasoning and open-domain question-answering tasks.</abstract>
      <url hash="df6288f3">2023.findings-emnlp.826</url>
      <bibkey>huang-etal-2023-languages</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.826</doi>
    </paper>
    <paper id="827">
      <title><fixed-case>D</fixed-case>etect<fixed-case>LLM</fixed-case>: Leveraging Log Rank Information for Zero-Shot Detection of Machine-Generated Text</title>
      <author><first>Jinyan</first><last>Su</last></author>
      <author><first>Terry</first><last>Zhuo</last></author>
      <author><first>Di</first><last>Wang</last></author>
      <author><first>Preslav</first><last>Nakov</last></author>
      <pages>12395-12412</pages>
      <abstract>With the rapid progress of Large language models (LLMs) and the huge amount of text they generate, it becomes impractical to manually distinguish whether a text is machine-generated. The growing use of LLMs in social media and education, prompts us to develop methods to detect machine-generated text, preventing malicious use such as plagiarism, misinformation, and propaganda. In this paper, we introduce two novel zero-shot methods for detecting machine-generated text by leveraging the Log-Rank information. One is called DetectLLM-LRR, which is fast and efficient, and the other is called DetectLLM-NPR, which is more accurate, but slower due to the need for perturbations. Our experiments on three datasets and seven language models show that our proposed methods improve over the state of the art by 3.9 and 1.75 AUROC points absolute. Moreover, DetectLLM-NPR needs fewer perturbations than previous work to achieve the same level of performance, which makes it more practical for real-world use. We also investigate the efficiency-performance trade-off based on users’ preference for these two measures and provide intuition for using them in practice effectively. We release the data and the code of both methods in https://github.com/mbzuai-nlp/DetectLLM.</abstract>
      <url hash="96cf3bf8">2023.findings-emnlp.827</url>
      <bibkey>su-etal-2023-detectllm</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.827</doi>
    </paper>
    <paper id="828">
      <title>From Complex to Simple: Unraveling the Cognitive Tree for Reasoning with Small Language Models</title>
      <author><first>Yan</first><last>Junbing</last></author>
      <author><first>Chengyu</first><last>Wang</last></author>
      <author><first>Taolin</first><last>Zhang</last></author>
      <author><first>Xiaofeng</first><last>He</last></author>
      <author><first>Jun</first><last>Huang</last></author>
      <author><first>Wei</first><last>Zhang</last></author>
      <pages>12413-12425</pages>
      <abstract>Reasoning is a distinctive human capacity, enabling us to address complex problems by breaking them down into a series of manageable cognitive steps. Yet, complex logical reasoning is still cumbersome for language models. Based on the dual process theory in cognitive science, we are the first to unravel the cognitive reasoning abilities of language models. Our framework employs an iterative methodology to construct a Cognitive Tree (CogTree). The root node of this tree represents the initial query, while the leaf nodes consist of straightforward questions that can be answered directly. This construction involves two main components: the implicit extraction module (referred to as the intuitive system) and the explicit reasoning module (referred to as the reflective system). The intuitive system rapidly generates multiple responses by utilizing in-context examples, while the reflective system scores these responses using comparative learning. The scores guide the intuitive system in its subsequent generation step.Our experimental results on two popular and challenging reasoning tasks indicate that it is possible to achieve a performance level comparable to that of GPT-3.5 (with 175B parameters), using a significantly smaller language model that contains fewer parameters (&lt;=7B) than 5% of GPT-3.5.</abstract>
      <url hash="4705bd6f">2023.findings-emnlp.828</url>
      <bibkey>junbing-etal-2023-complex</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.828</doi>
    </paper>
    <paper id="829">
      <title>Macedon: Minimizing Representation Coding Rate Reduction for Cross-Lingual Natural Language Understanding</title>
      <author><first>Haoyu</first><last>Wang</last></author>
      <author><first>Yaqing</first><last>Wang</last></author>
      <author><first>Huaxiu</first><last>Yao</last></author>
      <author><first>Jing</first><last>Gao</last></author>
      <pages>12426-12436</pages>
      <abstract>Cross-lingual natural language understanding(NLU) is one of the fundamental tasks of NLP. The goal is to learn a model which can generalize well on both high-resource and low-resource language data. Recent pre-trained multilingual language models, e.g., multilingual BERT, XLM, have shown impressive performance on cross-lingual NLU tasks. However, such promising results request the use of sufficient training data, which is a difficult condition to satisfy for low-resource language. When the data is limited in those low resource languages, the accuracy of existing models will drop. In light of this challenge, we investigate the important task of how to train the cross-lingual model with abundant high-source language data and limited low-resource language data. Existing methods typically learn language-agnostic representation via adversarial training and mutual information estimation. Existing approaches may suffer When data is very limited (e.g., low-resource language) because it is challenging to estimate data distribution accurately. To tackle this issue, we propose a conceptually innovative approach to remove language-associated information via <b>m</b>inimizing represent<b>a</b>tion <b>c</b>oding rate r<b>ed</b>ucti<b>on</b>(Macedon). Specifically, Macedon avoids using extra codes to encode language-related information, which is measured by the rate-distortion function. To validate the effectiveness of Macedon, we conduct extensive experiments on three tasks, including paraphrase identification, natural language inference, and query advertisement matching. The experiment results show that the proposed Macedon outperforms state-of-the-art cross-lingual NLU approaches.</abstract>
      <url hash="b59428b6">2023.findings-emnlp.829</url>
      <bibkey>wang-etal-2023-macedon</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.829</doi>
    </paper>
    <paper id="830">
      <title>Adversarial Robustness for Large Language <fixed-case>NER</fixed-case> models using Disentanglement and Word Attributions</title>
      <author><first>Xiaomeng</first><last>Jin</last></author>
      <author><first>Bhanukiran</first><last>Vinzamuri</last></author>
      <author><first>Sriram</first><last>Venkatapathy</last></author>
      <author><first>Heng</first><last>Ji</last></author>
      <author><first>Pradeep</first><last>Natarajan</last></author>
      <pages>12437-12450</pages>
      <abstract>Large language models (LLM’s) have been widely used for several applications such as question answering, text classification and clustering. While the preliminary results across the aforementioned tasks looks promising, recent work has dived deep into LLM’s performing poorly for complex Named Entity Recognition (NER) tasks in comparison to fine-tuned pre-trained language models (PLM’s). To enhance wider adoption of LLM’s, our paper investigates the robustness of such LLM NER models and its instruction fine-tuned variants to adversarial attacks. In particular, we propose a novel attack which relies on disentanglement and word attribution techniques where the former aids in learning an embedding capturing both entity and non-entity influences separately, and the latter aids in identifying important words across both components. This is in stark contrast to most techniques which primarily leverage non-entity words for perturbations limiting the space being explored to synthesize effective adversarial examples. Adversarial training results based on our method improves the F1 score over original LLM NER model by 8% and 18% on CoNLL-2003 and Ontonotes 5.0 datasets respectively.</abstract>
      <url hash="7ec663d1">2023.findings-emnlp.830</url>
      <bibkey>jin-etal-2023-adversarial</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.830</doi>
    </paper>
    <paper id="831">
      <title><fixed-case>LLM</fixed-case>s – the Good, the Bad or the Indispensable?: A Use Case on Legal Statute Prediction and Legal Judgment Prediction on <fixed-case>I</fixed-case>ndian Court Cases</title>
      <author><first>Shaurya</first><last>Vats</last></author>
      <author><first>Atharva</first><last>Zope</last></author>
      <author><first>Somsubhra</first><last>De</last></author>
      <author><first>Anurag</first><last>Sharma</last></author>
      <author><first>Upal</first><last>Bhattacharya</last></author>
      <author><first>Shubham</first><last>Nigam</last></author>
      <author><first>Shouvik</first><last>Guha</last></author>
      <author><first>Koustav</first><last>Rudra</last></author>
      <author><first>Kripabandhu</first><last>Ghosh</last></author>
      <pages>12451-12474</pages>
      <abstract>The Large Language Models (LLMs) have impacted many real-life tasks. To examine the efficacy of LLMs in a high-stake domain like law, we have applied state-of-the-art LLMs for two popular tasks: Statute Prediction and Judgment Prediction, on Indian Supreme Court cases. We see that while LLMs exhibit excellent predictive performance in Statute Prediction, their performance dips in Judgment Prediction when compared with many standard models. The explanations generated by LLMs (along with prediction) are of moderate to decent quality. We also see evidence of gender and religious bias in the LLM-predicted results. In addition, we present a note from a senior legal expert on the ethical concerns of deploying LLMs in these critical legal tasks.</abstract>
      <url hash="7e1b5922">2023.findings-emnlp.831</url>
      <bibkey>vats-etal-2023-llms</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.831</doi>
    </paper>
    <paper id="832">
      <title>You Are What You Annotate: Towards Better Models through Annotator Representations</title>
      <author><first>Naihao</first><last>Deng</last></author>
      <author><first>Xinliang</first><last>Zhang</last></author>
      <author><first>Siyang</first><last>Liu</last></author>
      <author><first>Winston</first><last>Wu</last></author>
      <author><first>Lu</first><last>Wang</last></author>
      <author><first>Rada</first><last>Mihalcea</last></author>
      <pages>12475-12498</pages>
      <abstract>Annotator disagreement is ubiquitous in natural language processing (NLP) tasks. There are multiple reasons for such disagreements, including the subjectivity of the task, difficult cases, unclear guidelines, and so on. Rather than simply aggregating labels to obtain data annotations, we instead try to directly model the diverse perspectives of the annotators, and explicitly account for annotators’ idiosyncrasies in the modeling process by creating representations for each annotator (*annotator embeddings*) and also their annotations (*annotation embeddings*). In addition, we propose **TID-8**, **T**he **I**nherent **D**isagreement - **8** dataset, a benchmark that consists of eight existing language understanding datasets that have inherent annotator disagreement. We test our approach on TID-8 and show that our approach helps models learn significantly better from disagreements on six different datasets in TID-8 while increasing model size by fewer than 1% parameters. By capturing the unique tendencies and subjectivity of individual annotators through embeddings, our representations prime AI models to be inclusive of diverse viewpoints.</abstract>
      <url hash="6c3c290b">2023.findings-emnlp.832</url>
      <bibkey>deng-etal-2023-annotate</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.832</doi>
    </paper>
    <paper id="833">
      <title>Large Language Models Are Better Adversaries: Exploring Generative Clean-Label Backdoor Attacks Against Text Classifiers</title>
      <author><first>Wencong</first><last>You</last></author>
      <author><first>Zayd</first><last>Hammoudeh</last></author>
      <author><first>Daniel</first><last>Lowd</last></author>
      <pages>12499-12527</pages>
      <abstract>Backdoor attacks manipulate model predictions by inserting innocuous triggers into training and test data. We focus on more realistic and more challenging clean-label attacks where the adversarial training examples are correctly labeled. Our attack, LLMBkd, leverages language models to automatically insert diverse style-based triggers into texts. We also propose a poison selection technique to improve the effectiveness of both LLMBkd as well as existing textual backdoor attacks. Lastly, we describe REACT, a baseline defense to mitigate backdoor attacks via antidote training examples. Our evaluations demonstrate LLMBkd’s effectiveness and efficiency, where we consistently achieve high attack success rates across a wide range of styles with little effort and no model training.</abstract>
      <url hash="d45c27d7">2023.findings-emnlp.833</url>
      <bibkey>you-etal-2023-large</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.833</doi>
    </paper>
    <paper id="834">
      <title>Noise-Robust Fine-Tuning of Pretrained Language Models via External Guidance</title>
      <author><first>Song</first><last>Wang</last></author>
      <author><first>Zhen</first><last>Tan</last></author>
      <author><first>Ruocheng</first><last>Guo</last></author>
      <author><first>Jundong</first><last>Li</last></author>
      <pages>12528-12540</pages>
      <abstract>Adopting a two-stage paradigm of pretraining followed by fine-tuning, Pretrained Language Models (PLMs) have achieved substantial advancements in the field of natural language processing. However, in real-world scenarios, data labels are often noisy due to the complex annotation process, making it essential to develop strategies for fine-tuning PLMs with such noisy labels. To this end, we introduce an innovative approach for fine-tuning PLMs using noisy labels, which incorporates the guidance of Large Language Models (LLMs) like ChatGPT. This guidance assists in accurately distinguishing between clean and noisy samples and provides supplementary information beyond the noisy labels, thereby boosting the learning process during fine-tuning PLMs. Extensive experiments on synthetic and real-world noisy datasets further demonstrate the superior advantages of our framework over the state-of-the-art baselines.</abstract>
      <url hash="53f60ca1">2023.findings-emnlp.834</url>
      <bibkey>wang-etal-2023-noise</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.834</doi>
    </paper>
    <paper id="835">
      <title>Probabilistic Tree-of-thought Reasoning for Answering Knowledge-intensive Complex Questions</title>
      <author><first>Shulin</first><last>Cao</last></author>
      <author><first>Jiajie</first><last>Zhang</last></author>
      <author><first>Jiaxin</first><last>Shi</last></author>
      <author><first>Xin</first><last>Lv</last></author>
      <author><first>Zijun</first><last>Yao</last></author>
      <author><first>Qi</first><last>Tian</last></author>
      <author><first>Lei</first><last>Hou</last></author>
      <author><first>Juanzi</first><last>Li</last></author>
      <pages>12541-12560</pages>
      <abstract>Large language models (LLMs) are capable of answering knowledge-intensive complex questions with chain-of-thought (CoT) reasoning. However, they tend to generate factually incorrect reasoning steps when the required knowledge is not available or up-to-date in models’ parameters. Recent works turn to retrieving external knowledge to augment CoT reasoning. Despite being promising, these chain-based methods suffer from: 1) Negative retrieval. Unnecessary or incorrect retrieval may mislead the reasoning; 2) Limited sight. Lacking the ability to look backward or forward, a local error in one step will propagate along the chain. In this paper, we propose a novel approach: Probabilistic Tree-of-thought Reasoning (ProbTree). First, LLMs translate a complex question into a query tree, in which each non-root node denotes a sub-question of its parent node. Then, probabilistic reasoning is conducted over the tree, by solving questions from leaf to root considering the confidence of both question decomposing and answering. During reasoning, for leaf nodes, LLMs choose a more confident answer from Closed-book QA that employs parametric knowledge and Open-book QA that employs retrieved external knowledge, thus eliminating the negative retrieval problem. For non-leaf nodes, with the hierarchical structure, LLMs have broader sights and are able to globally reason with the information from child nodes, thus recovering from local errors. The experiments on three Complex QA datasets under the open-domain setting show that our approach outperforms SOTA methods significantly, demonstrating the effect of probabilistic tree-of-thought reasoning.</abstract>
      <url hash="a184c390">2023.findings-emnlp.835</url>
      <bibkey>cao-etal-2023-probabilistic</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.835</doi>
    </paper>
    <paper id="836">
      <title>Ensemble-Instruct: Instruction Tuning Data Generation with a Heterogeneous Mixture of <fixed-case>LM</fixed-case>s</title>
      <author><first>Young-Suk</first><last>Lee</last></author>
      <author><first>Md</first><last>Sultan</last></author>
      <author><first>Yousef</first><last>El-Kurdi</last></author>
      <author><first>Tahira</first><last>Naseem</last></author>
      <author><first>Asim</first><last>Munawar</last></author>
      <author><first>Radu</first><last>Florian</last></author>
      <author><first>Salim</first><last>Roukos</last></author>
      <author><first>Ramón</first><last>Astudillo</last></author>
      <pages>12561-12571</pages>
      <abstract>Using in-context learning (ICL) for data generation, techniques such as Self-Instruct (Wang et al., 2023) or the follow-up Alpaca (Taori et al., 2023) can train strong conversational agents with only a small amount of human supervision. One limitation of these approaches is that they resort to very large language models (around 175B parameters) that are also proprietary and non-public. Here we explore the application of such techniques to language models that are much smaller (around 10B–40B parameters) and have permissive licenses. We find the Self-Instruct approach to be less effective at these sizes and propose new ICL methods that draw on two main ideas: (a) categorization and simplification of the ICL templates to make prompt learning easier for the LM, and (b) ensembling over multiple LM outputs to help select high-quality synthetic examples. Our algorithm leverages the 175 Self-Instruct seed tasks and employs separate pipelines for instructions that require an input and instructions that do not. Empirical investigations with different LMs show that: (1) Our proposed method yields higher-quality instruction tuning data than Self-Instruct, (2) It improves performances of both vanilla and instruction-tuned LMs by significant margins, and (3) Smaller instruction-tuned LMs generate more useful examples than their larger un-tuned counterparts.</abstract>
      <url hash="2c7e28c2">2023.findings-emnlp.836</url>
      <bibkey>lee-etal-2023-ensemble</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.836</doi>
    </paper>
    <paper id="837">
      <title>The Less the Merrier? Investigating Language Representation in Multilingual Models</title>
      <author><first>Hellina</first><last>Nigatu</last></author>
      <author><first>Atnafu</first><last>Tonja</last></author>
      <author><first>Jugal</first><last>Kalita</last></author>
      <pages>12572-12589</pages>
      <abstract>Multilingual Language Models offer a way to incorporate multiple languages in one model and utilize cross-language transfer learning to improve performance for different Natural Language Processing (NLP) tasks. Despite progress in multilingual models, not all languages are supported as well, particularly in low-resource settings. In this work, we investigate the linguistic representation of different languages in multilingual models. We start by asking the question which languages are supported in popular multilingual models and which languages are left behind. Then, for included languages, we look at models’ learned representations based on language family and dialect and try to understand how models’ learned representations for (1) seen and (2) unseen languages vary across different language groups. In addition, we test and analyze performance on downstream tasks such as text generation and Named Entity Recognition. We observe from our experiments that community-centered models—models that focus on languages of a given family or geographical location and are built by communities who speak them—perform better at distinguishing between languages in the same family for low-resource languages. Our paper contributes to the literature in understanding multilingual models and their shortcomings and offers insights on potential ways to improve them.</abstract>
      <url hash="26b9d6eb">2023.findings-emnlp.837</url>
      <bibkey>nigatu-etal-2023-less</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.837</doi>
    </paper>
    <paper id="838">
      <title><fixed-case>S</fixed-case>uper<fixed-case>T</fixed-case>weet<fixed-case>E</fixed-case>val: A Challenging, Unified and Heterogeneous Benchmark for Social Media <fixed-case>NLP</fixed-case> Research</title>
      <author><first>Dimosthenis</first><last>Antypas</last></author>
      <author><first>Asahi</first><last>Ushio</last></author>
      <author><first>Francesco</first><last>Barbieri</last></author>
      <author><first>Leonardo</first><last>Neves</last></author>
      <author><first>Kiamehr</first><last>Rezaee</last></author>
      <author><first>Luis</first><last>Espinosa-Anke</last></author>
      <author><first>Jiaxin</first><last>Pei</last></author>
      <author><first>Jose</first><last>Camacho-Collados</last></author>
      <pages>12590-12607</pages>
      <abstract>Despite its relevance, the maturity of NLP for social media pales in comparison with general-purpose models, metrics and benchmarks. This fragmented landscape makes it hard for the community to know, for instance, given a task, which is the best performing model and how it compares with others. To alleviate this issue, we introduce a unified benchmark for NLP evaluation in social media, SuperTweetEval, which includes a heterogeneous set of tasks and datasets combined, adapted and constructed from scratch. We benchmarked the performance of a wide range of models on SuperTweetEval and our results suggest that, despite the recent advances in language modelling, social media remains challenging.</abstract>
      <url hash="7ac25c93">2023.findings-emnlp.838</url>
      <bibkey>antypas-etal-2023-supertweeteval</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.838</doi>
    </paper>
    <paper id="839">
      <title>Enabling Unsupervised Neural Machine Translation with Word-level Visual Representations</title>
      <author><first>Chengpeng</first><last>Fu</last></author>
      <author><first>Xiaocheng</first><last>Feng</last></author>
      <author><first>Yichong</first><last>Huang</last></author>
      <author><first>Wenshuai</first><last>Huo</last></author>
      <author><first>Hui</first><last>Wang</last></author>
      <author><first>Bing</first><last>Qin</last></author>
      <author><first>Ting</first><last>Liu</last></author>
      <pages>12608-12618</pages>
      <abstract>Unsupervised neural machine translation has recently made remarkable strides, achieving impressive results with the exclusive use of monolingual corpora. Nonetheless, these methods still exhibit fundamental flaws, such as confusing similar words. A straightforward remedy to rectify this drawback is to employ bilingual dictionaries, however, high-quality bilingual dictionaries can be costly to obtain. To overcome this limitation, we propose a method that incorporates images at the word level to augment the lexical mappings. Specifically, our method inserts visual representations into the model, modifying the corresponding embedding layer information. Besides, a visible matrix is adopted to isolate the impact of images on other unrelated words. Experiments on the Multi30k dataset with over 300,000 self-collected images validate the effectiveness in generating more accurate word translation, achieving an improvement of up to <tex-math>+</tex-math>2.81 BLEU score, which is comparable or even superior to using bilingual dictionaries.</abstract>
      <url hash="d021b61e">2023.findings-emnlp.839</url>
      <bibkey>fu-etal-2023-enabling</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.839</doi>
    </paper>
    <paper id="840">
      <title>Pragmatics in Language Grounding: Phenomena, Tasks, and Modeling Approaches</title>
      <author><first>Daniel</first><last>Fried</last></author>
      <author><first>Nicholas</first><last>Tomlin</last></author>
      <author><first>Jennifer</first><last>Hu</last></author>
      <author><first>Roma</first><last>Patel</last></author>
      <author><first>Aida</first><last>Nematzadeh</last></author>
      <pages>12619-12640</pages>
      <abstract>People rely heavily on context to enrich meaning beyond what is literally said, enabling concise but effective communication. To interact successfully and naturally with people, user-facing artificial intelligence systems will require similar skills in pragmatics: relying on various types of context — from shared linguistic goals and conventions, to the visual and embodied world — to use language effectively. We survey existing grounded settings and pragmatic modeling approaches and analyze how the task goals, environmental contexts, and communicative affordances in each work enrich linguistic meaning. We present recommendations for future grounded task design to naturally elicit pragmatic phenomena, and suggest directions that focus on a broader range of communicative contexts and affordances.</abstract>
      <url hash="234cf732">2023.findings-emnlp.840</url>
      <bibkey>fried-etal-2023-pragmatics</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.840</doi>
    </paper>
    <paper id="841">
      <title><fixed-case>MISCA</fixed-case>: A Joint Model for Multiple Intent Detection and Slot Filling with Intent-Slot Co-Attention</title>
      <author><first>Thinh</first><last>Pham</last></author>
      <author><first>Chi</first><last>Tran</last></author>
      <author><first>Dat Quoc</first><last>Nguyen</last></author>
      <pages>12641-12650</pages>
      <abstract>The research study of detecting multiple intents and filling slots is becoming more popular because of its relevance to complicated real-world situations. Recent advanced approaches, which are joint models based on graphs, might still face two potential issues: (i) the uncertainty introduced by constructing graphs based on preliminary intents and slots, which may transfer intent-slot correlation information to incorrect label node destinations, and (ii) direct incorporation of multiple intent labels for each token w.r.t. token-level intent voting might potentially lead to incorrect slot predictions, thereby hurting the overall performance. To address these two issues, we propose a joint model named MISCA. Our MISCA introduces an intent-slot co-attention mechanism and an underlying layer of label attention mechanism. These mechanisms enable MISCA to effectively capture correlations between intents and slot labels, eliminating the need for graph construction. They also facilitate the transfer of correlation information in both directions: from intents to slots and from slots to intents, through multiple levels of label-specific representations, without relying on token-level intent information. Experimental results show that MISCA outperforms previous models, achieving new state-of-the-art overall accuracy performances on two benchmark datasets MixATIS and MixSNIPS. This highlights the effectiveness of our attention mechanisms.</abstract>
      <url hash="3fca8694">2023.findings-emnlp.841</url>
      <bibkey>pham-etal-2023-misca</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.841</doi>
    </paper>
    <paper id="842">
      <title>Enhancing Emotion Recognition in Conversation via Multi-view Feature Alignment and Memorization</title>
      <author><first>Guiyang</first><last>Hou</last></author>
      <author><first>Yongliang</first><last>Shen</last></author>
      <author><first>Wenqi</first><last>Zhang</last></author>
      <author><first>Wei</first><last>Xue</last></author>
      <author><first>Weiming</first><last>Lu</last></author>
      <pages>12651-12663</pages>
      <abstract>Emotion recognition in conversation (ERC) has attracted increasing attention in natural language processing community. Previous work commonly first extract semantic-view features via fine-tuning PLMs, then models context-view features based on the obtained semantic-view features by various graph neural networks. However, it is difficult to fully model interaction between utterances simply through a graph neural network and the features at semantic-view and context-view are not well aligned. Moreover, the previous parametric learning paradigm struggle to learn the patterns of tail class given fewer instances. To this end, we treat the pre-trained conversation model as a prior knowledge base and from which we elicit correlations between utterances by a probing procedure. And we adopt supervised contrastive learning to align semantic-view and context-view features, these two views of features work together in a complementary manner, contributing to ERC from distinct perspectives. Meanwhile, we propose a new semi-parametric paradigm of inferencing through memorization to solve the recognition problem of tail class samples. We consistently achieve state-of-the-art results on four widely used benchmarks. Extensive experiments demonstrate the effectiveness of our proposed multi-view feature alignment and memorization.</abstract>
      <url hash="b441f7fe">2023.findings-emnlp.842</url>
      <bibkey>hou-etal-2023-enhancing</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.842</doi>
    </paper>
    <paper id="843">
      <title><fixed-case>M</fixed-case>andarin classifier systems optimize to accommodate communicative pressures</title>
      <author><first>Yamei</first><last>Wang</last></author>
      <author><first>Géraldine</first><last>Walther</last></author>
      <pages>12664-12674</pages>
      <abstract>Previous work on noun classification implies that gender systems are inherently optimized to accommodate communicative pressures on human language learning and processing (Dye. et al 2017, 2018). They state that languages make use of either grammatical (e.g., gender) or probabilistic (pre-nominal modifiers) to smoothe the entropy of nouns in context. We show that even languages that are considered genderless, like Mandarin Chinese, possess a noun classification device that plays the same functional role as gender markers. Based on close to 1M Mandarin noun phrases extracted from the Leipzig Corpora Collection (Goldhahn et al. 2012) and their corresponding fastText embeddings (Bojanowski et al. 2016), we show that noun-classifier combinations are sensitive to same frequency, similarity, and co-occurrence interactions that structure gender systems. We also present the first study of the effects of the interaction between grammatical and probabilisitic noun classification.</abstract>
      <url hash="31ed9d9a">2023.findings-emnlp.843</url>
      <bibkey>wang-walther-2023-mandarin</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.843</doi>
    </paper>
    <paper id="844">
      <title>Probing Representations for Document-level Event Extraction</title>
      <author><first>Barry</first><last>Wang</last></author>
      <author><first>Xinya</first><last>Du</last></author>
      <author><first>Claire</first><last>Cardie</last></author>
      <pages>12675-12683</pages>
      <abstract>The probing classifiers framework has been employed for interpreting deep neural network models for a variety of natural language processing (NLP) applications. Studies, however, have largely focused on sentencelevel NLP tasks. This work is the first to apply the probing paradigm to representations learned for document-level information extraction (IE). We designed eight embedding probes to analyze surface, semantic, and event-understanding capabilities relevant to document-level event extraction. We apply them to the representations acquired by learning models from three different LLM-based document-level IE approaches on a standard dataset. We found that trained encoders from these models yield embeddings that can modestly improve argument detections and labeling but only slightly enhance event-level tasks, albeit trade-offs in information helpful for coherence and event-type prediction. We further found that encoder models struggle with document length and cross-sentence discourse.</abstract>
      <url hash="5bfbf3a1">2023.findings-emnlp.844</url>
      <bibkey>wang-etal-2023-probing</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.844</doi>
    </paper>
    <paper id="845">
      <title>Cultural Compass: Predicting Transfer Learning Success in Offensive Language Detection with Cultural Features</title>
      <author><first>Li</first><last>Zhou</last></author>
      <author><first>Antonia</first><last>Karamolegkou</last></author>
      <author><first>Wenyu</first><last>Chen</last></author>
      <author><first>Daniel</first><last>Hershcovich</last></author>
      <pages>12684-12702</pages>
      <abstract>The increasing ubiquity of language technology necessitates a shift towards considering cultural diversity in the machine learning realm, particularly for subjective tasks that rely heavily on cultural nuances, such as Offensive Language Detection (OLD). Current understanding underscores that these tasks are substantially influenced by cultural values, however, a notable gap exists in determining if cultural features can accurately predict the success of cross-cultural transfer learning for such subjective tasks. Addressing this, our study delves into the intersection of cultural features and transfer learning effectiveness. The findings reveal that cultural value surveys indeed possess a predictive power for cross-cultural transfer learning success in OLD tasks, and that it can be further improved using offensive word distance. Based on these results, we advocate for the integration of cultural information into datasets. Additionally, we recommend leveraging data sources rich in cultural information, such as surveys, to enhance cultural adaptability. Our research signifies a step forward in the quest for more inclusive, culturally sensitive language technologies.</abstract>
      <url hash="ee960ef1">2023.findings-emnlp.845</url>
      <bibkey>zhou-etal-2023-cultural</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.845</doi>
    </paper>
    <paper id="846">
      <title>Linguistically Motivated Sign Language Segmentation</title>
      <author><first>Amit</first><last>Moryossef</last></author>
      <author><first>Zifan</first><last>Jiang</last></author>
      <author><first>Mathias</first><last>Müller</last></author>
      <author><first>Sarah</first><last>Ebling</last></author>
      <author><first>Yoav</first><last>Goldberg</last></author>
      <pages>12703-12724</pages>
      <abstract>Sign language segmentation is a crucial task in sign language processing systems. It enables downstream tasks such as sign recognition, transcription, and machine translation. In this work, we consider two kinds of segmentation: segmentation into individual signs and segmentation into <i>phrases</i>, larger units comprising several signs. We propose a novel approach to jointly model these two tasks. Our method is motivated by linguistic cues observed in sign language corpora. We replace the predominant IO tagging scheme with BIO tagging to account for continuous signing. Given that prosody plays a significant role in phrase boundaries, we explore the use of optical flow features. We also provide an extensive analysis of hand shapes and 3D hand normalization. We find that introducing BIO tagging is necessary to model sign boundaries. Explicitly encoding prosody by optical flow improves segmentation in shallow models, but its contribution is negligible in deeper models. Careful tuning of the decoding algorithm atop the models further improves the segmentation quality. We demonstrate that our final models generalize to out-of-domain video content in a different signed language, even under a zero-shot setting. We observe that including optical flow and 3D hand normalization enhances the robustness of the model in this context.</abstract>
      <url hash="1bc12be7">2023.findings-emnlp.846</url>
      <bibkey>moryossef-etal-2023-linguistically</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.846</doi>
    </paper>
    <paper id="847">
      <title>Re-weighting Tokens: A Simple and Effective Active Learning Strategy for Named Entity Recognition</title>
      <author><first>Haocheng</first><last>Luo</last></author>
      <author><first>Wei</first><last>Tan</last></author>
      <author><first>Ngoc</first><last>Nguyen</last></author>
      <author><first>Lan</first><last>Du</last></author>
      <pages>12725-12734</pages>
      <abstract>Active learning, a widely adopted technique for enhancing machine learning models in text and image classification tasks with limited annotation resources, has received relatively little attention in the domain of Named Entity Recognition (NER). The challenge of data imbalance in NER has hindered the effectiveness of active learning, as sequence labellers lack sufficient learning signals. To address these challenges, this paper presents a novel re-weighting-based active learning strategy that assigns dynamic smoothing weights to individual tokens. This adaptable strategy is compatible with various token-level acquisition functions and contributes to the development of robust active learners. Experimental results on multiple corpora demonstrate the substantial performance improvement achieved by incorporating our re-weighting strategy into existing acquisition functions, validating its practical efficacy. We will release our implementation upon the publication of this paper.</abstract>
      <url hash="66ba9d4d">2023.findings-emnlp.847</url>
      <bibkey>luo-etal-2023-weighting</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.847</doi>
    </paper>
    <paper id="848">
      <title>Language-Agnostic Bias Detection in Language Models with Bias Probing</title>
      <author><first>Abdullatif</first><last>Köksal</last></author>
      <author><first>Omer</first><last>Yalcin</last></author>
      <author><first>Ahmet</first><last>Akbiyik</last></author>
      <author><first>M.</first><last>Kilavuz</last></author>
      <author><first>Anna</first><last>Korhonen</last></author>
      <author><first>Hinrich</first><last>Schuetze</last></author>
      <pages>12735-12747</pages>
      <abstract>Pretrained language models (PLMs) are key components in NLP, but they contain strong social biases. Quantifying these biases is challenging because current methods focusing on fill-the-mask objectives are sensitive to slight changes in input. To address this, we propose a bias probing technique called LABDet, for evaluating social bias in PLMs with a robust and language-agnostic method. For nationality as a case study, we show that LABDet “surfaces” nationality bias by training a classifier on top of a frozen PLM on non-nationality sentiment detection. We find consistent patterns of nationality bias across monolingual PLMs in six languages that align with historical and political context. We also show for English BERT that bias surfaced by LABDet correlates well with bias in the pretraining data; thus, our work is one of the few studies that directly links pretraining data to PLM behavior. Finally, we verify LABDet’s reliability and applicability to different templates and languages through an extensive set of robustness checks. We publicly share our code and dataset in https://github.com/akoksal/LABDet.</abstract>
      <url hash="8ff8051d">2023.findings-emnlp.848</url>
      <bibkey>koksal-etal-2023-language</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.848</doi>
    </paper>
    <paper id="849">
      <title><fixed-case>C</fixed-case>omple<fixed-case>QA</fixed-case>: Benchmarking the Impacts of Knowledge Graph Completion Methods on Question Answering</title>
      <author><first>Donghan</first><last>Yu</last></author>
      <author><first>Yu</first><last>Gu</last></author>
      <author><first>Chenyan</first><last>Xiong</last></author>
      <author><first>Yiming</first><last>Yang</last></author>
      <pages>12748-12755</pages>
      <abstract>How much success in Knowledge Graph Completion (KGC) would translate into the performance enhancement in downstream tasks is an important question that has not been studied in depth. In this paper, we introduce a novel benchmark, namely CompleQA, to comprehensively assess the influence of representative KGC methods on Knowledge Graph Question Answering (KGQA), one of the most important downstream applications. This benchmark includes a knowledge graph with 3 million triplets across 5 distinct domains, coupled with over 5000 question-answering pairs and a completion dataset that is well-aligned with these questions. Our evaluation of four well-known KGC methods in combination with two state-of-the-art KGQA systems shows that effective KGC can significantly mitigate the impact of knowledge graph incompleteness on question-answering performance. Surprisingly, we also find that the best-performing KGC method(s) does not necessarily lead to the best QA results, underscoring the need to consider downstream applications when doing KGC.</abstract>
      <url hash="406cf568">2023.findings-emnlp.849</url>
      <bibkey>yu-etal-2023-compleqa</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.849</doi>
    </paper>
    <paper id="850">
      <title>Improving Multi-Criteria <fixed-case>C</fixed-case>hinese Word Segmentation through Learning Sentence Representation</title>
      <author><first>Chun</first><last>Lin</last></author>
      <author><first>Ying-Jia</first><last>Lin</last></author>
      <author><first>Chia-Jen</first><last>Yeh</last></author>
      <author><first>Yi-Ting</first><last>Li</last></author>
      <author><first>Ching</first><last>Yang</last></author>
      <author><first>Hung-Yu</first><last>Kao</last></author>
      <pages>12756-12763</pages>
      <abstract>Recent Chinese word segmentation (CWS) models have shown competitive performance with pre-trained language models’ knowledge. However, these models tend to learn the segmentation knowledge through in-vocabulary words rather than understanding the meaning of the entire context. To address this issue, we introduce a context-aware approach that incorporates unsupervised sentence representation learning over different dropout masks into the multi-criteria training framework. We demonstrate that our approach reaches state-of-the-art (SoTA) performance on F1 scores for six of the nine CWS benchmark datasets and out-of-vocabulary (OOV) recalls for eight of nine. Further experiments discover that substantial improvements can be brought with various sentence representation objectives.</abstract>
      <url hash="eb3ba1f0">2023.findings-emnlp.850</url>
      <bibkey>lin-etal-2023-improving</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.850</doi>
    </paper>
    <paper id="851">
      <title>A Joint Matrix Factorization Analysis of Multilingual Representations</title>
      <author><first>Zheng</first><last>Zhao</last></author>
      <author><first>Yftah</first><last>Ziser</last></author>
      <author><first>Bonnie</first><last>Webber</last></author>
      <author><first>Shay</first><last>Cohen</last></author>
      <pages>12764-12783</pages>
      <abstract>We present an analysis tool based on joint matrix factorization for comparing latent representations of multilingual and monolingual models. An alternative to probing, this tool allows us to analyze multiple sets of representations in a joint manner. Using this tool, we study to what extent and how morphosyntactic features are reflected in the representations learned by multilingual pre-trained models. We conduct a large-scale empirical study of over 33 languages and 17 morphosyntactic categories. Our findings demonstrate variations in the encoding of morphosyntactic information across upper and lower layers, with category-specific differences influenced by language properties. Hierarchical clustering of the factorization outputs yields a tree structure that is related to phylogenetic trees manually crafted by linguists. Moreover, we find the factorization outputs exhibit strong associations with performance observed across different cross-lingual tasks. We release our code to facilitate future research.</abstract>
      <url hash="dff83051">2023.findings-emnlp.851</url>
      <bibkey>zhao-etal-2023-joint</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.851</doi>
    </paper>
    <paper id="852">
      <title>Don’t Add, don’t Miss: Effective Content Preserving Generation from Pre-Selected Text Spans</title>
      <author><first>Aviv</first><last>Slobodkin</last></author>
      <author><first>Avi</first><last>Caciularu</last></author>
      <author><first>Eran</first><last>Hirsch</last></author>
      <author><first>Ido</first><last>Dagan</last></author>
      <pages>12784-12800</pages>
      <abstract>The recently introduced Controlled Text Reduction (CTR) task isolates the text generation step within typical summarization-style tasks. It does so by challenging models to generate coherent text conforming to pre-selected content within the input text (“highlights”). This framing enables increased modularity in summarization-like tasks, allowing to couple a single CTR model with various content-selection setups and modules. However, there are currently no reliable CTR models, while the performance of the existing baseline for the task is mediocre, falling short of practical utility. Here, we address this gap by introducing a high-quality, open-source CTR model that tackles two prior key limitations: inadequate enforcement of the content-preservation constraint, and suboptimal silver training data. Addressing these, we amplify the content-preservation constraint in both training, via RL, and inference, via a controlled decoding strategy. Further, we substantially improve the silver training data quality via GPT-4 distillation. Overall, pairing the distilled dataset with the highlight-adherence strategies yields marked gains over the current baseline, of up to 30 ROUGE-L points, providing a reliable CTR model for downstream use.</abstract>
      <url hash="04268526">2023.findings-emnlp.852</url>
      <bibkey>slobodkin-etal-2023-dont</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.852</doi>
    </paper>
    <paper id="853">
      <title>A Computational Interface to Translate Strategic Intent from Unstructured Language in a Low-Data Setting</title>
      <author><first>Pradyumna</first><last>Tambwekar</last></author>
      <author><first>Lakshita</first><last>Dodeja</last></author>
      <author><first>Nathan</first><last>Vaska</last></author>
      <author><first>Wei</first><last>Xu</last></author>
      <author><first>Matthew</first><last>Gombolay</last></author>
      <pages>12801-12819</pages>
      <abstract>Many real-world tasks involve a mixed-initiative setup, wherein humans and AI systems collaboratively perform a task. While significant work has been conducted towards enabling humans to specify, through language, exactly how an agent should complete a task (i.e., low-level specification), prior work lacks on interpreting the high-level strategic intent of the human commanders. Parsing strategic intent from language will allow autonomous systems to independently operate according to the user’s plan without frequent guidance or instruction. In this paper, we build a computational interface capable of translating unstructured language strategies into actionable intent in the form of goals and constraints. Leveraging a game environment, we collect a dataset of over 1000 examples, mapping language strategies to the corresponding goals and constraints, and show that our model, trained on this dataset, significantly outperforms human interpreters in inferring strategic intent (i.e., goals and constraints) from language (p &lt; 0.05). Furthermore, we show that our model (125M parameters) significantly outperforms ChatGPT for this task (p &lt; 0.05) in a low-data setting.</abstract>
      <url hash="344ea665">2023.findings-emnlp.853</url>
      <bibkey>tambwekar-etal-2023-computational</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.853</doi>
    </paper>
    <paper id="854">
      <title><fixed-case>HFMRE</fixed-case>: Constructing <fixed-case>H</fixed-case>uffman Tree in Bags to Find Excellent Instances for Distantly Supervised Relation Extraction</title>
      <author><first>Min</first><last>Li</last></author>
      <author><first>Cong</first><last>Shao</last></author>
      <author><first>Gang</first><last>Li</last></author>
      <author><first>Mingle</first><last>Zhou</last></author>
      <pages>12820-12832</pages>
      <abstract>Since the introduction of distantly supervised relation extraction methods, numerous approaches have been developed, the most representative of which is multi-instance learning (MIL). To find reliable features that are most representative of multi-instance bags, aggregation strategies such as AVG (average), ONE (at least one), and ATT (sentence-level attention) are commonly used. These strategies tend to train third-party vectors to select sentence-level features, leaving it to the third party to decide/identify what is noise, ignoring the intrinsic associations that naturally exist from sentence to sentence. In this paper, we propose the concept of circular cosine similarity, which is used to explicitly show the intrinsic associations between sentences within a bag. We also consider the previous methods to be a crude denoising process as they are interrupted and do not have a continuous noise detection procedure. Following this consideration, we implement a relation extraction framework (HFMRE) that relies on the Huffman tree, where sentences are considered as leaf nodes and circular cosine similarity are considered as node weights. HFMRE can continuously and iteratively discriminate noise and aggregated features during the construction of the Huffman tree, eventually finding an excellent instance that is representative of a bag-level feature. The experiments demonstrate the remarkable effectiveness of our method, outperforming previously advanced baselines on the popular DSRE datasets.</abstract>
      <url hash="db5ecdb9">2023.findings-emnlp.854</url>
      <bibkey>li-etal-2023-hfmre</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.854</doi>
    </paper>
    <paper id="855">
      <title><fixed-case>DISCO</fixed-case>: A Large Scale Human Annotated Corpus for Disfluency Correction in <fixed-case>I</fixed-case>ndo-<fixed-case>E</fixed-case>uropean Languages</title>
      <author><first>Vineet</first><last>Bhat</last></author>
      <author><first>Preethi</first><last>Jyothi</last></author>
      <author><first>Pushpak</first><last>Bhattacharyya</last></author>
      <pages>12833-12857</pages>
      <abstract>Disfluency correction (DC) is the process of removing disfluent elements like fillers, repetitions and corrections from spoken utterances to create readable and interpretable text. DC is a vital post-processing step applied to Automatic Speech Recognition (ASR) outputs, before subsequent processing by downstream language understanding tasks. Existing DC research has primarily focused on English due to the unavailability of large-scale open-source datasets. Towards the goal of multilingual disfluency correction, we present a high-quality human-annotated DC corpus covering four important Indo-European languages: English, Hindi, German and French. We provide extensive analysis of results of state-of-the-art DC models across all four languages obtaining F1 scores of 97.55 (English), 94.29 (Hindi), 95.89 (German) and 92.97 (French). To demonstrate the benefits of DC on downstream tasks, we show that DC leads to 5.65 points increase in BLEU scores on average when used in conjunction with a state-of-the-art Machine Translation (MT) system. We release code to run our experiments along with our annotated dataset here.</abstract>
      <url hash="edbf56ef">2023.findings-emnlp.855</url>
      <bibkey>bhat-etal-2023-disco</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.855</doi>
    </paper>
    <paper id="856">
      <title>Towards Being Parameter-Efficient: A Stratified Sparsely Activated Transformer with Dynamic Capacity</title>
      <author><first>Haoran</first><last>Xu</last></author>
      <author><first>Maha</first><last>Elbayad</last></author>
      <author><first>Kenton</first><last>Murray</last></author>
      <author><first>Jean</first><last>Maillard</last></author>
      <author><first>Vedanuj</first><last>Goswami</last></author>
      <pages>12858-12870</pages>
      <abstract>Mixture-of-experts (MoE) models that employ sparse activation have demonstrated effectiveness in significantly increasing the number of parameters while maintaining low computational requirements per token. However, recent studies have established that MoE models are inherently parameter-inefficient as the improvement in performance diminishes with an increasing number of experts. We hypothesize this parameter inefficiency is a result of all experts having equal capacity, which may not adequately meet the varying complexity requirements of different tokens or tasks. In light of this, we propose Stratified Mixture of Experts (SMoE) models, which feature a stratified structure and can assign dynamic capacity to different tokens. We demonstrate the effectiveness of SMoE on three multilingual machine translation benchmarks, containing 4, 15, and 94 language pairs, respectively. We show that SMoE outperforms multiple state-of-the-art MoE models with the same or fewer parameters.</abstract>
      <url hash="5e347a33">2023.findings-emnlp.856</url>
      <bibkey>xu-etal-2023-towards-parameter</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.856</doi>
    </paper>
    <paper id="857">
      <title>Misery Loves Complexity: Exploring Linguistic Complexity in the Context of Emotion Detection</title>
      <author><first>Pranaydeep</first><last>Singh</last></author>
      <author><first>Luna</first><last>De Bruyne</last></author>
      <author><first>Orphée</first><last>De Clercq</last></author>
      <author><first>Els</first><last>Lefever</last></author>
      <pages>12871-12880</pages>
      <abstract>Given the omnipresence of social media in our society, thoughts and opinions are being shared online in an unprecedented manner. This means that both positive and negative emotions can be equally and freely expressed. However, the negativity bias posits that human beings are inherently drawn to and more moved by negativity and, as a consequence, negative emotions get more traffic. Correspondingly, when writing about emotions this negativity bias could lead to expressions of negative emotions that are linguistically more complex. In this paper, we attempt to use readability and linguistic complexity metrics to better understand the manifestation of emotions on social media platforms like Reddit based on the widely-used GoEmotions dataset. We demonstrate that according to most metrics, negative emotions indeed tend to generate more complex text than positive emotions. In addition, we examine whether a higher complexity hampers the automatic identification of emotions. To answer this question, we fine-tuned three state-of-the-art transformers (BERT, RoBERTa, and SpanBERT) on the same emotion detection dataset. We demonstrate that these models often fail to predict emotions for the more complex texts. More advanced LLMs like RoBERTa and SpanBERT also fail to improve by significant margins on complex samples. This calls for a more nuanced interpretation of the emotion detection performance of transformer models. We make the automatically annotated data available for further research at: https://huggingface.co/datasets/pranaydeeps/CAMEO</abstract>
      <url hash="d6349f77">2023.findings-emnlp.857</url>
      <bibkey>singh-etal-2023-misery</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.857</doi>
    </paper>
    <paper id="858">
      <title>Probing the “Creativity” of Large Language Models: Can models produce divergent semantic association?</title>
      <author><first>Honghua</first><last>Chen</last></author>
      <author><first>Nai</first><last>Ding</last></author>
      <pages>12881-12888</pages>
      <abstract>Large language models possess remarkable capacity for processing language, but it remains unclear whether these models can further generate creative content. The present study aims to investigate the creative thinking of large language models through a cognitive perspective. We utilize the divergent association task (DAT), an objective measurement of creativity that asks models to generate unrelated words and calculates the semantic distance between them. We compare the results across different models and decoding strategies. Our findings indicate that: (1) When using the greedy search strategy, GPT-4 outperforms 96% of humans, while GPT-3.5-turbo exceeds the average human level. (2) Stochastic sampling and temperature scaling are effective to obtain higher DAT scores for models except GPT-4, but face a trade-off between creativity and stability. These results imply that advanced large language models have divergent semantic associations, which is a fundamental process underlying creativity.</abstract>
      <url hash="a04b368a">2023.findings-emnlp.858</url>
      <bibkey>chen-ding-2023-probing</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.858</doi>
    </paper>
    <paper id="859">
      <title>Code-Switching with Word Senses for Pretraining in Neural Machine Translation</title>
      <author><first>Vivek</first><last>Iyer</last></author>
      <author><first>Edoardo</first><last>Barba</last></author>
      <author><first>Alexandra</first><last>Birch</last></author>
      <author><first>Jeff</first><last>Pan</last></author>
      <author><first>Roberto</first><last>Navigli</last></author>
      <pages>12889-12901</pages>
      <abstract>Lexical ambiguity is a significant and pervasive challenge in Neural Machine Translation (NMT), with many state-of-the-art (SOTA) NMT systems struggling to handle polysemous words (Campolungo et al., 2022). The same holds for the NMT pretraining paradigm of denoising synthetic “code-switched” text (Pan et al., 2021; Iyer et al., 2023), where word senses are ignored in the noising stage – leading to harmful sense biases in the pretraining data that are subsequently inherited by the resulting models. In this work, we introduce Word Sense Pretraining for Neural Machine Translation (WSP-NMT) - an end-to-end approach for pretraining multilingual NMT models leveraging word sense-specific information from Knowledge Bases. Our experiments show significant improvements in overall translation quality. Then, we show the robustness of our approach to scale to various challenging data and resource-scarce scenarios and, finally, report fine-grained accuracy improvements on the DiBiMT disambiguation benchmark. Our studies yield interesting and novel insights into the merits and challenges of integrating word sense information and structured knowledge in multilingual pretraining for NMT.</abstract>
      <url hash="5f8a5912">2023.findings-emnlp.859</url>
      <bibkey>iyer-etal-2023-code</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.859</doi>
    </paper>
    <paper id="860">
      <title><fixed-case>D</fixed-case>iffusion<fixed-case>SL</fixed-case>: Sequence Labeling via Tag Diffusion Process</title>
      <author><first>Ziyang</first><last>Huang</last></author>
      <author><first>Pengfei</first><last>Cao</last></author>
      <author><first>Jun</first><last>Zhao</last></author>
      <author><first>Kang</first><last>Liu</last></author>
      <pages>12902-12920</pages>
      <abstract>Sequence Labeling (SL) is long-standing in Natural Language Processing (NLP). Traditionally, discriminative models have been widely used to capture the conditional distribution of sequence tags, rather than generative models. In this paper, we present DiffusionSL, a framework that utilizes a conditional discrete diffusion model for generating discrete tag data, resulting in a Tag Diffusion Process. We treat the natural language sequence as the conditional signal and the sequence tags as the generation target, iteratively refining the noisy tags to obtain clean ones. To address the discreteness issue, we propose the Bit-Tag Converter (BTConverter) to model the target in continuous data space. Furthermore, we introduce the Bit Diffusion Transformer (BitDiT) to model the process of noise elimination. Leveraging the powerful iterative refinement capability of the diffusion model, DiffusionSL achieves superior performance against previous state-of-the-art (SOTA) baselines and outperforms gpt-3.5-turbo significantly across multiple benchmark datasets and various tasks.</abstract>
      <url hash="e45a15d9">2023.findings-emnlp.860</url>
      <bibkey>huang-etal-2023-diffusionsl</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.860</doi>
    </paper>
    <paper id="861">
      <title><fixed-case>COMET</fixed-case>-<fixed-case>M</fixed-case>: Reasoning about Multiple Events in Complex Sentences</title>
      <author><first>Sahithya</first><last>Ravi</last></author>
      <author><first>Raymond</first><last>Ng</last></author>
      <author><first>Vered</first><last>Shwartz</last></author>
      <pages>12921-12937</pages>
      <abstract>Understanding the speaker’s intended meaning often involves drawing commonsense inferences to reason about what is not stated explicitly. In multi-event sentences, it requires understanding the relationships between events based on contextual knowledge. We propose COMET-M (Multi-Event), an event-centric commonsense model capable of generating commonsense inferences for a target event within a complex sentence. COMET-M builds upon COMET (Bosselut et al., 2019), which excels at generating event-centric inferences for simple sentences, but struggles with the complexity of multi-event sentences prevalent in natural text. To overcome this limitation, we curate a Multi-Event Inference (MEI) dataset of 35K human-written inferences. We train COMET-M on the human-written inferences and also create baselines using automatically labeled examples. Experimental results demonstrate the significant performance improvement of COMET-M over COMET in generating multi-event inferences. Moreover, COMET-M successfully produces distinct inferences for each target event, taking the complete context into consideration. COMET-M holds promise for downstream tasks involving natural text such as coreference resolution, dialogue, and story understanding.</abstract>
      <url hash="024707eb">2023.findings-emnlp.861</url>
      <bibkey>ravi-etal-2023-comet</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.861</doi>
    </paper>
    <paper id="862">
      <title>On Event Individuation for Document-Level Information Extraction</title>
      <author><first>William</first><last>Gantt</last></author>
      <author><first>Reno</first><last>Kriz</last></author>
      <author><first>Yunmo</first><last>Chen</last></author>
      <author><first>Siddharth</first><last>Vashishtha</last></author>
      <author><first>Aaron</first><last>White</last></author>
      <pages>12938-12958</pages>
      <abstract>As information extraction (IE) systems have grown more adept at processing whole documents, the classic task of *template filling* has seen renewed interest as a benchmark for document-level IE. In this position paper, we call into question the suitability of template filling for this purpose. We argue that the task demands definitive answers to thorny questions of *event individuation* — the problem of distinguishing distinct events — about which even human experts disagree. Through an annotation study and error analysis, we show that this raises concerns about the usefulness of template filling metrics, the quality of datasets for the task, and the ability of models to learn it. Finally, we consider possible solutions.</abstract>
      <url hash="d593c5ae">2023.findings-emnlp.862</url>
      <bibkey>gantt-etal-2023-event</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.862</doi>
    </paper>
    <paper id="863">
      <title><fixed-case>A</fixed-case>ni<fixed-case>EE</fixed-case>: A Dataset of Animal Experimental Literature for Event Extraction</title>
      <author><first>Dohee</first><last>Kim</last></author>
      <author><first>Ra</first><last>Yoo</last></author>
      <author><first>Soyoung</first><last>Yang</last></author>
      <author><first>Hee</first><last>Yang</last></author>
      <author><first>Jaegul</first><last>Choo</last></author>
      <pages>12959-12971</pages>
      <abstract>Event extraction (EE), as a crucial information extraction (IE) task, aims to identify event triggers and their associated arguments from unstructured text, subsequently classifying them into pre-defined types and roles. In the biomedical domain, EE is widely used to extract complex structures representing biological events from literature. Due to the complicated semantics and specialized domain knowledge, it is challenging to construct biomedical event extraction datasets. Additionally, most existing biomedical EE datasets primarily focus on cell experiments or the overall experimental procedures. Therefore, we introduce AniEE, an event extraction dataset concentrated on the animal experiment stage. We establish a novel animal experiment customized entity and event scheme in collaboration with domain experts. We then create an expert-annotated high-quality dataset containing discontinuous entities and nested events and evaluate our dataset on the recent outstanding NER and EE models.</abstract>
      <url hash="8dc81ef7">2023.findings-emnlp.863</url>
      <bibkey>kim-etal-2023-aniee</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.863</doi>
    </paper>
    <paper id="864">
      <title>From Words to Wires: Generating Functioning Electronic Devices from Natural Language Descriptions</title>
      <author><first>Peter</first><last>Jansen</last></author>
      <pages>12972-12990</pages>
      <abstract>In this work, we show that contemporary language models have a previously unknown skill – the capacity for electronic circuit design from high-level textual descriptions, akin to code generation. We introduce two benchmarks: PINS100, assessing model knowledge of electrical components, and MICRO25, evaluating a model’s capability to design common microcontroller circuits and code in the Arduino ecosystem that involve input, output, sensors, motors, protocols, and logic – with models such as GPT-4 and Claude-V1 achieving between 60% to 96% Pass@1 on generating full devices. We include six case studies of using language models as a design assistant for moderately complex devices, such as a radiation-powered random number generator, an emoji keyboard, a visible spectrometer, and several assistive devices, while offering a qualitative analysis performance, outlining evaluation challenges, and suggesting areas of development to improve complex circuit design and practical utility. With this work, we aim to spur research at the juncture of natural language processing and electronic design.</abstract>
      <url hash="52954b5f">2023.findings-emnlp.864</url>
      <bibkey>jansen-2023-words</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.864</doi>
    </paper>
    <paper id="865">
      <title>Data-efficient Active Learning for Structured Prediction with Partial Annotation and Self-Training</title>
      <author><first>Zhisong</first><last>Zhang</last></author>
      <author><first>Emma</first><last>Strubell</last></author>
      <author><first>Eduard</first><last>Hovy</last></author>
      <pages>12991-13008</pages>
      <abstract>In this work we propose a pragmatic method that reduces the annotation cost for structured label spaces using active learning. Our approach leverages partial annotation, which reduces labeling costs for structured outputs by selecting only the most informative sub-structures for annotation. We also utilize self-training to incorporate the current model’s automatic predictions as pseudo-labels for un-annotated sub-structures. A key challenge in effectively combining partial annotation with self-training to reduce annotation cost is determining which sub-structures to select to label. To address this challenge, we adopt an error estimator to adaptively decide the partial selection ratio according to the current model’s capability. In evaluations spanning four structured prediction tasks, we show that our combination of partial annotation and self-training using an adaptive selection ratio reduces annotation cost over strong full annotation baselines under a fair comparison scheme that takes reading time into consideration.</abstract>
      <url hash="3935e965">2023.findings-emnlp.865</url>
      <bibkey>zhang-etal-2023-data</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.865</doi>
    </paper>
    <paper id="866">
      <title>Explicit Alignment and Many-to-many Entailment Based Reasoning for Conversational Machine Reading</title>
      <author><first>Yangyang</first><last>Luo</last></author>
      <author><first>Shiyu</first><last>Tian</last></author>
      <author><first>Caixia</first><last>Yuan</last></author>
      <author><first>Xiaojie</first><last>Wang</last></author>
      <pages>13009-13022</pages>
      <abstract>Conversational Machine Reading (CMR) requires answering a user’s initial question through multi-turn dialogue interactions based on a given document. Although there exist many effective methods, they largely neglected the alignment between the <tex-math>\textit{document}</tex-math> and the <tex-math>\textit{user-provided information}</tex-math>, which significantly affects the intermediate decision-making and subsequent follow-up question generation. To address this issue, we propose a pipeline framework that (1) aligns the aforementioned two sides in an explicit way, (2) makes decisions using a lightweight many-to-many entailment reasoning module, and (3) directly generates follow-up questions based on the document and previously asked questions. Our proposed method achieves state-of-the-art in micro-accuracy and ranks the first place on the public leaderboard of the CMR benchmark dataset ShARC.</abstract>
      <url hash="1f13cf8f">2023.findings-emnlp.866</url>
      <bibkey>luo-etal-2023-explicit</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.866</doi>
    </paper>
    <paper id="867">
      <title>Harnessing Dataset Cartography for Improved Compositional Generalization in Transformers</title>
      <author><first>Osman</first><last>İnce</last></author>
      <author><first>Tanin</first><last>Zeraati</last></author>
      <author><first>Semih</first><last>Yagcioglu</last></author>
      <author><first>Yadollah</first><last>Yaghoobzadeh</last></author>
      <author><first>Erkut</first><last>Erdem</last></author>
      <author><first>Aykut</first><last>Erdem</last></author>
      <pages>13023-13041</pages>
      <abstract>Neural networks have revolutionized language modeling and excelled in various downstream tasks. However, the extent to which these models achieve compositional generalization comparable to human cognitive abilities remains a topic of debate. While existing approaches in the field have mainly focused on novel architectures and alternative learning paradigms, we introduce a pioneering method harnessing the power of dataset cartography (Swayamdipta et al., 2020). By strategically identifying a subset of compositional generalization data using this approach, we achieve a remarkable improvement in model accuracy, yielding enhancements of up to 10% on CFQ and COGS datasets. Notably, our technique incorporates dataset cartography as a curriculum learning criterion, eliminating the need for hyperparameter tuning while consistently achieving superior performance. Our findings highlight the untapped potential of dataset cartography in unleashing the full capabilities of compositional generalization within Transformer models.</abstract>
      <url hash="9783c6cc">2023.findings-emnlp.867</url>
      <bibkey>ince-etal-2023-harnessing</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.867</doi>
    </paper>
    <paper id="868">
      <title>Roles of Scaling and Instruction Tuning in Language Perception: Model vs. Human Attention</title>
      <author><first>Changjiang</first><last>Gao</last></author>
      <author><first>Shujian</first><last>Huang</last></author>
      <author><first>Jixing</first><last>Li</last></author>
      <author><first>Jiajun</first><last>Chen</last></author>
      <pages>13042-13055</pages>
      <abstract>Recent large language models (LLMs) have revealed strong abilities to understand natural language. Since most of them share the same basic structure, i.e. the transformer block, possible contributors to their success in the training process are scaling and instruction tuning. However, how these factors affect the models’ language perception is unclear. This work compares the self-attention of several existing LLMs (LLaMA, Alpaca and Vicuna) in different sizes (7B, 13B, 30B, 65B), together with eye saccade, an aspect of human reading attention, to assess the effect of scaling and instruction tuning on language perception. Results show that scaling enhances the human resemblance and improves the effective attention by reducing the trivial pattern reliance, while instruction tuning does not. However, instruction tuning significantly enhances the models’ sensitivity to instructions. We also find that current LLMs are consistently closer to non-native than native speakers in attention, suggesting a sub-optimal language perception of all models. Our code and data used in the analysis is available on GitHub.</abstract>
      <url hash="954e9774">2023.findings-emnlp.868</url>
      <bibkey>gao-etal-2023-roles</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.868</doi>
    </paper>
    <paper id="869">
      <title>Efficient Data Learning for Open Information Extraction with Pre-trained Language Models</title>
      <author><first>Zhiyuan</first><last>Fan</last></author>
      <author><first>Shizhu</first><last>He</last></author>
      <pages>13056-13063</pages>
      <abstract>Open Information Extraction (OpenIE) is a fundamental yet challenging task in Natural Language Processing, which involves extracting all triples (subject, predicate, object) from a given sentence. While labelling-based methods have their merits, generation-based techniques offer unique advantages, such as the ability to generate tokens not present in the original sentence. However, these generation-based methods often require a significant amount of training data to learn the task form of OpenIE and substantial training time to overcome slow model convergence due to the order penalty. In this paper, we introduce a novel framework, OK-IE, that ingeniously transforms the task form of OpenIE into the pre-training task form of the T5 model, thereby reducing the need for extensive training data. Furthermore, we introduce an innovative concept of ‘anchors’ to control the sequence of model outputs, effectively eliminating the impact of order penalty on model convergence and significantly reducing training time. Experimental results indicate that, compared to previous SOTA methods, OK-IE requires only 1/100 of the training data (900 instances) and 1/120 of the training time (3 minutes) to achieve comparable results.</abstract>
      <url hash="2f0e96a8">2023.findings-emnlp.869</url>
      <bibkey>fan-he-2023-efficient</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.869</doi>
    </paper>
    <paper id="870">
      <title>Survival of the Most Influential Prompts: Efficient Black-Box Prompt Search via Clustering and Pruning</title>
      <author><first>Han</first><last>Zhou</last></author>
      <author><first>Xingchen</first><last>Wan</last></author>
      <author><first>Ivan</first><last>Vulić</last></author>
      <author><first>Anna</first><last>Korhonen</last></author>
      <pages>13064-13077</pages>
      <abstract>Prompt-based learning has been an effective paradigm for large pretrained language models (LLM), enabling few-shot or even zero-shot learning. Black-box prompt search has received growing interest recently for its distinctive properties of gradient-free optimization, proven particularly useful and powerful for model-as-a-service usage. However, the discrete nature and the complexity of combinatorial optimization hinder the efficiency of modern black-box approaches. Despite extensive research on search algorithms, the crucial aspect of search space design and optimization has been largely overlooked. In this paper, we first conduct a sensitivity analysis by prompting LLM, revealing that only a small number of tokens exert a disproportionate amount of influence on LLM predictions. Leveraging this insight, we propose the Clustering and Pruning for Efficient Black-box Prompt Search (ClaPS), a simple black-box search method that first clusters and prunes the search space to focus exclusively on influential prompt tokens. By employing even simple search methods within the pruned search space, ClaPS achieves state-of-the-art performance across various tasks and LLMs, surpassing the performance of complex approaches while significantly reducing search costs. Our findings underscore the critical role of search space design and optimization in enhancing both the usefulness and the efficiency of black-box prompt-based learning.</abstract>
      <url hash="598ff2d0">2023.findings-emnlp.870</url>
      <bibkey>zhou-etal-2023-survival</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.870</doi>
    </paper>
    <paper id="871">
      <title>Towards Zero-shot Learning for End-to-end Cross-modal Translation Models</title>
      <author><first>Jichen</first><last>Yang</last></author>
      <author><first>Kai</first><last>Fan</last></author>
      <author><first>Minpeng</first><last>Liao</last></author>
      <author><first>Boxing</first><last>Chen</last></author>
      <author><first>Zhongqiang</first><last>Huang</last></author>
      <pages>13078-13087</pages>
      <abstract>One of the main problems in speech translation is the mismatches between different modalities. The second problem, scarcity of parallel data covering multiple modalities, means that the end-to-end multi-modal models tend to perform worse than cascade models, although there are exceptions under favorable conditions. To address these problems, we propose an end-to-end zero-shot speech translation model, connecting two pre-trained uni-modality modules via word rotator’s distance. The model retains the ability of zero-shot, which is like cascade models, and also can be trained in an end-to-end style to avoid error propagation. Our comprehensive experiments on the MuST-C benchmarks show that our end-to-end zero-shot approach performs better than or as well as those of the CTC-based cascade models and that our end-to-end model with supervised training also matches the latest baselines.</abstract>
      <url hash="c1f79dec">2023.findings-emnlp.871</url>
      <bibkey>yang-etal-2023-towards-zero</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.871</doi>
    </paper>
    <paper id="872">
      <title><fixed-case>LLM</fixed-case>a<fixed-case>AA</fixed-case>: Making Large Language Models as Active Annotators</title>
      <author><first>Ruoyu</first><last>Zhang</last></author>
      <author><first>Yanzeng</first><last>Li</last></author>
      <author><first>Yongliang</first><last>Ma</last></author>
      <author><first>Ming</first><last>Zhou</last></author>
      <author><first>Lei</first><last>Zou</last></author>
      <pages>13088-13103</pages>
      <abstract>Prevalent supervised learning methods in natural language processing (NLP) are notoriously data-hungry, which demand large amounts of high-quality annotated data. In practice, acquiring such data is a costly endeavor. Recently, the superior few-shot performance of large language models (LLMs) has propelled the development of dataset generation, where the training data are solely synthesized from LLMs. However, such an approach usually suffers from low-quality issues, and requires orders of magnitude more labeled data to achieve satisfactory performance. To fully exploit the potential of LLMs and make use of massive unlabeled data, we propose LLMaAA, which takes LLMs as annotators and puts them into an active learning loop to determine what to annotate efficiently. To learn robustly with pseudo labels, we optimize both the annotation and training processes: (1) we draw <tex-math>k</tex-math>-NN examples from a small demonstration pool as in-context examples, and (2) we adopt the example reweighting technique to assign training samples with learnable weights. Compared with previous approaches, LLMaAA features both efficiency and reliability. We conduct experiments and analysis on two classic NLP tasks, named entity recognition and relation extraction. With LLMaAA, task-specific models trained from LLM-generated labels can outperform the teacher within only hundreds of annotated examples, which is much more cost-effective than other baselines.</abstract>
      <url hash="358ab04c">2023.findings-emnlp.872</url>
      <bibkey>zhang-etal-2023-llmaaa</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.872</doi>
    </paper>
    <paper id="873">
      <title><fixed-case>NLM</fixed-case>s: Augmenting Negation in Language Models</title>
      <author><first>Rituraj</first><last>Singh</last></author>
      <author><first>Rahul</first><last>Kumar</last></author>
      <author><first>Vivek</first><last>Sridhar</last></author>
      <pages>13104-13116</pages>
      <abstract>Negation is the fundamental component in a natural language that reverses the semantic meaning of a sentence. It plays an extremely important role across a wide range of applications, yet they are underrepresented in pre-trained language models (LMs), resulting often in wrong inferences. In this work, we try to improve the underlying understanding of the negation in the pre-trained LMs. To augment negation understanding, we propose a language model objective with a weighted cross-entropy loss and elastic weight consolidation regularization. We reduce the mean top 1 error rate for BERT-base to 1.1%, BERT-large to 0.78%, RoBERTA-base to 3.74%, RoBERTA-large to 0.01% on the negated LAMA dataset. It minimizes the BERT error rate by a margin of 8% and also outperform the existing negation models. We also provide empirical evidences that negated augmented models outperform the classical models on original as well as negation benchmarks on natural language inference tasks.</abstract>
      <url hash="5fa16629">2023.findings-emnlp.873</url>
      <bibkey>singh-etal-2023-nlms</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.873</doi>
    </paper>
    <paper id="874">
      <title>Parameter-Efficient Prompt Tuning Makes Generalized and Calibrated Neural Text Retrievers</title>
      <author><first>Weng</first><last>Tam</last></author>
      <author><first>Xiao</first><last>Liu</last></author>
      <author><first>Kaixuan</first><last>Ji</last></author>
      <author><first>Lilong</first><last>Xue</last></author>
      <author><first>Jiahua</first><last>Liu</last></author>
      <author><first>Tao</first><last>Li</last></author>
      <author><first>Yuxiao</first><last>Dong</last></author>
      <author><first>Jie</first><last>Tang</last></author>
      <pages>13117-13130</pages>
      <abstract>Prompt tuning attempts to update few task-specific parameters in pre-trained models. It has achieved comparable performance to fine-tuning of the full parameter set on both language understanding and generation tasks. In this work, we study the problem of prompt tuning for neural text retrievers. We introduce parameter-efficient prompt tuning for text retrieval across in-domain, cross-domain, and cross-topic settings. Through an extensive analysis, we show that the strategy can mitigate the two issues—parameter-inefficiency and weak generalizability—faced by fine-tuning based retrieval methods. Notably, it can significantly improve the out-of-domain zero-shot generalization of the retrieval models. By updating only 0.1% of the model parameters, the prompt tuning strategy can help retrieval models achieve better generalization performance than traditional methods in which all parameters are updated. Finally, to facilitate research on retrievers’ cross-topic generalizability, we curate and release an academic retrieval dataset with 18K query-results pairs in 87 topics, making it the largest topic-specific one to date.</abstract>
      <url hash="e1e60480">2023.findings-emnlp.874</url>
      <bibkey>tam-etal-2023-parameter</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.874</doi>
    </paper>
    <paper id="875">
      <title><fixed-case>X</fixed-case>-<fixed-case>SNS</fixed-case>: Cross-Lingual Transfer Prediction through Sub-Network Similarity</title>
      <author><first>Taejun</first><last>Yun</last></author>
      <author><first>Jinhyeon</first><last>Kim</last></author>
      <author><first>Deokyeong</first><last>Kang</last></author>
      <author><first>Seonghoon</first><last>Lim</last></author>
      <author><first>Jihoon</first><last>Kim</last></author>
      <author><first>Taeuk</first><last>Kim</last></author>
      <pages>13131-13144</pages>
      <abstract>Cross-lingual transfer (XLT) is an emergent ability of multilingual language models that preserves their performance on a task to a significant extent when evaluated in languages that were not included in the fine-tuning process. While English, due to its widespread usage, is typically regarded as the primary language for model adaption in various tasks, recent studies have revealed that the efficacy of XLT can be amplified by selecting the most appropriate source languages based on specific conditions. In this work, we propose the utilization of sub-network similarity between two languages as a proxy for predicting the compatibility of the languages in the context of XLT. Our approach is model-oriented, better reflecting the inner workings of foundation models. In addition, it requires only a moderate amount of raw text from candidate languages, distinguishing it from the majority of previous methods that rely on external resources. In experiments, we demonstrate that our method is more effective than baselines across diverse tasks. Specifically, it shows proficiency in ranking candidates for zero-shot XLT, achieving an improvement of 4.6% on average in terms of NDCG@3. We also provide extensive analyses that confirm the utility of sub-networks for XLT prediction.</abstract>
      <url hash="36062516">2023.findings-emnlp.875</url>
      <bibkey>yun-etal-2023-x</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.875</doi>
    </paper>
    <paper id="876">
      <title>Noise-Robust Semi-Supervised Learning for Distantly Supervised Relation Extraction</title>
      <author><first>Xin</first><last>Sun</last></author>
      <author><first>Qiang</first><last>Liu</last></author>
      <author><first>Shu</first><last>Wu</last></author>
      <author><first>Zilei</first><last>Wang</last></author>
      <author><first>Liang</first><last>Wang</last></author>
      <pages>13145-13157</pages>
      <abstract>Distantly supervised relation extraction (DSRE) aims to extract relational facts from texts but suffers from noisy instances. To mitigate the influence of noisy labels, current methods typically use the Multi-Instance-Learning framework to extract relations for each bag. However, these approaches are not capable of extracting relation labels for individual sentences. Several studies have focused on sentence-level DSRE to solve the above problem. These studies primarily aim to develop methods for identifying noisy samples and filtering them out to mitigate the impact of noise. However, discarding noisy samples directly leads to the loss of useful information. To this end, we propose SSLRE, a novel Semi-Supervised-Learning Relation Extraction framework for sentence-level DSRE. We discard only the labels of the noisy samples and utilize these instances without labels as unlabeled samples. Our SSLRE framework utilizes a weighted K-NN graph to select confident samples as labeled data and the rest as unlabeled. We then design a robust semi-supervised learning framework that can efficiently handle remaining label noise present in the labeled dataset, while also making effective use of unlabeled samples. Based on our experiments on two real-world datasets, the SSLRE framework we proposed has achieved significant enhancements in sentence-level relation extraction performance compared to the existing state-of-the-art methods. Moreover, it has also attained a state-of-the-art level of performance in bag-level relation extraction with ONE aggregation strategy.</abstract>
      <url hash="f0739da5">2023.findings-emnlp.876</url>
      <bibkey>sun-etal-2023-noise</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.876</doi>
    </paper>
    <paper id="877">
      <title>Towards Concept-Aware Large Language Models</title>
      <author><first>Chen</first><last>Shani</last></author>
      <author><first>Jilles</first><last>Vreeken</last></author>
      <author><first>Dafna</first><last>Shahaf</last></author>
      <pages>13158-13170</pages>
      <abstract>Concepts play a pivotal role in various human cognitive functions, including learning, reasoning and communication. However, there is very little work on endowing machines with the ability to form and reason with concepts. In particular, state-of-the-art large language models (LLMs) work at the level of tokens, not concepts. In this work, we analyze how well contemporary LLMs capture human concepts and their structure. We then discuss ways to develop concept-aware LLMs, taking place at different stages of the pipeline. We sketch a method for pretraining LLMs using concepts, and also explore the simpler approach that uses the output of existing LLMs. Despite its simplicity, our proof-of-concept is shown to better match human intuition, as well as improve the robustness of predictions. These preliminary results underscore the promise of concept-aware LLMs.</abstract>
      <url hash="2a28878c">2023.findings-emnlp.877</url>
      <bibkey>shani-etal-2023-towards</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.877</doi>
    </paper>
    <paper id="878">
      <title><fixed-case>C</fixed-case>hat<fixed-case>GPT</fixed-case> Beyond <fixed-case>E</fixed-case>nglish: Towards a Comprehensive Evaluation of Large Language Models in Multilingual Learning</title>
      <author><first>Viet</first><last>Lai</last></author>
      <author><first>Nghia</first><last>Ngo</last></author>
      <author><first>Amir</first><last>Pouran Ben Veyseh</last></author>
      <author><first>Hieu</first><last>Man</last></author>
      <author><first>Franck</first><last>Dernoncourt</last></author>
      <author><first>Trung</first><last>Bui</last></author>
      <author><first>Thien</first><last>Nguyen</last></author>
      <pages>13171-13189</pages>
      <abstract>Over the last few years, large language models (LLMs) have emerged as the most important breakthroughs in natural language processing (NLP) that fundamentally transform research and developments in the field. ChatGPT represents one of the most exciting LLM systems developed recently to showcase impressive skills for language generation and highly attract public attention. Among various exciting applications discovered for ChatGPT in English, the model can process and generate texts for multiple languages due to its multilingual training data. Given the broad adoption of ChatGPT for English in different problems and areas, a natural question is whether ChatGPT can also be applied effectively for other languages or it is necessary to develop more language-specific technologies. The answer to this question requires a thorough evaluation of ChatGPT over multiple tasks with diverse languages and large datasets (i.e., beyond reported anecdotes), which is still missing or limited in current research. Our work aims to fill this gap for the evaluation of ChatGPT and similar LLMs to provide more comprehensive information for multilingual NLP applications. In particular, we evaluate ChatGPT on 7 different tasks, covering 37 diverse languages with high, medium, low, and extremely low resources. Compared to the performance of previous models, our extensive experiments demonstrate the worse performance of ChatGPT for different NLP tasks and languages, calling for further research to develop better models and understanding for multilingual learning.</abstract>
      <url hash="c8668ade">2023.findings-emnlp.878</url>
      <bibkey>lai-etal-2023-chatgpt</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.878</doi>
    </paper>
    <paper id="879">
      <title>Subspace Chronicles: How Linguistic Information Emerges, Shifts and Interacts during Language Model Training</title>
      <author><first>Max</first><last>Müller-Eberstein</last></author>
      <author><first>Rob</first><last>van der Goot</last></author>
      <author><first>Barbara</first><last>Plank</last></author>
      <author><first>Ivan</first><last>Titov</last></author>
      <pages>13190-13208</pages>
      <abstract>Representational spaces learned via language modeling are fundamental to Natural Language Processing (NLP), however there has been limited understanding regarding how and when during training various types of linguistic information emerge and interact. Leveraging a novel information theoretic probing suite, which enables direct comparisons of not just task performance, but their representational subspaces, we analyze nine tasks covering syntax, semantics and reasoning, across 2M pre-training steps and five seeds. We identify critical learning phases across tasks and time, during which subspaces emerge, share information, and later disentangle to specialize. Across these phases, syntactic knowledge is acquired rapidly after 0.5% of full training. Continued performance improvements primarily stem from the acquisition of open-domain knowledge, while semantics and reasoning tasks benefit from later boosts to long-range contextualization and higher specialization. Measuring cross-task similarity further reveals that linguistically related tasks share information throughout training, and do so more during the critical phase of learning than before or after. Our findings have implications for model interpretability, multi-task learning, and learning from limited data.</abstract>
      <url hash="684489b3">2023.findings-emnlp.879</url>
      <bibkey>muller-eberstein-etal-2023-subspace</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.879</doi>
    </paper>
    <paper id="880">
      <title>Not All Demonstration Examples are Equally Beneficial: Reweighting Demonstration Examples for In-Context Learning</title>
      <author><first>Zhe</first><last>Yang</last></author>
      <author><first>Damai</first><last>Dai</last></author>
      <author><first>Peiyi</first><last>Wang</last></author>
      <author><first>Zhifang</first><last>Sui</last></author>
      <pages>13209-13221</pages>
      <abstract>Large Language Models (LLMs) have recently gained the In-Context Learning (ICL) ability with the models scaling up, allowing them to quickly adapt to downstream tasks with only a few demonstration examples prepended in the input sequence. Nonetheless, the current practice of ICL treats all demonstration examples equally, which still warrants improvement, as the quality of examples is usually uneven. In this paper, we investigate how to determine approximately optimal weights for demonstration examples and how to apply them during ICL. To assess the quality of weights in the absence of additional validation data, we design a masked self-prediction (MSP) score that exhibits a strong correlation with the final ICL performance. To expedite the weight-searching process, we discretize the continuous weight space and adopt beam search. With approximately optimal weights obtained, we further propose two strategies to apply them to demonstrations at different model positions. Experimental results on 8 text classification tasks show that our approach outperforms conventional ICL by a large margin. Our code are publicly available at https:github.com/Zhe-Young/WICL.</abstract>
      <url hash="b4865a33">2023.findings-emnlp.880</url>
      <bibkey>yang-etal-2023-demonstration</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.880</doi>
    </paper>
    <paper id="881">
      <title>Difference-Masking: Choosing What to Mask in Continued Pretraining</title>
      <author><first>Alex</first><last>Wilf</last></author>
      <author><first>Syeda</first><last>Akter</last></author>
      <author><first>Leena</first><last>Mathur</last></author>
      <author><first>Paul</first><last>Liang</last></author>
      <author><first>Sheryl</first><last>Mathew</last></author>
      <author><first>Mengrou</first><last>Shou</last></author>
      <author><first>Eric</first><last>Nyberg</last></author>
      <author><first>Louis-Philippe</first><last>Morency</last></author>
      <pages>13222-13234</pages>
      <abstract>The self-supervised objective of masked prediction has led to promising performance gains on a variety of downstream tasks. However, while most approaches randomly mask tokens, there is strong intuition that deciding what to mask can substantially improve learning outcomes. We investigate this in continued pretraining setting in which pretrained models continue to pretrain on domain-specific data before performing some downstream task. We introduce Difference-Masking, a masking strategy that automatically chooses what to mask during continued pretraining by considering what makes a task domain different from the pretraining domain. Empirically, we find that Difference-Masking outperforms baselines on continued pretraining settings across four diverse language-only and multimodal video tasks.</abstract>
      <url hash="abe51712">2023.findings-emnlp.881</url>
      <bibkey>wilf-etal-2023-difference</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.881</doi>
    </paper>
    <paper id="882">
      <title>Learn From One Specialized Sub-Teacher: One-to-One Mapping for Feature-Based Knowledge Distillation</title>
      <author><first>Khouloud</first><last>Saadi</last></author>
      <author><first>Jelena</first><last>Mitrović</last></author>
      <author><first>Michael</first><last>Granitzer</last></author>
      <pages>13235-13245</pages>
      <abstract>Knowledge distillation is known as an effective technique for compressing over-parameterized language models. In this work, we propose to break down the global feature distillation task into N local sub-tasks. In this new framework, we consider each neuron in the last hidden layer of the teacher network as a specialized sub-teacher. We also consider each neuron in the last hidden layer of the student network as a focused sub-student. We make each focused sub-student learn from one corresponding specialized sub-teacher and ignore the others. This will facilitate the task for the sub-student and keep it focused. Our proposed method is novel and can be combined with other distillation techniques. Empirical results show that our proposed approach outperforms the state-of-the-art methods by maintaining higher performance on most benchmark datasets. Furthermore, we propose a randomized variant of our approach, called Masked One-to-One Mapping. Rather than learning all the N sub-tasks simultaneously, we focus on learning a subset of these sub-tasks at each optimization step. This variant enables the student to digest the received flow of knowledge more effectively and yields superior results.</abstract>
      <url hash="856567a3">2023.findings-emnlp.882</url>
      <bibkey>saadi-etal-2023-learn</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.882</doi>
    </paper>
    <paper id="883">
      <title><fixed-case>IMU</fixed-case>2<fixed-case>CLIP</fixed-case>: Language-grounded Motion Sensor Translation with Multimodal Contrastive Learning</title>
      <author><first>Seungwhan</first><last>Moon</last></author>
      <author><first>Andrea</first><last>Madotto</last></author>
      <author><first>Zhaojiang</first><last>Lin</last></author>
      <author><first>Aparajita</first><last>Saraf</last></author>
      <author><first>Amy</first><last>Bearman</last></author>
      <author><first>Babak</first><last>Damavandi</last></author>
      <pages>13246-13253</pages>
      <abstract>We present IMU2CLIP, a novel pre-training approach to align Inertial Measurement Unit (IMU) motion sensor recordings with text and video, by projecting them into the joint representation space of Contrastive Language-Image Pre-training (CLIP). The proposed approach allows IMU2CLIP to translate human motions (as measured by IMU sensors) into their corresponding textual descriptions and videos – while preserving the transitivity across these modalities. We introduce several new IMU-based Wearable AI applications such as motion-based media search, or an LM-based multimodal reasoning with motion sensor data – all using text as the grounding platform. In addition, we show that IMU2CLIP significantly improves downstream performances when fine-tuned for each application, demonstrating its universal usage as a new pre-trained resource. Our code and models will be released publicly.</abstract>
      <url hash="f72a3823">2023.findings-emnlp.883</url>
      <bibkey>moon-etal-2023-imu2clip</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.883</doi>
    </paper>
    <paper id="884">
      <title>Conditioning on Dialog Acts improves Empathy Style Transfer</title>
      <author><first>Renyi</first><last>Qu</last></author>
      <author><first>Lyle</first><last>Ungar</last></author>
      <author><first>João</first><last>Sedoc</last></author>
      <pages>13254-13271</pages>
      <abstract>We explore the role of dialog acts in style transfer, specifically empathy style transfer – rewriting a sentence to make it more empathetic without changing its meaning. Specifically, we use two novel few-shot prompting strategies: target prompting, which only uses examples of the target style (unlike traditional prompting with source/target pairs), and dialog-act-conditioned prompting, which first estimates the dialog act of the source sentence and then makes it more empathetic using few-shot examples of the same dialog act. Our study yields two key findings: (1) Target prompting typically improves empathy more effectively while maintaining the same level of semantic similarity; (2) Dialog acts matter. Dialog-act-conditioned prompting enhances empathy while preserving both semantics and the dialog-act type. Different dialog acts benefit differently from different prompting methods, highlighting the need for further investigation of the role of dialog acts in style transfer.</abstract>
      <url hash="57d28154">2023.findings-emnlp.884</url>
      <bibkey>qu-etal-2023-conditioning</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.884</doi>
    </paper>
    <paper id="885">
      <title>Systematic Assessment of Factual Knowledge in Large Language Models</title>
      <author><first>Linhao</first><last>Luo</last></author>
      <author><first>Trang</first><last>Vu</last></author>
      <author><first>Dinh</first><last>Phung</last></author>
      <author><first>Reza</first><last>Haf</last></author>
      <pages>13272-13286</pages>
      <abstract>Previous studies have relied on existing question-answering benchmarks to evaluate the knowledge stored in large language models (LLMs). However, this approach has limitations regarding factual knowledge coverage, as it mostly focuses on generic domains which may overlap with the pretraining data. This paper proposes a framework to systematically assess the factual knowledge of LLMs by leveraging knowledge graphs (KGs). Our framework automatically generates a set of questions and expected answers from the facts stored in a given KG, and then evaluates the accuracy of LLMs in answering these questions. We systematically evaluate the state-of-the-art LLMs with KGs in generic and specific domains. The experiment shows that ChatGPT is consistently the top performer across all domains. We also find that LLMs performance depends on the instruction finetuning, domain and question complexity and is prone to adversarial context.</abstract>
      <url hash="5ba5b3e6">2023.findings-emnlp.885</url>
      <bibkey>luo-etal-2023-systematic</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.885</doi>
    </paper>
    <paper id="886">
      <title>From Speculation Detection to Trustworthy Relational Tuples in Information Extraction</title>
      <author><first>Kuicai</first><last>Dong</last></author>
      <author><first>Aixin</first><last>Sun</last></author>
      <author><first>Jung-jae</first><last>Kim</last></author>
      <author><first>Xiaoli</first><last>Li</last></author>
      <pages>13287-13299</pages>
      <abstract>Speculation detection is an important NLP task to identify text factuality. However, the extracted speculative information (e.g., speculative polarity, cue, and scope) lacks structure and poses challenges for direct utilization in downstream tasks. Open Information Extraction (OIE), on the other hand, extracts structured tuples as facts, without examining the certainty of these tuples. Bridging this gap between speculation detection and information extraction becomes imperative to generate structured speculative information and trustworthy relational tuples. Existing studies on speculation detection are defined at sentence level; but even if a sentence is determined to be speculative, not all factual tuples extracted from it are speculative. In this paper, we propose to study speculations in OIE tuples and determine whether a tuple is speculative. We formally define the research problem of tuple-level speculation detection. We then conduct detailed analysis on the LSOIE dataset which provides labels for speculative tuples. Lastly, we propose a baseline model SpecTup for this new research task.</abstract>
      <url hash="1968462d">2023.findings-emnlp.886</url>
      <bibkey>dong-etal-2023-speculation</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.886</doi>
    </paper>
    <paper id="887">
      <title>Tokenization Consistency Matters for Generative Models on Extractive <fixed-case>NLP</fixed-case> Tasks</title>
      <author><first>Kaiser</first><last>Sun</last></author>
      <author><first>Peng</first><last>Qi</last></author>
      <author><first>Yuhao</first><last>Zhang</last></author>
      <author><first>Lan</first><last>Liu</last></author>
      <author><first>William</first><last>Wang</last></author>
      <author><first>Zhiheng</first><last>Huang</last></author>
      <pages>13300-13310</pages>
      <abstract>Generative models have been widely applied to solve extractive tasks, where parts of the input is extracted to form the desired output, and achieved significant success. For example, in extractive question answering (QA), generative models have constantly yielded state-of-the-art results. In this work, we study the issue of tokenization inconsistency that is commonly neglected in training these models. This issue damages the extractive nature of these tasks after the input and output are tokenized inconsistently by the tokenizer, and thus leads to performance drop as well as hallucination. We propose a simple yet effective fix to this issue and conduct a case study on extractive QA. We show that, with consistent tokenization, the model performs better in both in-domain and out-of-domain datasets, with a notable average of +1.7 F1 gain when a BART model is trained on SQuAD and evaluated on 8 QA datasets. Further, the model converges faster, and becomes less likely to generate out-of-context answers. Our results demonstrate the need for increased scrutiny regarding how tokenization is done in extractive tasks and the benefits of consistent tokenization during training.</abstract>
      <url hash="fee039af">2023.findings-emnlp.887</url>
      <bibkey>sun-etal-2023-tokenization</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.887</doi>
    </paper>
    <paper id="888">
      <title>Dialogue Medical Information Extraction with Medical-Item Graph and Dialogue-Status Enriched Representation</title>
      <author><first>Lei</first><last>Gao</last></author>
      <author><first>Xinnan</first><last>Zhang</last></author>
      <author><first>Xian</first><last>Wu</last></author>
      <author><first>Shen</first><last>Ge</last></author>
      <author><first>Yefeng</first><last>Zheng</last></author>
      <pages>13311-13321</pages>
      <abstract>The multi-turn doctor-patient dialogue includes rich medical knowledge, like the symptoms of the patient, the diagnosis and medication suggested by the doctor. If mined and represented properly, such medical knowledge can benefit a large range of clinical applications, including diagnosis assistance and medication recommendation. To derive structured knowledge from free text dialogues, we target a critical task: the Dialogue Medical Information Extraction (DMIE). DMIE aims to detect pre-defined clinical meaningful medical items (symptoms, surgery, etc.) as well as their statuses (positive, negative, etc.) from the dialogue. Existing approaches mainly formulate DMIE as a multi-label classification problem and ignore the relationships among medical items and statuses. Different from previous approaches, we propose a heterogeneous graph to model the relationship between items. We further propose two consecutive attention based modules to enrich the item representation with the dialogue and status. In this manner, we are able to model the relationships among medical items and statuses in the DMIE task. Experimental results on the public benchmark data set show that the proposed model outperforms previous works and achieves the state-of-the-art performance.</abstract>
      <url hash="e4520dab">2023.findings-emnlp.888</url>
      <bibkey>gao-etal-2023-dialogue-medical</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.888</doi>
    </paper>
    <paper id="889">
      <title><fixed-case>L</fixed-case>ogic<fixed-case>A</fixed-case>ttack: Adversarial Attacks for Evaluating Logical Consistency of Natural Language Inference</title>
      <author><first>Mutsumi</first><last>Nakamura</last></author>
      <author><first>Santosh</first><last>Mashetty</last></author>
      <author><first>Mihir</first><last>Parmar</last></author>
      <author><first>Neeraj</first><last>Varshney</last></author>
      <author><first>Chitta</first><last>Baral</last></author>
      <pages>13322-13334</pages>
      <abstract>Recently Large Language Models (LLMs) such as GPT-3, ChatGPT, and FLAN have led to impressive progress in Natural Language Inference (NLI) tasks. However, these models may rely on simple heuristics or artifacts in the evaluation data to achieve their high performance, which suggests that they still suffer from logical inconsistency. To assess the logical consistency of these models, we propose a LogicAttack, a method to attack NLI models using diverse logical forms of premise and hypothesis, providing a more robust evaluation of their performance. Our approach leverages a range of inference rules from propositional logic, such as Modus Tollens and Bidirectional Dilemma, to generate effective adversarial attacks and identify common vulnerabilities across multiple NLI models. We achieve an average ~53% Attack Success Rate (ASR) across multiple logic-based attacks. Moreover, we demonstrate that incorporating generated attack samples into training enhances the logical reasoning ability of the target model and decreases its vulnerability to logic-based attacks. Data and source code are available at https://github.com/msantoshmadhav/LogicAttack.</abstract>
      <url hash="6f54657d">2023.findings-emnlp.889</url>
      <bibkey>nakamura-etal-2023-logicattack</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.889</doi>
    </paper>
    <paper id="890">
      <title>Decomposed Prompt Tuning via Low-Rank Reparameterization</title>
      <author><first>Yao</first><last>Xiao</last></author>
      <author><first>Lu</first><last>Xu</last></author>
      <author><first>Jiaxi</first><last>Li</last></author>
      <author><first>Wei</first><last>Lu</last></author>
      <author><first>Xiaoli</first><last>Li</last></author>
      <pages>13335-13347</pages>
      <abstract>While prompt tuning approaches have achieved competitive performance with high efficiency, we observe that they invariably employ the same initialization process, wherein the soft prompt is either randomly initialized or derived from an existing embedding vocabulary. In contrast to these conventional methods, this study aims to investigate an alternative way to derive soft prompt. Our empirical studies show that the soft prompt typically exhibits a low “intrinsic rank” characteristic. With such observations, we propose decomposed prompt tuning, a novel approach that utilizes low-rank matrices to initialize the soft prompt. Through the low-rank reparameterization, our method significantly reduces the number of trainable parameters while maintaining effectiveness. Experimental results on the SuperGLUE benchmark in both high-resource and low-resource scenarios demonstrate the effectiveness of the proposed method.</abstract>
      <url hash="deebf232">2023.findings-emnlp.890</url>
      <bibkey>xiao-etal-2023-decomposed</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.890</doi>
    </paper>
    <paper id="891">
      <title><fixed-case>SGP</fixed-case>-<fixed-case>TOD</fixed-case>: Building Task Bots Effortlessly via Schema-Guided <fixed-case>LLM</fixed-case> Prompting</title>
      <author><first>Xiaoying</first><last>Zhang</last></author>
      <author><first>Baolin</first><last>Peng</last></author>
      <author><first>Kun</first><last>Li</last></author>
      <author><first>Jingyan</first><last>Zhou</last></author>
      <author><first>Helen</first><last>Meng</last></author>
      <pages>13348-13369</pages>
      <abstract>Building and maintaining end-to-end task bots using minimal human effort is a long-standing challenge in dialog research. In this work, we introduce SGP-TOD, Schema-Guided Prompting for building Task-Oriented Dialog systems effortlessly based on large language models (LLMs). Utilizing the predefined task schema, i.e., belief instruction and dialog policy, we instruct fixed LLMs to generate appropriate responses on novel tasks, without the need for training data. Specifically, SGP-TOD comprises three components: an LLM for interacting with users, a Dialog State Tracking (DST) Prompter to aid the LLM in tracking dialog states with the given belief instruction, and a Policy Prompter to direct the LLM to generate proper responses adhering to the provided dialog policy. Experimental results on Multiwoz, RADDLE, and STAR datasets show that our training-free strategy, SGP-TOD, yields state-of-the-art (SOTA) zero-shot performance, significantly surpassing the few-shot approaches. In a domain-extension setting, SGP-TOD aptly adapts to new functionalities by merely adding supplementary schema rules. We make our code and data publicly available.</abstract>
      <url hash="24c601cd">2023.findings-emnlp.891</url>
      <bibkey>zhang-etal-2023-sgp</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.891</doi>
    </paper>
    <paper id="892">
      <title>Ethical Reasoning over Moral Alignment: A Case and Framework for In-Context Ethical Policies in <fixed-case>LLM</fixed-case>s</title>
      <author><first>Abhinav</first><last>Rao</last></author>
      <author><first>Aditi</first><last>Khandelwal</last></author>
      <author><first>Kumar</first><last>Tanmay</last></author>
      <author><first>Utkarsh</first><last>Agarwal</last></author>
      <author><first>Monojit</first><last>Choudhury</last></author>
      <pages>13370-13388</pages>
      <abstract>In this position paper, we argue that instead of morally aligning LLMs to specific set of ethical principles, we should infuse generic ethical reasoning capabilities into them so that they can handle value pluralism at a global scale. When provided with an ethical policy, an LLM should be capable of making decisions that are ethically consistent to the policy. We develop a framework that integrates moral dilemmas with moral principles pertaining to different foramlisms of normative ethics, and at different levels of abstractions. Initial experiments with GPT-x models shows that while GPT-4 is a nearly perfect ethical reasoner, the models still have bias towards the moral values of Western and English speaking societies.</abstract>
      <url hash="a3509a17">2023.findings-emnlp.892</url>
      <bibkey>rao-etal-2023-ethical</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.892</doi>
    </paper>
    <paper id="893">
      <title>Vector-Quantized Prompt Learning for Paraphrase Generation</title>
      <author><first>Haotian</first><last>Luo</last></author>
      <author><first>Yixin</first><last>Liu</last></author>
      <author><first>Peidong</first><last>Liu</last></author>
      <author><first>Xianggen</first><last>Liu</last></author>
      <pages>13389-13398</pages>
      <abstract>Deep generative modeling of natural languages has achieved many successes, such as producing fluent sentences and translating from one language into another. However, the development of generative modeling techniques for paraphrase generation still lags behind largely due to the challenges in addressing the complex conflicts between expression diversity and semantic preservation. This paper proposes to generate diverse and high-quality paraphrases by exploiting the pre-trained models with instance-dependent prompts. To learn generalizable prompts, we assume that the number of abstract transforming patterns of paraphrase generation (governed by prompts) is finite and usually not large. Therefore, we present vector-quantized prompts as the cues to control the generation of pre-trained models. Extensive experiments demonstrate that the proposed method achieves new state-of-art results on three benchmark datasets, including Quora, Wikianswers, and MSCOCO. We will release all the code upon acceptance.</abstract>
      <url hash="c3d85ff9">2023.findings-emnlp.893</url>
      <bibkey>luo-etal-2023-vector</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.893</doi>
    </paper>
    <paper id="894">
      <title>Rethinking the Construction of Effective Metrics for Understanding the Mechanisms of Pretrained Language Models</title>
      <author><first>You</first><last>Li</last></author>
      <author><first>Jinhui</first><last>Yin</last></author>
      <author><first>Yuming</first><last>Lin</last></author>
      <pages>13399-13412</pages>
      <abstract>Pretrained language models are expected to effectively map input text to a set of vectors while preserving the inherent relationships within the text. Consequently, designing a white-box model to compute metrics that reflect the presence of specific internal relations in these vectors has become a common approach for post-hoc interpretability analysis of pretrained language models. However, achieving interpretability in white-box models and ensuring the rigor of metric computation becomes challenging when the source model lacks inherent interpretability. Therefore, in this paper, we discuss striking a balance in this trade-off and propose a novel line to constructing metrics for understanding the mechanisms of pretrained language models. We have specifically designed a family of metrics along this line of investigation, and the model used to compute these metrics is referred to as the tree topological probe. We conducted measurements on BERT-large by using these metrics. Based on the experimental results, we propose a speculation regarding the working mechanism of BERT-like pretrained language models, as well as a strategy for enhancing fine-tuning performance by leveraging the topological probe to improve specific submodules.</abstract>
      <url hash="87fff27f">2023.findings-emnlp.894</url>
      <bibkey>li-etal-2023-rethinking-construction</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.894</doi>
    </paper>
    <paper id="895">
      <title><fixed-case>PARROT</fixed-case>: Zero-Shot Narrative Reading Comprehension via Parallel Reading</title>
      <author><first>Chao</first><last>Zhao</last></author>
      <author><first>Anvesh</first><last>Vijjini</last></author>
      <author><first>Snigdha</first><last>Chaturvedi</last></author>
      <pages>13413-13424</pages>
      <abstract>Narrative comprehension is a challenging task that requires a deep understanding of the foundational elements of narratives. Acquiring this skill requires extensive annotated data. To mitigate the burden of data annotation, we present Parrot, a zero-shot approach for narrative reading comprehension through parallel reading, which involves two parallel narratives that tell the same story. By leveraging one narrative as a source of supervision signal to guide the understanding of the other, Parrot abstracts the textual content and develops genuine narrative understanding. Evaluation conducted on two narrative comprehension benchmarks demonstrates that Parrot surpasses previous zero-shot approaches and achieves comparable performance to fully supervised models. The code will be available at https://github.com/zhaochaocs/Parrot.</abstract>
      <url hash="4a29af21">2023.findings-emnlp.895</url>
      <bibkey>zhao-etal-2023-parrot</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.895</doi>
    </paper>
    <paper id="896">
      <title><fixed-case>B</fixed-case>io<fixed-case>DEX</fixed-case>: Large-Scale Biomedical Adverse Drug Event Extraction for Real-World Pharmacovigilance</title>
      <author><first>Karel</first><last>D’Oosterlinck</last></author>
      <author><first>François</first><last>Remy</last></author>
      <author><first>Johannes</first><last>Deleu</last></author>
      <author><first>Thomas</first><last>Demeester</last></author>
      <author><first>Chris</first><last>Develder</last></author>
      <author><first>Klim</first><last>Zaporojets</last></author>
      <author><first>Aneiss</first><last>Ghodsi</last></author>
      <author><first>Simon</first><last>Ellershaw</last></author>
      <author><first>Jack</first><last>Collins</last></author>
      <author><first>Christopher</first><last>Potts</last></author>
      <pages>13425-13454</pages>
      <abstract>Timely and accurate extraction of Adverse Drug Events (ADE) from biomedical literature is paramount for public safety, but involves slow and costly manual labor. We set out to improve drug safety monitoring (pharmacovigilance, PV) through the use of Natural Language Processing (NLP). We introduce BioDEX, a large-scale resource for Biomedical adverse Drug Event eXtraction, rooted in the historical output of drug safety reporting in the U.S. BioDEX consists of 65k abstracts and 19k full-text biomedical papers with 256k associated document-level safety reports created by medical experts. The core features of these reports include the reported weight, age, and biological sex of a patient, a set of drugs taken by the patient, the drug dosages, the reactions experienced, and whether the reaction was life threatening. In this work, we consider the task of predicting the core information of the report given its originating paper. We estimate human performance to be 72.0% F1, whereas our best model achieves 59.1% F1 (62.3 validation), indicating significant headroom. We also begin to explore ways in which these models could help professional PV reviewers. Our code and data are available at https://github.com/KarelDO/BioDEX.</abstract>
      <url hash="a49ec949">2023.findings-emnlp.896</url>
      <bibkey>doosterlinck-etal-2023-biodex</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.896</doi>
    </paper>
    <paper id="897">
      <title>Coarse-to-Fine Dual Encoders are Better Frame Identification Learners</title>
      <author><first>Kaikai</first><last>An</last></author>
      <author><first>Ce</first><last>Zheng</last></author>
      <author><first>Bofei</first><last>Gao</last></author>
      <author><first>Haozhe</first><last>Zhao</last></author>
      <author><first>Baobao</first><last>Chang</last></author>
      <pages>13455-13466</pages>
      <abstract>Frame identification aims to find semantic frames associated with target words in a sentence. Recent researches measure the similarity or matching score between targets and candidate frames by modeling frame definitions. However, they either lack sufficient representation learning of the definitions or face challenges in efficiently selecting the most suitable frame from over 1000 candidate frames. Moreover, commonly used lexicon filtering (<tex-math>lf</tex-math>) to obtain candidate frames for the target may ignore out-of-vocabulary targets and cause inadequate frame modeling. In this paper, we propose CoFFTEA, a <tex-math>\underline{Co}</tex-math>arse-to-<tex-math>\underline{F}</tex-math>ine <tex-math>\underline{F}</tex-math>rame and <tex-math>\underline{T}</tex-math>arget <tex-math>\underline{E}</tex-math>ncoders <tex-math>\underline{A}</tex-math>rchitecture. With contrastive learning and dual encoders, CoFFTEA efficiently and effectively models the alignment between frames and targets. By employing a coarse-to-fine curriculum learning procedure, CoFFTEA gradually learns to differentiate frames with varying degrees of similarity. Experimental results demonstrate that CoFFTEA outperforms previous models by 0.93 overall scores and 1.53 R@1 without <tex-math>lf</tex-math>. Further analysis suggests that CoFFTEA can better model the relationships between frame and frame, as well as target and target. The code for our approach is available at https://github.com/pkunlp-icler/COFFTEA.</abstract>
      <url hash="225bd44d">2023.findings-emnlp.897</url>
      <bibkey>an-etal-2023-coarse</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.897</doi>
    </paper>
    <paper id="898">
      <title>Sound of Story: Multi-modal Storytelling with Audio</title>
      <author><first>Jaeyeon</first><last>Bae</last></author>
      <author><first>Seokhoon</first><last>Jeong</last></author>
      <author><first>Seokun</first><last>Kang</last></author>
      <author><first>Namgi</first><last>Han</last></author>
      <author><first>Jae-Yon</first><last>Lee</last></author>
      <author><first>Hyounghun</first><last>Kim</last></author>
      <author><first>Taehwan</first><last>Kim</last></author>
      <pages>13467-13479</pages>
      <abstract>Storytelling is multi-modal in the real world. When one tells a story, one may use all of the visualizations and sounds along with the story itself. However, prior studies on storytelling datasets and tasks have paid little attention to sound even though sound also conveys meaningful semantics of the story. Therefore, we propose to extend story understanding and telling areas by establishing a new component called background sound which is story context-based audio without any linguistic information. For this purpose, we introduce a new dataset, called Sound of Story (SoS), which has paired image and text sequences with corresponding sound or background music for a story. To the best of our knowledge, this is the largest well-curated dataset for storytelling with sound. Our SoS dataset consists of 27,354 stories with 19.6 images per story and 984 hours of speech-decoupled audio such as background music and other sounds. As benchmark tasks for storytelling with sound and the dataset, we propose retrieval tasks between modalities, and audio generation tasks from image-text sequences, introducing strong baselines for them. We believe the proposed dataset and tasks may shed light on the multi-modal understanding of storytelling in terms of sound.</abstract>
      <url hash="d3a4478f">2023.findings-emnlp.898</url>
      <bibkey>bae-etal-2023-sound</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.898</doi>
    </paper>
    <paper id="899">
      <title>Synthesize, if you do not have: Effective Synthetic Dataset Creation Strategies for Self-Supervised Opinion Summarization in <fixed-case>E</fixed-case>-commerce</title>
      <author><first>Tejpalsingh</first><last>Siledar</last></author>
      <author><first>Suman</first><last>Banerjee</last></author>
      <author><first>Amey</first><last>Patil</last></author>
      <author><first>Sudhanshu</first><last>Singh</last></author>
      <author><first>Muthusamy</first><last>Chelliah</last></author>
      <author><first>Nikesh</first><last>Garera</last></author>
      <author><first>Pushpak</first><last>Bhattacharyya</last></author>
      <pages>13480-13491</pages>
      <abstract>In e-commerce, opinion summarization is the process of condensing the opinions presented in product reviews. However, the absence of large amounts of supervised datasets presents challenges in generating both aspect-specific and general opinion summaries. Existing approaches have attempted to address these challenges through synthetic dataset creation (SDC). However, general opinion summarization models struggle to generate summaries faithful to the input reviews whereas aspect-specific opinion summarization models are limited due to their reliance on human-specified aspects and seed words. To address this, we propose SDC strategies tailored for general and aspect-specific opinion summarization. We experimented on three e-commerce test sets: Oposum+, Amazon, and Flipkart. For general opinion summarization, pre-trained language model (PLM) fine-tuned on our general synthetic dataset surpass the SOTA on average by 2.3 R1 points. Faithfulness evaluation metrics and human evaluations indicate that our model-generated summaries are more faithful to the input compared to others. For aspect-specific opinion summarization, PLM fine-tuned on our aspect-specific synthetic dataset surpass SOTA by ~ 1 R1 point without the aid of any human-specified aspects or seed words.</abstract>
      <url hash="d2f28c62">2023.findings-emnlp.899</url>
      <bibkey>siledar-etal-2023-synthesize</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.899</doi>
    </paper>
    <paper id="900">
      <title>Leveraging Contrastive Learning and Knowledge Distillation for Incomplete Modality Rumor Detection</title>
      <author><first>Fan</first><last>Xu</last></author>
      <author><first>Pinyun</first><last>Fu</last></author>
      <author><first>Qi</first><last>Huang</last></author>
      <author><first>Bowei</first><last>Zou</last></author>
      <author><first>AiTi</first><last>Aw</last></author>
      <author><first>Mingwen</first><last>Wang</last></author>
      <pages>13492-13503</pages>
      <abstract>Rumors spread rapidly through online social microblogs at a relatively low cost, causing substantial economic losses and negative consequences in our daily lives. Existing rumor detection models often neglect the underlying semantic coherence between text and image components in multimodal posts, as well as the challenges posed by incomplete modalities in single modal posts, such as missing text or images. This paper presents CLKD-IMRD, a novel framework for Incomplete Modality Rumor Detection. CLKD-IMRD employs Contrastive Learning and Knowledge Distillation to capture the semantic consistency between text and image pairs, while also enhancing model generalization to incomplete modalities within individual posts. Extensive experimental results demonstrate that our CLKD-IMRD outperforms state-of-the-art methods on two English and two Chinese benchmark datasets for rumor detection in social media.</abstract>
      <url hash="047b1b72">2023.findings-emnlp.900</url>
      <bibkey>xu-etal-2023-leveraging</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.900</doi>
    </paper>
    <paper id="901">
      <title>Beyond Testers’ Biases: Guiding Model Testing with Knowledge Bases using <fixed-case>LLM</fixed-case>s</title>
      <author><first>Chenyang</first><last>Yang</last></author>
      <author><first>Rishabh</first><last>Rustogi</last></author>
      <author><first>Rachel</first><last>Brower-Sinning</last></author>
      <author><first>Grace</first><last>Lewis</last></author>
      <author><first>Christian</first><last>Kaestner</last></author>
      <author><first>Tongshuang</first><last>Wu</last></author>
      <pages>13504-13519</pages>
      <abstract>Current model testing work has mostly focused on creating test cases. Identifying what to test is a step that is largely ignored and poorly supported. We propose Weaver, an interactive tool that supports requirements elicitation for guiding model testing. Weaver uses large language models to generate knowledge bases and recommends concepts from them interactively, allowing testers to elicit requirements for further testing. Weaver provides rich external knowledge to testers and encourages testers to systematically explore diverse concepts beyond their own biases. In a user study, we show that both NLP experts and non-experts identified more, as well as more diverse concepts worth testing when using Weaver. Collectively, they found more than 200 failing test cases for stance detection with zero-shot ChatGPT. Our case studies further show that Weaver can help practitioners test models in real-world settings, where developers define more nuanced application scenarios (e.g., code understanding and transcript summarization) using LLMs.</abstract>
      <url hash="9e18eace">2023.findings-emnlp.901</url>
      <bibkey>yang-etal-2023-beyond</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.901</doi>
    </paper>
    <paper id="902">
      <title><fixed-case>CAR</fixed-case>: Conceptualization-Augmented Reasoner for Zero-Shot Commonsense Question Answering</title>
      <author><first>Weiqi</first><last>Wang</last></author>
      <author><first>Tianqing</first><last>Fang</last></author>
      <author><first>Wenxuan</first><last>Ding</last></author>
      <author><first>Baixuan</first><last>Xu</last></author>
      <author><first>Xin</first><last>Liu</last></author>
      <author><first>Yangqiu</first><last>Song</last></author>
      <author><first>Antoine</first><last>Bosselut</last></author>
      <pages>13520-13545</pages>
      <abstract>The task of zero-shot commonsense question answering evaluates models on their capacity to reason about general scenarios beyond those presented in specific datasets. Existing approaches for tackling this task leverage external knowledge from CommonSense Knowledge Bases (CSKBs) by pre-training the model on synthetic QA pairs constructed from CSKBs. In these approaches, negative examples (distractors) are formulated by randomly sampling from CSKBs using fairly primitive keyword constraints. However, two bottlenecks limit these approaches: the inherent incompleteness of CSKBs limits the semantic coverage of synthetic QA pairs, and the lack of human annotations makes the sampled negative examples potentially uninformative and contradictory. To tackle these limitations above, we propose Conceptualization-Augmented Reasoner (CAR), a zero-shot commonsense question-answering framework that fully leverages the power of conceptualization. Specifically, CAR abstracts a commonsense knowledge triple to many higher-level instances, which increases the coverage of the CSKB and expands the ground-truth answer space, reducing the likelihood of selecting false negative distractors. Extensive experiments demonstrate that CAR more robustly generalizes to answering questions about zero-shot commonsense scenarios than existing methods, including large language models, such as GPT3.5 and ChatGPT. Our code, data, and model checkpoints are available at https://github.com/HKUST-KnowComp/CAR.</abstract>
      <url hash="a9961c5e">2023.findings-emnlp.902</url>
      <bibkey>wang-etal-2023-car</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.902</doi>
    </paper>
    <paper id="903">
      <title>k<fixed-case>NN</fixed-case>-<fixed-case>CM</fixed-case>: A Non-parametric Inference-Phase Adaptation of Parametric Text Classifiers</title>
      <author><first>Rishabh</first><last>Bhardwaj</last></author>
      <author><first>Yingting</first><last>Li</last></author>
      <author><first>Navonil</first><last>Majumder</last></author>
      <author><first>Bo</first><last>Cheng</last></author>
      <author><first>Soujanya</first><last>Poria</last></author>
      <pages>13546-13557</pages>
      <abstract>Semi-parametric models exhibit the properties of both parametric and non-parametric modeling and have been shown to be effective in the next-word prediction language modeling task. However, there is a lack of studies on the text-discriminating properties of such models. We propose an inference-phase approach—<i>k</i>-Nearest Neighbor Classification Model (<i>k</i>NN-CM)—that enhances the capacity of a pre-trained parametric text classifier by incorporating a simple neighborhood search through the representation space of (memorized) training samples. The final class prediction of <i>k</i>NN-CM is based on the convex combination of probabilities obtained from <i>k</i>NN search and prediction of the classifier. Our experiments show consistent performance improvements on eight SuperGLUE tasks, three adversarial natural language inference (ANLI) datasets, 11 question-answering (QA) datasets, and two sentiment classification datasets.</abstract>
      <url hash="196c7562">2023.findings-emnlp.903</url>
      <bibkey>bhardwaj-etal-2023-knn</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.903</doi>
    </paper>
    <paper id="904">
      <title>Cross-modality Data Augmentation for End-to-End Sign Language Translation</title>
      <author><first>Jinhui</first><last>Ye</last></author>
      <author><first>Wenxiang</first><last>Jiao</last></author>
      <author><first>Xing</first><last>Wang</last></author>
      <author><first>Zhaopeng</first><last>Tu</last></author>
      <author><first>Hui</first><last>Xiong</last></author>
      <pages>13558-13571</pages>
      <abstract>End-to-end sign language translation (SLT) aims to directly convert sign language videos into spoken language texts without intermediate representations. It has been challenging due to the data scarcity of labeled data and the modality gap between sign videos and texts. To tackle these challenges, we propose a novel Cross-modality Data Augmentation (XmDA) framework to transfer the powerful gloss-to-text translation capabilities to end-to-end sign language translation (i.e., video-to-text). Specifically, XmDA consists of two key components: cross-modality mix-up and cross-modality knowledge distillation. The former one explicitly encourages the alignment between sign video features and gloss embeddings to bridge the modality gap. The latter one utilizes the generation knowledge from gloss-to-text teacher models to guide the spoken language text generation. Experimental results on two widely used SLT datasets, i.e., PHOENIX-2014T and CSL-Daily, demonstrate that the proposed XmDA framework significantly and consistently outperforms the baseline models. Extensive analyses confirm our claim that XmDA enhances end-to-end sign language translation by reducing the representation distance between sign videos and glosses, as well as improving the translation of low-frequency words and long sentences.</abstract>
      <url hash="32c3d552">2023.findings-emnlp.904</url>
      <bibkey>ye-etal-2023-cross</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.904</doi>
    </paper>
    <paper id="905">
      <title>Consistency is Key: On Data-Efficient Modality Transfer in Speech Translation</title>
      <author><first>Hojin</first><last>Lee</last></author>
      <author><first>Changmin</first><last>Lee</last></author>
      <author><first>Seung-won</first><last>Hwang</last></author>
      <pages>13572-13581</pages>
      <abstract>End-to-end approaches have shown promising results for speech translation (ST), but they suffer from its data scarcity compared to machine translation (MT). To address this, progressive training has become a common practice, of using external MT data during the fine-tuning phase. Despite of its prevalence and computational overhead, its validity is not extensively corroborated yet. This paper conducts an empirical investigation and finds that progressive training is ineffective. We identify learning-forgetting trade-off as a critical obstacle, then hypothesize and verify that consistency learning (CL) breaks the dilemma of learning-forgetting. The proposed method, which combines knowledge distillation (KD) and CL, outperforms the previous methods on MuST-C dataset even without additional data, and our proposed consistency-informed KD achieves additional improvements against KD+CL. Code and models are availble at https://github.com/hjlee1371/consistency-s2tt.</abstract>
      <url hash="60dd1ff5">2023.findings-emnlp.905</url>
      <bibkey>lee-etal-2023-consistency</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.905</doi>
    </paper>
    <paper id="906">
      <title>Relation-Aware Question Answering for Heterogeneous Knowledge Graphs</title>
      <author><first>Haowei</first><last>Du</last></author>
      <author><first>Quzhe</first><last>Huang</last></author>
      <author><first>Chen</first><last>Li</last></author>
      <author><first>Chen</first><last>Zhang</last></author>
      <author><first>Yang</first><last>Li</last></author>
      <author><first>Dongyan</first><last>Zhao</last></author>
      <pages>13582-13592</pages>
      <abstract>Multi-hop Knowledge Base Question Answering(KBQA) aims to find the answer entity in a knowledge graph (KG), which requires multiple steps of reasoning. Existing retrieval-based approaches solve this task by concentrating on the specific relation at different hops and predicting the intermediate entity within the reasoning path. However, these models fail to utilize information from head-tail entities and the semantic connection between relations to enhance the current relation representation, which undermines the information capturing of relations in KGs. To address this issue, we construct a <b>dual relation graph</b> where each node denotes a relation in the original KG (<b>primal entity graph</b>) and edges are constructed between relations sharing same head or tail entities. Then we iteratively do primal entity graph reasoning, dual relation graph information propagation, and interaction between these two graphs. In this way, the interaction between entity and relation is enhanced, and we derive better entity and relation representations. Experiments on two public datasets, WebQSP and CWQ, show that our approach achieves a significant performance gain over the prior state-of-the-art.</abstract>
      <url hash="238e2031">2023.findings-emnlp.906</url>
      <bibkey>du-etal-2023-relation</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.906</doi>
    </paper>
    <paper id="907">
      <title><fixed-case>I</fixed-case>nst<fixed-case>O</fixed-case>ptima: Evolutionary Multi-objective Instruction Optimization via Large Language Model-based Instruction Operators</title>
      <author><first>Heng</first><last>Yang</last></author>
      <author><first>Ke</first><last>Li</last></author>
      <pages>13593-13602</pages>
      <abstract>Instruction-based language modeling has received significant attention in pretrained language models. However, the efficiency of instruction engineering remains low and hinders the development of instruction studies. Recent studies have focused on automating instruction generation, but they primarily aim to improve performance without considering other crucial objectives that impact instruction quality, such as instruction length and perplexity. Therefore, we propose a novel approach (i.e., InstOptima) that treats instruction generation as an evolutionary multi-objective optimization problem. In contrast to text edition-based methods, our approach utilizes a large language model (LLM) to simulate instruction operators, including mutation and crossover. Furthermore, we introduce an objective-guided mechanism for these operators, allowing the LLM to comprehend the objectives and enhance the quality of the generated instructions. Experimental results demonstrate improved fine-tuning performance and the generation of a diverse set of high-quality instructions.</abstract>
      <url hash="bbf91499">2023.findings-emnlp.907</url>
      <bibkey>yang-li-2023-instoptima</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.907</doi>
    </paper>
    <paper id="908">
      <title>Less than One-shot: Named Entity Recognition via Extremely Weak Supervision</title>
      <author><first>Letian</first><last>Peng</last></author>
      <author><first>Zihan</first><last>Wang</last></author>
      <author><first>Jingbo</first><last>Shang</last></author>
      <pages>13603-13616</pages>
      <abstract>We study the named entity recognition (NER) problem under the extremely weak supervision (XWS) setting, where only one example entity per type is given in a context-free way. While one can see that XWS is <i>lighter than one-shot</i> in terms of the amount of supervision, we propose a novel method X-NER that can outperform the state-of-the-art one-shot NER methods. We first mine entity spans that are similar to the example entities from an unlabelled training corpus. Instead of utilizing entity span representations from language models, we find it more effective to compare the context distributions before and after the span is replaced by the entity example. We then leverage the top-ranked spans as pseudo-labels to train an NER tagger. Extensive experiments and analyses on 4 NER datasets show the superior end-to-end NER performance of X-NER, outperforming the state-of-the-art few-shot methods with 1-shot supervision and ChatGPT annotations significantly. Finally, our X-NER possesses several notable properties, such as inheriting the cross-lingual abilities of the underlying language models.</abstract>
      <url hash="6fb2c9da">2023.findings-emnlp.908</url>
      <bibkey>peng-etal-2023-less</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.908</doi>
    </paper>
    <paper id="909">
      <title>Focus on the Core: Efficient Attention via Pruned Token Compression for Document Classification</title>
      <author><first>Jungmin</first><last>Yun</last></author>
      <author><first>Mihyeon</first><last>Kim</last></author>
      <author><first>Youngbin</first><last>Kim</last></author>
      <pages>13617-13628</pages>
      <abstract>Transformer-based models have achieved dominant performance in numerous NLP tasks. Despite their remarkable successes, pre-trained transformers such as BERT suffer from a computationally expensive self-attention mechanism that interacts with all tokens, including the ones unfavorable to classification performance. To overcome these challenges, we propose integrating two strategies: token pruning and token combining. Token pruning eliminates less important tokens in the attention mechanism’s key and value as they pass through the layers. Additionally, we adopt fuzzy logic to handle uncertainty and alleviate potential mispruning risks arising from an imbalanced distribution of each token’s importance. Token combining, on the other hand, condenses input sequences into smaller sizes in order to further compress the model. By integrating these two approaches, we not only improve the model’s performance but also reduce its computational demands. Experiments with various datasets demonstrate superior performance compared to baseline models, especially with the best improvement over the existing BERT model, achieving +5%p in accuracy and +5.6%p in F1 score. Additionally, memory cost is reduced to 0.61x, and a speedup of 1.64x is achieved.</abstract>
      <url hash="9e0c3401">2023.findings-emnlp.909</url>
      <bibkey>yun-etal-2023-focus</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.909</doi>
    </paper>
    <paper id="910">
      <title>Semantic Decomposition of Question and <fixed-case>SQL</fixed-case> for Text-to-<fixed-case>SQL</fixed-case> Parsing</title>
      <author><first>Ben</first><last>Eyal</last></author>
      <author><first>Moran</first><last>Mahabi</last></author>
      <author><first>Ophir</first><last>Haroche</last></author>
      <author><first>Amir</first><last>Bachar</last></author>
      <author><first>Michael</first><last>Elhadad</last></author>
      <pages>13629-13645</pages>
      <abstract>Text-to-SQL semantic parsing faces challenges in generalizing to cross-domain and complex queries. Recent research has employed a question decomposition strategy to enhance the parsing of complex SQL queries.However, this strategy encounters two major obstacles: (1) existing datasets lack question decomposition; (2) due to the syntactic complexity of SQL, most complex queries cannot be disentangled into sub-queries that can be readily recomposed. To address these challenges, we propose a new modular Query Plan Language (QPL) that systematically decomposes SQL queries into simple and regular sub-queries. We develop a translator from SQL to QPL by leveraging analysis of SQL server query optimization plans, and we augment the Spider dataset with QPL programs. Experimental results demonstrate that the modular nature of QPL benefits existing semantic-parsing architectures, and training text-to-QPL parsers is more effective than text-to-SQL parsing for semantically equivalent queries. The QPL approach offers two additional advantages: (1) QPL programs can be paraphrased as simple questions, which allows us to create a dataset of (complex question, decomposed questions). Training on this dataset, we obtain a Question Decomposer for data retrieval that is sensitive to database schemas. (2) QPL is more accessible to non-experts for complex queries, leading to more interpretable output from the semantic parser.</abstract>
      <url hash="5158cc93">2023.findings-emnlp.910</url>
      <bibkey>eyal-etal-2023-semantic</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.910</doi>
    </paper>
    <paper id="911">
      <title>Time-Aware Language Modeling for Historical Text Dating</title>
      <author><first>Han</first><last>Ren</last></author>
      <author><first>Hai</first><last>Wang</last></author>
      <author><first>Yajie</first><last>Zhao</last></author>
      <author><first>Yafeng</first><last>Ren</last></author>
      <pages>13646-13656</pages>
      <abstract>Automatic text dating(ATD) is a challenging task since explicit temporal mentions usually do not appear in texts. Existing state-of-the-art approaches learn word representations via language models, whereas most of them ignore diachronic change of words, which may affect the efforts of text modeling. Meanwhile, few of them consider text modeling for long diachronic documents. In this paper, we present a time-aware language model named TALM, to learn temporal word representations by transferring language models of general domains to those of time-specific ones. We also build a hierarchical modeling approach to represent diachronic documents by encoding them with temporal word representations. Experiments on a Chinese diachronic corpus show that our model effectively captures implicit temporal information of words, and outperforms state-of-the-art approaches in historical text dating as well.</abstract>
      <url hash="59966dff">2023.findings-emnlp.911</url>
      <bibkey>ren-etal-2023-time</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.911</doi>
    </paper>
    <paper id="912">
      <title>A Read-and-Select Framework for Zero-shot Entity Linking</title>
      <author><first>Zhenran</first><last>Xu</last></author>
      <author><first>Yulin</first><last>Chen</last></author>
      <author><first>Baotian</first><last>Hu</last></author>
      <author><first>Min</first><last>Zhang</last></author>
      <pages>13657-13666</pages>
      <abstract>Zero-shot entity linking (EL) aims at aligning entity mentions to unseen entities to challenge the generalization ability. Previous methods largely focus on the candidate retrieval stage and ignore the essential candidate ranking stage, which disambiguates among entities and makes the final linking prediction. In this paper, we propose a read-and-select (ReS) framework by modeling the main components of entity disambiguation, i.e., mention-entity matching and cross-entity comparison. First, for each candidate, the reading module leverages mention context to output mention-aware entity representations, enabling mention-entity matching. Then, in the selecting module, we frame the choice of candidates as a sequence labeling problem, and all candidate representations are fused together to enable cross-entity comparison. Our method achieves the state-of-the-art performance on the established zero-shot EL dataset ZESHEL with a 2.55% micro-average accuracy gain, with no need for laborious multi-phase pre-training used in most of the previous work, showing the effectiveness of both mention-entity and cross-entity interaction.</abstract>
      <url hash="e172e859">2023.findings-emnlp.912</url>
      <bibkey>xu-etal-2023-read</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.912</doi>
    </paper>
    <paper id="913">
      <title>Multi-Task Learning of Query Generation and Classification for Generative Conversational Question Rewriting</title>
      <author><first>Sarawoot</first><last>Kongyoung</last></author>
      <author><first>Craig</first><last>MacDonald</last></author>
      <author><first>Iadh</first><last>Ounis</last></author>
      <pages>13667-13678</pages>
      <abstract>In conversational search settings, users ask questions and receive answers as part of a conversation. The ambiguity in the questions is a common challenge, which can be effectively addressed by leveraging contextual information from the conversation history. In this context, determining topic continuity and reformulating questions into well-defined queries are crucial tasks. Previous approaches have typically addressed these tasks either as a classification task in the case of topic continuity or as a text generation task for question reformulation. However, no prior work has combined both tasks to effectively identify ambiguous questions as part of a conversation. In this paper, we propose a Multi-Task Learning (MTL) approach that uses a text generation model for both question rewriting and classification. Our models, based on BART and T5, are trained to rewrite conversational questions and identify follow-up questions simultaneously. We evaluate our approach on multiple test sets and demonstrate that it outperforms single-task learning baselines on the three LIF test sets, with statistically significant improvements ranging from +3.5% to +10.5% in terms of F1 and Micro-F1 scores. We also show that our approach outperforms single-task question rewriting models in passage retrieval on a large OR-QuAC test set.</abstract>
      <url hash="edc4d866">2023.findings-emnlp.913</url>
      <bibkey>kongyoung-etal-2023-multi</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.913</doi>
    </paper>
    <paper id="914">
      <title><fixed-case>D</fixed-case>ep<fixed-case>N</fixed-case>e<fixed-case>CTI</fixed-case>: Dependency-based Nested Compound Type Identification for <fixed-case>S</fixed-case>anskrit</title>
      <author><first>Jivnesh</first><last>Sandhan</last></author>
      <author><first>Yaswanth</first><last>Narsupalli</last></author>
      <author><first>Sreevatsa</first><last>Muppirala</last></author>
      <author><first>Sriram</first><last>Krishnan</last></author>
      <author><first>Pavankumar</first><last>Satuluri</last></author>
      <author><first>Amba</first><last>Kulkarni</last></author>
      <author><first>Pawan</first><last>Goyal</last></author>
      <pages>13679-13692</pages>
      <abstract>Multi-component compounding is a prevalent phenomenon in Sanskrit, and understanding the implicit structure of a compound’s components is crucial for deciphering its meaning. Earlier approaches in Sanskrit have focused on binary compounds and neglected the multi-component compound setting. This work introduces the novel task of nested compound type identification (NeCTI), which aims to identify nested spans of a multi-component compound and decode the implicit semantic relations between them. To the best of our knowledge, this is the first attempt in the field of lexical semantics to propose this task. We present 2 newly annotated datasets including an out-of-domain dataset for this task. We also benchmark these datasets by exploring the efficacy of the standard problem formulations such as nested named entity recognition, constituency parsing and seq2seq, etc. We present a novel framework named DepNeCTI: Dependency-based Nested Compound Type Identifier that surpasses the performance of the best baseline with an average absolute improvement of 13.1 points F1-score in terms of Labeled Span Score (LSS) and a 5-fold enhancement in inference efficiency. In line with the previous findings in the binary Sanskrit compound identification task, context provides benefits for the NeCTI task. The codebase and datasets are publicly available at: https://github.com/yaswanth-iitkgp/DepNeCTI</abstract>
      <url hash="4f273f22">2023.findings-emnlp.914</url>
      <bibkey>sandhan-etal-2023-depnecti</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.914</doi>
    </paper>
    <paper id="915">
      <title><fixed-case>H</fixed-case>e<fixed-case>Q</fixed-case>: a Large and Diverse <fixed-case>H</fixed-case>ebrew Reading Comprehension Benchmark</title>
      <author><first>Amir</first><last>Cohen</last></author>
      <author><first>Hilla</first><last>Merhav-Fine</last></author>
      <author><first>Yoav</first><last>Goldberg</last></author>
      <author><first>Reut</first><last>Tsarfaty</last></author>
      <pages>13693-13705</pages>
      <abstract>Current benchmarks for Hebrew Natural Language Processing (NLP) focus mainly on morpho-syntactic tasks, neglecting the semantic dimension of language understanding. To bridge this gap, we set out to deliver a Hebrew Machine Reading Comprehension (MRC) dataset, where MRC is to be realized as extractive Question Answering. The morphologically-rich nature of Hebrew poses a challenge to this endeavor: the indeterminacy and non-transparency of span boundaries in morphologically complex forms lead to annotation inconsistencies, disagreements, and flaws of standard evaluation metrics. To remedy this, we devise a novel set of guidelines, a controlled crowdsourcing protocol, and revised evaluation metrics, that are suitable for the morphologically rich nature of the language. Our resulting benchmark, HeQ (Hebrew QA), features 30,147 diverse question-answer pairs derived from both Hebrew Wikipedia articles and Israeli tech news. Our empirical investigation reveals that standard evaluation metrics such as F1 Scores and Exact Match (EM) are not appropriate for Hebrew (and other MRLs), and we propose a relevant enhancement. In addition, our experiments show low correlation between models’ performance on morpho-syntactic tasks and on MRC, which suggests that models that are designed for the former might underperform on semantic-heavy tasks. The development and exploration of HeQ illustrate some of the challenges MRLs pose in natural language understanding (NLU), fostering progression towards more and better NLU models for Hebrew and other MRLs.</abstract>
      <url hash="6de7e756">2023.findings-emnlp.915</url>
      <bibkey>cohen-etal-2023-heq</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.915</doi>
    </paper>
    <paper id="916">
      <title><fixed-case>HANSEN</fixed-case>: Human and <fixed-case>AI</fixed-case> Spoken Text Benchmark for Authorship Analysis</title>
      <author><first>Nafis</first><last>Tripto</last></author>
      <author><first>Adaku</first><last>Uchendu</last></author>
      <author><first>Thai</first><last>Le</last></author>
      <author><first>Mattia</first><last>Setzu</last></author>
      <author><first>Fosca</first><last>Giannotti</last></author>
      <author><first>Dongwon</first><last>Lee</last></author>
      <pages>13706-13724</pages>
      <abstract><tex-math>\textit{Authorship Analysis}</tex-math>, also known as stylometry, has been an essential aspect of Natural Language Processing (NLP) for a long time. Likewise, the recent advancement of Large Language Models (LLMs) has made authorship analysis increasingly crucial for distinguishing between human-written and AI-generated texts. However, these authorship analysis tasks have primarily been focused on <tex-math>\textit{written texts}</tex-math>, not considering <tex-math>\textit{spoken texts}</tex-math>. Thus, we introduce the largest benchmark for spoken texts - <tex-math>{\sf HANSEN}</tex-math>(<tex-math>\underline{H}</tex-math>uman <tex-math>\underline{AN}</tex-math>d ai <tex-math>\underline{S}</tex-math>poken t<tex-math>\underline{E}</tex-math>xt be<tex-math>\underline{N}</tex-math>chmark). <tex-math>{\sf HANSEN}</tex-math> encompasses meticulous curation of existing speech datasets accompanied by transcripts, alongside the creation of novel AI-generated spoken text datasets. Together, it comprises 17 human datasets, and AI-generated spoken texts created using 3 prominent LLMs: ChatGPT, PaLM2, and Vicuna13B. To evaluate and demonstrate the utility of <tex-math>{\sf HANSEN}</tex-math>, we perform Authorship Attribution (AA) &amp; Author Verification (AV) on human-spoken datasets and conducted Human vs. AI text detection using state-of-the-art (SOTA) models. While SOTA methods, such as, character n-gram or Transformer-based model, exhibit similar AA &amp; AV performance in human-spoken datasets compared to written ones, there is much room for improvement in AI-generated spoken text detection. The <tex-math>{\sf HANSEN}</tex-math> benchmark is available at: https://huggingface.co/datasets/HANSEN-REPO/HANSEN</abstract>
      <url hash="d8f6b4bf">2023.findings-emnlp.916</url>
      <bibkey>tripto-etal-2023-hansen</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.916</doi>
    </paper>
    <paper id="917">
      <title>Data Augmentation for Code Translation with Comparable Corpora and Multiple References</title>
      <author><first>Yiqing</first><last>Xie</last></author>
      <author><first>Atharva</first><last>Naik</last></author>
      <author><first>Daniel</first><last>Fried</last></author>
      <author><first>Carolyn</first><last>Rose</last></author>
      <pages>13725-13739</pages>
      <abstract>One major challenge of translating code between programming languages is that parallel training data is often limited. To overcome this challenge, we present two data augmentation techniques, one that builds comparable corpora (i.e., code pairs with similar functionality), and another that augments existing parallel data with multiple reference translations. Specifically, we build and analyze multiple types of comparable corpora, including programs generated from natural language documentation using a code generation model. Furthermore, to reduce overfitting to a single reference translation, we automatically generate additional translation references for available parallel data and filter the translations by unit tests, which increases variation in target translations. Experiments show that our data augmentation techniques significantly improve CodeT5 for translation between Java, Python, and C++ by an average of 7.5% Computational Accuracy (CA@1), which verifies the correctness of translations by execution. The code is available at https://github.com/Veronicium/CMTrans.</abstract>
      <url hash="87c73bab">2023.findings-emnlp.917</url>
      <bibkey>xie-etal-2023-data</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.917</doi>
    </paper>
    <paper id="918">
      <title>Multilingual Generation and Answering of Questions from Texts and Knowledge Graphs</title>
      <author><first>Kelvin</first><last>Han</last></author>
      <author><first>Claire</first><last>Gardent</last></author>
      <pages>13740-13756</pages>
      <abstract>The ability to bridge Question Generation (QG) and Question Answering (QA) across structured and unstructured modalities has the potential for aiding different NLP applications. One key application is in QA-based methods that have recently been shown to be useful for automatically evaluating Natural Language (NL) texts generated from Knowledge Graphs (KG). While methods have been proposed for QG-QA across these modalities, these efforts have been in English only; in this work, we bring multilinguality (Brazilian Portuguese and Russian) to multimodal (KG and NL) QG-QA. Using synthetic data generation and machine translation to produce QG-QA data that is aligned between graph and text, we are able to train multimodal, multi-task models that can perform multimodal QG and QA in Portuguese and Russian. We show that our approach outperforms a baseline which is derived from previous work on English and adapted to handle these two languages.</abstract>
      <url hash="ce387690">2023.findings-emnlp.918</url>
      <bibkey>han-gardent-2023-multilingual</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.918</doi>
    </paper>
    <paper id="919">
      <title><fixed-case>I</fixed-case>nfo<fixed-case>D</fixed-case>iffusion: Information Entropy Aware Diffusion Process for Non-Autoregressive Text Generation</title>
      <author><first>Renzhi</first><last>Wang</last></author>
      <author><first>Jing</first><last>Li</last></author>
      <author><first>Piji</first><last>Li</last></author>
      <pages>13757-13770</pages>
      <abstract>Diffusion models have garnered considerable interest in the field of text generation. Several studies have explored text diffusion models with different structures and applied them to various tasks, including named entity recognition and summarization. However, there exists a notable disparity between the “easy-first” text generation process of current diffusion models and the “keyword-first” natural text generation process of humans, which has received limited attention. To bridge this gap, we propose InfoDiffusion, a non-autoregressive text diffusion model. Our approach introduces a “keyinfo-first” generation strategy and incorporates a noise schedule based on the amount of text information. In addition, InfoDiffusion combines self-conditioning with a newly proposed partially noising model structure. Experimental results show that InfoDiffusion outperforms the baseline model in terms of generation quality and diversity, as well as exhibiting higher sampling efficiency.</abstract>
      <url hash="a02f024c">2023.findings-emnlp.919</url>
      <bibkey>wang-etal-2023-infodiffusion</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.919</doi>
    </paper>
    <paper id="920">
      <title>Enhancing Scalability of Pre-trained Language Models via Efficient Parameter Sharing</title>
      <author><first>Peiyu</first><last>Liu</last></author>
      <author><first>Ze-Feng</first><last>Gao</last></author>
      <author><first>Yushuo</first><last>Chen</last></author>
      <author><first>Xin</first><last>Zhao</last></author>
      <author><first>Ji-Rong</first><last>Wen</last></author>
      <pages>13771-13785</pages>
      <abstract>In this paper, we propose a highly parameter-efficient approach to scaling pre-trained language models (PLMs) to a deeper model depth. Unlike prior work that shares all parameters or uses extra blocks, we design a more capable parameter-sharing architecture based on matrix product operator (MPO), an efficient tensor decomposition method to factorize the parameter matrix into a set of local tensors. Based on such a decomposition, we share the important local tensor across all layers for reducing the model size and meanwhile keep layer-specific tensors (also using Adapters) for enhancing the adaptation flexibility. To improve the model training, we further propose a stable initialization algorithm tailored for the MPO-based architecture. Extensive experiments have demonstrated the effectiveness of our proposed model in enhancing scalability and achieving higher performance (i.e., with fewer parameters than BERT-base, we successfully scale the model depth by a factor of 4x and even achieve 0.1 points higher than BERT-large for GLUE score). The code to reproduce the results of this paper can be found at https://github.com/RUCAIBox/MPOBERT-code.</abstract>
      <url hash="f2e09138">2023.findings-emnlp.920</url>
      <bibkey>liu-etal-2023-enhancing-scalability</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.920</doi>
    </paper>
    <paper id="921">
      <title>Boosting Prompt-Based Self-Training With Mapping-Free Automatic Verbalizer for Multi-Class Classification</title>
      <author><first>Yookyung</first><last>Kho</last></author>
      <author><first>Jaehee</first><last>Kim</last></author>
      <author><first>Pilsung</first><last>Kang</last></author>
      <pages>13786-13800</pages>
      <abstract>Recently, prompt-based fine-tuning has garnered considerable interest as a core technique for few-shot text classification task. This approach reformulates the fine-tuning objective to align with the Masked Language Modeling (MLM) objective. Leveraging unlabeled data, prompt-based self-training has shown greater effectiveness in binary and three-class classification. However, prompt-based self-training for multi-class classification has not been adequately investigated, despite its significant applicability to real-world scenarios. Moreover, extending current methods to multi-class classification suffers from the verbalizer that extracts the predicted value of manually pre-defined single label word for each class from MLM predictions. Consequently, we introduce a novel, efficient verbalizer structure, named Mapping-free Automatic Verbalizer (MAV). Comprising two fully connected layers, MAV serves as a trainable verbalizer that automatically extracts the requisite word features for classification by capitalizing on all available information from MLM predictions. Experimental results on five multi-class classification datasets indicate MAV’s superior self-training efficacy.</abstract>
      <url hash="7d77daeb">2023.findings-emnlp.921</url>
      <bibkey>kho-etal-2023-boosting</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.921</doi>
    </paper>
    <paper id="922">
      <title>On the Impact of Cross-Domain Data on <fixed-case>G</fixed-case>erman Language Models</title>
      <author><first>Amin</first><last>Dada</last></author>
      <author><first>Aokun</first><last>Chen</last></author>
      <author><first>Cheng</first><last>Peng</last></author>
      <author><first>Kaleb</first><last>Smith</last></author>
      <author><first>Ahmad</first><last>Idrissi-Yaghir</last></author>
      <author><first>Constantin</first><last>Seibold</last></author>
      <author><first>Jianning</first><last>Li</last></author>
      <author><first>Lars</first><last>Heiliger</last></author>
      <author><first>Christoph</first><last>Friedrich</last></author>
      <author><first>Daniel</first><last>Truhn</last></author>
      <author><first>Jan</first><last>Egger</last></author>
      <author><first>Jiang</first><last>Bian</last></author>
      <author><first>Jens</first><last>Kleesiek</last></author>
      <author><first>Yonghui</first><last>Wu</last></author>
      <pages>13801-13813</pages>
      <abstract>Traditionally, large language models have been either trained on general web crawls or domain-specific data. However, recent successes of generative large language models, have shed light on the benefits of cross-domain datasets. To examine the significance of prioritizing data diversity over quality, we present a German dataset comprising texts from five domains, along with another dataset aimed at containing high-quality data. Through training a series of models ranging between 122M and 750M parameters on both datasets, we conduct a comprehensive benchmark on multiple downstream tasks. Our findings demonstrate that the models trained on the cross-domain dataset outperform those trained on quality data alone, leading to improvements up to 4.45% over the previous state-of-the-art.</abstract>
      <url hash="38b7b802">2023.findings-emnlp.922</url>
      <bibkey>dada-etal-2023-impact</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.922</doi>
    </paper>
    <paper id="923">
      <title>Dialect-to-Standard Normalization: A Large-Scale Multilingual Evaluation</title>
      <author><first>Olli</first><last>Kuparinen</last></author>
      <author><first>Aleksandra</first><last>Miletić</last></author>
      <author><first>Yves</first><last>Scherrer</last></author>
      <pages>13814-13828</pages>
      <abstract>Text normalization methods have been commonly applied to historical language or user-generated content, but less often to dialectal transcriptions. In this paper, we introduce dialect-to-standard normalization – i.e., mapping phonetic transcriptions from different dialects to the orthographic norm of the standard variety – as a distinct sentence-level character transduction task and provide a large-scale analysis of dialect-to-standard normalization methods. To this end, we compile a multilingual dataset covering four languages: Finnish, Norwegian, Swiss German and Slovene. For the two biggest corpora, we provide three different data splits corresponding to different use cases for automatic normalization. We evaluate the most successful sequence-to-sequence model architectures proposed for text normalization tasks using different tokenization approaches and context sizes. We find that a character-level Transformer trained on sliding windows of three words works best for Finnish, Swiss German and Slovene, whereas the pre-trained byT5 model using full sentences obtains the best results for Norwegian. Finally, we perform an error analysis to evaluate the effect of different data splits on model performance.</abstract>
      <url hash="75becd8a">2023.findings-emnlp.923</url>
      <bibkey>kuparinen-etal-2023-dialect</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.923</doi>
    </paper>
    <paper id="924">
      <title>Re-Examining Summarization Evaluation across Multiple Quality Criteria</title>
      <author><first>Ori</first><last>Ernst</last></author>
      <author><first>Ori</first><last>Shapira</last></author>
      <author><first>Ido</first><last>Dagan</last></author>
      <author><first>Ran</first><last>Levy</last></author>
      <pages>13829-13838</pages>
      <abstract>The common practice for assessing automatic evaluation metrics is to measure the correlation between their induced system rankings and those obtained by reliable human evaluation, where a higher correlation indicates a better metric. Yet, an intricate setting arises when an NLP task is evaluated by multiple Quality Criteria (QCs), like for text summarization where prominent criteria including relevance, consistency, fluency and coherence. In this paper, we challenge the soundness of this methodology when multiple QCs are involved, concretely for the summarization case. First, we show that the allegedly best metrics for certain QCs actually do not perform well, failing to detect even drastic summary corruptions with respect to the considered QC. To explain this, we show that some of the high correlations obtained in the multi-QC setup are spurious. Finally, we propose a procedure that may help detecting this effect. Overall, our findings highlight the need for further investigating metric evaluation methodologies for the multiple-QC case.</abstract>
      <url hash="e97d79f9">2023.findings-emnlp.924</url>
      <bibkey>ernst-etal-2023-examining</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.924</doi>
    </paper>
    <paper id="925">
      <title>A Parallel Corpus for <fixed-case>V</fixed-case>ietnamese Central-Northern Dialect Text Transfer</title>
      <author><first>Thang</first><last>Le</last></author>
      <author><first>Anh</first><last>Luu</last></author>
      <pages>13839-13855</pages>
      <abstract>The Vietnamese language embodies dialectal variants closely attached to the nation’s three macro-regions: the Northern, Central and Southern regions. As the northern dialect forms the basis of the standard language, it’s considered the prestige dialect. While the northern dialect differs from the remaining two in certain aspects, it almost shares an identical lexicon with the southern dialect, making the textual attributes nearly interchangeable. In contrast, the central dialect possesses a number of unique vocabularies and is less mutually intelligible to the standard dialect. Through preliminary experiments, we observe that current NLP models do not possess understandings of the Vietnamese central dialect text, which most likely originates from the lack of resources. To facilitate research on this domain, we introduce a new parallel corpus for Vietnamese central-northern dialect text transfer. Via exhaustive benchmarking, we discover monolingual language models’ superiority over their multilingual counterparts on the dialect transfer task. We further demonstrate that fine-tuned transfer models can seamlessly improve the performance of existing NLP systems on the central dialect domain with dedicated results in translation and text-image retrieval tasks.</abstract>
      <url hash="183115f6">2023.findings-emnlp.925</url>
      <bibkey>le-luu-2023-parallel</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.925</doi>
    </paper>
    <paper id="926">
      <title>A Comprehensive Evaluation of Tool-Assisted Generation Strategies</title>
      <author><first>Alon</first><last>Jacovi</last></author>
      <author><first>Avi</first><last>Caciularu</last></author>
      <author><first>Jonathan</first><last>Herzig</last></author>
      <author><first>Roee</first><last>Aharoni</last></author>
      <author><first>Bernd</first><last>Bohnet</last></author>
      <author><first>Mor</first><last>Geva</last></author>
      <pages>13856-13878</pages>
      <abstract>A growing area of research investigates augmenting language models with tools (e.g., search engines, calculators) to overcome their shortcomings (e.g., missing or incorrect knowledge, incorrect logical inferences). Various few-shot tool-usage strategies have been proposed. However, there is no systematic and fair comparison across different strategies, or between these strategies and strong baselines that do not leverage tools. We conduct an extensive empirical analysis, finding that (1) across various datasets, example difficulty levels, and models, strong no-tool baselines are competitive to tool-assisted strategies, implying that effectively using tools with in-context demonstrations is a difficult unsolved problem; (2) for knowledge-retrieval tasks, strategies that *refine* incorrect outputs with tools outperform strategies that retrieve relevant information *ahead of* or *during generation*; (3) tool-assisted strategies are expensive in the number of tokens they require to work—incurring additional costs by orders of magnitude—which does not translate into significant improvement in performance. Overall, our findings suggest that few-shot tool integration is still an open challenge, emphasizing the need for comprehensive evaluations of future strategies to accurately assess their *benefits* and *costs*.</abstract>
      <url hash="baaa094a">2023.findings-emnlp.926</url>
      <bibkey>jacovi-etal-2023-comprehensive</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.926</doi>
    </paper>
    <paper id="927">
      <title><fixed-case>I</fixed-case>nherit<fixed-case>S</fixed-case>umm: A General, Versatile and Compact Summarizer by Distilling from <fixed-case>GPT</fixed-case></title>
      <author><first>Yichong</first><last>Xu</last></author>
      <author><first>Ruochen</first><last>Xu</last></author>
      <author><first>Dan</first><last>Iter</last></author>
      <author id="yang-liu-edinburgh"><first>Yang</first><last>Liu</last></author>
      <author><first>Shuohang</first><last>Wang</last></author>
      <author><first>Chenguang</first><last>Zhu</last></author>
      <author><first>Michael</first><last>Zeng</last></author>
      <pages>13879-13892</pages>
      <abstract>While large models such as GPT-3 demonstrate exceptional performance in zeroshot and fewshot summarization tasks, their extensive serving and fine-tuning costs hinder their utilization in various applications. Conversely, previous studies have found that although automatic metrics tend to favor smaller fine-tuned models, the quality of the summaries they generate is inferior to that of larger models like GPT-3 when assessed by human evaluators. To address this issue, we propose InheritSumm, a versatile and compact summarization model derived from GPT-3.5 through distillation. InheritSumm not only exhibits comparable zeroshot and fewshot summarization capabilities to GPT-3.5 but is also sufficiently compact for fine-tuning purposes. Experimental results demonstrate that InheritSumm achieves similar or superior performance to GPT-3.5 in zeroshot and fewshot settings. Furthermore, it outperforms the previously established best small models in both prefix-tuning and full-data fine-tuning scenarios.</abstract>
      <url hash="ff5e8569">2023.findings-emnlp.927</url>
      <bibkey>xu-etal-2023-inheritsumm</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.927</doi>
    </paper>
    <paper id="928">
      <title>Learning to love diligent trolls: Accounting for rater effects in the dialogue safety task</title>
      <author><first>Michael</first><last>Ilagan</last></author>
      <pages>13893-13899</pages>
      <abstract>Chatbots have the risk of generating offensive utterances, which must be avoided. Post-deployment, one way for a chatbot to continuously improve is to source utterance/label pairs from feedback by live users. However, among users are trolls, who provide training examples with incorrect labels. To de-troll training data, previous work removed training examples that have high user-aggregated cross-validation (CV) error. However, CV is expensive; and in a coordinated attack, CV may be overwhelmed by trolls in number and in consistency among themselves. In the present work, I address both limitations by proposing a solution inspired by methodology in automated essay scoring (AES): have multiple users rate each utterance, then perform latent class analysis (LCA) to infer correct labels. As it does not require GPU computations, LCA is inexpensive. In experiments, I found that the AES-like solution can infer training labels with high accuracy when trolls are consistent, even when trolls are the majority.</abstract>
      <url hash="71fffebe">2023.findings-emnlp.928</url>
      <bibkey>ilagan-2023-learning</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.928</doi>
    </paper>
    <paper id="929">
      <title>Can <fixed-case>C</fixed-case>hat<fixed-case>GPT</fixed-case> Perform Reasoning Using the <fixed-case>IRAC</fixed-case> Method in Analyzing Legal Scenarios Like a Lawyer?</title>
      <author><first>Xiaoxi</first><last>Kang</last></author>
      <author><first>Lizhen</first><last>Qu</last></author>
      <author><first>Lay-Ki</first><last>Soon</last></author>
      <author><first>Adnan</first><last>Trakic</last></author>
      <author><first>Terry</first><last>Zhuo</last></author>
      <author><first>Patrick</first><last>Emerton</last></author>
      <author><first>Genevieve</first><last>Grant</last></author>
      <pages>13900-13923</pages>
      <abstract>Large Language Models (LLMs), such as ChatGPT, have drawn a lot of attentions recently in the legal domain due to its emergent ability to tackle a variety of legal tasks. However, it is still unknown if LLMs are able to analyze a legal case and perform reasoning in the same manner as lawyers. Therefore, we constructed a novel corpus consisting of scenarios pertain to Contract Acts Malaysia and Australian Social Act for Dependent Child. ChatGPT is applied to perform analysis on the corpus using the IRAC method, which is a framework widely used by legal professionals for organizing legal analysis. Each scenario in the corpus is annotated with a complete IRAC analysis in a semi-structured format so that both machines and legal professionals are able to interpret and understand the annotations. In addition, we conducted the first empirical assessment of ChatGPT for IRAC analysis in order to understand how well it aligns with the analysis of legal professionals. Our experimental results shed lights on possible future research directions to improve alignments between LLMs and legal experts in terms of legal reasoning.</abstract>
      <url hash="40f6581a">2023.findings-emnlp.929</url>
      <bibkey>kang-etal-2023-chatgpt</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.929</doi>
    </paper>
    <paper id="930">
      <title>Coverage-based Example Selection for In-Context Learning</title>
      <author><first>Shivanshu</first><last>Gupta</last></author>
      <author><first>Matt</first><last>Gardner</last></author>
      <author><first>Sameer</first><last>Singh</last></author>
      <pages>13924-13950</pages>
      <abstract>In-context learning (ICL), the ability of large language models to perform novel tasks by conditioning on a prompt with a few task examples, requires these examples to be informative about the test instance. The standard approach of independently ranking and selecting the most similar examples selects redundant examples while omitting important information. In this work, we show that BERTScore-Recall (BSR) selects better examples that demonstrate more of the salient aspects, e.g. reasoning patterns, of the test input. We further extend BSR and many standard metrics to easily optimizable set-level metrics, giving still better coverage of those salient aspects. On 15 datasets spanning 6 tasks and with 7 diverse LLMs, we show that (1) BSR is the superior metric for in-context example selection across the board, and (2) for compositional tasks, set selection using Set-BSR outperforms independent ranking by up to 17 points on average and, despite being training-free, surpasses methods that leverage task or LLM-specific training.</abstract>
      <url hash="8fb1b5ab">2023.findings-emnlp.930</url>
      <bibkey>gupta-etal-2023-coverage</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.930</doi>
    </paper>
    <paper id="931">
      <title>Are Structural Concepts Universal in Transformer Language Models? Towards Interpretable Cross-Lingual Generalization</title>
      <author><first>Ningyu</first><last>Xu</last></author>
      <author><first>Qi</first><last>Zhang</last></author>
      <author><first>Jingting</first><last>Ye</last></author>
      <author><first>Menghan</first><last>Zhang</last></author>
      <author><first>Xuanjing</first><last>Huang</last></author>
      <pages>13951-13976</pages>
      <abstract>Large language models (LLMs) have exhibited considerable cross-lingual generalization abilities, whereby they implicitly transfer knowledge across languages. However, the transfer is not equally successful for all languages, especially for low-resource ones, which poses an ongoing challenge. It is unclear whether we have reached the limits of implicit cross-lingual generalization and if explicit knowledge transfer is viable. In this paper, we investigate the potential for explicitly aligning conceptual correspondence between languages to enhance cross-lingual generalization. Using the syntactic aspect of language as a testbed, our analyses of 43 languages reveal a high degree of alignability among the spaces of structural concepts within each language for both encoder-only and decoder-only LLMs. We then propose a meta-learning-based method to learn to align conceptual spaces of different languages, which facilitates zero-shot and few-shot generalization in concept classification and also offers insights into the cross-lingual in-context learning phenomenon. Experiments on syntactic analysis tasks show that our approach achieves competitive results with state-of-the-art methods and narrows the performance gap between languages, particularly benefiting those with limited resources.</abstract>
      <url hash="1d72f4bb">2023.findings-emnlp.931</url>
      <bibkey>xu-etal-2023-structural</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.931</doi>
    </paper>
    <paper id="932">
      <title>Thorny Roses: Investigating the Dual Use Dilemma in Natural Language Processing</title>
      <author><first>Lucie-Aimée</first><last>Kaffee</last></author>
      <author><first>Arnav</first><last>Arora</last></author>
      <author><first>Zeerak</first><last>Talat</last></author>
      <author><first>Isabelle</first><last>Augenstein</last></author>
      <pages>13977-13998</pages>
      <abstract>Dual use, the intentional, harmful reuse of technology and scientific artefacts, is an ill-defined problem within the context of Natural Language Processing (NLP). As large language models (LLMs) have advanced in their capabilities and become more accessible, the risk of their intentional misuse becomes more prevalent. To prevent such intentional malicious use, it is necessary for NLP researchers and practitioners to understand and mitigate the risks of their research. Hence, we present an NLP-specific definition of dual use informed by researchers and practitioners in the field. Further, we propose a checklist focusing on dual-use in NLP, that can be integrated into existing conference ethics-frameworks. The definition and checklist are created based on a survey of NLP researchers and practitioners.</abstract>
      <url hash="9d7c4a7d">2023.findings-emnlp.932</url>
      <bibkey>kaffee-etal-2023-thorny</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.932</doi>
    </paper>
    <paper id="933">
      <title><fixed-case>BYOC</fixed-case>: Personalized Few-Shot Classification with Co-Authored Class Descriptions</title>
      <author><first>Arth</first><last>Bohra</last></author>
      <author><first>Govert</first><last>Verkes</last></author>
      <author><first>Artem</first><last>Harutyunyan</last></author>
      <author><first>Pascal</first><last>Weinberger</last></author>
      <author><first>Giovanni</first><last>Campagna</last></author>
      <pages>13999-14015</pages>
      <abstract>Text classification is a well-studied and versatile building block for many NLP applications. Yet, existing approaches require either large annotated corpora to train a model with or, when using large language models as a base, require carefully crafting the prompt as well as using a long context that can fit many examples. As a result, it is not possible for end-users to build classifiers for themselves. To address this issue, we propose a novel approach to few-shot text classification using an LLM. Rather than few-shot examples, the LLM is prompted with descriptions of the salient features of each class. These descriptions are coauthored by the user and the LLM interactively: while the user annotates each few-shot example, the LLM asks relevant questions that the user answers. Examples, questions, and answers are summarized to form the classification prompt. Our experiments show that our approach yields high accuracy classifiers, within 79% of the performance of models trained with significantly larger datasets while using only 1% of their training sets. Additionally, in a study with 30 participants, we show that end-users are able to build classifiers to suit their specific needs. The personalized classifiers show an average accuracy of 90%, which is 15% higher than the state-of-the-art approach.</abstract>
      <url hash="08762312">2023.findings-emnlp.933</url>
      <bibkey>bohra-etal-2023-byoc</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.933</doi>
    </paper>
    <paper id="934">
      <title>Approximating <fixed-case>CKY</fixed-case> with Transformers</title>
      <author><first>Ghazal</first><last>Khalighinejad</last></author>
      <author><first>Ollie</first><last>Liu</last></author>
      <author><first>Sam</first><last>Wiseman</last></author>
      <pages>14016-14030</pages>
      <abstract>We investigate the ability of transformer models to approximate the CKY algorithm, using them to directly predict a sentence’s parse and thus avoid the CKY algorithm’s cubic dependence on sentence length. We find that on standard constituency parsing benchmarks this approach achieves competitive or better performance than comparable parsers that make use of CKY, while being faster. We also evaluate the viability of this approach for parsing under <i>random</i> PCFGs. Here we find that performance declines as the grammar becomes more ambiguous, suggesting that the transformer is not fully capturing the CKY computation. However, we also find that incorporating additional inductive bias is helpful, and we propose a novel approach that makes use of gradients with respect to chart representations in predicting the parse, in analogy with the CKY algorithm being a subgradient of a partition function variant with respect to the chart.</abstract>
      <url hash="2afcc21f">2023.findings-emnlp.934</url>
      <bibkey>khalighinejad-etal-2023-approximating</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.934</doi>
    </paper>
    <paper id="935">
      <title><fixed-case>D</fixed-case>ial<fixed-case>G</fixed-case>uide: Aligning Dialogue Model Behavior with Developer Guidelines</title>
      <author><first>Prakhar</first><last>Gupta</last></author>
      <author id="yang-liu"><first>Yang</first><last>Liu</last></author>
      <author><first>Di</first><last>Jin</last></author>
      <author><first>Behnam</first><last>Hedayatnia</last></author>
      <author><first>Spandana</first><last>Gella</last></author>
      <author><first>Sijia</first><last>Liu</last></author>
      <author><first>Patrick</first><last>Lange</last></author>
      <author><first>Julia</first><last>Hirschberg</last></author>
      <author><first>Dilek</first><last>Hakkani-Tur</last></author>
      <pages>14031-14047</pages>
      <abstract>Dialogue models are able to generate coherent and fluent responses, but they can still be challenging to control and may produce non-engaging, unsafe results. This unpredictability diminishes user trust and can hinder the use of the models in the real world. To address this, we introduce DialGuide, a novel framework for controlling dialogue model behavior using natural language rules, or guidelines. These guidelines provide information about the context they are applicable to and what should be included in the response, allowing the models to generate responses that are more closely aligned with the developer’s expectations and intent. We evaluate DialGuide on three tasks in open-domain dialogue response generation: guideline selection, response generation, and response entailment verification. Our dataset contains 10,737 positive and 15,467 negative dialogue context-response-guideline triplets across two domains - chit-chat and safety. We provide baseline models for the tasks and benchmark their performance. We also demonstrate that DialGuide is effective in the dialogue safety domain, producing safe and engaging responses that follow developer guidelines.</abstract>
      <url hash="557a2d9e">2023.findings-emnlp.935</url>
      <bibkey>gupta-etal-2023-dialguide</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.935</doi>
    </paper>
    <paper id="936">
      <title><fixed-case>RWKV</fixed-case>: Reinventing <fixed-case>RNN</fixed-case>s for the Transformer Era</title>
      <author><first>Bo</first><last>Peng</last></author>
      <author><first>Eric</first><last>Alcaide</last></author>
      <author><first>Quentin</first><last>Anthony</last></author>
      <author><first>Alon</first><last>Albalak</last></author>
      <author><first>Samuel</first><last>Arcadinho</last></author>
      <author><first>Stella</first><last>Biderman</last></author>
      <author><first>Huanqi</first><last>Cao</last></author>
      <author><first>Xin</first><last>Cheng</last></author>
      <author><first>Michael</first><last>Chung</last></author>
      <author><first>Leon</first><last>Derczynski</last></author>
      <author><first>Xingjian</first><last>Du</last></author>
      <author><first>Matteo</first><last>Grella</last></author>
      <author><first>Kranthi</first><last>Gv</last></author>
      <author><first>Xuzheng</first><last>He</last></author>
      <author><first>Haowen</first><last>Hou</last></author>
      <author><first>Przemyslaw</first><last>Kazienko</last></author>
      <author><first>Jan</first><last>Kocon</last></author>
      <author><first>Jiaming</first><last>Kong</last></author>
      <author><first>Bartłomiej</first><last>Koptyra</last></author>
      <author><first>Hayden</first><last>Lau</last></author>
      <author><first>Jiaju</first><last>Lin</last></author>
      <author><first>Krishna Sri Ipsit</first><last>Mantri</last></author>
      <author><first>Ferdinand</first><last>Mom</last></author>
      <author><first>Atsushi</first><last>Saito</last></author>
      <author><first>Guangyu</first><last>Song</last></author>
      <author><first>Xiangru</first><last>Tang</last></author>
      <author><first>Johan</first><last>Wind</last></author>
      <author><first>Stanisław</first><last>Woźniak</last></author>
      <author><first>Zhenyuan</first><last>Zhang</last></author>
      <author><first>Qinghua</first><last>Zhou</last></author>
      <author><first>Jian</first><last>Zhu</last></author>
      <author><first>Rui-Jie</first><last>Zhu</last></author>
      <pages>14048-14077</pages>
      <abstract>Transformers have revolutionized almost all natural language processing (NLP) tasks but suffer from memory and computational complexity that scales quadratically with sequence length. In contrast, recurrent neural networks (RNNs) exhibit linear scaling in memory and computational requirements but struggle to match the same performance as Transformers due to limitations in parallelization and scalability. We propose a novel model architecture, Receptance Weighted Key Value (RWKV), that combines the efficient parallelizable training of transformers with the efficient inference of RNNs. Our approach leverages a linear attention mechanism and allows us to formulate the model as either a Transformer or an RNN, thus parallelizing computations during training and maintains constant computational and memory complexity during inference. We scale our models as large as 14 billion parameters, by far the largest dense RNN ever trained, and find RWKV performs on par with similarly sized Transformers, suggesting future work can leverage this architecture to create more efficient models. This work presents a significant step towards reconciling trade-offs between computational efficiency and model performance in sequence processing tasks.</abstract>
      <url hash="4552e07b">2023.findings-emnlp.936</url>
      <bibkey>peng-etal-2023-rwkv</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.936</doi>
    </paper>
    <paper id="937">
      <title>Who Wrote it and Why? Prompting Large-Language Models for Authorship Verification</title>
      <author><first>Chia-Yu</first><last>Hung</last></author>
      <author><first>Zhiqiang</first><last>Hu</last></author>
      <author><first>Yujia</first><last>Hu</last></author>
      <author><first>Roy</first><last>Lee</last></author>
      <pages>14078-14084</pages>
      <abstract>Authorship verification (AV) is a fundamental task in natural language processing (NLP) and computational linguistics, with applications in forensic analysis, plagiarism detection, and identification of deceptive content. Existing AV techniques, including traditional stylometric and deep learning approaches, face limitations in terms of data requirements and lack of explainability. To address these limitations, this paper proposes PromptAV, a novel technique that leverages Large-Language Models (LLMs) for AV by providing step-by-step stylometric explanation prompts. PromptAV outperforms state-of-the-art baselines, operates effectively with limited training data, and enhances interpretability through intuitive explanations, showcasing its potential as an effective and interpretable solution for the AV task.</abstract>
      <url hash="54f6396c">2023.findings-emnlp.937</url>
      <bibkey>hung-etal-2023-wrote</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.937</doi>
    </paper>
    <paper id="938">
      <title>Transitioning Representations between Languages for Cross-lingual Event Detection via Langevin Dynamics</title>
      <author><first>Chien</first><last>Nguyen</last></author>
      <author id="huy-nguyen-bcl"><first>Huy</first><last>Nguyen</last></author>
      <author><first>Franck</first><last>Dernoncourt</last></author>
      <author><first>Thien</first><last>Nguyen</last></author>
      <pages>14085-14093</pages>
      <abstract>Cross-lingual transfer learning (CLTL) for event detection (ED) aims to develop models in high-resource source languages that can be directly applied to produce effective performance for lower-resource target languages. Previous research in this area has focused on representation matching methods to develop a language-universal representation space into which source- and target-language example representations can be mapped to achieve cross-lingual transfer. However, as this approach modifies the representations for the source-language examples, the models might lose discriminative features for ED that are learned over training data of the source language to prevent effective predictions. To this end, our work introduces a novel approach for cross-lingual ED where we only aim to transition the representations for the target-language examples into the source-language space, thus preserving the representations in the source language and their discriminative information. Our method introduces Langevin Dynamics to perform representation transition and a semantic preservation framework to retain event type features during the transition process. Extensive experiments over three languages demonstrate the state-of-the-art performance for ED in CLTL.</abstract>
      <url hash="bfe4f9b9">2023.findings-emnlp.938</url>
      <bibkey>nguyen-etal-2023-transitioning</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.938</doi>
    </paper>
    <paper id="939">
      <title><fixed-case>VISIT</fixed-case>: Visualizing and Interpreting the Semantic Information Flow of Transformers</title>
      <author><first>Shahar</first><last>Katz</last></author>
      <author><first>Yonatan</first><last>Belinkov</last></author>
      <pages>14094-14113</pages>
      <abstract>Recent advances in interpretability suggest we can project weights and hidden states of transformer-based language models (LMs) to their vocabulary, a transformation that makes them more human interpretable. In this paper, we investigate LM attention heads and memory values, the vectors the models dynamically create and recall while processing a given input. By analyzing the tokens they represent through this projection, we identify patterns in the information flow inside the attention mechanism. Based on our discoveries, we create a tool to visualize a forward pass of Generative Pre-trained Transformers (GPTs) as an interactive flow graph, with nodes representing neurons or hidden states and edges representing the interactions between them. Our visualization simplifies huge amounts of data into easy-to-read plots that can reflect the models’ internal processing, uncovering the contribution of each component to the models’ final prediction. Our visualization also unveils new insights about the role of layer norms as semantic filters that influence the models’ output, and about neurons that are always activated during forward passes and act as regularization vectors.</abstract>
      <url hash="3e2971ae">2023.findings-emnlp.939</url>
      <bibkey>katz-belinkov-2023-visit</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.939</doi>
    </paper>
    <paper id="940">
      <title>Is Robustness Transferable across Languages in Multilingual Neural Machine Translation?</title>
      <author><first>Leiyu</first><last>Pan</last></author>
      <author><first/><last>Supryadi</last></author>
      <author><first>Deyi</first><last>Xiong</last></author>
      <pages>14114-14125</pages>
      <abstract>Robustness, the ability of models to maintain performance in the face of perturbations, is critical for developing reliable NLP systems. Recent studies have shown promising results in improving the robustness of models through adversarial training and data augmentation. However, in machine translation, most of these studies have focused on bilingual machine translation with a single translation direction. In this paper, we investigate the transferability of robustness across different languages in multilingual neural machine translation. We propose a robustness transfer analysis protocol and conduct a series of experiments. In particular, we use character-, word-, and multi-level noises to attack the specific translation direction of the multilingual neural machine translation model and evaluate the robustness of other translation directions. Our findings demonstrate that the robustness gained in one translation direction can indeed transfer to other translation directions. Additionally, we empirically find scenarios where robustness to character-level noise and word-level noise is more likely to transfer.</abstract>
      <url hash="1697c86a">2023.findings-emnlp.940</url>
      <bibkey>pan-etal-2023-robustness</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.940</doi>
    </paper>
    <paper id="941">
      <title><fixed-case>A</fixed-case>rabic Mini-<fixed-case>C</fixed-case>limate<fixed-case>GPT</fixed-case> : A Climate Change and Sustainability Tailored <fixed-case>A</fixed-case>rabic <fixed-case>LLM</fixed-case></title>
      <author><first>Sahal</first><last>Mullappilly</last></author>
      <author><first>Abdelrahman</first><last>Shaker</last></author>
      <author><first>Omkar</first><last>Thawakar</last></author>
      <author><first>Hisham</first><last>Cholakkal</last></author>
      <author><first>Rao</first><last>Anwer</last></author>
      <author><first>Salman</first><last>Khan</last></author>
      <author><first>Fahad</first><last>Khan</last></author>
      <pages>14126-14136</pages>
      <abstract>Climate change is one of the most significant challenges we face together as a society. Creating awareness and educating policy makers the wide-ranging impact of climate change is an essential step towards a sustainable future. Recently, Large Language Models (LLMs) like ChatGPT and Bard have shown impressive conversational abilities and excel in a wide variety of NLP tasks. While these models are close-source, recently alternative open-source LLMs such as Stanford Alpaca and Vicuna have shown promising results. However, these open-source models are not specifically tailored for climate related domain specific information and also struggle to generate meaningful responses in other languages such as, Arabic. To this end, we propose a light-weight Arabic Mini-ClimateGPT that is built on an open-source LLM and is specifically fine-tuned on a conversational-style instruction tuning curated Arabic dataset Clima500-Instruct with over 500k instructions about climate change and sustainability. Further, our model also utilizes a vector embedding based retrieval mechanism during inference. We validate our proposed model through quantitative and qualitative evaluations on climate-related queries. Our model surpasses the baseline LLM in 88.3% of cases during ChatGPT-based evaluation. Furthermore, our human expert evaluation reveals an 81.6% preference for our model’s responses over multiple popular open-source models. Our open-source demos, models and curated instruction sets are available here : https://github.com/mbzuai-oryx/ClimateGPT</abstract>
      <url hash="e50bf567">2023.findings-emnlp.941</url>
      <bibkey>mullappilly-etal-2023-arabic</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.941</doi>
    </paper>
    <paper id="942">
      <title>Interpreting Answers to Yes-No Questions in User-Generated Content</title>
      <author><first>Shivam</first><last>Mathur</last></author>
      <author><first>Keun</first><last>Park</last></author>
      <author><first>Dhivya</first><last>Chinnappa</last></author>
      <author><first>Saketh</first><last>Kotamraju</last></author>
      <author><first>Eduardo</first><last>Blanco</last></author>
      <pages>14137-14161</pages>
      <abstract>Interpreting answers to yes-no questions in social media is difficult. Yes and no keywords are uncommon, and the few answers that include them are rarely to be interpreted what the keywords suggest. In this paper, we present a new corpus of 4,442 yes-no question-answer pairs from Twitter. We discuss linguistic characteristics of answers whose interpretation is yes or no, as well as answers whose interpretation is unknown. We show that large language models are far from solving this problem, even after fine-tuning and blending other corpora for the same problem but outside social media.</abstract>
      <url hash="bb75a368">2023.findings-emnlp.942</url>
      <bibkey>mathur-etal-2023-interpreting</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.942</doi>
    </paper>
    <paper id="943">
      <title>Task-Aware Self-Supervised Framework for Dialogue Discourse Parsing</title>
      <author><first>Wei</first><last>Li</last></author>
      <author><first>Luyao</first><last>Zhu</last></author>
      <author><first>Wei</first><last>Shao</last></author>
      <author><first>Zonglin</first><last>Yang</last></author>
      <author><first>Erik</first><last>Cambria</last></author>
      <pages>14162-14173</pages>
      <abstract>Dialogue discourse parsing is a fundamental natural language processing task. It can benefit a series of conversation-related downstream tasks including dialogue summarization and emotion recognition in conversations. However, existing parsing approaches are constrained by predefined relation types, which can impede the adaptability of the parser for downstream tasks. To this end, we propose to introduce a task-aware paradigm to improve the versatility of the parser in this paper. Moreover, to alleviate error propagation and learning bias, we design a graph-based discourse parsing model termed DialogDP. Building upon the symmetrical property of matrix-embedded parsing graphs, we have developed an innovative self-supervised mechanism that leverages both bottom-up and top-down parsing strategies. This approach allows the parsing graphs to mutually regularize and enhance each other. Empirical studies on dialogue discourse parsing datasets and a downstream task demonstrate the effectiveness and flexibility of our framework.</abstract>
      <url hash="fa01de3a">2023.findings-emnlp.943</url>
      <bibkey>li-etal-2023-task</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.943</doi>
    </paper>
    <paper id="944">
      <title>Selective Demonstrations for Cross-domain Text-to-<fixed-case>SQL</fixed-case></title>
      <author><first>Shuaichen</first><last>Chang</last></author>
      <author><first>Eric</first><last>Fosler-Lussier</last></author>
      <pages>14174-14189</pages>
      <abstract>Large language models (LLMs) with in-context learning have demonstrated impressive generalization capabilities in the cross-domain text-to-SQL task, without the use of in-domain annotations. However, incorporating in-domain demonstration examples has been found to greatly enhance LLMs’ performance. In this paper, we delve into the key factors within in-domain examples that contribute to the improvement and explore whether we can harness these benefits without relying on in-domain annotations. Based on our findings, we propose a demonstration selection framework, ODIS, which utilizes both out-of-domain examples and synthetically generated in-domain examples to construct demonstrations. By retrieving demonstrations from hybrid sources, ODIS leverages the advantages of both, showcasing its effectiveness compared to baseline methods that rely on a single data source. Furthermore, ODIS outperforms state-of-the-art approaches on two cross-domain text-to-SQL datasets, with improvements of 1.1 and 11.8 points in execution accuracy, respectively.</abstract>
      <url hash="8de00874">2023.findings-emnlp.944</url>
      <bibkey>chang-fosler-lussier-2023-selective</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.944</doi>
    </paper>
    <paper id="945">
      <title><fixed-case>D</fixed-case>oc<fixed-case>S</fixed-case>plit: Simple Contrastive Pretraining for Large Document Embeddings</title>
      <author><first>Yujie</first><last>Wang</last></author>
      <author><first>Mike</first><last>Izbicki</last></author>
      <pages>14190-14196</pages>
      <abstract>Existing model pretraining methods only consider local information. For example, in the popular token masking strategy, the words closer to the masked token are more important for prediction than words far away. This results in pretrained models that generate high-quality sentence embeddings, but low-quality embeddings for large documents. We propose a new pretraining method called DocSplit which forces models to consider the entire global context of a large document. Our method uses a contrastive loss where the positive examples are randomly sampled sections of the input document, and negative examples are randomly sampled sections of unrelated documents. Like previous pretraining methods, DocSplit is fully unsupervised, easy to implement, and can be used to pretrain any model architecture. Our experiments show that DocSplit outperforms other pretraining methods for document classification, few shot learning, and information retrieval tasks.</abstract>
      <url hash="dfa8e435">2023.findings-emnlp.945</url>
      <bibkey>wang-izbicki-2023-docsplit</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.945</doi>
    </paper>
    <paper id="946">
      <title><fixed-case>TEL</fixed-case>e<fixed-case>R</fixed-case>: A General Taxonomy of <fixed-case>LLM</fixed-case> Prompts for Benchmarking Complex Tasks</title>
      <author><first>Shubhra Kanti</first><last>Karmaker Santu</last></author>
      <author><first>Dongji</first><last>Feng</last></author>
      <pages>14197-14203</pages>
      <abstract>While LLMs have shown great success in understanding and generating text in traditional conversational settings, their potential for performing ill-defined complex tasks is largely under-studied and yet to be benchmarked. However, conducting such benchmarking studies is challenging because of the large variations in LLMs’ performance when different prompt types/styles are used and different degrees of detail are provided in the prompts. To address this issue, this paper proposes a general taxonomy that can be used to design prompts with specific properties in order to perform a wide range of complex tasks. This taxonomy will allow future benchmarking studies to report the specific categories of prompts used as part of the study, enabling meaningful comparisons across different studies. Also, by establishing a common standard through this taxonomy, researchers will be able to draw more accurate conclusions about LLMs’ performance on a specific complex task.</abstract>
      <url hash="4c59d4e4">2023.findings-emnlp.946</url>
      <bibkey>karmaker-santu-feng-2023-teler</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.946</doi>
    </paper>
    <paper id="947">
      <title><fixed-case>I</fixed-case>nten<fixed-case>DD</fixed-case>: A Unified Contrastive Learning Approach for Intent Detection and Discovery</title>
      <author><first>Bhavuk</first><last>Singhal</last></author>
      <author><first>Ashim</first><last>Gupta</last></author>
      <author><first>V P</first><last>Shivasankaran</last></author>
      <author><first>Amrith</first><last>Krishna</last></author>
      <pages>14204-14216</pages>
      <abstract>Identifying intents from dialogue utterances forms an integral component of task-oriented dialogue systems. Intent-related tasks are typically formulated either as a classification task, where the utterances are classified into predefined categories or as a clustering task when new and previously unknown intent categories need to be discovered from these utterances. Further, the intent classification may be modeled in a multiclass (MC) or multilabel (ML) setup. While typically these tasks are modeled as separate tasks, we propose IntenDD a unified approach leveraging a shared utterance encoding backbone. IntenDD uses an entirely unsupervised contrastive learning strategy for representation learning, where pseudo-labels for the unlabeled utterances are generated based on their lexical features. Additionally, we introduce a two-step post-processing setup for the classification tasks using modified adsorption. Here, first, the residuals in the training data are propagated followed by smoothing the labels both modeled in a transductive setting. Through extensive evaluations on various benchmark datasets, we find that our approach consistently outperforms competitive baselines across all three tasks. On average, IntenDD reports percentage improvements of 2.32 %, 1.26 %, and 1.52 % in their respective metrics for few-shot MC, few-shot ML, and the intent discovery tasks respectively.</abstract>
      <url hash="80520c24">2023.findings-emnlp.947</url>
      <bibkey>singhal-etal-2023-intendd</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.947</doi>
    </paper>
    <paper id="948">
      <title><fixed-case>IN</fixed-case>ar<fixed-case>IG</fixed-case>: Iterative Non-autoregressive Instruct Generation Model For Word-Level Auto Completion</title>
      <author><first>Hengchao</first><last>Shang</last></author>
      <author><first>Zongyao</first><last>Li</last></author>
      <author><first>Daimeng</first><last>Wei</last></author>
      <author><first>Jiaxin</first><last>Guo</last></author>
      <author><first>Minghan</first><last>Wang</last></author>
      <author><first>Xiaoyu</first><last>Chen</last></author>
      <author><first>Lizhi</first><last>Lei</last></author>
      <author><first>Hao</first><last>Yang</last></author>
      <pages>14217-14228</pages>
      <abstract>Computer-aided translation (CAT) aims to enhance human translation efficiency and is still important in scenarios where machine translation cannot meet quality requirements. One fundamental task within this field is Word-Level Auto Completion (WLAC). WLAC predicts a target word given a source sentence, translation context, and a human typed character sequence. Previous works either employ word classification models to exploit contextual information from both sides of the target word or directly disregarded the dependencies from the right-side context. Furthermore, the key information, i.e. human typed sequences, is only used as prefix constraints in the decoding module. In this paper, we propose the INarIG (Iterative Non-autoregressive Instruct Generation) model, which constructs the human typed sequence into Instruction Unit and employs iterative decoding with subwords to fully utilize input information given in the task. Our model is more competent in dealing with low-frequency words (core scenario of this task), and achieves state-of-the-art results on the WMT22 and benchmark datasets, with a maximum increase of over 10% prediction accuracy.</abstract>
      <url hash="0d28143c">2023.findings-emnlp.948</url>
      <bibkey>shang-etal-2023-inarig</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.948</doi>
    </paper>
    <paper id="949">
      <title>Is the Answer in the Text? Challenging <fixed-case>C</fixed-case>hat<fixed-case>GPT</fixed-case> with Evidence Retrieval from Instructive Text</title>
      <author><first>Sophie</first><last>Henning</last></author>
      <author><first>Talita</first><last>Anthonio</last></author>
      <author><first>Wei</first><last>Zhou</last></author>
      <author><first>Heike</first><last>Adel</last></author>
      <author><first>Mohsen</first><last>Mesgar</last></author>
      <author><first>Annemarie</first><last>Friedrich</last></author>
      <pages>14229-14241</pages>
      <abstract>Generative language models have recently shown remarkable success in generating answers to questions in a given textual context. However, these answers may suffer from hallucination, wrongly cite evidence, and spread misleading information. In this work, we address this problem by employing ChatGPT, a state-of-the-art generative model, as a machine-reading system. We ask it to retrieve answers to lexically varied and open-ended questions from trustworthy instructive texts. We introduce WHERE (WikiHow Evidence REtrieval), a new high-quality evaluation benchmark of a set of WikiHow articles exhaustively annotated with evidence sentences to questions that comes with a special challenge: All questions are about the article’s topic, but not all can be answered using the provided context. We interestingly find that when using a regular question-answering prompt, ChatGPT neglects to detect the unanswerable cases. When provided with a few examples, it learns to better judge whether a text provides answer evidence or not. Alongside this important finding, our dataset defines a new benchmark for evidence retrieval in question answering, which we argue is one of the necessary next steps for making large language models more trustworthy.</abstract>
      <url hash="3b1f68a5">2023.findings-emnlp.949</url>
      <bibkey>henning-etal-2023-answer</bibkey>
      <revision id="1" href="2023.findings-emnlp.949v1" hash="547fa057"/>
      <revision id="2" href="2023.findings-emnlp.949v2" hash="3b1f68a5" date="2023-12-15">This revision provides a corrected version of Figure 1.</revision>
    </paper>
    <paper id="950">
      <title><fixed-case>P</fixed-case>a<fixed-case>R</fixed-case>a<fixed-case>D</fixed-case>e: Passage Ranking using Demonstrations with <fixed-case>LLM</fixed-case>s</title>
      <author><first>Andrew</first><last>Drozdov</last></author>
      <author><first>Honglei</first><last>Zhuang</last></author>
      <author><first>Zhuyun</first><last>Dai</last></author>
      <author><first>Zhen</first><last>Qin</last></author>
      <author><first>Razieh</first><last>Rahimi</last></author>
      <author><first>Xuanhui</first><last>Wang</last></author>
      <author><first>Dana</first><last>Alon</last></author>
      <author><first>Mohit</first><last>Iyyer</last></author>
      <author><first>Andrew</first><last>McCallum</last></author>
      <author><first>Donald</first><last>Metzler</last></author>
      <author><first>Kai</first><last>Hui</last></author>
      <pages>14242-14252</pages>
      <abstract>Recent studies show that large language models (LLMs) can be instructed to effectively perform zero-shot passage re-ranking, in which the results of a first stage retrieval method, such as BM25, are rated and reordered to improve relevance. In this work, we improve LLM-based re-ranking by algorithmically selecting few-shot demonstrations to include in the prompt. Our analysis investigates the conditions where demonstrations are most helpful, and shows that adding even one demonstration is significantly beneficial. We propose a novel demonstration selection strategy based on difficulty rather than the commonly used semantic similarity. Furthermore, we find that demonstrations helpful for ranking are also effective at question generation. We hope our work will spur more principled research into question generation and passage ranking.</abstract>
      <url hash="116cf250">2023.findings-emnlp.950</url>
      <bibkey>drozdov-etal-2023-parade</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.950</doi>
    </paper>
    <paper id="951">
      <title>Learning Dynamic Representations for Discourse Dependency Parsing</title>
      <author><first>Tianyi</first><last>Liu</last></author>
      <author><first>Yansong</first><last>Feng</last></author>
      <author><first>Dongyan</first><last>Zhao</last></author>
      <pages>14253-14263</pages>
      <abstract>Transition systems have been widely used for the discourse dependency parsing task. Existing works often characterize transition states by examining a certain number of elementary discourse units (EDUs), while neglecting the arcs obtained from the transition history. In this paper, we propose to employ GAT-based encoder to learn dynamic representations for sub-trees constructed in previous transition steps. By incorporating these representations, our model is able to retain accessibility to all parsed EDUs through the obtained arcs, thus better utilizing the structural information of the document, particularly when handling lengthy text spans with complex structures. For the discourse relation recognition task, we employ edge-featured GATs to derive better representations for EDU pairs. Experimental results show that our model can achieve state-of-the-art performance on widely adopted datasets including RST-DT, SciDTB and CDTB. Our code is available at <tex-math>{https://github.com/lty-lty/Discourse-Dependency-Parsing}</tex-math>.</abstract>
      <url hash="202d0111">2023.findings-emnlp.951</url>
      <bibkey>liu-etal-2023-learning-dynamic</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.951</doi>
    </paper>
    <paper id="952">
      <title>K-<fixed-case>HATERS</fixed-case>: A Hate Speech Detection Corpus in <fixed-case>K</fixed-case>orean with Target-Specific Ratings</title>
      <author><first>Chaewon</first><last>Park</last></author>
      <author><first>Soohwan</first><last>Kim</last></author>
      <author><first>Kyubyong</first><last>Park</last></author>
      <author><first>Kunwoo</first><last>Park</last></author>
      <pages>14264-14278</pages>
      <abstract>Numerous datasets have been proposed to combat the spread of online hate. Despite these efforts, a majority of these resources are English-centric, primarily focusing on overt forms of hate. This research gap calls for developing high-quality corpora in diverse languages that also encapsulate more subtle hate expressions. This study introduces K-HATERS, a new corpus for hate speech detection in Korean, comprising approximately 192K news comments with target-specific offensiveness ratings. This resource is the largest offensive language corpus in Korean and is the first to offer target-specific ratings on a three-point Likert scale, enabling the detection of hate expressions in Korean across varying degrees of offensiveness. We conduct experiments showing the effectiveness of the proposed corpus, including a comparison with existing datasets. Additionally, to address potential noise and bias in human annotations, we explore a novel idea of adopting the Cognitive Reflection Test, which is widely used in social science for assessing an individual’s cognitive ability, as a proxy of labeling quality. Findings indicate that annotations from individuals with the lowest test scores tend to yield detection models that make biased predictions toward specific target groups and are less accurate. This study contributes to the NLP research on hate speech detection and resource construction. The code and dataset can be accessed at https://github.com/ssu-humane/K-HATERS.</abstract>
      <url hash="48939af9">2023.findings-emnlp.952</url>
      <bibkey>park-etal-2023-k</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.952</doi>
    </paper>
    <paper id="953">
      <title>Mitigating Data Imbalance and Representation Degeneration in Multilingual Machine Translation</title>
      <author><first>Wen</first><last>Lai</last></author>
      <author><first>Alexandra</first><last>Chronopoulou</last></author>
      <author><first>Alexander</first><last>Fraser</last></author>
      <pages>14279-14294</pages>
      <abstract>Despite advances in multilingual neural machine translation (MNMT), we argue that there are still two major challenges in this area: data imbalance and representation degeneration. The data imbalance problem refers to the imbalance in the amount of parallel corpora for all language pairs, especially for long-tail languages (i.e., very low-resource languages). The representation degeneration problem refers to the problem of encoded tokens tending to appear only in a small subspace of the full space available to the MNMT model. To solve these two issues, we propose Bi-ACL, a framework which only requires target-side monolingual data and a bilingual dictionary to improve the performance of the MNMT model. We define two modules, named bidirectional autoencoder and bidirectional contrastive learning, which we combine with an online constrained beam search and a curriculum learning sampling strategy. Extensive experiments show that our proposed method is more effective than strong baselines both in long-tail languages and in high-resource languages. We also demonstrate that our approach is capable of transferring knowledge between domains and languages in zero-shot scenarios.</abstract>
      <url hash="ad1c5678">2023.findings-emnlp.953</url>
      <bibkey>lai-etal-2023-mitigating</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.953</doi>
    </paper>
    <paper id="954">
      <title><fixed-case>B</fixed-case>ot<fixed-case>P</fixed-case>ercent: Estimating Bot Populations in <fixed-case>T</fixed-case>witter Communities</title>
      <author><first>Zhaoxuan</first><last>Tan</last></author>
      <author><first>Shangbin</first><last>Feng</last></author>
      <author><first>Melanie</first><last>Sclar</last></author>
      <author><first>Herun</first><last>Wan</last></author>
      <author><first>Minnan</first><last>Luo</last></author>
      <author><first>Yejin</first><last>Choi</last></author>
      <author><first>Yulia</first><last>Tsvetkov</last></author>
      <pages>14295-14312</pages>
      <abstract>Twitter bot detection is vital in combating misinformation and safeguarding the integrity of social media discourse. While malicious bots are becoming more and more sophisticated and personalized, standard bot detection approaches are still agnostic to social environments (henceforth, communities) the bots operate at. In this work, we introduce community-specific bot detection, estimating the percentage of bots given the context of a community. Our method—BotPercent—is an amalgamation of Twitter bot detection datasets and feature-, text-, and graph-based models, adjusted to a particular community on Twitter. We introduce an approach that performs confidence calibration across bot detection models, which addresses generalization issues in existing community-agnostic models targeting individual bots and leads to more accurate community-level bot estimations. Experiments demonstrate that BotPercent achieves state-of-the-art performance in community-level Twitter bot detection across both balanced and imbalanced class distribution settings, presenting a less biased estimator of Twitter bot populations within the communities we analyze. We then analyze bot rates in several Twitter groups, including users who engage with partisan news media, political communities in different countries, and more. Our results reveal that the presence of Twitter bots is not homogeneous, but exhibiting a spatial-temporal distribution with considerable heterogeneity that should be taken into account for content moderation and social media policy making. The implementation of BotPercent is available at https://github.com/TamSiuhin/BotPercent.</abstract>
      <url hash="5208abfe">2023.findings-emnlp.954</url>
      <bibkey>tan-etal-2023-botpercent</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.954</doi>
    </paper>
    <paper id="955">
      <title>The Locality and Symmetry of Positional Encodings</title>
      <author><first>Lihu</first><last>Chen</last></author>
      <author><first>Gael</first><last>Varoquaux</last></author>
      <author><first>Fabian</first><last>Suchanek</last></author>
      <pages>14313-14331</pages>
      <abstract>Positional Encodings (PEs) are used to inject word-order information into transformer-based language models. While they can significantly enhance the quality of sentence representations, their specific contribution to language models is not fully understood, especially given recent findings that various positional encodings are insensitive to word order. In this work, we conduct a systematic study of positional encodings in <b>Bidirectional Masked Language Models</b> (BERT-style) , which complements existing work in three aspects: (1) We uncover the core function of PEs by identifying two common properties, Locality and Symmetry; (2) We show that the two properties are closely correlated with the performances of downstream tasks; (3) We quantify the weakness of current PEs by introducing two new probing tasks, on which current PEs perform poorly. We believe that these results are the basis for developing better PEs for transformer-based language models.</abstract>
      <url hash="15098d62">2023.findings-emnlp.955</url>
      <bibkey>chen-etal-2023-locality</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.955</doi>
    </paper>
    <paper id="956">
      <title>Towards a Deep Understanding of Multilingual End-to-End Speech Translation</title>
      <author><first>Haoran</first><last>Sun</last></author>
      <author><first>Xiaohu</first><last>Zhao</last></author>
      <author><first>Yikun</first><last>Lei</last></author>
      <author><first>Shaolin</first><last>Zhu</last></author>
      <author><first>Deyi</first><last>Xiong</last></author>
      <pages>14332-14348</pages>
      <abstract>In this paper, we employ Singular Value Canonical Correlation Analysis (SVCCA) to analyze representations learnt in a multilingual end-to-end speech translation model trained over 22 languages. SVCCA enables us to estimate representational similarity across languages and layers, enhancing our understanding of the functionality of multilingual speech translation and its potential connection to multilingual neural machine translation. The multilingual speech translation model is trained on the CoVoST 2 dataset in all possible directions, and we utilize LASER to extract parallel bitext data for SVCCA analysis. We derive three major findings from our analysis: (I) Linguistic similarity loses its efficacy in multilingual speech translation when the training data for a specific language is limited. (II) Enhanced encoder representations and well-aligned audio-text data significantly improve translation quality, surpassing the bilingual counterparts when the training data is not compromised. (III) The encoder representations of multilingual speech translation demonstrate superior performance in predicting phonetic features in linguistic typology prediction. With these findings, we propose that releasing the constraint of limited data for low-resource languages and subsequently combining them with linguistically related high-resource languages could offer a more effective approach for multilingual end-to-end speech translation.</abstract>
      <url hash="110a1872">2023.findings-emnlp.956</url>
      <bibkey>sun-etal-2023-towards-deep</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.956</doi>
    </paper>
    <paper id="957">
      <title>An Empirical Investigation of Implicit and Explicit Knowledge-Enhanced Methods for Ad Hoc Dataset Retrieval</title>
      <author><first>Weiqing</first><last>Luo</last></author>
      <author><first>Qiaosheng</first><last>Chen</last></author>
      <author><first>Zhiyang</first><last>Zhang</last></author>
      <author><first>Zixian</first><last>Huang</last></author>
      <author><first>Gong</first><last>Cheng</last></author>
      <pages>14349-14360</pages>
      <abstract>Ad hoc dataset retrieval has become an important way of finding data on the Web, where the underlying problem is how to measure the relevance of a dataset to a query. State-of-the-art solutions for this task are still lexical methods, which cannot capture semantic similarity. Semantics-aware knowledge-enhanced retrieval methods, which achieved promising results on other tasks, have yet to be systematically studied on this specialized task. To fill the gap, in this paper, we present an empirical investigation of the task where we implement and evaluate, on two test collections, a set of implicit and explicit knowledge-enhancement retrieval methods in various settings. Our results reveal the unique features of the task and suggest an interpolation of different kinds of methods as the current best practice.</abstract>
      <url hash="a7b92e76">2023.findings-emnlp.957</url>
      <bibkey>luo-etal-2023-empirical</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.957</doi>
    </paper>
    <paper id="958">
      <title>A Multi-Modal Multilingual Benchmark for Document Image Classification</title>
      <author><first>Yoshinari</first><last>Fujinuma</last></author>
      <author><first>Siddharth</first><last>Varia</last></author>
      <author><first>Nishant</first><last>Sankaran</last></author>
      <author><first>Srikar</first><last>Appalaraju</last></author>
      <author><first>Bonan</first><last>Min</last></author>
      <author><first>Yogarshi</first><last>Vyas</last></author>
      <pages>14361-14376</pages>
      <abstract>Document image classification is different from plain-text document classification and consists of classifying a document by understanding the content and structure of documents such as forms, emails, and other such documents. We show that the only existing dataset for this task (Lewis et al., 2006) has several limitations and we introduce two newly curated multilingual datasets WIKI-DOC and MULTIEURLEX-DOC that overcome these limitations. We further undertake a comprehensive study of popular visually-rich document understanding or Document AI models in previously untested setting in document image classification such as 1) multi-label classification, and 2) zero-shot cross-lingual transfer setup. Experimental results show limitations of multilingual Document AI models on cross-lingual transfer across typologically distant languages. Our datasets and findings open the door for future research into improving Document AI models.</abstract>
      <url hash="c927c007">2023.findings-emnlp.958</url>
      <bibkey>fujinuma-etal-2023-multi</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.958</doi>
    </paper>
    <paper id="959">
      <title>Unnatural language processing: How do language models handle machine-generated prompts?</title>
      <author><first>Corentin</first><last>Kervadec</last></author>
      <author><first>Francesca</first><last>Franzon</last></author>
      <author><first>Marco</first><last>Baroni</last></author>
      <pages>14377-14392</pages>
      <abstract>Language model prompt optimization research has shown that semantically and grammatically well-formed manually crafted prompts are routinely outperformed by automatically generated token sequences with no apparent meaning or syntactic structure, including sequences of vectors from a model’s embedding space. We use machine-generated prompts to probe how models respond to input that is not composed of natural language expressions. We study the behavior of models of different sizes in multiple semantic tasks in response to both continuous and discrete machine-generated prompts, and compare it to the behavior in response to human-generated natural-language prompts. Even when producing a similar output, machine-generated and human prompts trigger different response patterns through the network processing pathways, including different perplexities, different attention and output entropy distributions, and different unit activation profiles. We provide preliminary insight into the nature of the units activated by different prompt types, suggesting that only natural language prompts recruit a genuinely linguistic circuit.</abstract>
      <url hash="76520991">2023.findings-emnlp.959</url>
      <bibkey>kervadec-etal-2023-unnatural</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.959</doi>
    </paper>
    <paper id="960">
      <title>Investigating the Effectiveness of Multiple Expert Models Collaboration</title>
      <author><first>Ikumi</first><last>Ito</last></author>
      <author><first>Takumi</first><last>Ito</last></author>
      <author><first>Jun</first><last>Suzuki</last></author>
      <author><first>Kentaro</first><last>Inui</last></author>
      <pages>14393-14404</pages>
      <abstract>This paper aims to investigate the effectiveness of several machine translation (MT) models and aggregation methods in a multi-domain setting under fair conditions and explore a direction for tackling multi-domain MT. We mainly compare the performance of the single model approach by jointly training all domains and the multi-expert models approach with a particular aggregation strategy. We conduct experiments on multiple domain datasets and demonstrate that a combination of smaller domain expert models can outperform a larger model trained for all domain data.</abstract>
      <url hash="b8afb9f9">2023.findings-emnlp.960</url>
      <bibkey>ito-etal-2023-investigating</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.960</doi>
    </paper>
    <paper id="961">
      <title>Gradually Excavating External Knowledge for Implicit Complex Question Answering</title>
      <author><first>Chang</first><last>Liu</last></author>
      <author><first>Xiaoguang</first><last>Li</last></author>
      <author><first>Lifeng</first><last>Shang</last></author>
      <author><first>Xin</first><last>Jiang</last></author>
      <author><first>Qun</first><last>Liu</last></author>
      <author><first>Edmund</first><last>Lam</last></author>
      <author><first>Ngai</first><last>Wong</last></author>
      <pages>14405-14417</pages>
      <abstract>Recently, large language models (LLMs) have gained much attention for the emergence of human-comparable capabilities and huge potential. However, for open-domain implicit question-answering problems, LLMs may not be the ultimate solution due to the reasons of: 1) uncovered or out-of-date domain knowledge, 2) one-shot generation and hence restricted comprehensiveness. To this end, this work proposes a gradual knowledge excavation framework for open-domain complex question answering, where LLMs iteratively and actively acquire extrinsic information, then reason based on acquired historical knowledge. Specifically, during each step of the solving process, the model selects an action to execute, such as querying external knowledge or performing a single logical reasoning step, to gradually progress toward a final answer. Our method can effectively leverage plug-and-play external knowledge and dynamically adjust the strategy for solving complex questions. Evaluated on the StrategyQA dataset, our method achieves 78.17% accuracy with less than 6% parameters of its competitors, setting new SOTA in the ~10B LLM class.</abstract>
      <url hash="de9fd44c">2023.findings-emnlp.961</url>
      <bibkey>liu-etal-2023-gradually</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.961</doi>
    </paper>
    <paper id="962">
      <title>Evaluating Subjective Cognitive Appraisals of Emotions from Large Language Models</title>
      <author><first>Hongli</first><last>Zhan</last></author>
      <author><first>Desmond</first><last>Ong</last></author>
      <author><first>Junyi Jessy</first><last>Li</last></author>
      <pages>14418-14446</pages>
      <abstract>The emotions we experience involve complex processes; besides physiological aspects, research in psychology has studied cognitive appraisals where people assess their situations subjectively, according to their own values (Scherer, 2005). Thus, the same situation can often result in different emotional experiences. While the detection of emotion is a well-established task, there is very limited work so far on the automatic prediction of cognitive appraisals. This work fills the gap by presenting CovidET-Appraisals, the most comprehensive dataset to-date that assesses 24 appraisal dimensions, each with a natural language rationale, across 241 Reddit posts. CovidET-Appraisals presents an ideal testbed to evaluate the ability of large language models — excelling at a wide range of NLP tasks — to automatically assess and explain cognitive appraisals. We found that while the best models are performant, open-sourced LLMs fall short at this task, presenting a new challenge in the future development of emotionally intelligent models. We release our dataset at https://github.com/honglizhan/CovidET-Appraisals-Public.</abstract>
      <url hash="d92848d6">2023.findings-emnlp.962</url>
      <bibkey>zhan-etal-2023-evaluating</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.962</doi>
    </paper>
    <paper id="963">
      <title>Exploring Linguistic Properties of Monolingual <fixed-case>BERT</fixed-case>s with Typological Classification among Languages</title>
      <author><first>Elena</first><last>Ruzzetti</last></author>
      <author><first>Federico</first><last>Ranaldi</last></author>
      <author><first>Felicia</first><last>Logozzo</last></author>
      <author><first>Michele</first><last>Mastromattei</last></author>
      <author><first>Leonardo</first><last>Ranaldi</last></author>
      <author><first>Fabio</first><last>Zanzotto</last></author>
      <pages>14447-14461</pages>
      <abstract>The impressive achievements of transformers force NLP researchers to delve into how these models represent the underlying structure of natural language. In this paper, we propose a novel standpoint to investigate the above issue: using typological similarities among languages to observe how their respective monolingual models encode structural information. We aim to layer-wise compare transformers for typologically similar languages to observe whether these similarities emerge for particular layers. For this investigation, we propose to use Centered Kernel Alignment to measure similarity among weight matrices. We found that syntactic typological similarity is consistent with the similarity between the weights in the middle layers, which are the pretrained BERT layers to which syntax encoding is generally attributed. Moreover, we observe that a domain adaptation on semantically equivalent texts enhances this similarity among weight matrices.</abstract>
      <url hash="114b617a">2023.findings-emnlp.963</url>
      <bibkey>ruzzetti-etal-2023-exploring</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.963</doi>
    </paper>
    <paper id="964">
      <title>Discourse Sense Flows: Modelling the Rhetorical Style of Documents across Various Domains</title>
      <author><first>Rene</first><last>Knaebel</last></author>
      <author><first>Manfred</first><last>Stede</last></author>
      <pages>14462-14482</pages>
      <abstract>Recent research on shallow discourse parsing has given renewed attention to the role of discourse relation signals, in particular explicit connectives and so-called alternative lexicalizations. In our work, we first develop new models for extracting signals and classifying their senses, both for explicit connectives and alternative lexicalizations, based on the Penn Discourse Treebank v3 corpus. Thereafter, we apply these models to various raw corpora, and we introduce ‘discourse sense flows’, a new way of modeling the rhetorical style of a document by the linear order of coherence relations, as captured by the PDTB senses. The corpora span several genres and domains, and we undertake comparative analyses of the sense flows, as well as experiments on automatic genre/domain discrimination using discourse sense flow patterns as features. We find that n-gram patterns are indeed stronger predictors than simple sense (unigram) distributions.</abstract>
      <url hash="ce9fb45a">2023.findings-emnlp.964</url>
      <bibkey>knaebel-stede-2023-discourse</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.964</doi>
    </paper>
    <paper id="965">
      <title><fixed-case>H</fixed-case>ierarchical<fixed-case>C</fixed-case>ontrast: A Coarse-to-Fine Contrastive Learning Framework for Cross-Domain Zero-Shot Slot Filling</title>
      <author><first>Junwen</first><last>Zhang</last></author>
      <author><first>Yin</first><last>Zhang</last></author>
      <pages>14483-14503</pages>
      <abstract>In task-oriented dialogue scenarios, cross-domain zero-shot slot filling plays a vital role in leveraging source domain knowledge to learn a model with high generalization ability in unknown target domain where annotated data is unavailable. However, the existing state-of-the-art zero-shot slot filling methods have limited generalization ability in target domain, they only show effective knowledge transfer on seen slots and perform poorly on unseen slots. To alleviate this issue, we present a novel Hierarchical Contrastive Learning Framework (HiCL) for zero-shot slot filling. Specifically, we propose a coarse- to fine-grained contrastive learning based on Gaussian-distributed embedding to learn the generalized deep semantic relations between utterance-tokens, by optimizing inter- and intra-token distribution distance. This encourages HiCL to generalize to the slot types unseen at training phase. Furthermore, we present a new iterative label set semantics inference method to unbiasedly and separately evaluate the performance of unseen slot types which entangled with their counterparts (i.e., seen slot types) in the previous zero-shot slot filling evaluation methods. The extensive empirical experiments on four datasets demonstrate that the proposed method achieves comparable or even better performance than the current state-of-the-art zero-shot slot filling approaches.</abstract>
      <url hash="731c6aa3">2023.findings-emnlp.965</url>
      <bibkey>zhang-zhang-2023-hierarchicalcontrast</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.965</doi>
    </paper>
    <paper id="966">
      <title>A Confederacy of Models: a Comprehensive Evaluation of <fixed-case>LLM</fixed-case>s on Creative Writing</title>
      <author><first>Carlos</first><last>Gómez-Rodríguez</last></author>
      <author><first>Paul</first><last>Williams</last></author>
      <pages>14504-14528</pages>
      <abstract>We evaluate a range of recent LLMs on English creative writing, a challenging and complex task that requires imagination, coherence, and style. We use a difficult, open-ended scenario chosen to avoid training data reuse: an epic narration of a single combat between Ignatius J. Reilly, the protagonist of the Pulitzer Prize-winning novel A Confederacy of Dunces (1980), and a pterodactyl, a prehistoric flying reptile. We ask several LLMs and humans to write such a story and conduct a human evalution involving various criteria such as fluency, coherence, originality, humor, and style. Our results show that some state-of-the-art commercial LLMs match or slightly outperform our writers in most dimensions; whereas open-source LLMs lag behind. Humans retain an edge in creativity, while humor shows a binary divide between LLMs that can handle it comparably to humans and those that fail at it. We discuss the implications and limitations of our study and suggest directions for future research.</abstract>
      <url hash="42496d1d">2023.findings-emnlp.966</url>
      <bibkey>gomez-rodriguez-williams-2023-confederacy</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.966</doi>
    </paper>
    <paper id="967">
      <title>1-<fixed-case>PAGER</fixed-case>: One Pass Answer Generation and Evidence Retrieval</title>
      <author><first>Palak</first><last>Jain</last></author>
      <author><first>Livio</first><last>Soares</last></author>
      <author><first>Tom</first><last>Kwiatkowski</last></author>
      <pages>14529-14543</pages>
      <abstract>We present 1-Pager the first system that answers a question and retrieves evidence using a single Transformer-based model and decoding process. 1-Pager incrementally partitions the retrieval corpus using constrained decoding to select a document and answer string, and we show that this is competitive with comparable retrieve-and-read alternatives according to both retrieval and answer accuracy metrics. 1-Pager also outperforms the equivalent ‘closed-book’ question answering model, by grounding predictions in an evidence corpus. While 1-Pager is not yet on-par with more expensive systems that read many more documents before generating an answer, we argue that it provides an important step toward attributed generation by folding retrieval into the sequence-to-sequence paradigm that is currently dominant in NLP. We also show that the search paths used to partition the corpus are easy to read and understand, paving a way forward for interpretable neural retrieval.</abstract>
      <url hash="d17c63ad">2023.findings-emnlp.967</url>
      <bibkey>jain-etal-2023-1</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.967</doi>
    </paper>
    <paper id="968">
      <title>Context-faithful Prompting for Large Language Models</title>
      <author><first>Wenxuan</first><last>Zhou</last></author>
      <author><first>Sheng</first><last>Zhang</last></author>
      <author><first>Hoifung</first><last>Poon</last></author>
      <author><first>Muhao</first><last>Chen</last></author>
      <pages>14544-14556</pages>
      <abstract>Large language models (LLMs) encode parametric knowledge about world facts and have shown remarkable performance in knowledge-driven NLP tasks. However, their reliance on parametric knowledge may cause them to overlook contextual cues, leading to incorrect predictions in context-sensitive NLP tasks (e.g., knowledge acquisition tasks). In this paper, we seek to assess and enhance LLMs’ contextual faithfulness in two aspects: knowledge conflict and prediction with abstention. We demonstrate that LLMs’ faithfulness can be significantly improved using carefully designed prompting strategies. In particular, we identify opinion-based prompts and counterfactual demonstrations as the most effective methods. Opinion-based prompts reframe the context as a narrator’s statement and inquire about the narrator’s opinions, while counterfactual demonstrations use instances containing false facts to improve faithfulness in knowledge conflict situations. Neither technique requires additional training. We conduct experiments on three datasets of two standard NLP tasks, machine reading comprehension and relation extraction, and the results demonstrate significant improvement in faithfulness to contexts. Code and data are released at https://github.com/wzhouad/context-faithful-llm.</abstract>
      <url hash="522b01d4">2023.findings-emnlp.968</url>
      <bibkey>zhou-etal-2023-context</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.968</doi>
    </paper>
    <paper id="969">
      <title><fixed-case>I</fixed-case>nfo<fixed-case>CL</fixed-case>: Alleviating Catastrophic Forgetting in Continual Text Classification from An Information Theoretic Perspective</title>
      <author><first>Yifan</first><last>Song</last></author>
      <author><first>Peiyi</first><last>Wang</last></author>
      <author><first>Weimin</first><last>Xiong</last></author>
      <author><first>Dawei</first><last>Zhu</last></author>
      <author><first>Tianyu</first><last>Liu</last></author>
      <author><first>Zhifang</first><last>Sui</last></author>
      <author><first>Sujian</first><last>Li</last></author>
      <pages>14557-14570</pages>
      <abstract>Continual learning (CL) aims to constantly learn new knowledge over time while avoiding catastrophic forgetting on old tasks. We focus on continual text classification under the class-incremental setting. Recent CL studies have identified the severe performance decrease on analogous classes as a key factor for catastrophic forgetting. In this paper, through an in-depth exploration of the representation learning process in CL, we discover that the compression effect of the information bottleneck leads to confusion on analogous classes. To enable the model learn more sufficient representations, we propose a novel replay-based continual text classification method, InfoCL. Our approach utilizes fast-slow and current-past contrastive learning to perform mutual information maximization and better recover the previously learned representations. In addition, InfoCL incorporates an adversarial memory augmentation strategy to alleviate the overfitting problem of replay. Experimental results demonstrate that InfoCL effectively mitigates forgetting and achieves state-of-the-art performance on three text classification tasks.</abstract>
      <url hash="82738631">2023.findings-emnlp.969</url>
      <bibkey>song-etal-2023-infocl</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.969</doi>
    </paper>
    <paper id="970">
      <title>Sparse Frame Grouping Network with Action Centered for Untrimmed Video Paragraph Captioning</title>
      <author><first>Guorui</first><last>Yu</last></author>
      <author><first>Yimin</first><last>Hu</last></author>
      <author><first>Yuejie</first><last>Zhang</last></author>
      <author><first>Rui</first><last>Feng</last></author>
      <author><first>Tao</first><last>Zhang</last></author>
      <author><first>Shang</first><last>Gao</last></author>
      <pages>14571-14580</pages>
      <abstract>Generating paragraph captions for untrimmed videos without event annotations is challenging, especially when aiming to enhance precision and minimize repetition at the same time. To address this challenge, we propose a module called Sparse Frame Grouping (SFG). It dynamically groups event information with the help of action information for the entire video and excludes redundant frames within pre-defined clips. To enhance the performance, an Intra Contrastive Learning technique is designed to align the SFG module with the core event content in the paragraph, and an Inter Contrastive Learning technique is employed to learn action-guided context with reduced static noise simultaneously. Extensive experiments are conducted on two benchmark datasets (ActivityNet Captions and YouCook2). Results demonstrate that SFG outperforms the state-of-the-art methods on all metrics.</abstract>
      <url hash="14cf83b8">2023.findings-emnlp.970</url>
      <bibkey>yu-etal-2023-sparse-frame</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.970</doi>
    </paper>
    <paper id="971">
      <title>Unsupervised Binary Code Translation with Application to Code Clone Detection and Vulnerability Discovery</title>
      <author><first>Iftakhar</first><last>Ahmad</last></author>
      <author><first>Lannan</first><last>Luo</last></author>
      <pages>14581-14592</pages>
      <abstract>Binary code analysis has immense importance in the research domain of software security. Today, software is very often compiled for various Instruction Set Architectures (ISAs). As a result, cross-architecture binary code analysis has become an emerging problem. Recently, deep learning-based binary analysis has shown promising success. It is widely known that training a deep learning model requires a massive amount of data. However, for some low-resource ISAs, an adequate amount of data is hard to find, preventing deep learning from being widely adopted for binary analysis. To overcome the data scarcity problem and facilitate cross-architecture binary code analysis, we propose to apply the ideas and techniques in Neural Machine Translation (NMT) to binary code analysis. Our insight is that a binary, after disassembly, is represented in some assembly language. Given a binary in a low-resource ISA, we translate it to a binary in a high-resource ISA (e.g., x86). Then we can use a model that has been trained on the high-resource ISA to test the translated binary. We have implemented the model called UNSUPERBINTRANS, and conducted experiments to evaluate its performance. Specifically, we conducted two downstream tasks, including code similarity detection and vulnerability discovery. In both tasks, we achieved high accuracies.</abstract>
      <url hash="05b1483e">2023.findings-emnlp.971</url>
      <bibkey>ahmad-luo-2023-unsupervised</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.971</doi>
    </paper>
    <paper id="972">
      <title>Drilling Down into the Discourse Structure with <fixed-case>LLM</fixed-case>s for Long Document Question Answering</title>
      <author><first>Inderjeet</first><last>Nair</last></author>
      <author><first>Shwetha</first><last>Somasundaram</last></author>
      <author><first>Apoorv</first><last>Saxena</last></author>
      <author><first>Koustava</first><last>Goswami</last></author>
      <pages>14593-14606</pages>
      <abstract>We address the task of evidence retrieval for long document question answering, which involves locating relevant paragraphs within a document to answer a question. We aim to assess the applicability of large language models (LLMs) in the task of zero-shot long document evidence retrieval, owing to their unprecedented performance across various NLP tasks. However, currently the LLMs can consume limited context lengths as input, thus providing document chunks as inputs might overlook the global context while missing out on capturing the inter-segment dependencies. Moreover, directly feeding the large input sets can incur significant computational costs, particularly when processing the entire document (and potentially incurring monetary expenses with enterprise APIs like OpenAI’s GPT variants). To address these challenges, we propose a suite of techniques that exploit the discourse structure commonly found in documents. By utilizing this structure, we create a condensed representation of the document, enabling a more comprehensive understanding and analysis of relationships between different parts. We retain 99.6% of the best zero-shot approach’s performance, while processing only 26% of the total tokens used by the best approach in the information seeking evidence retrieval setup. We also show how our approach can be combined with *self-ask* reasoning agent to achieve best zero-shot performance in complex multi-hop question answering, just <tex-math>\approx 4</tex-math>% short of zero-shot performance using gold evidence.</abstract>
      <url hash="86234499">2023.findings-emnlp.972</url>
      <bibkey>nair-etal-2023-drilling</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.972</doi>
    </paper>
    <paper id="973">
      <title>Emergent Inabilities? Inverse Scaling Over the Course of Pretraining</title>
      <author><first>James</first><last>Michaelov</last></author>
      <author><first>Ben</first><last>Bergen</last></author>
      <pages>14607-14615</pages>
      <abstract>Does inverse scaling only occur as a function of model size, or can it also occur over the course of training? We carry out an exploratory study investigating whether the performance of language models on specific tasks can decrease (while general performance remains high) during training on the language modeling task. We find 8 tasks on which Pythia 12B (Biderman et al., 2023) shows decreased performance over the course of training. Five of these tasks (TruthfulQA-MC1, TruthfulQA-MC2, Hindsight Neglect, Memo Trap, and Pattern Match Suppression) additionally show a consistent relationship whereby larger language models show a greater decrease in performance the more they are trained, despite showing standard (positive) scaling overall. This highlights the importance of testing performance at all relevant benchmarks any time models are trained on additional data, even if their overall performance improves.</abstract>
      <url hash="813509ae">2023.findings-emnlp.973</url>
      <bibkey>michaelov-bergen-2023-emergent</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.973</doi>
    </paper>
    <paper id="974">
      <title>Alignment Precedes Fusion: Open-Vocabulary Named Entity Recognition as Context-Type Semantic Matching</title>
      <author><first>Zhuoran</first><last>Jin</last></author>
      <author><first>Pengfei</first><last>Cao</last></author>
      <author><first>Zhitao</first><last>He</last></author>
      <author><first>Yubo</first><last>Chen</last></author>
      <author><first>Kang</first><last>Liu</last></author>
      <author><first>Jun</first><last>Zhao</last></author>
      <pages>14616-14637</pages>
      <abstract>Despite the significant progress in developing named entity recognition models, scaling to novel-emerging types still remains challenging in real-world scenarios. Continual learning and zero-shot learning approaches have been explored to handle novel-emerging types with less human supervision, but they have not been as successfully adopted as supervised approaches. Meanwhile, humans possess a much larger vocabulary size than these approaches and have the ability to learn the alignment between entities and concepts effortlessly through natural supervision. In this paper, we consider a more realistic and challenging setting called open-vocabulary named entity recognition (OVNER) to imitate human-level ability. OVNER aims to recognize entities in novel types by their textual names or descriptions. Specifically, we formulate OVNER as a semantic matching task and propose a novel and scalable two-stage method called Context-Type SemAntiC Alignment and FusiOn (CACAO). In the pre-training stage, we adopt Dual-Encoder for context-type semantic alignment and pre-train Dual-Encoder on 80M context-type pairs which are easily accessible through natural supervision. In the fine-tuning stage, we use Cross-Encoder for context-type semantic fusion and fine-tune Cross-Encoder on base types with human supervision. Experimental results show that our method outperforms the previous state-of-the-art methods on three challenging OVNER benchmarks by 9.7%, 9.5%, and 1.8% F1-score of novel types. Moreover, CACAO also demonstrates its flexible transfer ability in cross-domain NER.</abstract>
      <url hash="455e7649">2023.findings-emnlp.974</url>
      <bibkey>jin-etal-2023-alignment</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.974</doi>
    </paper>
    <paper id="975">
      <title>Representation Projection Invariance Mitigates Representation Collapse</title>
      <author><first>Anastasia</first><last>Razdaibiedina</last></author>
      <author><first>Ashish</first><last>Khetan</last></author>
      <author><first>Zohar</first><last>Karnin</last></author>
      <author><first>Daniel</first><last>Khashabi</last></author>
      <author><first>Vivek</first><last>Madan</last></author>
      <pages>14638-14664</pages>
      <abstract>Fine-tuning contextualized representations learned by pre-trained language models remains a prevalent practice in NLP. However, fine-tuning can lead to representation degradation (also known as representation collapse), which may result in instability, sub-optimal performance, and weak generalization. In this paper, we propose Representation Projection Invariance (REPINA), a novel regularization method to maintain the information content of representation and reduce representation collapse during fine-tuning by discouraging undesirable changes in the representations. We study the empirical behavior of the proposed regularization in comparison to 5 comparable baselines across 13 language understanding tasks (GLUE benchmark and six additional datasets). When evaluating in-domain performance, REPINA consistently outperforms other baselines on most tasks (10 out of 13). Additionally, REPINA improves out-of-distribution performance. We also demonstrate its effectiveness in few-shot settings and robustness to label perturbation. As a by-product, we extend previous studies of representation collapse and propose several metrics to quantify it. Our empirical findings show that our approach is significantly more effective at mitigating representation collapse.</abstract>
      <url hash="baa6ebfe">2023.findings-emnlp.975</url>
      <bibkey>razdaibiedina-etal-2023-representation</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.975</doi>
    </paper>
    <paper id="976">
      <title>Tunable Soft Prompts are Messengers in Federated Learning</title>
      <author><first>Chenhe</first><last>Dong</last></author>
      <author><first>Yuexiang</first><last>Xie</last></author>
      <author><first>Bolin</first><last>Ding</last></author>
      <author><first>Ying</first><last>Shen</last></author>
      <author><first>Yaliang</first><last>Li</last></author>
      <pages>14665-14675</pages>
      <abstract>Federated learning (FL) enables multiple participants to collaboratively train machine learning models using decentralized data sources, alleviating privacy concerns that arise from directly sharing local data. However, the lack of model privacy protection in FL becomes an unneglectable challenge, especially when people want to federally finetune models based on a proprietary large language model. In this study, we propose a novel FL training approach that accomplishes information exchange among participants via tunable soft prompts. These soft prompts, updated and transmitted between the server and clients, assume the role of the global model parameters and serve as messengers to deliver useful knowledge from the local data and global model. As the global model itself is not required to be shared and the local training is conducted based on an auxiliary model with fewer parameters than the global model, the proposed approach provides protection for the global model while reducing communication and computation costs in FL. Extensive experiments show the effectiveness of the proposed approach compared to several baselines. We have released the source code at https://github.com/alibaba/FederatedScope/tree/fedsp/federatedscope/nlp/fedsp.</abstract>
      <url hash="b0c8358a">2023.findings-emnlp.976</url>
      <bibkey>dong-etal-2023-tunable</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.976</doi>
    </paper>
    <paper id="977">
      <title>Style-Aware Radiology Report Generation with <fixed-case>R</fixed-case>ad<fixed-case>G</fixed-case>raph and Few-Shot Prompting</title>
      <author><first>Benjamin</first><last>Yan</last></author>
      <author><first>Ruochen</first><last>Liu</last></author>
      <author><first>David</first><last>Kuo</last></author>
      <author><first>Subathra</first><last>Adithan</last></author>
      <author><first>Eduardo</first><last>Reis</last></author>
      <author><first>Stephen</first><last>Kwak</last></author>
      <author><first>Vasantha</first><last>Venugopal</last></author>
      <author><first>Chloe</first><last>O’Connell</last></author>
      <author><first>Agustina</first><last>Saenz</last></author>
      <author><first>Pranav</first><last>Rajpurkar</last></author>
      <author><first>Michael</first><last>Moor</last></author>
      <pages>14676-14688</pages>
      <abstract>Automatically generated reports from medical images promise to improve the workflow of radiologists. Existing methods consider an image-to-report modeling task by directly generating a fully-fledged report from an image. However, this conflates the content of the report (e.g., findings and their attributes) with its style (e.g., format and choice of words), which can lead to clinically inaccurate reports. To address this, we propose a two-step approach for radiology report generation. First, we extract the content from an image; then, we verbalize the extracted content into a report that matches the style of a specific radiologist. For this, we leverage RadGraph—a graph representation of reports—together with large language models (LLMs). In our quantitative evaluations, we find that our approach leads to beneficial performance. Our human evaluation with clinical raters highlights that the AI-generated reports are indistinguishably tailored to the style of individual radiologist despite leveraging only a few examples as context.</abstract>
      <url hash="262fbef7">2023.findings-emnlp.977</url>
      <bibkey>yan-etal-2023-style</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.977</doi>
    </paper>
    <paper id="978">
      <title>Incorporating Probing Signals into Multimodal Machine Translation via Visual Question-Answering Pairs</title>
      <author><first>Yuxin</first><last>Zuo</last></author>
      <author><first>Bei</first><last>Li</last></author>
      <author><first>Chuanhao</first><last>Lv</last></author>
      <author><first>Tong</first><last>Zheng</last></author>
      <author><first>Tong</first><last>Xiao</last></author>
      <author><first>JingBo</first><last>Zhu</last></author>
      <pages>14689-14701</pages>
      <abstract>This paper presents an in-depth study of multimodal machine translation (MMT), examining the prevailing understanding that MMT systems exhibit decreased sensitivity to visual information when text inputs are complete. Instead, we attribute this phenomenon to insufficient cross-modal interaction, rather than image information redundancy. A novel approach is proposed to generate parallel Visual Question-Answering (VQA) style pairs from the source text, fostering more robust cross-modal interaction. Using Large Language Models (LLMs), we explicitly model the probing signal in MMT to convert it into VQA-style data to create the Multi30K-VQA dataset. An MMT-VQA multitask learning framework is introduced to incorporate explicit probing signals from the dataset into the MMT training process. Experimental results on two widely-used benchmarks demonstrate the effectiveness of this novel approach. Our code and data would be available at: <url>https://github.com/libeineu/MMT-VQA</url>.</abstract>
      <url hash="4558a24e">2023.findings-emnlp.978</url>
      <bibkey>zuo-etal-2023-incorporating</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.978</doi>
    </paper>
    <paper id="979">
      <title><fixed-case>G</fixed-case>en<fixed-case>KIE</fixed-case>: Robust Generative Multimodal Document Key Information Extraction</title>
      <author><first>Panfeng</first><last>Cao</last></author>
      <author><first>Ye</first><last>Wang</last></author>
      <author><first>Qiang</first><last>Zhang</last></author>
      <author><first>Zaiqiao</first><last>Meng</last></author>
      <pages>14702-14713</pages>
      <abstract>Key information extraction (KIE) from scanned documents has gained increasing attention because of its applications in various domains. Although promising results have been achieved by some recent KIE approaches, they are usually built based on discriminative models, which lack the ability to handle optical character recognition (OCR) errors and require laborious token-level labeling. In this paper, we propose a novel generative end-to-end model, named GenKIE, to address the KIE task. GenKIE is a sequence-to-sequence multimodal generative model that utilizes multimodal encoders to embed visual, layout and textual features and a decoder to generate the desired output. Well-designed prompts are leveraged to incorporate the label semantics as the weakly supervised signals and entice the generation of the key information. One notable advantage of the generative model is that it enables automatic correction of OCR errors. Besides, token-level granular annotation is not required. Extensive experiments on multiple public real-world datasets show that GenKIE effectively generalizes over different types of documents and achieves state-of-the-art results. Our experiments also validate the model’s robustness against OCR errors, making GenKIE highly applicable in real-world scenarios.</abstract>
      <url hash="231a11a0">2023.findings-emnlp.979</url>
      <bibkey>cao-etal-2023-genkie</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.979</doi>
    </paper>
    <paper id="980">
      <title>Improving Multimodal Sentiment Analysis: Supervised Angular margin-based Contrastive Learning for Enhanced Fusion Representation</title>
      <author><first>Cong-Duy</first><last>Nguyen</last></author>
      <author><first>Thong</first><last>Nguyen</last></author>
      <author><first>Duc</first><last>Vu</last></author>
      <author><first>Anh</first><last>Luu</last></author>
      <pages>14714-14724</pages>
      <abstract>The effectiveness of a model is heavily reliant on the quality of the fusion representation of multiple modalities in multimodal sentiment analysis. Moreover, each modality is extracted from raw input and integrated with the rest to construct a multimodal representation. Although previous methods have proposed multimodal representations and achieved promising results, most of them focus on forming positive and negative pairs, neglecting the variation in sentiment scores within the same class. Additionally, they fail to capture the significance of unimodal representations in the fusion vector. To address these limitations, we introduce a framework called Supervised Angular-based Contrastive Learning for Multimodal Sentiment Analysis. This framework aims to enhance discrimination and generalizability of the multimodal representation and overcome biases in the fusion vector’s modality. Our experimental results, along with visualizations on two widely used datasets, demonstrate the effectiveness of our approach.</abstract>
      <url hash="a50c1690">2023.findings-emnlp.980</url>
      <bibkey>nguyen-etal-2023-improving-multimodal</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.980</doi>
    </paper>
    <paper id="981">
      <title>Efficient Multilingual Language Model Compression through Vocabulary Trimming</title>
      <author><first>Asahi</first><last>Ushio</last></author>
      <author><first>Yi</first><last>Zhou</last></author>
      <author><first>Jose</first><last>Camacho-Collados</last></author>
      <pages>14725-14739</pages>
      <abstract>Multilingual language models (LMs) have become a powerful tool in NLP, especially for non-English languages. Nevertheless, model parameters of multilingual LMs remain large due to the larger embedding matrix of the vocabulary covering tokens in different languages. Instead, monolingual LMs can be trained in a target language with the language-specific vocabulary only. In this paper, we propose vocabulary-trimming (VT), a method to reduce a multilingual LM vocabulary to a target language by deleting potentially irrelevant tokens from its vocabulary. In theory, VT can compress any existing multilingual LM to any language covered by the original model. In our experiments, we show that VT can retain the original performance of the multilingual LM, while being considerably smaller in size than the original multilingual LM. The evaluation is performed over four NLP tasks (two generative and two classification tasks) among four widely used multilingual LMs in seven languages. The results show that this methodology can keep the best of both monolingual and multilingual worlds by keeping a small size as monolingual models without the need for specifically retraining them, and can even help limit potentially harmful social biases.</abstract>
      <url hash="31f74fd1">2023.findings-emnlp.981</url>
      <bibkey>ushio-etal-2023-efficient</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.981</doi>
    </paper>
    <paper id="982">
      <title><fixed-case>ICU</fixed-case>: Conquering Language Barriers in Vision-and-Language Modeling by Dividing the Tasks into Image Captioning and Language Understanding</title>
      <author><first>Guojun</first><last>Wu</last></author>
      <pages>14740-14746</pages>
      <abstract>Most multilingual vision-and-language (V&amp;L) research aims to accomplish multilingual and multimodal capabilities within one model. However, the scarcity of multilingual captions for images has hindered the development. To overcome this obstacle, we propose ICU, Image Caption Understanding, which divides a V&amp;L task into two stages: a V&amp;L model performs image captioning in English, and a multilingual language model (mLM), in turn, takes the caption as the alt text and performs cross-lingual language understanding. The burden of multilingual processing is lifted off V&amp;L model and placed on mLM. Since the multilingual text data is relatively of higher abundance and quality, ICU can facilitate the conquering of language barriers for V&amp;L models. In experiments on two tasks across 9 languages in the IGLUE benchmark, we show that ICU can achieve new state-of-the-art results for five languages, and comparable results for the rest.</abstract>
      <url hash="b7047832">2023.findings-emnlp.982</url>
      <bibkey>wu-2023-icu</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.982</doi>
    </paper>
    <paper id="983">
      <title><fixed-case>GTA</fixed-case>: Gated Toxicity Avoidance for <fixed-case>LM</fixed-case> Performance Preservation</title>
      <author><first>Heegyu</first><last>Kim</last></author>
      <author><first>Hyunsouk</first><last>Cho</last></author>
      <pages>14747-14763</pages>
      <abstract>Caution: This paper includes offensive words that could potentially cause unpleasantness. The fast-paced evolution of generative language models such as GPT-4 has demonstrated outstanding results in various NLP generation tasks. However, due to the potential generation of offensive words related to race or gender, various Controllable Text Generation (CTG) methods have been proposed to mitigate the occurrence of harmful words. However, existing CTG methods not only reduce toxicity but also negatively impact several aspects of the language model’s generation performance, including topic consistency, grammar, and perplexity. This paper explores the limitations of previous methods and introduces a novel solution in the form of a simple Gated Toxicity Avoidance (GTA) that can be applied to any CTG method. We also evaluate the effectiveness of the proposed GTA by comparing it with state-of-the-art CTG methods across various datasets. Our findings reveal that gated toxicity avoidance efficiently achieves comparable levels of toxicity reduction to the original CTG methods while preserving the generation performance of the language model.</abstract>
      <url hash="8346cafb">2023.findings-emnlp.983</url>
      <bibkey>kim-cho-2023-gta</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.983</doi>
    </paper>
    <paper id="984">
      <title><fixed-case>LMGQS</fixed-case>: A Large-scale Dataset for Query-focused Summarization</title>
      <author><first>Ruochen</first><last>Xu</last></author>
      <author><first>Song</first><last>Wang</last></author>
      <author id="yang-liu-edinburgh"><first>Yang</first><last>Liu</last></author>
      <author><first>Shuohang</first><last>Wang</last></author>
      <author><first>Yichong</first><last>Xu</last></author>
      <author><first>Dan</first><last>Iter</last></author>
      <author><first>Pengcheng</first><last>He</last></author>
      <author><first>Chenguang</first><last>Zhu</last></author>
      <author><first>Michael</first><last>Zeng</last></author>
      <pages>14764-14776</pages>
      <abstract>Query-focused summarization (QFS) aims to extract or generate a summary of an input document that directly answers or is relevant to a given query. The lack of large-scale datasets in the form of documents, queries, and summaries has hindered model development in this area. In contrast, multiple large-scale high-quality datasets for generic summarization exist. We hypothesize that there is a hidden query for each summary sentence in a generic summarization annotation, and we utilize a large-scale pretrained language model to recover it. In this way, we convert four generic summarization benchmarks into a new QFS benchmark dataset, LMGQS, which consists of over 1 million document-query-summary samples. We thoroughly investigate the properties of our proposed dataset and establish baselines with state-of-the-art summarization models. By fine-tuning a language model on LMGQS, we achieve state-of-the-art zero-shot and supervised performance on multiple existing QFS benchmarks, demonstrating the high quality and diversity of LMGQS.</abstract>
      <url hash="f22cfec3">2023.findings-emnlp.984</url>
      <bibkey>xu-etal-2023-lmgqs</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.984</doi>
    </paper>
    <paper id="985">
      <title><fixed-case>C</fixed-case>hat<fixed-case>C</fixed-case>o<fixed-case>T</fixed-case>: Tool-Augmented Chain-of-Thought Reasoning on Chat-based Large Language Models</title>
      <author><first>Zhipeng</first><last>Chen</last></author>
      <author><first>Kun</first><last>Zhou</last></author>
      <author><first>Beichen</first><last>Zhang</last></author>
      <author><first>Zheng</first><last>Gong</last></author>
      <author><first>Xin</first><last>Zhao</last></author>
      <author><first>Ji-Rong</first><last>Wen</last></author>
      <pages>14777-14790</pages>
      <abstract>Although large language models (LLMs) have achieved excellent performance in a variety of evaluation benchmarks, they still struggle in complex reasoning tasks which require specific knowledge and multi-hop reasoning. To improve the reasoning abilities, we propose <tex-math>\textbf{ChatCoT}</tex-math>, a tool-augmented chain-of-thought reasoning framework for chat-based LLMs (<tex-math>\textit{e.g.,}</tex-math> ChatGPT). In ChatCoT, we model the chain-of-thought (CoT) reasoning as multi-turn conversations, to utilize tools in a more natural way through chatting. At each turn, LLMs can either interact with tools or perform the reasoning. Our approach can effectively leverage the multi-turn conversation ability of chat-based LLMs, and integrate the thought chain following and tools manipulation in a unified way. Specially, we initialize the early turns of the conversation by the knowledge about tools, tasks, and reasoning format, and propose an iterative <tex-math>\textit{tool-augmented reasoning}</tex-math> step to perform step-by-step tool-augmented reasoning. The experiment results on two complex reasoning datasets (MATH and HotpotQA) have shown the effectiveness of ChatCoT on complex reasoning tasks, achieving a 7.9% relative improvement over the state-of-the-art baseline.</abstract>
      <url hash="660e3c90">2023.findings-emnlp.985</url>
      <bibkey>chen-etal-2023-chatcot</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.985</doi>
    </paper>
    <paper id="986">
      <title>Non-Autoregressive Document-Level Machine Translation</title>
      <author><first>Guangsheng</first><last>Bao</last></author>
      <author><first>Zhiyang</first><last>Teng</last></author>
      <author><first>Hao</first><last>Zhou</last></author>
      <author><first>Jianhao</first><last>Yan</last></author>
      <author><first>Yue</first><last>Zhang</last></author>
      <pages>14791-14803</pages>
      <abstract>Non-autoregressive translation (NAT) models achieve comparable performance and superior speed compared to auto-regressive translation (AT) models in the context of sentence-level machine translation (MT). However, their abilities are unexplored in document-level MT, hindering their usage in real scenarios. In this paper, we conduct a comprehensive examination of typical NAT models in the context of document-level MT and further propose a simple but effective design of sentence alignment between source and target. Experiments show that NAT models achieve high acceleration on documents, and sentence alignment significantly enhances their performance. However, current NAT models still have a significant performance gap compared to their AT counterparts. Further investigation reveals that NAT models suffer more from the multi-modality and misalignment issues in the context of document-level MT, and current NAT models struggle with exploiting document context and handling discourse phenomena. We delve into these challenges and provide our code at <url>https://github.com/baoguangsheng/nat-on-doc</url>.</abstract>
      <url hash="01318d15">2023.findings-emnlp.986</url>
      <bibkey>bao-etal-2023-non</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.986</doi>
    </paper>
    <paper id="987">
      <title>Exploring the Effectiveness of Multi-Lingual Commonsense Knowledge-Aware Open-Domain Dialogue Response Generation</title>
      <author><first>Sixing</first><last>Wu</last></author>
      <author><first>Jiong</first><last>Yu</last></author>
      <author><first>Tianshi</first><last>Che</last></author>
      <author><first>Yang</first><last>Zhou</last></author>
      <author><first>Wei</first><last>Zhou</last></author>
      <pages>14804-14814</pages>
      <abstract>Prior works have shown the promising results of commonsense knowledge-aware models in improving informativeness while reducing the hallucination issue. Nonetheless, prior works often can only use monolingual knowledge whose language is consistent with the dialogue context. Except for a few high-resource languages, such as English and Chinese, most languages suffer from insufficient knowledge issues, especially minority languages. To this end, this work proposes a new task, Multi-Lingual Commonsense Knowledge-Aware Response Generation (MCKRG), which tries to use commonsense knowledge in other languages to enhance the current dialogue generation. Then, we construct a MCKRG dataset MCK-Dialog of seven languages with multiple alignment methods. Finally, we verify the effectiveness of using multi-lingual commonsense knowledge with a proposed MCK-T5 model. Extensive experimental results demonstrate the great potential of using multi-lingual commonsense knowledge in high-resource and low-resource languages. To the best of our knowledge, this work is the first to explore Multi-Lingual Commonsense Knowledge-Aware Response Generation.</abstract>
      <url hash="770bdfc4">2023.findings-emnlp.987</url>
      <bibkey>wu-etal-2023-exploring</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.987</doi>
    </paper>
    <paper id="988">
      <title>Mixture of Soft Prompts for Controllable Data Generation</title>
      <author><first>Derek</first><last>Chen</last></author>
      <author><first>Celine</first><last>Lee</last></author>
      <author><first>Yunan</first><last>Lu</last></author>
      <author><first>Domenic</first><last>Rosati</last></author>
      <author><first>Zhou</first><last>Yu</last></author>
      <pages>14815-14833</pages>
      <abstract>Large language models (LLMs) effectively generate fluent text when the target output follows natural language patterns. However, structured prediction tasks confine the output format to a limited ontology, causing even very large models to struggle since they were never trained with such restrictions in mind. The difficulty of using LLMs for direct prediction is exacerbated in few-shot learning scenarios, which commonly arise due to domain shift and resource limitations. We flip the problem on its head by leveraging the LLM as a tool for data augmentation rather than direct prediction. Our proposed Mixture of Soft Prompts (MSP) serves as a parameter-efficient procedure for generating multi-attribute data in a controlled manner. Denoising mechanisms are further applied to improve the quality of synthesized data. Automatic metrics show our method is capable of producing diverse and natural text, while preserving label semantics. Moreover, MSP achieves state-of-the-art results on three benchmarks when compared against strong baselines. Our method offers an alternate data-centric approach for applying LLMs to complex prediction tasks.</abstract>
      <url hash="b6c5acaf">2023.findings-emnlp.988</url>
      <bibkey>chen-etal-2023-mixture</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.988</doi>
    </paper>
    <paper id="989">
      <title>A Boundary Offset Prediction Network for Named Entity Recognition</title>
      <author><first>Minghao</first><last>Tang</last></author>
      <author><first>Yongquan</first><last>He</last></author>
      <author><first>Yongxiu</first><last>Xu</last></author>
      <author><first>Hongbo</first><last>Xu</last></author>
      <author><first>Wenyuan</first><last>Zhang</last></author>
      <author><first>Yang</first><last>Lin</last></author>
      <pages>14834-14846</pages>
      <abstract>Named entity recognition (NER) is a fundamental task in natural language processing that aims to identify and classify named entities in text. However, span-based methods for NER typically assign entity types to text spans, resulting in an imbalanced sample space and neglecting the connections between non-entity and entity spans. To address these issues, we propose a novel approach for NER, named the Boundary Offset Prediction Network (BOPN), which predicts the boundary offsets between candidate spans and their nearest entity spans. By leveraging the guiding semantics of boundary offsets, BOPN establishes connections between non-entity and entity spans, enabling non-entity spans to function as additional positive samples for entity detection. Furthermore, our method integrates entity type and span representations to generate type-aware boundary offsets instead of using entity types as detection targets. We conduct experiments on eight widely-used NER datasets, and the results demonstrate that our proposed BOPN outperforms previous state-of-the-art methods.</abstract>
      <url hash="63b3898d">2023.findings-emnlp.989</url>
      <bibkey>tang-etal-2023-boundary</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.989</doi>
    </paper>
    <paper id="990">
      <title>Prefix-Tuning Based Unsupervised Text Style Transfer</title>
      <author><first>Huiyu</first><last>Mai</last></author>
      <author><first>Wenhao</first><last>Jiang</last></author>
      <author><first>Zhi-Hong</first><last>Deng</last></author>
      <pages>14847-14856</pages>
      <abstract>Unsupervised text style transfer aims at training a generative model that can alter the style of the input sentence while preserving its content without using any parallel data. In this paper, we employ powerful pre-trained large language models and present a new prefix-tuning-based method for unsupervised text style transfer. We construct three different kinds of prefixes, i.e., shared prefix, style prefix, and content prefix, to encode task-specific information, target style, and the content information of the input sentence, respectively. Compared to embeddings used by previous works, the proposed prefixes can provide richer information for the model. Furthermore, we adopt a recursive way of using language models in the process of style transfer. This strategy provides a more effective way for the interactions between the input sentence and GPT-2, helps the model construct more informative prefixes, and thus, helps improve the performance. Evaluations on the well-known datasets show that our method outperforms the state-of-the-art baselines. Results, analysis of ablation studies, and subjective evaluations from humans are also provided for a deeper understanding of the proposed method.</abstract>
      <url hash="6a1a9a7d">2023.findings-emnlp.990</url>
      <bibkey>mai-etal-2023-prefix</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.990</doi>
    </paper>
    <paper id="991">
      <title>Evaluating and Enhancing the Robustness of Code Pre-trained Models through Structure-Aware Adversarial Samples Generation</title>
      <author><first>Nuo</first><last>Chen</last></author>
      <author><first>Qiushi</first><last>Sun</last></author>
      <author><first>Jianing</first><last>Wang</last></author>
      <author><first>Ming</first><last>Gao</last></author>
      <author><first>Xiaoli</first><last>Li</last></author>
      <author><first>Xiang</first><last>Li</last></author>
      <pages>14857-14873</pages>
      <abstract>Code pre-trained models (CodePTMs) have significantly advanced the field of neural code intelligence. Despite their capabilities, these models are susceptible to adversarial attacks that subtly modify the model inputs, resulting in incorrect outputs or predictions. Previous methods of robustness evaluation for CodePTMs primarily stem from a textual perspective, without explicitly taking into account the structure of the code. Furthermore, prior studies fail to encompass a broad enough spectrum of tasks and models. In this paper, we propose a set of novel robustness evaluation methods based on the intrinsic structure of the code. Specifically, we first launch adversarial attacks on crucial identifier tokens and sub-tree structures to explore the impact of imperceptible perturbation. Then, we perform global restructuring of the code using different traversal methods for abstract syntax trees, aiming to explore the model’s sensitivity to input samples with equivalent information. Moreover, for each scenario, we employ adversarial training methods to explore the possibility of restoring the performance of perturbed models. For both code understanding and generation, our proposed method has demonstrated its effectiveness across a wide range of models and tasks, thereby allowing us to make one step forward in our understanding of the inner mechanisms of CodePTMs.</abstract>
      <url hash="9848219f">2023.findings-emnlp.991</url>
      <bibkey>chen-etal-2023-evaluating</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.991</doi>
    </paper>
    <paper id="992">
      <title>Annotation Sensitivity: Training Data Collection Methods Affect Model Performance</title>
      <author><first>Christoph</first><last>Kern</last></author>
      <author><first>Stephanie</first><last>Eckman</last></author>
      <author><first>Jacob</first><last>Beck</last></author>
      <author><first>Rob</first><last>Chew</last></author>
      <author><first>Bolei</first><last>Ma</last></author>
      <author><first>Frauke</first><last>Kreuter</last></author>
      <pages>14874-14886</pages>
      <abstract>When training data are collected from human annotators, the design of the annotation instrument, the instructions given to annotators, the characteristics of the annotators, and their interactions can impact training data. This study demonstrates that design choices made when creating an annotation instrument also impact the models trained on the resulting annotations. We introduce the term annotation sensitivity to refer to the impact of annotation data collection methods on the annotations themselves and on downstream model performance and predictions. We collect annotations of hate speech and offensive language in five experimental conditions of an annotation instrument, randomly assigning annotators to conditions. We then fine-tune BERT models on each of the five resulting datasets and evaluate model performance on a holdout portion of each condition. We find considerable differences between the conditions for 1) the share of hate speech/offensive language annotations, 2) model performance, 3) model predictions, and 4) model learning curves. Our results emphasize the crucial role played by the annotation instrument which has received little attention in the machine learning literature. We call for additional research into how and why the instrument impacts the annotations to inform the development of best practices in instrument design.</abstract>
      <url hash="3c25113c">2023.findings-emnlp.992</url>
      <bibkey>kern-etal-2023-annotation</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.992</doi>
    </paper>
    <paper id="993">
      <title>Qualitative Code Suggestion: A Human-Centric Approach to Qualitative Coding</title>
      <author><first>Cesare</first><last>Spinoso-Di Piano</last></author>
      <author><first>Samira</first><last>Rahimi</last></author>
      <author><first>Jackie</first><last>Cheung</last></author>
      <pages>14887-14909</pages>
      <abstract>Qualitative coding is a content analysis method in which researchers read through a text corpus and assign descriptive labels or qualitative codes to passages. It is an arduous and manual process which human-computer interaction (HCI) studies have shown could greatly benefit from NLP techniques to assist qualitative coders. Yet, previous attempts at leveraging language technologies have set up qualitative coding as a fully automatable classification problem. In this work, we take a more assistive approach by defining the task of qualitative code suggestion (QCS) in which a ranked list of previously assigned qualitative codes is suggested from an identified passage. In addition to being user-motivated, QCS integrates previously ignored properties of qualitative coding such as the sequence in which passages are annotated, the importance of rare codes and the differences in annotation styles between coders. We investigate the QCS task by releasing the first publicly available qualitative coding dataset, CVDQuoding, consisting of interviews conducted with women at risk of cardiovascular disease. In addition, we conduct a human evaluation which shows that our systems consistently make relevant code suggestions.</abstract>
      <url hash="f6217b77">2023.findings-emnlp.993</url>
      <bibkey>piano-etal-2023-qualitative</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.993</doi>
    </paper>
    <paper id="994">
      <title><fixed-case>D</fixed-case><tex-math>^2</tex-math><fixed-case>TV</fixed-case>: Dual Knowledge Distillation and Target-oriented Vision Modeling for Many-to-Many Multimodal Summarization</title>
      <author><first>Yunlong</first><last>Liang</last></author>
      <author><first>Fandong</first><last>Meng</last></author>
      <author><first>Jiaan</first><last>Wang</last></author>
      <author><first>Jinan</first><last>Xu</last></author>
      <author><first>Yufeng</first><last>Chen</last></author>
      <author><first>Jie</first><last>Zhou</last></author>
      <pages>14910-14922</pages>
      <abstract>Many-to-many multimodal summarization (M<tex-math>^3</tex-math>S) task aims to generate summaries in any language with document inputs in any language and the corresponding image sequence, which essentially comprises of multimodal monolingual summarization (MMS) and multimodal cross-lingual summarization (MXLS) tasks. Although much work has been devoted to either MMS or MXLS, little research pays attention to the M<tex-math>^3</tex-math>S task. Besides, existing studies mainly focus on 1) utilizing MMS to enhance MXLS via knowledge distillation without considering the performance of MMS or 2) improving MMS models by filtering summary-unrelated visual features with implicit learning or explicitly complex training objectives. In this paper, we first introduce a general and practical task, <i>i.e.</i>, M<tex-math>^3</tex-math>S. Further, we propose a dual knowledge distillation and target-oriented vision modeling framework for the M<tex-math>^3</tex-math>S task. Specifically, the dual knowledge distillation method guarantees that the knowledge of MMS and MXLS can be transferred to each other and thus mutually prompt both of them. To offer target-oriented visual features, a simple yet effective target-oriented contrastive objective is designed and responsible for discarding needless visual information. Extensive experiments on the many-to-many setting show the effectiveness of the proposed approach. Additionally, we contribute a many-to-many multimodal summarization (lmttM<tex-math>^3</tex-math>Sum) dataset with 44 languages to facilitate future research.</abstract>
      <url hash="a4c4556e">2023.findings-emnlp.994</url>
      <bibkey>liang-etal-2023-d2tv</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.994</doi>
    </paper>
    <paper id="995">
      <title>Improving Input-label Mapping with Demonstration Replay for In-context Learning</title>
      <author><first>Zhuocheng</first><last>Gong</last></author>
      <author><first>Jiahao</first><last>Liu</last></author>
      <author><first>Qifan</first><last>Wang</last></author>
      <author><first>Jingang</first><last>Wang</last></author>
      <author><first>Xunliang</first><last>Cai</last></author>
      <author><first>Dongyan</first><last>Zhao</last></author>
      <author><first>Rui</first><last>Yan</last></author>
      <pages>14923-14934</pages>
      <abstract>In-context learning (ICL) is an emerging capability of large autoregressive language models where a few input-label demonstrations are appended to the input to enhance the model’s understanding of downstream NLP tasks, without directly adjusting the model parameters. The effectiveness of ICL can be attributed to the strong language modeling capabilities of large language models (LLMs), which enable them to learn the mapping between input and labels based on in-context demonstrations. Despite achieving promising results, the causal nature of language modeling in ICL restricts the attention to be backward only, i.e., a token only attends to its previous tokens, failing to capture the full input-label information and limiting the model’s performance. In this paper, we propose a novel ICL method called Repeated Demonstration with Sliding Causal Attention, (RdSca). Specifically, we duplicate later demonstrations and concatenate them to the front, allowing the model to ‘observe’ the later information even under the causal restriction. Besides, we introduce sliding causal attention, which customizes causal attention to avoid information leakage. Experimental results show that our method significantly improves the input-label mapping in ICL demonstrations. We also conduct an in-depth analysis of how to customize the causal attention without training, which has been an unexplored area in previous research.</abstract>
      <url hash="5180701e">2023.findings-emnlp.995</url>
      <bibkey>gong-etal-2023-improving</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.995</doi>
    </paper>
    <paper id="996">
      <title>Enhancing Text-to-<fixed-case>SQL</fixed-case> Capabilities of Large Language Models: A Study on Prompt Design Strategies</title>
      <author><first>Linyong</first><last>Nan</last></author>
      <author><first>Yilun</first><last>Zhao</last></author>
      <author><first>Weijin</first><last>Zou</last></author>
      <author><first>Narutatsu</first><last>Ri</last></author>
      <author><first>Jaesung</first><last>Tae</last></author>
      <author><first>Ellen</first><last>Zhang</last></author>
      <author><first>Arman</first><last>Cohan</last></author>
      <author><first>Dragomir</first><last>Radev</last></author>
      <pages>14935-14956</pages>
      <abstract>In-context learning (ICL) has emerged as a new approach to various natural language processing tasks, utilizing large language models (LLMs) to make predictions based on context that has been supplemented with a few examples or task-specific instructions. In this paper, we aim to extend this method to question answering tasks that utilize structured knowledge sources, and improve Text-to-SQL systems by exploring various prompt design strategies for employing LLMs. We conduct a systematic investigation into different demonstration selection methods and optimal instruction formats for prompting LLMs in the Text-to-SQL task. Our approach involves leveraging the syntactic structure of an example’s SQL query to retrieve demonstrations, and we demonstrate that pursuing both diversity and similarity in demonstration selection leads to enhanced performance. Furthermore, we show that LLMs benefit from database-related knowledge augmentations. Our most effective strategy outperforms the state-of-the-art system by 2.5 points (Execution Accuracy) and the best fine-tuned system by 5.1 points on the Spider dataset. These results highlight the effectiveness of our approach in adapting LLMs to the Text-to-SQL task, and we present an analysis of the factors contributing to the success of our strategy.</abstract>
      <url hash="143b6ccc">2023.findings-emnlp.996</url>
      <bibkey>nan-etal-2023-enhancing</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.996</doi>
    </paper>
    <paper id="997">
      <title>Cross-lingual Open-Retrieval Question Answering for <fixed-case>A</fixed-case>frican Languages</title>
      <author><first>Odunayo</first><last>Ogundepo</last></author>
      <author><first>Tajuddeen</first><last>Gwadabe</last></author>
      <author><first>Clara</first><last>Rivera</last></author>
      <author><first>Jonathan</first><last>Clark</last></author>
      <author><first>Sebastian</first><last>Ruder</last></author>
      <author><first>David</first><last>Adelani</last></author>
      <author><first>Bonaventure</first><last>Dossou</last></author>
      <author><first>Abdou</first><last>Diop</last></author>
      <author><first>Claytone</first><last>Sikasote</last></author>
      <author><first>Gilles</first><last>Hacheme</last></author>
      <author><first>Happy</first><last>Buzaaba</last></author>
      <author><first>Ignatius</first><last>Ezeani</last></author>
      <author><first>Rooweither</first><last>Mabuya</last></author>
      <author><first>Salomey</first><last>Osei</last></author>
      <author><first>Chris</first><last>Emezue</last></author>
      <author><first>Albert</first><last>Kahira</last></author>
      <author><first>Shamsuddeen</first><last>Muhammad</last></author>
      <author><first>Akintunde</first><last>Oladipo</last></author>
      <author><first>Abraham</first><last>Owodunni</last></author>
      <author><first>Atnafu</first><last>Tonja</last></author>
      <author><first>Iyanuoluwa</first><last>Shode</last></author>
      <author><first>Akari</first><last>Asai</last></author>
      <author><first>Anuoluwapo</first><last>Aremu</last></author>
      <author><first>Ayodele</first><last>Awokoya</last></author>
      <author><first>Bernard</first><last>Opoku</last></author>
      <author><first>Chiamaka</first><last>Chukwuneke</last></author>
      <author><first>Christine</first><last>Mwase</last></author>
      <author><first>Clemencia</first><last>Siro</last></author>
      <author><first>Stephen</first><last>Arthur</last></author>
      <author><first>Tunde</first><last>Ajayi</last></author>
      <author><first>Verrah</first><last>Otiende</last></author>
      <author><first>Andre</first><last>Rubungo</last></author>
      <author><first>Boyd</first><last>Sinkala</last></author>
      <author><first>Daniel</first><last>Ajisafe</last></author>
      <author><first>Emeka</first><last>Onwuegbuzia</last></author>
      <author><first>Falalu</first><last>Lawan</last></author>
      <author><first>Ibrahim</first><last>Ahmad</last></author>
      <author><first>Jesujoba</first><last>Alabi</last></author>
      <author><first>Chinedu</first><last>Mbonu</last></author>
      <author><first>Mofetoluwa</first><last>Adeyemi</last></author>
      <author><first>Mofya</first><last>Phiri</last></author>
      <author><first>Orevaoghene</first><last>Ahia</last></author>
      <author><first>Ruqayya</first><last>Iro</last></author>
      <author><first>Sonia</first><last>Adhiambo</last></author>
      <pages>14957-14972</pages>
      <abstract>African languages have far less in-language content available digitally, making it challenging for question answering systems to satisfy the information needs of users. Cross-lingual open-retrieval question answering (XOR QA) systems – those that retrieve answer content from other languages while serving people in their native language—offer a means of filling this gap. To this end, we create Our Dataset, the first cross-lingual QA dataset with a focus on African languages. Our Dataset includes 12,000+ XOR QA examples across 10 African languages. While previous datasets have focused primarily on languages where cross-lingual QA augments coverage from the target language, Our Dataset focuses on languages where cross-lingual answer content is the only high-coverage source of answer content. Because of this, we argue that African languages are one of the most important and realistic use cases for XOR QA. Our experiments demonstrate the poor performance of automatic translation and multilingual retrieval methods. Overall, Our Dataset proves challenging for state-of-the-art QA models. We hope that the dataset enables the development of more equitable QA technology.</abstract>
      <url hash="176d1de6">2023.findings-emnlp.997</url>
      <bibkey>ogundepo-etal-2023-cross</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.997</doi>
    </paper>
    <paper id="998">
      <title>Viewing Knowledge Transfer in Multilingual Machine Translation Through a Representational Lens</title>
      <author><first>David</first><last>Stap</last></author>
      <author><first>Vlad</first><last>Niculae</last></author>
      <author><first>Christof</first><last>Monz</last></author>
      <pages>14973-14987</pages>
      <abstract>We argue that translation quality alone is not a sufficient metric for measuring knowledge transfer in multilingual neural machine translation. To support this claim, we introduce Representational Transfer Potential (RTP), which measures representational similarities between languages. We show that RTP can measure both positive and negative transfer (interference), and find that RTP is strongly correlated with changes in translation quality, indicating that transfer <i>does</i> occur. Furthermore, we investigate data and language characteristics that are relevant for transfer, and find that multi-parallel overlap is an important yet under-explored feature. Based on this, we develop a novel training scheme, which uses an auxiliary similarity loss that encourages representations to be more invariant across languages by taking advantage of multi-parallel data. We show that our method yields increased translation quality for low- and mid-resource languages across multiple data and model setups.</abstract>
      <url hash="d9b64c76">2023.findings-emnlp.998</url>
      <bibkey>stap-etal-2023-viewing</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.998</doi>
    </paper>
    <paper id="999">
      <title>Aligning Predictive Uncertainty with Clarification Questions in Grounded Dialog</title>
      <author><first>Kata</first><last>Naszadi</last></author>
      <author><first>Putra</first><last>Manggala</last></author>
      <author><first>Christof</first><last>Monz</last></author>
      <pages>14988-14998</pages>
      <abstract>Asking for clarification is fundamental to effective collaboration. An interactive artificial agent must know when to ask a human instructor for more information in order to ascertain their goals. Previous work bases the timing of questions on supervised models learned from interactions between humans. Instead of a supervised classification task, we wish to ground the need for questions in the acting agent’s predictive uncertainty. In this work, we investigate if ambiguous linguistic instructions can be aligned with uncertainty in neural models. We train an agent using the T5 encoder-decoder architecture to solve the Minecraft Collaborative Building Task and identify uncertainty metrics that achieve better distributional separation between clear and ambiguous instructions. We further show that well-calibrated prediction probabilities benefit the detection of ambiguous instructions. Lastly, we provide a novel empirical analysis on the relationship between uncertainty and dialog history length and highlight an important property that poses a difficulty for detection.</abstract>
      <url hash="f4c4cfbe">2023.findings-emnlp.999</url>
      <bibkey>naszadi-etal-2023-aligning</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.999</doi>
    </paper>
    <paper id="1000">
      <title>Cache me if you Can: an Online Cost-aware Teacher-Student framework to Reduce the Calls to Large Language Models</title>
      <author><first>Ilias</first><last>Stogiannidis</last></author>
      <author><first>Stavros</first><last>Vassos</last></author>
      <author><first>Prodromos</first><last>Malakasiotis</last></author>
      <author><first>Ion</first><last>Androutsopoulos</last></author>
      <pages>14999-15008</pages>
      <abstract>Prompting Large Language Models (LLMs) performs impressively in zero- and few-shot settings. Hence, small and medium-sized enterprises (SMEs) that cannot afford the cost of creating large task-specific training datasets, but also the cost of pretraining their own LLMs, are increasingly turning to third-party services that allow them to prompt LLMs. However, such services currently require a payment per call, which becomes a significant operating expense (OpEx). Furthermore, customer inputs are often very similar over time, hence SMEs end-up prompting LLMs with very similar instances. We propose a framework that allows reducing the calls to LLMs by caching previous LLM responses and using them to train a local inexpensive model on the SME side. The framework includes criteria for deciding when to trust the local model or call the LLM, and a methodology to tune the criteria and measure the tradeoff between performance and cost. For experimental purposes, we instantiate our framework with two LLMs, GPT-3.5 or GPT-4, and two inexpensive students, a <tex-math>k</tex-math>-NN classifier or a Multi-Layer Perceptron, using two common business tasks, intent recognition and sentiment analysis. Experimental results indicate that significant OpEx savings can be obtained with only slightly lower performance.</abstract>
      <url hash="a27d1c32">2023.findings-emnlp.1000</url>
      <bibkey>stogiannidis-etal-2023-cache</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.1000</doi>
    </paper>
    <paper id="1001">
      <title><fixed-case>P</fixed-case>arro<fixed-case>T</fixed-case>: Translating during Chat using Large Language Models tuned with Human Translation and Feedback</title>
      <author><first>Wenxiang</first><last>Jiao</last></author>
      <author><first>Jen-tse</first><last>Huang</last></author>
      <author><first>Wenxuan</first><last>Wang</last></author>
      <author><first>Zhiwei</first><last>He</last></author>
      <author><first>Tian</first><last>Liang</last></author>
      <author><first>Xing</first><last>Wang</last></author>
      <author><first>Shuming</first><last>Shi</last></author>
      <author><first>Zhaopeng</first><last>Tu</last></author>
      <pages>15009-15020</pages>
      <abstract>Large language models (LLMs) like ChatGPT have exhibited remarkable abilities on a wide range of natural language processing (NLP) tasks, including various machine translation abilities accomplished during chat. However, these models are only accessible through restricted APIs, which creates barriers to new research and advancements in the field. Therefore, we propose ParroT, a framework to enhance and regulate the translation abilities during chat based on open-source LLMs (e.g., LLaMA), human-written translation and feedback data. Specifically, ParroT reformulates translation data into the instruction-following style, and introduces a “Hint” field for incorporating extra requirements to regulate the translation process. Accordingly, we propose three instruction types for finetuning ParroT models, including translation instruction, contrastive instruction, and error-guided instruction. Experiments on Flores subsets and WMT22 test sets suggest that translation instruction improves the translation performance of vanilla LLMs significantly while error-guided instruction can lead to further improvement, which demonstrates the importance of learning from low-quality translations annotated by humans. We also demonstrate the potential of automatic evaluation tools in providing quality information of translations, when constructing error-guided instructions for directions that lack human annotation data. Please refer to our Github project for more implementation details: https://github.com/wxjiao/ParroT.</abstract>
      <url hash="6a7139d7">2023.findings-emnlp.1001</url>
      <bibkey>jiao-etal-2023-parrot</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.1001</doi>
    </paper>
    <paper id="1002">
      <title>Dense Retrieval as Indirect Supervision for Large-space Decision Making</title>
      <author><first>Nan</first><last>Xu</last></author>
      <author><first>Fei</first><last>Wang</last></author>
      <author><first>Mingtao</first><last>Dong</last></author>
      <author><first>Muhao</first><last>Chen</last></author>
      <pages>15021-15033</pages>
      <abstract>Many discriminative natural language understanding (NLU) tasks have large label spaces. Learning such a process of large-space decision making is particularly challenging due to the lack of training instances per label and the difficulty of selection among many fine-grained labels. Inspired by dense retrieval methods for passage finding in open-domain QA, we propose a reformulation of large-space discriminative NLU tasks as a learning-to-retrieve task, leading to a novel solution named Dense Decision Retrieval (DDR). Instead of predicting fine-grained decisions as logits, DDR adopts a dual-encoder architecture that learns to predict by retrieving from a decision thesaurus. This approach not only leverages rich indirect supervision signals from easy-to-consume learning resources for dense retrieval, it also leads to enhanced prediction generalizability with a semantically meaningful representation of the large decision space. When evaluated on tasks with decision spaces ranging from hundreds to hundred-thousand scales, DDR outperforms strong baselines greatly by 27.54% in P @1 on two extreme multi-label classification tasks, 1.17% in F1 score ultra-fine entity typing, and 1.26% in accuracy on three few-shot intent classification tasks on average.</abstract>
      <url hash="08508a08">2023.findings-emnlp.1002</url>
      <bibkey>xu-etal-2023-dense</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.1002</doi>
    </paper>
    <paper id="1003">
      <title>One-Model-Connects-All: A Unified Graph Pre-Training Model for Online Community Modeling</title>
      <author><first>Ruoxue</first><last>Ma</last></author>
      <author><first>Jiarong</first><last>Xu</last></author>
      <author><first>Xinnong</first><last>Zhang</last></author>
      <author><first>Haozhe</first><last>Zhang</last></author>
      <author><first>Zuyu</first><last>Zhao</last></author>
      <author><first>Qi</first><last>Zhang</last></author>
      <author><first>Xuanjing</first><last>Huang</last></author>
      <author><first>Zhongyu</first><last>Wei</last></author>
      <pages>15034-15045</pages>
      <abstract>Online community is composed of communities, users, and user-generated textual content, with rich information that can help us solve social problems. Previous research hasn’t fully utilized these three components and the relationship among them. What’s more, they can’t adapt to a wide range of downstream tasks. To solve these problems, we focus on a framework that simultaneously considers communities, users, and texts. And it can easily connect with a variety of downstream tasks related to social media. Specifically, we use a ternary heterogeneous graph to model online communities. Text reconstruction and edge generation are used to learn structural and semantic knowledge among communities, users, and texts. By leveraging this pre-trained model, we achieve promising results across multiple downstream tasks, such as violation detection, sentiment analysis, and community recommendation. Our exploration will improve online community modeling.</abstract>
      <url hash="87fa3767">2023.findings-emnlp.1003</url>
      <bibkey>ma-etal-2023-one</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.1003</doi>
    </paper>
    <paper id="1004">
      <title>In-Image Neural Machine Translation with Segmented Pixel Sequence-to-Sequence Model</title>
      <author><first>Yanzhi</first><last>Tian</last></author>
      <author><first>Xiang</first><last>Li</last></author>
      <author><first>Zeming</first><last>Liu</last></author>
      <author><first>Yuhang</first><last>Guo</last></author>
      <author><first>Bin</first><last>Wang</last></author>
      <pages>15046-15057</pages>
      <abstract>In-Image Machine Translation (IIMT) aims to convert images containing texts from one language to another. Traditional approaches for this task are cascade methods, which utilize optical character recognition (OCR) followed by neural machine translation (NMT) and text rendering. However, the cascade methods suffer from compounding errors of OCR and NMT, leading to a decrease in translation quality. In this paper, we propose an end-to-end model instead of the OCR, NMT and text rendering pipeline. Our neural architecture adopts encoder-decoder paradigm with segmented pixel sequences as inputs and outputs. Through end-to-end training, our model yields improvements across various dimensions, (i) it achieves higher translation quality by avoiding error propagation, (ii) it demonstrates robustness for out domain data, and (iii) it displays insensitivity to incomplete words. To validate the effectiveness of our method and support for future research, we construct our dataset containing 4M pairs of De-En images and train our end-to-end model. The experimental results show that our approach outperforms both cascade method and current end-to-end model.</abstract>
      <url hash="e1854a0d">2023.findings-emnlp.1004</url>
      <bibkey>tian-etal-2023-image</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.1004</doi>
    </paper>
    <paper id="1005">
      <title><fixed-case>N</fixed-case>arrative<fixed-case>XL</fixed-case>: a Large-scale Dataset for Long-Term Memory Models</title>
      <author><first>Arsenii</first><last>Moskvichev</last></author>
      <author><first>Ky-Vinh</first><last>Mai</last></author>
      <pages>15058-15072</pages>
      <abstract>We propose a new large-scale (nearly a million questions) ultra-long-context (more than 50,000 words average document length) reading comprehension dataset. Using GPT 3.5, we summarized each scene in 1,500 hand-curated fiction books from Project Gutenberg, which resulted in approximately 150 scene-level summaries per book. After that, we created a number of reading comprehension questions based on these summaries, including three types of multiple-choice scene recognition questions, as well as free-form narrative reconstruction questions. With 990,595 total questions, our dataset is an order of magnitude larger than the closest alternatives. Crucially, most questions have a known “retention demand”, indicating how long-term of a memory is needed to answer them, which should aid long-term memory performance evaluation. We validate our data in four small-scale experiments: one with human labelers, and three with existing language models. We show that our questions 1) adequately represent the source material 2) can be used to diagnose a model’s memory capacity 3) are not trivial for modern language models even when the memory demand does not exceed those models’ context lengths. Lastly, we provide our code which can be used to further expand the dataset with minimal human labor.</abstract>
      <url hash="a5d5ac47">2023.findings-emnlp.1005</url>
      <bibkey>moskvichev-mai-2023-narrativexl</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.1005</doi>
    </paper>
    <paper id="1006">
      <title>Dialogue Act-Aided Backchannel Prediction Using Multi-Task Learning</title>
      <author><first>Wencke</first><last>Liermann</last></author>
      <author><first>Yo-Han</first><last>Park</last></author>
      <author><first>Yong-Seok</first><last>Choi</last></author>
      <author><first>Kong</first><last>Lee</last></author>
      <pages>15073-15079</pages>
      <abstract>Produced in the form of small injections such as “Yeah!” or “Uh-Huh” by listeners in a conversation, supportive verbal feedback (i.e., backchanneling) is essential for natural dialogue. Highlighting its tight relation to speaker intent and utterance type, we propose a multi-task learning approach that learns textual representations for the task of backchannel prediction in tandem with dialogue act classification. We demonstrate the effectiveness of our approach by improving the prediction of specific backchannels like “Yeah” or “Really?” by up to 2.0% in F1. Additionally, whereas previous models relied on well-established methods to extract audio features, we further pre-train the audio encoder in a self-supervised fashion using voice activity projection. This leads to additional gains of 1.4% in weighted F1.</abstract>
      <url hash="3ce0efe4">2023.findings-emnlp.1006</url>
      <bibkey>liermann-etal-2023-dialogue</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.1006</doi>
    </paper>
    <paper id="1007">
      <title>m<fixed-case>R</fixed-case>e<fixed-case>F</fixed-case>in<fixed-case>ED</fixed-case>: An Efficient End-to-End Multilingual Entity Linking System</title>
      <author><first>Peerat</first><last>Limkonchotiwat</last></author>
      <author><first>Weiwei</first><last>Cheng</last></author>
      <author><first>Christos</first><last>Christodoulopoulos</last></author>
      <author><first>Amir</first><last>Saffari</last></author>
      <author><first>Jens</first><last>Lehmann</last></author>
      <pages>15080-15089</pages>
      <abstract>End-to-end multilingual entity linking (MEL) is concerned with identifying multilingual entity mentions and their corresponding entity IDs in a knowledge base. Existing works assumed that entity mentions were given and skipped the entity mention detection step due to a lack of high-quality multilingual training corpora. To overcome this limitation, we propose mReFinED, the first end-to-end multilingual entity linking. Additionally, we propose a bootstrapping mention detection framework that enhances the quality of training corpora. Our experimental results demonstrated that mReFinED outperformed the best existing work in the end-to-end MEL task while being 44 times faster.</abstract>
      <url hash="ad12cbb8">2023.findings-emnlp.1007</url>
      <bibkey>limkonchotiwat-etal-2023-mrefined</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.1007</doi>
    </paper>
    <paper id="1008">
      <title>Sub-network Discovery and Soft-masking for Continual Learning of Mixed Tasks</title>
      <author><first>Zixuan</first><last>Ke</last></author>
      <author><first>Bing</first><last>Liu</last></author>
      <author><first>Wenhan</first><last>Xiong</last></author>
      <author><first>Asli</first><last>Celikyilmaz</last></author>
      <author><first>Haoran</first><last>Li</last></author>
      <pages>15090-15107</pages>
      <abstract>Continual learning (CL) has two main objectives: preventing catastrophic forgetting (CF) and encouraging knowledge transfer (KT). The existing literature mainly focused on overcoming CF. Some work has also been done on KT when the tasks are similar. To our knowledge, only one method has been proposed to learn a sequence of mixed tasks. However, these techniques still suffer from CF and/or limited KT. This paper proposes a new CL method to achieve both. It overcomes CF by isolating the knowledge of each task via discovering a sub-network for it. A soft-masking mechanism is also proposed to preserve the previous knowledge and to enable the new task to leverage the past knowledge to achieve KT. Experiments using classification, generation, information extraction, and their mixture (i.e., heterogeneous tasks) show that the proposed method consistently outperforms strong baselines.</abstract>
      <url hash="9c743bbd">2023.findings-emnlp.1008</url>
      <bibkey>ke-etal-2023-sub</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.1008</doi>
    </paper>
    <paper id="1009">
      <title><fixed-case>PIVOINE</fixed-case>: Instruction Tuning for Open-world Entity Profiling</title>
      <author><first>Keming</first><last>Lu</last></author>
      <author><first>Xiaoman</first><last>Pan</last></author>
      <author><first>Kaiqiang</first><last>Song</last></author>
      <author><first>Hongming</first><last>Zhang</last></author>
      <author><first>Dong</first><last>Yu</last></author>
      <author><first>Jianshu</first><last>Chen</last></author>
      <pages>15108-15127</pages>
      <abstract>This work considers the problem of Open-world Entity Profiling, a sub-domain of Open-world Information Extraction (Open-world IE). Unlike the conventional closed-world IE, Open-world IE is considered a more general situation where entities and relations could be beyond a predefined ontology. We seek to develop a large language model (LLM) that can perform Open-world Entity Profiling with instruction tuning to extract desirable entity profiles characterized by (possibly fine-grained) natural language instructions. In particular, we construct INSTRUCTOPENWIKI, a substantial instruction-tuning dataset for Open-world Entity Profiling enriched with a comprehensive corpus, extensive annotations, and diverse instructions. We finetune pretrained BLOOM models on INSTRUCTOPENWIKI and obtain PIVOINE, an LLM for Open-world Entity Profiling with strong instruction-following capabilities. Our experiments demonstrate that PIVOINE significantly outperforms traditional methods and ChatGPT-based baselines, displaying impressive generalization capabilities on both unseen instructions and out-of-ontology cases. Consequently, PIVOINE emerges as a promising solution to tackle the open-world challenge of entity profiling.</abstract>
      <url hash="45f5ecdb">2023.findings-emnlp.1009</url>
      <bibkey>lu-etal-2023-pivoine</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.1009</doi>
    </paper>
    <paper id="1010">
      <title><fixed-case>D</fixed-case>i<fixed-case>QAD</fixed-case>: A Benchmark Dataset for Open-domain Dialogue Quality Assessment</title>
      <author><first>Yukun</first><last>Zhao</last></author>
      <author><first>Lingyong</first><last>Yan</last></author>
      <author><first>Weiwei</first><last>Sun</last></author>
      <author><first>Chong</first><last>Meng</last></author>
      <author><first>Shuaiqiang</first><last>Wang</last></author>
      <author><first>Zhicong</first><last>Cheng</last></author>
      <author><first>Zhaochun</first><last>Ren</last></author>
      <author><first>Dawei</first><last>Yin</last></author>
      <pages>15128-15145</pages>
      <abstract>Dialogue assessment plays a critical role in the development of open-domain dialogue systems. Existing work are uncapable of providing an end-to-end and human-epistemic assessment dataset, while they only provide sub-metrics like coherence or the dialogues are conversed between annotators far from real user settings. In this paper, we release a large-scale dialogue quality assessment dataset (DiQAD), for automatically assessing open-domain dialogue quality. Specifically, we (1) establish the assessment criteria based on the dimensions conforming to human judgements on dialogue qualities, and (2) annotate large-scale dialogues that conversed between real users based on these annotation criteria, which contains around 100,000 dialogues. We conduct several experiments and report the performances of the baselines as the benchmark on DiQAD. The dataset is openly accessible at <url>https://github.com/yukunZhao/Dataset_Dialogue_quality_evaluation</url>.</abstract>
      <url hash="34ddc7e6">2023.findings-emnlp.1010</url>
      <bibkey>zhao-etal-2023-diqad</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.1010</doi>
    </paper>
    <paper id="1011">
      <title>Tuna: Instruction Tuning using Feedback from Large Language Models</title>
      <author><first>Haoran</first><last>Li</last></author>
      <author><first>Yiran</first><last>Liu</last></author>
      <author><first>Xingxing</first><last>Zhang</last></author>
      <author><first>Wei</first><last>Lu</last></author>
      <author><first>Furu</first><last>Wei</last></author>
      <pages>15146-15163</pages>
      <abstract>Instruction tuning of open-source large language models (LLMs) like LLaMA, using direct outputs from more powerful LLMs such as Instruct-GPT and GPT-4, has proven to be a cost-effective way to align model behaviors with human preferences. However, the instruction-tuned model has only seen one response per instruction, lacking the knowledge of potentially better responses. In this paper, we propose finetuning an instruction-tuned LLM using our novel probabilistic ranking and contextual ranking approaches to increase the likelihood of generating better responses. Probabilistic ranking enables the instruction-tuned model to inherit the relative rankings of high-quality and low-quality responses from the teacher LLM. On the other hand, learning with contextual ranking allows the model to refine its own response distribution using the contextual understanding ability of stronger LLMs. Furthermore, we apply probabilistic ranking and contextual ranking sequentially to the instruction-tuned LLM. The resulting model, which we call Tuna, consistently improves the performance on Super Natural Instructions (119 test tasks), LMentry (25 test tasks), Vicuna QA, and can even obtain better results than several strong reinforcement learning baselines. Our code and data are available at https://github.com/microsoft/LMOps.</abstract>
      <url hash="006f6442">2023.findings-emnlp.1011</url>
      <bibkey>li-etal-2023-tuna</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.1011</doi>
    </paper>
    <paper id="1012">
      <title>Emptying the Ocean with a Spoon: Should We Edit Models?</title>
      <author><first>Yuval</first><last>Pinter</last></author>
      <author><first>Michael</first><last>Elhadad</last></author>
      <pages>15164-15172</pages>
      <abstract>We call into question the recently popularized method of direct model editing as a means of correcting factual errors in LLM generations. We contrast model editing with three similar but distinct approaches that pursue better defined objectives: (1) retrieval-based architectures, which decouple factual memory from inference and linguistic capabilities embodied in LLMs; (2) concept erasure methods, which aim at preventing systemic bias in generated text; and (3) attribution methods, which aim at grounding generations into identified textual sources. We argue that direct model editing cannot be trusted as a systematic remedy for the disadvantages inherent to LLMs, and while it has proven potential in improving model explainability, it opens risks by reinforcing the notion that models can be trusted for factuality. We call for cautious promotion and application of model editing as part of the LLM deployment process, and for responsibly limiting the use cases of LLMs to those not relying on editing as a critical component.</abstract>
      <url hash="10937ad7">2023.findings-emnlp.1012</url>
      <bibkey>pinter-elhadad-2023-emptying</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.1012</doi>
    </paper>
    <paper id="1013">
      <title>A Causal View of Entity Bias in (Large) Language Models</title>
      <author><first>Fei</first><last>Wang</last></author>
      <author><first>Wenjie</first><last>Mo</last></author>
      <author><first>Yiwei</first><last>Wang</last></author>
      <author><first>Wenxuan</first><last>Zhou</last></author>
      <author><first>Muhao</first><last>Chen</last></author>
      <pages>15173-15184</pages>
      <abstract>Entity bias widely affects pretrained (large) language models, causing them to rely on (biased) parametric knowledge to make unfaithful predictions. Although causality-inspired methods have shown great potential to mitigate entity bias, it is hard to precisely estimate the parameters of underlying causal models in practice. The rise of black-box LLMs also makes the situation even worse, because of their inaccessible parameters and uncalibrated logits. To address these problems, we propose a specific structured causal model (SCM) whose parameters are comparatively easier to estimate. Building upon this SCM, we propose causal intervention techniques to mitigate entity bias for both white-box and black-box settings. The proposed causal intervention perturbs the original entity with neighboring entities. This intervention reduces specific biasing information pertaining to the original entity while still preserving sufficient semantic information from similar entities. Under the white-box setting, our training-time intervention improves OOD performance of PLMs on relation extraction (RE) and machine reading comprehension (MRC) by 5.7 points and by 9.1 points, respectively. Under the black-box setting, our in-context intervention effectively reduces the entity-based knowledge conflicts of GPT-3.5, achieving up to 20.5 points of improvement of exact match accuracy on MRC and up to 17.6 points of reduction in memorization ratio on RE.</abstract>
      <url hash="3583e7cd">2023.findings-emnlp.1013</url>
      <bibkey>wang-etal-2023-causal</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.1013</doi>
    </paper>
    <paper id="1014">
      <title><fixed-case>T</fixed-case>5<fixed-case>S</fixed-case>core: Discriminative Fine-tuning of Generative Evaluation Metrics</title>
      <author><first>Yiwei</first><last>Qin</last></author>
      <author><first>Weizhe</first><last>Yuan</last></author>
      <author><first>Graham</first><last>Neubig</last></author>
      <author><first>Pengfei</first><last>Liu</last></author>
      <pages>15185-15202</pages>
      <abstract>Modern embedding-based metrics for evaluation of generated text generally fall into one of two paradigms: discriminative metrics that are trained to directly predict which outputs are of higher quality according to supervised human annotations, and generative metrics that are trained to evaluate text based on the probabilities of a generative model. Both have their advantages; discriminative metrics are able to directly optimize for the problem of distinguishing between good and bad outputs, while generative metrics can be trained using abundant raw text. In this paper, we present a framework that combines the best of both worlds, using both supervised and unsupervised signals from whatever data we have available. We operationalize this idea by training T5Score, a metric that uses these training signals with mT5 as backbone. We perform an extensive empirical comparison with other existing metrics on 5 datasets, 19 languages and 280 systems, demonstrating the utility of our method. Experimental results show that: T5Score achieves the best performance on all datasets against existing top-scoring metrics at the segment level.</abstract>
      <url hash="93b9c58e">2023.findings-emnlp.1014</url>
      <bibkey>qin-etal-2023-t5score</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.1014</doi>
    </paper>
    <paper id="1015">
      <title><fixed-case>T</fixed-case>-Projection: High Quality Annotation Projection for Sequence Labeling Tasks</title>
      <author><first>Iker</first><last>García-Ferrero</last></author>
      <author><first>Rodrigo</first><last>Agerri</last></author>
      <author><first>German</first><last>Rigau</last></author>
      <pages>15203-15217</pages>
      <abstract>In the absence of readily available labeled data for a given sequence labeling task and language, annotation projection has been proposed as one of the possible strategies to automatically generate annotated data. Annotation projection has often been formulated as the task of transporting, on parallel corpora, the labels pertaining to a given span in the source language into its corresponding span in the target language. In this paper we present T-Projection, a novel approach for annotation projection that leverages large pretrained text2text language models and state-of-the-art machine translation technology. T-Projection decomposes the label projection task into two subtasks: (i) A candidate generation step, in which a set of projection candidates using a multilingual T5 model is generated and, (ii) a candidate selection step, in which the generated candidates are ranked based on translation probabilities. We conducted experiments on intrinsic and extrinsic tasks in 5 Indo-European and 8 low-resource African languages. We demostrate that T-projection outperforms previous annotation projection methods by a wide margin. We believe that T-Projection can help to automatically alleviate the lack of high-quality training data for sequence labeling tasks. Code and data are publicly available.</abstract>
      <url hash="515888d2">2023.findings-emnlp.1015</url>
      <bibkey>garcia-ferrero-etal-2023-projection</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.1015</doi>
    </paper>
    <paper id="1016">
      <title><fixed-case>MTGER</fixed-case>: Multi-view Temporal Graph Enhanced Temporal Reasoning over Time-Involved Document</title>
      <author><first>Zheng</first><last>Chu</last></author>
      <author><first>Zekun</first><last>Wang</last></author>
      <author><first>Jiafeng</first><last>Liang</last></author>
      <author><first>Ming</first><last>Liu</last></author>
      <author><first>Bing</first><last>Qin</last></author>
      <pages>15218-15233</pages>
      <abstract>The facts and time in the document are intricately intertwined, making temporal reasoning over documents challenging. Previous work models time implicitly, making it difficult to handle such complex relationships. To address this issue, we propose MTGER, a novel Multi-view Temporal Graph Enhanced Reasoning framework for temporal reasoning over time-involved documents. Concretely, MTGER explicitly models the temporal relationships among facts by multi-view temporal graphs. On the one hand, the heterogeneous temporal graphs explicitly model the temporal and discourse relationships among facts; on the other hand, the multi-view mechanism captures both time-focused and fact-focused information, allowing the two views to complement each other through adaptive fusion. To further improve the implicit reasoning capability of the model, we design a self-supervised time-comparing objective. Extensive experimental results demonstrate the effectiveness of our method on the TimeQA and SituatedQA datasets. Furthermore, MTGER gives more consistent answers under question perturbations.</abstract>
      <url hash="914a602c">2023.findings-emnlp.1016</url>
      <bibkey>chu-etal-2023-mtger</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.1016</doi>
    </paper>
    <paper id="1017">
      <title><fixed-case>MSCFFN</fixed-case>: A New <fixed-case>FFN</fixed-case> with Multi-Space Cross to Accelerate Transformer</title>
      <author><first>Tang</first><last>Dongge</last></author>
      <author><first>Qing</first><last>Yang</last></author>
      <pages>15234-15239</pages>
      <abstract>Transformer models have achieved impressive success in various natural language processing tasks. But it is also limited used in some areas and the heavy computation complexity is one of the main limitations. Many model structures have been proposed to reduce the computation complexity and some are really effective. The previous research can be divided into two categories. One is to use more effective training and inference strategies and the other is focused on how to replace the standard self-attention mechanism with linear attention method. Differently, we revisit the design in Transformer and find that the feed forward network (FFN) is also computationally expensive, especially when the hidden dimension is large. In this paper, we propose a new FFN structure, named MSCFFN, which splits the large matrix space to several small space to reduce the computation complexity and uses the Multi-Space Cross method to ensure the accurate result. To the best of our knowledge, this is the first time to redesign FFN to accelerate Transformers. We experimentally validate the effectiveness of the proposed method on the Long-Range Arena benchmark. And the results show MSCFFN can achieve a faster speed with a similar or even better accuracy.</abstract>
      <url hash="70524514">2023.findings-emnlp.1017</url>
      <bibkey>dongge-yang-2023-mscffn</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.1017</doi>
    </paper>
    <paper id="1018">
      <title>Dialect Transfer for <fixed-case>S</fixed-case>wiss <fixed-case>G</fixed-case>erman Speech Translation</title>
      <author><first>Claudio</first><last>Paonessa</last></author>
      <author><first>Yanick</first><last>Schraner</last></author>
      <author><first>Jan</first><last>Deriu</last></author>
      <author><first>Manuela</first><last>Hürlimann</last></author>
      <author><first>Manfred</first><last>Vogel</last></author>
      <author><first>Mark</first><last>Cieliebak</last></author>
      <pages>15240-15254</pages>
      <abstract>This paper investigates the challenges in building Swiss German speech translation systems, specifically focusing on the impact of dialect diversity and differences between Swiss German and Standard German. Swiss German is a spoken language with no formal writing system, it comprises many diverse dialects and is a low-resource language with only around 5 million speakers. The study is guided by two key research questions: how does the inclusion and exclusion of dialects during the training of speech translation models for Swiss German impact the performance on specific dialects, and how do the differences between Swiss German and Standard German impact the performance of the systems? We show that dialect diversity and linguistic differences pose significant challenges to Swiss German speech translation, which is in line with linguistic hypotheses derived from empirical investigations.</abstract>
      <url hash="97c394d9">2023.findings-emnlp.1018</url>
      <bibkey>paonessa-etal-2023-dialect</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.1018</doi>
    </paper>
    <paper id="1019">
      <title>Masked Path Modeling for Vision-and-Language Navigation</title>
      <author><first>Zi-Yi</first><last>Dou</last></author>
      <author><first>Feng</first><last>Gao</last></author>
      <author><first>Nanyun</first><last>Peng</last></author>
      <pages>15255-15269</pages>
      <abstract>Vision-and-language navigation (VLN) agents are trained to navigate in real-world environments based on natural language instructions. A major challenge in VLN is the limited available training data, which hinders the models’ ability to generalize effectively. Previous approaches have attempted to alleviate this issue by using external tools to generate pseudo-labeled data or integrating web-scaled image-text pairs during training. However, these methods often rely on automatically-generated or out-of-domain data, leading to challenges such as suboptimal data quality and domain mismatch. In this paper, we introduce a masked path modeling (MPM) objective. MPM pretrains an agent using self-collected data for subsequent navigation tasks, eliminating the need for external tools. Specifically, our method allows the agent to explore navigation environments and record the paths it traverses alongside the corresponding agent actions. Subsequently, we train the agent on this collected data to reconstruct the original action sequence when given a randomly masked subsequence of the original path. This approach enables the agent to accumulate a diverse and substantial dataset, facilitating the connection between visual observations of paths and the agent’s actions, which is the foundation of the VLN task. Importantly, the collected data are in-domain, and the training process avoids synthetic data with uncertain quality, addressing previous issues. We conduct experiments on various VLN datasets and demonstrate the applications of MPM across different levels of instruction complexity. Our results exhibit significant improvements in success rates, with enhancements of 1.3%, 1.1%, and 1.2% on the val-unseen split of the Room-to-Room, Room-for-Room, and Room-across-Room datasets, respectively. Additionally, we underscore the adaptability of MPM as well as the potential for additional improvements when the agent is allowed to explore unseen environments prior to testing.</abstract>
      <url hash="3e2891d4">2023.findings-emnlp.1019</url>
      <bibkey>dou-etal-2023-masked</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.1019</doi>
    </paper>
    <paper id="1020">
      <title>Learning Interpretable Style Embeddings via Prompting <fixed-case>LLM</fixed-case>s</title>
      <author><first>Ajay</first><last>Patel</last></author>
      <author><first>Delip</first><last>Rao</last></author>
      <author><first>Ansh</first><last>Kothary</last></author>
      <author><first>Kathleen</first><last>McKeown</last></author>
      <author><first>Chris</first><last>Callison-Burch</last></author>
      <pages>15270-15290</pages>
      <abstract>Style representation learning builds content-independent representations of author style in text. To date, no large dataset of texts with stylometric annotations on a wide range of style dimensions has been compiled, perhaps because the linguistic expertise to perform such annotation would be prohibitively expensive. Therefore, current style representation approaches make use of unsupervised neural methods to disentangle style from content to create style vectors. These approaches, however, result in uninterpretable representations, complicating their usage in downstream applications like authorship attribution where auditing and explainability is critical. In this work, we use prompting to perform stylometry on a large number of texts to generate a synthetic stylometry dataset. We use this synthetic data to then train human-interpretable style representations we call LISA embeddings. We release our synthetic dataset (StyleGenome) and our interpretable style embedding model (LISA) as resources.</abstract>
      <url hash="a361eb56">2023.findings-emnlp.1020</url>
      <bibkey>patel-etal-2023-learning</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.1020</doi>
    </paper>
    <paper id="1021">
      <title>Exploring Context-Aware Evaluation Metrics for Machine Translation</title>
      <author><first>Xinyu</first><last>Hu</last></author>
      <author><first>Xunjian</first><last>Yin</last></author>
      <author><first>Xiaojun</first><last>Wan</last></author>
      <pages>15291-15298</pages>
      <abstract>Previous studies on machine translation evaluation mostly focused on the quality of individual sentences, while overlooking the important role of contextual information. Although WMT Metrics Shared Tasks have introduced context content into the human annotations of translation evaluation since 2019, the relevant metrics and methods still did not take advantage of the corresponding context. In this paper, we propose a context-aware machine translation evaluation metric called Cont-COMET, built upon the effective COMET framework. Our approach simultaneously considers the preceding and subsequent contexts of the sentence to be evaluated and trains our metric to be aligned with the setting during human annotation. We also introduce a content selection method to extract and utilize the most relevant information. The experiments and evaluation of Cont-COMET on the official test framework from WMT show improvements in both system-level and segment-level assessments.</abstract>
      <url hash="f7d5e71d">2023.findings-emnlp.1021</url>
      <bibkey>hu-etal-2023-exploring</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.1021</doi>
    </paper>
    <paper id="1022">
      <title><fixed-case>GRACE</fixed-case>: Discriminator-Guided Chain-of-Thought Reasoning</title>
      <author><first>Muhammad</first><last>Khalifa</last></author>
      <author><first>Lajanugen</first><last>Logeswaran</last></author>
      <author><first>Moontae</first><last>Lee</last></author>
      <author><first>Honglak</first><last>Lee</last></author>
      <author><first>Lu</first><last>Wang</last></author>
      <pages>15299-15328</pages>
      <abstract>In the context of multi-step reasoning, e.g., with chain-of-thought, language models (LMs) can easily assign a high likelihood to incorrect steps. As a result, decoding strategies that optimize for solution likelihood often yield incorrect solutions. To address this issue, we propose Guiding chain-of-thought ReAsoning with a CorrectnEss Discriminator (GRACE), a stepwise decoding approach that steers the decoding process towards producing correct reasoning steps. GRACE employs a discriminator trained with a contrastive loss over correct and incorrect steps, which is used during decoding to score next-step candidates based on their correctness. Importantly, GRACE only requires sampling from the LM, without the need for LM training or fine-tuning. Using models from FLAN-T5 and LLaMA families, we evaluate GRACE over four math and two symbolic reasoning tasks, where it exhibits substantial performance gains compared to greedy decoding, verifiers, and self-consistency in most settings. When further combined with self-consistency, GRACE outperforms all the baselines by sizeable margins. Human and LLM evaluations over GSM8K show that GRACE not only improves the final answer accuracy but also the correctness of the intermediate reasoning.</abstract>
      <url hash="423b9728">2023.findings-emnlp.1022</url>
      <bibkey>khalifa-etal-2023-grace</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.1022</doi>
    </paper>
    <paper id="1023">
      <title><fixed-case>QADYNAMICS</fixed-case>: Training Dynamics-Driven Synthetic <fixed-case>QA</fixed-case> Diagnostic for Zero-Shot Commonsense Question Answering</title>
      <author><first>Haochen</first><last>Shi</last></author>
      <author><first>Weiqi</first><last>Wang</last></author>
      <author><first>Tianqing</first><last>Fang</last></author>
      <author><first>Baixuan</first><last>Xu</last></author>
      <author><first>Wenxuan</first><last>Ding</last></author>
      <author><first>Xin</first><last>Liu</last></author>
      <author><first>Yangqiu</first><last>Song</last></author>
      <pages>15329-15341</pages>
      <abstract>Zero-shot commonsense Question-Answering (QA) requires models to reason about general situations beyond specific benchmarks. State-of-the-art approaches fine-tune language models on QA pairs constructed from CommonSense Knowledge Bases (CSKBs) to equip the models with more commonsense knowledge in a QA context. However, current QA synthesis protocols may introduce noise from the CSKBs and generate ungrammatical questions and false negative options, which impede the model’s ability to generalize. To address these issues, we propose QADYNAMICS, a training dynamics-driven framework for QA diagnostics and refinement. Our approach analyzes the training dynamics of each QA pair at both the question level and option level, discarding machine-detectable artifacts by removing uninformative QA pairs and mislabeled or false-negative options. Extensive experiments demonstrate the effectiveness of our approach, which outperforms all baselines while using only 33% of the synthetic data, even including LLMs such as ChatGPT. Moreover, expert evaluations confirm that our framework significantly improves the quality of QA synthesis. Our code and model checkpoints are available at https://github.com/HKUST-KnowComp/QaDynamics.</abstract>
      <url hash="590d34f3">2023.findings-emnlp.1023</url>
      <bibkey>shi-etal-2023-qadynamics</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.1023</doi>
    </paper>
    <paper id="1024">
      <title><fixed-case>R</fixed-case>ex<fixed-case>UIE</fixed-case>: A Recursive Method with Explicit Schema Instructor for Universal Information Extraction</title>
      <author><first>Chengyuan</first><last>Liu</last></author>
      <author><first>Fubang</first><last>Zhao</last></author>
      <author><first>Yangyang</first><last>Kang</last></author>
      <author><first>Jingyuan</first><last>Zhang</last></author>
      <author><first>Xiang</first><last>Zhou</last></author>
      <author><first>Changlong</first><last>Sun</last></author>
      <author><first>Kun</first><last>Kuang</last></author>
      <author><first>Fei</first><last>Wu</last></author>
      <pages>15342-15359</pages>
      <abstract>Universal Information Extraction (UIE) is an area of interest due to the challenges posed by varying targets, heterogeneous structures, and demand-specific schemas. Previous works have achieved success by unifying a few tasks, such as Named Entity Recognition (NER) and Relation Extraction (RE), while they fall short of being true UIE models particularly when extracting other general schemas such as quadruples and quintuples. Additionally, these models used an implicit structural schema instructor, which could lead to incorrect links between types, hindering the model’s generalization and performance in low-resource scenarios. In this paper, we redefine the true UIE with a formal formulation that covers almost all extraction schemas. To the best of our knowledge, we are the first to introduce UIE for any kind of schemas. In addition, we propose RexUIE, which is a Recursive Method with Explicit Schema Instructor for UIE. To avoid interference between different types, we reset the position ids and attention mask matrices. RexUIE shows strong performance under both full-shot and few-shot settings and achieves state-of-the-art results on the tasks of extracting complex schemas.</abstract>
      <url hash="3087f0c1">2023.findings-emnlp.1024</url>
      <bibkey>liu-etal-2023-rexuie</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.1024</doi>
    </paper>
    <paper id="1025">
      <title><fixed-case>P</fixed-case>rompt<fixed-case>ARA</fixed-case>: Improving Deep Representation in Hybrid Automatic Readability Assessment with Prompt and Orthogonal Projection</title>
      <author><first>Jinshan</first><last>Zeng</last></author>
      <author><first>Xianglong</first><last>Yu</last></author>
      <author><first>Xianchao</first><last>Tong</last></author>
      <author><first>Wenyan</first><last>Xiao</last></author>
      <pages>15360-15371</pages>
      <abstract>Readability assessment aims to automatically classify texts based on readers’ reading levels. The hybrid automatic readability assessment (ARA) models using both deep and linguistic features have attracted rising attention in recent years due to their impressive performance. However, deep features are not fully explored due to the scarcity of training data, and the fusion of deep and linguistic features is not very effective in existing hybrid ARA models. In this paper, we propose a novel hybrid ARA model called PromptARA through employing prompts to improve deep feature representations and an orthogonal projection layer to fuse both deep and linguistic features. A series of experiments are conducted over four English and two Chinese corpora to show the effectiveness of the proposed model. Experimental results demonstrate that the proposed model is superior to state-of-the-art models.</abstract>
      <url hash="8ae92d15">2023.findings-emnlp.1025</url>
      <bibkey>zeng-etal-2023-promptara</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.1025</doi>
    </paper>
    <paper id="1026">
      <title>Does Listener Gaze in Face-to-Face Interaction Follow the Entropy Rate Constancy Principle: An Empirical Study</title>
      <author><first>Yu</first><last>Wang</last></author>
      <author><first>Hendrik</first><last>Buschmeier</last></author>
      <pages>15372-15379</pages>
      <abstract>It is generally assumed that language (written and spoken) follows the entropy rate constancy (ERC) principle, which states that the information density of a text is constant over time. Recently, this has also been found for nonverbal gestures used in monologue, but it is still unclear whether the ERC principle also applies to listeners’ nonverbal signals. We focus on listeners’ gaze behaviour extracted from video-recorded conversations and trained a transformer-based neural sequence model to process the gaze data of the dialogues and compute its information density. We also compute the information density of the corresponding speech using a pre-trained language model. Our results show (1) that listeners’ gaze behaviour in dialogues roughly follows the ERC principle, as well as (2) a congruence between information density of speech and listeners’ gaze behaviour.</abstract>
      <url hash="82f4089c">2023.findings-emnlp.1026</url>
      <bibkey>wang-buschmeier-2023-listener</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.1026</doi>
    </paper>
    <paper id="1027">
      <title>Incorporating Object-Level Visual Context for Multimodal Fine-Grained Entity Typing</title>
      <author><first>Ying</first><last>Zhang</last></author>
      <author><first>Wenbo</first><last>Fan</last></author>
      <author><first>Kehui</first><last>Song</last></author>
      <author><first>Yu</first><last>Zhao</last></author>
      <author><first>Xuhui</first><last>Sui</last></author>
      <author><first>Xiaojie</first><last>Yuan</last></author>
      <pages>15380-15390</pages>
      <abstract>Fine-grained entity typing (FGET) aims to assign appropriate fine-grained types to entity mentions within their context, which is an important foundational task in natural language processing. Previous approaches for FGET only utilized textual context information. However, in the form of short text, the contextual semantic information is often insufficient for FGET. In many real-world scenarios, text is often accompanied by images, and the visual context is valuable for FGET. To this end, we firstly propose a new task called multimodal fine-grained entity typing (MFGET). Then we construct a large-scale dataset for multimodal fine-grained entity typing called MFIGER based on FIGER. To fully leverage both textual and visual information, we propose a novel Multimodal Object-Level Visual Context Network (MOVCNet). MOVCNet can capture fine-grained semantic information by detecting objects in images, and effectively merge both textual and visual context. Experimental results demonstrate that our approach achieves superior classification performance compared to previous text-based approaches.</abstract>
      <url hash="6f9f2f24">2023.findings-emnlp.1027</url>
      <bibkey>zhang-etal-2023-incorporating-object</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.1027</doi>
    </paper>
    <paper id="1028">
      <title>Exploring the Numerical Reasoning Capabilities of Language Models: A Comprehensive Analysis on Tabular Data</title>
      <author><first>Mubashara</first><last>Akhtar</last></author>
      <author><first>Abhilash</first><last>Shankarampeta</last></author>
      <author><first>Vivek</first><last>Gupta</last></author>
      <author><first>Arpit</first><last>Patil</last></author>
      <author><first>Oana</first><last>Cocarascu</last></author>
      <author><first>Elena</first><last>Simperl</last></author>
      <pages>15391-15405</pages>
      <abstract>Numerical data plays a crucial role in various real-world domains like finance, economics, and science. Thus, understanding and reasoning with numbers are essential in these fields. Recent benchmarks have assessed the numerical reasoning abilities of language models, revealing their limitations in limited and specific numerical aspects. In this paper, we propose a complete hierarchical taxonomy for numerical reasoning skills, encompassing over ten reasoning types across four levels: representation, number sense, manipulation, and complex reasoning. We conduct a comprehensive evaluation of state-of-the-art models on all reasoning types. To identify challenging reasoning types for different model types, we develop a diverse and extensive set of numerical probes and measure performance shifts. By employing a semi-automated approach, we focus on the tabular Natural Language Inference (TNLI) task as a case study. While no single model excels in all reasoning types, FlanT5 (few-/zero-shot) and GPT3.5 (few-shot) demonstrate strong overall numerical reasoning skills compared to other models in our probes.</abstract>
      <url hash="d056d131">2023.findings-emnlp.1028</url>
      <bibkey>akhtar-etal-2023-exploring</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.1028</doi>
    </paper>
    <paper id="1029">
      <title>Assessing Privacy Risks in Language Models: A Case Study on Summarization Tasks</title>
      <author><first>Ruixiang</first><last>Tang</last></author>
      <author><first>Gord</first><last>Lueck</last></author>
      <author><first>Rodolfo</first><last>Quispe</last></author>
      <author><first>Huseyin</first><last>Inan</last></author>
      <author><first>Janardhan</first><last>Kulkarni</last></author>
      <author><first>Xia</first><last>Hu</last></author>
      <pages>15406-15418</pages>
      <abstract>Large language models have revolutionized the field of NLP by achieving state-of-the-art performance on various tasks. However, there is a concern that these models may disclose information in the training data. In this study, we focus on the summarization task and investigate the membership inference (MI) attack: given a sample and black-box access to a model’s API, it is possible to determine if the sample was part of the training data. We exploit text similarity and the model’s resistance to document modifications as potential MI signals and evaluate their effectiveness on widely used datasets. Our results demonstrate that summarization models are at risk of exposing data membership, even in cases where the reference summary is not available. Furthermore, we discuss several safeguards for training summarization models to protect against MI attacks and discuss the inherent trade-off between privacy and utility.</abstract>
      <url hash="2c6b66d6">2023.findings-emnlp.1029</url>
      <bibkey>tang-etal-2023-assessing</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.1029</doi>
    </paper>
    <paper id="1030">
      <title><fixed-case>BERT</fixed-case> Has More to Offer: <fixed-case>BERT</fixed-case> Layers Combination Yields Better Sentence Embeddings</title>
      <author><first>MohammadSaleh</first><last>Hosseini</last></author>
      <author><first>Munawara</first><last>Munia</last></author>
      <author><first>Latifur</first><last>Khan</last></author>
      <pages>15419-15431</pages>
      <abstract>Obtaining sentence representations from BERT-based models as feature extractors is invaluable as it takes much less time to pre-compute a one-time representation of the data and then use it for the downstream tasks, rather than fine-tune the whole BERT. Most previous works acquire a sentence’s representation by passing it to BERT and averaging its last layer. In this paper, we propose that the combination of certain layers of a BERT-based model rested on the data set and model can achieve substantially better results. We empirically show the effectiveness of our method for different BERT-based models on different tasks and data sets. Specifically, on seven standard semantic textual similarity data sets, we outperform the baseline BERT by improving the Spearman’s correlation by up to 25.75% and on average 16.32% without any further training. We also achieved state-of-the-art results on eight transfer data sets by reducing the relative error by up to 37.41% and on average 17.92%.</abstract>
      <url hash="21f07cdc">2023.findings-emnlp.1030</url>
      <bibkey>hosseini-etal-2023-bert</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.1030</doi>
    </paper>
    <paper id="1031">
      <title>Extrapolating Multilingual Understanding Models as Multilingual Generators</title>
      <author><first>Bohong</first><last>Wu</last></author>
      <author><first>Fei</first><last>Yuan</last></author>
      <author><first>Hai</first><last>Zhao</last></author>
      <author><first>Lei</first><last>Li</last></author>
      <author><first>Jingjing</first><last>Xu</last></author>
      <pages>15432-15444</pages>
      <abstract>Multilingual understanding models (or encoder-based), pre-trained via masked language modeling, have achieved promising results on many language understanding tasks (e.g., mBERT). However, these models are not capable of generating high-quality text compared with decoder-based causal language models. Can we transform a pre-trained language understanding model into an effective language generation model? We propose a Semantic-Guided Alignment-then-Denoising (SGA) approach to adapt a multilingual encoder to a multilingual generator with a small number of additional parameters. Experiments show that the proposed approach is an effective adaption method, outperforming widely-used initialization-based methods with gains of 9.4 BLEU on machine translation, 8.1 Rouge-L on question generation, and 5.5 METEOR on story generation on XLM-R<tex-math>_{large}</tex-math>. On the other hand, we observe that XLM-R is still inferior to mBART in supervised settings despite better results on zero-shot settings, indicating that more exploration is required to make understanding models strong generators. Our code is available at https://github.com/chengzhipanpan/XLMR4MT.</abstract>
      <url hash="fe400d51">2023.findings-emnlp.1031</url>
      <bibkey>wu-etal-2023-extrapolating</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.1031</doi>
    </paper>
    <paper id="1032">
      <title><fixed-case>SAC</fixed-case><tex-math>^3</tex-math>: Reliable Hallucination Detection in Black-Box Language Models via Semantic-aware Cross-check Consistency</title>
      <author><first>Jiaxin</first><last>Zhang</last></author>
      <author><first>Zhuohang</first><last>Li</last></author>
      <author><first>Kamalika</first><last>Das</last></author>
      <author><first>Bradley</first><last>Malin</last></author>
      <author><first>Sricharan</first><last>Kumar</last></author>
      <pages>15445-15458</pages>
      <abstract>Hallucination detection is a critical step toward understanding the trustworthiness of modern language models (LMs). To achieve this goal, we re-examine existing detection approaches based on the self-consistency of LMs and uncover two types of hallucinations resulting from 1) question-level and 2) model-level, which cannot be effectively identified through self-consistency check alone. Building upon this discovery, we propose a novel sampling-based method, i.e., semantic-aware cross-check consistency (SAC<tex-math>^3</tex-math>) that expands on the principle of self-consistency checking. Our SAC<tex-math>^3</tex-math> approach incorporates additional mechanisms to detect both question-level and model-level hallucinations by leveraging advances including semantically equivalent question perturbation and cross-model response consistency checking. Through extensive and systematic empirical analysis, we demonstrate that SAC<tex-math>^3</tex-math> outperforms the state of the art in detecting both non-factual and factual statements across multiple question-answering and open-domain generation benchmarks.</abstract>
      <url hash="dd934050">2023.findings-emnlp.1032</url>
      <bibkey>zhang-etal-2023-sac3</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.1032</doi>
    </paper>
    <paper id="1033">
      <title>Test-Time Self-Adaptive Small Language Models for Question Answering</title>
      <author><first>Soyeong</first><last>Jeong</last></author>
      <author><first>Jinheon</first><last>Baek</last></author>
      <author><first>Sukmin</first><last>Cho</last></author>
      <author><first>Sung</first><last>Hwang</last></author>
      <author><first>Jong</first><last>Park</last></author>
      <pages>15459-15469</pages>
      <abstract>Recent instruction-finetuned large language models (LMs) have achieved notable performances in various tasks, such as question-answering (QA). However, despite their ability to memorize a vast amount of general knowledge across diverse tasks, they might be suboptimal on specific tasks due to their limited capacity to transfer and adapt knowledge to target tasks. Moreover, further finetuning LMs with labeled datasets is often infeasible due to their absence, but it is also questionable if we can transfer smaller LMs having limited knowledge only with unlabeled test data. In this work, we show and investigate the capabilities of smaller self-adaptive LMs, only with unlabeled test data. In particular, we first stochastically generate multiple answers, and then ensemble them while filtering out low-quality samples to mitigate noise from inaccurate labels. Our proposed self-adaption strategy demonstrates significant performance improvements on benchmark QA datasets with higher robustness across diverse prompts, enabling LMs to stay stable. Code is available at: https://github.com/starsuzi/T-SAS.</abstract>
      <url hash="a7fe5cae">2023.findings-emnlp.1033</url>
      <bibkey>jeong-etal-2023-test</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.1033</doi>
    </paper>
    <paper id="1034">
      <title><fixed-case>E</fixed-case>xp<fixed-case>N</fixed-case>ote: Black-box Large Language Models are better Task Solvers with Experience Notebook</title>
      <author><first>Wangtao</first><last>Sun</last></author>
      <author><first>Xuanqing</first><last>Yu</last></author>
      <author><first>Shizhu</first><last>He</last></author>
      <author><first>Jun</first><last>Zhao</last></author>
      <author><first>Kang</first><last>Liu</last></author>
      <pages>15470-15481</pages>
      <abstract>Black-box Large Language Models (LLMs) have shown great power in solving various tasks and are considered general problem solvers. However, LLMs still fail in many specific tasks although understand the task instruction. In this paper, we focus on the problem of boosting the ability of black-box LLMs to solve downstream tasks. We propose ExpNote, an automated framework to help LLMs better adapt to unfamiliar tasks through reflecting and noting experiences from training data and retrieving them from external memory during testing. We evaluate ExpNote on multiple tasks and the experimental results demonstrate that the proposed method significantly improves the performance of black-box LLMs. The data and code are available at https://github.com/forangel2014/ExpNote.</abstract>
      <url hash="85831d5d">2023.findings-emnlp.1034</url>
      <bibkey>sun-etal-2023-expnote</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.1034</doi>
    </paper>
    <paper id="1035">
      <title>Evaluating Parameter-Efficient Finetuning Approaches for Pre-trained Models on the Financial Domain</title>
      <author><first>Isabella</first><last>Olariu</last></author>
      <author><first>Cedric</first><last>Lothritz</last></author>
      <author><first>Jacques</first><last>Klein</last></author>
      <author><first>Tegawendé</first><last>Bissyandé</last></author>
      <author><first>Siwen</first><last>Guo</last></author>
      <author><first>Shohreh</first><last>Haddadan</last></author>
      <pages>15482-15491</pages>
      <abstract>Large-scale language models with millions, billions, or trillions of trainable parameters are becoming increasingly popular. However, they risk becoming rapidly over-parameterized and the adaptation cost of fully fine-tuning them increases significantly. Storing them becomes progressively impractical as it requires keeping a separate copy of all the fine-tuned weights for each task. By freezing all pre-trained weights during fine-tuning, parameter-efficient tuning approaches have become an appealing alternative to traditional fine-tuning. The performance of these approaches has been evaluated on common NLP tasks of the GLUE benchmark and shown to match full fine-tuning performance, however, their impact is less researched in domain-specific fields such as finance. This work compares the performance of a set of financial BERT-like models to their fully fine-tuned counterparts by leveraging different parameter-efficient tuning methods. We see that results are comparable to traditional fine-tuning while gaining in time and resource efficiency.</abstract>
      <url hash="e48f4cd0">2023.findings-emnlp.1035</url>
      <bibkey>olariu-etal-2023-evaluating</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.1035</doi>
    </paper>
    <paper id="1036">
      <title>Can Retriever-Augmented Language Models Reason? The Blame Game Between the Retriever and the Language Model</title>
      <author><first>Parishad</first><last>BehnamGhader</last></author>
      <author><first>Santiago</first><last>Miret</last></author>
      <author><first>Siva</first><last>Reddy</last></author>
      <pages>15492-15509</pages>
      <abstract>Augmenting pretrained language models with retrievers has shown promise in effectively solving common NLP problems, such as language modeling and question answering. In this paper, we evaluate the strengths and weaknesses of popular retriever-augmented language models, namely kNN-LM, REALM, DPR + FiD, Contriever + ATLAS, and Contriever + Flan-T5, in reasoning over retrieved statements across different tasks. Our findings indicate that the simple similarity metric employed by retrievers is insufficient for retrieving all the necessary statements for reasoning. Additionally, the language models do not exhibit strong reasoning even when provided with only the required statements. Furthermore, when combined with imperfect retrievers, the performance of the language models becomes even worse, e.g., Flan-T5’s performance drops by 28.6% when retrieving 5 statements using Contriever. While larger language models improve performance, there is still a substantial room for enhancement. Our further analysis indicates that multihop retrieve-and-read is promising for large language models like GPT-3.5, but does not generalize to other language models like Flan-T5-xxl. The code is available at https://github.com/McGill-NLP/retriever-lm-reasoning.</abstract>
      <url hash="e1ea2a88">2023.findings-emnlp.1036</url>
      <bibkey>behnamghader-etal-2023-retriever</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.1036</doi>
    </paper>
    <paper id="1037">
      <title><fixed-case>BERT</fixed-case>wich: Extending <fixed-case>BERT</fixed-case>’s Capabilities to Model Dialectal and Noisy Text</title>
      <author><first>Aarohi</first><last>Srivastava</last></author>
      <author><first>David</first><last>Chiang</last></author>
      <pages>15510-15521</pages>
      <abstract>Real-world NLP applications often deal with nonstandard text (e.g., dialectal, informal, or misspelled text). However, language models like BERT deteriorate in the face of dialect variation or noise. How do we push BERT’s modeling capabilities to encompass nonstandard text? Fine-tuning helps, but it is designed for specializing a model to a task and does not seem to bring about the deeper, more pervasive changes needed to adapt a model to nonstandard language. In this paper, we introduce the novel idea of sandwiching BERT’s encoder stack between additional encoder layers trained to perform masked language modeling on noisy text. We find that our approach, paired with recent work on including character-level noise in fine-tuning data, can promote zero-shot transfer to dialectal text, as well as reduce the distance in the embedding space between words and their noisy counterparts.</abstract>
      <url hash="55ed9234">2023.findings-emnlp.1037</url>
      <bibkey>srivastava-chiang-2023-bertwich</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.1037</doi>
    </paper>
    <paper id="1038">
      <title>Closed Boundary Learning for Classification Tasks with the Universum Class</title>
      <author><first>Hanzhang</first><last>Zhou</last></author>
      <author><first>Zijian</first><last>Feng</last></author>
      <author><first>Kezhi</first><last>Mao</last></author>
      <pages>15522-15536</pages>
      <abstract>The Universum class, often known as the *other* class or the*miscellaneous* class, is defined as a collection of samples that do not belong to any class of interest. It is a typical class that exists in many classification-based tasks in NLP, such as relation extraction, named entity recognition, sentiment analysis, etc. The Universum class exhibits very different properties, namely heterogeneity and lack of representativeness in training data; however, existing methods often treat the Universum class equally with the classes of interest, leading to problems such as overfitting, misclassification, and diminished model robustness. In this work, we propose a closed boundary learning method that applies closed decision boundaries to classes of interest and designates the area outside all closed boundaries in the feature space as the space of the Universum class. Specifically, we formulate closed boundaries as arbitrary shapes, propose the inter-class rule-based probability estimation for the Universum class to cater to its unique properties, and propose a boundary learning loss to adjust decision boundaries based on the balance of misclassified samples inside and outside the boundary. In adherence to the natural properties of the Universum class, our method enhances both accuracy and robustness of classification models, demonstrated by improvements on six state-of-the-art works across three different tasks. Our code is available at https://github.com/hzzhou01/Closed-Boundary-Learning.</abstract>
      <url hash="0b21b0c7">2023.findings-emnlp.1038</url>
      <bibkey>zhou-etal-2023-closed</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.1038</doi>
    </paper>
    <paper id="1039">
      <title>Revisiting Entropy Rate Constancy in Text</title>
      <author><first>Vivek</first><last>Verma</last></author>
      <author><first>Nicholas</first><last>Tomlin</last></author>
      <author><first>Dan</first><last>Klein</last></author>
      <pages>15537-15549</pages>
      <abstract>The uniform information density (UID) hypothesis states that humans tend to distribute information roughly evenly across an utterance or discourse. Early evidence in support of the UID hypothesis came from Genzel and Charniak (2002), which proposed an entropy rate constancy principle based on the probability of English text under <tex-math>n</tex-math>-gram language models. We re-evaluate the claims of Genzel and Charniak (2002) with neural language models, failing to find clear evidence in support of entropy rate constancy. We conduct a range of experiments across datasets, model sizes, and languages and discuss implications for the uniform information density hypothesis and linguistic theories of efficient communication more broadly.</abstract>
      <url hash="22883154">2023.findings-emnlp.1039</url>
      <bibkey>verma-etal-2023-revisiting</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.1039</doi>
    </paper>
    <paper id="1040">
      <title>Calibrated Seq2seq Models for Efficient and Generalizable Ultra-fine Entity Typing</title>
      <author><first>Yanlin</first><last>Feng</last></author>
      <author><first>Adithya</first><last>Pratapa</last></author>
      <author><first>David</first><last>Mortensen</last></author>
      <pages>15550-15560</pages>
      <abstract>Ultra-fine entity typing plays a crucial role in information extraction by predicting fine-grained semantic types for entity mentions in text. However, this task poses significant challenges due to the massive number of entity types in the output space. The current state-of-the-art approaches, based on standard multi-label classifiers or cross-encoder models, suffer from poor generalization performance or inefficient inference speed. In this paper, we present CASENT, a seq2seq model designed for ultra-fine entity typing that predicts ultra-fine types with calibrated confidence scores. Our model takes an entity mention as input and employs constrained beam search to generate multiple types autoregressively. The raw sequence probabilities associated with the predicted types are then transformed into confidence scores using a novel calibration method. We conduct extensive experiments on the UFET dataset which contains over <tex-math>10k</tex-math> types. Our method outperforms the previous state-of-the-art in terms of F1 score and calibration error, while achieving an inference speedup of over 50 times. Additionally, we demonstrate the generalization capabilities of our model by evaluating it in zero-shot and few-shot settings on five specialized domain entity typing datasets that are unseen during training. Remarkably, our model outperforms large language models with 10 times more parameters in the zero-shot setting, and when fine-tuned on 50 examples, it significantly outperforms ChatGPT on all datasets.</abstract>
      <url hash="97d0afe0">2023.findings-emnlp.1040</url>
      <bibkey>feng-etal-2023-calibrated</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.1040</doi>
    </paper>
    <paper id="1041">
      <title>Learning Semantic Role Labeling from Compatible Label Sequences</title>
      <author><first>Tao</first><last>Li</last></author>
      <author><first>Ghazaleh</first><last>Kazeminejad</last></author>
      <author><first>Susan</first><last>Brown</last></author>
      <author><first>Vivek</first><last>Srikumar</last></author>
      <author><first>Martha</first><last>Palmer</last></author>
      <pages>15561-15572</pages>
      <abstract>Semantic role labeling (SRL) has multiple disjoint label sets, e.g., VerbNet and PropBank. Creating these datasets is challenging, therefore a natural question is how to use each one to help the other. Prior work has shown that cross-task interaction helps, but only explored multitask learning so far. A common issue with multi-task setup is that argument sequences are still separately decoded, running the risk of generating structurally inconsistent label sequences (as per lexicons like Semlink). In this paper, we eliminate such issue with a framework that jointly models VerbNet and PropBank labels as one sequence. In this setup, we show that enforcing Semlink constraints during decoding constantly improves the overall F1. With special input constructions, our joint model infers VerbNet arguments from given PropBank arguments with over 99 F1. For learning, we propose a constrained marginal model that learns with knowledge defined in Semlink to further benefit from the large amounts of PropBank-only data. On the joint benchmark based on CoNLL05, our models achieve state-of-the-art F1’s, outperforming the prior best in-domain model by 3.5 (VerbNet) and 0.8 (PropBank). For out-of-domain generalization, our models surpass the prior best by 3.4 (VerbNet) and 0.2 (PropBank).</abstract>
      <url hash="829fb000">2023.findings-emnlp.1041</url>
      <bibkey>li-etal-2023-learning-semantic</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.1041</doi>
    </paper>
    <paper id="1042">
      <title><fixed-case>QUADR</fixed-case>o: Dataset and Models for <fixed-case>QU</fixed-case>estion-Answer Database Retrieval</title>
      <author><first>Stefano</first><last>Campese</last></author>
      <author><first>Ivano</first><last>Lauriola</last></author>
      <author><first>Alessandro</first><last>Moschitti</last></author>
      <pages>15573-15587</pages>
      <abstract>An effective approach to design automated Question Answering (QA) systems is to efficiently retrieve answers from pre-computed databases containing question/answer pairs. One of the main challenges to this design is the lack of training/testing data. Existing resources are limited in size and topics and either do not consider answers (question-question similarity only) or their quality in the annotation process. To fill this gap, we introduce a novel open-domain annotated resource to train and evaluate models for this task. The resource consists of 15,211 input questions. Each question is paired with 30 similar question/answer pairs, resulting in a total of 443,000 annotated examples. The binary label associated with each pair indicates the relevance with respect to the input question. Furthermore, we report extensive experimentation to test the quality and properties of our resource with respect to various key aspects of QA systems, including answer relevance, training strategies, and models input configuration.</abstract>
      <url hash="90ea3a53">2023.findings-emnlp.1042</url>
      <bibkey>campese-etal-2023-quadro</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.1042</doi>
    </paper>
    <paper id="1043">
      <title>Give Me the Facts! A Survey on Factual Knowledge Probing in Pre-trained Language Models</title>
      <author><first>Paul</first><last>Youssef</last></author>
      <author><first>Osman</first><last>Koraş</last></author>
      <author><first>Meijie</first><last>Li</last></author>
      <author><first>Jörg</first><last>Schlötterer</last></author>
      <author><first>Christin</first><last>Seifert</last></author>
      <pages>15588-15605</pages>
      <abstract>Pre-trained Language Models (PLMs) are trained on vast unlabeled data, rich in world knowledge. This fact has sparked the interest of the community in quantifying the amount of factual knowledge present in PLMs, as this explains their performance on downstream tasks, and potentially justifies their use as knowledge bases. In this work, we survey methods and datasets that are used to probe PLMs for factual knowledge. Our contributions are: (1) We propose a categorization scheme for factual probing methods that is based on how their inputs, outputs and the probed PLMs are adapted; (2) We provide an overview of the datasets used for factual probing; (3) We synthesize insights about knowledge retention and prompt optimization in PLMs, analyze obstacles to adopting PLMs as knowledge bases and outline directions for future work.</abstract>
      <url hash="9af3c88a">2023.findings-emnlp.1043</url>
      <bibkey>youssef-etal-2023-give</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.1043</doi>
    </paper>
    <paper id="1044">
      <title>Is <fixed-case>C</fixed-case>hat<fixed-case>GPT</fixed-case> the ultimate Data Augmentation Algorithm?</title>
      <author><first>Frédéric</first><last>Piedboeuf</last></author>
      <author><first>Philippe</first><last>Langlais</last></author>
      <pages>15606-15615</pages>
      <abstract>In the aftermath of GPT-3.5, commonly known as ChatGPT, research have attempted to assess its capacity for lowering annotation cost, either by doing zero-shot learning, generating new data, or replacing human annotators. Some studies have also investigated its use for data augmentation (DA), but only in limited contexts, which still leaves the question of how ChatGPT performs compared to state-of-the-art algorithms. In this paper, we use ChatGPT to create new data both with paraphrasing and with zero-shot generation, and compare it to seven other algorithms. We show that while ChatGPT performs exceptionally well on some simpler data, it overall does not perform better than the other algorithms, yet demands a much larger implication from the practitioner due to the ChatGPT often refusing to answer due to sensitive content in the datasets.</abstract>
      <url hash="d3015450">2023.findings-emnlp.1044</url>
      <bibkey>piedboeuf-langlais-2023-chatgpt</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.1044</doi>
    </paper>
    <paper id="1045">
      <title>Enhanced Simultaneous Machine Translation with Word-level Policies</title>
      <author><first>Kang</first><last>Kim</last></author>
      <author><first>Hankyu</first><last>Cho</last></author>
      <pages>15616-15634</pages>
      <abstract>Recent years have seen remarkable advances in the field of Simultaneous Machine Translation (SiMT) due to the introduction of innovative policies that dictate whether to READ or WRITE at each step of the translation process. However, a common assumption in many existing studies is that operations are carried out at the subword level, even though the standard unit for input and output in most practical scenarios is typically at the word level. This paper demonstrates that policies devised and validated at the subword level are surpassed by those operating at the word level, which process multiple subwords to form a complete word in a single step. Additionally, we suggest a method to boost SiMT models using language models (LMs), wherein the proposed word-level policy plays a vital role in addressing the subword disparity between LMs and SiMT models. Code is available at https://github.com/xl8-ai/WordSiMT.</abstract>
      <url hash="bfa1b5fc">2023.findings-emnlp.1045</url>
      <bibkey>kim-cho-2023-enhanced</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.1045</doi>
    </paper>
    <paper id="1046">
      <title>Causal Intervention-based Few-Shot Named Entity Recognition</title>
      <author><first>Zhen</first><last>Yang</last></author>
      <author><first>Yongbin</first><last>Liu</last></author>
      <author><first>Chunping</first><last>Ouyang</last></author>
      <pages>15635-15646</pages>
      <abstract>Few-shot named entity recognition (NER) systems aim to recognize new classes of entities with limited labeled samples. However, these systems face a significant challenge of overfitting compared to tasks with abundant samples. This overfitting is mainly caused by the spurious correlation resulting from the bias in selecting a few samples. To address this issue, we propose a causal intervention-based few-shot NER method in this paper. Our method, based on the prototypical network, intervenes in the context to block the backdoor path between context and label. In the one-shot scenario, where no additional context is available for intervention, we employ incremental learning to intervene on the prototype, which also helps mitigate catastrophic forgetting. Our experiments on various benchmarks demonstrate that our approach achieves new state-of-the-art results.</abstract>
      <url hash="b03e135c">2023.findings-emnlp.1046</url>
      <bibkey>yang-etal-2023-causal</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.1046</doi>
    </paper>
    <paper id="1047">
      <title><fixed-case>TADI</fixed-case>: Topic-aware Attention and Powerful Dual-encoder Interaction for Recall in News Recommendation</title>
      <author><first>Junxiang</first><last>Jiang</last></author>
      <pages>15647-15658</pages>
      <abstract>News recommendation is one of the widest commercialization in natural language processing research area, which aims to recommend news according to user interests. New recall plays an important role in news recommendation. It is to recall candidates from a very large news database. Recent researches of news recall mostly adopt dual-encoder architecture as it provides a much faster recall scheme, and they encode each word equally. However, these works remain two challenges: irrelevant word distraction and weak dual-encoder interaction. Therefore, we propose a model Topic-aware Attention and powerful Dual-encoder Interaction for Recall in news recommendation (TADI). To avoid irrelevant word distraction, TADI designs a Topic-aware Attention (TA) which weights words according to news topics. To enhance dual-encoder interaction, TADI provides a cheap yet powerful interaction module, namely Dual-encoder Interaction (DI). DI helps dual encoders interact powerfully based on two aux targets. After performance comparisons between TADI and state-of-the-arts in a series of experiments, we verify the effectiveness of TADI.</abstract>
      <url hash="def6be9b">2023.findings-emnlp.1047</url>
      <bibkey>jiang-2023-tadi</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.1047</doi>
    </paper>
    <paper id="1048">
      <title>Unveiling the Power of Argument Arrangement in Online Persuasive Discussions</title>
      <author><first>Nailia</first><last>Mirzakhmedova</last></author>
      <author><first>Johannes</first><last>Kiesel</last></author>
      <author><first>Khalid</first><last>Al-Khatib</last></author>
      <author><first>Benno</first><last>Stein</last></author>
      <pages>15659-15671</pages>
      <abstract>Previous research on argumentation in online discussions has largely focused on examining individual comments and neglected the interactive nature of discussions. In line with previous work, we represent individual comments as sequences of semantic argumentative unit types. However, because it is intuitively necessary for dialogical argumentation to address the opposing viewpoints, we extend this model by clustering type sequences into different argument arrangement patterns and representing discussions as sequences of these patterns. These sequences of patterns are a symbolic representation of argumentation strategies that capture the overall structure of discussions. Using this novel approach, we conduct an in-depth analysis of the strategies in 34,393 discussions from the online discussion forum Change My View and show that our discussion model is effective for persuasiveness prediction, outperforming LLM-based classifiers on the same data. Our results provide valuable insights into argumentation dynamics in online discussions and, through the presented prediction procedure, are of practical importance for writing assistance and persuasive text generation systems.</abstract>
      <url hash="aed806f6">2023.findings-emnlp.1048</url>
      <bibkey>mirzakhmedova-etal-2023-unveiling</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.1048</doi>
    </paper>
    <paper id="1049">
      <title><fixed-case>FFAE</fixed-case>val: Evaluating Dialogue System via Free-For-All Ranking</title>
      <author><first>Zeyao</first><last>Ma</last></author>
      <author><first>Zijun</first><last>Yao</last></author>
      <author><first>Jing</first><last>Zhang</last></author>
      <author><first>Jifan</first><last>Yu</last></author>
      <author><first>Xiaohan</first><last>Zhang</last></author>
      <author><first>Juanzi</first><last>Li</last></author>
      <author><first>Jie</first><last>Tang</last></author>
      <pages>15672-15684</pages>
      <abstract>Evaluating open-domain dialogue systems is currently an open question. Automatic evaluation metrics have shown poor correlation with human assessment in dialogue generation tasks. Human evaluation, which involves annotators for multi-dimension scoring, is trustworthy but time-consuming. In this work, we propose FFAEval, a reliable and efficient human evaluation framework using Free-For-All ranking approach. By sharing the dialogue history, the framework enables annotators to converse with multiple dialogue systems simultaneously in a single-blind, multi-turn manner. The subsequent free-for-all allows annotators to select the most favourable model in each turn from among all the participating dialogue systems. The final performance of each model is represented by calculating the TrueSkill score derived from the free-for-all competition. Our empirical study on English and Chinese dialogue systems demonstrates that FFAEval achieves a strong correlation with score-based human assessment compared to existing evaluation methods. We further prove the efficiency and stability of our framework in additional experiments. The source code and data are available on Github.</abstract>
      <url hash="ffe14d49">2023.findings-emnlp.1049</url>
      <bibkey>ma-etal-2023-ffaeval</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.1049</doi>
    </paper>
    <paper id="1050">
      <title>Orca: A Few-shot Benchmark for <fixed-case>C</fixed-case>hinese Conversational Machine Reading Comprehension</title>
      <author><first>Nuo</first><last>Chen</last></author>
      <author><first>Hongguang</first><last>Li</last></author>
      <author><first>Junqing</first><last>He</last></author>
      <author><first>Yinan</first><last>Bao</last></author>
      <author><first>Xinshi</first><last>Lin</last></author>
      <author><first>Qi</first><last>Yang</last></author>
      <author><first>Jianfeng</first><last>Liu</last></author>
      <author><first>Ruyi</first><last>Gan</last></author>
      <author><first>Jiaxing</first><last>Zhang</last></author>
      <author><first>Baoyuan</first><last>Wang</last></author>
      <author><first>Jia</first><last>Li</last></author>
      <pages>15685-15699</pages>
      <abstract>The conversational machine reading comprehension (CMRC) task aims to answer questions in conversations, which has been a hot research topic in recent years because of its wide applications. However, existing CMRC benchmarks in which each conversation is assigned a static passage are inconsistent with real scenarios. Thus, model’s comprehension ability towards real scenarios are hard to evaluate reasonably. To this end, we propose the first Chinese CMRC benchmark <b>Orca</b> and further provide zero-shot/few-shot settings to evaluate model’s generalization ability towards diverse domains. We collect 831 hot-topic driven conversations with 4,742 turns in total. Each turn of a conversation is assigned with a response-related passage, aiming to evaluate model’s comprehension ability more reasonably. The topics of conversations are collected from social media platform and cover 33 domains, trying to be consistent with real scenarios. Importantly, answers in Orca are all well-annotated natural responses rather than the specific spans or short phrase in previous datasets. Besides, we implement three strong baselines to tackle the challenge in Orca. The results indicate the great challenge of our CMRC benchmark.</abstract>
      <url hash="a05d6eaa">2023.findings-emnlp.1050</url>
      <bibkey>chen-etal-2023-orca</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.1050</doi>
    </paper>
    <paper id="1051">
      <title><fixed-case>VER</fixed-case>: Unifying Verbalizing Entities and Relations</title>
      <author><first>Jie</first><last>Huang</last></author>
      <author><first>Kevin</first><last>Chang</last></author>
      <pages>15700-15710</pages>
      <abstract>Entities and relationships between entities are vital in the real world. Essentially, we understand the world by understanding entities and relations. For instance, to understand a field, e.g., computer science, we need to understand the relevant concepts, e.g., machine learning, and the relationships between concepts, e.g., machine learning and artificial intelligence. To understand a person, we should first know who he/she is and how he/she is related to others. To understand entities and relations, humans may refer to natural language descriptions. For instance, when learning a new scientific term, people usually start by reading its definition in dictionaries or encyclopedias. To know the relationship between two entities, humans tend to create a sentence to connect them. In this paper, we propose VER: a unified model for Verbalizing Entities and Relations. Specifically, we attempt to build a system that takes any entity or entity set as input and generates a sentence to represent entities and relations. Extensive experiments demonstrate that our model can generate high-quality sentences describing entities and entity relationships and facilitate various tasks on entities and relations, including definition modeling, relation modeling, and generative commonsense reasoning.</abstract>
      <url hash="35df39e5">2023.findings-emnlp.1051</url>
      <bibkey>huang-chang-2023-ver</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.1051</doi>
    </paper>
    <paper id="1052">
      <title>The Linearity of the Effect of Surprisal on Reading Times across Languages</title>
      <author><first>Weijie</first><last>Xu</last></author>
      <author><first>Jason</first><last>Chon</last></author>
      <author><first>Tianran</first><last>Liu</last></author>
      <author><first>Richard</first><last>Futrell</last></author>
      <pages>15711-15721</pages>
      <abstract>In psycholinguistics, surprisal theory posits that the amount of online processing effort expended by a human comprehender per word positively correlates with the surprisal of that word given its preceding context. In addition to this overall correlation, more importantly, the specific quantitative form taken by the processing effort as a function of surprisal offers insights into the underlying cognitive mechanisms of language processing. Focusing on English, previous studies have looked into the linearity of surprisal on reading times. Here, we extend the investigation by examining eyetracking corpora of seven languages: Danish, Dutch, English, German, Japanese, Mandarin, and Russian. We find evidence for superlinearity in some languages, but the results are highly sensitive to which language model is used to estimate surprisal.</abstract>
      <url hash="987cd50c">2023.findings-emnlp.1052</url>
      <bibkey>xu-etal-2023-linearity</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.1052</doi>
    </paper>
    <paper id="1053">
      <title>Adversarial Text Generation by Search and Learning</title>
      <author><first>Guoyi</first><last>Li</last></author>
      <author><first>Bingkang</first><last>Shi</last></author>
      <author><first>Zongzhen</first><last>Liu</last></author>
      <author><first>Dehan</first><last>Kong</last></author>
      <author><first>Yulei</first><last>Wu</last></author>
      <author><first>Xiaodan</first><last>Zhang</last></author>
      <author><first>Longtao</first><last>Huang</last></author>
      <author><first>Honglei</first><last>Lyu</last></author>
      <pages>15722-15738</pages>
      <abstract>Recent research has shown that evaluating the robustness of natural language processing models using textual attack methods is significant. However, most existing text attack methods only use heuristic replacement strategies or language models to generate replacement words at the word level. The blind pursuit of high attack success rates makes it difficult to ensure the quality of the generated adversarial text. As a result, adversarial text is often difficult for humans to understand. In fact, many methods that perform well in terms of text attacks often generate adversarial text with poor quality. To address this important gap, our work treats black-box text attack as an unsupervised text generation problem and proposes a search and learning framework for Adversarial Text Generation by Search and Learning (ATGSL) and develops three adversarial attack methods (ATGSL-SA, ATGSL-BM, ATGSL-FUSION) for black box text attacks. We first apply a heuristic search attack algorithm (ATGSL-SA) and a linguistic thesaurus to generate adversarial samples with high semantic similarity. After this process, we train a conditional generative model to learn from the search results while smoothing out search noise. Moreover, we design an efficient ATGSL-BM attack algorithm based on the text generator. Furthermore, we propose a hybrid attack method (ATGSL-FUSION) that integrates the advantages of ATGSL-SA and ATGSL-BM to enhance attack effectiveness. Our proposed attack algorithms are significantly superior to the most advanced methods in terms of attack efficiency and adversarial text quality.</abstract>
      <url hash="77309104">2023.findings-emnlp.1053</url>
      <bibkey>li-etal-2023-adversarial</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.1053</doi>
    </paper>
    <paper id="1054">
      <title>Measuring Pointwise <tex-math>\mathcal{V}</tex-math>-Usable Information In-Context-ly</title>
      <author><first>Sheng</first><last>Lu</last></author>
      <author><first>Shan</first><last>Chen</last></author>
      <author><first>Yingya</first><last>Li</last></author>
      <author><first>Danielle</first><last>Bitterman</last></author>
      <author><first>Guergana</first><last>Savova</last></author>
      <author><first>Iryna</first><last>Gurevych</last></author>
      <pages>15739-15756</pages>
      <abstract>In-context learning (ICL) is a new learning paradigm that has gained popularity along with the development of large language models. In this work, we adapt a recently proposed hardness metric, pointwise <tex-math>\mathcal{V}</tex-math>-usable information (PVI), to an in-context version (in-context PVI). Compared to the original PVI, in-context PVI is more efficient in that it requires only a few exemplars and does not require fine-tuning. We conducted a comprehensive empirical analysis to evaluate the reliability of in-context PVI. Our findings indicate that in-context PVI estimates exhibit similar characteristics to the original PVI. Specific to the in-context setting, we show that in-context PVI estimates remain consistent across different exemplar selections and numbers of shots. The variance of in-context PVI estimates across different exemplar selections is insignificant, which suggests that in-context PVI estimates are stable. Furthermore, we demonstrate how in-context PVI can be employed to identify challenging instances. Our work highlights the potential of in-context PVI and provides new insights into the capabilities of ICL.</abstract>
      <url hash="2157d386">2023.findings-emnlp.1054</url>
      <bibkey>lu-etal-2023-measuring</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.1054</doi>
    </paper>
    <paper id="1055">
      <title><fixed-case>S</fixed-case>peech<fixed-case>GPT</fixed-case>: Empowering Large Language Models with Intrinsic Cross-Modal Conversational Abilities</title>
      <author><first>Dong</first><last>Zhang</last></author>
      <author><first>Shimin</first><last>Li</last></author>
      <author><first>Xin</first><last>Zhang</last></author>
      <author><first>Jun</first><last>Zhan</last></author>
      <author><first>Pengyu</first><last>Wang</last></author>
      <author><first>Yaqian</first><last>Zhou</last></author>
      <author><first>Xipeng</first><last>Qiu</last></author>
      <pages>15757-15773</pages>
      <abstract>Multi-modal large language models are regarded as a crucial step towards Artificial General Intelligence (AGI) and have garnered significant interest with the emergence of ChatGPT. However, current speech-language models typically adopt the cascade paradigm, preventing inter-modal knowledge transfer. In this paper, we propose SpeechGPT, a large language model with intrinsic cross-modal conversational abilities, capable of perceiving and generating multi-modal content. With discrete speech representations, we construct SpeechInstruct, the first large-scale cross-modal speech instruction dataset. Additionally, we employ a three-stage training strategy that includes modality-adaptation pre-training, cross-modal instruction fine-tuning, and chain-of-modality instruction fine-tuning. The experimental results demonstrate that SpeechGPT has an impressive capacity to follow cross-modal human instructions and highlight the potential of handling multiple modalities with one model. Code and models are available in <url>https://github.com/0nutation/SpeechGPT</url>. Demos are shown in <url>https://0nutation.github.io/SpeechGPT.github.io/</url>.</abstract>
      <url hash="6bb0f854">2023.findings-emnlp.1055</url>
      <bibkey>zhang-etal-2023-speechgpt</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.1055</doi>
    </paper>
    <paper id="1056">
      <title>Unleashing the Multilingual Encoder Potential: Boosting Zero-Shot Performance via Probability Calibration</title>
      <author><first>Ercong</first><last>Nie</last></author>
      <author><first>Helmut</first><last>Schmid</last></author>
      <author><first>Hinrich</first><last>Schuetze</last></author>
      <pages>15774-15782</pages>
      <abstract>Pretrained multilingual encoder models can directly perform zero-shot multilingual tasks or linguistic probing by reformulating the input examples into cloze-style prompts. This is accomplished by predicting the probabilities of the label words at the masked token position, without requiring any updates to the model parameters. However, the performance of this method is limited by the model’s bias toward predicting label words which frequently occurred during the pretraining. These words typically receive high probabilities. To address this issue, we combine the models with calibration techniques which modify the probabilities of label words predicted by the models. We first validate the effectiveness of a proposed simple calibration method together with other existing techniques on monolingual encoders in both zero- and few-shot scenarios. We subsequently employ these calibration techniques on multilingual encoders, resulting in substantial performance improvements across a wide range of tasks.</abstract>
      <url hash="405a01f5">2023.findings-emnlp.1056</url>
      <bibkey>nie-etal-2023-unleashing</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.1056</doi>
    </paper>
    <paper id="1057">
      <title>A Thorough Examination on Zero-shot Dense Retrieval</title>
      <author><first>Ruiyang</first><last>Ren</last></author>
      <author><first>Yingqi</first><last>Qu</last></author>
      <author><first>Jing</first><last>Liu</last></author>
      <author><first>Xin</first><last>Zhao</last></author>
      <author><first>Qifei</first><last>Wu</last></author>
      <author><first>Yuchen</first><last>Ding</last></author>
      <author><first>Hua</first><last>Wu</last></author>
      <author><first>Haifeng</first><last>Wang</last></author>
      <author><first>Ji-Rong</first><last>Wen</last></author>
      <pages>15783-15796</pages>
      <abstract>Recent years have witnessed the significant advance in dense retrieval (DR) based on powerful pre-trained language models (PLM). DR models have achieved excellent performance in several benchmark datasets, while they are shown to be not as competitive as traditional sparse retrieval models (e.g., BM25) in a zero-shot retrieval setting. However, in the related literature, there still lacks a detailed and comprehensive study on zero-shot retrieval. In this paper, we present the first thorough examination of the zero-shot capability of DR models. We aim to identify the key factors and analyze how they affect zero-shot retrieval performance. In particular, we discuss the effect of several key factors related to source training set, analyze the potential bias from the target dataset, and review and compare existing zero-shot DR models. Our findings provide important evidence to better understand and develop zero-shot DR models.</abstract>
      <url hash="42a0430d">2023.findings-emnlp.1057</url>
      <bibkey>ren-etal-2023-thorough</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.1057</doi>
    </paper>
    <paper id="1058">
      <title>Contrastive Pre-training for Personalized Expert Finding</title>
      <author><first>Qiyao</first><last>Peng</last></author>
      <author><first>Hongtao</first><last>Liu</last></author>
      <author><first>Zhepeng</first><last>Lv</last></author>
      <author><first>Qing</first><last>Yang</last></author>
      <author><first>Wenjun</first><last>Wang</last></author>
      <pages>15797-15806</pages>
      <abstract>Expert finding could help route questions to potential suitable users to answer in Community Question Answering (CQA) platforms. Hence it is essential to learn accurate representations of experts and questions according to the question text articles. Recently the pre-training and fine-tuning paradigms are powerful for natural language understanding, which has the potential for better question modeling and expert finding. Inspired by this, we propose a CQA-domain Contrastive Pre-training framework for Expert Finding, named CPEF, which could learn more comprehensive question representations. Specifically, considering that there is semantic complementation between question titles and bodies, during the domain pre-training phase, we propose a title-body contrastive learning task to enhance question representations, which directly treats the question title and the corresponding body as positive samples of each other, instead of designing extra data-augmentation strategies. Furthermore, a personalized tuning network is proposed to inject the personalized preferences of different experts during the fine-tuning phase. Extensive experimental results on six real-world datasets demonstrate that our method could achieve superior performance for expert finding.</abstract>
      <url hash="79ef45db">2023.findings-emnlp.1058</url>
      <bibkey>peng-etal-2023-contrastive</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.1058</doi>
    </paper>
    <paper id="1059">
      <title>Mitigating Intrinsic Named Entity-Related Hallucinations of Abstractive Text Summarization</title>
      <author><first>Jianbin</first><last>Shen</last></author>
      <author><first>Junyu</first><last>Xuan</last></author>
      <author><first>Christy</first><last>Liang</last></author>
      <pages>15807-15824</pages>
      <abstract>Abstractive text summarization (ATS) is both important and challenging. Recent studies have shown that ATS still faces various forms of hallucination. Our study also indicates that a significant portion of hallucinations is named entity-related. They might appear in different forms, such as mistaken entities and erroneous entity references. The underlying causes implicit in data are complex: data samples pose varying learning conditions. Despite recent research efforts dedicated to named entity-related hallucinations, the solutions have not adequately addressed the varying learning conditions posed by data. This paper aims to bridge the gap in pursuit of reducing intrinsic named entity-related hallucinations. To do so, we propose an adaptive margin ranking loss to facilitate two entity-alignment learning methods to tackle them. Our experiment results show that our methods improve the used baseline model on automatic evaluation scores. The human evaluation also indicates that our methods jointly reduce the intrinsic named entity-related hallucinations considerably compared to the used baseline model.</abstract>
      <url hash="c223a8eb">2023.findings-emnlp.1059</url>
      <bibkey>shen-etal-2023-mitigating</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.1059</doi>
    </paper>
    <paper id="1060">
      <title>Towards Informative Few-Shot Prompt with Maximum Information Gain for In-Context Learning</title>
      <author><first>Hongfu</first><last>Liu</last></author>
      <author><first>Ye</first><last>Wang</last></author>
      <pages>15825-15838</pages>
      <abstract>Large Language models (LLMs) possess the capability to engage In-context Learning (ICL) by leveraging a few demonstrations pertaining to a new downstream task as conditions. However, this particular learning paradigm suffers from high instability stemming from substantial variances induced by factors such as the input distribution of selected examples, their ordering, and prompt formats. In this work, we demonstrate that even when all these factors are held constant, the random selection of examples still results in high variance. Consequently, we aim to explore the informative ability of data examples by quantifying the Information Gain (IG) obtained in prediction after observing a given example candidate. Then we propose to sample those with maximum IG. Additionally, we identify the presence of template bias, which can lead to unfair evaluations of IG during the sampling process. To mitigate this bias, we introduce Calibration Before Sampling strategy. The experimental results illustrate that our proposed method can yield an average relative improvement of 14.3% across six classification tasks using three LLMs.</abstract>
      <url hash="f31a55d8">2023.findings-emnlp.1060</url>
      <bibkey>liu-wang-2023-towards</bibkey>
      <doi>10.18653/v1/2023.findings-emnlp.1060</doi>
    </paper>
  </volume>
</collection>
