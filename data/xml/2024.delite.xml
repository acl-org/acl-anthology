<?xml version='1.0' encoding='UTF-8'?>
<collection id="2024.delite">
  <volume id="1" ingest-date="2024-05-16" type="proceedings">
    <meta>
      <booktitle>Proceedings of the First Workshop on Language-driven Deliberation Technology (DELITE) @ LREC-COLING 2024</booktitle>
      <editor><first>Annette</first><last>Hautli-Janisz</last></editor>
      <editor><first>Gabriella</first><last>Lapesa</last></editor>
      <editor><first>Lucas</first><last>Anastasiou</last></editor>
      <editor><first>Valentin</first><last>Gold</last></editor>
      <editor><first>Anna De</first><last>Liddo</last></editor>
      <editor><first>Chris</first><last>Reed</last></editor>
      <publisher>ELRA and ICCL</publisher>
      <address>Torino, Italia</address>
      <month>May</month>
      <year>2024</year>
      <url hash="18466707">2024.delite-1</url>
      <venue>delite</venue>
    </meta>
    <frontmatter>
      <url hash="142c5bb6">2024.delite-1.0</url>
      <bibkey>delite-2024-language</bibkey>
    </frontmatter>
    <paper id="1">
      <title><fixed-case>AQ</fixed-case>u<fixed-case>A</fixed-case> – Combining Experts’ and Non-Experts’ Views To Assess Deliberation Quality in Online Discussions Using <fixed-case>LLM</fixed-case>s</title>
      <author><first>Maike</first><last>Behrendt</last></author>
      <author><first>Stefan Sylvius</first><last>Wagner</last></author>
      <author><first>Marc</first><last>Ziegele</last></author>
      <author><first>Lena</first><last>Wilms</last></author>
      <author><first>Anke</first><last>Stoll</last></author>
      <author><first>Dominique</first><last>Heinbach</last></author>
      <author><first>Stefan</first><last>Harmeling</last></author>
      <pages>1–12</pages>
      <abstract>Measuring the quality of contributions in political online discussions is crucial in deliberation research and computer science. Research has identified various indicators to assess online discussion quality, and with deep learning advancements, automating these measures has become feasible. While some studies focus on analyzing specific quality indicators, a comprehensive quality score incorporating various deliberative aspects is often preferred. In this work, we introduce AQuA, an additive score that calculates a unified deliberative quality score from multiple indices for each discussion post. Unlike other singular scores, AQuA preserves information on the deliberative aspects present in comments, enhancing model transparency. We develop adapter models for 20 deliberative indices, and calculate correlation coefficients between experts’ annotations and the perceived deliberativeness by non-experts to weigh the individual indices into a single deliberative score. We demonstrate that the AQuA score can be computed easily from pre-trained adapters and aligns well with annotations on other datasets that have not be seen during training. The analysis of experts’ vs. non-experts’ annotations confirms theoretical findings in the social science literature.</abstract>
      <url hash="9acdb949">2024.delite-1.1</url>
      <bibkey>behrendt-etal-2024-aqua</bibkey>
    </paper>
    <paper id="2">
      <title>A Unified <fixed-case>LLM</fixed-case>-<fixed-case>KG</fixed-case> Framework to Assist Fact-Checking in Public Deliberation</title>
      <author><first>Nikolaos</first><last>Giarelis</last></author>
      <author><first>Charalampos</first><last>Mastrokostas</last></author>
      <author><first>Nikos</first><last>Karacapilidis</last></author>
      <pages>13–19</pages>
      <abstract>Fact-checking plays a crucial role in public deliberation by promoting transparency, accuracy, credibility, and accountability. Aiming to augment the efficiency and adoption of current public deliberation platforms, which mostly rely on the abilities of participants to meaningfully process and interpret the associated content, this paper explores the combination of deep learning and symbolic reasoning. Specifically, it proposes a framework that unifies the capabilities of Large Language Models (LLMs) and Knowledge Graphs (KGs), and reports on an experimental evaluation. This evaluation is conducted through a questionnaire asking users to assess a baseline LLM against the proposed framework, using a series of fact-checking metrics, namely readability, coverage, non-redundancy, and quality. The experimentation results are promising and confirm the potential of combining the capabilities of these two technologies in the context of public deliberation and digital democracy.</abstract>
      <url hash="7fc63397">2024.delite-1.2</url>
      <bibkey>giarelis-etal-2024-unified</bibkey>
    </paper>
    <paper id="3">
      <title>Can Text Simplification Help to Increase the Acceptance of <fixed-case>E</fixed-case>-participation?</title>
      <author><first>Regina</first><last>Stodden</last></author>
      <author><first>Phillip</first><last>Nguyen</last></author>
      <pages>20–32</pages>
      <abstract>This study investigated the effect of text simplification (with and without artificial intelligence support) and the role of participants (author or reader) on the acceptance of e-participation processes. Therefore, a near-realistic experimental study with 276 participants was conducted simulating a participatory budgeting process. The results of our study show, on the one hand, that text simplification and the role of participants has no direct influence on the intention to use e-participation. Although a higher level of participation cannot be achieved by text simplification, our results also show that no negative consequences for usage intention can be expected from text simplification. On the other hand, the results show that people with reading and writing difficulties prefer text simplification for proposals in e-participation.</abstract>
      <url hash="0f3b57eb">2024.delite-1.3</url>
      <bibkey>stodden-nguyen-2024-text</bibkey>
    </paper>
    <paper id="4">
      <title>Pitfalls of Conversational <fixed-case>LLM</fixed-case>s on News Debiasing</title>
      <author><first>Ipek</first><last>Baris Schlicht</last></author>
      <author><first>Defne</first><last>Altiok</last></author>
      <author><first>Maryanne</first><last>Taouk</last></author>
      <author><first>Lucie</first><last>Flek</last></author>
      <pages>33–38</pages>
      <abstract>This paper addresses debiasing in news editing and evaluates the effectiveness of conversational Large Language Models in this task. We designed an evaluation checklist tailored to news editors’ perspectives, obtained generated texts from three popular conversational models using a subset of a publicly available dataset in media bias, and evaluated the texts according to the designed checklist. Furthermore, we examined the models as evaluator for checking the quality of debiased model outputs. Our findings indicate that none of the LLMs are perfect in debiasing. Notably, some models, including ChatGPT, introduced unnecessary changes that may impact the author’s style and create misinformation. Lastly, we show that the models do not perform as proficiently as domain experts in evaluating the quality of debiased outputs.</abstract>
      <url hash="4eba65dd">2024.delite-1.4</url>
      <bibkey>baris-schlicht-etal-2024-pitfalls</bibkey>
    </paper>
    <paper id="5">
      <title>Integrating conflict prevention tools into deliberative democracy online platforms</title>
      <author><first>Sara</first><last>Greco</last></author>
      <author><first>Chiara</first><last>Jermini</last></author>
      <pages>39–44</pages>
      <abstract>This paper presents a set of preliminary guidelines for conflict prevention developed within the EU-funded research project ORBIS (“Augmenting participation, co-creation, trust and transparency in Deliberative Democracy at all scales”), whose goal is developing online platforms that enable citizens to enhance their participation in democratic processes, through open discussions around important political topics. Based on previous research on communication and argumentation in conflict resolution discourse and on the empirical analysis of discussions around deliberative democracy topics, this paper highlights recurrent interpersonal communication problems that might occur in group discussions around complex topics and that, if not handled well, can lead to conflicts; and introduces a first proposal for solutions to help, both through technology and with the assistance of human moderations, participants in such discussions to avoid the development and the escalation of conflicts.</abstract>
      <url hash="43496c1c">2024.delite-1.5</url>
      <bibkey>greco-jermini-2024-integrating</bibkey>
    </paper>
    <paper id="6">
      <title>A Hybrid Human-<fixed-case>AI</fixed-case> Approach for Argument Map Creation From Transcripts</title>
      <author><first>Lucas</first><last>Anastasiou</last></author>
      <author><first>Anna</first><last>De Liddo</last></author>
      <pages>45–51</pages>
      <abstract>In order to overcome challenges of traditional deliberation approaches that often silo information exchange between synchronous and asynchronous modes therefore hindering effective deliberation, we present a hybrid framework combining Large Language Models (LLMs) and human-in-the-loop curation to generate argument maps from deliberation transcripts. This approach aims to enhance the efficiency and quality of the generated argument maps, promote transparency, and connect the asynchronous and synchronous deliberation modes. Finally, we outline a realistic deliberation scenario where this process can be successfully integrated.</abstract>
      <url hash="b715a34a">2024.delite-1.6</url>
      <bibkey>anastasiou-de-liddo-2024-hybrid</bibkey>
    </paper>
    <paper id="7">
      <title>Leveraging High-Precision Corpus Queries for Text Classification via Large Language Models</title>
      <author><first>Nathan</first><last>Dykes</last></author>
      <author><first>Stephanie</first><last>Evert</last></author>
      <author><first>Philipp</first><last>Heinrich</last></author>
      <author><first>Merlin</first><last>Humml</last></author>
      <author><first>Lutz</first><last>Schröder</last></author>
      <pages>52–57</pages>
      <abstract>We use query results from manually designed corpus queries for fine-tuning an LLM to identify argumentative fragments as a text mining task. The resulting model outperforms both an LLM fine-tuned on a relatively large manually annotated gold standard of tweets as well as a rule-based approach. This proof-of-concept study demonstrates the usefulness of corpus queries to generate training data for complex text categorisation tasks, especially if the targeted category has low prevalence (so that a manually annotated gold standard contains only a small number of positive examples).</abstract>
      <url hash="6334d784">2024.delite-1.7</url>
      <bibkey>dykes-etal-2024-leveraging</bibkey>
    </paper>
  </volume>
</collection>
