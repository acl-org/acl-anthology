<?xml version='1.0' encoding='UTF-8'?>
<collection id="2021.conll">
  <volume id="1" ingest-date="2021-10-28">
    <meta>
      <booktitle>Proceedings of the 25th Conference on Computational Natural Language Learning</booktitle>
      <editor><first>Arianna</first><last>Bisazza</last></editor>
      <editor><first>Omri</first><last>Abend</last></editor>
      <publisher>Association for Computational Linguistics</publisher>
      <address>Online</address>
      <month>November</month>
      <year>2021</year>
      <venue>conll</venue>
    </meta>
    <frontmatter>
      <url hash="a00cd227">2021.conll-1.0</url>
      <bibkey>conll-2021-natural</bibkey>
    </frontmatter>
    <paper id="1">
      <title>“It’s our fault!”: Insights Into Users’ Understanding and Interaction With an Explanatory Collaborative Dialog System</title>
      <author><first>Katharina</first><last>Weitz</last></author>
      <author><first>Lindsey</first><last>Vanderlyn</last></author>
      <author><first>Ngoc Thang</first><last>Vu</last></author>
      <author><first>Elisabeth</first><last>André</last></author>
      <pages>1–16</pages>
      <abstract>Human-AI collaboration, a long standing goal in AI, refers to a partnership where a human and artificial intelligence work together towards a shared goal. Collaborative dialog allows human-AI teams to communicate and leverage strengths from both partners. To design collaborative dialog systems, it is important to understand what mental models users form about their AI-dialog partners, however, how users perceive these systems is not fully understood. In this study, we designed a novel, collaborative, communication-based puzzle game and explanatory dialog system. We created a public corpus from 117 conversations and post-surveys and used this to analyze what mental models users formed. Key takeaways include: Even when users were not engaged in the game, they perceived the AI-dialog partner as intelligent and likeable, implying they saw it as a partner separate from the game. This was further supported by users often overestimating the system’s abilities and projecting human-like attributes which led to miscommunications. We conclude that creating shared mental models between users and AI systems is important to achieving successful dialogs. We propose that our insights on mental models and miscommunication, the game, and our corpus provide useful tools for designing collaborative dialog systems.</abstract>
      <url hash="7a6fa03b">2021.conll-1.1</url>
      <bibkey>weitz-etal-2021-fault</bibkey>
      <doi>10.18653/v1/2021.conll-1.1</doi>
      <video href="2021.conll-1.1.mp4"/>
      <revision id="1" href="2021.conll-1.1v1" hash="25e22930"/>
      <revision id="2" href="2021.conll-1.1v2" hash="7a6fa03b" date="2022-10-25">Corrected stats, table, figure and analysis in Quantitative Analysis.</revision>
    </paper>
    <paper id="2">
      <title>Dependency Induction Through the Lens of Visual Perception</title>
      <author><first>Ruisi</first><last>Su</last></author>
      <author><first>Shruti</first><last>Rijhwani</last></author>
      <author><first>Hao</first><last>Zhu</last></author>
      <author><first>Junxian</first><last>He</last></author>
      <author><first>Xinyu</first><last>Wang</last></author>
      <author><first>Yonatan</first><last>Bisk</last></author>
      <author><first>Graham</first><last>Neubig</last></author>
      <pages>17–26</pages>
      <abstract>Most previous work on grammar induction focuses on learning phrasal or dependency structure purely from text. However, because the signal provided by text alone is limited, recently introduced visually grounded syntax models make use of multimodal information leading to improved performance in constituency grammar induction. However, as compared to dependency grammars, constituency grammars do not provide a straightforward way to incorporate visual information without enforcing language-specific heuristics. In this paper, we propose an unsupervised grammar induction model that leverages word concreteness and a structural vision-based heuristic to jointly learn constituency-structure and dependency-structure grammars. Our experiments find that concreteness is a strong indicator for learning dependency grammars, improving the direct attachment score (DAS) by over 50% as compared to state-of-the-art models trained on pure text. Next, we propose an extension of our model that leverages both word concreteness and visual semantic role labels in constituency and dependency parsing. Our experiments show that the proposed extension outperforms the current state-of-the-art visually grounded models in constituency parsing even with a smaller grammar size.</abstract>
      <url hash="3ce2def5">2021.conll-1.2</url>
      <bibkey>su-etal-2021-dependency</bibkey>
      <doi>10.18653/v1/2021.conll-1.2</doi>
      <video href="2021.conll-1.2.mp4"/>
      <pwccode url="https://github.com/ruisi-su/concrete_dep" additional="false">ruisi-su/concrete_dep</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/coco">COCO</pwcdataset>
    </paper>
    <paper id="3">
      <title><fixed-case>VQA</fixed-case>-<fixed-case>MHUG</fixed-case>: A Gaze Dataset to Study Multimodal Neural Attention in Visual Question Answering</title>
      <author><first>Ekta</first><last>Sood</last></author>
      <author><first>Fabian</first><last>Kögel</last></author>
      <author><first>Florian</first><last>Strohm</last></author>
      <author><first>Prajit</first><last>Dhar</last></author>
      <author><first>Andreas</first><last>Bulling</last></author>
      <pages>27–43</pages>
      <abstract>We present VQA-MHUG – a novel 49-participant dataset of multimodal human gaze on both images and questions during visual question answering (VQA) collected using a high-speed eye tracker. We use our dataset to analyze the similarity between human and neural attentive strategies learned by five state-of-the-art VQA models: Modular Co-Attention Network (MCAN) with either grid or region features, Pythia, Bilinear Attention Network (BAN), and the Multimodal Factorized Bilinear Pooling Network (MFB). While prior work has focused on studying the image modality, our analyses show – for the first time – that for all models, higher correlation with human attention on text is a significant predictor of VQA performance. This finding points at a potential for improving VQA performance and, at the same time, calls for further research on neural text attention mechanisms and their integration into architectures for vision and language tasks, including but potentially also beyond VQA.</abstract>
      <url hash="f46b645d">2021.conll-1.3</url>
      <bibkey>sood-etal-2021-vqa</bibkey>
      <doi>10.18653/v1/2021.conll-1.3</doi>
      <video href="2021.conll-1.3.mp4"/>
      <pwcdataset url="https://paperswithcode.com/dataset/vqa-mhug">VQA-MHUG</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/salicon">SALICON</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/tdiuc">TDIUC</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/vqa-hat">VQA-HAT</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/visual-question-answering">Visual Question Answering</pwcdataset>
    </paper>
    <paper id="4">
      <title>“It seemed like an annoying woman”: On the Perception and Ethical Considerations of Affective Language in Text-Based Conversational Agents</title>
      <author><first>Lindsey</first><last>Vanderlyn</last></author>
      <author><first>Gianna</first><last>Weber</last></author>
      <author><first>Michael</first><last>Neumann</last></author>
      <author><first>Dirk</first><last>Väth</last></author>
      <author><first>Sarina</first><last>Meyer</last></author>
      <author><first>Ngoc Thang</first><last>Vu</last></author>
      <pages>44–57</pages>
      <abstract>Previous research has found that task-oriented conversational agents are perceived more positively by users when they provide information in an empathetic manner compared to a plain, emotionless information exchange. However, users’ perception and ethical considerations related to a dialog systems’ response language style have received comparatively little attention in the field of human-computer interaction. To bridge this gap, we explored these ethical implications through a scenario-based user study. 127 participants interacted with one of three variants of an affective, task-oriented conversational agent, each variant providing responses in a different language style. After the interaction, participants filled out a survey about their feelings during the experiment and their perception of various aspects of the chatbot. Based on statistical and qualitative analysis of the responses, we found language style played an important role in how human-like participants perceived a dialog agent as well as how likable. Language style also had a direct effect on how users perceived the use of personal pronouns ‘I’ and ‘You’ and how they projected gender onto the chatbot. Finally, we identify and discuss ethical implications. In particular we focus on what factors/stereotypes influenced participants’ impressions of gender, and what trade-offs a more human-like chatbot brings.</abstract>
      <url hash="ed5113d5">2021.conll-1.4</url>
      <bibkey>vanderlyn-etal-2021-seemed</bibkey>
      <doi>10.18653/v1/2021.conll-1.4</doi>
      <video href="2021.conll-1.4.mp4"/>
    </paper>
    <paper id="5">
      <title>On Language Models for Creoles</title>
      <author><first>Heather</first><last>Lent</last></author>
      <author><first>Emanuele</first><last>Bugliarello</last></author>
      <author><first>Miryam</first><last>de Lhoneux</last></author>
      <author><first>Chen</first><last>Qiu</last></author>
      <author><first>Anders</first><last>Søgaard</last></author>
      <pages>58–71</pages>
      <abstract>Creole languages such as Nigerian Pidgin English and Haitian Creole are under-resourced and largely ignored in the NLP literature. Creoles typically result from the fusion of a foreign language with multiple local languages, and what grammatical and lexical features are transferred to the creole is a complex process. While creoles are generally stable, the prominence of some features may be much stronger with certain demographics or in some linguistic situations. This paper makes several contributions: We collect existing corpora and release models for Haitian Creole, Nigerian Pidgin English, and Singaporean Colloquial English. We evaluate these models on intrinsic and extrinsic tasks. Motivated by the above literature, we compare standard language models with distributionally robust ones and find that, somewhat surprisingly, the standard language models are superior to the distributionally robust ones. We investigate whether this is an effect of over-parameterization or relative distributional stability, and find that the difference persists in the absence of over-parameterization, and that drift is limited, confirming the relative stability of creole languages.</abstract>
      <url hash="32c6b62b">2021.conll-1.5</url>
      <bibkey>lent-etal-2021-language</bibkey>
      <doi>10.18653/v1/2021.conll-1.5</doi>
      <video href="2021.conll-1.5.mp4"/>
      <pwccode url="https://github.com/hclent/creole-dro" additional="false">hclent/creole-dro</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/wilds">Wilds</pwcdataset>
    </paper>
    <paper id="6">
      <title>Do pretrained transformers infer telicity like humans?</title>
      <author><first>Yiyun</first><last>Zhao</last></author>
      <author><first>Jian Gang</first><last>Ngui</last></author>
      <author><first>Lucy</first><last>Hall Hartley</last></author>
      <author><first>Steven</first><last>Bethard</last></author>
      <pages>72–81</pages>
      <abstract>Pretrained transformer-based language models achieve state-of-the-art performance in many NLP tasks, but it is an open question whether the knowledge acquired by the models during pretraining resembles the linguistic knowledge of humans. We present both humans and pretrained transformers with descriptions of events, and measure their preference for telic interpretations (the event has a natural endpoint) or atelic interpretations (the event does not have a natural endpoint). To measure these preferences and determine what factors influence them, we design an English test and a novel-word test that include a variety of linguistic cues (noun phrase quantity, resultative structure, contextual information, temporal units) that bias toward certain interpretations. We find that humans’ choice of telicity interpretation is reliably influenced by theoretically-motivated cues, transformer models (BERT and RoBERTa) are influenced by some (though not all) of the cues, and transformer models often rely more heavily on temporal units than humans do.</abstract>
      <url hash="7c337a5c">2021.conll-1.6</url>
      <bibkey>zhao-etal-2021-pretrained</bibkey>
      <doi>10.18653/v1/2021.conll-1.6</doi>
      <revision id="1" href="2021.conll-1.6v1" hash="5bbe307e"/>
      <revision id="2" href="2021.conll-1.6v2" hash="7c337a5c" date="2022-03-20">Added missing grant acknowledgements.</revision>
      <video href="2021.conll-1.6.mp4"/>
    </paper>
    <paper id="7">
      <title>The Low-Dimensional Linear Geometry of Contextualized Word Representations</title>
      <author><first>Evan</first><last>Hernandez</last></author>
      <author><first>Jacob</first><last>Andreas</last></author>
      <pages>82–93</pages>
      <abstract>Black-box probing models can reliably extract linguistic features like tense, number, and syntactic role from pretrained word representations. However, the manner in which these features are encoded in representations remains poorly understood. We present a systematic study of the linear geometry of contextualized word representations in ELMO and BERT. We show that a variety of linguistic features (including structured dependency relationships) are encoded in low-dimensional subspaces. We then refine this geometric picture, showing that there are hierarchical relations between the subspaces encoding general linguistic categories and more specific ones, and that low-dimensional feature encodings are distributed rather than aligned to individual neurons. Finally, we demonstrate that these linear subspaces are causally related to model behavior, and can be used to perform fine-grained manipulation of BERT’s output distribution.</abstract>
      <url hash="6ae74c58">2021.conll-1.7</url>
      <bibkey>hernandez-andreas-2021-low</bibkey>
      <doi>10.18653/v1/2021.conll-1.7</doi>
      <video href="2021.conll-1.7.mp4"/>
    </paper>
    <paper id="8">
      <title>Generalising to <fixed-case>G</fixed-case>erman Plural Noun Classes, from the Perspective of a Recurrent Neural Network</title>
      <author><first>Verna</first><last>Dankers</last></author>
      <author><first>Anna</first><last>Langedijk</last></author>
      <author><first>Kate</first><last>McCurdy</last></author>
      <author><first>Adina</first><last>Williams</last></author>
      <author><first>Dieuwke</first><last>Hupkes</last></author>
      <pages>94–108</pages>
      <abstract>Inflectional morphology has since long been a useful testing ground for broader questions about generalisation in language and the viability of neural network models as cognitive models of language. Here, in line with that tradition, we explore how recurrent neural networks acquire the complex German plural system and reflect upon how their strategy compares to human generalisation and rule-based models of this system. We perform analyses including behavioural experiments, diagnostic classification, representation analysis and causal interventions, suggesting that the models rely on features that are also key predictors in rule-based models of German plurals. However, the models also display shortcut learning, which is crucial to overcome in search of more cognitively plausible generalisation behaviour.</abstract>
      <url hash="7d490210">2021.conll-1.8</url>
      <bibkey>dankers-etal-2021-generalising</bibkey>
      <doi>10.18653/v1/2021.conll-1.8</doi>
      <video href="2021.conll-1.8.mp4"/>
    </paper>
    <paper id="9">
      <title>Can Language Models Encode Perceptual Structure Without Grounding? A Case Study in Color</title>
      <author><first>Mostafa</first><last>Abdou</last></author>
      <author><first>Artur</first><last>Kulmizev</last></author>
      <author><first>Daniel</first><last>Hershcovich</last></author>
      <author><first>Stella</first><last>Frank</last></author>
      <author><first>Ellie</first><last>Pavlick</last></author>
      <author><first>Anders</first><last>Søgaard</last></author>
      <pages>109–132</pages>
      <abstract>Pretrained language models have been shown to encode relational information, such as the relations between entities or concepts in knowledge-bases — (Paris, Capital, France). However, simple relations of this type can often be recovered heuristically and the extent to which models implicitly reflect topological structure that is grounded in world, such as perceptual structure, is unknown. To explore this question, we conduct a thorough case study on color. Namely, we employ a dataset of monolexemic color terms and color chips represented in CIELAB, a color space with a perceptually meaningful distance metric. Using two methods of evaluating the structural alignment of colors in this space with text-derived color term representations, we find significant correspondence. Analyzing the differences in alignment across the color spectrum, we find that warmer colors are, on average, better aligned to the perceptual color space than cooler ones, suggesting an intriguing connection to findings from recent work on efficient communication in color naming. Further analysis suggests that differences in alignment are, in part, mediated by collocationality and differences in syntactic usage, posing questions as to the relationship between color perception and usage and context.</abstract>
      <url hash="b50390ec">2021.conll-1.9</url>
      <bibkey>abdou-etal-2021-language</bibkey>
      <doi>10.18653/v1/2021.conll-1.9</doi>
      <video href="2021.conll-1.9.mp4"/>
    </paper>
    <paper id="10">
      <title>Empathetic Dialog Generation with Fine-Grained Intents</title>
      <author><first>Yubo</first><last>Xie</last></author>
      <author><first>Pearl</first><last>Pu</last></author>
      <pages>133–147</pages>
      <abstract>Empathetic dialog generation aims at generating coherent responses following previous dialog turns and, more importantly, showing a sense of caring and a desire to help. Existing models either rely on pre-defined emotion labels to guide the response generation, or use deterministic rules to decide the emotion of the response. With the advent of advanced language models, it is possible to learn subtle interactions directly from the dataset, providing that the emotion categories offer sufficient nuances and other non-emotional but emotional regulating intents are included. In this paper, we describe how to incorporate a taxonomy of 32 emotion categories and 8 additional emotion regulating intents to succeed the task of empathetic response generation. To facilitate the training, we also curated a large-scale emotional dialog dataset from movie subtitles. Through a carefully designed crowdsourcing experiment, we evaluated and demonstrated how our model produces more empathetic dialogs compared with its baselines.</abstract>
      <url hash="0c3c2d54">2021.conll-1.10</url>
      <attachment type="Software" hash="b7e92b5b">2021.conll-1.10.Software.zip</attachment>
      <bibkey>xie-pu-2021-empathetic</bibkey>
      <doi>10.18653/v1/2021.conll-1.10</doi>
      <video href="2021.conll-1.10.mp4"/>
      <pwccode url="https://github.com/yuboxie/meed2" additional="false">yuboxie/meed2</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/emotionlines">EmotionLines</pwcdataset>
    </paper>
    <paper id="11">
      <title>Enriching Language Models with Visually-grounded Word Vectors and the <fixed-case>L</fixed-case>ancaster Sensorimotor Norms</title>
      <author><first>Casey</first><last>Kennington</last></author>
      <pages>148–157</pages>
      <abstract>Language models are trained only on text despite the fact that humans learn their first language in a highly interactive and multimodal environment where the first set of learned words are largely concrete, denoting physical entities and embodied states. To enrich language models with some of this missing experience, we leverage two sources of information: (1) the Lancaster Sensorimotor norms, which provide ratings (means and standard deviations) for over 40,000 English words along several dimensions of embodiment, and which capture the extent to which something is experienced across 11 different sensory modalities, and (2) vectors from coefficients of binary classifiers trained on images for the BERT vocabulary. We pre-trained the ELECTRA model and fine-tuned the RoBERTa model with these two sources of information then evaluate using the established GLUE benchmark and the Visual Dialog benchmark. We find that enriching language models with the Lancaster norms and image vectors improves results in both tasks, with some implications for robust language models that capture holistic linguistic meaning in a language learning context.</abstract>
      <url hash="18495466">2021.conll-1.11</url>
      <bibkey>kennington-2021-enriching</bibkey>
      <doi>10.18653/v1/2021.conll-1.11</doi>
      <video href="2021.conll-1.11.mp4"/>
      <pwcdataset url="https://paperswithcode.com/dataset/conceptual-captions">Conceptual Captions</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/glue">GLUE</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/visdial">VisDial</pwcdataset>
    </paper>
    <paper id="12">
      <title>Learning Zero-Shot Multifaceted Visually Grounded Word Embeddings via Multi-Task Training</title>
      <author><first>Hassan</first><last>Shahmohammadi</last></author>
      <author><first>Hendrik P. A.</first><last>Lensch</last></author>
      <author><first>R. Harald</first><last>Baayen</last></author>
      <pages>158–170</pages>
      <abstract>Language grounding aims at linking the symbolic representation of language (e.g., words) into the rich perceptual knowledge of the outside world. The general approach is to embed both textual and visual information into a common space -the grounded space- confined by an explicit relationship. We argue that since concrete and abstract words are processed differently in the brain, such approaches sacrifice the abstract knowledge obtained from textual statistics in the process of acquiring perceptual information. The focus of this paper is to solve this issue by implicitly grounding the word embeddings. Rather than learning two mappings into a joint space, our approach integrates modalities by implicit alignment. This is achieved by learning a reversible mapping between the textual and the grounded space by means of multi-task training. Intrinsic and extrinsic evaluations show that our way of visual grounding is highly beneficial for both abstract and concrete words. Our embeddings are correlated with human judgments and outperform previous works using pretrained word embeddings on a wide range of benchmarks. Our grounded embeddings are publicly available here.</abstract>
      <url hash="6386e0f9">2021.conll-1.12</url>
      <bibkey>shahmohammadi-etal-2021-learning</bibkey>
      <doi>10.18653/v1/2021.conll-1.12</doi>
      <video href="2021.conll-1.12.mp4"/>
      <pwccode url="https://github.com/Hazel1994/Visually_Grounded_Word_Embeddings" additional="false">Hazel1994/Visually_Grounded_Word_Embeddings</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/coco">COCO</pwcdataset>
    </paper>
    <paper id="13">
      <title>Does language help generalization in vision models?</title>
      <author><first>Benjamin</first><last>Devillers</last></author>
      <author><first>Bhavin</first><last>Choksi</last></author>
      <author><first>Romain</first><last>Bielawski</last></author>
      <author><first>Rufin</first><last>VanRullen</last></author>
      <pages>171–182</pages>
      <abstract>Vision models trained on multimodal datasets can benefit from the wide availability of large image-caption datasets. A recent model (CLIP) was found to generalize well in zero-shot and transfer learning settings. This could imply that linguistic or “semantic grounding” confers additional generalization abilities to the visual feature space. Here, we systematically evaluate various multimodal architectures and vision-only models in terms of unsupervised clustering, few-shot learning, transfer learning and adversarial robustness. In each setting, multimodal training produced no additional generalization capability compared to standard supervised visual training. We conclude that work is still required for semantic grounding to help improve vision models.</abstract>
      <url hash="c19a04c3">2021.conll-1.13</url>
      <bibkey>devillers-etal-2021-language</bibkey>
      <doi>10.18653/v1/2021.conll-1.13</doi>
      <video href="2021.conll-1.13.mp4"/>
      <pwccode url="https://github.com/bdvllrs/generalization-vision" additional="false">bdvllrs/generalization-vision</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/cifar-10">CIFAR-10</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/cifar-100">CIFAR-100</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/coco">COCO</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/cub-200-2011">CUB-200-2011</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/fashion-mnist">Fashion-MNIST</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/howto100m">HowTo100M</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/svhn">SVHN</pwcdataset>
    </paper>
    <paper id="14">
      <title>Understanding Guided Image Captioning Performance across Domains</title>
      <author><first>Edwin G.</first><last>Ng</last></author>
      <author><first>Bo</first><last>Pang</last></author>
      <author><first>Piyush</first><last>Sharma</last></author>
      <author><first>Radu</first><last>Soricut</last></author>
      <pages>183–193</pages>
      <abstract>Image captioning models generally lack the capability to take into account user interest, and usually default to global descriptions that try to balance readability, informativeness, and information overload. We present a Transformer-based model with the ability to produce captions focused on specific objects, concepts or actions in an image by providing them as guiding text to the model. Further, we evaluate the quality of these guided captions when trained on Conceptual Captions which contain 3.3M image-level captions compared to Visual Genome which contain 3.6M object-level captions. Counter-intuitively, we find that guided captions produced by the model trained on Conceptual Captions generalize better on out-of-domain data. Our human-evaluation results indicate that attempting in-the-wild guided image captioning requires access to large, unrestricted-domain training datasets, and that increased style diversity (even without increasing the number of unique tokens) is a key factor for improved performance.</abstract>
      <url hash="2102e90d">2021.conll-1.14</url>
      <bibkey>ng-etal-2021-understanding</bibkey>
      <doi>10.18653/v1/2021.conll-1.14</doi>
      <video href="2021.conll-1.14.mp4"/>
      <pwccode url="https://github.com/google-research-datasets/T2-Guiding" additional="false">google-research-datasets/T2-Guiding</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/t2-guiding">T2 Guiding</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/conceptual-captions">Conceptual Captions</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/localized-narratives">Localized Narratives</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/visual-genome">Visual Genome</pwcdataset>
    </paper>
    <paper id="15">
      <title>Counterfactual Interventions Reveal the Causal Effect of Relative Clause Representations on Agreement Prediction</title>
      <author><first>Shauli</first><last>Ravfogel</last></author>
      <author><first>Grusha</first><last>Prasad</last></author>
      <author><first>Tal</first><last>Linzen</last></author>
      <author><first>Yoav</first><last>Goldberg</last></author>
      <pages>194–209</pages>
      <abstract>When language models process syntactically complex sentences, do they use their representations of syntax in a manner that is consistent with the grammar of the language? We propose AlterRep, an intervention-based method to address this question. For any linguistic feature of a given sentence, AlterRep generates counterfactual representations by altering how the feature is encoded, while leaving in- tact all other aspects of the original representation. By measuring the change in a model’s word prediction behavior when these counterfactual representations are substituted for the original ones, we can draw conclusions about the causal effect of the linguistic feature in question on the model’s behavior. We apply this method to study how BERT models of different sizes process relative clauses (RCs). We find that BERT variants use RC boundary information during word prediction in a manner that is consistent with the rules of English grammar; this RC boundary information generalizes to a considerable extent across different RC types, suggesting that BERT represents RCs as an abstract linguistic category.</abstract>
      <url hash="bcd5f605">2021.conll-1.15</url>
      <bibkey>ravfogel-etal-2021-counterfactual</bibkey>
      <doi>10.18653/v1/2021.conll-1.15</doi>
      <video href="2021.conll-1.15.mp4"/>
    </paper>
    <paper id="16">
      <title>Who’s on First?: Probing the Learning and Representation Capabilities of Language Models on Deterministic Closed Domains</title>
      <author><first>David</first><last>Demeter</last></author>
      <author><first>Doug</first><last>Downey</last></author>
      <pages>210–222</pages>
      <abstract>The capabilities of today’s natural language processing systems are typically evaluated using large datasets of curated questions and answers. While these are critical benchmarks of progress, they also suffer from weakness due to artificial distributions and incomplete knowledge. Artifacts arising from artificial distributions can overstate language model performance, while incomplete knowledge limits fine-grained analysis. In this work, we introduce a complementary benchmarking approach based on SimPlified Language Activity Traces (SPLAT). SPLATs are corpora of language encodings of activity in some closed domain (we study traces from chess and baseball games in this work). SPLAT datasets use naturally-arising distributions, allow the generation of question-answer pairs at scale, and afford complete knowledge in their closed domains. We show that language models of three different architectures can answer questions about world states using only verb-like encodings of activity. Our approach is extensible to new language models and additional question-answering tasks.</abstract>
      <url hash="51efaf81">2021.conll-1.16</url>
      <bibkey>demeter-downey-2021-whos</bibkey>
      <doi>10.18653/v1/2021.conll-1.16</doi>
      <video href="2021.conll-1.16.mp4"/>
      <pwccode url="https://github.com/daviddemeter/splatbenchmarks" additional="false">daviddemeter/splatbenchmarks</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/coqa">CoQA</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/glue">GLUE</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/decanlp">decaNLP</pwcdataset>
    </paper>
    <paper id="17">
      <title>Data Augmentation of Incorporating Real Error Patterns and Linguistic Knowledge for Grammatical Error Correction</title>
      <author><first>Xia</first><last>Li</last></author>
      <author><first>Junyi</first><last>He</last></author>
      <pages>223–233</pages>
      <abstract>Data augmentation aims at expanding training data with clean text using noising schemes to improve the performance of grammatical error correction (GEC). In practice, there are a great number of real error patterns in the manually annotated training data. We argue that these real error patterns can be introduced into clean text to effectively generate more real and high quality synthetic data, which is not fully explored by previous studies. Moreover, we also find that linguistic knowledge can be incorporated into data augmentation for generating more representative and more diverse synthetic data. In this paper, we propose a novel data augmentation method that fully considers the real error patterns and the linguistic knowledge for the GEC task. We conduct extensive experiments on public data sets and the experimental results show that our method outperforms several strong baselines with far less external unlabeled clean text data, highlighting its extraordinary effectiveness in the GEC task that lacks large-scale labeled training data.</abstract>
      <url hash="548cf5a9">2021.conll-1.17</url>
      <bibkey>li-he-2021-data</bibkey>
      <doi>10.18653/v1/2021.conll-1.17</doi>
      <video href="2021.conll-1.17.mp4"/>
      <pwcdataset url="https://paperswithcode.com/dataset/billion-word-benchmark">Billion Word Benchmark</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/fce">FCE</pwcdataset>
    </paper>
    <paper id="18">
      <title>Agree to Disagree: Analysis of Inter-Annotator Disagreements in Human Evaluation of Machine Translation Output</title>
      <author><first>Maja</first><last>Popović</last></author>
      <pages>234–243</pages>
      <abstract>This work describes an analysis of inter-annotator disagreements in human evaluation of machine translation output. The errors in the analysed texts were marked by multiple annotators under guidance of different quality criteria: adequacy, comprehension, and an unspecified generic mixture of adequacy and fluency. Our results show that different criteria result in different disagreements, and indicate that a clear definition of quality criterion can improve the inter-annotator agreement. Furthermore, our results show that for certain linguistic phenomena which are not limited to one or two words (such as word ambiguity or gender) but span over several words or even entire phrases (such as negation or relative clause), disagreements do not necessarily represent “errors” or “noise” but are rather inherent to the evaluation process. %These disagreements are caused by differences in error perception and/or the fact that there is no single correct translation of a text so that multiple solutions are possible. On the other hand, for some other phenomena (such as omission or verb forms) agreement can be easily improved by providing more precise and detailed instructions to the evaluators.</abstract>
      <url hash="2b979c2a">2021.conll-1.18</url>
      <bibkey>popovic-2021-agree</bibkey>
      <doi>10.18653/v1/2021.conll-1.18</doi>
    </paper>
    <paper id="19">
      <title>A Multilingual Benchmark for Probing Negation-Awareness with Minimal Pairs</title>
      <author><first>Mareike</first><last>Hartmann</last></author>
      <author><first>Miryam</first><last>de Lhoneux</last></author>
      <author><first>Daniel</first><last>Hershcovich</last></author>
      <author><first>Yova</first><last>Kementchedjhieva</last></author>
      <author><first>Lukas</first><last>Nielsen</last></author>
      <author><first>Chen</first><last>Qiu</last></author>
      <author><first>Anders</first><last>Søgaard</last></author>
      <pages>244–257</pages>
      <abstract>Negation is one of the most fundamental concepts in human cognition and language, and several natural language inference (NLI) probes have been designed to investigate pretrained language models’ ability to detect and reason with negation. However, the existing probing datasets are limited to English only, and do not enable controlled probing of performance in the absence or presence of negation. In response, we present a multilingual (English, Bulgarian, German, French and Chinese) benchmark collection of NLI examples that are grammatical and correctly labeled, as a result of manual inspection and reformulation. We use the benchmark to probe the negation-awareness of multilingual language models and find that models that correctly predict examples with negation cues, often fail to correctly predict their counter-examples without negation cues, even when the cues are irrelevant for semantic inference.</abstract>
      <url hash="b5dee3ad">2021.conll-1.19</url>
      <bibkey>hartmann-etal-2021-multilingual</bibkey>
      <doi>10.18653/v1/2021.conll-1.19</doi>
      <video href="2021.conll-1.19.mp4"/>
      <pwccode url="https://github.com/mahartmann/negationminpairs" additional="false">mahartmann/negationminpairs</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/multinli">MultiNLI</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/snli">SNLI</pwcdataset>
    </paper>
    <paper id="20">
      <title>Explainable Natural Language to Bash Translation using Abstract Syntax Tree</title>
      <author><first>Shikhar</first><last>Bharadwaj</last></author>
      <author><first>Shirish</first><last>Shevade</last></author>
      <pages>258–267</pages>
      <abstract>Natural language processing for program synthesis has been widely researched. In this work, we focus on generating Bash commands from natural language invocations with explanations. We propose a novel transformer based solution by utilizing Bash Abstract Syntax Trees and manual pages. Our method incorporates tree structure information in the transformer architecture and provides explanations for its predictions via alignment matrices between user invocation and manual page text. Our method performs on par with the state of the art performance on Natural Language Context to Command task and performs better than fine-tuned T5 and Seq2Seq models.</abstract>
      <url hash="c3cce084">2021.conll-1.20</url>
      <bibkey>bharadwaj-shevade-2021-explainable</bibkey>
      <doi>10.18653/v1/2021.conll-1.20</doi>
      <video href="2021.conll-1.20.mp4"/>
      <pwccode url="https://github.com/shikhar-s/explainable-nl-to-bash-ast" additional="false">shikhar-s/explainable-nl-to-bash-ast</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/nlc2cmd">NLC2CMD</pwcdataset>
    </paper>
    <paper id="21">
      <title>Learned Construction Grammars Converge Across Registers Given Increased Exposure</title>
      <author><first>Jonathan</first><last>Dunn</last></author>
      <author><first>Harish</first><last>Tayyar Madabushi</last></author>
      <pages>268–278</pages>
      <abstract>This paper measures the impact of increased exposure on whether learned construction grammars converge onto shared representations when trained on data from different registers. Register influences the frequency of constructions, with some structures common in formal but not informal usage. We expect that a grammar induction algorithm exposed to different registers will acquire different constructions. To what degree does increased exposure lead to the convergence of register-specific grammars? The experiments in this paper simulate language learning in 12 languages (half Germanic and half Romance) with corpora representing three registers (Twitter, Wikipedia, Web). These simulations are repeated with increasing amounts of exposure, from 100k to 2 million words, to measure the impact of exposure on the convergence of grammars. The results show that increased exposure does lead to converging grammars across all languages. In addition, a shared core of register-universal constructions remains constant across increasing amounts of exposure.</abstract>
      <url hash="512c7443">2021.conll-1.21</url>
      <bibkey>dunn-tayyar-madabushi-2021-learned</bibkey>
      <doi>10.18653/v1/2021.conll-1.21</doi>
      <video href="2021.conll-1.21.mp4"/>
    </paper>
    <paper id="22">
      <title>Tokenization Repair in the Presence of Spelling Errors</title>
      <author><first>Hannah</first><last>Bast</last></author>
      <author><first>Matthias</first><last>Hertel</last></author>
      <author><first>Mostafa M.</first><last>Mohamed</last></author>
      <pages>279–289</pages>
      <abstract>We consider the following tokenization repair problem: Given a natural language text with any combination of missing or spurious spaces, correct these. Spelling errors can be present, but it’s not part of the problem to correct them. For example, given: “Tispa per isabout token izaionrep air”, compute “Tis paper is about tokenizaion repair”. We identify three key ingredients of high-quality tokenization repair, all missing from previous work: deep language models with a bidirectional component, training the models on text with spelling errors, and making use of the space information already present. Our methods also improve existing spell checkers by fixing not only more tokenization errors but also more spelling errors: once it is clear which characters form a word, it is much easier for them to figure out the correct word. We provide six benchmarks that cover three use cases (OCR errors, text extraction from PDF, human errors) and the cases of partially correct space information and all spaces missing. We evaluate our methods against the best existing methods and a non-trivial baseline. We provide full reproducibility under https://ad.informatik.uni-freiburg.de/publications.</abstract>
      <url hash="b3fb406b">2021.conll-1.22</url>
      <bibkey>bast-etal-2021-tokenization</bibkey>
      <doi>10.18653/v1/2021.conll-1.22</doi>
      <video href="2021.conll-1.22.mp4"/>
      <pwccode url="https://github.com/ad-freiburg/tokenization-repair" additional="true">ad-freiburg/tokenization-repair</pwccode>
    </paper>
    <paper id="23">
      <title>A Coarse-to-Fine Labeling Framework for Joint Word Segmentation, <fixed-case>POS</fixed-case> Tagging, and Constituent Parsing</title>
      <author><first>Yang</first><last>Hou</last></author>
      <author><first>Houquan</first><last>Zhou</last></author>
      <author><first>Zhenghua</first><last>Li</last></author>
      <author><first>Yu</first><last>Zhang</last></author>
      <author><first>Min</first><last>Zhang</last></author>
      <author><first>Zhefeng</first><last>Wang</last></author>
      <author><first>Baoxing</first><last>Huai</last></author>
      <author><first>Nicholas Jing</first><last>Yuan</last></author>
      <pages>290–299</pages>
      <abstract>The most straightforward approach to joint word segmentation (WS), part-of-speech (POS) tagging, and constituent parsing is converting a word-level tree into a char-level tree, which, however, leads to two severe challenges. First, a larger label set (e.g., ≥ 600) and longer inputs both increase computational costs. Second, it is difficult to rule out illegal trees containing conflicting production rules, which is important for reliable model evaluation. If a POS tag (like VV) is above a phrase tag (like VP) in the output tree, it becomes quite complex to decide word boundaries. To deal with both challenges, this work proposes a two-stage coarse-to-fine labeling framework for joint WS-POS-PAR. In the coarse labeling stage, the joint model outputs a bracketed tree, in which each node corresponds to one of four labels (i.e., phrase, subphrase, word, subword). The tree is guaranteed to be legal via constrained CKY decoding. In the fine labeling stage, the model expands each coarse label into a final label (such as VP, VP*, VV, VV*). Experiments on Chinese Penn Treebank 5.1 and 7.0 show that our joint model consistently outperforms the pipeline approach on both settings of w/o and w/ BERT, and achieves new state-of-the-art performance.</abstract>
      <url hash="c09860d3">2021.conll-1.23</url>
      <bibkey>hou-etal-2021-coarse</bibkey>
      <doi>10.18653/v1/2021.conll-1.23</doi>
      <video href="2021.conll-1.23.mp4"/>
      <pwccode url="https://github.com/ironsword666/jointparser" additional="false">ironsword666/jointparser</pwccode>
    </paper>
    <paper id="24">
      <title>Understanding the Extent to which Content Quality Metrics Measure the Information Quality of Summaries</title>
      <author><first>Daniel</first><last>Deutsch</last></author>
      <author><first>Dan</first><last>Roth</last></author>
      <pages>300–309</pages>
      <abstract>Reference-based metrics such as ROUGE or BERTScore evaluate the content quality of a summary by comparing the summary to a reference. Ideally, this comparison should measure the summary’s information quality by calculating how much information the summaries have in common. In this work, we analyze the token alignments used by ROUGE and BERTScore to compare summaries and argue that their scores largely cannot be interpreted as measuring information overlap. Rather, they are better estimates of the extent to which the summaries discuss the same topics. Further, we provide evidence that this result holds true for many other summarization evaluation metrics. The consequence of this result is that the most frequently used summarization evaluation metrics do not align with the community’s research goal, to generate summaries with high-quality information. However, we conclude by demonstrating that a recently proposed metric, QAEval, which scores summaries using question-answering, appears to better capture information quality than current evaluations, highlighting a direction for future research.</abstract>
      <url hash="c39f1355">2021.conll-1.24</url>
      <bibkey>deutsch-roth-2021-understanding</bibkey>
      <doi>10.18653/v1/2021.conll-1.24</doi>
      <video href="2021.conll-1.24.mp4"/>
    </paper>
    <paper id="25">
      <title>Summary-Source Proposition-level Alignment: Task, Datasets and Supervised Baseline</title>
      <author><first>Ori</first><last>Ernst</last></author>
      <author><first>Ori</first><last>Shapira</last></author>
      <author><first>Ramakanth</first><last>Pasunuru</last></author>
      <author><first>Michael</first><last>Lepioshkin</last></author>
      <author><first>Jacob</first><last>Goldberger</last></author>
      <author><first>Mohit</first><last>Bansal</last></author>
      <author><first>Ido</first><last>Dagan</last></author>
      <pages>310–322</pages>
      <abstract>Aligning sentences in a reference summary with their counterparts in source documents was shown as a useful auxiliary summarization task, notably for generating training data for salience detection. Despite its assessed utility, the alignment step was mostly approached with heuristic unsupervised methods, typically ROUGE-based, and was never independently optimized or evaluated. In this paper, we propose establishing summary-source alignment as an explicit task, while introducing two major novelties: (1) applying it at the more accurate proposition span level, and (2) approaching it as a supervised classification task. To that end, we created a novel training dataset for proposition-level alignment, derived automatically from available summarization evaluation data. In addition, we crowdsourced dev and test datasets, enabling model development and proper evaluation. Utilizing these data, we present a supervised proposition alignment baseline model, showing improved alignment-quality over the unsupervised approach.</abstract>
      <url hash="e9ca9b2e">2021.conll-1.25</url>
      <bibkey>ernst-etal-2021-summary</bibkey>
      <doi>10.18653/v1/2021.conll-1.25</doi>
      <video href="2021.conll-1.25.mp4"/>
      <pwccode url="https://github.com/oriern/SuperPAL" additional="false">oriern/SuperPAL</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/multi-news">Multi-News</pwcdataset>
    </paper>
    <paper id="26">
      <title>Exploring Metaphoric Paraphrase Generation</title>
      <author><first>Kevin</first><last>Stowe</last></author>
      <author><first>Nils</first><last>Beck</last></author>
      <author><first>Iryna</first><last>Gurevych</last></author>
      <pages>323–336</pages>
      <abstract>Metaphor generation is a difficult task, and has seen tremendous improvement with the advent of deep pretrained models. We focus here on the specific task of metaphoric paraphrase generation, in which we provide a literal sentence and generate a metaphoric sentence which paraphrases that input. We compare naive, “free” generation models with those that exploit forms of control over the generation process, adding additional information based on conceptual metaphor theory. We evaluate two methods for generating paired training data, which is then used to train T5 models for free and controlled generation. We use crowdsourcing to evaluate the results, showing that free models tend to generate more fluent paraphrases, while controlled models are better at generating novel metaphors. We then analyze evaluation metrics, showing that different metrics are necessary to capture different aspects of metaphoric paraphrasing. We release our data and models, as well as our annotated results in order to facilitate development of better evaluation metrics.</abstract>
      <url hash="25165235">2021.conll-1.26</url>
      <bibkey>stowe-etal-2021-exploring</bibkey>
      <doi>10.18653/v1/2021.conll-1.26</doi>
      <video href="2021.conll-1.26.mp4"/>
      <pwccode url="https://github.com/ukplab/conll2021-metaphoric-paraphrase-generation" additional="false">ukplab/conll2021-metaphoric-paraphrase-generation</pwccode>
    </paper>
    <paper id="27">
      <title>Imposing Relation Structure in Language-Model Embeddings Using Contrastive Learning</title>
      <author><first>Christos</first><last>Theodoropoulos</last></author>
      <author><first>James</first><last>Henderson</last></author>
      <author><first>Andrei Catalin</first><last>Coman</last></author>
      <author><first>Marie-Francine</first><last>Moens</last></author>
      <pages>337–348</pages>
      <abstract>Though language model text embeddings have revolutionized NLP research, their ability to capture high-level semantic information, such as relations between entities in text, is limited. In this paper, we propose a novel contrastive learning framework that trains sentence embeddings to encode the relations in a graph structure. Given a sentence (unstructured text) and its graph, we use contrastive learning to impose relation-related structure on the token level representations of the sentence obtained with a CharacterBERT (El Boukkouri et al., 2020) model. The resulting relation-aware sentence embeddings achieve state-of-the-art results on the relation extraction task using only a simple KNN classifier, thereby demonstrating the success of the proposed method. Additional visualization by a tSNE analysis shows the effectiveness of the learned representation space compared to baselines. Furthermore, we show that we can learn a different space for named entity recognition, again using a contrastive learning objective, and demonstrate how to successfully combine both representation spaces in an entity-relation task.</abstract>
      <url hash="71988cb1">2021.conll-1.27</url>
      <bibkey>theodoropoulos-etal-2021-imposing</bibkey>
      <doi>10.18653/v1/2021.conll-1.27</doi>
      <video href="2021.conll-1.27.mp4"/>
      <pwccode url="https://github.com/christos42/CLDR_CLNER_models" additional="false">christos42/CLDR_CLNER_models</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/ade-corpus">Adverse Drug Events (ADE) Corpus</pwcdataset>
    </paper>
    <paper id="28">
      <title><fixed-case>NOPE</fixed-case>: A Corpus of Naturally-Occurring Presuppositions in <fixed-case>E</fixed-case>nglish</title>
      <author><first>Alicia</first><last>Parrish</last></author>
      <author><first>Sebastian</first><last>Schuster</last></author>
      <author><first>Alex</first><last>Warstadt</last></author>
      <author><first>Omar</first><last>Agha</last></author>
      <author><first>Soo-Hwan</first><last>Lee</last></author>
      <author><first>Zhuoye</first><last>Zhao</last></author>
      <author><first>Samuel R.</first><last>Bowman</last></author>
      <author><first>Tal</first><last>Linzen</last></author>
      <pages>349–366</pages>
      <abstract>Understanding language requires grasping not only the overtly stated content, but also making inferences about things that were left unsaid. These inferences include presuppositions, a phenomenon by which a listener learns about new information through reasoning about what a speaker takes as given. Presuppositions require complex understanding of the lexical and syntactic properties that trigger them as well as the broader conversational context. In this work, we introduce the Naturally-Occurring Presuppositions in English (NOPE) Corpus to investigate the context-sensitivity of 10 different types of presupposition triggers and to evaluate machine learning models’ ability to predict human inferences. We find that most of the triggers we investigate exhibit moderate variability. We further find that transformer-based models draw correct inferences in simple cases involving presuppositions, but they fail to capture the minority of exceptional cases in which human judgments reveal complex interactions between context and triggers.</abstract>
      <url hash="38b27a26">2021.conll-1.28</url>
      <bibkey>parrish-etal-2021-nope</bibkey>
      <doi>10.18653/v1/2021.conll-1.28</doi>
      <video href="2021.conll-1.28.mp4"/>
      <pwccode url="https://github.com/nyu-mll/nope" additional="false">nyu-mll/nope</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/anli">ANLI</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/multinli">MultiNLI</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/snli">SNLI</pwcdataset>
    </paper>
    <paper id="29">
      <title>Pragmatic competence of pre-trained language models through the lens of discourse connectives</title>
      <author><first>Lalchand</first><last>Pandia</last></author>
      <author><first>Yan</first><last>Cong</last></author>
      <author><first>Allyson</first><last>Ettinger</last></author>
      <pages>367–379</pages>
      <abstract>As pre-trained language models (LMs) continue to dominate NLP, it is increasingly important that we understand the depth of language capabilities in these models. In this paper, we target pre-trained LMs’ competence in pragmatics, with a focus on pragmatics relating to discourse connectives. We formulate cloze-style tests using a combination of naturally-occurring data and controlled inputs drawn from psycholinguistics. We focus on testing models’ ability to use pragmatic cues to predict discourse connectives, models’ ability to understand implicatures relating to connectives, and the extent to which models show humanlike preferences regarding temporal dynamics of connectives. We find that although models predict connectives reasonably well in the context of naturally-occurring data, when we control contexts to isolate high-level pragmatic cues, model sensitivity is much lower. Models also do not show substantial humanlike temporal preferences. Overall, the findings suggest that at present, dominant pre-training paradigms do not result in substantial pragmatic competence in our models.</abstract>
      <url hash="f0c810df">2021.conll-1.29</url>
      <bibkey>pandia-etal-2021-pragmatic</bibkey>
      <doi>10.18653/v1/2021.conll-1.29</doi>
      <video href="2021.conll-1.29.mp4"/>
    </paper>
    <paper id="30">
      <title>Predicting Text Readability from Scrolling Interactions</title>
      <author><first>Sian</first><last>Gooding</last></author>
      <author><first>Yevgeni</first><last>Berzak</last></author>
      <author><first>Tony</first><last>Mak</last></author>
      <author><first>Matt</first><last>Sharifi</last></author>
      <pages>380–390</pages>
      <abstract>Judging the readability of text has many important applications, for instance when performing text simplification or when sourcing reading material for language learners. In this paper, we present a 518 participant study which investigates how scrolling behaviour relates to the readability of English texts. We make our dataset publicly available and show that (1) there are statistically significant differences in the way readers interact with text depending on the text level, (2) such measures can be used to predict the readability of text, and (3) the background of a reader impacts their reading interactions and the factors contributing to text difficulty.</abstract>
      <url hash="111d2236">2021.conll-1.30</url>
      <bibkey>gooding-etal-2021-predicting</bibkey>
      <doi>10.18653/v1/2021.conll-1.30</doi>
      <video href="2021.conll-1.30.mp4"/>
      <pwccode url="https://github.com/siangooding/readability_scroll" additional="false">siangooding/readability_scroll</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/scroll-readability-dataset">Scroll Readability Dataset</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/onestopenglish">OneStopEnglish</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/onestopqa">OneStopQA</pwcdataset>
    </paper>
    <paper id="31">
      <title>Modeling the Interaction Between Perception-Based and Production-Based Learning in Children’s Early Acquisition of Semantic Knowledge</title>
      <author><first>Mitja</first><last>Nikolaus</last></author>
      <author><first>Abdellah</first><last>Fourtassi</last></author>
      <pages>391–407</pages>
      <abstract>Children learn the meaning of words and sentences in their native language at an impressive speed and from highly ambiguous input. To account for this learning, previous computational modeling has focused mainly on the study of perception-based mechanisms like cross-situational learning. However, children do not learn only by exposure to the input. As soon as they start to talk, they practice their knowledge in social interactions and they receive feedback from their caregivers. In this work, we propose a model integrating both perception- and production-based learning using artificial neural networks which we train on a large corpus of crowd-sourced images with corresponding descriptions. We found that production-based learning improves performance above and beyond perception-based learning across a wide range of semantic tasks including both word- and sentence-level semantics. In addition, we documented a synergy between these two mechanisms, where their alternation allows the model to converge on more balanced semantic knowledge. The broader impact of this work is to highlight the importance of modeling language learning in the context of social interactions where children are not only understood as passively absorbing the input, but also as actively participating in the construction of their linguistic knowledge.</abstract>
      <url hash="7bd45ec6">2021.conll-1.31</url>
      <attachment type="Software" hash="88614bb9">2021.conll-1.31.Software.zip</attachment>
      <bibkey>nikolaus-fourtassi-2021-modeling</bibkey>
      <doi>10.18653/v1/2021.conll-1.31</doi>
      <video href="2021.conll-1.31.mp4"/>
      <pwccode url="https://github.com/mitjanikolaus/perception-and-production-based-learning" additional="false">mitjanikolaus/perception-and-production-based-learning</pwccode>
    </paper>
    <paper id="32">
      <title>Scaffolded input promotes atomic organization in the recurrent neural network language model</title>
      <author><first>Philip A.</first><last>Huebner</last></author>
      <author><first>Jon A.</first><last>Willits</last></author>
      <pages>408–422</pages>
      <abstract>The recurrent neural network (RNN) language model is a powerful tool for learning arbitrary sequential dependencies in language data. Despite its enormous success in representing lexical sequences, little is known about the quality of the lexical representations that it acquires. In this work, we conjecture that it is straightforward to extract lexical representations (i.e. static word embeddings) from an RNN, but that the amount of semantic information that is encoded is limited when lexical items in the training data provide redundant semantic information. We conceptualize this limitation of the RNN as a failure to learn atomic internal states - states which capture information relevant to single word types without being influenced by redundant information provided by words with which they co-occur. Using a corpus of artificial language, we verify that redundancy in the training data yields non-atomic internal states, and propose a novel method for inducing atomic internal states. We show that 1) our method successfully induces atomic internal organization in controlled experiments, and 2) under more realistic conditions in which the training consists of child-directed language, application of our method improves the performance of lexical representations on a downstream semantic categorization task.</abstract>
      <url hash="5b2e87c6">2021.conll-1.32</url>
      <bibkey>huebner-willits-2021-scaffolded</bibkey>
      <doi>10.18653/v1/2021.conll-1.32</doi>
      <pwccode url="https://github.com/phueb/entropic" additional="false">phueb/entropic</pwccode>
    </paper>
    <paper id="33">
      <title>Grammatical Profiling for Semantic Change Detection</title>
      <author><first>Andrey</first><last>Kutuzov</last></author>
      <author><first>Lidia</first><last>Pivovarova</last></author>
      <author><first>Mario</first><last>Giulianelli</last></author>
      <pages>423–434</pages>
      <abstract>Semantics, morphology and syntax are strongly interdependent. However, the majority of computational methods for semantic change detection use distributional word representations which encode mostly semantics. We investigate an alternative method, grammatical profiling, based entirely on changes in the morphosyntactic behaviour of words. We demonstrate that it can be used for semantic change detection and even outperforms some distributional semantic methods. We present an in-depth qualitative and quantitative analysis of the predictions made by our grammatical profiling system, showing that they are plausible and interpretable.</abstract>
      <url hash="03e5f541">2021.conll-1.33</url>
      <bibkey>kutuzov-etal-2021-grammatical</bibkey>
      <doi>10.18653/v1/2021.conll-1.33</doi>
      <video href="2021.conll-1.33.mp4"/>
      <pwccode url="https://github.com/glnmario/semchange-profiling" additional="false">glnmario/semchange-profiling</pwccode>
    </paper>
    <paper id="34">
      <title>Deconstructing syntactic generalizations with minimalist grammars</title>
      <author><first>Marina</first><last>Ermolaeva</last></author>
      <pages>435–444</pages>
      <abstract>Within the currently dominant Minimalist framework for syntax (Chomsky, 1995, 2000), it is not uncommon to encounter multiple proposals for the same natural language pattern in the literature. We investigate the possibility of evaluating and comparing analyses of syntax phenomena, implemented as minimalist grammars (Stabler, 1997), from a quantitative point of view. This paper introduces a principled way of making linguistic generalizations by detecting and eliminating syntactic and phonological redundancies in the data. As proof of concept, we first provide a small step-by-step example transforming a naive grammar over unsegmented words into a linguistically motivated grammar over morphemes, and then discuss a description of the English auxiliary system, passives, and raising verbs produced by a prototype implementation of a procedure for automated grammar optimization.</abstract>
      <url hash="01ae985c">2021.conll-1.34</url>
      <bibkey>ermolaeva-2021-deconstructing</bibkey>
      <doi>10.18653/v1/2021.conll-1.34</doi>
      <video href="2021.conll-1.34.mp4"/>
    </paper>
    <paper id="35">
      <title>Relation-aware Bidirectional Path Reasoning for Commonsense Question Answering</title>
      <author><first>Junxing</first><last>Wang</last></author>
      <author><first>Xinyi</first><last>Li</last></author>
      <author><first>Zhen</first><last>Tan</last></author>
      <author><first>Xiang</first><last>Zhao</last></author>
      <author><first>Weidong</first><last>Xiao</last></author>
      <pages>445–453</pages>
      <abstract>Commonsense Question Answering is an important natural language processing (NLP) task that aims to predict the correct answer to a question through commonsense reasoning. Previous studies utilize pre-trained models on large-scale corpora such as BERT, or perform reasoning on knowledge graphs. However, these methods do not explicitly model the <i>relations</i> that connect entities, which are informational and can be used to enhance reasoning. To address this issue, we propose a relation-aware reasoning method. Our method uses a relation-aware graph neural network to capture the rich contextual information from both entities and relations. Compared with methods that use fixed relation embeddings from pre-trained models, our model dynamically updates relations with contextual information from a multi-source subgraph, built from multiple external knowledge sources. The enhanced representations of relations are then fed to a bidirectional reasoning module. A bidirectional attention mechanism is applied between the question sequence and the paths that connect entities, which provides us with transparent interpretability. Experimental results on the CommonsenseQA dataset illustrate that our method results in significant improvements over the baselines while also providing clear reasoning paths.</abstract>
      <url hash="235c3f2d">2021.conll-1.35</url>
      <bibkey>wang-etal-2021-relation</bibkey>
      <doi>10.18653/v1/2021.conll-1.35</doi>
      <video href="2021.conll-1.35.mp4"/>
      <pwcdataset url="https://paperswithcode.com/dataset/commonsenseqa">CommonsenseQA</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/conceptnet">ConceptNet</pwcdataset>
    </paper>
    <paper id="36">
      <title>Does referent predictability affect the choice of referential form? A computational approach using masked coreference resolution</title>
      <author><first>Laura</first><last>Aina</last></author>
      <author><first>Xixian</first><last>Liao</last></author>
      <author><first>Gemma</first><last>Boleda</last></author>
      <author><first>Matthijs</first><last>Westera</last></author>
      <pages>454–469</pages>
      <abstract>It is often posited that more predictable parts of a speaker’s meaning tend to be made less explicit, for instance using shorter, less informative words. Studying these dynamics in the domain of referring expressions has proven difficult, with existing studies, both psycholinguistic and corpus-based, providing contradictory results. We test the hypothesis that speakers produce less informative referring expressions (e.g., pronouns vs. full noun phrases) when the context is more informative about the referent, using novel computational estimates of referent predictability. We obtain these estimates training an existing coreference resolution system for English on a new task, masked coreference resolution, giving us a probability distribution over referents that is conditioned on the context but not the referring expression. The resulting system retains standard coreference resolution performance while yielding a better estimate of human-derived referent predictability than previous attempts. A statistical analysis of the relationship between model output and mention form supports the hypothesis that predictability affects the form of a mention, both its morphosyntactic type and its length.</abstract>
      <url hash="2f31102d">2021.conll-1.36</url>
      <bibkey>aina-etal-2021-referent</bibkey>
      <doi>10.18653/v1/2021.conll-1.36</doi>
      <video href="2021.conll-1.36.mp4"/>
      <pwccode url="https://github.com/amore-upf/masked-coreference" additional="false">amore-upf/masked-coreference</pwccode>
    </paper>
    <paper id="37">
      <title>Polar Embedding</title>
      <author><first>Ran</first><last>Iwamoto</last></author>
      <author><first>Ryosuke</first><last>Kohita</last></author>
      <author><first>Akifumi</first><last>Wachi</last></author>
      <pages>470–480</pages>
      <abstract>Hierarchical relationships are invaluable information for many natural language processing (NLP) tasks. Distributional representation has become a fundamental approach for encoding word relationships, particularly embeddings in hyperbolic space showed great performance in representing hierarchies by taking advantage of their spatial properties. However, most machine learning systems do not suppose to use in such complex non-Euclidean geometries. To achieve hierarchy representations in commonly used Euclidean space, we propose Polar Embedding that learns word embeddings with the polar coordinate system. Utilizing characteristics of polar coordinates, the hierarchy of words is expressed with two independent variables: radius (generality) and angles (similarity), and their variables are optimized separately. Polar embedding shows word hierarchies explicitly and allows us to use beneficial resources such as word frequencies or word generality annotations for computing radiuses. We introduce an optimization method for learning angles in limited ranges of polar coordinates, which combining a loss function controlling gradient and distribution uniformization. Experimental results on hypernymy datasets indicate that our approach outperforms other embeddings in low-dimensional Euclidean space and competitively performs even with hyperbolic embeddings, which possess a geometric advantage.</abstract>
      <url hash="8ca623a8">2021.conll-1.37</url>
      <attachment type="Software" hash="4e460f2e">2021.conll-1.37.Software.zip</attachment>
      <bibkey>iwamoto-etal-2021-polar</bibkey>
      <doi>10.18653/v1/2021.conll-1.37</doi>
      <video href="2021.conll-1.37.mp4"/>
    </paper>
    <paper id="38">
      <title>Commonsense Knowledge in Word Associations and <fixed-case>C</fixed-case>oncept<fixed-case>N</fixed-case>et</title>
      <author><first>Chunhua</first><last>Liu</last></author>
      <author><first>Trevor</first><last>Cohn</last></author>
      <author><first>Lea</first><last>Frermann</last></author>
      <pages>481–495</pages>
      <abstract>Humans use countless basic, shared facts about the world to efficiently navigate in their environment. This commonsense knowledge is rarely communicated explicitly, however, understanding how commonsense knowledge is represented in different paradigms is important for (a) a deeper understanding of human cognition and (b) augmenting automatic reasoning systems. This paper presents an in-depth comparison of two large-scale resources of general knowledge: ConceptNet, an engineered relational database, and SWOW, a knowledge graph derived from crowd-sourced word associations. We examine the structure, overlap and differences between the two graphs, as well as the extent of situational commonsense knowledge present in the two resources. We finally show empirically that both resources improve downstream task performance on commonsense reasoning benchmarks over text-only baselines, suggesting that large-scale word association data, which have been obtained for several languages through crowd-sourcing, can be a valuable complement to curated knowledge graphs.</abstract>
      <url hash="c036cde7">2021.conll-1.38</url>
      <bibkey>liu-etal-2021-commonsense</bibkey>
      <doi>10.18653/v1/2021.conll-1.38</doi>
      <video href="2021.conll-1.38.mp4"/>
      <pwcdataset url="https://paperswithcode.com/dataset/atomic">ATOMIC</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/commonsenseqa">CommonsenseQA</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/conceptnet">ConceptNet</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/mcscript">MCScript</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/openbookqa">OpenBookQA</pwcdataset>
    </paper>
    <paper id="39">
      <title>Cross-document Event Identity via Dense Annotation</title>
      <author><first>Adithya</first><last>Pratapa</last></author>
      <author><first>Zhengzhong</first><last>Liu</last></author>
      <author><first>Kimihiro</first><last>Hasegawa</last></author>
      <author><first>Linwei</first><last>Li</last></author>
      <author><first>Yukari</first><last>Yamakawa</last></author>
      <author><first>Shikun</first><last>Zhang</last></author>
      <author><first>Teruko</first><last>Mitamura</last></author>
      <pages>496–517</pages>
      <abstract>In this paper, we study the identity of textual events from different documents. While the complex nature of event identity is previously studied (Hovy et al., 2013), the case of events across documents is unclear. Prior work on cross-document event coreference has two main drawbacks. First, they restrict the annotations to a limited set of event types. Second, they insufficiently tackle the concept of event identity. Such annotation setup reduces the pool of event mentions and prevents one from considering the possibility of quasi-identity relations. We propose a dense annotation approach for cross-document event coreference, comprising a rich source of event mentions and a dense annotation effort between related document pairs. To this end, we design a new annotation workflow with careful quality control and an easy-to-use annotation interface. In addition to the links, we further collect overlapping event contexts, including time, location, and participants, to shed some light on the relation between identity decisions and context. We present an open-access dataset for cross-document event coreference, CDEC-WN, collected from English Wikinews and open-source our annotation toolkit to encourage further research on cross-document tasks.</abstract>
      <url hash="7d643b29">2021.conll-1.39</url>
      <bibkey>pratapa-etal-2021-cross</bibkey>
      <doi>10.18653/v1/2021.conll-1.39</doi>
      <video href="2021.conll-1.39.mp4"/>
      <pwccode url="https://github.com/adithya7/cdec-wikinews" additional="false">adithya7/cdec-wikinews</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/ecb">ECB+</pwcdataset>
    </paper>
    <paper id="40">
      <title>Tackling Zero Pronoun Resolution and Non-Zero Coreference Resolution Jointly</title>
      <author><first>Shisong</first><last>Chen</last></author>
      <author><first>Binbin</first><last>Gu</last></author>
      <author><first>Jianfeng</first><last>Qu</last></author>
      <author><first>Zhixu</first><last>Li</last></author>
      <author><first>An</first><last>Liu</last></author>
      <author><first>Lei</first><last>Zhao</last></author>
      <author><first>Zhigang</first><last>Chen</last></author>
      <pages>518–527</pages>
      <abstract>Zero pronoun resolution aims at recognizing dropped pronouns and pointing out their anaphoric mentions, while non-zero coreference resolution targets at clustering mentions referring to the same entity. Existing efforts often deal with the two problems separately regardless of their close essential correlations. In this paper, we investigate the possibility of jointly solving zero pronoun resolution and coreference resolution via a novel end-to-end neural model. Specifically, we design a gap-masked self-attention model that encodes gaps and tokens in the same space, where gaps could capture valuable contextual information according to their surrounding tokens while tokens could maintain original sequential information without disturbance. Additionally, we also propose a two-stage interaction mechanism to make full use of the exclusive relationship between zero pronouns and mentions. Our empirical study conducted on the OntoNotes 5.0 Chinese dataset shows that our model could outperform corresponding state-of-the-art approaches on both tasks.</abstract>
      <url hash="d5907136">2021.conll-1.40</url>
      <attachment type="Software" hash="6ae6e500">2021.conll-1.40.Software.zip</attachment>
      <bibkey>chen-etal-2021-tackling</bibkey>
      <doi>10.18653/v1/2021.conll-1.40</doi>
      <video href="2021.conll-1.40.mp4"/>
      <pwccode url="https://github.com/cheniison/e2e-joint-coref" additional="false">cheniison/e2e-joint-coref</pwccode>
    </paper>
    <paper id="41">
      <title>Negation-Instance Based Evaluation of End-to-End Negation Resolution</title>
      <author><first>Elizaveta</first><last>Sineva</last></author>
      <author><first>Stefan</first><last>Grünewald</last></author>
      <author><first>Annemarie</first><last>Friedrich</last></author>
      <author><first>Jonas</first><last>Kuhn</last></author>
      <pages>528–543</pages>
      <abstract>In this paper, we revisit the task of negation resolution, which includes the subtasks of cue detection (e.g. “not”, “never”) and scope resolution. In the context of previous shared tasks, a variety of evaluation metrics have been proposed. Subsequent works usually use different subsets of these, including variations and custom implementations, rendering meaningful comparisons between systems difficult. Examining the problem both from a linguistic perspective and from a downstream viewpoint, we here argue for a negation-instance based approach to evaluating negation resolution. Our proposed metrics correspond to expectations over per-instance scores and hence are intuitively interpretable. To render research comparable and to foster future work, we provide results for a set of current state-of-the-art systems for negation resolution on three English corpora, and make our implementation of the evaluation scripts publicly available.</abstract>
      <url hash="a1f1ddc1">2021.conll-1.41</url>
      <bibkey>sineva-etal-2021-negation</bibkey>
      <doi>10.18653/v1/2021.conll-1.41</doi>
      <video href="2021.conll-1.41.mp4"/>
      <pwccode url="https://github.com/boschresearch/negation_resolution_evaluation_conll2021" additional="false">boschresearch/negation_resolution_evaluation_conll2021</pwccode>
    </paper>
    <paper id="42">
      <title>Controlling Prosody in End-to-End <fixed-case>TTS</fixed-case>: A Case Study on Contrastive Focus Generation</title>
      <author><first>Siddique</first><last>Latif</last></author>
      <author><first>Inyoung</first><last>Kim</last></author>
      <author><first>Ioan</first><last>Calapodescu</last></author>
      <author><first>Laurent</first><last>Besacier</last></author>
      <pages>544–551</pages>
      <abstract>While End-2-End Text-to-Speech (TTS) has made significant progresses over the past few years, these systems still lack intuitive user controls over prosody. For instance, generating speech with fine-grained prosody control (prosodic prominence, contextually appropriate emotions) is still an open challenge. In this paper, we investigate whether we can control prosody directly from the input text, in order to code information related to contrastive focus which emphasizes a specific word that is contrary to the presuppositions of the interlocutor. We build and share a specific dataset for this purpose and show that it allows to train a TTS system were this fine-grained prosodic feature can be correctly conveyed using control tokens. Our evaluation compares synthetic and natural utterances and shows that prosodic patterns of contrastive focus (variations of Fo, Intensity and Duration) can be learnt accurately. Such a milestone is important to allow, for example, smart speakers to be programmatically controlled in terms of output prosody.</abstract>
      <url hash="1ea87db4">2021.conll-1.42</url>
      <bibkey>latif-etal-2021-controlling</bibkey>
      <doi>10.18653/v1/2021.conll-1.42</doi>
      <video href="2021.conll-1.42.mp4"/>
    </paper>
    <paper id="43">
      <title>A Large-scale Comprehensive Abusiveness Detection Dataset with Multifaceted Labels from <fixed-case>R</fixed-case>eddit</title>
      <author><first>Hoyun</first><last>Song</last></author>
      <author><first>Soo Hyun</first><last>Ryu</last></author>
      <author><first>Huije</first><last>Lee</last></author>
      <author><first>Jong</first><last>Park</last></author>
      <pages>552–561</pages>
      <abstract>As users in online communities suffer from severe side effects of abusive language, many researchers attempted to detect abusive texts from social media, presenting several datasets for such detection. However, none of them contain both comprehensive labels and contextual information, which are essential for thoroughly detecting all kinds of abusiveness from texts, since datasets with such fine-grained features demand a significant amount of annotations, leading to much increased complexity. In this paper, we propose a Comprehensive Abusiveness Detection Dataset (CADD), collected from the English Reddit posts, with multifaceted labels and contexts. Our dataset is annotated hierarchically for an efficient annotation through crowdsourcing on a large-scale. We also empirically explore the characteristics of our dataset and provide a detailed analysis for novel insights. The results of our experiments with strong pre-trained natural language understanding models on our dataset show that our dataset gives rise to meaningful performance, assuring its practicality for abusive language detection.</abstract>
      <url hash="beecf2a8">2021.conll-1.43</url>
      <bibkey>song-etal-2021-large</bibkey>
      <doi>10.18653/v1/2021.conll-1.43</doi>
      <video href="2021.conll-1.43.mp4"/>
      <pwccode url="https://github.com/nlpcl-lab/cadd_dataset" additional="false">nlpcl-lab/cadd_dataset</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/hate-speech">Hate Speech</pwcdataset>
    </paper>
    <paper id="44">
      <title><fixed-case>M</fixed-case>irror<fixed-case>W</fixed-case>i<fixed-case>C</fixed-case>: On Eliciting Word-in-Context Representations from Pretrained Language Models</title>
      <author><first>Qianchu</first><last>Liu</last></author>
      <author><first>Fangyu</first><last>Liu</last></author>
      <author><first>Nigel</first><last>Collier</last></author>
      <author><first>Anna</first><last>Korhonen</last></author>
      <author><first>Ivan</first><last>Vulić</last></author>
      <pages>562–574</pages>
      <abstract>Recent work indicated that pretrained language models (PLMs) such as BERT and RoBERTa can be transformed into effective sentence and word encoders even via simple self-supervised techniques. Inspired by this line of work, in this paper we propose a fully unsupervised approach to improving word-in-context (WiC) representations in PLMs, achieved via a simple and efficient WiC-targeted fine-tuning procedure: MirrorWiC. The proposed method leverages only raw texts sampled from Wikipedia, assuming no sense-annotated data, and learns context-aware word representations within a standard contrastive learning setup. We experiment with a series of standard and comprehensive WiC benchmarks across multiple languages. Our proposed fully unsupervised MirrorWiC models obtain substantial gains over off-the-shelf PLMs across all monolingual, multilingual and cross-lingual setups. Moreover, on some standard WiC benchmarks, MirrorWiC is even on-par with supervised models fine-tuned with in-task data and sense labels.</abstract>
      <url hash="1207684d">2021.conll-1.44</url>
      <bibkey>liu-etal-2021-mirrorwic</bibkey>
      <doi>10.18653/v1/2021.conll-1.44</doi>
      <video href="2021.conll-1.44.mp4"/>
      <pwccode url="https://github.com/cambridgeltl/mirrorwic" additional="false">cambridgeltl/mirrorwic</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/am2ico">AM2iCo</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/wic">WiC</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/wic-tsv">WiC-TSV</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/word-sense-disambiguation-a-unified">Word Sense Disambiguation: a Unified Evaluation Framework and Empirical Comparison</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/xl-wic">XL-WiC</pwcdataset>
    </paper>
    <paper id="45">
      <title>A Data Bootstrapping Recipe for Low-Resource Multilingual Relation Classification</title>
      <author><first>Arijit</first><last>Nag</last></author>
      <author><first>Bidisha</first><last>Samanta</last></author>
      <author><first>Animesh</first><last>Mukherjee</last></author>
      <author><first>Niloy</first><last>Ganguly</last></author>
      <author><first>Soumen</first><last>Chakrabarti</last></author>
      <pages>575–587</pages>
      <abstract>Relation classification (sometimes called ‘extraction’) requires trustworthy datasets for fine-tuning large language models, as well as for evaluation. Data collection is challenging for Indian languages, because they are syntactically and morphologically diverse, as well as different from resource-rich languages like English. Despite recent interest in deep generative models for Indian languages, relation classification is still not well-served by public data sets. In response, we present IndoRE, a dataset with 39K entity- and relation-tagged gold sentences in three Indian languages, plus English. We start with a multilingual BERT (mBERT) based system that captures entity span positions and type information and provides competitive monolingual relation classification. Using this system, we explore and compare transfer mechanisms between languages. In particular, we study the accuracy-efficiency tradeoff between expensive gold instances vs. translated and aligned ‘silver’ instances.</abstract>
      <url hash="22bad2c9">2021.conll-1.45</url>
      <bibkey>nag-etal-2021-data</bibkey>
      <doi>10.18653/v1/2021.conll-1.45</doi>
      <video href="2021.conll-1.45.mp4"/>
    </paper>
    <paper id="46">
      <title><fixed-case>FAST</fixed-case>: A carefully sampled and cognitively motivated dataset for distributional semantic evaluation</title>
      <author><first>Stefan</first><last>Evert</last></author>
      <author><first>Gabriella</first><last>Lapesa</last></author>
      <pages>588–595</pages>
      <abstract>What is the first word that comes to your mind when you hear giraffe, or damsel, or freedom? Such free associations contain a huge amount of information on the mental representations of the corresponding concepts, and are thus an extremely valuable testbed for the evaluation of semantic representations extracted from corpora. In this paper, we present FAST (Free ASsociation Tasks), a free association dataset for English rigorously sampled from two standard free association norms collections (the Edinburgh Associative Thesaurus and the University of South Florida Free Association Norms), discuss two evaluation tasks, and provide baseline results. In parallel, we discuss methodological considerations concerning the desiderata for a proper evaluation of semantic representations.</abstract>
      <url hash="f588f087">2021.conll-1.46</url>
      <bibkey>evert-lapesa-2021-fast</bibkey>
      <doi>10.18653/v1/2021.conll-1.46</doi>
      <video href="2021.conll-1.46.mp4"/>
    </paper>
    <paper id="47">
      <title>Automatic Error Type Annotation for <fixed-case>A</fixed-case>rabic</title>
      <author><first>Riadh</first><last>Belkebir</last></author>
      <author><first>Nizar</first><last>Habash</last></author>
      <pages>596–606</pages>
      <abstract>We present ARETA, an automatic error type annotation system for Modern Standard Arabic. We design ARETA to address Arabic’s morphological richness and orthographic ambiguity. We base our error taxonomy on the Arabic Learner Corpus (ALC) Error Tagset with some modifications. ARETA achieves a performance of 85.8% (micro average F1 score) on a manually annotated blind test portion of ALC. We also demonstrate ARETA’s usability by applying it to a number of submissions from the QALB 2014 shared task for Arabic grammatical error correction. The resulting analyses give helpful insights on the strengths and weaknesses of different submissions, which is more useful than the opaque M2 scoring metrics used in the shared task. ARETA employs a large Arabic morphological analyzer, but is completely unsupervised otherwise. We make ARETA publicly available.</abstract>
      <url hash="9d7458ed">2021.conll-1.47</url>
      <bibkey>belkebir-habash-2021-automatic</bibkey>
      <doi>10.18653/v1/2021.conll-1.47</doi>
      <video href="2021.conll-1.47.mp4"/>
      <pwccode url="https://github.com/camel-lab/arabic_error_type_annotation" additional="false">camel-lab/arabic_error_type_annotation</pwccode>
    </paper>
    <paper id="48">
      <title>The Emergence of the Shape Bias Results from Communicative Efficiency</title>
      <author><first>Eva</first><last>Portelance</last></author>
      <author><first>Michael C.</first><last>Frank</last></author>
      <author><first>Dan</first><last>Jurafsky</last></author>
      <author><first>Alessandro</first><last>Sordoni</last></author>
      <author><first>Romain</first><last>Laroche</last></author>
      <pages>607–623</pages>
      <abstract>By the age of two, children tend to assume that new word categories are based on objects’ shape, rather than their color or texture; this assumption is called the shape bias. They are thought to learn this bias by observing that their caregiver’s language is biased towards shape based categories. This presents a chicken and egg problem: if the shape bias must be present in the language in order for children to learn it, how did it arise in language in the first place? In this paper, we propose that communicative efficiency explains both how the shape bias emerged and why it persists across generations. We model this process with neural emergent language agents that learn to communicate about raw pixelated images. First, we show that the shape bias emerges as a result of efficient communication strategies employed by agents. Second, we show that pressure brought on by communicative need is also necessary for it to persist across generations; simply having a shape bias in an agent’s input language is insufficient. These results suggest that, over and above the operation of other learning strategies, the shape bias in human learners may emerge and be sustained by communicative pressures.</abstract>
      <url hash="f860bf92">2021.conll-1.48</url>
      <bibkey>portelance-etal-2021-emergence</bibkey>
      <doi>10.18653/v1/2021.conll-1.48</doi>
      <video href="2021.conll-1.48.mp4"/>
      <pwccode url="https://github.com/evaportelance/emergent-shape-bias" additional="false">evaportelance/emergent-shape-bias</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/clevr">CLEVR</pwcdataset>
    </paper>
    <paper id="49">
      <title><fixed-case>B</fixed-case>aby<fixed-case>BERT</fixed-case>a: Learning More Grammar With Small-Scale Child-Directed Language</title>
      <author><first>Philip A.</first><last>Huebner</last></author>
      <author><first>Elior</first><last>Sulem</last></author>
      <author><first>Fisher</first><last>Cynthia</last></author>
      <author><first>Dan</first><last>Roth</last></author>
      <pages>624–646</pages>
      <abstract>Transformer-based language models have taken the NLP world by storm. However, their potential for addressing important questions in language acquisition research has been largely ignored. In this work, we examined the grammatical knowledge of RoBERTa (Liu et al., 2019) when trained on a 5M word corpus of language acquisition data to simulate the input available to children between the ages 1 and 6. Using the behavioral probing paradigm, we found that a smaller version of RoBERTa-base that never predicts unmasked tokens, which we term BabyBERTa, acquires grammatical knowledge comparable to that of pre-trained RoBERTa-base - and does so with approximately 15X fewer parameters and 6,000X fewer words. We discuss implications for building more efficient models and the learnability of grammar from input available to children. Lastly, to support research on this front, we release our novel grammar test suite that is compatible with the small vocabulary of child-directed input.</abstract>
      <url hash="0b8dbb3a">2021.conll-1.49</url>
      <bibkey>huebner-etal-2021-babyberta</bibkey>
      <doi>10.18653/v1/2021.conll-1.49</doi>
      <video href="2021.conll-1.49.mp4"/>
      <pwcdataset url="https://paperswithcode.com/dataset/blimp">BLiMP</pwcdataset>
    </paper>
    <paper id="50">
      <title>Analysing Human Strategies of Information Transmission as a Function of Discourse Context</title>
      <author><first>Mario</first><last>Giulianelli</last></author>
      <author><first>Raquel</first><last>Fernández</last></author>
      <pages>647–660</pages>
      <abstract>Speakers are thought to use rational information transmission strategies for efficient communication (Genzel and Charniak, 2002; Aylett and Turk, 2004; Jaeger and Levy, 2007). Previous work analysing these strategies in sentence production has failed to take into account how the information content of sentences varies as a function of the available discourse context. In this study, we estimate sentence information content within discourse context. We find that speakers transmit information at a stable rate—i.e., rationally—in English newspaper articles but that this rate decreases in spoken open domain and written task-oriented dialogues. We also observe that speakers’ choices are not oriented towards local uniformity of information, which is another hypothesised rational strategy. We suggest that a more faithful model of communication should explicitly include production costs and goal-oriented rewards.</abstract>
      <url hash="284d5e39">2021.conll-1.50</url>
      <attachment type="Software" hash="09b8af38">2021.conll-1.50.Software.zip</attachment>
      <bibkey>giulianelli-fernandez-2021-analysing</bibkey>
      <doi>10.18653/v1/2021.conll-1.50</doi>
      <video href="2021.conll-1.50.mp4"/>
      <pwccode url="https://github.com/dmg-illc/uid-dialogue" additional="false">dmg-illc/uid-dialogue</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/photobook">PhotoBook</pwcdataset>
    </paper>
    <paper id="51">
      <title>Predicting non-native speech perception using the Perceptual Assimilation Model and state-of-the-art acoustic models</title>
      <author><first>Juliette</first><last>Millet</last></author>
      <author><first>Ioana</first><last>Chitoran</last></author>
      <author><first>Ewan</first><last>Dunbar</last></author>
      <pages>661–673</pages>
      <abstract>Our native language influences the way we perceive speech sounds, affecting our ability to discriminate non-native sounds. We compare two ideas about the influence of the native language on speech perception: the Perceptual Assimilation Model, which appeals to a mental classification of sounds into native phoneme categories, versus the idea that rich, fine-grained phonetic representations tuned to the statistics of the native language, are sufficient. We operationalise this idea using representations from two state-of-the-art speech models, a Dirichlet process Gaussian mixture model and the more recent wav2vec 2.0 model. We present a new, open dataset of French- and English-speaking participants’ speech perception behaviour for 61 vowel sounds from six languages. We show that phoneme assimilation is a better predictor than fine-grained phonetic modelling, both for the discrimination behaviour as a whole, and for predicting differences in discriminability associated with differences in native language background. We also show that wav2vec 2.0, while not good at capturing the effects of native language on speech perception, is complementary to information about native phoneme assimilation, and provides a good model of low-level phonetic representations, supporting the idea that both categorical and fine-grained perception are used during speech perception.</abstract>
      <url hash="97724f5f">2021.conll-1.51</url>
      <bibkey>millet-etal-2021-predicting</bibkey>
      <doi>10.18653/v1/2021.conll-1.51</doi>
      <video href="2021.conll-1.51.mp4"/>
    </paper>
    <paper id="52">
      <title>The Influence of Regional Pronunciation Variation on Children’s Spelling and the Potential Benefits of Accent Adapted Spellcheckers</title>
      <author><first>Emma</first><last>O’Neill</last></author>
      <author><first>Joe</first><last>Kenny</last></author>
      <author><first>Anthony</first><last>Ventresque</last></author>
      <author><first>Julie</first><last>Carson-Berndsen</last></author>
      <pages>674–683</pages>
      <abstract>A child who is unfamiliar with the correct spelling of a word often employs a “sound it out” approach: breaking the word down into its constituent sounds and then choosing letters to represent the identified sounds. This often results in a misspelling that is orthographically very different to the intended target. Recently, efforts have been made to develop phonetic based spellcheckers to tackle the more deviant nature of children’s misspellings. However, little work has been done to investigate the potential of spelling correction tools that incorporate regional pronunciation variation. If a child must first identify the sounds that make up a word, it stands to reason their pronunciation would influence this process. We investigate this hypothesis along with the feasibility and potential benefits of adapting spelling correction tools to more specific language variants - particularly Irish Accented English. We use misspelling data from schoolchildren across Ireland to adapt an existing English phonetic-based spellchecker and demonstrate improvements in performance. These results not only prompt consideration of language varieties in the development of spellcheckers but also contribute to existing literature on the role of regional accent in the acquisition of writing proficiency.</abstract>
      <url hash="061c5269">2021.conll-1.52</url>
      <bibkey>oneill-etal-2021-influence</bibkey>
      <doi>10.18653/v1/2021.conll-1.52</doi>
      <video href="2021.conll-1.52.mp4"/>
    </paper>
  </volume>
</collection>
