<?xml version='1.0' encoding='UTF-8'?>
<collection id="2023.jeptalnrecital">
  <volume id="coria" ingest-date="2023-06-25" type="proceedings">
    <meta>
      <booktitle>Actes de CORIA-TALN 2023. Actes de la 18e Conférence en Recherche d'Information et Applications (CORIA)</booktitle>
      <editor><first>Haïfa</first><last>Zargayouna</last></editor>
      <publisher>ATALA</publisher>
      <address>Paris, France</address>
      <month>6</month>
      <year>2023</year>
      <venue>jeptalnrecital</venue>
    </meta>
    <frontmatter>
      <url hash="50d313b5">2023.jeptalnrecital-coria.0</url>
      <bibkey>jep-taln-recital-2023-actes</bibkey>
    </frontmatter>
    <paper id="1">
      <title>Impact de l’apprentissage multi-labels actif appliqué aux transformers</title>
      <author><first>Maxime</first><last>Arens</last></author>
      <author><first>Charles</first><last>Teissèdre</last></author>
      <author><first>Lucile</first><last>Callebert</last></author>
      <author><first>Jose G</first><last>Moreno</last></author>
      <author><first>Mohand</first><last>Boughanem</last></author>
      <pages>2–17</pages>
      <abstract>L’Apprentissage Actif (AA) est largement utilisé en apprentissage automatique afin de réduire l’effort d’annotation. Bien que la plupart des travaux d’AA soient antérieurs aux transformers, le succès récent de ces architectures a conduit la communauté à revisiter l’AA dans le contexte des modèles de langues pré-entraînés.De plus, le mécanisme de fine-tuning, où seules quelques données annotées sont utilisées pour entraîner le modèle sur une nouvelle tâche, est parfaitement en accord avec l’objectif de l’AA. Nous proposons d’étudier l’impact de l’AA dans le contexte des transformers pour la tâche de classification multi-labels. Or la plupart des stratégies AA, lorsqu’elles sont appliquées à ces modèles, conduisent à des temps de calcul excessifs, ce qui empêche leur utilisation au cours d’une interaction homme-machine en temps réel. Afin de pallier ce problème, nous utilisons des stratégies d’AA basées sur l’incertitude. L’article compare six stratégies d’AA basées sur l’incertitude dans le contexte des transformers et montre que si deux stratégies améliorent invariablement les performances, les autres ne surpassent pas l’échantillonnage aléatoire. L’étude montre également que les stratégies performantes ont tendance à sélectionner des ensembles d’instances plus diversifiées pour l’annotation.</abstract>
      <url hash="58e2263e">2023.jeptalnrecital-coria.1</url>
      <language>fra</language>
      <bibkey>arens-etal-2023-impact</bibkey>
    </paper>
    <paper id="2">
      <title>Quelles évolutions sur cette loi ? Entre abstraction et hallucination dans le domaine du résumé de textes juridiques</title>
      <author><first>Nihed</first><last>Bendahman</last></author>
      <author><first>Karen</first><last>Pinel-Sauvagnat</last></author>
      <author><first>Gilles</first><last>Hubert</last></author>
      <author><first>Mokhtar Boumedyen</first><last>Billami</last></author>
      <pages>18–36</pages>
      <abstract>Résumer automatiquement des textes juridiques permettrait aux chargés de veille d’éviter une surcharge informationnelle et de gagner du temps sur une activité particulièrement chronophage. Dans cet article, nous présentons un corpus de textes juridiques en français associés à des résumés de référence produits par des experts, et cherchons à établir quels modèles génératifs de résumé sont les plus intéressants sur ces documents possédant de fortes spécificités métier. Nous étudions quatre modèles de l’état de l’art, que nous commençons à évaluer avec des métriques traditionnelles. Afin de comprendre en détail la capacité des modèles à transcrire les spécificités métiers, nous effectuons une analyse plus fine sur les entités d’intérêt. Nous évaluons notamment la couverture des résumés en termes d’entités, mais aussi l’apparition d’informations non présentes dans les documents d’origine, dites hallucinations. Les premiers résultats montrent que le contrôle des hallucinations est crucial dans les domaines de spécialité, particulièrement le juridique.</abstract>
      <url hash="c0917a39">2023.jeptalnrecital-coria.2</url>
      <language>fra</language>
      <bibkey>bendahman-etal-2023-quelles</bibkey>
    </paper>
    <paper id="3">
      <title>Augmentation de jeux de données <fixed-case>RI</fixed-case> pour la recherche conversationnelle à initiative mixte</title>
      <author><first>Pierre</first><last>Erbacher</last></author>
      <author><first>Philippe</first><last>Preux</last></author>
      <author><first>Jian-Yun</first><last>Nie</last></author>
      <author><first>Laure</first><last>Soulier</last></author>
      <pages>37–58</pages>
      <abstract>Une des particularités des systèmes de recherche conversationnelle est qu’ils impliquent des initiatives mixtes telles que des questions de clarification des requêtes générées par le système pour mieux comprendre le besoin utilisateur. L’évaluation de ces systèmes à grande échelle sur la tâche finale de RI est très difficile et nécessite des ensembles de données adéquats contenant de telles interactions. Cependant, les jeux de données actuels se concentrent uniquement sur les tâches traditionnelles de RI ad hoc ou sur les tâches de clarification de la requête. Pour combler cette lacune, nous proposons une méthodologie pour construire automatiquement des ensembles de données de RI conversationnelle à grande échelle à partir d’ensembles de données de RI ad hoc afin de faciliter les explorations sur la RI conversationnelle. Nous effectuons une évaluation approfondie montrant la qualité et la pertinence des interactions générées pour chaque requête initiale. Cet article montre la faisabilité et l’utilité de l’augmentation des ensembles de données de RI ad-hoc pour la RI conversationnelle.</abstract>
      <url hash="3aeecf1a">2023.jeptalnrecital-coria.3</url>
      <language>fra</language>
      <bibkey>erbacher-etal-2023-augmentation</bibkey>
    </paper>
    <paper id="4">
      <title>Apprentissage de sous-espaces de préfixes</title>
      <author><first>Louis</first><last>Falissard</last></author>
      <author><first>Vincent</first><last>Guigue</last></author>
      <author><first>Laure</first><last>Soulier</last></author>
      <pages>59–73</pages>
      <abstract>Cet article propose une nouvelle façon d’ajuster des modèles de langue en “Few-shot learning” se basant sur une méthode d’optimisation récemment introduite en vision informatique, l’apprentissage de sous-espaces de modèles. Cette méthode, permettant de trouver non pas un point minimum local de la fonction coût dans l’espace des paramètres du modèle, mais tout un simplexe associé à des valeurs basses, présente typiquement des capacités de généralisation supérieures aux solutions obtenues par ajustement traditionnel. L’adaptation de cette méthode aux gros modèles de langue n’est pas triviale mais son application aux méthodes d’ajustement dites “Parameter Efficient” est quant à elle relativement naturelle. On propose de plus une façon innovante d’utiliser le simplexe de solution étudié afin de revisiter la notion de guidage de l’ajustement d’un modèle par l’inférence d’une métrique de validation, problématique d’actualité en “few-shot learning”. On montre finalement que ces différentes contributions centrées autour de l’ajustement de sous-espaces de modèles est empiriquement associée à un gain considérable en performances de généralisation sur les tâches de compréhension du langage du benchmark GLUE, dans un contexte de “few-shot learning”.</abstract>
      <url hash="63b2ee0a">2023.jeptalnrecital-coria.4</url>
      <language>fra</language>
      <bibkey>falissard-etal-2023-apprentissage</bibkey>
    </paper>
    <paper id="5">
      <title>Recherche cross-modale pour répondre à des questions visuelles</title>
      <author><first>Paul</first><last>Lerner</last></author>
      <author><first>Ferret</first><last>Olivier</last></author>
      <author><first>Camille</first><last>Guinaudeau</last></author>
      <pages>74–92</pages>
      <abstract>Répondre à des questions visuelles à propos d’entités nommées (KVQAE) est une tâche difficile qui demande de rechercher des informations dans une base de connaissances multimodale. Nous étudions ici comment traiter cette tâche avec une recherche cross-modale et sa combinaison avec une recherche mono-modale, en se focalisant sur le modèle CLIP, un modèle multimodal entraîné sur des images appareillées à leur légende textuelle. Nos résultats démontrent la supériorité de la recherche cross-modale, mais aussi la complémentarité des deux, qui peuvent être combinées facilement. Nous étudions également différentes manières d’ajuster CLIP et trouvons que l’optimisation cross-modale est la meilleure solution, étant en adéquation avec son pré-entraînement. Notre méthode surpasse les approches précédentes, tout en étant plus simple et moins coûteuse. Ces gains de performance sont étudiés intrinsèquement selon la pertinence des résultats de la recherche et extrinsèquement selon l’exactitude de la réponse extraite par un module externe. Nous discutons des différences entre ces métriques et de ses implications pour l’évaluation de la KVQAE.</abstract>
      <url hash="b6101ed9">2023.jeptalnrecital-coria.5</url>
      <language>fra</language>
      <bibkey>lerner-etal-2023-recherche</bibkey>
    </paper>
    <paper id="6">
      <title>Adaptation de domaine pour la recherche dense par annotation automatique</title>
      <author><first>Minghan</first><last>Li</last></author>
      <author><first>Eric</first><last>Gaussier</last></author>
      <pages>93–110</pages>
      <abstract>Bien que la recherche d’information neuronale ait connu des améliorations, les modèles de recherche dense ont une capacité de généralisation à de nouveaux domaines limitée, contrairement aux modèles basés sur l’interaction. Les approches d’apprentissage adversarial et de génération de requêtes n’ont pas résolu ce problème. Cet article propose une approche d’auto-supervision utilisant des étiquettes de pseudo-pertinence automatiquement générées pour le domaine cible. Le modèle T53B est utilisé pour réordonner une liste de documents fournie par BM25 afin d’obtenir une annotation des exemples positifs. L’extraction des exemples négatifs est effectuée en explorant différentes stratégies. Les expériences montrent que cette approche aide le modèle dense sur le domaine cible et améliore l’approche de génération de requêtes GPL.</abstract>
      <url hash="a1018d15">2023.jeptalnrecital-coria.6</url>
      <language>fra</language>
      <bibkey>li-gaussier-2023-adaptation</bibkey>
    </paper>
    <paper id="7">
      <title>Extraction d’entités nommées à partir de descriptions d’espèces</title>
      <author><first>Maya</first><last>Sahraoui</last></author>
      <author><first>Vincent</first><last>Guigue</last></author>
      <author><first>Régine</first><last>Vignes-Lebbe</last></author>
      <author><first>Marc</first><last>Pignal</last></author>
      <pages>111–126</pages>
      <abstract>Les descriptions d’espèces contiennent des informations importantes sur les caractéristiques morphologiques des espèces, mais l’extraction de connaissances structurées à partir de ces descriptions est souvent chronophage. Nous proposons un modèle texte-graphe adapté aux descriptions d’espèces en utilisant la reconnaissance d’entités nommées (NER) faiblement supervisée. Après avoir extrait les entités nommées, nous reconstruisons les triplets en utilisant des règles de dépendance pour créer le graphe. Notre méthode permet de comparer différentes espèces sur la base de caractères morphologiques et de relier différentes sources de données. Les résultats de notre étude se concentrent sur notre modèle NER et démontrent qu’il est plus performant que les modèles de référence et qu’il constitue un outil précieux pour la communauté de l’écologie et de la biodiversité.</abstract>
      <url hash="8817be75">2023.jeptalnrecital-coria.7</url>
      <language>fra</language>
      <bibkey>sahraoui-etal-2023-extraction</bibkey>
    </paper>
    <paper id="8">
      <title>Le théâtre français du <fixed-case>XVII</fixed-case>e siècle : une expérience en catégorisation de textes</title>
      <author><first>Jacques</first><last>Savoy</last></author>
      <pages>127–138</pages>
      <abstract>La catégorisation de documents (attribution d’un texte à une ou plusieurs catégories prédéfinies) possède de multiples applications. Cette communication se focalise sur l’attribution d’auteur en analysant le style de vingt pièces de théâtre du XVIIe siècle. L’hypothèse que nous souhaitons vérifier admet que le véritable auteur est le nom apparaissant sur la couverture. Afin de vérifier la qualité de deux méthodes d’attribution, nous avons repris deux corpus additionnels basés sur des romans écrits en français et italien. Nous proposons une amélioration de la méthode Delta ainsi qu’une nouvelle grille d’analyse pour cette approche. Ensuite, nous avons appliqué ces approches sur notre collection de comédies. Les résultats démontrent que l’hypothèse de base doit être écartée. De plus, ces œuvres présentent des styles proches rendant toute attribution difficile.</abstract>
      <url hash="b18d8cf5">2023.jeptalnrecital-coria.8</url>
      <language>fra</language>
      <bibkey>savoy-2023-le</bibkey>
    </paper>
    <paper id="9">
      <title>Enrichissement des modèles de langue pré-entraînés par la distillation mutuelle des connaissances</title>
      <author><first>Raphaël</first><last>Sourty</last></author>
      <author><first>Jose G</first><last>Moreno</last></author>
      <author><first>François-Paul</first><last>Servant</last></author>
      <author><first>Lynda</first><last>Tamine</last></author>
      <pages>139–156</pages>
      <abstract>Les bases de connaissances sont des ressources essentielles dans un large éventail d’applications à forte intensité de connaissances. Cependant, leur incomplétude limite intrinsèquement leur utilisation et souligne l’importance de les compléter. À cette fin, la littérature a récemment adopté un point de vue de monde ouvert en associant la capacité des bases de connaissances à représenter des connaissances factuelles aux capacités des modèles de langage pré-entraînés (PLM) à capturer des connaissances linguistiques de haut niveau et contextuelles à partir de corpus de textes. Dans ce travail, nous proposons un cadre de distillation pour la complétion des bases de connaissances où les PLMs exploitent les étiquettes souples sous la forme de prédictions d’entités et de relations fournies par un modèle de plongements de bases de connaissances, tout en conservant leur pouvoir de prédiction d’entités sur de grandes collections des textes. Pour mieux s’adapter à la tâche de complétion des connaissances, nous étendons la modélisation traditionnelle du langage masqué des PLM à la prédiction d’entités et d’entités liées dans le contexte. Des expériences utilisant les tâches à forte intensité de connaissances dans le cadre du benchmark d’évaluation KILT montrent le potentiel de notre approche.</abstract>
      <url hash="2323fe21">2023.jeptalnrecital-coria.9</url>
      <language>fra</language>
      <bibkey>sourty-etal-2023-enrichissement</bibkey>
    </paper>
    <paper id="10">
      <title>Constitution de sous-fils de conversations d’emails</title>
      <author><first>Lionel</first><last>Tadonfouet Tadjou</last></author>
      <author><first>Eric</first><last>De La Clergerie</last></author>
      <author><first>Fabrice</first><last>Bourge</last></author>
      <author><first>Tiphaine</first><last>Marie</last></author>
      <pages>157–171</pages>
      <abstract>Les conversations d’emails en entreprise sont parfois difficiles à suivre par les collaborateurs car elles peuvent traiter de plusieurs sujets à la fois et impliquer de nombreux interlocuteurs. Pour faciliter la compréhension des messages clés, il est utile de créer des sous-fils de conversations. Dans notre étude, nous proposons un pipeline en deux étapes pour reconnaître les actes de dialogue dans les segments de texte d’une conversation et les relier pour améliorer l’accessibilité de l’information. Ce pipeline construit ainsi des paires de segments de texte transverses sur les emails d’une conversationfacilitant ainsi la compréhension des messages clés inhérents à celle-ci. A notre connaissance, c’est la première fois que cette problématique de constitution de fils de conversations est abordée sur les conversations d’emails. Nous avons annoté le corpus d’emails BC3 en actes de dialogues et mis enrelation les segments de texte de conversation d’emails de BC3.</abstract>
      <url hash="9552bf01">2023.jeptalnrecital-coria.10</url>
      <language>fra</language>
      <bibkey>tadonfouet-tadjou-etal-2023-constitution</bibkey>
    </paper>
    <paper id="11">
      <title>Intégration du raisonnement numérique dans les modèles de langue : État de l’art et direction de recherche</title>
      <author><first>Sarah</first><last>Abchiche</last></author>
      <author><first>Lynda</first><last>Said Lhadj</last></author>
      <author><first>Vincent</first><last>Guigue</last></author>
      <author><first>Laure</first><last>Soulier</last></author>
      <pages>173–184</pages>
      <abstract>Ces dernières années, les modèles de langue ont connu une évolution galopante grâce à l’augmentation de la puissance de calcul qui a rendu possible l’utilisation des réseaux de neurones. Parallèlement, l’intégration du raisonnement numérique dans les modèles de langue a suscité un intérêt grandissant. Pourtant, bien que l’entraînement des modèles de langue sur des données numériques soit devenu un paradigme courant, les modèles actuels ne parviennent pas à effectuer des calculs de manière satisfaisante. Pour y remédier, une solution est d’entraîner les modèles de langue à utiliser des outils externes tels qu’une calculatrice ou un “runtime” de code python pour effectuer le raisonnement numérique. L’objectif de ce papier est double, dans un premier temps nous passons en revue les travaux de l’état de l’art sur le raisonnement numérique dans les modèles de langue et dans un second temps nous discutons des différentes perspectives de recherche pour augmenter les compétences numériques des modèles.</abstract>
      <url hash="84894bd1">2023.jeptalnrecital-coria.11</url>
      <language>fra</language>
      <bibkey>abchiche-etal-2023-integration</bibkey>
    </paper>
    <paper id="12">
      <title>Reconnaissance d’Entités Nommées fondée sur des Modèles de Langue Enrichis avec des Définitions des Types d’Entités</title>
      <author><first>Jesús</first><last>Lovón Melgarejo</last></author>
      <author><first>Jose</first><last>Moreno</last></author>
      <author><first>Romaric</first><last>Besançon</last></author>
      <author><first>Olivier</first><last>Ferret</last></author>
      <author><first>Lynda</first><last>Tamine</last></author>
      <pages>185–194</pages>
      <abstract>Des études récentes ont identifié de nouveaux défis dans la tâche de reconnaissance d’entités nommées (NER), tels que la reconnaissance d’entités complexes qui ne sont pas des phrases nominales simples et/ou figurent dans des entrées textuelles courtes, avec une faible quantité d’informations contextuelles. Cet article propose une nouvelle approche qui relève ce défi, en se basant sur des modèles de langues pré-entraînés par enrichissement des définitions des types d’entités issus d’une base de connaissances. Les expériences menées dans le cadre de la tâche MultiCoNER I de SemEval ont montré que l’approche proposée permet d’atteindre des gains en performance par rapport aux modèles de référence de la tâche.</abstract>
      <url hash="b743ee36">2023.jeptalnrecital-coria.12</url>
      <language>fra</language>
      <bibkey>lovon-melgarejo-etal-2023-reconnaissance</bibkey>
    </paper>
    <paper id="13">
      <title>Entity Enhanced Attention Graph-Based Passages Retrieval</title>
      <author><first>Lucas</first><last>Albarede</last></author>
      <author><first>Lorraine</first><last>Goeuriot</last></author>
      <author><first>Philippe</first><last>Mulhem</last></author>
      <author><first>Claude</first><last>Le Pape-Gardeux</last></author>
      <author><first>Sylvain</first><last>Marie</last></author>
      <author><first>Trinidad</first><last>Chardin-Segui</last></author>
      <pages>196–200</pages>
      <abstract>Passage retrieval is crucial in specialized domains where documents are long and complex, such as patents, legal documents, scientific reports, etc. We explore in this paper the integration of Entities and passages in Heterogeneous Attention Graph Models dedicated to passage retrieval. We use the two passage retrieval architectures based on re-ranking proposed in [1]. We experiment our proposal on the TREC CAR Y3 Passage Retrieval Task. The results obtained show an improvement over state-of-the-art techniques and proves the effectiveness of the approach. Our experiments also show the importance of using adequate parameters for such approach.</abstract>
      <url hash="2a56f989">2023.jeptalnrecital-coria.13</url>
      <bibkey>albarede-etal-2023-entity</bibkey>
    </paper>
    <paper id="14">
      <title>Highlighting exact matching via marking strategies for ad hoc document ranking with pretrained contextualized language models</title>
      <author><first>Lila</first><last>Boualili</last></author>
      <author><first>Jose</first><last>Moreno</last></author>
      <author><first>Mohand</first><last>Boughanem</last></author>
      <pages>201–201</pages>
      <abstract>Les modèles de langue pré-entraînés (MLPs) à l’instar de BERT se sont révélés remarquablement efficaces pour le classement ad hoc. Contrairement aux modèles antérieurs à BERT qui nécessitent des composants neuronaux spécialisés pour capturer les différents aspects de la pertinence entre la requête et le document, les MLPs sont uniquement basés sur des blocs de “transformers” où l’attention est le seul mécanisme utilisé pour extraire des signaux à partir des interactions entre les termes de la requête et le document. Grâce à l’attention croisée du “transformer”, BERT s’est avéré être un modèle d’appariement sémantique efficace. Cependant, l’appariement exact reste un signal essentiel pour évaluer la pertinence d’un document par rapport à une requête de recherche d’informations, en dehors de l’appariement sémantique. Dans cet article, nous partons de l’hypothèse que BERT pourrait bénéficier d’indices explicites d’appariement exact pour mieux s’adapter à la tâche d’estimation de pertinence. Dans ce travail, nous explorons des stratégies d’intégration des signaux d’appariement exact en utilisant des “tokens” de marquage permettant de mettre en évidence les correspondances exactes entre les termes de la requête et ceux du document. Nous constatons que cette approche de marquage simple améliore de manière significative le modèle BERT vanille de référence. Nous démontrons empiriquement l’efficacité de notre approche par le biais d’expériences exhaustives sur trois collections standards en recherche d’information (RI). Les résultats montrent que les indices explicites de correspondance exacte transmis par le marquage sont bénéfiques pour des MLPs aussi bien BERT que pour ELECTRA. Nos résultats confirment que les indices traditionnels de RI, tels que la correspondance exacte de termes, sont toujours utiles pour les nouveaux modèles contextualisés pré-entraînés tels que BERT.</abstract>
      <url hash="f31af2c8">2023.jeptalnrecital-coria.14</url>
      <bibkey>boualili-etal-2023-highlighting</bibkey>
    </paper>
    <paper id="15">
      <title>Vers l’évaluation continue des systèmes de recherche d’information.</title>
      <author><first>Petra</first><last>Galuscakova</last></author>
      <author><first>Romain</first><last>Deveaud</last></author>
      <author><first>Gabriela</first><last>Gonzalez-Saez</last></author>
      <author><first>Philippe</first><last>Mulhem</last></author>
      <author><first>Lorraine</first><last>Goeuriot</last></author>
      <author><first>Florina</first><last>Piroi</last></author>
      <author><first>Martin</first><last>Popel</last></author>
      <pages>202–206</pages>
      <abstract>Cet article présente le corpus de données associé à la première campagne évaluation LongEval dans le cadre de CLEF 2023. L’objectif de cette évaluation est d’étudier comment les systèmes de recherche d’informations réagissent à l’évolution des données qu’ils manipulent (notamment les documents et les requêtes). Nous détaillons les objectifs de la tâche, le processus d’acquisition des données et les mesures d’évaluation utilisées.</abstract>
      <url hash="344e039f">2023.jeptalnrecital-coria.15</url>
      <language>fra</language>
      <bibkey>galuscakova-etal-2023-vers</bibkey>
    </paper>
    <paper id="16">
      <title><fixed-case>C</fixed-case>o<fixed-case>SPLADE</fixed-case> : Adaptation d’un Modèle Neuronal Basé sur des Représentations Parcimonieuses pour la Recherche d’Information Conversationnelle</title>
      <author><first>Nam</first><last>Le Hai</last></author>
      <author><first>Thomas</first><last>Gerald</last></author>
      <author><first>Thibault</first><last>Formal</last></author>
      <author><first>Jian-Yun</first><last>Nie</last></author>
      <author><first>Benjamin</first><last>Piwowarksi</last></author>
      <author><first>Laure</first><last>Soulier</last></author>
      <pages>207–212</pages>
      <abstract>La recherche conversationnelle est une tâche qui vise à retrouver des documents à partir de la questioncourante de l’utilisateur ainsi que l’historique complet de la conversation. La plupart des méthodesantérieures sont basées sur une approche multi-étapes reposant sur une reformulation de la question.Cette étape de reformulation est critique, car elle peut conduire à un classement sous-optimal des do-cuments. D’autres approches ont essayé d’ordonner directement les documents, mais s’appuient pourla plupart sur un jeu de données contenant des pseudo-labels. Dans ce travail, nous proposons une tech-nique d’apprentissage à la fois “légère” et innovante pour un modèle contextualisé d’ordonnancementbasé sur SPLADE. En s’appuyant sur les représentations parcimonieuses de SPLADE, nous montronsque notre modèle, lorsqu’il est combiné avec le modèle de ré-ordonnancement T5Mono, obtient desrésultats qui sont compétitifs avec ceux obtenus par les participants des campagnes d’évaluation TRECCAsT 2020 et 2021. Le code source est disponible sur https://github.com/anonymous.</abstract>
      <url hash="76554917">2023.jeptalnrecital-coria.16</url>
      <language>fra</language>
      <bibkey>le-hai-etal-2023-cosplade</bibkey>
    </paper>
    <paper id="17">
      <title>The Power of Selecting Key Blocks with Local Pre-ranking for Long Document Information Retrieval</title>
      <author><first>Minghan</first><last>Li</last></author>
      <author><first>Diana Nicoleta</first><last>Popa</last></author>
      <author><first>Johan</first><last>Chagnon</last></author>
      <author><first>Yagmur Gizem</first><last>Cinar</last></author>
      <author><first>Eric</first><last>Gaussier</last></author>
      <pages>213–213</pages>
      <abstract>Les réseaux neuronaux profonds et les modèles fondés sur les transformeurs comme BERT ont envahi le domaine de la recherche d’informations (RI) ces dernières années. Leur succès est lié au mécanisme d’auto-attention qui permet de capturer les dépendances entre les mots indépendamment de leur distance. Cependant, en raison de sa complexité quadratique dans le nombre de mots, ce mécanisme ne peut être directement utilisé sur de longues séquences, ce qui ne permet pas de déployer entièrement les modèles neuronaux sur des documents longs pouvant contenir des milliers de mots. Trois stratégies standard ont été adoptées pour contourner ce problème. La première consiste à tronquer les documents longs, la deuxième à segmenter les documents longs en passages plus courts et la dernière à remplacer le module d’auto-attention par des modules d’attention parcimonieux. Dans le premier cas, des informations importantes peuvent être perdues et le jugement de pertinence n’est fondé que sur une partie de l’information contenue dans le document. Dans le deuxième cas, une architecture hiérarchique peut être adoptée pour construire une représentation du document sur la base des représentations de chaque passage. Cela dit, malgré ses résultats prometteurs, cette stratégie reste coûteuse en temps, en mémoire et en énergie. Dans le troisième cas, les contraintes de parcimonie peuvent conduire à manquer des dépendances importantes et, in fine, à des résultats sous-optimaux. L’approche que nous proposons est légèrement différente de ces stratégies et vise à capturer, dans les documents longs, les blocs les plus importants permettant de décider du statut, pertinent ou non, de l’ensemble du document. Elle repose sur trois étapes principales : (a) la sélection de blocs clés (c’est-à-dire susceptibles d’être pertinents) avec un pré-classement local en utilisant soit des modèles de RI classiques, soit un module d’apprentissage, (b) l’apprentissage d’une représentation conjointe des requêtes et des blocs clés à l’aide d’un modèle BERT standard, et (c) le calcul d’un score de pertinence final qui peut être considéré comme une agrégation d’informations de pertinence locale. Dans cet article, nous menons tout d’abord une analyse qui révèle que les signaux de pertinence peuvent apparaître à différents endroits dans les documents et que de tels signaux sont mieux capturés par des relations sémantiques que par des correspondances exactes. Nous examinons ensuite plusieurs méthodes pour sélectionner les blocs pertinents et montrons comment intégrer ces méthodes dans les modèles récents de RI.</abstract>
      <url hash="43d3316e">2023.jeptalnrecital-coria.17</url>
      <bibkey>li-etal-2023-power</bibkey>
    </paper>
    <paper id="18">
      <title>i<fixed-case>QPP</fixed-case>: Une Référence pour la Prédiction de Performances des Requêtes d’Images</title>
      <author><first>Eduard</first><last>Poesina</last></author>
      <author><first>Radu Tudor</first><last>Ionescu</last></author>
      <author><first>Josiane</first><last>Mothe</last></author>
      <pages>214–220</pages>
      <abstract>La prédiction de la performance des requêtes (QPP) dans le contexte de la recherche d’images basée sur le contenu reste une tâche largement inexplorée, en particulier dans le scénario de la recherche par l’exemple, où la requête est une image. Pour stimuler les recherches dans ce domaine, nous proposons la première collection de référence. Nous proposons un ensemble de quatre jeux de données (PASCAL VOC 2012, Caltech-101, ROxford5k et RParis6k) avec les performances attendues pour chaque requête à l’aide de deux modèles de recherche d’images état de l’art. Nous proposons également de nouveaux prédicteurs pré et post-recherche. Les résultats empiriques montrent que la plupart des prédicteurs ne se généralisent pas aux différents scénarios d’évaluation. Nos expériences exhaustives indiquent que l’iQPP est une référence difficile, révélant une importante lacune dans la recherche qui doit être abordée dans les travaux futurs. Nous publions notre code et nos données.</abstract>
      <url hash="00b98e85">2023.jeptalnrecital-coria.18</url>
      <language>fra</language>
      <bibkey>poesina-etal-2023-iqpp</bibkey>
    </paper>
    <paper id="19">
      <title><fixed-case>XPMIR</fixed-case>: Une bibliothèque modulaire pour l’apprentissage d’ordonnancement et les expériences de <fixed-case>RI</fixed-case> neuronale</title>
      <author><first>Yuxuan</first><last>Zong</last></author>
      <author><first>Benjamin</first><last>Piwowarski</last></author>
      <pages>222–233</pages>
      <abstract>Ces dernières années, plusieurs librairies pour la recherche d’information (neuronale) ont été proposées. Cependant, bien qu’elles permettent de reproduire des résultats déjà publiés, il est encore très difficile de réutiliser certaines parties des chaînes de traitement d’apprentissage, comme par exemple le pré-entraînement, la stratégie d’échantillonnage ou la définition du coût dans les modèles nouvellement développés. Il est également difficile d’utiliser de nouvelles techniques d’apprentissage avec d’anciens modèles, ce qui complique l’évaluation de l’utilité des nouvelles idées pour les différents modèles de RI neuronaux. Cela ralentit l’adoption de nouvelles techniques et, par conséquent, le développement du domaine de la RI. Dans cet article, nous présentons XPMIR, une librairie Python définissant un ensemble réutilisable de composants expérimentaux. La bibliothèque contient déjà des modèles et des techniques d’indexation de pointe, et est intégrée au hub HuggingFace.</abstract>
      <url hash="1ee7b885">2023.jeptalnrecital-coria.19</url>
      <language>fra</language>
      <bibkey>zong-piwowarski-2023-xpmir</bibkey>
    </paper>
  </volume>
  <volume id="rjc" ingest-date="2023-06-25" type="proceedings">
    <meta>
      <booktitle>Actes de CORIA-TALN 2023. Actes des 16e Rencontres Jeunes Chercheurs en RI (RJCRI) et 25e Rencontre des Étudiants Chercheurs \\ en Informatique pour le Traitement Automatique des Langues (RÉCITAL)</booktitle>
      <editor><first>Marie</first><last>Candito</last></editor>
      <editor><first>Thomas</first><last>Gerald</last></editor>
      <editor><first>José G</first><last>Moreno</last></editor>
      <publisher>ATALA</publisher>
      <address>Paris, France</address>
      <month>6</month>
      <year>2023</year>
      <venue>jeptalnrecital</venue>
    </meta>
    <frontmatter>
      <url hash="67f0e382">2023.jeptalnrecital-rjc.0</url>
      <bibkey>jep-taln-recital-2023-actes-de</bibkey>
    </frontmatter>
    <paper id="1">
      <title>Les jeux de données en compréhension du langage naturel et parlé : paradigmes d’annotation et représentations sémantiques</title>
      <author><first>Rim</first><last>Abrougui</last></author>
      <pages>1–20</pages>
      <abstract>La compréhension du langage naturel et parlé (NLU/SLU) couvre le problème d’extraire et d’annoter la structure sémantique, à partir des énoncés des utilisateurs dans le contexte des interactions humain/machine, telles que les systèmes de dialogue. Elle se compose souvent de deux tâches principales : la détection des intentions et la classification des concepts. Dans cet article, différents corpora SLU sont étudiés au niveau formel et sémantique : leurs différents formats d’annotations (à plat et structuré) et leurs ontologies ont été comparés et discutés. Avec leur pouvoir expressif gardant la hiérarchie sémantique entre les intentions et les concepts, les représentations sémantiques structurées sous forme de graphe ont été mises en exergue. En se positionnant vis à vis de la littérature et pour les futures études, une projection sémantique et une modification au niveau de l’ontologie du corpus MultiWOZ ont été proposées.</abstract>
      <url hash="ea655370">2023.jeptalnrecital-rjc.1</url>
      <language>fra</language>
      <bibkey>abrougui-2023-les</bibkey>
    </paper>
    <paper id="2">
      <title>Étude de la fidélité des entités dans les résumés par abstraction</title>
      <author><first>Eunice</first><last>Akani</last></author>
      <pages>21–36</pages>
      <abstract>L’un des problèmes majeurs dans le résumé automatique de texte par abstraction est la fidélité du résumé généré vis-à-vis du document. Les systèmes peuvent produire des informations incohérentes vis-à-vis du document. Ici, nous mettons l’accent sur ce phénomène en restant focalisé sur les entités nommées. L’objectif est de réduire les hallucinations sur celles-ci. Ainsi, nous avons généré des résumés par sampling et avons sélectionné, à l’aide d’un critère basé sur le risque d’hallucination sur les entités et les performances du modèle, ceux qui minimisent les hallucinations sur les entités. Une étude empirique du critère montre son adaptabilité pour la sélection de résumé. Nous avons proposé des heuristiques pour la détection des entités qui sont des variations ou flexions d’autres entités. Les résultats obtenus montrent que le critère réduit les hallucinations sur les entités nommées en gardant un score ROUGE comparable pour CNN/DM.</abstract>
      <url hash="878b64b7">2023.jeptalnrecital-rjc.2</url>
      <language>fra</language>
      <bibkey>akani-2023-etude</bibkey>
    </paper>
    <paper id="3">
      <title>Mise en place d’un modèle compact à architecture Transformer pour la détection jointe des intentions et des concepts dans le cadre d’un système interactif de questions-réponses</title>
      <author><first>Nadège</first><last>Alavoine</last></author>
      <author><first>Arthur</first><last>Babin</last></author>
      <pages>37–56</pages>
      <abstract>Les tâches de détection d’intention et d’identification des concepts sont toutes deux des éléments importants de la compréhension de la parole. Elles sont souvent réalisées par deux modules différents au sein d’un pipeline. L’apparition de modèles réalisant conjointement ces deux tâches a permis d’exploiter les dépendances entre elles et d’améliorer les performances obtenues. Plus récemment, des modèles de détection jointe reposant sur des architectures Transformer ont été décrits dans la littérature. Par ailleurs, avec la popularité et taille croissante des modèles Transformer ainsi que les inquiétudes ergonomiques et écologiques grandissantes, des modèles compacts ont été proposés. Dans cet article, nous présentons la mise en place et l’évaluation d’un modèle compact pour la détection jointe de l’intention et des concepts. Notre contexte applicatif est celui d’un système interactif de questions-réponses français.</abstract>
      <url hash="5573a1e0">2023.jeptalnrecital-rjc.3</url>
      <language>fra</language>
      <bibkey>alavoine-babin-2023-mise</bibkey>
    </paper>
    <paper id="4">
      <title>Utiliser les syntagmes nominaux complexes anglais pour évaluer la robustesse des systèmes de traduction anglais-français en langue de spécialité</title>
      <author><first>Maud</first><last>Bénard</last></author>
      <pages>57–71</pages>
      <abstract>Nous défendons l’idée que l’analyse des erreurs faites lors de la traduction des syntagmes nominaux complexes présente un intérêt pour évaluer la robustesse des systèmes de traduction automatique anglais-français en langue de spécialité. Ces constructions syntaxiques impliquent des questions de syntaxe et de lexique qui constituent un obstacle important à leur compréhension et leur production pour les locuteurs d’anglais non natifs. Nous soutenons que ces analyses contribueraient à garantir que les systèmes de TA répondent aux exigences linguistiques des utilisateurs finaux auxquels ils sont destinés.</abstract>
      <url hash="31c45ca1">2023.jeptalnrecital-rjc.4</url>
      <language>fra</language>
      <bibkey>benard-2023-utiliser</bibkey>
    </paper>
    <paper id="5">
      <title>Vers une implémentation de la théorie sens-texte avec les grammaires catégorielles abstraites</title>
      <author><first>Marie</first><last>Cousin</last></author>
      <pages>72–86</pages>
      <abstract>La théorie sens-texte est une théorie linguistique visant à décrire la correspondance entre le sens et le texte d’un énoncé à l’aide d’un outil formel qui simule l’activité langagière d’un locuteur natif. Nous avons mis en place une premiere implémentation de cette théorie à l’aide des grammaires catégorielles abstraites, qui sont un formalisme grammatical basé sur le lambda-calcul. Cette implémentation représente les trois niveaux de représentation sémantique, syntaxique profonde et syntaxique de surface de la théorie sens-texte. Elle montre que la transition de l’un à l’autre de ces niveaux (en particulier la génération d’une représentation de syntaxe de surface à partir d’une représentation sémantique d’un même énoncé) peut être implémentée en utilisant les propriétés avantageuses des grammaires catégorielles abstraites, dont la transduction.</abstract>
      <url hash="21ac028c">2023.jeptalnrecital-rjc.5</url>
      <language>fra</language>
      <bibkey>cousin-2023-vers</bibkey>
    </paper>
    <paper id="6">
      <title>Analyse de la légitimité des start-ups</title>
      <author><first>Asmaa</first><last>Lagrid</last></author>
      <pages>87–100</pages>
      <abstract>La légitimité est un élément crucial pour la stabilité et la survie des startups en phase de croissance. Ce concept est défini dans la littérature comme étant la perception de l’adéquation d’une organisation à un système social en termes de règles, valeurs, normes et définitions. En d’autres termes, la légitimité des startups repose sur l’alignement des jugements subjectifs avec les jugements objectifs des experts, basés sur les performances des startups. Cette mesure de la subjectivité de la légitimité est très similaire à l’analyse des sentiments financiers réalisée sur les entreprises pour évaluer leur santé financière et prendre des décisions d’investissement. Dans ce travail, nous présentons les travaux sur la légitimité et les avancées de l’analyse des sentiments qui peuvent nous aider à analyser la légitimité. Nous examinons également les similitudes et les différences entre la légitimité et l’analyse des sentiments financiers. Nous présentons une première expérimentation sur les annonces de projets sur une plateforme de crowdfunding, en utilisant le modèle DistilBERT, qui a déjà été largement utilisé pour la classification de texte. En conclusion, nous discutons des perspectives de notre recherche pour mesurer la légitimité des startups.</abstract>
      <url hash="6b752481">2023.jeptalnrecital-rjc.6</url>
      <language>fra</language>
      <bibkey>lagrid-2023-analyse</bibkey>
    </paper>
    <paper id="7">
      <title>Approches neuronales pour la détection des chaînes de coréférences : un état de l’art</title>
      <author><first>Fabien</first><last>Lopez</last></author>
      <pages>101–113</pages>
      <abstract>La résolution des liens de coréférences est une tâche importante du TALN impliquant cohérence et compréhension d’un texte. Nous présenterons dans ce papier une vision actuelle de l’état de l’art sur la résolution des liens de coréférence depuis 2013 et l’avènement des modèles neuronaux pour cette tâche. Cela comprend les corpus disponibles en français, les méthodes d’évaluation ainsi que les différentes architectures et leur approche. Enfin nous détaillerons les résultats, témoignant de l’évolution de méthodes de résolutions des liens de coréférences.</abstract>
      <url hash="56498cc4">2023.jeptalnrecital-rjc.7</url>
      <language>fra</language>
      <bibkey>lopez-2023-approches</bibkey>
    </paper>
    <paper id="8">
      <title>Etudes sur la géolocalisation de Tweets</title>
      <author><first>Thibaud</first><last>Martin</last></author>
      <pages>114–130</pages>
      <abstract>La géolocalisation de textes non structurés est un problème de recherche consistant à extraire uncontexte géographique d’un texte court. Sa résolution passe typiquement par une recherche de termesspatiaux et de la désambiguïsation. Dans cet article, nous proposons une analyse du problème, ainsi que deux méthodes d’inférence pourdéterminer le lieu dont traite un texte : 1. Comparaison de termes spatiaux à un index géographique2. Géolocalisation de textes sans information géographique à partir d’un graphe de co-occurrencede termes (avec et sans composante temporelle) Nos recherches sont basées sur un dataset de 10 millions de Tweets traitant de lieux français, dont57 830 possèdent une coordonnée géographique.</abstract>
      <url hash="4099995c">2023.jeptalnrecital-rjc.8</url>
      <language>fra</language>
      <bibkey>martin-2023-etudes</bibkey>
    </paper>
    <paper id="9">
      <title><fixed-case>IR</fixed-case>-<fixed-case>S</fixed-case>en<fixed-case>T</fixed-case>rans<fixed-case>B</fixed-case>io: Modèles Neuronaux Siamois pour la Recherche d’Information Biomédicale</title>
      <author><first>Safaa</first><last>Menad</last></author>
      <pages>131–142</pages>
      <abstract>L’entraînement de modèles transformeurs de langages sur des données biomédicales a permis d’obtenir des résultats prometteurs. Cependant, ces modèles de langage nécessitent pour chaque tâche un affinement (fine-tuning) sur des données supervisées très spécifiques qui sont peu disponibles dans le domaine biomédical. Dans le cadre de la classification d’articles scientifiques et les réponses aux questions biomédicales, nous proposons d’utiliser de nouveaux modèles neuronaux siamois (sentence transformers) qui plongent des textes à comparer dans un espace vectoriel. Nos modèles optimisent une fonction objectif d’apprentissage contrastif auto-supervisé sur des articles issus de la base de données bibliographique MEDLINE associés à leurs mots-clés MeSH (Medical Subject Headings). Les résultats obtenus sur plusieurs benchmarks montrent que les modèles proposés permettent de résoudre ces tâches sans exemples (zero-shot) et sont comparables à des modèles transformeurs biomédicaux affinés sur des données supervisés spécifiques aux problèmes traités. De plus, nous exploitons nos modèles dans la tâche de la recherche d’information biomédicale. Nous montrons que la combinaison de la méthode BM25 et de nos modèles permet d’obtenir des améliorations supplémentaires dans ce cadre.</abstract>
      <url hash="27e38187">2023.jeptalnrecital-rjc.9</url>
      <language>fra</language>
      <bibkey>menad-2023-ir</bibkey>
    </paper>
    <paper id="10">
      <title>L’évaluation de la traduction automatique du caractère au document : un état de l’art</title>
      <author><first>Mariam</first><last>Nakhlé</last></author>
      <pages>143–159</pages>
      <abstract>Ces dernières années l’évaluation de la traduction automatique, qu’elle soit humaine ou automatique,a rencontré des difficultés. Face aux importantes avancées en matière de traduction automatiqueneuronale, l’évaluation s’est montrée peu fiable. De nombreuses nouvelles approches ont été pro-posées pour améliorer les protocoles d’évaluation. L’objectif de ce travail est de proposer une vued’ensemble sur l’état global de l’évaluation de la Traduction Automatique (TA). Nous commenceronspar exposer les approches d’évaluation humaine, ensuite nous présenterons les méthodes d’évaluationautomatiques tout en différenciant entre les familles d’approches (métriques superficielles et apprises)et nous prêterons une attention particulière à l’évaluation au niveau du document qui prend comptedu contexte. Pour terminer, nous nous concentrerons sur la méta-évaluation des méthodes.</abstract>
      <url hash="4dc49e75">2023.jeptalnrecital-rjc.10</url>
      <language>fra</language>
      <bibkey>nakhle-2023-levaluation</bibkey>
    </paper>
    <paper id="11">
      <title>Normalisation lexicale de contenus générés par les utilisateurs sur les réseaux sociaux</title>
      <author><first>Lydia</first><last>Nishimwe</last></author>
      <pages>160–183</pages>
      <abstract>L’essor du traitement automatique des langues (TAL) se vit dans un monde où l’on produit de plus en plus de contenus en ligne. En particulier sur les réseaux sociaux, les textes publiés par les internautes sont remplis de phénomènes « non standards » tels que les fautes d’orthographe, l’argot, les marques d’expressivité, etc. Ainsi, les modèles de TAL, en grande partie entraînés sur des données « standards », voient leur performance diminuer lorsqu’ils sont appliqués aux contenus générés par les utilisateurs (CGU). L’une des approches pour atténuer cette dégradation est la normalisation lexicale : les mots non standards sont remplacés par leurs formes standards. Dans cet article, nous réalisons un état de l’art de la normalisation lexicale des CGU, ainsi qu’une étude expérimentale préliminaire pour montrer les avantages et les difficultés de cette tâche.</abstract>
      <url hash="76606a4b">2023.jeptalnrecital-rjc.11</url>
      <language>fra</language>
      <bibkey>nishimwe-2023-normalisation</bibkey>
    </paper>
  </volume>
  <volume id="arts" ingest-date="2023-06-25" type="proceedings">
    <meta>
      <booktitle>Actes de CORIA-TALN 2023. Actes de l'atelier "Analyse et Recherche de Textes Scientifiques" (ARTS)@TALN 2023</booktitle>
      <editor><first>Florian</first><last>Boudin</last></editor>
      <editor><first>Béatrice</first><last>Daille</last></editor>
      <editor><first>Richard</first><last>Dufour</last></editor>
      <editor><first>Oumaima</first><last>El</last></editor>
      <editor><first>Maël</first><last>Houbre</last></editor>
      <editor><first>Léane</first><last>Jourdan</last></editor>
      <editor><first>Nihel</first><last>Kooli</last></editor>
      <publisher>ATALA</publisher>
      <address>Paris, France</address>
      <month>6</month>
      <year>2023</year>
      <venue>jeptalnrecital</venue>
    </meta>
    <frontmatter>
      <url hash="155c2d66">2023.jeptalnrecital-arts.0</url>
      <bibkey>jep-taln-recital-2023-actes-de-coria</bibkey>
    </frontmatter>
    <paper id="1">
      <title>La pré-annotation automatique de textes cliniques comme support au dialogue avec les experts du domaine lors de la mise au point d’un schéma d’annotation</title>
      <author><first>Virgile</first><last>Barthet</last></author>
      <author><first>Marie-José</first><last>Aroulanda</last></author>
      <author><first>Laura</first><last>Monceaux-Cachard</last></author>
      <author><first>Christine</first><last>Jacquin</last></author>
      <author><first>Cyril</first><last>Grouin</last></author>
      <author><first>Johann</first><last>Gutton</last></author>
      <author><first>Guillaume</first><last>Hocquet</last></author>
      <author><first>Pascal</first><last>De Groote</last></author>
      <author><first>Michel</first><last>Komajda</last></author>
      <author><first>Emmanuel</first><last>Morin</last></author>
      <author><first>Pierre</first><last>Zweigenbaum</last></author>
      <pages>1–7</pages>
      <abstract>La pré-annotation automatique de textes est une tâche essentielle qui peut faciliter l’annotationd’un corpus de textes. Dans le contexte de la cardiologie, l’annotation est une tâche complexe quinécessite des connaissances approfondies dans le domaine et une expérience pratique dans le métier.Pré-annoter les textes vise à diminuer le temps de sollicitation des experts, facilitant leur concentrationsur les aspects plus critiques de l’annotation. Nous rapportons ici une expérience de pré-annotationde textes cliniques en cardiologie : nous présentons ses modalités et les observations que nous enretirons sur l’interaction avec les experts du domaine et la mise au point du schéma d’an</abstract>
      <url hash="65830462">2023.jeptalnrecital-arts.1</url>
      <language>fra</language>
      <bibkey>barthet-etal-2023-la</bibkey>
    </paper>
    <paper id="2">
      <title><fixed-case>M</fixed-case>a<fixed-case>TOS</fixed-case>: Traduction automatique pour la science ouverte</title>
      <author><first>Maud</first><last>Bénard</last></author>
      <author><first>Alexandra</first><last>Mestivier</last></author>
      <author><first>Natalie</first><last>Kubler</last></author>
      <author><first>Lichao</first><last>Zhu</last></author>
      <author><first>Rachel</first><last>Bawden</last></author>
      <author><first>Eric</first><last>De La Clergerie</last></author>
      <author><first>Laurent</first><last>Romary</last></author>
      <author><first>Mathilde</first><last>Huguin</last></author>
      <author><first>Jean-François</first><last>Nominé</last></author>
      <author><first>Ziqian</first><last>Peng</last></author>
      <author><first>François</first><last>Yvon</last></author>
      <pages>8–15</pages>
      <abstract>Cette contribution présente le projet MaTOS (Machine Translation for Open Science), qui vise à développer de nouvelles méthodes pour la traduction automatique (TA) intégrale de documents scientifiques entre le français et l’anglais, ainsi que des métriques automatiques pour évaluer la qualité des traductions produites. Pour ce faire, MaTOS s’intéresse (a) au recueil de ressources ouvertes pour la TA spécialisée; (b) à la description des marqueurs de cohérence textuelle pour les articles scientifiques; (c) au développement de nouvelles méthodes de traitement multilingue pour les documents; (d) aux métriques mesurant les progrès de la traduction de documents complets.</abstract>
      <url hash="43188435">2023.jeptalnrecital-arts.2</url>
      <language>fra</language>
      <bibkey>benard-etal-2023-matos</bibkey>
    </paper>
    <paper id="3">
      <title>Projet <fixed-case>N</fixed-case>avi<fixed-case>T</fixed-case>erm : navigation terminologique pour une montée en compétence rapide et personnalisée sur un domaine de recherche</title>
      <author><first>Florian</first><last>Boudin</last></author>
      <author><first>Richard</first><last>Dufour</last></author>
      <author><first>Béatrice</first><last>Daille</last></author>
      <pages>16–20</pages>
      <abstract>Cet article présente le projet NaviTerm dont l’objectif est d’accélérer la montée en compétence des chercheurs sur un domaine de recherche par la création automatique de représentations terminologiques synthétiques et navigables des connaissances scientifiques.</abstract>
      <url hash="9a25e0bd">2023.jeptalnrecital-arts.3</url>
      <language>fra</language>
      <bibkey>boudin-etal-2023-projet</bibkey>
    </paper>
    <paper id="4">
      <title>Annotation d’interactions hôte-microbiote dans des articles scientifiques par similarité sémantique avec une ontologie</title>
      <author><first>Oumaima</first><last>El Khettari</last></author>
      <author><first>Solen</first><last>Quiniou</last></author>
      <author><first>Samuel</first><last>Chaffron</last></author>
      <pages>21–26</pages>
      <abstract>Nous nous intéressons à l’extraction de relations, dans des articles scientifiques, portant sur le microbiome humain. Afin de construire un corpus annoté, nous avons évalué l’utilisation de l’ontologie OHMI pour détecter les relations présentes dans les phrases des articles scientifiques, en calculant la similarité sémantique entre les relations définies dans l’ontologie et les phrases des articles. Le modèle BERT et trois variantes biomédicales sont utilisés pour obtenir les représentations des relations et des phrases. Ces modèles sont comparés sur un corpus construit à partir d’articles scientifiques complets issus de la plateforme ISTEX, dont une sous-partie a été annotée manuellement.</abstract>
      <url hash="f6fa6285">2023.jeptalnrecital-arts.4</url>
      <language>fra</language>
      <bibkey>el-khettari-etal-2023-annotation</bibkey>
    </paper>
    <paper id="5">
      <title>Quand des Non-Experts Recherchent des Textes Scientifiques Rapport sur l’action <fixed-case>CLEF</fixed-case> 2023 <fixed-case>S</fixed-case>imple<fixed-case>T</fixed-case>ext</title>
      <author><first>Liana</first><last>Ermakova</last></author>
      <author><first>Stéphane</first><last>Huet</last></author>
      <author><first>Eric</first><last>Sanjuan</last></author>
      <author><first>Hosein</first><last>Azarbonyad</last></author>
      <author><first>Olivier</first><last>Augereau</last></author>
      <author><first>Jaap</first><last>Kamps</last></author>
      <pages>27–33</pages>
      <abstract>Le grand public a tendance à éviter les sources fiables telles que la littérature scientifique en raison de leur langage complexe et du manque de connaissances nécessaires. Au lieu de cela, il s’appuie sur des sources superficielles, trouvées sur internet ou dans les médias sociaux et qui sont pourtant souvent publiées pour des raisons commerciales ou politiques, plutôt que pour leur valeur informative. La simplification des textes peut-elle contribuer à supprimer certains de ces obstacles à l’accès ? Cet article présente l’action « CLEF 2023 SimpleText » qui aborde les défis techniques et d’évaluation de l’accès à l’information scientifique pour le grand public. Nous fournissons des données réutilisables et des critères de référence pour la simplification des textes scientifiques et encourageons les recherches visant à faciliter à la compréhension des textes complexes.</abstract>
      <url hash="a015a360">2023.jeptalnrecital-arts.5</url>
      <language>fra</language>
      <bibkey>ermakova-etal-2023-quand</bibkey>
    </paper>
    <paper id="6">
      <title>Apprentissage de dépendances entre labels pour la classification multi-labels à l’aide de transformeurs</title>
      <author><first>Haytame</first><last>Fallah</last></author>
      <author><first>Elisabeth</first><last>Murisasco</last></author>
      <author><first>Emmanuel</first><last>Bruno</last></author>
      <author><first>Patrice</first><last>Bellot</last></author>
      <pages>34–40</pages>
      <abstract>Dans cet article, nous proposons des approches pour améliorer les architectures basées sur des transformeurs pour la classification de documents multi-labels. Les dépendances entre les labels sont cruciales dans ce contexte. Notre méthode, appelée DepReg, ajoute un terme de régularisation à la fonction de perte pour encourager le modèle à prédire des labels susceptibles de coexister. Nous introduisons également un nouveau jeu de données nommé “arXiv-ACM”, composé de résumés scientifiques de la bibliothèque numérique arXiv, étiquetés avec les mots-clés ACM correspondants.</abstract>
      <url hash="310f8dec">2023.jeptalnrecital-arts.6</url>
      <language>fra</language>
      <bibkey>fallah-etal-2023-apprentissage</bibkey>
    </paper>
    <paper id="7">
      <title>Elaboration d’un corpus d’apprentissage à partir d’articles de recherche en chimie</title>
      <author><first>Bénédicte</first><last>Goujon</last></author>
      <pages>41–46</pages>
      <abstract>Dans le cadre d’un projet mené en 2021, un objectif consistait à extraire automatiquement des informations à partir d’articles de recherche en chimie des matériaux : des valeurs associées à des propriétés pour différents composants chimiques. Le travail présenté ici décrit les étapes de la construction du corpus textuel d’apprentissage, annoté manuellement par des experts du domaine selon les besoins identifiés dans le projet, pour une utilisation ultérieure par des outils d’extraction d’informations.</abstract>
      <url hash="2acc1603">2023.jeptalnrecital-arts.7</url>
      <language>fra</language>
      <bibkey>goujon-2023-elaboration</bibkey>
    </paper>
    <paper id="8">
      <title>Classification de relation pour la génération de mots-clés absents</title>
      <author><first>Maël</first><last>Houbre</last></author>
      <author><first>Florian</first><last>Boudin</last></author>
      <author><first>Béatrice</first><last>Daille</last></author>
      <pages>47–53</pages>
      <abstract>Les modèles encodeur-décodeur constituent l’état de l’art en génération de mots-clés. Cependant, malgré de nombreuses adaptations de cette architecture, générer des mots-clés absents du texte du document est toujours une tâche difficile. Cette étude montre qu’entraîner au préalable un modèle sur une tâche de classification de relation entre un document et un mot-clé, permet d’améliorer la génération de mots-clés absents.</abstract>
      <url hash="fd9f171e">2023.jeptalnrecital-arts.8</url>
      <language>fra</language>
      <bibkey>houbre-etal-2023-classification</bibkey>
    </paper>
    <paper id="9">
      <title>Le corpus « Machine Translation » : une exploration diachronique des (méta)données Istex</title>
      <author><first>Mathilde</first><last>Huguin</last></author>
      <author><first>Sabine</first><last>Barreaux</last></author>
      <pages>54–59</pages>
      <abstract>Le corpus Machine Translation se compose de publications scientifiques issues du réservoir Istex. Conçu comme un cas d’usage, il permet d’explorer l’histoire de la traduction automatique au travers des métadonnées et des textes intégraux disponibles pour chacun de ses documents. D’une part, les métadonnées permettent d’apporter un premier regard sur le paysage de la traduction automatique grâce à des tableaux de bord bibliométriques. D’autre part, l’utilisation d’outils de fouille de textes sur le texte intégral rend saillantes des informations inaccessibles sans une lecture approfondie des articles. L’exploration du corpus est réalisée grâce à Lodex, logiciel open source dédié à la valorisation de données structurées.</abstract>
      <url hash="7333cf63">2023.jeptalnrecital-arts.9</url>
      <language>fra</language>
      <bibkey>huguin-barreaux-2023-le</bibkey>
    </paper>
    <paper id="10">
      <title><fixed-case>CASIMIR</fixed-case> : un Corpus d’Articles Scientifiques Intégrant les <fixed-case>M</fixed-case>od<fixed-case>I</fixed-case>fications et Révisions des auteurs</title>
      <author><first>Léane</first><last>Jourdan</last></author>
      <author><first>Florian</first><last>Boudin</last></author>
      <author><first>Richard</first><last>Dufour</last></author>
      <author><first>Nicolas</first><last>Hernandez</last></author>
      <pages>60–65</pages>
      <abstract>Écrire un article scientifique est une tâche difficile. L’écriture scientifique étant un genre très codifié, de bonnes compétences d’écriture sont essentielles pour transmettre ses idées et les résultats de ses recherches. Cet article décrit les motivations et les travaux préliminaires de la création du corpus CASIMIR dont l’objectif est d’offrir une ressource sur l’étape de révision du processus d’écriture d’un article scientifique. CASIMIR est un corpus des multiples versions de 26 355 articles scientifiques provenant d’OpenReview accompagné des relectures par les pairs.</abstract>
      <url hash="0e93ebe2">2023.jeptalnrecital-arts.10</url>
      <language>fra</language>
      <bibkey>jourdan-etal-2023-casimir</bibkey>
    </paper>
    <paper id="11">
      <title><fixed-case>MORFITT</fixed-case> : Un corpus multi-labels d’articles scientifiques français dans le domaine biomédical</title>
      <author><first>Yanis</first><last>Labrak</last></author>
      <author><first>Mickael</first><last>Rouvier</last></author>
      <author><first>Richard</first><last>Dufour</last></author>
      <pages>66–70</pages>
      <abstract>Cet article présente MORFITT, le premier corpus multi-labels en français annoté en spécialités dans le domaine médical. MORFITT est composé de 3 624 résumés d’articles scientifiques issus de PubMed, annotés en 12 spécialités pour un total de 5 116 annotations. Nous détaillons le corpus, les expérimentations et les résultats préliminaires obtenus à l’aide d’un classifieur fondé sur le modèle de langage pré-entraîné CamemBERT. Ces résultats préliminaires démontrent la difficulté de la tâche, avec un F-score moyen pondéré de 61,78%.</abstract>
      <url hash="6899cf91">2023.jeptalnrecital-arts.11</url>
      <language>fra</language>
      <bibkey>labrak-etal-2023-morfitt</bibkey>
    </paper>
    <paper id="12">
      <title>La détection de textes générés par des modèles de langue : une tâche complexe? Une étude sur des textes académiques</title>
      <author><first>Vijini</first><last>Liyanage</last></author>
      <author><first>Davide</first><last>Buscaldi</last></author>
      <pages>71–78</pages>
      <abstract>L’émergence de modèles de langage très puissants tels que GPT-3 a sensibilisé les chercheurs à la problématique de la détection de textes académiques générés automatiquement, principalement dans un souci de prévention de plagiat. Plusieurs études ont montré que les modèles de détection actuels ont une précision élevée, en donnant l’impression que la tâche soit résolue. Cependant, nous avons observé que les ensembles de données utilisés pour ces expériences contiennent des textes générés automatiquement à partir de modèles pré-entraînés. Une utilisation plus réaliste des modèles de langage consisterait à effectuer un fine-tuning sur un texte écrit par un humain pour compléter les parties manquantes. Ainsi, nous avons constitué un corpus de textes générés de manière plus réaliste et mené des expériences avec plusieurs modèles de classification. Nos résultats montrent que lorsque les ensembles de données sont générés de manière réaliste pour simuler l’utilisation de modèles de langage par les chercheurs, la détection de ces textes devient une tâche assez difficile.</abstract>
      <url hash="d150b643">2023.jeptalnrecital-arts.12</url>
      <language>fra</language>
      <bibkey>liyanage-buscaldi-2023-la</bibkey>
    </paper>
    <paper id="13">
      <title>Construction d’un jeu de données de publications scientifiques pour le <fixed-case>TAL</fixed-case> et la fouille de textes à partir d’<fixed-case>ISTEX</fixed-case></title>
      <author><first>Constant</first><last>Mathieu</last></author>
      <pages>79–79</pages>
      <abstract>La plateforme ISTEX (https://www.istex.fr/) permet d’accéder à une large base d’archives scientifiques comptant plus de 25 millions de documents de tous les grands domaines scientifiques. Les documents incluent non seulement les métadonnées mais aussi le texte plein, et ont été prétraités de manière homogène pour faciliter leur traitement automatique. Dans cet exposé, nous présenterons une initiative pour créer une dynamique de recherche en TAL et TDM autour de ces données. En particulier, nous présenterons les travaux en cours pour la construction d’un jeu de données dédié au TAL et la fouille de textes.</abstract>
      <url hash="626f7c8d">2023.jeptalnrecital-arts.13</url>
      <language>fra</language>
      <bibkey>mathieu-2023-construction</bibkey>
    </paper>
    <paper id="14">
      <title>What shall we read : the article or the citations? - A case study on scientific language understanding</title>
      <author><first>Aman</first><last>Sinha</last></author>
      <author><first>Sam</first><last>Bigeard</last></author>
      <author><first>Marianne</first><last>Clausel</last></author>
      <author><first>Mathieu</first><last>Constant</last></author>
      <pages>80–85</pages>
      <abstract>The number of scientific articles is increasing tremendously across all domains to such an extent that it has become hard for researchers to remain up-to-date. Evidently, scientific language understanding systems and Information Extraction (IE) systems, with the advancement of Natural Language Processing (NLP) techniques, are benefiting the needs of users. Although the majority of the practices for building such systems are data-driven, advocating the idea of “The more, the better”. In this work, we revisit the paradigm - questioning what type of data : text (title, abstract) or citations, can have more impact on the performance of scientific language understanding systems.</abstract>
      <url hash="2e0b2dd3">2023.jeptalnrecital-arts.14</url>
      <bibkey>sinha-etal-2023-shall</bibkey>
    </paper>
  </volume>
  <volume id="deft" ingest-date="2023-06-25" type="proceedings">
    <meta>
      <booktitle>Actes de CORIA-TALN 2023. Actes du Défi Fouille de Textes@TALN2023</booktitle>
      <editor><first>Adrien</first><last>Bazoge</last></editor>
      <editor><first>Béatrice</first><last>Daille</last></editor>
      <editor><first>Richard</first><last>Dufour</last></editor>
      <editor><first>Yanis</first><last>Labrak</last></editor>
      <editor><first>Emmanuel</first><last>Morin</last></editor>
      <editor><first>Mickael</first><last>Rouvier</last></editor>
      <publisher>ATALA</publisher>
      <address>Paris, France</address>
      <month>6</month>
      <year>2023</year>
      <venue>jeptalnrecital</venue>
    </meta>
    <frontmatter>
      <url hash="3e86fefb">2023.jeptalnrecital-deft.0</url>
      <bibkey>jep-taln-recital-2023-actes-de-coria-taln</bibkey>
    </frontmatter>
    <paper id="1">
      <title>Qui de <fixed-case>D</fixed-case>r<fixed-case>BERT</fixed-case>, Wikipédia ou Flan-T5 s’y connaît le plus en questions médicales ?</title>
      <author><first>Clément</first><last>Besnard</last></author>
      <author><first>Mohamed</first><last>Ettaleb</last></author>
      <author><first>Christian</first><last>Raymond</last></author>
      <author><first>Nathalie</first><last>Camelin</last></author>
      <pages>1–10</pages>
      <abstract>Ce papier décrit la participation de l’équipe LIUM-IRISA à la campagne d’évaluation DEFT 2023.Notre équipe a participé à la tâche principale. Cette année, celle-ci consiste à la mise en placed’approches afin de répondre automatiquement à des questions à choix multiples. Nous avons mis enplace plusieurs systèmes, un premier avec une base de connaissances, un second système utilisant unmodèle génératif, un système à base de similarité et un dernier système combinant un ensemble dedescripteurs.</abstract>
      <url hash="82620982">2023.jeptalnrecital-deft.1</url>
      <language>fra</language>
      <bibkey>besnard-etal-2023-qui</bibkey>
    </paper>
    <paper id="2">
      <title><fixed-case>SPQR</fixed-case>@Deft2023: Similarité Sorbonne Pour les Systèmes de Question Réponse</title>
      <author><first>Julien</first><last>Bezançon</last></author>
      <author><first>Toufik</first><last>Boubehziz</last></author>
      <author><first>Corina</first><last>Chutaux</last></author>
      <author><first>Oumaima</first><last>Zine</last></author>
      <author><first>Laurie</first><last>Acensio</last></author>
      <author><first>Ibtihel</first><last>Ben Ltaifa</last></author>
      <author><first>Nour El Houda</first><last>Ben Chaabene</last></author>
      <author><first>Caroline</first><last>Koudoro-Parfait</last></author>
      <author><first>Andrea</first><last>Briglia</last></author>
      <author><first>Gaël</first><last>Lejeune</last></author>
      <pages>11–22</pages>
      <abstract>Nous présentons le travail de SPQR (Sorbonne Question-Réponses) au DÉfi Fouille de Textes 2023 sur la réponse automatique à des questionnaires à choix multiples dans le domaine de la pharmacologie. Nous proposons une approche fondée sur la constitution de corpus de spécialité et la recherche de phrases similaires entre ces corpus et les différentes réponses possibles à une question. Nous calculons une similarité cosinus sur des vecteurs en n-grammes de caractères pour déterminer les bonnes réponses. Cette approche a obtenu un score maximal en Hamming de 0,249 sur les données de test (0,305 sur le dev) et de 0,0997 en Exact Match Ratio (0,16 sur le dev).</abstract>
      <url hash="334255ae">2023.jeptalnrecital-deft.2</url>
      <language>fra</language>
      <bibkey>bezancon-etal-2023-spqr</bibkey>
    </paper>
    <paper id="3">
      <title>Participation de l’équipe <fixed-case>TTGV</fixed-case> à <fixed-case>DEFT</fixed-case> 2023~: Réponse automatique à des <fixed-case>QCM</fixed-case> issus d’examens en pharmacie</title>
      <author><first>Andréa</first><last>Blivet</last></author>
      <author><first>Solène</first><last>Degrutère</last></author>
      <author><first>Barbara</first><last>Gendron</last></author>
      <author><first>Aurélien</first><last>Renault</last></author>
      <author><first>Cyrille</first><last>Siouffi</last></author>
      <author><first>Vanessa</first><last>Gaudray Bouju</last></author>
      <author><first>Christophe</first><last>Cerisara</last></author>
      <author><first>Hélène</first><last>Flamein</last></author>
      <author><first>Gaël</first><last>Guibon</last></author>
      <author><first>Matthieu</first><last>Labeau</last></author>
      <author><first>Tom</first><last>Rousseau</last></author>
      <pages>23–38</pages>
      <abstract>Cet article présente l’approche de l’équipe TTGV dans le cadre de sa participation aux deux tâches proposées lors du DEFT 2023 : l’identification du nombre de réponses supposément justes à un QCM et la prédiction de l’ensemble de réponses correctes parmi les cinq proposées pour une question donnée. Cet article présente les différentes méthodologies mises en oeuvre, explorant ainsi un large éventail d’approches et de techniques pour aborder dans un premier temps la distinction entre les questions appelant une seule ou plusieurs réponses avant de s’interroger sur l’identification des réponses correctes. Nous détaillerons les différentes méthodes utilisées, en mettant en exergue leurs avantages et leurs limites respectives. Ensuite, nous présenterons les résultats obtenus pour chaque approche. Enfin, nous discuterons des limitations intrinsèques aux tâches elles-mêmes ainsi qu’aux approches envisagées dans cette contribution.</abstract>
      <url hash="95a3a9ba">2023.jeptalnrecital-deft.3</url>
      <language>fra</language>
      <bibkey>blivet-etal-2023-participation</bibkey>
    </paper>
    <paper id="4">
      <title>Participation d’<fixed-case>EDF</fixed-case> <fixed-case>R</fixed-case>&amp;<fixed-case>D</fixed-case> au défi <fixed-case>DEFT</fixed-case> 2023 : réponses automatiques à des questionnaires à choix multiples à l’aide de « Larges Modèles de Langue »</title>
      <author><first>Meryl</first><last>Bothua</last></author>
      <author><first>Leila</first><last>Hassani</last></author>
      <author><first>Marie</first><last>Jubault</last></author>
      <author><first>Philippe</first><last>Suignard</last></author>
      <pages>39–45</pages>
      <abstract>Ce papier présente la participation d’EDF R&amp;D à la campagne d’évaluation DEFT 2023. Notre équipe a participé à la tâche de réponse automatique à des questions à choix multiples issus d’annales d’examens en pharmacie en français. Le corpus utilisé est FrenchMedMCQA. Nous avons testé des Large Language Models pour générer des réponses. Notre équipe s’est classée A COMPLETER.</abstract>
      <url hash="5ec05807">2023.jeptalnrecital-deft.4</url>
      <language>fra</language>
      <bibkey>bothua-etal-2023-participation</bibkey>
    </paper>
    <paper id="5">
      <title><fixed-case>LIS</fixed-case>@<fixed-case>DEFT</fixed-case>’23 : les <fixed-case>LLM</fixed-case>s peuvent-ils répondre à des <fixed-case>QCM</fixed-case> ? (a) oui; (b) non; (c) je ne sais pas.</title>
      <author><first>Benoit</first><last>Favre</last></author>
      <pages>46–56</pages>
      <abstract>Cet article présente un ensemble d’expériences sur la tâche de réponse à des questions à choix multiple de DEFT 2023. Des grands modèles de langage sont amorcés avec les questions afin de collecter les réponses générées. Les résultats montrent que les modèles ouverts sans affinage obtiennent des performances similaires à celles d’un système supervisé fondé sur BERT, et que l’affinage sur les données de la tâche apporte des améliorations.</abstract>
      <url hash="b0d07bb3">2023.jeptalnrecital-deft.5</url>
      <language>fra</language>
      <bibkey>favre-2023-lis</bibkey>
    </paper>
    <paper id="6">
      <title>Tâches et systèmes de détection automatique des réponses correctes dans des <fixed-case>QCM</fixed-case>s liés au domaine médical : Présentation de la campagne <fixed-case>DEFT</fixed-case> 2023</title>
      <author><first>Yanis</first><last>Labrak</last></author>
      <author><first>Adrien</first><last>Bazoge</last></author>
      <author><first>Béatrice</first><last>Daille</last></author>
      <author><first>Richard</first><last>Dufour</last></author>
      <author><first>Emmanuel</first><last>Morin</last></author>
      <author><first>Mickael</first><last>Rouvier</last></author>
      <pages>57–67</pages>
      <abstract>L’édition 2023 du DÉfi Fouille de Textes (DEFT) s’est concentrée sur le développement de méthodes permettant de choisir automatiquement des réponses dans des questions à choix multiples (QCMs) en français. Les approches ont été évaluées sur le corpus FrenchMedMCQA, intégrant un ensemble de QCMs avec, pour chaque question, cinq réponses potentielles, dans le cadre d’annales d’examens de pharmacie.Deux tâches ont été proposées. La première consistait à identifier automatiquement l’ensemble des réponses correctes à une question. Les résultats obtenus, évalués selon la métrique de l’Exact Match Ratio (EMR), variaient de 9,97% à 33,76%, alors que les performances en termes de distance de Hamming s’échelonnaient de 24,93 à 52,94. La seconde tâche visait à identifier automatiquement le nombre exact de réponses correctes. Les résultats, quant à eux, étaient évalués d’une part avec la métrique de F1-Macro, variant de 13,26% à 42,42%, et la métrique (Accuracy), allant de 47,43% à 68,65%. Parmi les approches variées proposées par les six équipes participantes à ce défi, le meilleur système s’est appuyé sur un modèle de langage large de type LLaMa affiné en utilisant la méthode d’adaptation LoRA.</abstract>
      <url hash="225f186f">2023.jeptalnrecital-deft.6</url>
      <language>fra</language>
      <bibkey>labrak-etal-2023-taches</bibkey>
    </paper>
    <paper id="7">
      <title>Passe ta pharma d’abord !</title>
      <author><first>Simon</first><last>Meoni</last></author>
      <author><first>Rian</first><last>Touchent</last></author>
      <author><first>Eric</first><last>De La Clergerie</last></author>
      <pages>68–76</pages>
      <abstract>Nous présentons les 3 expériences menées par l’équipe ALMAnaCH - Arkhn et leurs résultats pour le DÉfi Fouille de Textes (DEFT) 2023. Les scores sont encourageants mais suggèrent surtout de nouveaux éléments à prendre en compte pour réussir ce défi. Nous avons exploré différentes approches avec des modèles de tailles variables et modélisé la tâche de différentes manières (classification multi-labels, implication textuelle, séquence à séquence). Nous n’avons pas observé des gains de performance significatifs. Nos expériences semblent montrer la nécessité de l’utilisation de bases de connaissances externes pour obtenir de bons résultats sur ce type de tâche.</abstract>
      <url hash="4b6c028c">2023.jeptalnrecital-deft.7</url>
      <bibkey>meoni-etal-2023-passe</bibkey>
    </paper>
  </volume>
</collection>
