<?xml version='1.0' encoding='UTF-8'?>
<collection id="2023.artofsafety">
  <volume id="1" ingest-date="2024-01-18" type="proceedings">
    <meta>
      <booktitle>Proceedings of the ART of Safety: Workshop on Adversarial testing and Red-Teaming for generative AI</booktitle>
      <editor><first>Alicia</first><last>Parrish</last></editor>
      <publisher>Association for Computational Linguistics</publisher>
      <address>Bali, Indonesia</address>
      <month>November</month>
      <year>2023</year>
      <venue>artofsafety</venue>
      <venue>ws</venue>
    </meta>
    <frontmatter>
      <url hash="9ead3f05">2023.artofsafety-1.0</url>
      <bibkey>artofsafety-2023-art</bibkey>
    </frontmatter>
    <paper id="1">
      <title>Red Teaming for Large Language Models At Scale: Tackling Hallucinations on Mathematics Tasks</title>
      <author><first>Aleksander</first><last>Buszydlik</last></author>
      <author><first>Karol</first><last>Dobiczek</last></author>
      <author><first>Michał Teodor</first><last>Okoń</last></author>
      <author><first>Konrad</first><last>Skublicki</last></author>
      <author><first>Philip</first><last>Lippmann</last></author>
      <author><first>Jie</first><last>Yang</last></author>
      <pages>1–10</pages>
      <url hash="6fb98696">2023.artofsafety-1.1</url>
      <bibkey>buszydlik-etal-2023-red</bibkey>
      <doi>10.18653/v1/2023.artofsafety-1.1</doi>
    </paper>
    <paper id="2">
      <title>Student-Teacher Prompting for Red Teaming to Improve Guardrails</title>
      <author><first>Rodrigo</first><last>Revilla Llaca</last></author>
      <author><first>Victoria</first><last>Leskoschek</last></author>
      <author><first>Vitor</first><last>Costa Paiva</last></author>
      <author><first>Cătălin</first><last>Lupău</last></author>
      <author><first>Philip</first><last>Lippmann</last></author>
      <author><first>Jie</first><last>Yang</last></author>
      <pages>11–23</pages>
      <url hash="3d0ec274">2023.artofsafety-1.2</url>
      <bibkey>revilla-llaca-etal-2023-student</bibkey>
      <doi>10.18653/v1/2023.artofsafety-1.2</doi>
    </paper>
    <paper id="3">
      <title>Distilling Adversarial Prompts from Safety Benchmarks: Report for the Adversarial Nibbler Challenge</title>
      <author><first>Manuel</first><last>Brack</last></author>
      <author><first>Patrick</first><last>Schramowski</last></author>
      <author><first>Kristian</first><last>Kersting</last></author>
      <pages>24–28</pages>
      <url hash="301a3f16">2023.artofsafety-1.3</url>
      <bibkey>brack-etal-2023-distilling</bibkey>
      <doi>10.18653/v1/2023.artofsafety-1.3</doi>
    </paper>
    <paper id="4">
      <title>Measuring Adversarial Datasets</title>
      <author><first>Yuanchen</first><last>Bai</last></author>
      <author><first>Raoyi</first><last>Huang</last></author>
      <author><first>Vijay</first><last>Viswanathan</last></author>
      <author><first>Tzu-Sheng</first><last>Kuo</last></author>
      <author><first>Tongshuang</first><last>Wu</last></author>
      <pages>29–42</pages>
      <url hash="4c55c86b">2023.artofsafety-1.4</url>
      <bibkey>bai-etal-2023-measuring</bibkey>
      <doi>10.18653/v1/2023.artofsafety-1.4</doi>
    </paper>
    <paper id="5">
      <title>Discovering Safety Issues in Text-to-Image Models: Insights from Adversarial Nibbler Challenge</title>
      <author><first>Gauri</first><last>Sharma</last></author>
      <pages>43–48</pages>
      <url hash="0aeebf0f">2023.artofsafety-1.5</url>
      <bibkey>sharma-2023-discovering</bibkey>
      <doi>10.18653/v1/2023.artofsafety-1.5</doi>
    </paper>
    <paper id="6">
      <title>Uncovering Bias in <fixed-case>AI</fixed-case>-Generated Images</title>
      <author><first>Kimberley</first><last>Baxter</last></author>
      <pages>49–50</pages>
      <url hash="3f07f3fd">2023.artofsafety-1.6</url>
      <bibkey>baxter-2023-uncovering</bibkey>
      <doi>10.18653/v1/2023.artofsafety-1.6</doi>
    </paper>
  </volume>
</collection>
