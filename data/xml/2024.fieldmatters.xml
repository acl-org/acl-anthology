<?xml version='1.0' encoding='UTF-8'?>
<collection id="2024.fieldmatters">
  <volume id="1" ingest-date="2024-07-26" type="proceedings">
    <meta>
      <booktitle>Proceedings of the 3rd Workshop on NLP Applications to Field Linguistics (Field Matters 2024)</booktitle>
      <editor><first>Oleg</first><last>Serikov</last></editor>
      <editor><first>Ekaterina</first><last>Voloshina</last></editor>
      <editor><first>Anna</first><last>Postnikova</last></editor>
      <editor><first>Saliha</first><last>Muradoglu</last></editor>
      <editor><first>Eric</first><last>Le Ferrand</last></editor>
      <editor><first>Elena</first><last>Klyachko</last></editor>
      <editor><first>Ekaterina</first><last>Vylomova</last></editor>
      <editor><first>Tatiana</first><last>Shavrina</last></editor>
      <editor><first>Francis</first><last>Tyers</last></editor>
      <publisher>Association for Computational Linguistics</publisher>
      <address>Bangkok, Thailand</address>
      <month>August</month>
      <year>2024</year>
      <url hash="4a1321cb">2024.fieldmatters-1</url>
      <venue>fieldmatters</venue>
      <venue>ws</venue>
    </meta>
    <frontmatter>
      <url hash="dc82c8ca">2024.fieldmatters-1.0</url>
      <bibkey>fieldmatters-2024-nlp</bibkey>
    </frontmatter>
    <paper id="1">
      <title>The Parallel Corpus of <fixed-case>R</fixed-case>ussian and Ruska <fixed-case>R</fixed-case>omani Languages</title>
      <author><first>Kirill</first><last>Koncha</last></author>
      <author><first>Abina</first><last>Kukanova</last></author>
      <author><first>Kazakova</first><last>Tatiana</last><affiliation>Higher School of Economics</affiliation></author>
      <author><first>Gloria</first><last>Rozovskaya</last><affiliation>NA</affiliation></author>
      <pages>1-5</pages>
      <abstract>The paper presents a parallel corpus for the Ruska Romani dialect and Russian language. Ruska Romani is the dialect of Romani language attributed to Ruska Roma, the largest subgroup of Romani people in Russia. The corpus contains the translations of Russian literature into Ruska Romani dialect. The corpus creation involved manual alignment of a small part of translations with original works, fine-tuning a language model on the aligned pairs, and using the fine-tuned model to align the remaining data. Ruska Romani sentences were annotated using a morphological analyzer, with rules crafted for proper nouns and borrowings. The corpus, available in JSON and Russian National Corpus XML formats. It includes 88,742 Russian tokens and 84,635 Ruska Romani tokens, 74,291 of which were grammatically annotated. The corpus could be used for linguistic research, including comparative and diachronic studies, bilingual dictionary creation, stylometry research, and NLP/MT tool development for Ruska Romani.</abstract>
      <url hash="b3d4d4db">2024.fieldmatters-1.1</url>
      <bibkey>koncha-etal-2024-parallel</bibkey>
      <doi>10.18653/v1/2024.fieldmatters-1.1</doi>
    </paper>
    <paper id="2">
      <title><fixed-case>M</fixed-case>an<fixed-case>W</fixed-case>av: The First <fixed-case>M</fixed-case>anchu <fixed-case>ASR</fixed-case> Model</title>
      <author><first>Jean</first><last>Seo</last></author>
      <author><first>Minha</first><last>Kang</last><affiliation>Seoul National University</affiliation></author>
      <author><first>SungJoo</first><last>Byun</last><affiliation>Seoul National University</affiliation></author>
      <author><first>Sangah</first><last>Lee</last><affiliation>Seoul National University</affiliation></author>
      <pages>6-11</pages>
      <abstract>This study addresses the widening gap in Automatic Speech Recognition (ASR) research between high resource and extremely low resource languages, with a particular focus on Manchu, a severely endangered language. Manchu exemplifies the challenges faced by marginalized linguistic communities in accessing state-of-the-art technologies. In a pioneering effort, we introduce the first-ever Manchu ASR model ManWav, leveraging Wav2Vec2-XLSR-53. The results of the first Manchu ASR is promising, especially when trained with our augmented data. Wav2Vec2-XLSR-53 fine-tuned with augmented data demonstrates a 0.02 drop in CER and 0.13 drop in WER compared to the same base model fine-tuned with original data.</abstract>
      <url hash="09953f81">2024.fieldmatters-1.2</url>
      <bibkey>seo-etal-2024-manwav</bibkey>
      <doi>10.18653/v1/2024.fieldmatters-1.2</doi>
    </paper>
    <paper id="3">
      <title>User-Centered Design of Digital Tools for Sociolinguistic Studies in Under-Resourced Languages</title>
      <author><first>Jonas</first><last>Adler</last></author>
      <author><first>Carsten</first><last>Scholle</last></author>
      <author><first>Daniel</first><last>Buschek</last><affiliation>University of Bayreuth</affiliation></author>
      <author><first>Nicolo’</first><last>Brandizzi</last><affiliation>University of Roma “La Sapienza”</affiliation></author>
      <author><first>Muhadj</first><last>Adnan</last></author>
      <pages>12-27</pages>
      <abstract>Investigating language variation is a core aspect of sociolinguistics, especially through the use of linguistic corpora. Collecting and analyzing spoken language in text-based corpora can be time-consuming and error-prone, especially for under-resourced languages with limited software assistance. This paper explores the language variation research process using a User-Centered Design (UCD) approach from the field of Human-Computer Interaction (HCI), offering guidelines for the development of digital tools for sociolinguists. We interviewed four researchers, observed their workflows and software usage, and analyzed the data using Grounded Theory. This revealed key challenges in manual tasks, software assistance, and data management. Based on these insights, we identified a set of requirements that future tools should meet to be valuable for researchers in this domain. The paper concludes by proposing design concepts with sketches and prototypes based on the identified requirements. These concepts aim to guide the implementation of a fully functional, open-source tool. This work presents an interdisciplinary approach between sociolinguistics and HCI by emphasizing the practical aspects of research that are often overlooked.</abstract>
      <url hash="ce03a15c">2024.fieldmatters-1.3</url>
      <bibkey>adler-etal-2024-user</bibkey>
      <doi>10.18653/v1/2024.fieldmatters-1.3</doi>
    </paper>
    <paper id="4">
      <title>Documenting Endangered Languages with <fixed-case>L</fixed-case>ang<fixed-case>D</fixed-case>oc: A Wordlist-Based System and A Case Study on <fixed-case>M</fixed-case>oklen</title>
      <author><first>Piyapath</first><last>Spencer</last><affiliation>Ludwig-Maximilians-Universität München and Chulalongkorn University</affiliation></author>
      <pages>28-36</pages>
      <abstract>Language documentation, especially languages lacking standardised writing systems, is a laborious and time-consuming process. This paper introduces LangDoc, a comprehensive system designed to address challenges and improve the efficiency and accuracy of language documentation projects. LangDoc offers several features, including tools for managing, recording, and reviewing the collected data. It operates both online and offline, crucial for fieldwork in remote locations. The paper also presents a comparative analysis demonstrating LangDoc’s efficiency compared to other methods. A case study of the Moklen language documentation project demonstrates how the features address the specific challenges of working with endangered languages and remote communities. Future development areas include integrating with NLP tools for advanced linguistic analysis and emphasising its potential to support the preservation of language diversity.</abstract>
      <url hash="0c3d7f35">2024.fieldmatters-1.4</url>
      <bibkey>spencer-2024-documenting</bibkey>
      <doi>10.18653/v1/2024.fieldmatters-1.4</doi>
    </paper>
    <paper id="5">
      <title>Leveraging Deep Learning to Shed Light on Tones of an Endangered Language: A Case Study of <fixed-case>M</fixed-case>oklen</title>
      <author><first>Sireemas</first><last>Maspong</last></author>
      <author><first>Francesco</first><last>Burroni</last><affiliation>Ludwig-Maximilians-Universität München</affiliation></author>
      <author><first>Teerawee</first><last>Sukanchanon</last><affiliation>NA</affiliation></author>
      <author><first>Warunsiri</first><last>Pornpottanamas</last><affiliation>NA</affiliation></author>
      <author><first>Pittayawat</first><last>Pittayaporn</last><affiliation>NA</affiliation></author>
      <pages>37-42</pages>
      <abstract>Moklen, a tonal Austronesian language spoken in Thailand, exhibits two tones with unbalanced distributions. We employed machine learning techniques for time-series classification to investigate its acoustic properties. Our analysis reveals that a synergy between pitch and vowel quality is crucial for tone distinction, as the model trained with these features achieved the highest accuracy.</abstract>
      <url hash="40dde821">2024.fieldmatters-1.5</url>
      <bibkey>maspong-etal-2024-leveraging</bibkey>
      <doi>10.18653/v1/2024.fieldmatters-1.5</doi>
    </paper>
    <paper id="6">
      <title>A Comparative Analysis of Speaker Diarization Models: Creating a Dataset for <fixed-case>G</fixed-case>erman Dialectal Speech</title>
      <author><first>Lea</first><last>Fischbach</last><affiliation>Phillips-Universität Marburg</affiliation></author>
      <pages>43-51</pages>
      <abstract>Speaker diarization is a critical task in the field of computer science, aiming to assign timestamps and speaker labels to audio segments. The aim of these tests in this Publication is to find a pretrained speaker diarization pipeline capable of distinguishing dialectal speakers from each other and an explorer. To achieve this, three pipelines, namely Pyannote, CLEAVER and NeMo, are tested and compared, across various segmentation and parameterization strategies. The study considers multiple scenarios, such as the impact of threshold values, overlap handling, and minimum duration parameters, on classification accuracy. Additionally, this study aims to create a dataset for German dialect identification (DID) based on the findings from this research.</abstract>
      <url hash="45b1672a">2024.fieldmatters-1.6</url>
      <bibkey>fischbach-2024-comparative</bibkey>
      <doi>10.18653/v1/2024.fieldmatters-1.6</doi>
    </paper>
    <paper id="7">
      <title>Noise Be Gone: Does Speech Enhancement Distort Linguistic Nuances?</title>
      <author><first>Iñigo</first><last>Parra</last></author>
      <pages>52-60</pages>
      <abstract>This study evaluates the impact of speech enhancement (SE) techniques on linguistic research, focusing on their ability to maintain essential acoustic characteristics in enhanced audio without introducing significant artifacts. Through a sociophonetic analysis of Peninsular and Peruvian Spanish speakers, using both original and enhanced recordings, we demonstrate that SE effectively preserves critical speech nuances such as voicing and vowel quality. This supports the use of SE in improving the quality of speech samples. This study marks an initial effort to assess SE’s reliability in language studies and proposes a methodology for enhancing low-quality audio corpora of under-resourced languages.</abstract>
      <url hash="0be609fb">2024.fieldmatters-1.7</url>
      <bibkey>parra-2024-noise</bibkey>
      <doi>10.18653/v1/2024.fieldmatters-1.7</doi>
    </paper>
    <paper id="8">
      <title>Comparing <fixed-case>K</fixed-case>aldi-Based Pipeline Elpis and Whisper for Čakavian Transcription</title>
      <author><first>Austin</first><last>Jones</last><affiliation>University of Georgia</affiliation></author>
      <author><first>Shulin</first><last>Zhang</last></author>
      <author><first>John</first><last>Hale</last><affiliation>Johns Hopkins University, University of Georgia and DeepMind</affiliation></author>
      <author><first>Margaret</first><last>Renwick</last></author>
      <author><first>Zvjezdana</first><last>Vrzic</last><affiliation>NA</affiliation></author>
      <author><first>Keith</first><last>Langston</last><affiliation>University of Georgia</affiliation></author>
      <pages>61-68</pages>
      <abstract>Automatic speech recognition (ASR) has the potential to accelerate the documentation of endangered languages, but the dearth of resources poses a major obstacle. Čakavian, an endangered variety spoken primarily in Croatia, is a case in point, lacking transcription tools that could aid documentation efforts. We compare training a new ASR model on a limited dataset using the Kaldi-based ASR pipeline Elpis to using the same dataset to adapt the transformer-based pretrained multilingual model Whisper, to determine which is more practical in the documentation context. Results show that Whisper outperformed Elpis, achieving the lowest average Word Error Rate (WER) of 57.3% and median WER of 35.48%. While Elpis offers a less computationally expensive model and friendlier user experience, Whisper appears better at adapting to our collected Čakavian data.</abstract>
      <url hash="b623596a">2024.fieldmatters-1.8</url>
      <bibkey>jones-etal-2024-comparing</bibkey>
      <doi>10.18653/v1/2024.fieldmatters-1.8</doi>
    </paper>
    <paper id="9">
      <title>Zero-shot Cross-lingual <fixed-case>POS</fixed-case> Tagging for <fixed-case>F</fixed-case>ilipino</title>
      <author><first>Jimson</first><last>Layacan</last></author>
      <author><first>Isaiah Edri W.</first><last>Flores</last><affiliation>NA</affiliation></author>
      <author><first>Katrina</first><last>Tan</last></author>
      <author><first>Ma. Regina E.</first><last>Estuar</last><affiliation>NA</affiliation></author>
      <author><first>Jann</first><last>Montalan</last><affiliation>AI Singapore and Ateneo de Manila University</affiliation></author>
      <author><first>Marlene M.</first><last>De Leon</last><affiliation>NA</affiliation></author>
      <pages>69-77</pages>
      <abstract>Supervised learning approaches in NLP, exemplified by POS tagging, rely heavily on the presence of large amounts of annotated data. However, acquiring such data often requires significant amount of resources and incurs high costs. In this work, we explore zero-shot cross-lingual transfer learning to address data scarcity issues in Filipino POS tagging, particularly focusing on optimizing source language selection. Our zero-shot approach demonstrates superior performance compared to previous studies, with top-performing fine-tuned PLMs achieving F1 scores as high as 79.10%. The analysis reveals moderate correlations between cross-lingual transfer performance and specific linguistic distances–featural, inventory, and syntactic–suggesting that source languages with these features closer to Filipino provide better results. We identify tokenizer optimization as a key challenge, as PLM tokenization sometimes fails to align with meaningful representations, thus hindering POS tagging performance.</abstract>
      <url hash="bc2a362a">2024.fieldmatters-1.9</url>
      <bibkey>layacan-etal-2024-zero</bibkey>
      <doi>10.18653/v1/2024.fieldmatters-1.9</doi>
    </paper>
  </volume>
</collection>
