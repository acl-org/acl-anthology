<?xml version='1.0' encoding='UTF-8'?>
<collection id="2023.acl">
  <volume id="srw" ingest-date="2023-06-29">
    <meta>
      <booktitle>Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics - Student Research Workshop</booktitle>
      <editor><first>Vishakh</first><last>Padmakumar</last></editor>
      <editor><first>Gisela</first><last>Vallejo</last></editor>
      <editor><first>Yao</first><last>Fu</last></editor>
      <publisher>Association for Computational Linguistics</publisher>
      <address>Toronto, Canada</address>
      <month>July</month>
      <year>2023</year>
      <url hash="d8f06fd0">2023.acl-srw</url>
      <venue>acl</venue>
    </meta>
    <frontmatter>
      <url hash="44ac9b55">2023.acl-srw.0</url>
      <bibkey>acl-2023-association</bibkey>
    </frontmatter>
    <paper id="1">
      <title><fixed-case>C</fixed-case>hat<fixed-case>GPT</fixed-case> vs Human-authored Text: Insights into Controllable Text Summarization and Sentence Style Transfer</title>
      <author><first>Dongqi</first><last>Pu</last><affiliation>Saarland University</affiliation></author>
      <author><first>Vera</first><last>Demberg</last><affiliation>Saarland University</affiliation></author>
      <pages>1-18</pages>
      <abstract>ChatGPT Analysis</abstract>
      <url hash="14931f61">2023.acl-srw.1</url>
      <bibkey>pu-demberg-2023-chatgpt</bibkey>
    </paper>
    <paper id="2">
      <title>Multi-Dialectal Representation Learning of Sinitic Phonology</title>
      <author><first>Zhibai</first><last>Jia</last><affiliation>No.2 High School of East China Normal University</affiliation></author>
      <pages>19-29</pages>
      <abstract>Representation learning of Sinitic Phonology using a knowledge graph based method</abstract>
      <url hash="86e7ec92">2023.acl-srw.2</url>
      <attachment type="SupplementaryMaterial" hash="7bc909c5">2023.acl-srw.2.SupplementaryMaterial.zip</attachment>
      <bibkey>jia-2023-multi</bibkey>
    </paper>
    <paper id="4">
      <title>Prompt-based Zero-shot Text Classification with Conceptual Knowledge</title>
      <author><first>Yuqi</first><last>Wang</last><affiliation>Xi’an Jiaotong Liverpool University</affiliation></author>
      <author><first>Wei</first><last>Wang</last><affiliation>Xi’an Jiaotong Liverpool University</affiliation></author>
      <author><first>Qi</first><last>Chen</last><affiliation>Xi’an Jiaotong Liverpool University</affiliation></author>
      <author><first>Kaizhu</first><last>Huang</last><affiliation>Duke Kunshan University</affiliation></author>
      <author><first>Anh</first><last>Nguyen</last><affiliation>University of Liverpool</affiliation></author>
      <author><first>Suparna</first><last>De</last><affiliation>University of Surrey</affiliation></author>
      <pages>30-38</pages>
      <abstract>The proposed framework incorporates conceptual knowledge for prompt-based text classification in the extreme zero-shot setting, which outperforms existing approaches in sentiment analysis and topic detection on four widely-used datasets.</abstract>
      <url hash="32d39d3c">2023.acl-srw.4</url>
      <bibkey>wang-etal-2023-prompt</bibkey>
    </paper>
    <paper id="5">
      <title>How do different tokenizers perform on downstream tasks in scriptio continua languages?: A case study in <fixed-case>J</fixed-case>apanese</title>
      <author><first>Takuro</first><last>Fujii</last><affiliation>Yokohama National University</affiliation></author>
      <author><first>Koki</first><last>Shibata</last><affiliation>University of Tsukuba</affiliation></author>
      <author><first>Atsuki</first><last>Yamaguchi</last><affiliation>Hitachi, Ltd.</affiliation></author>
      <author><first>Terufumi</first><last>Morishita</last><affiliation>Hitachi.ltd</affiliation></author>
      <author><first>Yasuhiro</first><last>Sogawa</last><affiliation>Hitachi, Ltd.</affiliation></author>
      <pages>39-49</pages>
      <abstract>We investigate the impact of different tokenizers on downstream performance in Japanese NLP, with the case of BERT architecture.</abstract>
      <url hash="7805d815">2023.acl-srw.5</url>
      <bibkey>fujii-etal-2023-different</bibkey>
    </paper>
    <paper id="7">
      <title>Semantic-Aware Dynamic Retrospective-Prospective Reasoning for Event-Level Video Question Answering</title>
      <author><first>Chenyang</first><last>Lyu</last><affiliation>Dublin City University</affiliation></author>
      <author><first>Tianbo</first><last>Ji</last><affiliation>Nantong University</affiliation></author>
      <author><first>Yvette</first><last>Graham</last><affiliation>ADAPT, Trinity College Dublin</affiliation></author>
      <author><first>Jennifer</first><last>Foster</last><affiliation>Dublin City University</affiliation></author>
      <pages>50-56</pages>
      <abstract>The paper is about video QA. It utilizes SRL partitioning to improve multi-step attention and reasoning of the models to attend to different frames for different parts of the question.</abstract>
      <url hash="92b00d3d">2023.acl-srw.7</url>
      <bibkey>lyu-etal-2023-semantic</bibkey>
    </paper>
    <paper id="8">
      <title>Jamp: Controlled <fixed-case>J</fixed-case>apanese Temporal Inference Dataset for Evaluating Generalization Capacity of Language Models</title>
      <author><first>Tomoki</first><last>Sugimoto</last><affiliation>The University of Tokyo</affiliation></author>
      <author><first>Yasumasa</first><last>Onoe</last><affiliation>The University of Texas at Austin</affiliation></author>
      <author><first>Hitomi</first><last>Yanaka</last><affiliation>The University of Tokyo</affiliation></author>
      <pages>57-68</pages>
      <abstract>We construct Jamp, which is a Japanese NLI dataset for temporal inference, and evaluate the generalization capacity of several LMs on our dataset.</abstract>
      <url hash="7c374394">2023.acl-srw.8</url>
      <bibkey>sugimoto-etal-2023-jamp</bibkey>
    </paper>
    <paper id="10">
      <title>Constructing Multilingual Code Search Dataset Using Neural Machine Translation</title>
      <author><first>Ryo</first><last>Sekizawa</last><affiliation>The University of Tokyo</affiliation></author>
      <author><first>Nan</first><last>Duan</last><affiliation>Microsoft Research Asia</affiliation></author>
      <author><first>Shuai</first><last>Lu</last><affiliation>Microsoft</affiliation></author>
      <author><first>Hitomi</first><last>Yanaka</last><affiliation>The University of Tokyo</affiliation></author>
      <pages>69-75</pages>
      <abstract>We create a multilingual code search dataset by translating the existing English dataset with a machine translation model and conduct a baseline experiment on a code search task.</abstract>
      <url hash="dd8df7e4">2023.acl-srw.10</url>
      <bibkey>sekizawa-etal-2023-constructing</bibkey>
    </paper>
    <paper id="12">
      <title>Multimodal Neural Machine Translation Using Synthetic Images Transformed by Latent Diffusion Model</title>
      <author><first>Ryoya</first><last>Yuasa</last><affiliation>Doshisha University</affiliation></author>
      <author><first>Akihiro</first><last>Tamura</last><affiliation>Doshisha University</affiliation></author>
      <author><first>Tomoyuki</first><last>Kajiwara</last><affiliation>Ehime University</affiliation></author>
      <author><first>Takashi</first><last>Ninomiya</last><affiliation>Ehime University</affiliation></author>
      <author><first>Tsuneo</first><last>Kato</last><affiliation>Doshisha university</affiliation></author>
      <pages>76-82</pages>
      <abstract>This study proposes a new multimodal neural machine translation model using synthetic images transformed by a latent diffusion model.</abstract>
      <url hash="d793880d">2023.acl-srw.12</url>
      <bibkey>yuasa-etal-2023-multimodal</bibkey>
    </paper>
    <paper id="15">
      <title>Enhancing <fixed-case>A</fixed-case>ncient <fixed-case>C</fixed-case>hinese Understanding with Derived Noisy Syntax Trees</title>
      <author><first>Ping</first><last>Wang</last><affiliation>Wuhan University</affiliation></author>
      <author><first>Shitou</first><last>Zhang</last><affiliation>Wuhan University</affiliation></author>
      <author><first>Zuchao</first><last>Li</last><affiliation>Wuhan University</affiliation></author>
      <author><first>Jingrui</first><last>Hou</last><affiliation>Department of Computer Science,Loughborough University</affiliation></author>
      <pages>83-92</pages>
      <abstract>This paper introduces a confidence-based syntax encoding network (cSEN) to incorporate syntax in ancient Chinese understanding tasks, effectively improving performance by mitigating noise and incompatibility issues.</abstract>
      <url hash="39081656">2023.acl-srw.15</url>
      <bibkey>wang-etal-2023-enhancing</bibkey>
    </paper>
    <paper id="17">
      <title>The <fixed-case>T</fixed-case>uring Quest: Can Transformers Make Good <fixed-case>NPC</fixed-case>s?</title>
      <author><first>Qi Chen</first><last>Gao</last><affiliation>Brock University</affiliation></author>
      <author><first>Ali</first><last>Emami</last><affiliation>Brock University</affiliation></author>
      <pages>93-103</pages>
      <abstract>We explored the generation of NPC dialogue using a zero-shot prompting method as well as the ability of LMs to self-evaluate and score dialogue with few-shot learning.</abstract>
      <url hash="1b12fd49">2023.acl-srw.17</url>
      <bibkey>gao-emami-2023-turing</bibkey>
    </paper>
    <paper id="18">
      <title>Making the Most Out of the Limited Context Length: Predictive Power Varies with Clinical Note Type and Note Section</title>
      <author><first>Hongyi</first><last>Zheng</last><affiliation>Center for Data Science, New York University; Department of Neurosurgery, NYU Langone Health</affiliation></author>
      <author><first>Yixin</first><last>Zhu</last><affiliation>Center for Data Science, New York University; Department of Neurosurgery, NYU Langone Health</affiliation></author>
      <author><first>Lavender</first><last>Jiang</last><affiliation>Center for Data Science, New York University; Department of Neurosurgery, NYU Langone Health</affiliation></author>
      <author><first>Kyunghyun</first><last>Cho</last><affiliation>Center for Data Science and Courant Institute of Mathematical Sciences, New York University; Prescient Design; CIFAR</affiliation></author>
      <author><first>Eric</first><last>Oermann</last><affiliation>Department of Neurosurgery, NYU Langone Health; Department of Neurosurgery and Radiology, NYU Grossman School of Medicine</affiliation></author>
      <pages>104-108</pages>
      <abstract>We propose a data-driven framework to select clinical note sections with high predictive power.</abstract>
      <url hash="bc3e066d">2023.acl-srw.18</url>
      <bibkey>zheng-etal-2023-making</bibkey>
    </paper>
    <paper id="19">
      <title>Intriguing Effect of the Correlation Prior on <fixed-case>ICD</fixed-case>-9 Code Assignment</title>
      <author><first>Zihao</first><last>Yang</last><affiliation>Center for Data Science, New York University; Department of Neurosurgery, NYU Langone Health</affiliation></author>
      <author><first>Chenkang</first><last>Zhang</last><affiliation>Center for Data Science, New York University; Department of Neurosurgery, NYU Langone Health</affiliation></author>
      <author><first>Muru</first><last>Wu</last><affiliation>Center for Data Science, New York University; Department of Neurosurgery, NYU Langone Health</affiliation></author>
      <author><first>Xujin</first><last>Liu</last><affiliation>Department of Electrical and Computer Engineering, New York University; Department of Neurosurgery, NYU Langone Health</affiliation></author>
      <author><first>Lavender</first><last>Jiang</last><affiliation>Center of Data Science, New York University; Department of Neurosurgery, NYU Langone Health</affiliation></author>
      <author><first>Kyunghyun</first><last>Cho</last><affiliation>Center of Data Science &amp; Courant Institute of Mathematical Sciences, New York University; Prescient Design; CIFAR</affiliation></author>
      <author><first>Eric</first><last>Oermann</last><affiliation>Department of Neurosurgery, NYU Langone Health; Department of Neurosurgery and Radiology, NYU Grossman School of Medicine</affiliation></author>
      <pages>109-118</pages>
      <abstract>This paper investigates the usefulness of correlation bias in improving language models’ performance on predicting imbalanced clinical codes from discharge summaries.</abstract>
      <url hash="d23d745e">2023.acl-srw.19</url>
      <bibkey>yang-etal-2023-intriguing</bibkey>
    </paper>
    <paper id="20">
      <title>Classical Out-of-Distribution Detection Methods Benchmark in Text Classification Tasks</title>
      <author><first>Mateusz</first><last>Baran</last><affiliation>Wrocław University of Science and Technology</affiliation></author>
      <author><first>Joanna</first><last>Baran</last><affiliation>Wroclaw University of Science and Technology</affiliation></author>
      <author><first>Mateusz</first><last>Wójcik</last><affiliation>Wroclaw University of Science and Technology. Alphamoon Ltd.</affiliation></author>
      <author><first>Maciej</first><last>Zięba</last><affiliation>Wroclaw University of Science and Technology</affiliation></author>
      <author><first>Adam</first><last>Gonczarek</last><affiliation>Alphamoon Ltd.</affiliation></author>
      <pages>119-129</pages>
      <abstract>The paper evaluates existing OOD detection methods for NLP systems and emphasizes the need for further research to develop more effective approaches to ensure safety and trustworthiness of NLP systems.</abstract>
      <url hash="c6515660">2023.acl-srw.20</url>
      <attachment type="SupplementaryMaterial" hash="6402114e">2023.acl-srw.20.SupplementaryMaterial.zip</attachment>
      <bibkey>baran-etal-2023-classical</bibkey>
    </paper>
    <paper id="22">
      <title>Can <fixed-case>LM</fixed-case>s Store and Retrieve 1-to-N Relational Knowledge?</title>
      <author><first>Haruki</first><last>Nagasawa</last><affiliation>Tohoku University</affiliation></author>
      <author><first>Benjamin</first><last>Heinzerling</last><affiliation>RIKEN AIP &amp; Tohoku University</affiliation></author>
      <author><first>Kazuma</first><last>Kokuta</last><affiliation>Tohoku University</affiliation></author>
      <author><first>Kentaro</first><last>Inui</last><affiliation>Tohoku University / Riken</affiliation></author>
      <pages>130-138</pages>
      <abstract>Our study aimed to explore the feasibility of using LMs as KBs, and we focused specifically on 1-to-N relational knowledge, an area that has not been extensively researched, and proposed a comprehensive approach that involved identifying the unique characteristics of this type of knowledge, designing appropriate training methods, and developing evaluation perspectives.</abstract>
      <url hash="6971f41d">2023.acl-srw.22</url>
      <bibkey>nagasawa-etal-2023-lms</bibkey>
    </paper>
    <paper id="24">
      <title>Theoretical Linguistics Rivals Embeddings in Language Clustering for Multilingual Named Entity Recognition</title>
      <author><first>Sakura</first><last>Imai</last><affiliation>Waseda University</affiliation></author>
      <author><first>Daisuke</first><last>Kawahara</last><affiliation>Waseda University</affiliation></author>
      <author><first>Naho</first><last>Orita</last><affiliation>Waseda University</affiliation></author>
      <author><first>Hiromune</first><last>Oda</last><affiliation>The University of Tokyo</affiliation></author>
      <pages>139-151</pages>
      <abstract>This study investigates whether and how theoretical linguistics improves language clustering for multilingual named entity recognition (NER), with the two types of language groupings proposed: one based on morpho-syntactic features in a nominal domain and one based on a head parameter.</abstract>
      <url hash="318c1d81">2023.acl-srw.24</url>
      <bibkey>imai-etal-2023-theoretical</bibkey>
    </paper>
    <paper id="26">
      <title>Native Language Prediction from Gaze: a Reproducibility Study</title>
      <author><first>Lina</first><last>Skerath</last><affiliation>IT University of Copenhagen</affiliation></author>
      <author><first>Paulina</first><last>Toborek</last><affiliation>IT University of Copenhagen</affiliation></author>
      <author><first>Anita</first><last>Zielińska</last><affiliation>IT University of Copenhagen</affiliation></author>
      <author><first>Maria</first><last>Barrett</last><affiliation>IT University of Copenhagen</affiliation></author>
      <author><first>Rob</first><last>Van Der Goot</last><affiliation>IT University of Copenhagen</affiliation></author>
      <pages>152-159</pages>
      <abstract>A reproduction study of native language prediction from English as second language reading eye-tracking data.</abstract>
      <url hash="ba76735e">2023.acl-srw.26</url>
      <bibkey>skerath-etal-2023-native</bibkey>
    </paper>
    <paper id="27">
      <title><fixed-case>M</fixed-case>ed<fixed-case>T</fixed-case>em2.0: Prompt-based Temporal Classification of Treatment Events from Discharge Summaries</title>
      <author><first>Yang</first><last>Cui</last><affiliation>University of Manchester</affiliation></author>
      <author><first>Lifeng</first><last>Han</last><affiliation>The University of Manchester</affiliation></author>
      <author><first>Goran</first><last>Nenadic</last><affiliation>University of Manchester</affiliation></author>
      <pages>160-183</pages>
      <abstract>We use Prompt-based learning on LLMs for Temporal Classification of Treatment Events from Discharge Summaries of clinical data.</abstract>
      <url hash="517efa23">2023.acl-srw.27</url>
      <bibkey>cui-etal-2023-medtem2</bibkey>
    </paper>
    <paper id="28">
      <title>Sudden Semantic Shifts in <fixed-case>S</fixed-case>wedish <fixed-case>NATO</fixed-case> discourse</title>
      <author><first>Brian</first><last>Bonafilia</last><affiliation>Chalmers University of Technology</affiliation></author>
      <author><first>Bastiaan</first><last>Bruinsma</last><affiliation>Chalmers University of Technology</affiliation></author>
      <author><first>Denitsa</first><last>Saynova</last><affiliation>Chalmers University of Technology</affiliation></author>
      <author><first>Moa</first><last>Johansson</last><affiliation>Chalmers University of Technology</affiliation></author>
      <pages>184-193</pages>
      <abstract>We look at short-term semantic shifts in the Swedish discussion about NATO membership.</abstract>
      <url hash="9e42105e">2023.acl-srw.28</url>
      <bibkey>bonafilia-etal-2023-sudden</bibkey>
    </paper>
    <paper id="29">
      <title>Building a Buzzer-quiz Answering System</title>
      <author><first>Naoya</first><last>Sugiura</last><affiliation>Nagoya University</affiliation></author>
      <author><first>Kosuke</first><last>Yamada</last><affiliation>Nagoya university</affiliation></author>
      <author><first>Ryohei</first><last>Sasano</last><affiliation>Nagoya University</affiliation></author>
      <author><first>Koichi</first><last>Takeda</last><affiliation>Nagoya University</affiliation></author>
      <author><first>Katsuhiko</first><last>Toyama</last><affiliation>Nagoya University</affiliation></author>
      <pages>194-199</pages>
      <abstract>This paper presents two types of buzzer-quiz answering systems that can predict the answer from only part of a question and then proposes a method to estimate the accuracy of the answers for each system by using the internal scores of each model.</abstract>
      <url hash="21b4e3c7">2023.acl-srw.29</url>
      <bibkey>sugiura-etal-2023-building</bibkey>
    </paper>
    <paper id="30">
      <title>Probing for Hyperbole in Pre-Trained Language Models</title>
      <author><first>Nina</first><last>Schneidermann</last><affiliation>University of Copenhagen</affiliation></author>
      <author><first>Daniel</first><last>Hershcovich</last><affiliation>University of Copenhagen</affiliation></author>
      <author><first>Bolette</first><last>Pedersen</last><affiliation>University of Copenhagen</affiliation></author>
      <pages>200-211</pages>
      <abstract>This paper contributes to hyperbole identification research in NLP with two probing tasks (edge and MDL probing) for 3 pre-trained language models, as well as an attempt to shed light on problems annotating hyperbole.</abstract>
      <url hash="5bd81614">2023.acl-srw.30</url>
      <bibkey>schneidermann-etal-2023-probing</bibkey>
    </paper>
    <paper id="31">
      <title>Towards Efficient Dialogue Processing in the Emergency Response Domain</title>
      <author><first>Tatiana</first><last>Anikina</last><affiliation>DFKI / Saarland Informatics Campus</affiliation></author>
      <pages>212-225</pages>
      <abstract>This paper is about dialogue act classification and slot tagging in the emergency response domain.</abstract>
      <url hash="bb4799cb">2023.acl-srw.31</url>
      <bibkey>anikina-2023-towards</bibkey>
    </paper>
    <paper id="33">
      <title><fixed-case>I</fixed-case> already said that! Degenerating redundant questions in open-domain dialogue systems.</title>
      <author><first>Long</first><last>Mai</last><affiliation>University College Dublin</affiliation></author>
      <author><first>Julie</first><last>Carson-berndsen</last><affiliation>University College Dublin</affiliation></author>
      <pages>226-236</pages>
      <abstract>This paper propose methods to reduce the number of redundant questions generated by open-domain dialogue systems.</abstract>
      <url hash="6dc7fccc">2023.acl-srw.33</url>
      <bibkey>mai-carson-berndsen-2023-already</bibkey>
    </paper>
    <paper id="34">
      <title>Is a Knowledge-based Response Engaging?: An Analysis on Knowledge-Grounded Dialogue with Information Source Annotation</title>
      <author><first>Takashi</first><last>Kodama</last><affiliation>Kyoto University</affiliation></author>
      <author><first>Hirokazu</first><last>Kiyomaru</last><affiliation>Kyoto University</affiliation></author>
      <author><first>Yin Jou</first><last>Huang</last><affiliation>Kyoto University</affiliation></author>
      <author><first>Taro</first><last>Okahisa</last><affiliation>Shizuoka University</affiliation></author>
      <author><first>Sadao</first><last>Kurohashi</last><affiliation>Kyoto University</affiliation></author>
      <pages>237-243</pages>
      <abstract>This paper investigates how humans incorporate speaker-derived information by annotating the utterances in a knowledge-grounded dialogue corpus.</abstract>
      <url hash="7d7191ff">2023.acl-srw.34</url>
      <bibkey>kodama-etal-2023-knowledge</bibkey>
    </paper>
    <paper id="35">
      <title>Choosing What to Mask: More Informed Masking for Multimodal Machine Translation</title>
      <author><first>Julia</first><last>Sato</last><affiliation>Federal University of Sao Carlos</affiliation></author>
      <author><first>Helena</first><last>Caseli</last><affiliation>Federal University of São Carlos</affiliation></author>
      <author><first>Lucia</first><last>Specia</last><affiliation>Imperial College London</affiliation></author>
      <pages>244-253</pages>
      <abstract>More informed masking in cross-lingual visual pre-training for multimodal machine translation.</abstract>
      <url hash="ed7f9453">2023.acl-srw.35</url>
      <bibkey>sato-etal-2023-choosing</bibkey>
    </paper>
    <paper id="36">
      <title>Combining Tradition with Modernness: Exploring Event Representations in Vision-and-Language Models for Visual Goal-Step Inference</title>
      <author><first>Chong</first><last>Shen</last><affiliation>University of Stuttgart</affiliation></author>
      <author><first>Carina</first><last>Silberer</last><affiliation>University of Stuttgart</affiliation></author>
      <pages>254-265</pages>
      <abstract>This paper studies various methods and their effects on multimodal procedural knowledge understanding of injecting the early shallow017 event representations to nowadays multimodal deep learning-based models.</abstract>
      <url hash="890fb69a">2023.acl-srw.36</url>
      <bibkey>shen-silberer-2023-combining</bibkey>
    </paper>
    <paper id="37">
      <title>Data Selection for Fine-tuning Large Language Models Using Transferred Shapley Values</title>
      <author><first>Stephanie</first><last>Schoch</last><affiliation>University of Virginia</affiliation></author>
      <author><first>Yangfeng</first><last>Ji</last><affiliation>University of Virginia</affiliation></author>
      <author><first>Ritwick</first><last>Mishra</last><affiliation>University of Virginia</affiliation></author>
      <pages>266-275</pages>
      <abstract>This paper proposes a sampling chain based method to make Shapley values computationally feasible for data valuation and selection for large language models.</abstract>
      <url hash="0e209134">2023.acl-srw.37</url>
      <bibkey>schoch-etal-2023-data</bibkey>
    </paper>
    <paper id="38">
      <title>Distractor Generation for Fill-in-the-Blank Exercises by Question Type</title>
      <author><first>Nana</first><last>Yoshimi</last><affiliation>Ehime University</affiliation></author>
      <author><first>Tomoyuki</first><last>Kajiwara</last><affiliation>Ehime University</affiliation></author>
      <author><first>Satoru</first><last>Uchida</last><affiliation>Kyushu University</affiliation></author>
      <author><first>Yuki</first><last>Arase</last><affiliation>Osaka University</affiliation></author>
      <author><first>Takashi</first><last>Ninomiya</last><affiliation>Ehime University</affiliation></author>
      <pages>276-281</pages>
      <abstract>We define three types of questions (grammar, function word, and context) for fill-in-the-blank exercises and propose a method to generate distractors according to the characteristics of each question type.</abstract>
      <url hash="34f8aa38">2023.acl-srw.38</url>
      <bibkey>yoshimi-etal-2023-distractor</bibkey>
    </paper>
    <paper id="40">
      <title>Moral Mimicry: Large Language Models Produce Moral Rationalizations Tailored to Political Identity</title>
      <author><first>Gabriel</first><last>Simmons</last><affiliation>University of California, Davis</affiliation></author>
      <pages>282-297</pages>
      <abstract>This paper studies whether LLMs moral preferences based on prompted political ideology replicate known results obtained in social science studies, using tools from Moral Foundations Theory</abstract>
      <url hash="9b4c8c27">2023.acl-srw.40</url>
      <bibkey>simmons-2023-moral</bibkey>
    </paper>
    <paper id="43">
      <title><fixed-case>LECO</fixed-case>: Improving Early Exiting via Learned Exits and Comparison-based Exiting Mechanism</title>
      <author><first>Jingfan</first><last>Zhang</last><affiliation>Univ of Ottawa</affiliation></author>
      <author><first>Ming</first><last>Tan</last><affiliation>Tencent</affiliation></author>
      <author><first>Pengyu</first><last>Dai</last><affiliation>Sjtu</affiliation></author>
      <author><first>Wei</first><last>Zhu</last><affiliation>East China Normal University</affiliation></author>
      <pages>298-309</pages>
      <abstract>Speeding up the inference of pretrained models by designing better intermediate early exits and a comparison-based early exiting mechanism</abstract>
      <url hash="98549855">2023.acl-srw.43</url>
      <bibkey>zhang-etal-2023-leco</bibkey>
    </paper>
    <paper id="44">
      <title>Authorship Attribution of Late 19th Century Novels using <fixed-case>GAN</fixed-case>-<fixed-case>BERT</fixed-case></title>
      <author><first>Kanishka</first><last>Silva</last><affiliation>University of Wolverhampton</affiliation></author>
      <author><first>Burcu</first><last>Can</last><affiliation>University of Stirling</affiliation></author>
      <author><first>Frédéric</first><last>Blain</last><affiliation>Tilburg University</affiliation></author>
      <author><first>Raheem</first><last>Sarwar</last><affiliation>OTEHM, Manchester Metropolitan University</affiliation></author>
      <author><first>Laura</first><last>Ugolini</last><affiliation>University of Wolverhampton</affiliation></author>
      <author><first>Ruslan</first><last>Mitkov</last><affiliation>University of Wolverhampton</affiliation></author>
      <pages>310-320</pages>
      <abstract>This paper is about performing authorship attribution of long 19th-century novels using the GAN-BERT model, comparing author counts, author combinations and sample text sizes.</abstract>
      <url hash="b31cd570">2023.acl-srw.44</url>
      <bibkey>silva-etal-2023-authorship</bibkey>
    </paper>
    <paper id="46">
      <title>How-to Guides for Specific Audiences: A Corpus and Initial Findings</title>
      <author><first>Nicola</first><last>Fanton</last><affiliation>Universität Stuttgart</affiliation></author>
      <author><first>Agnieszka</first><last>Falenska</last><affiliation>IMS, University of Stuttgart</affiliation></author>
      <author><first>Michael</first><last>Roth</last><affiliation>University of Stuttgart</affiliation></author>
      <pages>321-333</pages>
      <abstract>We collect how-to guides for different target audiences and investigate qualitative and quantitative differences.</abstract>
      <url hash="fd5a1489">2023.acl-srw.46</url>
      <bibkey>fanton-etal-2023-guides</bibkey>
    </paper>
    <paper id="47">
      <title>“When Words Fail, Emojis Prevail”: A Novel Architecture for Generating Sarcastic Sentences With Emoji Using Valence Reversal and Semantic Incongruity</title>
      <author><first>Faria Binte</first><last>Kader</last><affiliation>Islamic University of Technology</affiliation></author>
      <author><first>Nafisa</first><last>Hossain Nujat</last><affiliation>Islamic University of Technology</affiliation></author>
      <author><first>Tasmia Binte</first><last>Sogir</last><affiliation>Islamic University of Technology</affiliation></author>
      <author><first>Mohsinul</first><last>Kabir</last><affiliation>Islamic University of Technology</affiliation></author>
      <author><first>Hasan</first><last>Mahmud</last><affiliation>Associate Professor</affiliation></author>
      <author><first>Md Kamrul</first><last>Hasan</last><affiliation>Islamic University of Technology</affiliation></author>
      <pages>334-351</pages>
      <abstract>A new framework in which when given a non-sarcastic text as input, the text is converted into a sarcastic one with emoji where the emoji will specifically help to identify the sarcastic intent of the text.</abstract>
      <url hash="c23cc187">2023.acl-srw.47</url>
      <bibkey>kader-etal-2023-words</bibkey>
    </paper>
    <paper id="48">
      <title>Semantic Accuracy in Natural Language Generation: A Thesis Proposal</title>
      <author><first>Patricia</first><last>Schmidtova</last><affiliation>Charles University</affiliation></author>
      <pages>352-361</pages>
      <abstract>We propose a thesis in which we explore how evaluation and interpretability techniques could lead to better natural language generation systems.</abstract>
      <url hash="a4d44d8d">2023.acl-srw.48</url>
      <bibkey>schmidtova-2023-semantic</bibkey>
    </paper>
  </volume>
</collection>
