<?xml version='1.0' encoding='UTF-8'?>
<collection id="2024.icon">
  <volume id="fauxhate" ingest-date="2025-01-28" type="proceedings">
    <meta>
      <booktitle>Proceedings of the 21st International Conference on Natural Language Processing (ICON): Shared Task on Decoding Fake Narratives in Spreading Hateful Stories (Faux-Hate)</booktitle>
      <editor><first>Shankar</first><last>Biradar</last></editor>
      <editor><first>Kasu Sai Kartheek</first><last>Reddy</last></editor>
      <editor><first>Sunil</first><last>Saumya</last></editor>
      <editor><first>Md. Shad</first><last>Akhtar</last></editor>
      <publisher>NLP Association of India (NLPAI)</publisher>
      <address>AU-KBC Research Centre, Chennai, India</address>
      <month>December</month>
      <year>2024</year>
      <venue>icon</venue>
    </meta>
    <frontmatter>
      <url hash="40d11d96">2024.icon-fauxhate.0</url>
      <bibkey>icon-2024-fauxhate</bibkey>
    </frontmatter>
    <paper id="1">
      <title>Proceedings of the 21st International Conference on Natural Language Processing (<fixed-case>ICON</fixed-case>): Shared Task on Decoding Fake Narratives in Spreading Hateful Stories (Faux-Hate)</title>
      <author><first>Shankar</first><last>Biradar</last></author>
      <author><first>Kasu Sai Kartheek</first><last>Reddy</last></author>
      <author><first>Sunil</first><last>Saumya</last></author>
      <author><first>Md. Shad</first><last>Akhtar</last></author>
      <pages>1–5</pages>
      <abstract>The rapid expansion of social media has led toan increase in code-mixed content, presentingsignificant challenges in the effective detectionof hate speech and fake narratives. To advanceresearch in this area, a shared task titled De-coding Fake Narratives in Spreading HatefulStories (Faux-Hate) was organized as part ofICON 2024. This paper introduces a multi-task learning model designed to classify Hindi-English code-mixed tweets into two distinct cat-egories: hate speech and false content. The pro-posed framework utilizes fastText embeddingsto create a shared feature space that adeptly cap-tures the semantic and syntactic intricacies ofcode-mixed text, including transliterated termsand out-of-vocabulary words. These sharedembeddings are then processed through twoindependent Support Vector Machine (SVM)classifiers, each specifically tailored for oneof the classification tasks. Our team, secured10th place among the participating teams, asevaluated by the organizers based on Macro F1scores.</abstract>
      <url hash="b0228956">2024.icon-fauxhate.1</url>
      <bibkey>biradar-etal-2024-proceedings</bibkey>
    </paper>
    <paper id="2">
      <title>Unpacking Faux-Hate: Addressing Faux-Hate Detection and Severity Prediction in Code-Mixed <fixed-case>H</fixed-case>inglish Text with <fixed-case>H</fixed-case>ing<fixed-case>R</fixed-case>o<fixed-case>BERT</fixed-case>a and Class Weighting Techniques</title>
      <author><first>Ashweta</first><last>A. Fondekar</last></author>
      <author><first>Milind</first><last>M. Shivolkar</last></author>
      <author><first>Jyoti</first><last>D. Pawar</last></author>
      <pages>6–11</pages>
      <abstract>The proliferation of hate speech and fake narra-tives on social media poses significant societalchallenges, especially in multilingual and code-mixed contexts. This paper presents our systemsubmitted to the ICON 2024 shared task onDecoding Fake Narratives in Spreading Hate-ful Stories (Faux-Hate). We tackle the prob-lem of Faux-Hate Detection, which involvesdetecting fake narratives and hate speech incode-mixed Hinglish text. Leveraging Hin-gRoBERTa, a pre-trained transformer modelfine-tuned on Hinglish datasets, we addresstwo sub-tasks: Binary Faux-Hate Detection andTarget and Severity Prediction. Through the in-troduction of class weighting techniques andthe optimization of a multi-task learning ap-proach, we demonstrate improved performancein identifying hate and fake speech, as well asin classifying their target and severity. Thisresearch contributes to a scalable and efficientframework for addressing complex real-worldtext processing challenges.</abstract>
      <url hash="0a1d4844">2024.icon-fauxhate.2</url>
      <bibkey>a-fondekar-etal-2024-unpacking</bibkey>
    </paper>
    <paper id="3">
      <title>Decoding Fake Narratives in Spreading Hateful Stories: A Dual-Head <fixed-case>R</fixed-case>o<fixed-case>BERT</fixed-case>a Model with Multi-Task Learning</title>
      <author><first>Yash</first><last>Bhaskar</last></author>
      <author><first>Sankalp</first><last>Bahad</last></author>
      <author><first>Parameswari</first><last>Krishnamurthy</last></author>
      <pages>12–15</pages>
      <abstract>Social media platforms, while enabling globalconnectivity, have become hubs for the rapidspread of harmful content, including hatespeech and fake narratives (Davidson et al.,2017; Shu et al., 2017). The Faux-Hateshared task focuses on detecting a specific phe-nomenon: the generation of hate speech drivenby fake narratives, termed Faux-Hate. Partici-pants are challenged to identify such instancesin code-mixed Hindi-English social media text.This paper describes our system developed forthe shared task, addressing two primary sub-tasks: (a) Binary Faux-Hate detection, involv-ing fake and hate speech classification, and(b) Target and Severity prediction, categoriz-ing the intended target and severity of hate-ful content. Our approach combines advancednatural language processing techniques withdomain-specific pretraining to enhance perfor-mance across both tasks. The system achievedcompetitive results, demonstrating the efficacyof leveraging multi-task learning for this com-plex problem.</abstract>
      <url hash="53ac13ad">2024.icon-fauxhate.3</url>
      <bibkey>bhaskar-etal-2024-decoding</bibkey>
    </paper>
    <paper id="4">
      <title>Challenges and Insights in Identifying Hate Speech and Fake News on Social Media</title>
      <author><first>Shanthi</first><last>Murugan</last></author>
      <author><first>Arthi</first><last>R</last></author>
      <author><first>Boomika</first><last>E</last></author>
      <author><first>Jeyanth</first><last>S</last></author>
      <author><first>Kaviyarasu</first><last>S</last></author>
      <pages>16–21</pages>
      <abstract>Social media has transformed communication, but it has also brought abouta number of serious problems, most notablythe proliferation of hate speech and falseinformation. hate-related conversations arefrequently fueled by misleading narratives.We address this issue by building a multiclassclassification model trained on Faux HateMulti-Label Dataset (Biradar et al. 2024)which consists of hateful remarks that arefraudulent and have a code mix of Hindi andEnglish. Model has been built to classifySeverity (Low, Medium, High) and Target(Individual, Organization, Religion) on thedataset. Performance of the model isevaluated on test dataset achieved varyingscored for each. For Severity model achieves74%, for Target model achieves 74%. Thelimitations and performance issues of themodel has been understood and wellexplained.</abstract>
      <url hash="320fe6cb">2024.icon-fauxhate.4</url>
      <bibkey>murugan-etal-2024-challenges</bibkey>
    </paper>
    <paper id="5">
      <title>Detecting Hate Speech and Fake Narratives in Code-Mixed <fixed-case>H</fixed-case>inglish Social Media Text</title>
      <author><first>Advaitha</first><last>Vetagiri</last></author>
      <author><first>Partha</first><last>Pakray</last></author>
      <pages>22–28</pages>
      <abstract>The increasing prevalence of hate speech and fake narratives on social media platforms posessignificant societal challenges. This study ad-dresses these issues through the developmentof robust machine learning models for twotasks: (1) detecting hate speech and fake nar-ratives (Task A) and (2) predicting the targetand severity of hateful content (Task B) incode-mixed Hindi-English text. We proposefour separate CNN-BiLSTM models tailoredfor each subtask. The models were evaluatedusing validation and 5-fold cross-validationdatasets, achieving F1-scores of 74% and 79%for hate and fake detection, respectively, and63% and 54% for target and severity predic-tion and achieved 65% and 57% for testingresults. The results highlight the models’ effec-tiveness in handling the nuances of code-mixedtext while underscoring the challenges of under-represented classes. This work contributes tothe ongoing effort to develop automated toolsfor detecting and mitigating harmful contentonline, paving the way for safer and more in-clusive digital spaces.</abstract>
      <url hash="54e1800b">2024.icon-fauxhate.5</url>
      <bibkey>vetagiri-pakray-2024-detecting</bibkey>
    </paper>
    <paper id="6">
      <title>Transformer-driven Multi-task Learning for Fake and Hateful Content Detection</title>
      <author><first>Asha</first><last>Hegde</last></author>
      <author><first>H L</first><last>Shashirekha</last></author>
      <pages>29–35</pages>
      <abstract>Social media has revolutionized communica-tion these days in addition to facilitating thespread of fake and hate content. While fakecontent is the manipulation of facts by disin-formation, hate content is textual violence ordiscrimination targeting a group or an individ-ual. Fake narratives have the potential to spreadhate content making people aggressive or hurt-ing the sentiments of an individual or a group.Further, false narratives often dominate discus-sions on sensitive topics, amplifying harmfulmessages contributing to the rise of hate speech.Hence, understanding the relationship betweenhate speech driven by fake narratives is cru-cial in this digital age making it necessary todevelop automatic tools to identify fake andhate content. In this direction, Decoding FakeNarratives in Spreading Hateful Stories (Faux-Hate) - a shared task organized at the Inter-national Conference on Natural Language Pro-cessing (ICON) 2024, invites researchers totackle both fake and hate detection in socialmedia comments, with additional emphasis onidentifying the target and severity of hatefulspeech. The shared task consists of two sub-tasks - Task A (Identifying fake and hate con-tent) and Task B (Identifying the target andseverity of hateful speech). In this paper, we -team MUCS, describe the models proposed toaddress the challenges of this shared task. Wepropose two models: i) Hing_MTL - a Multi-task Learning (MTL) model implemented us-ing pre-trained Hinglish Bidirectional EncoderRepresentations from Transformers (Hinglish-BERT), and ii) Ensemble_MTL - a MTL modelimplemented by ensembling two pre-trainedmodels (HinglishBERT, and Multilingual Dis-tiled version of BERT (MDistilBERT)), to de-tect fake and hate content and identify the targetand severity of hateful speech. Ensemble_MTLmodel outperformed Hing_MTL model withmacro F1 scores of 0.7589 and 0.5746 for TaskA and Task B respectively, securing 6th placein both subtasks.</abstract>
      <url hash="a3f7fe0c">2024.icon-fauxhate.6</url>
      <bibkey>hegde-shashirekha-2024-transformer</bibkey>
    </paper>
    <paper id="7">
      <title>Rejected Cookies @ Decoding Faux-Hate: Predicting Fake Narratives and Hateful Content</title>
      <author><first>Joel</first><last>D Joy</last></author>
      <author><first>Naman</first><last>Srivastava</last></author>
      <pages>36–39</pages>
      <abstract>This paper reports the results of our team for theICON 2024 shared task Decoding Fake Narra-tives in Spreading Hateful Stories (Faux-Hate).The task aims at classifying tweets in a multi-label and multi-class framework. It comprisestwo subtasks: (A) Binary Faux-Hate Detec-tion, which involves predicting whether a tweetis fake (1/0) and/or hate speech (1/0, and (B)Target and Severity Prediction, which cate-gorizes tweets based on their target (Individ-ual, Organization, Religion) and severity (Low,Medium, High). We evaluated Machine Learn-ing (ML) approaches, including Logistic Re-gression, Support Vector Machines (SVM), andRandom Forest; Deep Learning (DL) methods,such as Artificial Neural Networks (ANN) andBidirectional Encoder Representations fromTransformers (BERT); and innovative quantumhybrid models, like Hybrid Quantum NeuralNetworks (HQNN), for identifying and classi-fying tweets across these subtasks. Our exper-iments trained and compared multiple modelarchitectures to assess their comparative per-formance and detection capabilities in these di-verse modeling strategies.The best-performingmodels achieved F1 scores of 0.72, 0.76, 0.64,and 0.54 for the respective labels Hate, Fake,Target and Severity. We have open-sourced ourimplementation code for both tasks on Github1 .</abstract>
      <url hash="bff06436">2024.icon-fauxhate.7</url>
      <bibkey>d-joy-srivastava-2024-rejected</bibkey>
    </paper>
    <paper id="8">
      <title>A Machine Learning Framework for Detecting Hate Speech and Fake Narratives in <fixed-case>H</fixed-case>indi-<fixed-case>E</fixed-case>nglish Tweets</title>
      <author><first>R.n.</first><last>Yadawad</last></author>
      <author><first>Sunil</first><last>Saumya</last></author>
      <author><first>K.n.</first><last>Nivedh</last></author>
      <author><first>Siddhaling S.</first><last>Padanur</last></author>
      <author><first>Sudev</first><last>Basti</last></author>
      <pages>40–44</pages>
      <abstract>This paper presents a novel system developed for the Faux-Hate Shared Task at ICON2024, addressing the detection of hate speechand fake narratives within Hindi-English code-mixed social media data. Our approach com-bines advanced text preprocessing, TF-IDFvectorization, and Random Forest classifiersto identify harmful content, while employingSMOTE to address class imbalance. By lever-aging ensemble learning and feature engineer-ing, our system demonstrates robust perfor-mance in detecting hateful and fake content,classifying targets, and evaluating the sever-ity of hate speech. The results underscore thepotential for real-world applications, such asmoderating online platforms and identifyingharmful narratives. Furthermore, we highlightethical considerations for deploying such tools,emphasizing responsible use in sensitive do-mains, thereby advancing research in multilin-gual hate speech detection and online abusemitigation.</abstract>
      <url hash="b13ad069">2024.icon-fauxhate.8</url>
      <bibkey>yadawad-etal-2024-machine</bibkey>
    </paper>
    <paper id="9">
      <title>Faux-Hate Multitask Framework for Misinformation and Hate Speech Detection in Code-Mixed Languages</title>
      <author><first>Sunil Gopal</first><last>C V</last></author>
      <author><first>Sudhan</first><last>S</last></author>
      <author><first>Shreyas Gutti</first><last>Srinivas</last></author>
      <author><first>Sushanth</first><last>R</last></author>
      <author><first>Abhilash</first><last>C B</last></author>
      <pages>45–49</pages>
      <abstract>The Faux-Hate task looks at two big issues:misinformation and hate speech. It focuses onHindi-English social media posts. This papershares our methods for both parts of the task.For Task A, we built a special model based onXLM-RoBERTa. It has features that help usspot both fake news and hate speech at the sametime. For Task B, we wanted to identify whothe hate is aimed at (like individuals or groups)and how severe it is (high, medium, low). So,we added different tools to our model for thiskind of sorting. To get ready for all this, wecarefully cleaned the data, especially dealingwith mixing languages and different spellings.In Task A, our results show that our model canclearly tell the difference between fake and realstories, as well as between hate and non-hatespeech. For Task B, it does a good job withidentifying targets and severity levels, givingstrong predictions for multiple labels. Overall,these results show that cross-lingual models,combined with specific tweaks, can really helptackle complex text classification in languageswith fewer resources.</abstract>
      <url hash="f85af2e8">2024.icon-fauxhate.9</url>
      <bibkey>c-v-etal-2024-faux</bibkey>
    </paper>
    <paper id="10">
      <title>Multi-Task Learning for Faux-Hate Detection in <fixed-case>H</fixed-case>indi-<fixed-case>E</fixed-case>nglish Code-Mixed Text</title>
      <author><first>Hitesh</first><last>N P</last></author>
      <author><first>D</first><last>Ankith</last></author>
      <author><first>Poornachandra</first><last>A N</last></author>
      <author><first>Abhilash</first><last>C B</last></author>
      <pages>50–55</pages>
      <abstract>The prevalence of harmful internet content is on the rise, especially among young people. Thismakes social media sites breeding grounds forhate speech and negativity even though theirpurpose is to create connections. The study pro-poses a multi-task learning model for the iden-tification and analysis of harmful social mediacontent. This classifies the text into fake/realand hate/non-hate categories and further identi-fies the target and severity of the harmful con-tent. The proposed model showed significantimprovements in performance with training ontransliterated data as compared to code-mixeddata. It ranked 2nd and 3rd in the ICON 2024Faux-Hate Shared Task and the performanceshave made it very effective against harmful con-tent.</abstract>
      <url hash="10bd3550">2024.icon-fauxhate.10</url>
      <bibkey>n-p-etal-2024-multi</bibkey>
    </paper>
    <paper id="11">
      <title><fixed-case>L</fixed-case>o<fixed-case>RA</fixed-case> adapter weight tuning with multi-task learning for Faux-Hate detection</title>
      <author><first>Abhinandan</first><last>Onajol</last></author>
      <author><first>Varun</first><last>Gani</last></author>
      <author><first>Praneeta</first><last>Marakatti</last></author>
      <author><first>Bhakti</first><last>Malwankar</last></author>
      <author><first>Shankar</first><last>Biradar</last></author>
      <pages>56–60</pages>
      <abstract>Detecting misinformation and harmful language in bilingual texts, particularly those com-bining Hindi and English, poses considerabledifficulties. The intricacies of mixed-languagecontent and limited available resources compli-cate this task even more. The proposed workfocuses on unraveling deceptive stories thatpropagate hate. We have developed an inno-vative attention-weight-tuned LoRA Adopter-based model for such Faux-Hate content de-tection. This work is conducted as a partof the ICON 2024 shared task on DecodingFake narratives in spreading Hateful stories.The LoRA-enhanced architecture secured 13thplace among the participating teams for TaskA.</abstract>
      <url hash="ad912fa6">2024.icon-fauxhate.11</url>
      <bibkey>onajol-etal-2024-lora</bibkey>
    </paper>
    <paper id="12">
      <title>Shared Feature-Based Multitask Model for Faux-Hate Classification in Code-Mixed Text</title>
      <author><first>Sanjana</first><last>Kavatagi</last></author>
      <author><first>Rashmi</first><last>Rachh</last></author>
      <author><first>Prakul</first><last>Hiremath</last></author>
      <pages>61–65</pages>
      <abstract>In recent years, the rise of harmful narratives online has highlighted the need for advancedhate speech detection models. One emergingchallenge is the phenomenon of Faux Hate, anew type of hate speech that originates fromthe intersection of fake narratives and hatespeech. Faux Hate occurs when fabricatedclaims fuel the generation of hateful language,often blurring the line between misinforma-tion and malicious intent. Identifying suchspeech becomes especially difficult when thefake claim itself is not immediately apparent.This paper provides an overview of a sharedtask competition focused on detecting FauxHate, where participants were tasked with de-veloping methodologies to identify this nu-anced form of harmful speech.</abstract>
      <url hash="33305de5">2024.icon-fauxhate.12</url>
      <bibkey>kavatagi-etal-2024-shared</bibkey>
    </paper>
  </volume>
</collection>
