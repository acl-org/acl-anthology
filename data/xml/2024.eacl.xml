<?xml version='1.0' encoding='UTF-8'?>
<collection id="2024.eacl">
  <volume id="demo" ingest-date="2024-03-03" type="proceedings">
    <meta>
      <booktitle>Proceedings of the The 18th Conference of the European Chapter of the Association for Computational Linguistics: System Demonstrations</booktitle>
      <editor><first>Nikolaos</first><last>Aletras</last></editor>
      <editor><first>Orphee</first><last>De Clercq</last></editor>
      <publisher>Association for Computational Linguistics</publisher>
      <address>St. Julians, Malta</address>
      <month>March</month>
      <year>2024</year>
      <url hash="a56379aa">2024.eacl-demo</url>
      <venue>eacl</venue>
    </meta>
    <frontmatter>
      <url hash="96e3f288">2024.eacl-demo.0</url>
      <bibkey>eacl-2024-european</bibkey>
    </frontmatter>
    <paper id="1">
      <title><fixed-case>T</fixed-case>ext<fixed-case>BI</fixed-case>: An Interactive Dashboard for Visualizing Multidimensional <fixed-case>NLP</fixed-case> Annotations in Social Media Data</title>
      <author><first>Maxime</first><last>Masson</last><affiliation>LIUPPA, E2S, University of Pau and Pays Adour</affiliation></author>
      <author><first>Christian</first><last>Sallaberry</last><affiliation>LIUPPA, E2S, University of Pau and Pays Adour (UPPA)</affiliation></author>
      <author><first>Marie-Noelle</first><last>Bessagnet</last><affiliation>LIUPPA, E2S, University of Pau and Pays Adour (UPPA)</affiliation></author>
      <author><first>Annig</first><last>Le Parc Lacayrelle</last><affiliation>LIUPPA, E2S, University of Pau and Pays Adour (UPPA)</affiliation></author>
      <author><first>Philippe</first><last>Roose</last><affiliation>LIUPPA, E2S, University of Pau and Pays Adour (UPPA)</affiliation></author>
      <author><first>Rodrigo</first><last>Agerri</last><affiliation>HiTZ Center-Ixa, University of the Basque Country UPV/EHU</affiliation></author>
      <pages>1-9</pages>
      <abstract>In this paper we introduce TextBI, a multimodal generic dashboard designed to present multidimensional text annotations on large volumes of multilingual social media data. This tool focuses on four core dimensions: spatial, temporal, thematic, and personal, and also supports additional enrichment data such as sentiment and engagement. Multiple visualization modes are offered, including frequency, movement, and association. This dashboard addresses the challenge of facilitating the interpretation of NLP annotations by visualizing them in a user-friendly, interactive interface catering to two categories of users: (1) domain stakeholders and (2) NLP researchers. We conducted experiments within the domain of tourism leveraging data from X (formerly Twitter) and incorporating requirements from tourism offices. Our approach, TextBI, represents a significant advancement in the field of visualizing NLP annotations by integrating and blending features from a variety of Business Intelligence, Geographical Information Systems and NLP tools. A demonstration video is also provided https://youtu.be/x714RKvo9Cg</abstract>
      <url hash="df77c7ee">2024.eacl-demo.1</url>
      <bibkey>masson-etal-2024-textbi</bibkey>
    </paper>
    <paper id="2">
      <title>k<fixed-case>NN</fixed-case>-<fixed-case>BOX</fixed-case>: A Unified Framework for Nearest Neighbor Generation</title>
      <author><first>Wenhao</first><last>Zhu</last><affiliation>National Key Laboratory for Novel Software Technology, Nanjing University</affiliation></author>
      <author><first>Qianfeng</first><last>Zhao</last><affiliation>Nanjing University</affiliation></author>
      <author><first>Yunzhe</first><last>Lv</last><affiliation>Nanjing University</affiliation></author>
      <author><first>Shujian</first><last>Huang</last><affiliation>National Key Laboratory for Novel Software Technology, Nanjing University</affiliation></author>
      <author><first>Siheng</first><last>Zhao</last><affiliation>Nanjing University</affiliation></author>
      <author><first>Sizhe</first><last>Liu</last><affiliation>Nanjing University</affiliation></author>
      <author><first>Jiajun</first><last>Chen</last><affiliation>Nanjing University</affiliation></author>
      <pages>10-17</pages>
      <abstract>Augmenting the base neural model with a token-level symbolic datastore is a novel generation paradigm and has achieved promising results in machine translation (MT). In this paper, we introduce a unified framework kNN-BOX, which enables quick development and visualization for this novel paradigm. kNN-BOX decomposes the datastore-augmentation approach into three modules: datastore, retriever and combiner, thus putting diverse kNN generation methods into a unified way. Currently, kNN-BOX has provided implementation of seven popular kNN-MT variants, covering research from performance enhancement to efficiency optimization. It is easy for users to reproduce these existing work or customize their own models. Besides, users can interact with their kNN generation systems with kNN-BOX to better understand the underlying inference process in a visualized way. In experiment section, we apply kNN-BOX for machine translation and three other seq2seq generation tasks (text simplification, paraphrase generation and question generation). Experiment results show that augmenting the base neural model with kNN-BOX can bring large performance improvement in all these tasks. The code and document of kNN-BOX is available at https://github.com/NJUNLP/knn-box. The demo can be accessed at http://nlp.nju.edu.cn/demo/knn-box/. The introduction video is available at https://www.youtube.com/watch?v=m0eJldHVR3w.</abstract>
      <url hash="b981b9a2">2024.eacl-demo.2</url>
      <bibkey>zhu-etal-2024-knn</bibkey>
    </paper>
    <paper id="3">
      <title>A Human-Centric Evaluation Platform for Explainable Knowledge Graph Completion</title>
      <author><first>Zhao</first><last>Xu</last><affiliation>NEC Laboratories Europe</affiliation></author>
      <author><first>Wiem</first><last>Ben Rim</last><affiliation>NEC Laboratories Europe</affiliation></author>
      <author><first>Kiril</first><last>Gashteovski</last><affiliation>NEC Laboratories Europe</affiliation></author>
      <author><first>Timo</first><last>Sztyler</last><affiliation>NEC Laboratories Europe</affiliation></author>
      <author><first>Carolin</first><last>Lawrence</last><affiliation>NEC Laboratories Europe</affiliation></author>
      <pages>18-26</pages>
      <abstract>Explanations for AI are expected to help human users understand AI-driven predictions. Evaluating plausibility, the helpfulness of the explanations, is therefore essential for developing eXplainable AI (XAI) that can really aid human users. Here we propose a human-centric evaluation platform to measure plausibility of explanations in the context of eXplainable Knowledge Graph Completion (XKGC). The target audience of the platform are researchers and practitioners who want to 1) investigate real needs and interests of their target users in XKGC, 2) evaluate the plausibility of the XKGC methods. We showcase these two use cases in an experimental setting to illustrate what results can be achieved with our system.</abstract>
      <url hash="20749d1e">2024.eacl-demo.3</url>
      <bibkey>xu-etal-2024-human</bibkey>
    </paper>
    <paper id="4">
      <title>py<fixed-case>TLEX</fixed-case>: A Python Library for <fixed-case>T</fixed-case>ime<fixed-case>L</fixed-case>ine <fixed-case>EX</fixed-case>traction</title>
      <author><first>Akul</first><last>Singh</last><affiliation>Florida International University</affiliation></author>
      <author><first>Jared</first><last>Hummer</last><affiliation>Florida International University</affiliation></author>
      <author><first>Mustafa</first><last>Ocal</last><affiliation>Florida International University</affiliation></author>
      <author><first>Mark</first><last>Finlayson</last><affiliation>FIU</affiliation></author>
      <pages>27-34</pages>
      <abstract>pyTLEX is an implementation of the TimeLine EXtraction algorithm (TLEX; Finlayson et al.,2021) that enables users to work with TimeML annotations and perform advanced temporal analysis, offering a comprehensive suite of features. TimeML is a standardized markup language for temporal information in text. pyTLEX allows users to parse TimeML annotations, construct TimeML graphs, and execute the TLEX algorithm to effect complete timeline extraction. In contrast to previous implementations (i.e., jTLEX for Java), pyTLEX sets itself apart with a range of advanced features. It introduces a React-based visualization system, enhancing the exploration of temporal data and the comprehension of temporal connections within textual information. Furthermore, pyTLEX incorporates an algorithm for increasing connectivity in temporal graphs, which identifies graph disconnectivity and recommends links based on temporal reasoning, thus enhancing the coherence of the graph representation. Additionally, pyTLEX includes a built-in validation algorithm, ensuring compliance with TimeML annotation guidelines, which is essential for maintaining data quality and reliability. pyTLEX equips researchers and developers with an extensive toolkit for temporal analysis, and its testing across various datasets validates its accuracy and reliability.</abstract>
      <url hash="f73e10d4">2024.eacl-demo.4</url>
      <bibkey>singh-etal-2024-pytlex</bibkey>
    </paper>
    <paper id="5">
      <title><fixed-case>D</fixed-case>epress<fixed-case>M</fixed-case>ind: A Depression Surveillance System for Social Media Analysis</title>
      <author><first>Roque</first><last>Fernández-Iglesias</last><affiliation>University of Santiago de Compostela</affiliation></author>
      <author><first>Marcos</first><last>Fernandez-Pichel</last><affiliation>University of Santiago de Compostela</affiliation></author>
      <author><first>Mario</first><last>Aragon</last><affiliation>Universidade de Santiago de Compostela</affiliation></author>
      <author><first>David E.</first><last>Losada</last><affiliation>University of Santiago de Compostela</affiliation></author>
      <pages>35-43</pages>
      <abstract>Depression is a pressing global issue that impacts millions of individuals worldwide. This prevailing psychologicaldisorder profoundly influences the thoughts and behavior of those who suffer from it. We have developed DepressMind, a versatile screening tool designed to facilitate the analysis of social network data. This automated tool explores multiple psychological dimensions associated with clinical depression and estimates the extent to which these symptoms manifest in language use. Our project comprises two distinct components: one for data extraction and another one for analysis.The data extraction phase is dedicated to harvesting texts and the associated meta-information from social networks and transforming them into a user-friendly format that serves various analytical purposes.For the analysis, the main objective is to conduct an in-depth inspection of the user publications and establish connections between the posted contents and dimensions or traits defined by well-established clinical instruments.Specifically, we aim to associate extracts authored by individuals with symptoms or dimensions of the Beck Depression Inventory (BDI).</abstract>
      <url hash="490e6099">2024.eacl-demo.5</url>
      <bibkey>fernandez-iglesias-etal-2024-depressmind</bibkey>
    </paper>
    <paper id="6">
      <title>Check News in One Click: <fixed-case>NLP</fixed-case>-Empowered Pro-Kremlin Propaganda Detection</title>
      <author><first>Veronika</first><last>Solopova</last><affiliation>Freie University of Berlin</affiliation></author>
      <author><first>Viktoriia</first><last>Herman</last><affiliation>Freie University of Berlin</affiliation></author>
      <author><first>Christoph</first><last>Benzmüller</last><affiliation>FU Berlin</affiliation></author>
      <author><first>Tim</first><last>Landgraf</last><affiliation>FU Berlin</affiliation></author>
      <pages>44-51</pages>
      <abstract>Many European citizens become targets of the Kremlin propaganda campaigns, aiming to minimise public support for Ukraine, foster a climate of mistrust and disunity, and shape elections (Meister, 2022). To address this challenge, we developed “Check News in 1 Click”, the first NLP-empowered pro-Kremlin propaganda detection application available in 7 languages, which provides the lay user with feedback on their news, and explains manipulative linguistic features and keywords. We conducted a user study, analysed user entries and models’ behaviour paired with questionnaire answers, and investigated the advantages and disadvantages of the proposed interpretative solution.</abstract>
      <url hash="9673cb80">2024.eacl-demo.6</url>
      <bibkey>solopova-etal-2024-check</bibkey>
    </paper>
    <paper id="7">
      <title><fixed-case>NESTLE</fixed-case>: a No-Code Tool for Statistical Analysis of Legal Corpus</title>
      <author><first>Kyoungyeon</first><last>Cho</last><affiliation>LBox</affiliation></author>
      <author><first>Seungkum</first><last>Han</last><affiliation>LBox</affiliation></author>
      <author><first>Young Rok</first><last>Choi</last><affiliation>LBox</affiliation></author>
      <author><first>Wonseok</first><last>Hwang</last><affiliation>LBox</affiliation></author>
      <pages>52-61</pages>
      <abstract>The statistical analysis of large scale legal corpus can provide valuable legal insights. For such analysis one needs to (1) select a subset of the corpus using document retrieval tools, (2) structure text using information extraction (IE) systems, and (3) visualize the data for the statistical analysis. Each process demands either specialized tools or programming skills whereas no comprehensive unified “no-code” tools have been available. Here we provide NESTLE, a no-code tool for large-scale statistical analysis of legal corpus. Powered by a Large Language Model (LLM) and the internal custom end-to-end IE system, NESTLE can extract any type of information that has not been predefined in the IE system opening up the possibility of unlimited customizable statistical analysis of the corpus without writing a single line of code. We validate our system on 15 Korean precedent IE tasks and 3 legal text classification tasks from LexGLUE. The comprehensive experiments reveal NESTLE can achieve GPT-4 comparable performance by training the internal IE module with 4 human-labeled, and 192 LLM-labeled examples.</abstract>
      <url hash="03716bd4">2024.eacl-demo.7</url>
      <bibkey>cho-etal-2024-nestle</bibkey>
    </paper>
    <paper id="8">
      <title>Multi-party Multimodal Conversations Between Patients, Their Companions, and a Social Robot in a Hospital Memory Clinic</title>
      <author><first>Angus</first><last>Addlesee</last><affiliation>Heriot-Watt University</affiliation></author>
      <author><first>Neeraj</first><last>Cherakara</last><affiliation>Heriot-Watt University</affiliation></author>
      <author><first>Nivan</first><last>Nelson</last><affiliation>Heriot-Watt University</affiliation></author>
      <author><first>Daniel</first><last>Hernandez Garcia</last><affiliation>Heriot-Watt University</affiliation></author>
      <author><first>Nancie</first><last>Gunson</last><affiliation>Heriot-Watt University</affiliation></author>
      <author><first>Weronika</first><last>Sieińska</last><affiliation>Heriot-Watt University</affiliation></author>
      <author><first>Christian</first><last>Dondrup</last><affiliation>Heriot-Watt University</affiliation></author>
      <author><first>Oliver</first><last>Lemon</last><affiliation>Heriot-Watt University</affiliation></author>
      <pages>62-70</pages>
      <abstract>We have deployed an LLM-based spoken dialogue system in a real hospital. The ARI social robot embodies our system, which patients and their companions can have multi-party conversations with together. In order to enable this multi-party ability, multimodality is critical. Our system, therefore, receives speech and video as input, and generates both speech and gestures (arm, head, and eye movements). In this paper, we describe our complex setting and the architecture of our dialogue system. Each component is detailed, and a video of the full system is available with the appropriate components highlighted in real-time. Our system decides when it should take its turn, generates human-like clarification requests when the patient pauses mid-utterance, answers in-domain questions (grounding to the in-prompt knowledge), and responds appropriately to out-of-domain requests (like generating jokes or quizzes). This latter feature is particularly remarkable as real patients often utter unexpected sentences that could not be handled previously.</abstract>
      <url hash="9e81e1d3">2024.eacl-demo.8</url>
      <bibkey>addlesee-etal-2024-multi</bibkey>
    </paper>
    <paper id="9">
      <title><fixed-case>S</fixed-case>cam<fixed-case>S</fixed-case>pot: Fighting Financial Fraud in <fixed-case>I</fixed-case>nstagram Comments</title>
      <author><first>Stefan</first><last>Erben</last><affiliation>Lucerne University of Applied Sciences and Arts</affiliation></author>
      <author><first>Andreas</first><last>Waldis</last><affiliation>Hochschule Luzern</affiliation></author>
      <pages>71-81</pages>
      <abstract>The long-standing problem of spam and fraudulent messages in the comment sections of Instagram pages in the financial sector claims new victims every day. Instagram’s current spam filter proves inadequate, and existing research approaches are primarily confined to theoretical concepts. Practical implementations with evaluated results are missing. To solve this problem, we propose ScamSpot, a comprehensive system that includes a browser extension, a fine-tuned BERT model and a REST API. This approach ensures public accessibility of our results for Instagram users using the Chrome browser. Furthermore, we conduct a data annotation study, shedding light on the reasons and causes of the problem and evaluate the system through user feedback and comparison with existing models. ScamSpot is an open-source project and is publicly available at https://scamspot.github.io/.</abstract>
      <url hash="d6613b8d">2024.eacl-demo.9</url>
      <bibkey>erben-waldis-2024-scamspot</bibkey>
    </paper>
    <paper id="10">
      <title><fixed-case>N</fixed-case>arrative<fixed-case>P</fixed-case>lay: Interactive Narrative Understanding</title>
      <author><first>Runcong</first><last>Zhao</last><affiliation>King’s College London</affiliation></author>
      <author><first>Wenjia</first><last>Zhang</last><affiliation>University of Warwick</affiliation></author>
      <author><first>Jiazheng</first><last>Li</last><affiliation>King’s College London</affiliation></author>
      <author><first>Lixing</first><last>Zhu</last><affiliation>Department of Computer Science, University of Warwick</affiliation></author>
      <author><first>Yanran</first><last>Li</last><affiliation>The Hong Kong Polytechnic University</affiliation></author>
      <author><first>Yulan</first><last>He</last><affiliation>King’s College London</affiliation></author>
      <author><first>Lin</first><last>Gui</last><affiliation>King’s College London</affiliation></author>
      <pages>82-93</pages>
      <abstract>In this paper, we introduce NarrativePlay, a novel system that allows users to role-play a fictional character and interact with other characters in narratives in an immersive environment. We leverage Large Language Models (LLMs) to generate human-like responses, guided by personality traits extracted from narratives. The system incorporates auto-generated visual display of narrative settings, character portraits, and character speech, greatly enhancing the user experience. Our approach eschews predefined sandboxes, focusing instead on main storyline events from the perspective of a user-selected character. NarrativePlay has been evaluated on two types of narratives, detective and adventure stories, where users can either explore the world or increase affinity with other characters through conversations.</abstract>
      <url hash="a8809656">2024.eacl-demo.10</url>
      <bibkey>zhao-etal-2024-narrativeplay</bibkey>
    </paper>
    <paper id="11">
      <title><fixed-case>DP</fixed-case>-<fixed-case>NMT</fixed-case>: Scalable Differentially Private Machine Translation</title>
      <author><first>Timour</first><last>Igamberdiev</last><affiliation>Technical University of Darmstadt</affiliation></author>
      <author><first>Doan Nam Long</first><last>Vu</last><affiliation>Technical University of Darmstadt</affiliation></author>
      <author><first>Felix</first><last>Kuennecke</last><affiliation>TU Darmstadt</affiliation></author>
      <author><first>Zhuo</first><last>Yu</last><affiliation>Department of Computer Science, Technical University of Darmstadt</affiliation></author>
      <author><first>Jannik</first><last>Holmer</last><affiliation>TU Darmstadt</affiliation></author>
      <author><first>Ivan</first><last>Habernal</last><affiliation>Paderborn University</affiliation></author>
      <pages>94-105</pages>
      <abstract>Neural machine translation (NMT) is a widely popular text generation task, yet there is a considerable research gap in the development of privacy-preserving NMT models, despite significant data privacy concerns for NMT systems. Differentially private stochastic gradient descent (DP-SGD) is a popular method for training machine learning models with concrete privacy guarantees; however, the implementation specifics of training a model with DP-SGD are not always clarified in existing models, with differing software libraries used and code bases not always being public, leading to reproducibility issues. To tackle this, we introduce DP-NMT, an open-source framework for carrying out research on privacy-preserving NMT with DP-SGD, bringing together numerous models, datasets, and evaluation metrics in one systematic software package. Our goal is to provide a platform for researchers to advance the development of privacy-preserving NMT systems, keeping the specific details of the DP-SGD algorithm transparent and intuitive to implement. We run a set of experiments on datasets from both general and privacy-related domains to demonstrate our framework in use. We make our framework publicly available and welcome feedback from the community.</abstract>
      <url hash="cfc57f01">2024.eacl-demo.11</url>
      <bibkey>igamberdiev-etal-2024-dp</bibkey>
    </paper>
    <paper id="12">
      <title><fixed-case>A</fixed-case>nno<fixed-case>P</fixed-case>lot: Interactive Visualizations of Text Annotations</title>
      <author><first>Elisabeth</first><last>Fittschen</last><affiliation>Uni Hamburg</affiliation></author>
      <author><first>Tim</first><last>Fischer</last><affiliation>Universität Hamburg</affiliation></author>
      <author><first>Daniel</first><last>Brühl</last><affiliation>Universität Hamburg</affiliation></author>
      <author><first>Julia</first><last>Spahr</last><affiliation>Universität Hamburg</affiliation></author>
      <author><first>Yuliia</first><last>Lysa</last><affiliation>Universität Hamburg</affiliation></author>
      <author><first>Phuoc Thang</first><last>Le</last><affiliation>Universität Hamburg</affiliation></author>
      <pages>106-114</pages>
      <abstract>This paper presents AnnoPlot, a web application designed to analyze, manage, and visualize annotated text data.Users can configure projects, upload datasets, and explore their data through interactive visualization of span annotations with scatter plots, clusters, and statistics. AnnoPlot supports various transformer models to compute high-dimensional embeddings of text annotations and utilizes dimensionality reduction algorithms to offer users a novel 2D view of their datasets.A dynamic approach to dimensionality reduction allows users to adjust visualizations in real-time, facilitating category reorganization and error identification. The proposed application is open-source, promoting transparency and user control.Especially suited for the Digital Humanities, AnnoPlot offers a novel solution to address challenges in dynamic annotation datasets, empowering users to enhance data integrity and adapt to evolving categorizations.</abstract>
      <url hash="088189e5">2024.eacl-demo.12</url>
      <bibkey>fittschen-etal-2024-annoplot</bibkey>
    </paper>
    <paper id="13">
      <title><fixed-case>G</fixed-case>eospa<fixed-case>C</fixed-case>y: A tool for extraction and geographical referencing of spatial expressions in textual data</title>
      <author><first>Syed</first><last>Mehtab Alam</last><affiliation>CIRAD, TETIS</affiliation></author>
      <author><first>Elena</first><last>Arsevska</last><affiliation>Cirad, Inra</affiliation></author>
      <author><first>Mathieu</first><last>Roche</last><affiliation>CIRAD, TETIS</affiliation></author>
      <author><first>Maguelonne</first><last>Teisseire</last><affiliation>UMR TETIS (Earth Observation and Geoinformation for Environment and Land Management research Unit)</affiliation></author>
      <pages>115-126</pages>
      <abstract>Spatial information in text enables to understand the geographical context and relationships within text for better decision-making across various domains such as disease surveillance, disaster management and other location based services. Therefore, it is crucial to understand the precise geographical context for location-sensitive applications. In response to this necessity, we introduce the GeospaCy software tool, designed for the extraction and georeferencing of spatial information present in textual data. GeospaCy fulfils two primary objectives: 1) Geoparsing, which involves extracting spatial expressions, encompassing place names and associated spatial relations within the text data, and 2) Geocoding, which facilitates the assignment of geographical coordinates to the spatial expressions extracted during the Geoparsing task. Geoparsing is evaluated with a disease news article dataset consisting of event information, whereas a qualitative evaluation of geographical coordinates (polygons/geometries) of spatial expressions is performed by end-users for Geocoding task.</abstract>
      <url hash="ce33be76">2024.eacl-demo.13</url>
      <bibkey>mehtab-alam-etal-2024-geospacy</bibkey>
    </paper>
    <paper id="14">
      <title><fixed-case>MAMMOTH</fixed-case>: Massively Multilingual Modular Open Translation @ <fixed-case>H</fixed-case>elsinki</title>
      <author><first>Timothee</first><last>Mickus</last><affiliation>University of Helsinki</affiliation></author>
      <author><first>Stig-Arne</first><last>Grönroos</last><affiliation>Silo.AI</affiliation></author>
      <author><first>Joseph</first><last>Attieh</last><affiliation>University of Helsinki</affiliation></author>
      <author><first>Michele</first><last>Boggia</last><affiliation>University of Helsinki</affiliation></author>
      <author><first>Ona</first><last>De Gibert</last><affiliation>University of Helsinki</affiliation></author>
      <author><first>Shaoxiong</first><last>Ji</last><affiliation>University of Helsinki</affiliation></author>
      <author><first>Niki Andreas</first><last>Loppi</last><affiliation>NVIDIA</affiliation></author>
      <author><first>Alessandro</first><last>Raganato</last><affiliation>University of Milano-Bicocca</affiliation></author>
      <author><first>Raúl</first><last>Vázquez</last><affiliation>University of Helsinki</affiliation></author>
      <author><first>Jörg</first><last>Tiedemann</last><affiliation>University of Helsinki</affiliation></author>
      <pages>127-136</pages>
      <abstract>NLP in the age of monolithic large language models is approaching its limits in terms of size and information that can be handled. The trend goes to modularization, a necessary step into the direction of designing smaller sub-networks and components with specialized functionality. In this paper, we present the MAMMOTH toolkit: a framework designed for training massively multilingual modular machine translation systems at scale, initially derived from OpenNMT-py and then adapted to ensure efficient training across computation clusters.We showcase its efficiency across clusters of A100 and V100 NVIDIA GPUs, and discuss our design philosophy and plans for future information.The toolkit is publicly available online at https://github.com/Helsinki-NLP/mammoth.</abstract>
      <url hash="f7dfc576">2024.eacl-demo.14</url>
      <bibkey>mickus-etal-2024-mammoth</bibkey>
    </paper>
    <paper id="15">
      <title>The <fixed-case>DUR</fixed-case>el Annotation Tool: Human and Computational Measurement of Semantic Proximity, Sense Clusters and Semantic Change</title>
      <author><first>Dominik</first><last>Schlechtweg</last><affiliation>University of Stuttgart</affiliation></author>
      <author><first>Shafqat Mumtaz</first><last>Virk</last><affiliation>Språkbanken Text, Dept. of Swedish University of Gothenburg</affiliation></author>
      <author><first>Pauline</first><last>Sander</last><affiliation>University of Stuttgart</affiliation></author>
      <author><first>Emma</first><last>Sköldberg</last><affiliation>University of Gothenburg</affiliation></author>
      <author><first>Lukas</first><last>Theuer Linke</last><affiliation>University of Stuttgart</affiliation></author>
      <author><first>Tuo</first><last>Zhang</last><affiliation>University of Stuttgart</affiliation></author>
      <author><first>Nina</first><last>Tahmasebi</last><affiliation>University of Gothenburg</affiliation></author>
      <author><first>Jonas</first><last>Kuhn</last><affiliation>University of Stuttgart</affiliation></author>
      <author><first>Sabine</first><last>Schulte Im Walde</last><affiliation>University of Stuttgart</affiliation></author>
      <pages>137-149</pages>
      <abstract>We present the DURel tool implementing the annotation of semantic proximity between word uses into an online, open source interface. The tool supports standardized human annotation as well as computational annotation, building on recent advances with Word-in-Context models. Annotator judgments are clustered with automatic graph clustering techniques and visualized for analysis. This allows to measure word senses with simple and intuitive micro-task judgments between use pairs, requiring minimal preparation efforts. The tool offers additional functionalities to compare the agreement between annotators to guarantee the inter-subjectivity of the obtained judgments and to calculate summary statistics over the annotated data giving insights into sense frequency distributions, semantic variation or changes of senses over time.</abstract>
      <url hash="a47730f3">2024.eacl-demo.15</url>
      <bibkey>schlechtweg-etal-2024-durel</bibkey>
    </paper>
    <paper id="16">
      <title><fixed-case>RAGA</fixed-case>s: Automated Evaluation of Retrieval Augmented Generation</title>
      <author><first>Shahul</first><last>Es</last><affiliation>Exploding Gradients</affiliation></author>
      <author><first>Jithin</first><last>James</last><affiliation>Exploding Gradients</affiliation></author>
      <author><first>Luis</first><last>Espinosa Anke</last><affiliation>Cardiff University</affiliation></author>
      <author><first>Steven</first><last>Schockaert</last><affiliation>Cardiff University</affiliation></author>
      <pages>150-158</pages>
      <abstract>We introduce RAGAs (Retrieval Augmented Generation Assessment), a framework for reference-free evaluation of Retrieval Augmented Generation (RAG) pipelines. RAGAs is available at [https://github.com/explodinggradients/ragas]. RAG systems are composed of a retrieval and an LLM based generation module. They provide LLMs with knowledge from a reference textual database, enabling them to act as a natural language layer between a user and textual databases, thus reducing the risk of hallucinations. Evaluating RAG architectures is challenging due to several dimensions to consider: the ability of the retrieval system to identify relevant and focused context passages, the ability of the LLM to exploit such passages faithfully, and the quality of the generation itself. With RAGAs, we introduce a suite of metrics that can evaluate these different dimensions without relying on ground truth human annotations. We posit that such a framework can contribute crucially to faster evaluation cycles of RAG architectures, which is especially important given the fast adoption of LLMs.</abstract>
      <url hash="8b5c2d0c">2024.eacl-demo.16</url>
      <bibkey>es-etal-2024-ragas</bibkey>
    </paper>
    <paper id="17">
      <title><fixed-case>N</fixed-case>euro<fixed-case>P</fixed-case>rompts: An Adaptive Framework to Optimize Prompts for Text-to-Image Generation</title>
      <author><first>Shachar</first><last>Rosenman</last><affiliation>Intel Labs</affiliation></author>
      <author><first>Vasudev</first><last>Lal</last><affiliation>Intel Labs</affiliation></author>
      <author><first>Phillip</first><last>Howard</last><affiliation>Intel Labs</affiliation></author>
      <pages>159-167</pages>
      <abstract>Despite impressive recent advances in text-to-image diffusion models, obtaining high-quality images often requires prompt engineering by humans who have developed expertise in using them. In this work, we present NeuroPrompts, an adaptive framework that automatically enhances a user’s prompt to improve the quality of generations produced by text-to-image models. Our framework utilizes constrained text decoding with a pre-trained language model that has been adapted to generate prompts similar to those produced by human prompt engineers. This approach enables higher-quality text-to-image generations and provides user control over stylistic features via constraint set specification. We demonstrate the utility of our framework by creating an interactive application for prompt enhancement and image generation using Stable Diffusion. Additionally, we conduct experiments utilizing a large dataset of human-engineered prompts for text-to-image generation and show that our approach automatically produces enhanced prompts that result in superior image quality. We make our code, a screencast video demo and a live demo instance of NeuroPrompts publicly available.</abstract>
      <url hash="f715b7cd">2024.eacl-demo.17</url>
      <bibkey>rosenman-etal-2024-neuroprompts</bibkey>
    </paper>
    <paper id="18">
      <title><fixed-case>MEGA</fixed-case>nno+: A Human-<fixed-case>LLM</fixed-case> Collaborative Annotation System</title>
      <author><first>Hannah</first><last>Kim</last><affiliation>Megagon Labs</affiliation></author>
      <author><first>Kushan</first><last>Mitra</last><affiliation>Megagon Labs</affiliation></author>
      <author><first>Rafael</first><last>Li Chen</last><affiliation>Megagon Labs</affiliation></author>
      <author><first>Sajjadur</first><last>Rahman</last><affiliation>Megagon Labs</affiliation></author>
      <author><first>Dan</first><last>Zhang</last><affiliation>Megagon Labs</affiliation></author>
      <pages>168-176</pages>
      <abstract>Large language models (LLMs) can label data faster and cheaper than humans for various NLP tasks. Despite their prowess, LLMs may fall short in understanding of complex, sociocultural, or domain-specific context, potentially leading to incorrect annotations. Therefore, we advocate a collaborative approach where humans and LLMs work together to produce reliable and high-quality labels. We present MEGAnno+, a human-LLM collaborative annotation system that offers effective LLM agent and annotation management, convenient and robust LLM annotation, and exploratory verification of LLM labels by humans.</abstract>
      <url hash="629984d8">2024.eacl-demo.18</url>
      <bibkey>kim-etal-2024-meganno</bibkey>
    </paper>
    <paper id="19">
      <title><fixed-case>X</fixed-case>-<fixed-case>AMR</fixed-case> Annotation Tool</title>
      <author><first>Shafiuddin Rehan</first><last>Ahmed</last><affiliation>University of Colorado Boulder</affiliation></author>
      <author><first>Jon</first><last>Cai</last><affiliation>The University of Colorado</affiliation></author>
      <author><first>Martha</first><last>Palmer</last><affiliation>University of Colorado</affiliation></author>
      <author><first>James H.</first><last>Martin</last><affiliation>University of Colorado Boulder</affiliation></author>
      <pages>177-186</pages>
      <abstract>This paper presents a novel {textbf{Cross}-document {textbf{A}bstract {textbf{M}eaning {textbf{R}epresentation (X-AMR) annotation tool designed for annotating key corpus-level event semantics. Leveraging machine assistance through the Prodigy Annotation Tool, we enhance the user experience, ensuring ease and efficiency in the annotation process. Through empirical analyses, we demonstrate the effectiveness of our tool in augmenting an existing event corpus, highlighting its advantages when integrated with GPT-4. Code and annotations: {href{https://anonymous.4open.science/r/xamr-9ED0}{anonymous.4open.science/r/xamr-9ED0}{footnote{Demo: {href{https://youtu.be/TuirftxciNE}{https://youtu.be/TuirftxciNE}} {footnote{Live Link: {href{https://tinyurl.com/mrxmafwh}{https://tinyurl.com/mrxmafwh}}</abstract>
      <url hash="0d9a8852">2024.eacl-demo.19</url>
      <bibkey>ahmed-etal-2024-x</bibkey>
    </paper>
    <paper id="20">
      <title><fixed-case>D</fixed-case>oc<fixed-case>C</fixed-case>hecker: Bootstrapping Code Large Language Model for Detecting and Resolving Code-Comment Inconsistencies</title>
      <author><first>Anh</first><last>Dau</last><affiliation>FPT Software AI Center</affiliation></author>
      <author><first>Jin L.c.</first><last>Guo</last><affiliation>McGill University</affiliation></author>
      <author><first>Nghi</first><last>Bui</last><affiliation>Salesforce Research Asia</affiliation></author>
      <pages>187-194</pages>
      <abstract>Comments in source code are crucial for developers to understand the purpose of the code and to use it correctly. However, keeping comments aligned with the evolving codebase poses a significant challenge. With increasing interest in automated solutions to identify and rectify discrepancies between code and its associated comments, most existing methods rely heavily on heuristic rules. This paper introduces {textbf{DocChecker}, a language model-based framework adept at detecting inconsistencies between code and comments and capable of generating synthetic comments. This functionality allows {textbf{DocChecker} to identify and rectify cases where comments do not accurately represent the code they describe.The efficacy of DocChecker is demonstrated using the Just-In-Time and CodeXGlue datasets in various scenarios. Notably, DocChecker sets a new benchmark in the Inconsistency Code-Comment Detection (ICCD) task, achieving 72.3% accuracy, and scoring 33.64 in BLEU-4 on the code summarization task. These results surpass other Large Language Models (LLMs), including GPT 3.5 and CodeLlama.DocChecker is accessible for use and evaluation. It can be found on https://github.com/FSoft-AI4Code/DocChecker and at http://4.193.50.237:5000/. For a more comprehensive understanding of its functionality, a demonstration video is available on https://youtu.be/FqnPmd531xw.</abstract>
      <url hash="4ee92fab">2024.eacl-demo.20</url>
      <bibkey>dau-etal-2024-docchecker</bibkey>
    </paper>
    <paper id="21">
      <title><fixed-case>TL</fixed-case>;<fixed-case>DR</fixed-case> Progress: Multi-faceted Literature Exploration in Text Summarization</title>
      <author><first>Shahbaz</first><last>Syed</last><affiliation>Leipzig University</affiliation></author>
      <author><first>Khalid</first><last>Al Khatib</last><affiliation>Groningen University</affiliation></author>
      <author><first>Martin</first><last>Potthast</last><affiliation>Leipzig University</affiliation></author>
      <pages>195-206</pages>
      <abstract>This paper presents TL;DR Progress, a new tool for exploring the literature on neural text summarization. It organizes 514~papers based on a comprehensive annotation scheme for text summarization approaches and enables fine-grained, faceted search. Each paper was manually annotated to capture aspects such as evaluation metrics, quality dimensions, learning paradigms, challenges addressed, datasets, and document domains. In addition, a succinct indicative summary is provided for each paper, describing contextual factors, issues, and proposed solutions. The tool is available at {{url{https://www.tldr-progress.de}}, a demo video at {{url{https://youtu.be/uCVRGFvXUj8}}</abstract>
      <url hash="54a7554b">2024.eacl-demo.21</url>
      <bibkey>syed-etal-2024-tl</bibkey>
    </paper>
    <paper id="22">
      <title><fixed-case>FRAPPE</fixed-case>: <fixed-case>FRA</fixed-case>ming, Persuasion, and Propaganda Explorer</title>
      <author><first>Ahmed</first><last>Sajwani</last><affiliation>Khalifa University of Science and Technology</affiliation></author>
      <author><first>Alaa</first><last>El Setohy</last><affiliation>Egypt Japan University of Science and Technology</affiliation></author>
      <author><first>Ali</first><last>Mekky</last><affiliation>Alexandria University</affiliation></author>
      <author><first>Diana</first><last>Turmakhan</last><affiliation>Nazarbayev University</affiliation></author>
      <author><first>Lara</first><last>Hassan</last><affiliation>Alexandria University</affiliation></author>
      <author><first>Mohamed</first><last>El Zeftawy</last><affiliation>Alexandria University</affiliation></author>
      <author><first>Omar</first><last>El Herraoui</last><affiliation>NYU Abu Dhabi</affiliation></author>
      <author><first>Osama</first><last>Afzal</last><affiliation>Mohamed bin Zayed University of Artificial Intelligence</affiliation></author>
      <author><first>Qisheng</first><last>Liao</last><affiliation>Mohamed bin Zayed University of Artificial Intelligence</affiliation></author>
      <author><first>Tarek</first><last>Mahmoud</last><affiliation>Mohamed bin Zayed University of Artificial Intelligence</affiliation></author>
      <pages>207-213</pages>
      <abstract>The abundance of news sources and the urgent demand for reliable information have led to serious concerns about the threat of misleading information. In this paper, we present FRAPPE, a FRAming, Persuasion, and Propaganda Explorer system. FRAPPE goes beyond conventional news analysis of articles and unveils the intricate linguistic techniques used to shape readers’ opinions and emotions. Our system allows users not only to analyze individual articles for their genre, framings, and use of persuasion techniques, but also to draw comparisons between the strategies of persuasion and framing adopted by a diverse pool of news outlets and countries across multiple languages for different topics, thus providing a comprehensive understanding of how information is presented and manipulated. FRAPPE is publicly accessible at https://frappe.streamlit.app/ and a video explaining our system is available at https://www.youtube.com/watch?v=3RlTfSVnZmk</abstract>
      <url hash="e66c3473">2024.eacl-demo.22</url>
      <bibkey>sajwani-etal-2024-frappe</bibkey>
    </paper>
    <paper id="23">
      <title><fixed-case>LLM</fixed-case>e<fixed-case>B</fixed-case>ench: A Flexible Framework for Accelerating <fixed-case>LLM</fixed-case>s Benchmarking</title>
      <author><first>Fahim</first><last>Dalvi</last><affiliation>Qatar Computing Research Institute, HBKU</affiliation></author>
      <author><first>Maram</first><last>Hasanain</last><affiliation>Qatar Computing Research Institute</affiliation></author>
      <author><first>Sabri</first><last>Boughorbel</last><affiliation>Qatar Computing Research Institute, HBKU</affiliation></author>
      <author><first>Basel</first><last>Mousi</last><affiliation>QCRI</affiliation></author>
      <author><first>Samir</first><last>Abdaljalil</last><affiliation>Texas A&amp;M University</affiliation></author>
      <author><first>Nizi</first><last>Nazar</last><affiliation>Qatar Computing Research Institute, HBKU</affiliation></author>
      <author><first>Ahmed</first><last>Abdelali</last><affiliation>Qatar Computing Research Institute</affiliation></author>
      <author><first>Shammur Absar</first><last>Chowdhury</last><affiliation>Qatar Computing Research Institute</affiliation></author>
      <author><first>Hamdy</first><last>Mubarak</last><affiliation>Qatar Computing Research Institute</affiliation></author>
      <author><first>Ahmed</first><last>Ali</last><affiliation>Qatar Computing Research Institute</affiliation></author>
      <pages>214-222</pages>
      <abstract>The recent development and success of Large Language Models (LLMs) necessitate an evaluation of their performance across diverse NLP tasks in different languages. Although several frameworks have been developed and made publicly available, their customization capabilities for specific tasks and datasets are often complex for different users. In this study, we introduce the LLMeBench framework, which can be seamlessly customized to evaluate LLMs for any NLP task, regardless of language. The framework features generic dataset loaders, several model providers, and pre-implements most standard evaluation metrics. It supports in-context learning with zero- and few-shot settings. A specific dataset and task can be evaluated for a given LLM in less than 20 lines of code while allowing full flexibility to extend the framework for custom datasets, models, or tasks. The framework has been tested on 31 unique NLP tasks using 53 publicly available datasets within 90 experimental setups, involving approximately 296K data points. We open-sourced LLMeBench for the community (https://github.com/qcri/LLMeBench/) and a video demonstrating the framework is available online (https://youtu.be/9cC2m_abk3A).</abstract>
      <url hash="b9920324">2024.eacl-demo.23</url>
      <bibkey>dalvi-etal-2024-llmebench</bibkey>
    </paper>
    <paper id="24">
      <title>Sig-Networks Toolkit: Signature Networks for Longitudinal Language Modelling</title>
      <author><first>Talia</first><last>Tseriotou</last><affiliation>Queen Mary University of London</affiliation></author>
      <author><first>Ryan</first><last>Chan</last><affiliation>The Alan Turing Institute</affiliation></author>
      <author><first>Adam</first><last>Tsakalidis</last><affiliation>Queen Mary University of London</affiliation></author>
      <author><first>Iman Munire</first><last>Bilal</last><affiliation>University of Warwick</affiliation></author>
      <author><first>Elena</first><last>Kochkina</last><affiliation>Queen Mary University</affiliation></author>
      <author><first>Terry</first><last>Lyons</last><affiliation>University of Oxford</affiliation></author>
      <author><first>Maria</first><last>Liakata</last><affiliation>Queen Mary University of London</affiliation></author>
      <pages>223-237</pages>
      <abstract>We present an open-source, pip installable toolkit, Sig-Networks, the first of its kind for longitudinal language modelling. A central focus is the incorporation of Signature-based Neural Network models, which have recently shown success in temporal tasks. We apply and extend published research providing a full suite of signature-based models. Their components can be used as PyTorch building blocks in future architectures. Sig-Networks enables task-agnostic dataset plug-in, seamless preprocessing for sequential data, parameter flexibility, automated tuning across a range of models. We examine signature networks under three different NLP tasks of varying temporal granularity: counselling conversations, rumour stance switch and mood changes in social media threads, showing SOTA performance in all three, and provide guidance for future tasks. We release the Toolkit as a PyTorch package with an introductory video, Git repositories for preprocessing and modelling including sample notebooks on the modeled NLP tasks.</abstract>
      <url hash="31e5544c">2024.eacl-demo.24</url>
      <bibkey>tseriotou-etal-2024-sig</bibkey>
    </paper>
  </volume>
</collection>
