<?xml version='1.0' encoding='UTF-8'?>
<collection id="2025.ranlp">
  <volume id="1" ingest-date="2026-01-07" type="proceedings">
    <meta>
      <booktitle>Proceedings of the 15th International Conference on Recent Advances in Natural Language Processing - Natural Language Processing in the Generative AI Era</booktitle>
      <editor><first>Galia</first><last>Angelova</last></editor>
      <editor><first>Maria</first><last>Kunilovskaya</last></editor>
      <editor><first>Marie</first><last>Escribe</last></editor>
      <editor id="ruslan-mitkov"><first>Ruslan</first><last>Mitkov</last></editor>
      <publisher>INCOMA Ltd., Shoumen, Bulgaria</publisher>
      <address>Varna, Bulgaria</address>
      <month>September</month>
      <year>2025</year>
      <url hash="0d72f637">2025.ranlp-1</url>
      <venue>ranlp</venue>
    </meta>
    <frontmatter>
      <url hash="9d121ee6">2025.ranlp-1.0</url>
      <bibkey>ranlp-2025-1</bibkey>
    </frontmatter>
    <paper id="1">
      <title>Harnessing Open-Source <fixed-case>LLM</fixed-case>s for Tender Named Entity Recognition</title>
      <author><first>Asim</first><last>Abbas</last></author>
      <author><first>Venelin</first><last>Kovatchev</last></author>
      <author id="mark-lee"><first>Mark</first><last>Lee</last></author>
      <author><first>Niloofer</first><last>Shanavas</last></author>
      <author><first>Mubashir</first><last>Ali</last></author>
      <pages>1–10</pages>
      <abstract>In the public procurement domain, extracting accurate tender entities from unstructured text remains a critical, less explored challenge, because tender data is highly sensitive and confidential, and not available openly. Previously, state-of-the-art NLP models were developed for this task; however developing an NER model from scratch required huge amounts of data and resources. Similarly, performing fine-tuning of a transformer-based model like BERT requires training data, as a result posing challenges in training data cost, model generalization, and data privacy. To address these challenges, an emerging LLM such as GPT-4 in a Few-shot learning environment achieves SOTA performance comparable to fine-tuned models. However, being dependent on the closed-source commercial LLMs involves high cost and privacy concerns. In this study, we have investigated open-source LLMs like Mistral and LLAMA-3, focusing on the tender domain for the NER tasks on local consumer-grade CPUs in three different environments: Zero-shot, One-shot, and Few-shot learning. The motivation is to efficiently lessen costs compared to a cloud solution while preserving accuracy and data privacy. Similarly, we have utilized two datasets open-source from Singapore and closed-source commercially sensitive data provided by Siemens. As a result, all the open-source LLMs achieve above 85% F1-score on an open-source dataset and above 90% F1-score on a closed-source dataset.</abstract>
      <url hash="e42b4464">2025.ranlp-1.1</url>
      <bibkey>abbas-etal-2025-harnessing</bibkey>
    </paper>
    <paper id="2">
      <title>On the Limitations of Large Language Models (<fixed-case>LLM</fixed-case>s): False Attribution</title>
      <author><first>Tosin</first><last>Adewumi</last></author>
      <author><first>Nudrat</first><last>Habib</last></author>
      <author><first>Lama</first><last>Alkhaled</last></author>
      <author><first>Elisa</first><last>Barney</last></author>
      <pages>11–21</pages>
      <abstract>In this work, we introduce a new hallucination metric - SHI and provide insight into one important limitation of the parametric knowledge of large language models LLMs, i.e. false attribution. The task of automatic author attribution for relatively small chunks of text is an important NLP task but can be challenging. We empirically evaluate the power of 3 open SotA LLMs in zero-shot setting (Gemma-7B, Mixtral 8x7B, and LLaMA-2-13B). We acquired the top 10 most popular books of a month, according to Project Gutenberg, divided each one into equal chunks of 400 words, and prompted each LLM to predict the author. We then randomly sampled 162 chunks per book for human evaluation, based on the error margin of 7% and a confidence level of 95%. The average results show that Mixtral 8x7B has the highest prediction accuracy, the lowest SHI, and a Pearson’s correlation r of 0.724, 0.263, and -0.9996, respectively, followed by LLaMA-2-13B and Gemma-7B. However, Mixtral 8x7B suffers from high hallucinations for 3 books, rising as high as a SHI of 0.87 (in the range 0-1, where 1 is the worst). The strong negative correlation of accuracy and SHI, given by r, demonstrates the fidelity of the new hallucination metric, which may generalize to other tasks. We also show that prediction accuracies correlate positively with the frequencies of Wikipedia instances of the book titles instead of the downloads and we perform error analyses of predictions. We publicly release the annotated chunks of data and our codes to aid the reproducibility and evaluation of other models.</abstract>
      <url hash="a327320e">2025.ranlp-1.2</url>
      <bibkey>adewumi-etal-2025-limitations</bibkey>
    </paper>
    <paper id="3">
      <title>Candidate Profile Summarization: A <fixed-case>RAG</fixed-case> Approach with Synthetic Data Generation for Tech Jobs</title>
      <author><first>Anum</first><last>Afzal</last></author>
      <author><first>Ishwor</first><last>Subedi</last></author>
      <author><first>Florian</first><last>Matthes</last></author>
      <pages>22–31</pages>
      <abstract>As Large Language Models (LLMs) become increasingly applied to resume evaluation and candidate selection, this study investigates the effectiveness of using in-context example resumes to generate synthetic data. We compare a Retrieval-Augmented Generation (RAG) system to a Named Entity Recognition (NER)-based baseline for job-resume matching, generating diverse synthetic resumes with models like Mixtral-8x22B-Instruct-v0.1. Our results show that combining BERT, ROUGE, and Jaccard similarity metrics effectively assesses synthetic resume quality, ensuring the least lexical overlap along with high similarity and diversity. Our experiments show that RAG notably outperforms NER for retrieval tasks—though generation-based summarization remains challenged by role differentiation. Human evaluation further highlights issues of factual accuracy and completeness, emphasizing the importance of in-context examples, prompt engineering, and improvements in summary generation for robust, automated candidate selection.</abstract>
      <url hash="27f8b7c3">2025.ranlp-1.3</url>
      <bibkey>afzal-etal-2025-candidate</bibkey>
    </paper>
    <paper id="4">
      <title><fixed-case>P</fixed-case>ersian<fixed-case>S</fixed-case>ci<fixed-case>QA</fixed-case>: A New Dataset for Bridging the Language Gap in Scientific Question Answering</title>
      <author><first>Safoura</first><last>Aghadavoud Jolfaei</last></author>
      <author><first>Azadeh</first><last>Mohebi</last></author>
      <author><first>Zahra</first><last>Hemmat</last></author>
      <pages>32–37</pages>
      <abstract>The shortage of specialized datasets hinders the development of Natural Language Processing (NLP) for scientific texts in low-resource languages such as Persian. To address this, we introduce PersianSciQA , a large-scale resource of 39,809 question- answer snippet pairs, each containing a question and a scientific answer snippet from a scientific engineering abstract source from IranDoc’s ‘Ganj’ repository, linked by an LLM-assigned relevance score (0-3) that measures how relevant the question is to the content of the accompanying answer snippet. The dataset was generated using a two stage prompting methodology and refined through a rigorous cleaning pipe-line, including text normalization and semantic deduplication. Human validation of 1,000 instances by two NLP researchers confirmed the dataset’s quality and a substantial LLM-human agreement (Cohen’s kappa coefficient κ=0.6642). To demonstrate its value, we establish baseline benchmarks and show that fine-tuning on PersianSciQA dramatically improves a state-of-the-art model, achieving a Spearman correlation of 0.895 on a blind test set. PersianSciQA provides a crucial new resource to facilitate research in information retrieval and question answering within the Persian scientific domain.</abstract>
      <url hash="ffeab280">2025.ranlp-1.4</url>
      <bibkey>aghadavoud-jolfaei-etal-2025-persiansciqa</bibkey>
    </paper>
    <paper id="5">
      <title>Multilingual Pre-training Meets Supervised Neural Machine Translation: A Reproducible Evaluation on <fixed-case>E</fixed-case>nglish–<fixed-case>F</fixed-case>rench and <fixed-case>F</fixed-case>innish Translation</title>
      <author><first>Benyamin</first><last>Ahmadnia</last></author>
      <author><first>Yeswanth</first><last>Soma</last></author>
      <author><first>Hossein</first><last>Sarrafzadeh</last></author>
      <pages>38–47</pages>
      <abstract>This paper presents a comparative evaluation of Transformer-based Neural Machine Translation (NMT) models and pre-trained multilingual sequence-to-sequence models in the context of moderately-resourced MT. Using English-French (high-resource) and English-Finnish (moderate-resource) as case studies, we assess the effectiveness of fine-tuning the mBART model versus training standard NMT systems from scratch. Our experiments incorporate data-augmentation techniques such as back-translation and evaluate translation quality using BLEU, TER, METEOR, and COMET metrics. We also provide a detailed error analysis that covers lexical choice, named entity handling, and word order. While mBART demonstrates consistent improvements over classical NMT, particularly in handling complex linguistic structures and sparse training data, we acknowledge the challenges of deploying large models in resource-constrained settings. Our findings highlight practical trade-offs between model complexity, resource availability, and translation quality in multilingual scenarios.</abstract>
      <url hash="fa00cbd2">2025.ranlp-1.5</url>
      <bibkey>ahmadnia-etal-2025-multilingual</bibkey>
    </paper>
    <paper id="6">
      <title>Advancing Clinical Translation in <fixed-case>N</fixed-case>epali through Fine-Tuned Multilingual Models</title>
      <author><first>Benyamin</first><last>Ahmadnia</last></author>
      <author><first>Sumaiya</first><last>Shaikh</last></author>
      <author><first>Bibek</first><last>Poudel</last></author>
      <author><first>Shazan</first><last>Mohammed</last></author>
      <author><first>Sahar</first><last>Hooshmand</last></author>
      <pages>48–56</pages>
      <abstract>Low-resource Neural Machine Translation (NMT) remains a major challenge, particularly in high-stakes domains such as healthcare. This paper presents a domain-adapted pipeline for English-Nepali medical translation leveraging two state-of-the-art multilingual Large Language Models (LLMs): mBART and NLLB-200. A high-quality, domain-specific parallel corpus is curated, and both models are fine-tuned using PyTorch frameworks. Translation fidelity is assessed through a multi-metric evaluation strategy that combines BLEU, CHRF++, METEOR, BERTScore, COMET, and perplexity. Our experimental results show that NLLB-200 consistently outperforms mBART across surface-level and semantic metrics, achieving higher accuracy and lower hallucination rates in clinical settings. In addition, error profiling and ethical assessments are conducted to highlight challenges such as term omissions and cultural bias. This work underscores the viability of large-scale multilingual models in enhancing medical translation for low-resource languages and proposes actionable paths toward safer and more equitable MT deployment in healthcare.</abstract>
      <url hash="372acd77">2025.ranlp-1.6</url>
      <bibkey>ahmadnia-etal-2025-advancing</bibkey>
    </paper>
    <paper id="7">
      <title>Advancing Active Learning with Ensemble Strategies</title>
      <author><first>Naif</first><last>Alatrush</last></author>
      <author><first>Sultan</first><last>Alsarra</last></author>
      <author><first>Afraa</first><last>Alshammari</last></author>
      <author><first>Luay</first><last>Abdeljaber</last></author>
      <author><first>Niamat</first><last>Zawad</last></author>
      <author><first>Latifur</first><last>Khan</last></author>
      <author><first>Patrick T.</first><last>Brandt</last></author>
      <author><first>Javier</first><last>Osorio</last></author>
      <author><first>Vito</first><last>D’Orazio</last></author>
      <pages>57–66</pages>
      <abstract>Active learning (AL) reduces annotation costs by selecting the most informative samples for labeling. However, traditional AL methods rely on a single heuristic, limiting data exploration and annotation efficiency. This paper introduces two ensemble-based AL methods: Ensemble Union, which combines multiple heuristics to improve dataset exploration, and Ensemble Intersection, which applies majority voting for robust sample selection. We evaluate these approaches on the United Nations Parallel Corpus (UNPC) in both English and Spanish using domain-specific models such as ConfliBERT. Our results show that ensemble-based AL strategies outperform individual heuristics, achieving classification performance comparable to full dataset training while using significantly fewer labeled examples. Although focused on political texts, the proposed methods are applicable to broader NLP annotation tasks where labeling costs are high.</abstract>
      <url hash="4d021778">2025.ranlp-1.7</url>
      <bibkey>alatrush-etal-2025-advancing</bibkey>
    </paper>
    <paper id="8">
      <title>Evaluating Large Language Models on Sentiment Analysis in <fixed-case>A</fixed-case>rabic Dialects</title>
      <author><first>Maram I.</first><last>Alharbi</last></author>
      <author><first>Saad</first><last>Ezzini</last></author>
      <author><first>Hansi</first><last>Hettiarachchi</last></author>
      <author><first>Tharindu</first><last>Ranasinghe</last></author>
      <author id="ruslan-mitkov"><first>Ruslan</first><last>Mitkov</last></author>
      <pages>67–74</pages>
      <abstract>Despite recent progress in large language models (LLMs), their performance on Arabic dialects remains underexplored, particularly in the context of sentiment analysis. This study presents a comparative evaluation of three LLMs, DeepSeek-R1, Qwen2.5, and LLaMA-3, on sentiment classification across Modern Standard Arabic (MSA), Saudi dialect and Darija. We construct a balanced sentiment dataset by translating and validating MSA hotel reviews into Saudi dialect and Darija. Using parameter-efficient fine-tuning (LoRA) and dialect-specific prompts, we assess each model under matched and mismatched prompting conditions. Evaluation results show that Qwen2.5 achieves the highest macro F1 score of 79% on Darija input using MSA prompts, while DeepSeek performs best when prompted in the input dialect, reaching 71% on Saudi dialect. LLaMA-3 exhibits stable performance across prompt variations, with 75% macro F1 on Darija input under MSA prompting. Dialect-aware prompting consistently improves classification accuracy, particularly for neutral and negative sentiment classes.</abstract>
      <url hash="97a24392">2025.ranlp-1.8</url>
      <bibkey>alharbi-etal-2025-evaluating-large</bibkey>
    </paper>
    <paper id="9">
      <title>From Posts to Predictions: A User-Aware Framework for Faithful and Transparent Detection of Mental Health Risks on Social Media</title>
      <author><first>Hessam</first><last>Amini</last></author>
      <author><first>Leila</first><last>Kosseim</last></author>
      <pages>75–84</pages>
      <abstract>We propose a user-aware attention-based framework for early detection of mental health risks from social media posts. Our model combines DisorBERT, a mental health–adapted transformer encoder, with a user-level attention mechanism that produces transparent post-level explanations. To assess whether these explanations are faithful, i.e., aligned with the model’s true decision process, we apply adversarial training and quantify attention faithfulness using the AtteFa metric. Experiments on four eRisk tasks (depression, anorexia, self-harm, and pathological gambling) show that our model achieves competitive latency-weighted F1 scores while relying on a sparse subset of posts per user. We also evaluate attention robustness and conduct ablations, confirming the model’s reliance on high-weighted posts. Our work extends prior explainability studies by integrating faithfulness assessment in a real-world high-stakes application. We argue that systems combining predictive accuracy with faithful and transparent explanations offer a promising path toward safe and trustworthy AI for mental health support.</abstract>
      <url hash="66e3afe5">2025.ranlp-1.9</url>
      <bibkey>amini-kosseim-2025-posts</bibkey>
    </paper>
    <paper id="10">
      <title>Beyond Methods and Datasets Entities: Introducing <fixed-case>SH</fixed-case>-<fixed-case>NER</fixed-case> for Hardware and Software Entity Recognition in Scientific Text</title>
      <author><first>Aftab</first><last>Anjum</last></author>
      <author><first>Nimra</first><last>Maqbool</last></author>
      <author><first>Ralf</first><last>Krestel</last></author>
      <pages>85–94</pages>
      <abstract>Scientific Information Extraction (SciIE) has become essential for organizing and understanding scientific literature, powering tasks such as knowledge graph construction, method recommendation, and automated literature reviews. Although prior SciIE work commonly annotates entities such as tasks, methods, and datasets, it systematically neglects infrastructure-related entities like hardware and software specifications mentioned in publications. This gap limits key applications: knowledge graphs remain incomplete, and recommendation systems cannot effectively filter methods based on hardware compatibility. To address this gap, we introduce SH-NER, the first large-scale, manually annotated dataset focused on infrastructure-related entities in NLP research. SH-NER comprises 1,128 full-text papers from the ACL Anthology and annotates five entity types: Software, Cloud-Platform, Hardware-Device, Device-Count, and Device-Memory. Our dataset comprises over 9k sample sentences with around 6k annotated entity mentions. To assess the effectiveness of SH-NER, we conducted comprehensive experiments employing state-of-the-art supervised models alongside large language models (LLMs) as baselines. The results show that SH-NER improves scientific information extraction by better capturing infrastructure mentions. You can find the manually annotated dataset at https://github.com/coderhub84/SH-NER.</abstract>
      <url hash="24001373">2025.ranlp-1.10</url>
      <bibkey>anjum-etal-2025-beyond</bibkey>
    </paper>
    <paper id="11">
      <title>Toponym Resolution: Will Prompt Engineering Change Expectations?</title>
      <author><first>Isuri</first><last>Anuradha</last></author>
      <author><first>Deshan Koshala</first><last>Sumanathilaka</last></author>
      <author id="ruslan-mitkov"><first>Ruslan</first><last>Mitkov</last></author>
      <author><first>Paul</first><last>Rayson</last></author>
      <pages>95–104</pages>
      <abstract>Large Language Models(LLMs) have revolutionised the field of artificial intelligence and have been successfully employed in many disciplines, capturing widespread attention and enthusiasm. Many previous studies have established that Domain-specific Deep Learning models to competitively perform with the general-purpose LLMs (Maatouk et al., 2024;Lu et al., 2024). However, a suitable prompt which provides direct instructions and background information is expected to yield im- proved results (Kamruzzaman and Kim, 2024). The present study focuses on utilising LLMs for the Toponym Resolution task by incorporating Retrieval-Augmented Generation(RAG) and prompting techniques to surpass the results of the traditional Deep Learning models. Moreover, this study demonstrates that promising results can be achieved without relying on large amounts of labelled, domain-specific data. After a descriptive comparison between open-source and proprietary LLMs through different prompt engineering techniques, the GPT-4o model performs best compared to the other LLMs for the Toponym Resolution task.</abstract>
      <url hash="5dec699a">2025.ranlp-1.11</url>
      <bibkey>anuradha-etal-2025-toponym</bibkey>
    </paper>
    <paper id="12">
      <title><fixed-case>H</fixed-case>olo<fixed-case>BERT</fixed-case>: Pre-Trained Transformer Model for Historical Narratives</title>
      <author><first>Isuri</first><last>Anuradha</last></author>
      <author><first>Le An</first><last>Ha</last></author>
      <author id="ruslan-mitkov"><first>Ruslan</first><last>Mitkov</last></author>
      <pages>105–110</pages>
      <abstract>Oral texts often contain spontaneous, unstructured language with features like disfluencies, colloquialisms, and non-standard syntax. In this paper, we investigate how further pretraining language models with specialised learning objectives for oral and transcribed texts to enhance Named Entity Recognition (NER) performance in Holocaust-related discourse. To evaluate our models, we compare the extracted named entities (NE) against those from other pretrained models on historical texts and generative AI models such as GPT. Furthermore, we demonstrate practical applications of the recognised NEs by linking them to a knowledge base as structured metadata and representing them in a graph format. With these contributions, our work illustrates how the further-pretrain-and-fine-tune paradigm in Natural Language Processing advances research in Digital Humanities.</abstract>
      <url hash="1b0a5a6e">2025.ranlp-1.12</url>
      <bibkey>anuradha-etal-2025-holobert</bibkey>
    </paper>
    <paper id="13">
      <title>A Framework for Fine-Tuning <fixed-case>LLM</fixed-case>s Using Heterogeneous Feedback</title>
      <author><first>Ryan</first><last>Aponte</last></author>
      <author><first>Ryan A.</first><last>Rossi</last></author>
      <author><first>Shunan</first><last>Guo</last></author>
      <author><first>Franck</first><last>Dernoncourt</last></author>
      <author><first>Tong</first><last>Yu</last></author>
      <author><first>Xiang</first><last>Chen</last></author>
      <author><first>Subrata</first><last>Mitra</last></author>
      <author><first>Nedim</first><last>Lipka</last></author>
      <pages>111–117</pages>
      <abstract>Large language models (LLMs) have been applied to a wide range of tasks, including text summarization, web navigation, and chat- bots. They have benefitted from supervised fine-tuning (SFT) and reinforcement learning from human feedback (RLHF) following an un- supervised pretraining. These datasets can be difficult to collect, limited in scope, and vary in sample quality. Additionally, datasets can vary extensively in supervision format, from numer- ical to binary as well as multi-dimensional with many different values. We present a framework for fine-tuning LLMs using heterogeneous feed- back, which has two main components. First, we combine the heterogeneous feedback data into a single supervision format, compatible with methods like SFT and RLHF. Next, given this unified feedback dataset, we extract a high- quality and diverse subset to obtain perfor- mance increases potentially exceeding the full dataset. We conduct extensive experiments to understand the effectiveness of these tech- niques for incorporating heterogeneous feed- back, and demonstrate improvements from us- ing a high-quality and diverse subset of the data. We find that our framework is able to improve models in multiple areas simultaneously, such as in instruction following and bias reduction.</abstract>
      <url hash="29c4d16e">2025.ranlp-1.13</url>
      <bibkey>aponte-etal-2025-framework</bibkey>
    </paper>
    <paper id="14">
      <title>Chakoshi: A Customizable Guardrail for <fixed-case>LLM</fixed-case>s with a Focus on <fixed-case>J</fixed-case>apanese-Language Moderation</title>
      <author><first>Kazuhiro</first><last>Arai</last></author>
      <author><first>Ryota</first><last>Matsui</last></author>
      <author><first>Kenji</first><last>Miyama</last></author>
      <author><first>Yudai</first><last>Yamamoto</last></author>
      <author><first>Ren</first><last>Shibamiya</last></author>
      <author><first>Kaito</first><last>Sugimoto</last></author>
      <author><first>Yoshimasa</first><last>Iwase</last></author>
      <pages>118–124</pages>
      <abstract>In this research, we developed and evaluated “chakoshi” an LLM guardrail model designed to address Japanese-specific nuances. chakoshi is a lightweight LLM that has been fine-tuned using multiple open datasets and proprietary learning datasets. Based on gemma-2-9b, the chakoshi model achieved an average F1 score of 0.92 or higher across multiple test datasets, demonstrating superior performance compared to existing models. Additionally, we implemented a feature that allows customization of categories to be filtered using natural language, and confirmed its effectiveness through practical examples.</abstract>
      <url hash="88cdd505">2025.ranlp-1.14</url>
      <bibkey>arai-etal-2025-chakoshi</bibkey>
    </paper>
    <paper id="15">
      <title><fixed-case>K</fixed-case>o<fixed-case>W</fixed-case>it-24: A Richly Annotated Dataset of Wordplay in News Headlines</title>
      <author><first>Alexander</first><last>Baranov</last></author>
      <author><first>Anna</first><last>Palatkina</last></author>
      <author><first>Yulia</first><last>Makovka</last></author>
      <author><first>Pavel</first><last>Braslavski</last></author>
      <pages>125–132</pages>
      <abstract>We present KoWit-24, a dataset with fine-grained annotation of wordplay in 2,700 Russian news headlines. KoWit-24 annotations include the presence of wordplay, its type, wordplay anchors, and words/phrases the wordplay refers to. Unlike the majority of existing humor collections of canned jokes, KoWit-24 provides wordplay contexts – each headline is accompanied by the news lead and summary. The most common type of wordplay in the dataset is the transformation of collocations, idioms, and named entities – the mechanism that has been underrepresented in previous humor datasets. Our experiments with five LLMs show that there is ample room for improvement in wordplay detection and interpretation tasks. The dataset and evaluation scripts are available at https://github.com/Humor-Research/KoWit-24</abstract>
      <url hash="184acbd0">2025.ranlp-1.15</url>
      <bibkey>baranov-etal-2025-kowit</bibkey>
    </paper>
    <paper id="16">
      <title>Improving <fixed-case>E</fixed-case>stonian Text Simplification through Pretrained Language Models and Custom Datasets</title>
      <author><first>Eduard</first><last>Barbu</last></author>
      <author><first>Meeri-Ly</first><last>Muru</last></author>
      <author><first>Sten Marcus</first><last>Malva</last></author>
      <pages>133–142</pages>
      <abstract>This paper presents a method for text simplification based on two neural architectures: a neural machine translation (NMT) model and a fine-tuned large language model (LLaMA). Given the scarcity of existing resources for Estonian, a new dataset was created by combining manually translated corpora with GPT-4.0-generated simplifications. OpenNMT was selected as a representative NMT-based system, while LLaMA was fine-tuned on the constructed dataset. Evaluation shows LLaMA outperforms OpenNMT in grammaticality, readability, and meaning preservation. These results underscore the effectiveness of large language models for text simplification in low-resource language settings. The complete dataset, fine-tuning scripts, and evaluation pipeline are provided in a publicly accessible supplementary package to support reproducibility and adaptation to other languages.</abstract>
      <url hash="031a72ce">2025.ranlp-1.16</url>
      <bibkey>barbu-etal-2025-improving</bibkey>
    </paper>
    <paper id="17">
      <title>Mitigating Bias in Text Classification via Prompt-Based Text Transformation</title>
      <author><first>Charmaine</first><last>Barker</last></author>
      <author><first>Dimitar</first><last>Kazakov</last></author>
      <pages>143–149</pages>
      <abstract>The presence of specific linguistic signals particular to a certain sub-group can become highly salient to language models during training. In automated decision-making settings, this may lead to biased outcomes when models rely on cues that correlate with protected characteristics. We investigate whether prompting ChatGPT to rewrite text using simplification, neutralisation, localisation, and formalisation can reduce demographic signals while preserving meaning. Experimental results show a statistically significant drop in location classification accuracy across multiple models after transformation, suggesting reduced reliance on group-specific language. At the same time, sentiment analysis and rating prediction tasks confirm that the core meaning of the reviews remains greatly intact. These results suggest that prompt-based rewriting offers a practical and generalisable approach for mitigating bias in text classification.</abstract>
      <url hash="673d4477">2025.ranlp-1.17</url>
      <bibkey>barker-kazakov-2025-mitigating</bibkey>
    </paper>
    <paper id="18">
      <title>Towards <fixed-case>CEFR</fixed-case>-targeted Text Simplification for Question Adaptation</title>
      <author><first>Luca</first><last>Benedetto</last></author>
      <author><first>Paula</first><last>Buttery</last></author>
      <pages>150–157</pages>
      <abstract>Text Simplification (TS) can adapt educational content to learners’ proficiency levels. In reading comprehension questions, passage complexity directly affects the question difficulty; thus, TS could enable automatic question adaptation by generating multiple versions of a reading passage. However, despite the potential of TS and its applications in other domains, the feasibility, reliability, and robustness of TS for question adaptation remains unexplored. In this paper, we conduct the first evaluation of LLMs for CEFR targeted text simplification aimed at question adaptation. Specifically, we investigate whether LLMs can perform CEFR-targeted text simplification and how this affects question answerability. Evaluating four LLMs on two English learning datasets, we show that they can mostly perform targeted simplification with readability values correlating with reference CEFR levels, but alignment is imperfect. Crucially, the simplified texts generally preserve the information needed to for question answering, and questions associated with texts simplified at lower levels show reduced difficulty in virtual pretesting. These preliminary findings show the potential of LLMs for educational content adaptation, but practical deployment will need improved CEFR alignment.</abstract>
      <url hash="1a692ee5">2025.ranlp-1.18</url>
      <bibkey>benedetto-buttery-2025-towards</bibkey>
    </paper>
    <paper id="19">
      <title>Evaluation of Pretrained and Instruction-Based Pretrained Models for Emotion Detection in <fixed-case>A</fixed-case>rabic Social Media Text</title>
      <author><first>Md. Rafiul</first><last>Biswas</last></author>
      <author><first>Shimaa</first><last>Ibrahim</last></author>
      <author><first>Mabrouka</first><last>Bessghaier</last></author>
      <author><first>Wajdi</first><last>Zaghouani</last></author>
      <pages>158–165</pages>
      <abstract>This study evaluates three approaches—instruction prompting of large language models (LLMs), instruction fine-tuning of LLMs, and transformer-based pretrained models on emotion detection in Arabic social media text. We compare pretrained transformer models like AraBERT, CaMelBERT, and XLM-RoBERTa with instruction prompting with advanced LLMs like GPT-4o, Gemini, Deepseek, and Fanar, and instruction fine-tuning approaches with LLMs like Llama 3.1, Mistral, and Phi. With a highly preprocessed dataset of 10,000 labeled Arabic tweets with overlapping emotional labels, our findings reveal that transformer-based pretrained models outperform instruction prompting and instruction fine-tuning approaches. Instruction prompts leverage general linguistic skills with maximum efficiency but fall short in detecting subtle emotional contexts. Instruction fine-tuning is more specific but trails behind pretrained transformer models. Our findings establish the need for optimized instruction-based approaches and underscore the important role played by domain-specific transformer architectures in accurate Arabic emotion detection.</abstract>
      <url hash="074ffc1e">2025.ranlp-1.19</url>
      <bibkey>biswas-etal-2025-evaluation</bibkey>
    </paper>
    <paper id="20">
      <title>Can <fixed-case>LLM</fixed-case>s Disambiguate Grounded Language? The Case of <fixed-case>PP</fixed-case> Attachment</title>
      <author><first>John</first><last>Blackmore</last></author>
      <author><first>Matthew</first><last>Stone</last></author>
      <pages>166–174</pages>
      <abstract>We explore the potential of large language models in resolving ambiguity in prepositional phrase attachments in grounded language. We find that when prompted in such a way that we can compute a probability of the respective attachment, models yield promising results. However, additional inputs from a measure of information structure may help improve prediction accuracy. We also investigate where we need more sophisticated tools, commonsense reasoning, world knowledge, and additional context to resolve ambiguity.</abstract>
      <url hash="07a09cbc">2025.ranlp-1.20</url>
      <bibkey>blackmore-stone-2025-llms</bibkey>
    </paper>
    <paper id="21">
      <title><fixed-case>MLD</fixed-case>ata<fixed-case>F</fixed-case>orge: Accelerating Large-Scale Dataset Preprocessing and Access for Multimodal Foundation Model Training</title>
      <author><first>Andrea</first><last>Blasi Núñez</last></author>
      <author><first>Lukas Paul</first><last>Achatius Galke</last></author>
      <author><first>Peter</first><last>Schneider-Kamp</last></author>
      <pages>175–183</pages>
      <abstract>Preprocessing large and possibly multimodal datasets remains a key bottleneck in many machine learning workflows, particularly when random access to samples is needed for global shuffling and sorting. Existing approaches, including widely used formats like JSONL and frameworks such as Huggingface Datasets and MosaicML Streaming, typically incur substantial computational, memory, and storage overhead in such settings. Here, we introduce MLDataForge, a Python-based open-source framework designed for scalable dataset pre-processing and access. Our key contributions are: (1) optimized readers for Mosaic Data Shards (MDS) that substantially improve throughput, reduce peak storage usage, and support sample-level compression; (2) JINX (JSON Indexed ’N’ eXtended), a novel, index-augmented JSONL-compatible format supporting structured footers and binary sidecar files; and (3) a lazy-loading mechanism that defers data loading, decompression, and decoding JINX files until sample fields are accessed. We empirically evaluate MLDataForge and our contributions on a representative 200 GB supervised fine-tuning dataset for vision language models. Our best configuration – zstd-compressed JINX with binary sidecar and lazy loading – yields at least a decimal order-of-magnitude throughput increase compared to the best baselines for iteration, global shuffling, and sorting. These advances enable substantial gains in data preprocessing performance, facilitating more scalable and resource-efficient model training pipelines.</abstract>
      <url hash="088886ba">2025.ranlp-1.21</url>
      <bibkey>blasi-nunez-etal-2025-mldataforge</bibkey>
    </paper>
    <paper id="22">
      <title>The Impact of Named Entity Recognition on Transformer-Based Multi-Label Dietary Recipe Classification</title>
      <author><first>Kemalcan</first><last>Bora</last></author>
      <author><first>Horacio</first><last>Saggion</last></author>
      <pages>184–193</pages>
      <abstract>This research explores the impact of Named Entity Recognition (NER) on transformer-based models for multi-label recipe classification by dietary preference. To support this task, we introduce the NutriCuisine Index: a collection of 23,932 recipes annotated across six dietary categories (Healthy, Vegan, Gluten-Free, Low-Carb, High-Protein, Low-Sugar). Using BERT-base-uncased, RoBERTa-base, and DistilBERT-base-uncased, we evaluate how NER-based preprocessing affects the performance (F1-score, Precision, Recall, and Hamming Loss) of Transformer-based multi-label classification models. RoBERTa-base shows significant improvements with NER in F1-score (∆F1 = +0.0147, p &lt; 0.001), Precision, and Recall, while BERT and DistilBERT show no such gains. NER also leads to a slight but statistically significant increase in Hamming Loss across all models. These findings highlight the model dependent impact of NER on classification performance.</abstract>
      <url hash="8bdf321f">2025.ranlp-1.22</url>
      <bibkey>bora-saggion-2025-impact</bibkey>
    </paper>
    <paper id="23">
      <title>Balancing the Scales: Addressing Gender Bias in Social Media Toxicity Detection</title>
      <author><first>Beatriz</first><last>Botella-Gil</last></author>
      <author><first>Juan Pablo</first><last>Consuegra-Ayala</last></author>
      <author><first>Alba</first><last>Bonet-Jover</last></author>
      <author><first>Paloma</first><last>Moreda-Pozo</last></author>
      <pages>194–203</pages>
      <abstract>The detection of toxic content in social media has become a critical task in Natural Language Processing (NLP), particularly given its intersection with complex issues like subjectivity, implicit language, and cultural context. Among these challenges, bias in training data remains a central concern—especially as language models risk reproducing and amplifying societal inequalities. This paper investigates the interplay between toxicity and gender bias on Twitter/X by introducing a novel dataset of violent and non-violent tweets, annotated not only for violence but also for gender. We conduct an exploratory analysis of how biased data can distort toxicity classification and present algorithms to mitigate these effects through dataset balancing and debiasing. Our contributions include four new dataset splits—two balanced and two debiased—that aim to support the development of fairer and more inclusive NLP models. By foregrounding the importance of equity in data curation, this work lays the groundwork for more ethical approaches to automated violence detection and gender annotation.</abstract>
      <url hash="01519035">2025.ranlp-1.23</url>
      <bibkey>botella-gil-etal-2025-balancing</bibkey>
    </paper>
    <paper id="24">
      <title>“Simple-Tool”: A Tool for the Automatic Transformation of <fixed-case>S</fixed-case>panish Texts into Easy-to-Read</title>
      <author><first>Beatriz</first><last>Botella-Gil</last></author>
      <author><first>Isabel</first><last>Espinosa-Zaragoza</last></author>
      <author id="paloma-moreda-pozo"><first>Paloma</first><last>Moreda Pozo</last></author>
      <author id="manuel-palomar"><first>Manuel</first><last>Palomar</last></author>
      <pages>204–209</pages>
      <abstract>Automatic Text Simplification (ATS) has emerged as a key area of research within the field of Natural Language Processing, aiming to improve access to information by reducing the linguistic complexity of texts. Simplification can be applied at various levels—lexical, syntactic, semantic, and stylistic—and must be tailored to meet the needs of different target audiences, such as individuals with cognitive disabilities, low-literacy readers, or non-native speakers. This work introduces a tool that automatically adapts Spanish texts into Easy-to-Read format, enhancing comprehension for people with cognitive or reading difficulties. The proposal is grounded in a critical review of existing Spanish-language resources and addresses the need for accessible, well-documented solutions aligned with official guidelines, reinforcing the potential of text simplification as a strategy for inclusion.</abstract>
      <url hash="8edbbf3f">2025.ranlp-1.24</url>
      <bibkey>botella-gil-etal-2025-simple</bibkey>
    </paper>
    <paper id="25">
      <title><fixed-case>Q</fixed-case>u<fixed-case>ARK</fixed-case>: <fixed-case>LLM</fixed-case>-Based Domain-Specific Question Answering Using Retrieval Augmented Generation and Knowledge Graphs</title>
      <author><first>Edward</first><last>Burgin</last></author>
      <author><first>Sourav</first><last>Dutta</last></author>
      <author><first>Mingxue</first><last>Wang</last></author>
      <pages>210–217</pages>
      <abstract>Retrieval Augmented Generation (RAG) has been pivotal in the utilization of Large Language Models (LLM) to improve the factuality of long-form question answering systems in industrial settings. Knowledge graphs (KG) represent a linking of disparate information sources that potentially yield useful information for mitigating the issues of insufficient knowledge and hallucination within the LLM-RAG pipeline. However, the creation of domain-specific KG is costly and usually requires a domain expert. To alleviate the above challenges, this work proposes QuARK, a novel domain-specific question answering framework to enhance the knowledge capabilities of LLM by integrating structured KG, thereby significantly reducing the reliance on the “generic” latent knowledge of LLMs. Here, we showcase how LLMs can be deployed to not only act in dynamic information retrieval and in answer generating frameworks, but also as flexible agents to automatically extract relevant entities and relations for the automated construction of domain-specific KGs. Crucially we propose how the pairing of question decomposition and semantic triplet retrieval within RAG can enable optimal subgraph retrieval. Experimental evaluations of our framework on financial domain public dataset, demonstrate that it enables a robust pipeline incorporating schema-free KG within a RAG framework to improve the overall accuracy by nearly 13%.</abstract>
      <url hash="2e1d173f">2025.ranlp-1.25</url>
      <bibkey>burgin-etal-2025-quark</bibkey>
    </paper>
    <paper id="26">
      <title>Classifying Emotions in Tweets from the Financial Market: A <fixed-case>BERT</fixed-case>-based Approach</title>
      <author><first>Wesley Pompeu</first><last>Carvalho</last></author>
      <author id="norton-trevisan-roman"><first>Norton Trevisan</first><last>Roman</last></author>
      <pages>218–226</pages>
      <abstract>Behavioural finance emphasizes the relevance of investor sentiment and emotions in the pricing of financial assets. However, little research has examined how discrete emotions can be detected in text related to this domain, with extant work focusing mostly in sentiment instead. This study approaches this problem by describing a framework for emotion classification in tweets related to the stock market, written in Brazilian Portuguese. Emotion classifiers were then developed, based on Plutchik’s psychoevolutionary theory, by fine-tuning BERTimbau, a pre-trained BERT-based language model for Brazilian Portuguese, and applying it to an existing corpus of tweets, from the stock market domain, previously annotated with emotions. Each of Plutchik’s four emotional axes was modelled as a ternary classification problem. For each axis, 30 independent training iterations were executed using a repeated holdout strategy with different train/test splits in each iteration. In every iteration, hyperparameter tuning was performed via 10-fold stratified cross-validation on the training set to identify the best configuration. A final model was then retrained using the selected hyperparameters and evaluated on a hold-out test set, generating a distribution of macro-F1 scores in out-of-sample data. The results demonstrated statistically significant improvements over a stratified random baseline (Welch’s t-test, &lt;&lt; 0.001 across all axes), with macro-F1 scores ranging from 0.50 to 0.61. These findings point to the feasibility of using transformer-based models to capture emotional nuance in financial texts written in Portuguese and provide a reproducible framework for future research.</abstract>
      <url hash="37465594">2025.ranlp-1.26</url>
      <bibkey>carvalho-roman-2025-classifying</bibkey>
    </paper>
    <paper id="27">
      <title>Detecting Changes in Mental Health Status via <fixed-case>R</fixed-case>eddit Posts in Response to Global Negative Events</title>
      <author><first>Zenan</first><last>Chen</last></author>
      <author><first>Judita</first><last>Preiss</last></author>
      <author><first>Peter A.</first><last>Bath</last></author>
      <pages>227–233</pages>
      <abstract>Detecting population-level mental health responses to global negative events through social media language remains understudied, despite its potential for public health surveillance. While pretrained language models (PLMs) have shown promise in mental health detection, their effectiveness in capturing event-driven collective psychological shifts – especially across diverse crisis contexts – is unclear. We present a prototype evaluation of three PLMs for identifying population mental health dynamics triggered by real-world negative events. We introduce two novel datasets specifically designed for this task. Our findings suggest that DistilBERT is better suited to the noisier global negative events data, while MentalRoBERTa shows the validity of the method on the Covid-19 tidier data. SHAP interpretability analysis of 500 randomly sampled posts revealed that mental-health related vocabulary (anxiety, depression, worthless) emerged as the most influential linguistic markers for mental health classification.</abstract>
      <url hash="315b56c1">2025.ranlp-1.27</url>
      <bibkey>chen-etal-2025-detecting-changes</bibkey>
    </paper>
    <paper id="28">
      <title><fixed-case>APIO</fixed-case>: Automatic Prompt Induction and Optimization for Grammatical Error Correction and Text Simplification</title>
      <author><first>Artem</first><last>Chernodub</last></author>
      <author><first>Aman</first><last>Saini</last></author>
      <author><first>Yejin</first><last>Huh</last></author>
      <author><first>Vivek</first><last>Kulkarni</last></author>
      <author><first>Vipul</first><last>Raheja</last></author>
      <pages>234–239</pages>
      <abstract>Recent advancements in large language models (LLMs) have enabled a wide range of natural language processing (NLP) tasks through simple prompt-based interactions. Consequently, several approaches have been proposed to engineer prompts that most effectively enable LLMs to perform a given task (e.g., chain-of-thought prompting). In settings with a well-defined metric to optimize model performance, Automatic Prompt Optimization (APO) methods have been developed to refine a seed prompt. Subsequently, we propose APIO, a simple but effective prompt induction and optimization approach for the tasks of Grammatical Error Correction (GEC) and Text Simplification, without relying on manually specified seed prompts. APIO achieves a new state-of-the-art performance for purely LLM-based prompting methods on these tasks. We make our data, code, prompts, and outputs publicly available.</abstract>
      <url hash="898d9baf">2025.ranlp-1.28</url>
      <bibkey>chernodub-etal-2025-apio</bibkey>
    </paper>
    <paper id="29">
      <title>Integrating Archaic and Regional Lexicons to Improve the Readability of <fixed-case>O</fixed-case>ld <fixed-case>R</fixed-case>omanian Texts</title>
      <author><first>Madalina</first><last>Chitez</last></author>
      <author><first>Roxana</first><last>Rogobete</last></author>
      <author><first>Cristina Aura</first><last>Udrea</last></author>
      <author><first>Karla</first><last>Csürös</last></author>
      <author><first>Ana-Maria</first><last>Bucur</last></author>
      <author><first>Mihai</first><last>Dascalu</last></author>
      <pages>240–246</pages>
      <abstract>Access to age-appropriate texts is critical for young readers’ literacy acquisition. For limited-resourced languages, such as Romanian, this area remains under-researched. As such, we present ongoing work on improving readability for old Romanian texts by applying Large Language Models (LLMs). First, we compiled and cleaned a comprehensive list of archaic and regional terms from lexicographic sources, including DEX online and printed dictionaries. The cleaning process involved duplicate removal, orthographic normalization, context-based filtering, and manual review. Key challenges included distinguishing archaic forms from rare or poetic ones, resolving polysemous entries, and managing inconsistent labeling across sources. Second, LLMs were utilized to validate the archaic and regional nature of identified terms and replace them with modern equivalents, while also determining the appropriate reading level for both original and modified versions. Results show that through the replacement of archaic and regional terms, the appropriate age for the modified texts decreases by approximately 0.5 years for texts extracted from textbooks and canonical writings.</abstract>
      <url hash="d1eda7ca">2025.ranlp-1.29</url>
      <bibkey>chitez-etal-2025-integrating</bibkey>
    </paper>
    <paper id="30">
      <title><fixed-case>E</fixed-case>x<fixed-case>P</fixed-case>e: Exact Positional Encodings for Generative Transformer Models with Extrapolating Capabilities</title>
      <author><first>Aleksis Ioannis</first><last>Datseris</last></author>
      <author><first>Sylvia</first><last>Vassileva</last></author>
      <author><first>Ivan K.</first><last>Koychev</last></author>
      <author><first>Svetla</first><last>Boytcheva</last></author>
      <pages>247–253</pages>
      <abstract>This paper introduces a novel approach to position embeddings in transformer models, named “Exact Positional Embeddings” (ExPE). An absolute positional embedding method that can extrapolate to sequences of lengths longer than the ones it was trained on. Traditional transformer models rely on absolute or relative position embeddings to incorporate positional information into token embeddings, which often struggle with extrapolation to sequences longer than those seen during training. Our proposed method utilizes a novel embedding strategy that encodes exact positional information by overriding specific dimensions of the embedding vectors, thereby enabling a more precise representation of token positions. The proposed approach not only maintains the integrity of the original embeddings but also enhances the model’s ability to generalize to longer sequences. In causal language modeling, our ExPE embeddings significantly reduce perplexity compared to rotary and sinusoidal embeddings, when tested on sequences longer than those used in training. The code and supplementary materials can be found in</abstract>
      <url hash="d84264ce">2025.ranlp-1.30</url>
      <bibkey>datseris-etal-2025-expe</bibkey>
    </paper>
    <paper id="31">
      <title>End-to-End Deep Learning for Named Entity Recognition and Relation Extraction in Gut-Brain Axis <fixed-case>P</fixed-case>ub<fixed-case>M</fixed-case>ed Abstracts</title>
      <author><first>Aleksis Ioannis</first><last>Datseris</last></author>
      <author><first>Mario</first><last>Kuzmanov</last></author>
      <author><first>Ivelina</first><last>Nikolova-Koleva</last></author>
      <author><first>Dimitar</first><last>Taskov</last></author>
      <author><first>Svetla</first><last>Boytcheva</last></author>
      <pages>254–259</pages>
      <abstract>This is a comparative study tackling named entity recognition and relation extraction from PubMed abstracts with focus on the gut-brain interplay. The proposed systems for named entity recognition cover a range of models and techniques from traditional gazetteer-based approaches, transformer-based approaches, transformer domain adaptation, large models pre-training as well as LLM prompting. The best performing model among these achieves 82.53% F1-score. The relation extraction task is addressed with ATLOP and LLMs and their best results reach F1 up to 63.80% on binary relation extraction, 89.40% on ternary tag-based relation extraction and 40.32% on ternary mention-based relation extraction.</abstract>
      <url hash="a14e6f4d">2025.ranlp-1.31</url>
      <bibkey>datseris-etal-2025-end</bibkey>
    </paper>
    <paper id="32">
      <title>Enabling On-Premises Large Language Models for Space Traffic Management</title>
      <author><first>Enrique</first><last>De Alba</last></author>
      <pages>260–267</pages>
      <abstract>Natural language processing systems leveraging on-premises large language models (LLMs) can translate natural language into structured JSON commands for Space Traffic Management (STM) systems. While cloud-based LLMs excel at this task, security constraints necessitate local deployment, requiring evaluation of smaller on-premises models. We demonstrate that resource-efficient 7B-parameter models can achieve high accuracy for STM command generation through a two-stage pipeline. Our pipeline first classifies objectives, then generates schemas. Empirically, we observe that initial classification accuracy strongly influences overall performance, with failures cascading to the generation stage. We demonstrate that quantization disproportionately increases structural errors compared to semantic errors across 405 objectives. The best quantized model (Falcon3-7B-GPTQ) shows a 3.45% accuracy drop, primarily from structural errors. Our findings highlight limitations in how model compression affects applications that require syntactic validity. More broadly, we explore the feasibility of LLM deployment in air-gapped environments while uncovering how quantization asymmetrically impacts structured output generation.</abstract>
      <url hash="f0da5188">2025.ranlp-1.32</url>
      <bibkey>de-alba-2025-enabling</bibkey>
    </paper>
    <paper id="33">
      <title>Top Ten from Lakhs: A Transformer-based Retrieval System for Identifying Previously Fact-Checked Claims across Multiple Languages</title>
      <author><first>Srijani</first><last>Debnath</last></author>
      <author><first>Pritam</first><last>Pal</last></author>
      <author><first>Dipankar</first><last>Das</last></author>
      <pages>268–274</pages>
      <abstract>The efficient identification of previously fact-checked claims across multiple languages is a challenging task. It can be time-consuming for professional fact-checkers even within a single language. It becomes much more difficult to perform manually when the claim and the fact-check may be in different languages. This paper presents a systematic approach for the retrieval of top-k relevant fact-checks for a given post in a monolingual and cross-lingual setup using two transformer-based fact-checked claim retrieval frameworks that share a common preprocessing pipeline but differ in their underlying encoder implementations: TIDE, a TensorFlow-based custom dual encoder applied to english-translated data, and PTEX, a PyTorch-based encoder operating on both english-translated and original-language inputs, and introduces a lightweight post-processing technique based on a textual feature: Keyword Overlap Count applied via reranking on top of the transformer-based frameworks. Training and evaluation on a large multilingual corpus show that the fine-tuned E5-Large-v2 model in the PTEX framework yields the best monolingual track performance, achieving an average Success@10 score of 0.8846 and the same framework model with post-processing technique achieves an average Success@10 score of 0.7393 which is the best performance in crosslingual track.</abstract>
      <url hash="d01ab12e">2025.ranlp-1.33</url>
      <bibkey>debnath-etal-2025-top</bibkey>
    </paper>
    <paper id="34">
      <title>Evaluating Bilingual Lexicon Induction without Lexical Data</title>
      <author><first>Michaela</first><last>Denisová</last></author>
      <author id="pavel-rychly"><first>Pavel</first><last>Rychly</last></author>
      <pages>275–282</pages>
      <abstract>Bilingual Lexicon Induction (BLI) is a fundamental task in cross-lingual word embedding (CWE) evaluation, aimed at retrieving word translations from monolingual corpora in two languages. Despite the task’s central role, existing evaluation datasets based on lexical data often contain biases such as a lack of morphological diversity, frequency skew, semantic leakage, and overrepresentation of proper names, which undermine the validity of reported performance. In this paper, we propose a novel, language-agnostic evaluation methodology that entirely eliminates the dependency on lexical data. By training two sets of monolingual word embeddings (MWEs) using identical data and algorithms but with different weight initialisations, we enable the assessment on the BLI task without being affected by the quality of the evaluation dataset. We evaluate three baseline CWE models and analyse the impact of key hyperparameters. Our results provide a more reliable and bias-free perspective on CWE models’ performance.</abstract>
      <url hash="98504b40">2025.ranlp-1.34</url>
      <bibkey>denisova-rychly-2025-evaluating</bibkey>
    </paper>
    <paper id="35">
      <title>Utilizing Large Language Models for Focused Conversational Assistants</title>
      <author><first>Shruti</first><last>Dhavalikar</last></author>
      <author><first>Karthika</first><last>Vijayan</last></author>
      <pages>283–290</pages>
      <abstract>A focused conversational assistant (FCA) realizes human-computer interaction bounded in a predefined scope of operation. With the advent of large language models (LLMs), it has become imperative to integrate them in conversational assistants (CAs). However, an LLM can become largely inaccurate in an FCA with multiple responsibilities, like information extraction, scope adherence and response generation. In this paper, we attempt to use an LLM for an FCA while constricting the scope of operation and maintaining a guided flow of conversation. We present a strategical combination of discriminative AI methods and generative AI models. Our methodology includes (i) a component of natural language understanding (NLU) operating discriminatively, (ii) a conditional intent-based routing of user messages to appropriate response generators, and (iii) response generators which are either custom ones or open sourced LLMs. The collation of these three strategies realizes a hybrid AI system, assisting FCA with adhering to the defined scope, maintaining context and dialogue flow.</abstract>
      <url hash="9cb98aa4">2025.ranlp-1.35</url>
      <bibkey>dhavalikar-vijayan-2025-utilizing</bibkey>
    </paper>
    <paper id="36">
      <title><fixed-case>A</fixed-case>nti<fixed-case>S</fixed-case>em<fixed-case>RO</fixed-case>: Studying the <fixed-case>R</fixed-case>omanian Expression of Antisemitism</title>
      <author><first>Anca</first><last>Dinu</last></author>
      <author><first>Andreea C.</first><last>Moldovan</last></author>
      <author><first>Adina</first><last>Marincea</last></author>
      <pages>291–298</pages>
      <abstract>This study introduces an annotated dataset for the study of antisemitic hate speech and attitudes towards Jewish people in Romanian, collected from social media. We performed two types of annotation: with three simple tags (‘Neutral’, ‘Positive’, ‘Negative’), and with five more refined tags (Neutral’, ‘Ambiguous’, ‘Jewish Community’, Solidarity’, ‘Zionism’, ‘Antisemitism’). We perform several experiments on this dataset: clusterization, automatic classification, using classical machine learning models and transformer-based models, and sentiment analysis. The three classes clusterization produced well grouped clusters, while, as expected, the five classes clusterization produced moderately overlapping groups, except for ‘Antisemitism’, which is well away from the other four groups. We obtained a good F1-Score of 0.78 in the three classes classification task with Romanian BERT model and a moderate F1-score of 0.62 for the five classes classification task with a SVM model. The lowest negative sentiment was contained in the ‘Neuter’ class, while the highest was in ‘Zionism’, and not in ‘Antisemitism’, as expected. Also, the same ‘Zionism’ category displays the highest level of positive sentiment.</abstract>
      <url hash="1d120a1e">2025.ranlp-1.36</url>
      <bibkey>dinu-etal-2025-antisemro</bibkey>
    </paper>
    <paper id="37">
      <title>Towards a Map of Related Words in <fixed-case>R</fixed-case>omance Languages</title>
      <author id="liviu-p-dinu"><first>Liviu P.</first><last>Dinu</last></author>
      <author><first>Ana Sabina</first><last>Uban</last></author>
      <author><first>Ioan-Bogdan</first><last>Iordache</last></author>
      <author><first>Claudia</first><last>Vlad</last></author>
      <author><first>Simona</first><last>Georgescu</last></author>
      <author><first>Laurentiu</first><last>Zoicas</last></author>
      <author><first>Anca</first><last>Dinu</last></author>
      <pages>299–305</pages>
      <abstract>We propose a map of cognates and borrowings usage in Romance languages, having as a starting point the pairs of cognates and borrowings between any two of these idioms from RoBoCoP, the largest database built upon electronic dictionaries containing etymological information for Portuguese, Spanish, French, Italian and Romanian. Having in mind that words are used and evolve in language communities over time, on the basis of the pairs extracted from RoBoCoP, we determine how many of them occur and with what frequency in the context of the languages in use, based on three online parallel corpora that contain all five Romance languages: Wikipedia, Europarl – focusing on proceedings of the European Parliament and RomCro2.0 – containing literary texts in different languages, translated in Romance languages and Croatian.</abstract>
      <url hash="8ad83172">2025.ranlp-1.37</url>
      <bibkey>dinu-etal-2025-towards</bibkey>
    </paper>
    <paper id="38">
      <title>Decoding Emotion in Ancient Poetry: Leveraging Generative Models for Classical <fixed-case>C</fixed-case>hinese Sentiment Analysis</title>
      <author><first>Quanqi</first><last>Du</last></author>
      <author><first>Loic</first><last>De Langhe</last></author>
      <author><first>Els</first><last>Lefever</last></author>
      <author id="veronique-hoste"><first>Veronique</first><last>Hoste</last></author>
      <pages>306–315</pages>
      <abstract>This study explores the use of generative language models for sentiment analysis of classical Chinese poetry, aiming to better understand emotional expression in literary texts. Using the FSPC dataset, we evaluate two models, Qwen-2.5 and LLaMA-3.1, under various prompting strategies. Initial experiments show that base models struggle with task-specific instructions. By applying different instruction tuning strategies with Low-Rank Adaptation (LoRA), we significantly enhance the models’ ability to follow task instructions and capture poetic sentiment, with LLaMA-3.1 achieving the best results (67.10% accuracy, 65.42% macro F1), demonstrate competitive performance against data-intensive, domain-adapted baselines. We further examine the effects of prompt language and multi-task learning, finding that English prompts outperform Chinese ones. These results highlight the promise of instruction-tuned generative models in sentiment analysis of classical Chinese poetry, and underscore the importance of prompt formulation in literary understanding tasks.</abstract>
      <url hash="60cabde2">2025.ranlp-1.38</url>
      <bibkey>du-etal-2025-decoding</bibkey>
    </paper>
    <paper id="39">
      <title><fixed-case>GRILE</fixed-case>: A Benchmark for Grammar Reasoning and Explanation in <fixed-case>R</fixed-case>omanian <fixed-case>LLM</fixed-case>s</title>
      <author><first>Marius</first><last>Dumitran</last></author>
      <author><first>Angela</first><last>Dumitran</last></author>
      <author><first>Alexandra Mihaela</first><last>Danila</last></author>
      <pages>316–324</pages>
      <abstract>Large language models (LLMs) have revolutionised NLP, yet their pedagogical value for low‐resource languages remains unclear. We present GRILE, the first open benchmark of 1 151 multiple‐choice questions harvested from Romanian high‐stakes exams (National Evaluation, Baccalaureate, university admissions). GRILE enables us to probe two complementary abilities of seven state‐of‐the‐art multilingual and Romanian‐specific LLMs: (i) selecting the correct answer, and (ii) producing linguistically faithful explanations. While Gemini 2·5 Pro reaches 83% accuracy, most open‐weight models stay below 65%, and 48% of their explanations contain factual or pedagogical flaws according to expert review. A detailed error analysis pinpoints systematic weaknesses in morphology and in applying the latest DOOM 3 orthographic norms. All data, code and a public web demo are released to catalyse future research. Our findings expose open challenges for trustworthy educational NLP in low‐resource settings and establish GRILE as a new test‐bed for controllable explanation generation and evaluation.</abstract>
      <url hash="0582fde5">2025.ranlp-1.39</url>
      <bibkey>dumitran-etal-2025-grile</bibkey>
    </paper>
    <paper id="40">
      <title><fixed-case>P</fixed-case>er<fixed-case>S</fixed-case>pa<fixed-case>C</fixed-case>or: Correcting Space and <fixed-case>ZWNJ</fixed-case> Errors in <fixed-case>P</fixed-case>ersian Text with Transformer Models</title>
      <author><first>Matin</first><last>Ebrahimkhani</last></author>
      <author><first>Ebrahim</first><last>Ansari</last></author>
      <pages>325–333</pages>
      <abstract>Precision and clarity are essential qualities of written texts; however, Persian script, rooted in Arabic script, presents unique challenges that can compromise readability and correctness. In particular, the use of space and half-space—specifically the Zero Width Non-Joiner (ZWNJ)—is essential for proper character separation in Persian typography. This research introduces four models for correcting spacing and ZWNJ errors at the character level, thereby improving both readability and textual accuracy. By fine-tuning BERT-based transformer models on Bijankhan and Peykare corpora—comprising over 12.7 million preprocessed and annotated words—and formulating the task as sequence labeling, the best model achieves a macro-average F1-score of 97.26%. An interactive corrector that incorporates user input further improves performance to a macro-average F1-score of 98.38%. These results demonstrate the effectiveness of advanced language models in enhancing Persian text quality and highlight their applicability to real-world natural language processing tasks.</abstract>
      <url hash="0d6f698f">2025.ranlp-1.40</url>
      <bibkey>ebrahimkhani-ansari-2025-perspacor</bibkey>
    </paper>
    <paper id="41">
      <title><fixed-case>R</fixed-case>eddit-<fixed-case>V</fixed-case>: A Virality Prediction Dataset and Zero-Shot Evaluation with Large Language Models</title>
      <author><first>Samir</first><last>El-amrany</last></author>
      <author><first>Matthias</first><last>R. Brust</last></author>
      <author><first>Salima</first><last>Lamsiyah</last></author>
      <author><first>Pascal</first><last>Bouvry</last></author>
      <pages>334–341</pages>
      <abstract>We present Reddit-V, a new dataset designed to advance research on social media virality prediction in natural language processing. The dataset consists of over 27,000 Reddit posts, each enriched with images, textual content, and pre-engagement metadata such as post titles, categories, sentiment scores, and posting times. As an initial benchmark, we evaluate several instruction-tuned large language models (LLMs) in a zero-shot setting, prompting them with post titles and metadata to predict post virality. We then fine-tune two multimodal models, CLIP and IDEFICS, to assess whether incorporating visual context enhances predictive performance. Our results show that zero-shot LLMs perform poorly, whereas the fine-tuned multimodal models achieve better performance. Specifically, CLIP outperforms the best-performing zero-shot LLM (CodeLLaMA) by 3%, while IDEFICS achieves an 7% improvement over the same baseline, highlighting the importance of visual features in virality prediction. We release the Reddit-V dataset and our evaluation results to facilitate further research on multimodal and text-based virality prediction. Our dataset and code will be made publicly available on Github</abstract>
      <url hash="a5366c0a">2025.ranlp-1.41</url>
      <bibkey>el-amrany-etal-2025-reddit</bibkey>
    </paper>
    <paper id="42">
      <title>Simplifications Are Absolutists: How Simplified Language Reduces Word Sense Awareness in <fixed-case>LLM</fixed-case>-Generated Definitions</title>
      <author><first>Lukas</first><last>Ellinger</last></author>
      <author><first>Miriam</first><last>Anschütz</last></author>
      <author><first>Georg</first><last>Groh</last></author>
      <pages>342–351</pages>
      <abstract>Large Language Models (LLMs) can provide accurate word definitions and explanations for any context. However, the scope of the definition changes for different target groups, like children or language learners. This is especially relevant for homonyms—words with multiple meanings—where oversimplification might risk information loss by omitting key senses, potentially misleading users who trust LLM outputs. We investigate how simplification impacts homonym definition quality across three target groups: Normal, Simple, and ELI5. Using two novel evaluation datasets spanning multiple languages, we test DeepSeek v3, Llama 4 Maverick, Qwen3-30B A3B, GPT-4o mini, and Llama 3.1 8B via LLM-as-Judge and human annotations. Our results show that simplification drastically degrades definition completeness by neglecting polysemy, increasing the risk of misunderstanding. Fine-tuning Llama 3.1 8B with Direct Preference Optimization substantially improves homonym response quality across all prompt types. These findings highlight the need to balance simplicity and completeness in educational NLP to ensure reliable, context-aware definitions for all learners.</abstract>
      <url hash="b151ed06">2025.ranlp-1.42</url>
      <bibkey>ellinger-etal-2025-simplifications</bibkey>
    </paper>
    <paper id="43">
      <title>Multi-<fixed-case>LLM</fixed-case> Text Summarization</title>
      <author><first>Jiangnan</first><last>Fang</last></author>
      <author><first>Cheng-Tse</first><last>Liu</last></author>
      <author><first>Jieun</first><last>Kim</last></author>
      <author><first>Yash</first><last>Bhedaru</last></author>
      <author><first>Ethan</first><last>Liu</last></author>
      <author><first>Nikhil</first><last>Singh</last></author>
      <author><first>Nedim</first><last>Lipka</last></author>
      <author><first>Puneet</first><last>Mathur</last></author>
      <author><first>Nesreen K.</first><last>Ahmed</last></author>
      <author><first>Franck</first><last>Dernoncourt</last></author>
      <author><first>Ryan</first><last>Rossi</last></author>
      <author><first>Hanieh</first><last>Deilamsalehy</last></author>
      <pages>352–362</pages>
      <abstract>In this work, we propose a Multi-LLM summarization framework, and investigate two different multi-LLM strategies including centralized and decentralized. Our multi-LLM summarization framework has two fundamentally important steps at each round of conversation: generation and evaluation. These steps are different depending on whether our multi-LLM decentralized summarization is used or centralized. In both our multi-LLM decentralized and centralized strategies, we have k different LLMs that generate diverse summaries of the text. However, during evaluation, our multi-LLM centralized summarization approach leverages a single LLM to evaluate the summaries and select the best one whereas k LLMs are used for decentralized multi-LLM summarization. Overall, we find that our multi-LLM summarization approaches significantly outperform the baselines that leverage only a single LLM by up to 3x. These results indicate the effectiveness of multi-LLM approaches for summarization.</abstract>
      <url hash="f90256dc">2025.ranlp-1.43</url>
      <bibkey>fang-etal-2025-multi</bibkey>
    </paper>
    <paper id="44">
      <title><fixed-case>EDA</fixed-case>udio: Easy Data Augmentation for Dialectal Audio</title>
      <author><first>Lea</first><last>Fischbach</last></author>
      <author><first>Akbar</first><last>Karimi</last></author>
      <author><first>Alfred</first><last>Lameli</last></author>
      <author><first>Lucie</first><last>Flek</last></author>
      <pages>363–368</pages>
      <abstract>We investigate lightweight and easily applicable data augmentation techniques for dialectal audio classification. We evaluate four main methods, namely shifting pitch, interval removal, background noise insertion and interval swap as well as several subvariants on recordings from 20 German dialects. Each main method is tested across multiple hyperparameter combinations, inlcuding augmentation length, coverage ratio and number of augmentations per original sample. Our results show that frequency-based techniques, particularly frequency masking, consistently yield performance improvements, while others such as time masking or speaker-based insertion can negatively affect the results. Our comparative analysis identifies which augmentations are most effective under realistic conditions, offering simple and efficient strategies to improve dialectal speech classification.</abstract>
      <url hash="2903eb2c">2025.ranlp-1.44</url>
      <bibkey>fischbach-etal-2025-edaudio</bibkey>
    </paper>
    <paper id="45">
      <title>Authorship Verification Using Cloze Test with Large Language Models</title>
      <author><first>Tomáš</first><last>Foltýnek</last></author>
      <author><first>Tomáš</first><last>Kancko</last></author>
      <author id="pavel-rychly"><first>Pavel</first><last>Rychly</last></author>
      <pages>369–377</pages>
      <abstract>Assignment outsourcing, also known as contract cheating, occurs when a student outsources an assessment task or a part of it to a third party. It has been one of the most pressing ethical issues in university education and was further exacerbated by the wide availability of chatbots based on large language models. We propose a method that has the potential to verify the authorship of a document in question by filling in a cloze test. A close test with 10 items selected by our method can be used as a classifier with an accuracy of 0.988 and a <tex-math>F_1</tex-math> score of 0.937. We also describe a general method for building a cloze-test-based classifier when the probability of authors and non-authors correctly filling in cloze items is known.</abstract>
      <url hash="2d771cec">2025.ranlp-1.45</url>
      <bibkey>foltynek-etal-2025-authorship</bibkey>
    </paper>
    <paper id="46">
      <title>A Culturally-Rich <fixed-case>R</fixed-case>omanian <fixed-case>NLP</fixed-case> Dataset from “Who Wants to Be a Millionaire?” Videos</title>
      <author><first>Alexandru</first><last>Ganea</last></author>
      <author><first>Antonia-Adelina</first><last>Popovici</last></author>
      <author><first>Marius</first><last>Dumitran</last></author>
      <pages>378–387</pages>
      <abstract>Large Language Models (LLMs) demonstrate varying performance across languages and cultural contexts. This study introduces a novel, culturally-rich, multilingual dataset derived from video recordings of the Romanian game show “Who Wants to Be a Millionaire?” (Vrei să fii Milionar?). We employed an innovative process combining optical character recognition (OCR), automated text extraction, and manual verification to collect question-answer pairs, enriching them with metadata including question domain (e.g., biology, history), cultural relevance (Romanian-specific vs. international), and difficulty. Benchmarking state-of-the-art LLMs, including Romanian-adapted models, on this dataset revealed significant performance disparities: models consistently achieve higher accuracy (80-95%) on international questions compared to Romanian-specific cultural questions (50-75%). We further investigate these differences through experiments involving machine translation of Romanian questions into English and cross-lingual tests using a comparable dataset in French. Our findings underscore the impact of cultural context and data source on LLM performance and offer practical insights for building robust, culturally-aware multilingual NLP systems, especially in educational domains. The dataset is publicly available.</abstract>
      <url hash="88db3af7">2025.ranlp-1.46</url>
      <bibkey>ganea-etal-2025-culturally</bibkey>
    </paper>
    <paper id="47">
      <title>Graph-based <fixed-case>RAG</fixed-case> for Low-Resource <fixed-case>A</fixed-case>romanian–<fixed-case>R</fixed-case>omanian Translation</title>
      <author><first>Laurentiu G.</first><last>Ghetoiu</last></author>
      <author><first>Sergiu</first><last>Nisioi</last></author>
      <pages>388–394</pages>
      <abstract>Aromanian, a linguistically and culturally significant yet low-resource Romance language, poses substantial challenges in computational linguistic research due to its limited NLP resources and non-standardized orthography. In this paper, we present an experimental study aimed at translating Aromanian texts into Romanian using a variety of modern NLP methodologies. We leverage two key resources: a parallel corpus consisting of approximately 3,000 sentence-aligned short stories and a dictionary of over 28,000 Aromanian-Romanian word pairs. Our approaches include Retrieval-Augmented Generation (RAG) supported by a graph-based alignment database, fine-tuning multilingual transformer models (specifically Meta’s NLLB), and parameter-efficient fine-tuning techniques such as LoRA applied to LLaMA-derived models. Evaluations using standard metrics (BLEU, chrF) demonstrate varied effectiveness across these methodologies, highlighting the strong performance of NLLB for general translation tasks, while RAG excels in translating familiar content. Our findings underline the complexities inherent in low-resource language translation and provide valuable insights into effective digital preservation and NLP adaptation strategies for underrepresented languages.</abstract>
      <url hash="d647fa29">2025.ranlp-1.47</url>
      <bibkey>ghetoiu-nisioi-2025-graph</bibkey>
    </paper>
    <paper id="48">
      <title>Differential Robustness in Transformer Language Models: Empirical Evaluation under Adversarial Text Attacks</title>
      <author><first>Taniya</first><last>Gidatkar</last></author>
      <author><first>Oluwaseun</first><last>Ajao</last></author>
      <author><first>Matthew</first><last>Shardlow</last></author>
      <pages>395–402</pages>
      <abstract>This study evaluates the resilience of large language models (LLMs) against adversarial attacks, specifically focusing on Flan-T5, BERT, and RoBERTa-Base. Using systematically designed adversarial tests through TextFooler and BERTAttack, we found significant variations in model robustness. RoBERTa-Base and Flan-T5 demonstrated remarkable resilience, maintaining accuracy even when subjected to sophisticated attacks, with attack success rates of 0%. In contrast, BERT-Base showed considerable vulnerability, with TextFooler achieving a 93.75% success rate in reducing model accuracy from 48% to just 3%. Our research reveals that while certain LLMs have developed effective defensive mechanisms, these safeguards often require substantial computational resources. This study contributes to the understanding of LLM security by identifying existing strengths and weaknesses in current safeguarding approaches and proposes practical recommendations for developing more efficient and effective defensive strategies</abstract>
      <url hash="c61f965d">2025.ranlp-1.48</url>
      <bibkey>gidatkar-etal-2025-differential</bibkey>
    </paper>
    <paper id="49">
      <title>An Annotation Scheme for Factuality and Its Application to Parliamentary Proceedings</title>
      <author><first>Gili</first><last>Goldin</last></author>
      <author><first>Shira</first><last>Wigderson</last></author>
      <author><first>Ella</first><last>Rabinovich</last></author>
      <author><first>Shuly</first><last>Wintner</last></author>
      <pages>403–412</pages>
      <abstract>Factuality assesses the extent to which a language utterance relates to real-world information; it determines whether utterances correspond to facts, possibilities, or imaginary situations, and as such, it is instrumental for fact checking. Factuality is a complex notion that relies on multiple linguistic signals, and has been studied in various disciplines. We present a complex, multi-faceted annotation scheme of factuality that combines concepts from a variety of previous works. We developed the scheme for Hebrew, but we trust that it can be adapted to other languages. We also present a set of almost 5,000 sentences in the domain of parliamentary discourse that we manually annotated according to this scheme. We report on inter-annotator agreement, and experiment with various approaches to automatically predict (some features of) the scheme, in order to extend the annotation to a large corpus.</abstract>
      <url hash="35e85e38">2025.ranlp-1.49</url>
      <bibkey>goldin-etal-2025-annotation</bibkey>
    </paper>
    <paper id="50">
      <title>Can We Predict Innovation? Narrow Experts versus Competent Generalists</title>
      <author><first>Amir</first><last>Hazem</last></author>
      <author><first>Motohashi</first><last>Kazuyuki</last></author>
      <pages>413–422</pages>
      <abstract>In this paper, we investigate the role of large language models in predicting innovation. We contrast two main paradigms: i) narrow experts: which consists of supervised and semi-supervised models trained or fine-tuned on a specific task and ii) competent generalists: which consists of large language models with zero-shot and few-shots learning. We define the task of innovation modeling and present the first attempt to understand the transformation from research to innovation. We focus on product innovation which can be defined as the process of transforming technology to a product or service and bring it to the market. Our extensive empirical evaluation shows that most existing pretrained models are not suited and perform poorly on the innovation modeling task. We also show that injecting research information helps improving the alignment from technology to the market. Finally, we propose a new methodology and fine-tuning strategies that achieve significant performance boosts over the baselines.</abstract>
      <url hash="684be737">2025.ranlp-1.50</url>
      <bibkey>hazem-kazuyuki-2025-predict</bibkey>
    </paper>
    <paper id="51">
      <title><fixed-case>A</fixed-case>rabic to <fixed-case>R</fixed-case>omanian Machine Translation: A Case Study on Distant Language Pairs</title>
      <author><first>Ioan Alexandru</first><last>Hirica</last></author>
      <author><first>Stefana Arina</first><last>Tabusca</last></author>
      <author><first>Sergiu</first><last>Nisioi</last></author>
      <pages>423–432</pages>
      <abstract>This paper investigates machine translation between two linguistically distant languages, Arabic and Romanian, with a focus on translating from Arabic to Romanian. Dataset cleaning techniques are addressed, offering insights on the impact of translation for a language pair with limited resources. Using publicly available corpora (e.g., OPUS) and manually translated diplomatic texts, filtering methods are applied, such as duplicate removal, embedding similarity analysis (LEALLA), and Large Language Model (LLM)-based validation (Gemini-flash-002). Transformer models are trained and evaluated with diverse preprocessing pipelines that incorporate subword tokenization. Additionally, the performance of a fine-tuned LLM is assessed for this task and is compared to their pre-trained counterparts. Despite computational limitations, the results emphasize the importance of targeted preprocessing and model adaptation in improving Arabic-Romanian translation quality.</abstract>
      <url hash="fb8fcf54">2025.ranlp-1.51</url>
      <bibkey>hirica-etal-2025-arabic</bibkey>
    </paper>
    <paper id="52">
      <title><fixed-case>B</fixed-case>i<fixed-case>GCAT</fixed-case>: A Graph-Based Representation Learning Model with <fixed-case>LLM</fixed-case> Embeddings for Named Entity Recognition</title>
      <author><first>Md. Akram</first><last>Hossain</last></author>
      <author><first>Abdul</first><last>Aziz</last></author>
      <author><first>Muhammad Anwarul</first><last>Azim</last></author>
      <author><first>Abu Nowshed</first><last>Chy</last></author>
      <author><first>Md Zia</first><last>Ullah</last></author>
      <author><first>Mohammad Khairul</first><last>Islam</last></author>
      <pages>433–440</pages>
      <abstract>Named entity recognition from financial text is challenging because of word ambiguity, huge quantity of unknown corporation names, and word abbreviation compared to nonfinancial text. However, models often treat named entities in a linear sequence fashion, which might obscure the model’s ability to capture complex hierarchical relationships among the entities. In this paper, we proposed a novel named entity recognition model BiGCAT, which integrates large language model (LLM) embeddings with graph-based representation where the contextual information captured by the language model and graph representation learning can complement each other. The method builds a spanning graph with nodes representing word spans and edges weighted by LLM embeddings, optimized using a combination of graph neural networks, specifically a graph-convolutional network (GCN) and a graph-attention network (GAT). This approach effectively captures the hierarchical dependencies among the spans. Our proposed model outperformed the state-of-the-art by 10% and 18% on the two publicly available datasets FiNER-ORD and FIN, respectively, in terms of weighted F1 score. The code is available at: https://github.com/Akram1871/BiGCAT-RANLP-2025.</abstract>
      <url hash="a0ffff34">2025.ranlp-1.52</url>
      <bibkey>hossain-etal-2025-bigcat</bibkey>
    </paper>
    <paper id="53">
      <title>Measuring How (Not Just Whether) <fixed-case>VLM</fixed-case>s Build Common Ground</title>
      <author><first>Saki</first><last>Imai</last></author>
      <author><first>Mert</first><last>Inan</last></author>
      <author><first>Anthony B.</first><last>Sicilia</last></author>
      <author><first>Malihe</first><last>Alikhani</last></author>
      <pages>441–451</pages>
      <abstract>Large vision language models (VLMs) increasingly claim reasoning skills, yet current benchmarks evaluate them in single-turn or question answering settings. However, grounding is an interactive process in which people gradually develop shared understanding through ongoing communication. We introduce a four-metric suite (grounding efficiency, content alignment, lexical adaptation, and human-likeness) to systematically evaluate VLM performance in interactive grounding contexts. We deploy the suite on 150 self-play sessions of interactive referential games between three proprietary VLMs and compare them with human dyads. All three models diverge from human patterns on at least three metrics, while GPT4o-mini is the closest overall. We find that (i) task success scores do not indicate successful grounding and (ii) high image-utterance alignment does not necessarily predict task success. Our metric suite and findings offer a framework for future research on VLM grounding.</abstract>
      <url hash="d0a3d26f">2025.ranlp-1.53</url>
      <bibkey>imai-etal-2025-measuring</bibkey>
    </paper>
    <paper id="54">
      <title><fixed-case>S</fixed-case>i<fixed-case>LVERS</fixed-case>core: Semantically-Aware Embeddings for Sign Language Generation Evaluation</title>
      <author><first>Saki</first><last>Imai</last></author>
      <author><first>Mert</first><last>Inan</last></author>
      <author><first>Anthony B.</first><last>Sicilia</last></author>
      <author><first>Malihe</first><last>Alikhani</last></author>
      <pages>452–461</pages>
      <abstract>Evaluating sign language generation is often done through back-translation, where generated signs are first recognized back to text and then compared to a reference using text-based metrics. However, this two-step evaluation pipeline introduces ambiguity: it not only fails to capture the multimodal nature of sign language—such as facial expressions, spatial grammar, and prosody—but also makes it hard to pinpoint whether evaluation errors come from sign generation model or the translation system used to assess it. In this work, we propose SiLVERScore, a novel semantically-aware embedding-based evaluation metric that assesses sign language generation in a joint embedding space. Our contributions include: (1) identifying limitations of existing metrics, (2) introducing SiLVERScore for semantically-aware evaluation, (3) demonstrating its robustness to semantic and prosodic variations, and (4) exploring generalization challenges across datasets. On PHOENIX-14T and CSL-Daily datasets, SiLVERScore achieves near-perfect discrimination between correct and random pairs (ROC AUC = 0.99, overlap &lt; 7%), substantially outperforming traditional metrics.</abstract>
      <url hash="5b11011e">2025.ranlp-1.54</url>
      <bibkey>imai-etal-2025-silverscore</bibkey>
    </paper>
    <paper id="55">
      <title>Alignment of Historical Manuscript Transcriptions and Translations</title>
      <author><first>Maarten</first><last>Janssen</last></author>
      <author><first>Piroska</first><last>Lendvai</last></author>
      <author><first>Anna</first><last>Jouravel</last></author>
      <pages>462–470</pages>
      <abstract>Using an XML-based framework, we compiled a gold standard for alignments in five primary as well as derived texts, related to <i>De Lepra ad Sistelium</i> by Methodius Olympius. These comprise diplomatic transcripts, editions, and translations of this work, involving both historical and modern languages. Using the TEITOK corpus platform, we created sentence-level gold standard alignments for our parallel resp. comparable texts, and applied both neural and classical alignment methods (SentenceBERT, Hunalign, Awesome-Align). We evaluated the methods in terms of Alignment Error Rate. We show that for alignment of our historical texts, Hunalign performs better than deep learning based methods.</abstract>
      <url hash="829e9614">2025.ranlp-1.55</url>
      <bibkey>janssen-etal-2025-alignment</bibkey>
    </paper>
    <paper id="56">
      <title>Zero-shot <fixed-case>OCR</fixed-case> Accuracy of Low-Resourced Languages: A Comparative Analysis on <fixed-case>S</fixed-case>inhala and <fixed-case>T</fixed-case>amil</title>
      <author><first>Nevidu</first><last>Jayatilleke</last></author>
      <author><first>Nisansa</first><last>de Silva</last></author>
      <pages>471–480</pages>
      <abstract>Solving the problem of Optical Character Recognition (OCR) on printed text for Latin and its derivative scripts can now be considered settled due to the volumes of research done on English and other High-Resourced Languages (HRL). However, for Low-Resourced Languages (LRL) that use unique scripts, it remains an open problem. This study presents a comparative analysis of the zero-shot performance of six distinct OCR engines on two LRLs: Sinhala and Tamil. The selected engines include both commercial and open-source systems, aiming to evaluate the strengths of each category. The Cloud Vision API, Surya, Document AI, and Tesseract were evaluated for both Sinhala and Tamil, while Subasa OCR and EasyOCR were examined for only one language due to their limitations. The performance of these systems was rigorously analysed using five measurement techniques to assess accuracy at both the character and word levels. According to the findings, Surya delivered the best performance for Sinhala across all metrics, with a WER of 2.61%. Conversely, Document AI excelled across all metrics for Tamil, highlighted by a very low CER of 0.78%. In addition to the above analysis, we also introduce a novel synthetic Tamil OCR benchmarking dataset.</abstract>
      <url hash="3850457c">2025.ranlp-1.56</url>
      <bibkey>jayatilleke-de-silva-2025-zero</bibkey>
    </paper>
    <paper id="57">
      <title>Detecting Gender Stereotypical Language Using Model-agnostic and Model-specific Explanations</title>
      <author><first>Manuela Nayantara</first><last>Jeyaraj</last></author>
      <author><first>Sarah Jane</first><last>Delany</last></author>
      <pages>481–490</pages>
      <abstract>AI models learn gender-stereotypical language from human data. So, understanding how well different explanation techniques capture diverse language features that suggest gender stereotypes in text can be useful in identifying stereotypes that could potentially lead to gender bias. The influential words identified by four explanation techniques (LIME, SHAP, Integrated Gradients (IG) and Attention) in a gender stereotype detection task were compared with words annotated by human evaluators. All techniques emphasized adjectives and verbs related to characteristic traits and gender roles as the most influential words. LIME was best at detecting explicitly gendered words, while SHAP, IG and Attention showed stronger overall alignment and considerable overlap. A combination of these techniques, combining the strengths of model-agnostic and model-specific explanations, performs better at capturing gender-stereotypical language. Extending to hate speech and sentiment prediction tasks, annotator agreement suggests these tasks to be more subjective while explanation techniques can better capture explicit markers in hate speech than the more nuanced gender stereotypes. This research highlights the strengths of different explanation techniques in capturing subjective gender stereotype language in text.</abstract>
      <url hash="c93fb4d1">2025.ranlp-1.57</url>
      <bibkey>jeyaraj-delany-2025-detecting</bibkey>
    </paper>
    <paper id="58">
      <title>Reversing Causal Assumptions: Explainability in Online Sports Dialogues</title>
      <author><first>Asteria</first><last>Kaeberlein</last></author>
      <author><first>Malihe</first><last>Alikhani</last></author>
      <pages>491–500</pages>
      <abstract>Prior XAI research often assumes inputs must be “causes” and outputs must be “effects”, severely limiting applicability to analyzing behaviors that emerge as reactions or consequences. Many linguistic tasks, such as dialogues and conversations, involve such behaviors. To address this, we propose that the assumed causality from inputs to outputs can be reversed and still remain valid by using outputs that cause changes in features. We show how this enables analysis of complex feature sets through simpler metrics, propose a framework that is generalizable to most linguistic tasks, and highlight best practices for applying our framework. By training a predictive model from complex effects to simple causes, we apply feature attributions to estimate how the inputs change with the outputs. We demonstrate an application of this by studying sports fans’ comments made during a game and compare those comments to a simpler metric, win probability. We also expand on a prior study of intergroup bias, demonstrating how our framework can uncover behaviors that other XAI methods may overlook. We discuss the implications of these findings for advancing interpretability in computational linguistics and improving data-driven-decision-making in social contexts.</abstract>
      <url hash="e7a9726a">2025.ranlp-1.58</url>
      <bibkey>kaeberlein-alikhani-2025-reversing</bibkey>
    </paper>
    <paper id="59">
      <title>How <fixed-case>LLM</fixed-case>s Influence Perceived Bias in Journalism</title>
      <author><first>Asteria</first><last>Kaeberlein</last></author>
      <author><first>Malihe</first><last>Alikhani</last></author>
      <pages>501–510</pages>
      <abstract>As the use of generative AI tools in journalistic writing becomes more common, reporters have expressed growing concerns about how it may introduce bias to their works. This paper investigates how the integration of large language models (LLMs) into journalistic writing, both as editors and independent ‘authors’, can alter user perception of bias in media. We show novel insights into how human perception of media bias differs from automatic evaluations. Through human evaluations comparing original human-authored articles, AI-edited articles, and AI-generated articles, we show that while LLMs rarely introduce new bias and often trend towards neutrality, this supposedly ‘safe’ behavior can have harmful impacts. This is most observable in sensitive human rights contexts, where the AI’s neutral and measured tone can reduce the representation of relevant voices and present misinformation in a more convincing manner. Furthermore, we demonstrate the existence of previously unidentified patterns that existing automated bias detection methods fail to accurately capture. We underscore the critical need for human-centered evaluation frameworks in AI-assisted journalism by introducing human evaluations and contrasting against a state-of-the-art automated bias detection system.</abstract>
      <url hash="329da0f4">2025.ranlp-1.59</url>
      <bibkey>kaeberlein-alikhani-2025-llms</bibkey>
    </paper>
    <paper id="60">
      <title>Prompting Techniques for Reducing Social Bias in <fixed-case>LLM</fixed-case>s through System 1 and System 2 Cognitive Processes</title>
      <author><first>Mahammed</first><last>Kamruzzaman</last></author>
      <author><first>Gene Louis</first><last>Kim</last></author>
      <pages>511–520</pages>
      <abstract>Dual process theory posits that human cognition arises via two systems. System 1, which is a quick, emotional, and intuitive process, which is subject to cognitive biases, and System 2, is a slow, onerous, and deliberate process. Prior research in LLMs found that using chain-ofthought (CoT) prompting in LLMs, which has been often compared to System 2 reasoning, can lead to reduced gender bias. Along these lines, we investigate the relationship between bias, CoT prompting, a direct debiasing, and dual process theory modeling in LLMs. We compare zero-shot CoT, debiasing, and dual process theory-based prompting strategies on two bias datasets spanning nine different social bias categories. We incorporate human and machine personas to determine whether LLM modeling of the effects of dual process theory exist independent of explicit persona models or are tied to the LLM’s modeling of human-like generation. We find that a human persona, debiasing, System 2, and CoT prompting all tend to reduce social biases in LLMs, though the best combination of features depends on the exact model and bias category—resulting in up to a 33 percent drop in stereotypical judgments by an LLM.</abstract>
      <url hash="0359b6cb">2025.ranlp-1.60</url>
      <bibkey>kamruzzaman-kim-2025-prompting</bibkey>
    </paper>
    <paper id="61">
      <title>Performance Gaps in Acted and Naturalistic Speech: Insights from Speech Emotion Recognition Strategies on Customer Service Calls</title>
      <author><first>Lily</first><last>Kawaoto</last></author>
      <author><first>Hita</first><last>Gupta</last></author>
      <author><first>Ning</first><last>Yu</last></author>
      <author><first>Daniel</first><last>Dakota</last></author>
      <pages>521–530</pages>
      <abstract>Current research in speech emotion recognition (SER) often uses speech data produced by actors which does not always best represent naturalistic speech. This can lead to challenges when applying models trained on such data sources to real-world data. We investigate the application of SER models developed on acted data and more naturalistic podcasts to service call data, with a particular focus on anger detection. Our results indicate that while there is noticeable performance degradation of models trained on acted data to the naturalistic data, weighted multimodal models developed on existing SER datasets–both acted and natural–show promise, but are limited in ability to recognize emotions that do not discernibly cluster.</abstract>
      <url hash="2e27cb8b">2025.ranlp-1.61</url>
      <bibkey>kawaoto-etal-2025-performance</bibkey>
    </paper>
    <paper id="62">
      <title>Synthetic vs. Gold: The Role of <fixed-case>LLM</fixed-case> Generated Labels and Data in Cyberbullying Detection</title>
      <author><first>Arefeh</first><last>Kazemi</last></author>
      <author><first>Sri Balaaji</first><last>Natarajan Kalaivendan</last></author>
      <author><first>Joachim</first><last>Wagner</last></author>
      <author><first>Hamza</first><last>Qadeer</last></author>
      <author><first>Kanishk</first><last>Verma</last></author>
      <author><first>Brian</first><last>Davis</last></author>
      <pages>531–540</pages>
      <abstract>Cyberbullying (CB) presents a pressing threat, especially to children, underscoring the urgent need for robust detection systems to ensure online safety. While large-scale datasets on online abuse exist, there remains a significant gap in labeled data that specifically reflects the language and communication styles used by children. The acquisition of such data from vulnerable populations, such as children, is challenging due to ethical, legal and technical barriers. Moreover, annotating these datasets relies heavily on human effort, which not only strains resources but also raises significant concerns due to annotators’ exposure to harmful content. In this paper, we address these challenges by leveraging Large Language Models (LLMs) to generate synthetic data and labels. Our experiments demonstrate that synthetic data enables BERT-based CB classifiers to achieve performance close to that of those trained on fully authentic datasets (75.8% vs. 81.5% accuracy). Additionally, LLMs can effectively label authentic yet unlabeled data, allowing BERT classifiers to attain a comparable performance level (79.1% vs. 81.5% accuracy). These results highlight the potential of LLMs as a scalable, ethical, and cost-effective solution for generating data for CB detection.</abstract>
      <url hash="b501a4aa">2025.ranlp-1.62</url>
      <bibkey>kazemi-etal-2025-synthetic</bibkey>
    </paper>
    <paper id="63">
      <title><fixed-case>F</fixed-case>ree<fixed-case>T</fixed-case>xt: Analyse and Visualise Multilingual Qualitative Survey Data for Cultural Heritage Sites</title>
      <author><first>Nouran</first><last>Khallaf</last></author>
      <author><first>Ignatius</first><last>Ezeani</last></author>
      <author><first>Dawn</first><last>Knight</last></author>
      <author><first>Paul</first><last>Rayson</last></author>
      <author><first>Mo</first><last>El-Haj</last></author>
      <author><first>John</first><last>Vidler</last></author>
      <author><first>James</first><last>Davies</last></author>
      <author><first>Fernando</first><last>Alva-Manchego</last></author>
      <pages>541–545</pages>
      <abstract>We introduce FreeTxt, a free and open-source web-based tool designed to support the analysis and visualisation of multilingual qualitative survey data, with a focus on low-resource languages. Developed in collaboration with stakeholders, FreeTxt integrates established techniques from corpus linguistics with modern natural language processing methods in an intuitive interface accessible to non-specialists. The tool currently supports bilingual processing and visualisation of English and Welsh responses, with ongoing extensions to other languages such as Vietnamese. Key functionalities include semantic tagging via PyMUSAS, multilingual sentiment analysis, keyword and collocation visualisation, and extractive summarisation. User evaluations with cultural heritage institutions demonstrate the system’s utility and potential for broader impact.</abstract>
      <url hash="a543fed1">2025.ranlp-1.63</url>
      <bibkey>khallaf-etal-2025-freetxt</bibkey>
    </paper>
    <paper id="64">
      <title><fixed-case>GPT</fixed-case>-Based Lexical Simplification for Multi-Word Expressions Using Prompt Engineering</title>
      <author><first>Sardar Khan</first><last>Khayamkhani</last></author>
      <author><first>Matthew</first><last>Shardlow</last></author>
      <pages>546–556</pages>
      <abstract>Multiword Lexical Simplification (MWLS) is the task of replacing a complex phrase in a sentence with a simpler alternative. Whereas previous approaches to MWLS made use of the BERT language model, we make use of the Generative Pre-trained Transformer architecture. Our approach employs Large Language Models in an auto-regressive format, making use of prompt engineering and few-shot learning to develop new strategies for the MWLS task. We experiment with several GPT-based models and differing experimental settings including varying the number of requested examples, changing the base model type, adapting the prompt and zero-shot, one-shot and k-shot in-context learning. We show that a GPT-4o model with k-shot in-context learning (k=6) demonstrates state-of-the-art performance for the MWLS1 dataset with NDCG=0.3143, PREC@5=0.1048, beating the previous Bert-based approach by a wide margin on several metrics and consistently across subsets. Our findings indicate that GPT-based models are superior to BERT-based models for the MWLS task.</abstract>
      <url hash="e97c10af">2025.ranlp-1.64</url>
      <bibkey>khayamkhani-shardlow-2025-gpt</bibkey>
    </paper>
    <paper id="65">
      <title>Instruction-Tuning <fixed-case>LL</fixed-case>a<fixed-case>MA</fixed-case> for Synthetic Medical Note Generation in <fixed-case>S</fixed-case>wedish and <fixed-case>E</fixed-case>nglish</title>
      <author><first>Lotta</first><last>Kiefer</last></author>
      <author id="jesujoba-alabi"><first>Jesujoba</first><last>Alabi</last></author>
      <author><first>Thomas</first><last>Vakili</last></author>
      <author><first>Hercules</first><last>Dalianis</last></author>
      <author><first>Dietrich</first><last>Klakow</last></author>
      <pages>557–566</pages>
      <abstract>The increasing capabilities of large language models (LLMs) have unlocked transformative potential for medical applications, but privacy constraints limit access to high-quality training data from electronic health records (EHRs). In response, we propose a framework to generate synthetic EHRs by instruction-tuning an LLM using descriptions of diagnosis codes. We show that this framework overcomes problems of prior approaches, such as diversity reduction and medical incoherence, while maintaining strong privacy protections. Utility was measured by training models to predict diagnosis codes for EHRs. Real data still has higher utility, but synthetic data approaches real data results with increasing dataset size. The differences in utility were most likely due to noise in the synthetic data. A user study involving medical professionals confirmed no significant loss in readability or medical coherence compared to the real HRs, even though inter-annotator agreement is low. These findings establish synthetic EHRs as a viable alternative for privacypreserving and scalable clinical NLP applications. We release our code on GitHub.</abstract>
      <url hash="48795782">2025.ranlp-1.65</url>
      <bibkey>kiefer-etal-2025-instruction</bibkey>
    </paper>
    <paper id="66">
      <title>Output Trend Analysis in Semantic Classification of Katakana Words Using a Large Language Model</title>
      <author><first>Kazuki</first><last>Kodaki</last></author>
      <author><first>Minoru</first><last>Sasaki</last></author>
      <pages>567–571</pages>
      <abstract>In semantic classification of katakana words using a large language model (LLM), semantic divergences from the meanings of original English words such as Wasei-Eigo(Japanese-made English) may affect the accuracy of the model. In order to accurately capture the meaning of foreign words, we fine-tuned the LLM using data extracted from the BCCWJ(Balanced Corpus of Contemporary Written Japanese), analyzed the current accuracy and output trend of semantic classification for katakana words, and explored ways to improve the accuracy. The results of several experiments showed that fine-tuning was not effective for zero-shot learning, but in contrast, fine-tuning improved accuracy by about 10% for few-shot learning. Further analysis of the visualized data suggests trends related to words and meanings that the model struggles to classify correctly.</abstract>
      <url hash="ab5242bb">2025.ranlp-1.66</url>
      <bibkey>kodaki-sasaki-2025-output</bibkey>
    </paper>
    <paper id="67">
      <title>Domain Knowledge Distillation for Multilingual Sentence Encoders in Cross-lingual Sentence Similarity Estimation</title>
      <author><first>Risa</first><last>Kondo</last></author>
      <author><first>Hiroki</first><last>Yamauchi</last></author>
      <author><first>Tomoyuki</first><last>Kajiwara</last></author>
      <author><first>Marie</first><last>Katsurai</last></author>
      <author><first>Takashi</first><last>Ninomiya</last></author>
      <pages>572–577</pages>
      <abstract>We propose a domain adaptation method for multilingual sentence encoders. In domains requiring a high level of expertise, such as medical and academic, domain-specific pre-trained models have been released in each language. However, there is no its multilingual version, which prevents application to cross-lingual information retrieval. Obviously, multilingual pre-training with developing in-domain corpora in each language is costly. Therefore, we efficiently develop domain-specific cross-lingual sentence encoders from existing multilingual sentence encoders and domain-specific monolingual sentence encoders in each language. Experimental results on translation ranking in three language pairs with different domains reveal the effectiveness of the proposed method compared to baselines without domain adaptation and existing domain adaptation methods.</abstract>
      <url hash="1fb6c4b9">2025.ranlp-1.67</url>
      <bibkey>kondo-etal-2025-domain</bibkey>
    </paper>
    <paper id="68">
      <title>Am <fixed-case>I</fixed-case> Blue or Is My Hobby Counting the Teardrops? Expression Leakage in Large Language Models as a Symptom of Irrelevancy Disruption</title>
      <author><first>Berkay</first><last>Kopru</last></author>
      <author><first>Mehrzad</first><last>Mashal</last></author>
      <author><first>Yigit</first><last>Gurses</last></author>
      <author><first>Akos</first><last>Kadar</last></author>
      <author><first>Maximilian</first><last>Schmitt</last></author>
      <author><first>Ditty</first><last>Mathew</last></author>
      <author><first>Felix</first><last>Burkhardt</last></author>
      <author><first>Florian</first><last>Eyben</last></author>
      <author><first>Björn W.</first><last>Schuller</last></author>
      <pages>578–586</pages>
      <abstract>Large language models (LLMs) have advanced natural language processing (NLP) skills such as through next-token prediction and self-attention, but their ability to integrate broad context also makes them prone to incorporating irrelevant information. Prior work has focused on semantic leakage—bias introduced by semantically irrelevant context.In this paper, we introduce expression leakage, a novel phenomenon where LLMs systematically generate sentimentally charged expressions that are semantically unrelated to the input context. To analyse the expression leakage, we collect a benchmark dataset along with a scheme to automatically generate a dataset from free-form text from common-crawl. In addition, we propose an automatic evaluation pipeline that correlates well with human judgment, which accelerates the benchmarking by decoupling from the need of annotation for each analysed model. Our experiments show that, as the model scales in the parameter space, the expression leakage reduces within the same LLM family. On the other hand, we demonstrate that expression leakage mitigation requires specific care during the model building process, and cannot be mitigated by prompting. In addition, our experiments indicate that, when negative sentiment is injected in the prompt, it disrupts the generation process more than the positive sentiment, causing a higher expression leakage rate.</abstract>
      <url hash="0d5ccad2">2025.ranlp-1.68</url>
      <bibkey>kopru-etal-2025-blue</bibkey>
    </paper>
    <paper id="69">
      <title>Fusion of Object-Centric and Linguistic Features for Domain-Adapted Multimodal Learning</title>
      <author><first>Jordan Konstantinov</first><last>Kralev</last></author>
      <pages>587–594</pages>
      <abstract>Modern multimodal systems often struggle to link domain-specific visual content with textual descriptions, especially when object recognition is limited to general categories (e.g. COCO classes) and lacks customised adaptation to language models. In this paper, we present a novel framework that integrates a domain-specific adapted Detectron2 model into predefined models via a trainable projection layer, enabling precise crossmodal adaptation for specialised domains. Our approach extends Detectron2’s recognition capabilities to new categories by fine-tuning on multi-domain datasets, while a lightweight linear projection layer maps region-based visual features to the model’s embedding space without completely retraining the model. We evaluated the framework for domain-specific image captioning. The presented approach provides a scalable design for combining domain-specific visual recognition with language inference, with applications in domains that require fine-grained multimodal understanding.</abstract>
      <url hash="d9d030cb">2025.ranlp-1.69</url>
      <bibkey>kralev-2025-fusion</bibkey>
    </paper>
    <paper id="70">
      <title>Multi-Agent Reinforcement Learning for Interactive Code Debugging with Human Feedback and Memory</title>
      <author><first>Anjana</first><last>Krishnamoorthy</last></author>
      <author><first>Kartik</first><last>Ivatury</last></author>
      <author><first>Benyamin</first><last>Ahmadnia</last></author>
      <pages>595–603</pages>
      <abstract>This paper introduces an interactive Python debugging framework that combines multi-agent reinforcement learning, Natural Language Processing (NLP), and long-term memory. Two Proximal Policy Optimization (PPO) agents specialize in syntax and logic errors, generating candidate fixes that developers can accept, reject, or refine. A BERT-based module encodes natural language feedback into dense embeddings and quality scores, which shape reward signals for Reinforcement Learning from Human Feedback (RLHF). To support personalization, the system uses dual FAISS indices to retrieve past fixes based on code-error pairs and developer explanations. Evaluated on a synthetic dataset of 200 Python programs, our approach achieves an 88% syntax-fix rate and 45% logic-fix rate within five suggestions—outperforming one-shot Large Language Model (LLM) baselines. In addition, the system improves the quality of the explanation, as measured by BLEU, ROUGE, and CodeBLEU. By integrating multi-agent specialization, linguistic feedback, and memory-driven retrieval, our framework delivers a more efficient, adaptive, and developer-aligned debugging experience.</abstract>
      <url hash="2c6c985c">2025.ranlp-1.70</url>
      <bibkey>krishnamoorthy-etal-2025-multi</bibkey>
    </paper>
    <paper id="71">
      <title>Integrating Large Language Models for Comprehensive Study and Sentiment Analysis of Student Feedback</title>
      <author><first>Jana</first><last>Kuzmanova</last></author>
      <author><first>Katerina</first><last>Zdravkova</last></author>
      <author><first>Ivan</first><last>Chorbev</last></author>
      <pages>604–613</pages>
      <abstract>n academic year 2023/24, our university collected over 200,000 student feedback responses evaluating teaching staff and course experiences. The survey included demographic data, 10 Likert scale questions on teaching quality, a question on student attendance, and three open-ended questions about student experiences. This paper explores the integration of Large Language Models (LLM) Gemini for sentiment analysis to evaluate students’ feedback quantitatively and qualitatively. We statistically analyze the Likert scale responses. To address the linguistic diversity of open-ended responses, written in both Cyrillic and Latin scripts with standard and slang expressions in several languages, we employed a preprocessing step using Gemini to standardize the input for further analyses. Sentiment analysis aims to identify various sentiment nuances, including direct answers, contradiction, multipolarity, mixed sentiment, sarcasm, irony, negation, ambiguity, understatement, and over-exaggeration. By comparing these insights with quantitative feedback, we aim to uncover deeper patterns between student perceptions and teaching performance. While the focus is on sentiment analysis, we also discuss the evaluation of the results provided by LLM. For the sentiments with less answers, the evaluation of GenAI was done manually. For the sentiments with more than 1000 entries, we suggest a semi-automated approach for sentiment categorization, to be explored in future work. This study enhances our understanding of student feedback through advanced computational methods, providing a more nuanced perspective on teaching quality and student satisfaction.</abstract>
      <url hash="5dd910f4">2025.ranlp-1.71</url>
      <bibkey>kuzmanova-etal-2025-integrating</bibkey>
    </paper>
    <paper id="72">
      <title>Task-Oriented Dialogue Systems through Function Calling</title>
      <author><first>Tiziano</first><last>Labruna</last></author>
      <author><first>Giovanni</first><last>Bonetta</last></author>
      <author id="bernardo-magnini"><first>Bernardo</first><last>Magnini</last></author>
      <pages>614–622</pages>
      <abstract>Large Language Models (LLMs) have demonstrated remarkable capabilities in generating dialogues and handling a broad range of user queries. However, their effectiveness as end-to-end Task-Oriented Dialogue (TOD) systems remains limited due to their reliance on static parametric memory, which fails to accommodate evolving knowledge bases (KBs). This paper investigates a scalable function-calling approach that enables LLMs to retrieve only the necessary KB entries via schema-guided queries, rather than embedding the entire KB into each prompt. This selective retrieval strategy reduces prompt size and inference time while improving factual accuracy in system responses. We evaluate our method on the MultiWOZ 2.3 dataset and compare it against a full-KB baseline that injects the entire KB into every prompt. Experimental results show that our approach consistently outperforms the full-KB method in accuracy, while requiring significantly fewer input tokens and considerably less computation time, especially when the KB size increases.</abstract>
      <url hash="50d52f19">2025.ranlp-1.72</url>
      <bibkey>labruna-etal-2025-task</bibkey>
    </paper>
    <paper id="73">
      <title>When to Retrieve: Teaching <fixed-case>LLM</fixed-case>s to Utilize Information Retrieval Effectively</title>
      <author><first>Tiziano</first><last>Labruna</last></author>
      <author><first>Jon Ander</first><last>Campos</last></author>
      <author><first>Gorka</first><last>Azkune</last></author>
      <pages>623–632</pages>
      <abstract>In this paper, we demonstrate how Large Language Models (LLMs) can effectively learn to use an off-the-shelf information retrieval (IR) system specifically when additional context is required to answer a given question. Given the performance of IR systems, the optimal strategy for question answering does not always entail external information retrieval; rather, it often involves leveraging the parametric memory of the LLM itself. Prior research has identified this phenomenon in the PopQA dataset, wherein the most popular questions are effectively addressed using the LLM’s parametric memory, while less popular ones require IR system usage. Following this, we propose a tailored training approach for LLMs, leveraging existing open-domain question answering datasets. Here, LLMs are trained to generate a special token, &lt;RET$&gt;, when they do not know the answer to a question. Our evaluation of the Adaptive Retrieval LLM (Adapt-LLM) on the PopQA dataset showcases improvements over the same LLM under three configurations: (i) retrieving information for all the questions, (ii) using always the parametric memory of the LLM, and (iii) using a popularity threshold to decide when to use a retriever. Through our analysis, we demonstrate that Adapt-LLM is able to generate the &lt;RET&gt; token when it determines that it does not know how to answer a question, indicating the need for IR, while it achieves notably high accuracy levels when it chooses to rely only on its parametric memory.</abstract>
      <url hash="c7ef66c2">2025.ranlp-1.73</url>
      <bibkey>labruna-etal-2025-retrieve</bibkey>
    </paper>
    <paper id="74">
      <title>Trust but Verify: A Comprehensive Survey of Faithfulness Evaluation Methods in Abstractive Text Summarization</title>
      <author><first>Salima</first><last>Lamsiyah</last></author>
      <author><first>Aria</first><last>Nourbakhsh</last></author>
      <author><first>Christoph</first><last>Schommer</last></author>
      <pages>633–643</pages>
      <abstract>Abstractive text summarization systems have advanced significantly with the rise of neural language models. However, they frequently suffer from issues of unfaithfulness or factual inconsistency, generating content that is not verifiably supported by the source text. This survey provides a comprehensive review of over 40 studies published between 2020 and 2025 on methods for evaluating faithfulness in abstractive summarization. We present a unified taxonomy that covers human evaluation techniques and a variety of automatic metrics, including question answering (QA)-based methods, natural language inference (NLI)-based methods, graph-based approaches, and large language model (LLM)-based evaluation. We also discuss meta-evaluation protocols that assess the quality of these metrics. In addition, we analyze a wide range of benchmark datasets, highlighting their design, scope, and relevance to emerging challenges such as long-document and domain-specific summarization. In addition, we identify critical limitations in current evaluation practices, including poor alignment with human judgment, limited robustness, and inefficiencies in handling complex summaries. We conclude by outlining future directions to support the development of more reliable, interpretable, and scalable evaluation methods. This work aims to support researchers in navigating the rapidly evolving landscape of faithfulness evaluation in summarization.</abstract>
      <url hash="3ccad17f">2025.ranlp-1.74</url>
      <bibkey>lamsiyah-etal-2025-trust</bibkey>
    </paper>
    <paper id="75">
      <title>Evaluating Large Language Models on Multiword Expressions in Multilingual and Code-Switched Contexts</title>
      <author><first>Frances Adriana</first><last>Laureano De Leon</last></author>
      <author><first>Asim</first><last>Abbas</last></author>
      <author><first>Harish</first><last>Tayyar Madabushi</last></author>
      <author id="mark-lee"><first>Mark</first><last>Lee</last></author>
      <pages>644–653</pages>
      <abstract>Multiword expressions, characterised by non-compositional meanings and syntactic irregularities, are an example of nuanced language. These expressions can be used literally or idiomatically, leading to significant changes in meaning. Although large language models perform well on many tasks, their ability to handle subtle linguistic phenomena remains unclear. This study examines how state-of-the-art models process the ambiguity of potentially idiomatic multiword expressions, particularly in less frequent contexts where memorisation is less likely to help. By evaluating models in Portuguese, Galician, and English, and introducing a new code-switched dataset and task, we show that large language models, despite their strengths, have difficulty handling nuanced language. In particular, we find that the latest models, including GPT-4, fail to outperform the xlm-roBERTa-base baselines in both detection and semantic tasks, with especially poor performance on the novel tasks we introduce, despite its similarity to existing tasks. Overall, our results demonstrate that multiword expressions, especially those that are ambiguous, continue to be a challenge to models. We provide open access to our datasets, prompts and model responses.</abstract>
      <url hash="184c8673">2025.ranlp-1.75</url>
      <bibkey>laureano-de-leon-etal-2025-evaluating</bibkey>
    </paper>
    <paper id="76">
      <title>Instruction Finetuning to Attribute Language Stage, Dialect, and Provenance Region to Historical <fixed-case>C</fixed-case>hurch <fixed-case>S</fixed-case>lavic Texts</title>
      <author><first>Piroska</first><last>Lendvai</last></author>
      <author id="uwe-reichel"><first>Uwe</first><last>Reichel</last></author>
      <author><first>Anna</first><last>Jouravel</last></author>
      <author><first>Achim</first><last>Rabus</last></author>
      <author><first>Elena</first><last>Renje</last></author>
      <pages>654–662</pages>
      <abstract>Our study addresses domain-specific text provenance classification for the historical Church Slavic language. The downstream task is to attribute the language stage and its dialectal and regional varieties to texts compiled from newly curated sources, including digitally unpublished manuscripts, in addition to established Church Slavic resources from the Universal Dependencies Treebank. We aim to harmonize previously used tag sets pertaining to textual provenance, and construct a new, hierarchical, multi-layer provenance labeling scheme. For the classification task, we finetune Vikhr (Nikolich et al., 2004), a generative LLM with knowledge of modern Russian, with the instruction to generate labels to classify the provenance of sentence-level text units. Besides gold standard manuscript transcriptions, we test the finetuned model on character-corrupted data that emulate the quality of noisy, handwritten text recognition material. The experiments show that the Vikhr base model has low provenance attribution knowledge of Church Slavic, whereas our finetuned model achieves above .9 F-scores on Language stage labeling and Dialect labeling, and above .8 F-score on generating the label that jointly classifies all three provenance layers. The task of classifying the fine-grained geographical region from which a manuscript originates proves harder (but still performs above .8), and is negatively impacted by character level noise injection.</abstract>
      <url hash="06cbbcd5">2025.ranlp-1.76</url>
      <bibkey>lendvai-etal-2025-instruction</bibkey>
    </paper>
    <paper id="77">
      <title><fixed-case>M</fixed-case>ari<fixed-case>ATE</fixed-case>: Automatic Term Extraction Using Large Language Models in the Maritime Domain</title>
      <author><first>Shijie</first><last>Liu</last></author>
      <author><first>Els</first><last>Lefever</last></author>
      <author id="veronique-hoste"><first>Veronique</first><last>Hoste</last></author>
      <pages>663–673</pages>
      <abstract>This study presents a comprehensive evaluation of Large Language Models (LLMs) for automatic term extraction in the maritime safety domain. The research examines the zero-shot performance of seven state-of-the-art LLMs, including both open-source and closed-source models, and investigates terminology annotation strategies for optimal coverage. Nested annotation captures both complete technical expressions and their constituent components, while full-term annotation focuses exclusively on maximal-length terms. Experimental results demonstrate Claude-3.5-Sonnet’s superior performance (F1-score of 0.80) in maritime safety terminology extraction, particularly in boundary detection capabilities. Error analysis reveals three primary challenges: distinguishing contextual descriptions from legitimate terminology, handling complex multi-word expressions, and identifying maritime safety operational and navigational terms. Analysis of annotation strategies reveals that the full-term annotation approach achieves 95.24% coverage of unique terms compared to the nested annotation approach. The additional 4.76% of terms identified through nested annotation represents subcomponents of larger technical expressions. These findings advance the understanding of LLMs’ capabilities in specialized terminology extraction and provide empirical evidence supporting the sufficiency of full-term annotation for comprehensive terminology coverage in domain-specific applications.</abstract>
      <url hash="524aba2b">2025.ranlp-1.77</url>
      <bibkey>liu-etal-2025-mariate</bibkey>
    </paper>
    <paper id="78">
      <title>Exploring the Usage of Knowledge Graphs in Identifying Human and <fixed-case>LLM</fixed-case>-Generated Fake Reviews</title>
      <author><first>Ming</first><last>Liu</last></author>
      <author id="massimo-poesio"><first>Massimo</first><last>Poesio</last></author>
      <pages>674–681</pages>
      <abstract>The emergence of large language models has led to an explosion of machine-generated fake reviews. Although distinguishing between human and LLM-generated fake reviews is an area of active research, progress is still needed. One aspect which makes current LLM-generated fake reviews easier to recognize is that LLMs–in particular the smaller ones–lack domain-related knowledge. The objective of this work is to investigate whether large language models can produce more realistic artificial reviews when supplemented with knowledge graph information, thus resulting in a more challenging training dataset for human and LLM-generated fake reviews detectors. We propose a method for generating fake reviews by providing knowledge graph information to a llama model, and used it to generate a large number of fake reviews which used to fine tune a state-of-the-art human and LLM-generated fake reviews detection system. Our results show that when knowledge graph information is provided as part of the input, the accuracy of the model is improved by 0.24%. When the knowledge graph is used as an embedding layer and combined with the existing input embedding layer, the accuracy of the detection model is improved by 1.279%.</abstract>
      <url hash="7627ccde">2025.ranlp-1.78</url>
      <bibkey>liu-poesio-2025-exploring</bibkey>
    </paper>
    <paper id="79">
      <title>The Evaluation of Medical Terms Complexity Using Lexical Features and Large Language Models</title>
      <author><first>Liliya</first><last>Makhmutova</last></author>
      <author><first>Giancarlo Dondoni</first><last>Salton</last></author>
      <author><first>Fernando</first><last>Perez-Tellez</last></author>
      <author><first>Robert J.</first><last>Ross</last></author>
      <pages>682–693</pages>
      <abstract>Understanding medical terminology is critical for effective patient-doctor communication, yet many patients struggle with complex jargon. This study compares Machine Learning (ML) models and Large Language Models (LLMs) in predicting medical term complexity as a means of improving doctor-patient communication. Using survey data from 252 participants rating 1,000 words along with various lexical features, we measured the accuracy of both model types. The results show that LLMs outperform traditional lexical-feature-based models, suggesting their potential to identify complex medical terms and lay the groundwork for personalised patient-doctor communication.</abstract>
      <url hash="fd032f8d">2025.ranlp-1.79</url>
      <bibkey>makhmutova-etal-2025-evaluation</bibkey>
    </paper>
    <paper id="80">
      <title>Where and How as Key Factors for Knowledge-Enhanced Constrained Commonsense Generation</title>
      <author><first>Ivan</first><last>Martinez-Murillo</last></author>
      <author id="paloma-moreda-pozo"><first>Paloma</first><last>Moreda Pozo</last></author>
      <author><first>Elena</first><last>Lloret</last></author>
      <pages>694–703</pages>
      <abstract>This paper addresses a key limitation in Natural Language Generation (NLG) systems: their struggle with commonsense reasoning, which is essential for generating contextually appropriate and plausible text. The study proposes an approach to enhance the commonsense reasoning abilities of NLG systems by integrating external knowledge framed in a constrained commonsense generation task. The paper investigates strategies for extracting and injecting external knowledge into pre-trained models, specifically BART and T5, in both base and large configurations. Experimental results show that incorporating external knowledge extracted with a simple strategy leads to significant improvements in performance, with the models achieving 88% accuracy in generating plausible and correct sentences. When refined methods for knowledge extraction are applied, the accuracy further increases to 92%. These findings underscore the crucial role of high-quality external knowledge in enhancing the commonsense reasoning capabilities of NLG systems, suggesting that such integration is vital for advancing their performance in real-world applications.</abstract>
      <url hash="a918a0a4">2025.ranlp-1.80</url>
      <bibkey>martinez-murillo-etal-2025-key</bibkey>
    </paper>
    <paper id="81">
      <title>Forecasting Online Negativity Spikes with Multilingual Transformers for Strategic Decision-Making</title>
      <author><first>Rowan</first><last>Martnishn</last></author>
      <author><first>Vishal</first><last>Green</last></author>
      <author><first>Varun</first><last>Kadari</last></author>
      <author><first>Shravan</first><last>Athikinasetti</last></author>
      <author><first>Zach</first><last>Miller</last></author>
      <author><first>Julia</first><last>Brady</last></author>
      <author><first>Viraj</first><last>Chawda</last></author>
      <author><first>Nikhil</first><last>Badlani</last></author>
      <pages>704–710</pages>
      <abstract>Social media platforms like Reddit, YouTube, and Instagram amplify rapid dissemination of negative sentiment, potentially causing harm and fostering extremist discourse. This paper addresses the NLP challenge of predicting sudden spikes in negative sentiment by fine-tuning multilingual transformer models. We present a structured pipeline emphasizing linguistic feature extraction and temporal modeling. Our experimental results, obtained from extensive Reddit, YouTube, and Instagram data, demonstrate improved forecasting accuracy over baseline methods. Ethical considerations and implications for deployment in social media moderation are thoroughly discussed. The system includes user-centric interactive features such as real-time filtering dashboards, customizable negativity thresholds, and forecasting analytics, providing actionable insights for preventative content moderation. Given its real-time deployment potential and cross-platform applicability, our system offers actionable insights for proactive content moderation.</abstract>
      <url hash="782ba2c9">2025.ranlp-1.81</url>
      <bibkey>martnishn-etal-2025-forecasting</bibkey>
    </paper>
    <paper id="82">
      <title><fixed-case>C</fixed-case>-<fixed-case>SHAP</fixed-case>: Collocation-Aware Explanations for Financial <fixed-case>NLP</fixed-case></title>
      <author><first>Martina</first><last>Menzio</last></author>
      <author><first>Elisabetta</first><last>Fersini</last></author>
      <author><first>Davide</first><last>Paris</last></author>
      <pages>711–717</pages>
      <abstract>Understanding the internal decision-making process of NLP models in high-stakes domains such as the financial sector is particularly challenging due to the complexity of domain-specific terminology and the need for transparency and accountability. Although SHAP is a widely used model-agnostic method for attributing model predictions to input features, its standard formulation treats input tokens as independent units, failing to capture the influence of collocations that often carry non-compositional meaning, instead modeled by the current language models. We introduce C-SHAP, an extension of SHAP that incorporates collocational dependencies into the explanation process to account for word combinations in the financial sector. C-SHAP dynamically groups tokens into significant collocations using a financial glossary and computes Shapley values over these structured units. The proposed approach has been evaluated to explain sentiment classification of Federal Reserve Minutes, demonstrating improved alignment with human rationales and better association to model behaviour compared to the standard token-level approach.</abstract>
      <url hash="cedf4351">2025.ranlp-1.82</url>
      <bibkey>menzio-etal-2025-c</bibkey>
    </paper>
    <paper id="83">
      <title>Investigating Polarization in <fixed-case>Y</fixed-case>ou<fixed-case>T</fixed-case>ube Comments via Aspect-Based Sentiment Analysis</title>
      <author><first>Daniel</first><last>Miehling</last></author>
      <author><first>Daniel</first><last>Dakota</last></author>
      <author id="sandra-kubler"><first>Sandra</first><last>Kübler</last></author>
      <pages>718–728</pages>
      <abstract>We investigate the use of Aspect-Based Sentiment Analysis (ABSA) to analyze polarization in online discourse. For the analysis, we use a corpus of over 3 million user comments and replies from four state-funded media channels from YouTube Shorts in the context of the 2023 Israel–Hamas war. We first annotate a subsample of approx. 5 000 comments for positive, negative, and neutral sentiment towards a list of topic related aspects. After training an ABSA model (Yang et al., 2023) on the corpus, we evaluate its performance on this task intrinsically, before evaluating the usability of the automatic analysis of the whole corpus for analyzing polarization. Our results show that the ABSA model achieves an F1 score of 77.9. The longitudinal and outlet analyses corroborate known trends and offer subject experts more fine-grained information about the use of domain-specific language in user-generated content.</abstract>
      <url hash="1d51b7fe">2025.ranlp-1.83</url>
      <bibkey>miehling-etal-2025-investigating</bibkey>
    </paper>
    <paper id="84">
      <title>From the <fixed-case>T</fixed-case>ractatus Logico-Philosophicus to Later <fixed-case>W</fixed-case>ittgenstein: An <fixed-case>NLP</fixed-case>-Based Comparative Analysis</title>
      <author><first>Andreiana</first><last>Mihail</last></author>
      <author><first>Silviu-Florin</first><last>Gheorghe</last></author>
      <author><first>Andrei</first><last>Fotea</last></author>
      <author id="liviu-p-dinu"><first>Liviu P.</first><last>Dinu</last></author>
      <pages>729–736</pages>
      <abstract>This study investigates the application of Natural Language Processing (NLP) methods to uncover linguistic and stylistic variations within the corpus of Ludwig Wittgenstein, a philosopher renowned for his complex and notional contributions. By analyzing works such as Tractatus Logico-Philosophicus alongside his later notes, manuscripts, and student-dictated lectures in Cambridge, we aim to identify significant distinctions in language use and conceptual framing. The corpus poses unique difficulties because of its diverse origins, encompassing published works, personal notes, and collaboratively edited transcripts. Utilizing zero-shot NLP techniques, this exploratory/preliminary research aims to reveal patterns reflective of Wittgenstein’s philosophical evolution and differences in text production manners. The results highlight the potential of computational approaches to enhance our understanding of complex, context-dependent philosophical writings, providing a possible path for further interdisciplinary investigations into linguistic and conceptual dynamics in this challenging body of work.</abstract>
      <url hash="bd749e75">2025.ranlp-1.84</url>
      <bibkey>mihail-etal-2025-tractatus</bibkey>
    </paper>
    <paper id="85">
      <title>Towards Intention-aligned Reviews Summarization: Enhancing <fixed-case>LLM</fixed-case> Outputs with Pragmatic Cues</title>
      <author><first>Maria</first><last>Miro Maestre</last></author>
      <author><first>Robiert</first><last>Sepulveda-Torres</last></author>
      <author><first>Ernesto Luis</first><last>Estevanell-Valladares</last></author>
      <author><first>Armando</first><last>Suarez Cueto</last></author>
      <author><first>Elena</first><last>Lloret</last></author>
      <pages>737–747</pages>
      <abstract>Recent advancements in Natural Language Processing (NLP) have allowed systems to address complex tasks involving cultural knowledge, multi-step reasoning, and inference. While significant progress has been made in text summarization guided by specific instructions or stylistic cues, the integration of pragmatic aspects like communicative intentions remains underexplored, particularly in non-English languages. This study emphasizes communicative intentions as central to summary generation, classifying Spanish product reviews by intent and using prompt engineering to produce intention-aligned summaries. Results indicate challenges for large language models (LLMs) in processing extensive document clusters, with summarization accuracy heavily dependent on prior model exposure to similar intentions. Common intentions such as complimenting and criticizing are reliably handled, whereas less frequent ones like promising or questioning pose greater difficulties. These findings suggest that integrating communicative intentions into summarization tasks can significantly enhance summary relevance and clarity, thereby improving user experience in product review analysis.</abstract>
      <url hash="9c0bc651">2025.ranlp-1.85</url>
      <bibkey>miro-maestre-etal-2025-towards</bibkey>
    </paper>
    <paper id="86">
      <title>Subtle Shifts, Significant Threats: Leveraging <fixed-case>XAI</fixed-case> Methods and <fixed-case>LLM</fixed-case>s to Undermine Language Models Robustness</title>
      <author><first>Adrián</first><last>Moreno Muñoz</last></author>
      <author><first>L. Alfonso</first><last>Ureñ-López</last></author>
      <author><first>Eugenio</first><last>Martínez Cámara</last></author>
      <pages>748–757</pages>
      <abstract>Language models exhibit inherent security vulnerabilities, which may be related to several factors, among them the malicious alteration of the input data. Such weaknesses compromise the robustness of language models, which is more critical when adversarial attacks are stealthy and do not require high computational resources. In this work, we study how vulnerable English language models are to adversarial attacks based on subtle modifications of the input of pretrained English language models. We claim that the attack may be more effective if it is targeted to the most salient words for the discriminative task of the language models. Accordingly, we propose a new attack built upon a two-step approach: first, we use a posteriori explainability methods to identify the most influential words for the classification task, and second, we replace them with contextual synonyms retrieved by a small language model. Since the attack has to be as stealthy as possible, we also propose a new evaluation measure that combines the effectiveness of the attack with the number of modifications performed. The results show that pretrained English language models are vulnerable to minimal semantic changes, which makes the design of countermeasure methods imperative.</abstract>
      <url hash="f8a82593">2025.ranlp-1.86</url>
      <bibkey>moreno-munoz-etal-2025-subtle</bibkey>
    </paper>
    <paper id="87">
      <title>Fast Thinking with Structured Prompts: Enabling <fixed-case>LLM</fixed-case> Reasoning without Chain-of-Thought Generation</title>
      <author><first>Kirill</first><last>Morozov</last></author>
      <author><first>Liubov</first><last>Chubarova</last></author>
      <author><first>Irina</first><last>Piontkovskaya</last></author>
      <pages>758–766</pages>
      <abstract>The emergence of complex reasoning abilities in large language models (LLMs) has sparked great interest, and a variety of prompting techniques was proposed to coax them into emulating human thought processes. In this work, we introduce Think Node-by-Node, a graph-based reasoning framework inspired by mind maps, flowcharts, and other visual aids that help humans tackle complex problems. Rather than generating images directly, our approach leverages standard graph-building and rendering libraries, and requires no fine-tuning, only the model’s native coding capabilities. We further explore a “Fast Thinking” regime, in which a graph-reasoning example provided in the prompt, but the model generates the answers directly, without the full thought process reconstruction. Surprisingly, this approach leads to significant improvement upon baseline in general-knowledge tasks. Remarkably, Think Node-by-Node maintains strong performance even under a strict 25-token budget for answer generation. Across two instruction-tuned LLMs (0.5B and 7B parameters), our FastTNbN strategy outperforms baseline prompting techniques, improving accuracy by up to 10%, and exceeds the capabilities of other structured prompting methods under equivalent generation constraints.</abstract>
      <url hash="72e9aeee">2025.ranlp-1.87</url>
      <bibkey>morozov-etal-2025-fast</bibkey>
    </paper>
    <paper id="88">
      <title><fixed-case>T</fixed-case>2<fixed-case>K</fixed-case>now: Analysis and Trend Platform Using the Knowledge Extracted from Scientific Texts</title>
      <author id="rafael-munoz"><first>Rafael</first><last>Muñoz Guillena</last></author>
      <author id="manuel-palomar"><first>Manuel</first><last>Palomar</last></author>
      <author id="yoan-gutierrez"><first>Yoan</first><last>Gutiérrez</last></author>
      <author><first>Mar</first><last>Bonora</last></author>
      <pages>767–770</pages>
      <abstract>The T2Know project explores the application of natural language processing technologies to build a semantic platform for scientific documents using knowledge graphs. These graphs will interconnect meaningful sections from different documents, enabling both trend analysis and the generation of informed recommendations. The project’s objectives include the development of entity recognition systems, the definition of user and document profiles, and the linking of documents through transformer-based technologies. Consequently, the extracted relevant content will go beyond standard metadata such as titles and author affiliations, extending also to other key sections of scientific articles, including references, which are treated as integral components of the knowledge representation.</abstract>
      <url hash="74e1029e">2025.ranlp-1.88</url>
      <bibkey>munoz-guillena-etal-2025-t2know</bibkey>
    </paper>
    <paper id="89">
      <title>Investigating Large Language Models’ (<fixed-case>LLM</fixed-case>s) Capabilities for Sexism Detection on a Low-Resource Language</title>
      <author><first>Lutfiye Seda</first><last>Mut Altin</last></author>
      <author><first>Horacio</first><last>Saggion</last></author>
      <pages>771–779</pages>
      <abstract>Automatic detection of sexist language on social media is gaining attention due to its harmful societal impact and technical challenges it presents. The limited availability of data resources in some languages restricts the development of effective tools to fight the spread of such content. In this work, we investigated various methods to improve the efficiency of automatic detection of sexism and its subtypes in a low-resource language, Turkish. We first experimented with various LLM prompting strategies for classification and then investigated the impact of different data augmentation strategies, including both synthetic data generation with LLMs (GPT, DeepSeek) and translationbased augmentation using English and Spanish data. Finally, we examined whether these augmentation methods would improve model performance of a trained neural network (BERT). Our benchmarking results show that fine-tuned LLM (GPT-4o-mini) achieved the best performance compared to zero-shot, few-shot, Chain-of-Thought prompt classification and training a neural network (BERT) including the data augmented in different ways (synthetic generation, translation). Our results also indicated that, for the classification of more granular classes, in other words, more specific tasks, training a neural network generally performed better than prompt-based classification using an LLM.</abstract>
      <url hash="a9870d74">2025.ranlp-1.89</url>
      <bibkey>mut-altin-saggion-2025-investigating</bibkey>
    </paper>
    <paper id="90">
      <title><fixed-case>P</fixed-case>oly<fixed-case>H</fixed-case>ope-<fixed-case>M</fixed-case> at <fixed-case>RANLP</fixed-case>2025 Subtask-1 Binary Hope Speech Detection: <fixed-case>S</fixed-case>panish Language Classification Approach with Comprehensive Learning Using Transformer, and Traditional <fixed-case>ML</fixed-case>, and <fixed-case>DL</fixed-case></title>
      <author><first>Md. Julkar</first><last>Naeen</last></author>
      <author><first>Sourav Kumar</first><last>Das</last></author>
      <author><first>Sharun Akter</first><last>Khushbu</last></author>
      <author><first>Shahriar Sultan</first><last>Ramit</last></author>
      <author><first>Alaya Parven</first><last>Alo</last></author>
      <pages>780–786</pages>
      <abstract>This paper presents our system for the RANLP 2025 shared task on multilingual binary sentiment classification for Task-2 Spanish datasets for domains including social media and customer reviews. We experimented with various models from traditional machine learning approaches—Naive Bayes and LightGBM—to deep learning architectures like LSTM. Among them, the transformer-based XLM-RoBERTa model performed best with an F1 of 0.85, demonstrating its promise for multilingual sentiment work. Basic text preprocessing techniques were used for data quality assurance and improving model performance. Our comparison reflects the superiority of transformer-based models over the traditional methods in binary sentiment classification for multilingual and low-resource environments. This study enables the development of cross-lingual sentiment classification by establishing strong baselines and paying close attention to model performance in joint task settings.</abstract>
      <url hash="9724bdc4">2025.ranlp-1.90</url>
      <bibkey>naeen-etal-2025-polyhope</bibkey>
    </paper>
    <paper id="91">
      <title><fixed-case>F</fixed-case>-<fixed-case>L</fixed-case>o<fixed-case>RA</fixed-case>-<fixed-case>QA</fixed-case>: Finetuning <fixed-case>LL</fixed-case>a<fixed-case>MA</fixed-case> Models with Low-Rank Adaptation for <fixed-case>F</fixed-case>rench Botanical Question Generation and Answering</title>
      <author><first>Ayoub</first><last>Nainia</last></author>
      <author><first>Régine</first><last>Vignes-Lebbe</last></author>
      <author><first>Hajar</first><last>Mousannif</last></author>
      <author><first>Jihad</first><last>Zahir</last></author>
      <pages>787–796</pages>
      <abstract>Despite recent advances in large language models (LLMs), most question-answering (QA) systems remain English-centric and poorly suited to domain-specific scientific texts. This linguistic and domain bias poses a major challenge in botany, where a substantial portion of knowledge is documented in French. We introduce F-LoRA-QA, a fine-tuned LLaMA-based pipeline for French botanical QA, leveraging Low-Rank Adaptation (LoRA) for efficient domain adaptation. We construct a specialized dataset of 16,962 question-answer pairs extracted from scientific flora descriptions and fine-tune LLaMA models to retrieve structured knowledge from unstructured botanical texts. Expert-based evaluation confirms the linguistic quality and domain relevance of generated answers. Compared to baseline LLaMA models, F-LoRA-QA achieves a 300% BLEU score increase, 70% ROUGE-1 F1 gain, +16.8% BERTScore F1, and Exact Match improvement from 2.01% to 23.57%. These results demonstrate the effectiveness of adapting LLMs to low-resource scientific domains and highlight the potential of our approach for automated trait extraction and biodiversity data structuring.</abstract>
      <url hash="4ab37a0a">2025.ranlp-1.91</url>
      <bibkey>nainia-etal-2025-f</bibkey>
    </paper>
    <paper id="92">
      <title>Reverse Prompting: A Novel Computational Paradigm in Schizophrenia Based on Large Language Models</title>
      <author><first>Ivan</first><last>Nenchev</last></author>
      <author><first>Christiane</first><last>Montag</last></author>
      <author><first>Sandra Anna</first><last>Just</last></author>
      <pages>797–806</pages>
      <abstract>Large language models (LLMs) are increasingly being used to interpret and generate human language, yet their ability to process clinical language remains underexplored. This study examined whether three open-source LLMs can infer interviewer questions from participant responses in a semi-structured psychiatric interview (NET) conducted with individuals diagnosed with schizophrenia (n = 107) and neurotypical controls (n = 66). Using cosine similarity between LLM-generated questions and original prompts as a proxy for the precision of the inference, we found that responses from individuals with schizophrenia produced significantly lower similarity scores (beta = –0.165, p &lt; .001). Cosine similarity decreased across the nested structure of the interview, with smaller reductions observed in the schizophrenia group. Although all emotions decreased similarity with fear, only sadness showed a significant interaction with diagnosis, suggesting differential processing of emotional discourse. Model type and generation temperature also influenced outcomes, highlighting variability in model performance. Our findings demonstrate that LLMs systematically struggle to reconstruct interviewer intent from responses by individuals with schizophrenia, reflecting known discourse-level disturbances in the disorder.</abstract>
      <url hash="ad53cfc6">2025.ranlp-1.92</url>
      <bibkey>nenchev-etal-2025-reverse</bibkey>
    </paper>
    <paper id="93">
      <title>A Survey on Small Language Models</title>
      <author><first>Chien Van</first><last>Nguyen</last></author>
      <author><first>Xuan</first><last>Shen</last></author>
      <author><first>Ryan</first><last>Aponte</last></author>
      <author><first>Yu</first><last>Xia</last></author>
      <author><first>Samyadeep</first><last>Basu</last></author>
      <author><first>Zhengmian</first><last>Hu</last></author>
      <author><first>Jian</first><last>Chen</last></author>
      <author><first>Mihir</first><last>Parmar</last></author>
      <author><first>Sasidhar</first><last>Kunapuli</last></author>
      <author><first>Joe</first><last>Barrow</last></author>
      <author><first>Junda</first><last>Wu</last></author>
      <author><first>Ashish</first><last>Singh</last></author>
      <author><first>Yu</first><last>Wang</last></author>
      <author><first>Jiuxiang</first><last>Gu</last></author>
      <author><first>Nesreen</first><last>K. Ahmed</last></author>
      <author><first>Nedim</first><last>Lipka</last></author>
      <author><first>Ruiyi</first><last>Zhang</last></author>
      <author><first>Xiang</first><last>Chen</last></author>
      <author><first>Tong</first><last>Yu</last></author>
      <author><first>Sungchul</first><last>Kim</last></author>
      <author><first>Hanieh</first><last>Deilamsalehy</last></author>
      <author><first>Namyong</first><last>Park</last></author>
      <author><first>Michael</first><last>Rimer</last></author>
      <author><first>Zhehao</first><last>Zhang</last></author>
      <author><first>Huanrui</first><last>Yang</last></author>
      <author><first>Puneet</first><last>Mathur</last></author>
      <author><first>Gang</first><last>Wu</last></author>
      <author><first>Franck</first><last>Dernoncourt</last></author>
      <author><first>Ryan A.</first><last>Rossi</last></author>
      <author><first>Thien Huu</first><last>Nguyen</last></author>
      <pages>807–821</pages>
      <abstract>Small Language Models (SLMs) have become increasingly important due to their efficiency and performance to perform various language tasks with minimal computational resources, making them ideal for various settings including on-device, mobile, edge devices, among many others. In this article, we present a comprehensive survey on SLMs, focusing on their architectures, training techniques, and model compression techniques. We propose a novel taxonomy for categorizing the methods used to optimize SLMs, including model compression, pruning, and quantization techniques. We summarize the benchmark datasets that are useful for benchmarking SLMs along with the evaluation metrics commonly used. Additionally, we highlight key open challenges that remain to be addressed. Our survey aims to serve as a valuable resource for researchers and practitioners interested in developing and deploying small yet efficient language models.</abstract>
      <url hash="0ef1bbd8">2025.ranlp-1.93</url>
      <bibkey>nguyen-etal-2025-survey</bibkey>
    </paper>
    <paper id="94">
      <title>Quantifying the Overlap: Attribution Maps and Linguistic Heuristics in Encoder-Decoder Machine Translation Models</title>
      <author><first>Aria</first><last>Nourbakhsh</last></author>
      <author><first>Salima</first><last>Lamsiyah</last></author>
      <author><first>Christoph</first><last>Schommer</last></author>
      <pages>822–831</pages>
      <abstract>Explainable AI (XAI) attribution methods seek to illuminate the decision-making process of generative models by quantifying the contribution of each input token to the generated output. Different attribution algorithms, often rooted in distinct methodological frameworks, can produce varied interpretations of feature importance. In this study, we utilize attribution mappings derived from three distinct methods as weighting signals during the training of encoder-decoder models. Our findings demonstrate that Attention and Value Zeroing attribution weights consistently lead to improved model performance. To better understand the linguistic information these mappings capture, we extract part-of-speech (POS), dependency, and named entity recognition (NER) tags from the input-output pairs and compare them with the XAI attribution maps. Although the Saliency method shows greater alignment with POS and dependency annotations than Value Zeroing, it exhibits more divergence in places where its attributions do not conform to these linguistic tags, compared to the other two methods, and it contributes less to the models’ performance.</abstract>
      <url hash="585df74a">2025.ranlp-1.94</url>
      <bibkey>nourbakhsh-etal-2025-quantifying</bibkey>
    </paper>
    <paper id="95">
      <title>The Illusion of a Perfect Metric: Why Evaluating <fixed-case>AI</fixed-case> ́<fixed-case>S</fixed-case> Words Is Harder than It Looks</title>
      <author><first>Maria Paz</first><last>Oliva</last></author>
      <author><first>Adriana D.</first><last>Correia</last></author>
      <author><first>Ivan</first><last>Vankov</last></author>
      <author><first>Viktor</first><last>Botev</last></author>
      <pages>832–842</pages>
      <abstract>Evaluating Natural Language Generation (NLG) is crucial for the practical adoption of AI, but has been a longstanding research challenge. While human evaluation is considered the de-facto standard, it is expensive and lacks scalability. Practical applications have driven the development of various automatic evaluation metrics (AEM), designed to compare the model output with human-written references, generating a score which approximates human judgment. Over time, AEMs have evolved from simple lexical comparisons, to semantic similarity models and, more recently, to LLM-based evaluators. However, it seems that no single metric has emerged as a definitive solution, resulting in studies using different ones without fully considering the implications. This paper aims to show this by conducting a thorough examination of the methodologies of existing metrics, their documented strengths and limitations, validation methods, and correlations with human judgment. We identify several key challenges: metrics often capture only specific aspects of text quality, their effectiveness varies by task and dataset, validation practices remain unstructured, and correlations with human judgment are inconsistent. Importantly, we find that these challenges persist in the most recent type of metric, LLM-as-a-Judge, as well as in the evaluation of Retrieval Augmented Generation (RAG), an increasingly relevant task in academia and industry. Our findings challenge the quest for the ‘perfect metric’. We propose selecting metrics based on task-specific needs and leveraging complementary evaluations and advocate that new metrics should focus on enhanced validation methodologies.</abstract>
      <url hash="f9380d58">2025.ranlp-1.95</url>
      <bibkey>oliva-etal-2025-illusion</bibkey>
    </paper>
    <paper id="96">
      <title>Multi-<fixed-case>LLM</fixed-case> Debiasing Framework</title>
      <author><first>Deonna M.</first><last>Owens</last></author>
      <author><first>Ryan</first><last>Rossi</last></author>
      <author><first>Sungchul</first><last>Kim</last></author>
      <author><first>Tong</first><last>Yu</last></author>
      <author><first>Franck</first><last>Dernoncourt</last></author>
      <author><first>Xiang</first><last>Chen</last></author>
      <author><first>Ruiyi</first><last>Zhang</last></author>
      <author><first>Jiuxiang</first><last>Gu</last></author>
      <author><first>Hanieh</first><last>Deilamsalehy</last></author>
      <author><first>Nedim</first><last>Lipka</last></author>
      <pages>843–853</pages>
      <abstract>Large Language Models (LLMs) are powerful tools with the potential to benefit society immensely, yet, they have demonstrated biases that perpetuate societal inequalities. Despite significant advancements in bias mitigation techniques using data augmentation, zero-shot prompting, and model fine-tuning, biases continuously persist, including subtle biases that may elude human detection. Recent research has shown a growing interest in multi-LLM approaches, which have been demonstrated to be effective in improving the quality of reasoning and factuality in LLMs. Building on this approach, we propose a novel multi-LLM debiasing framework aimed at reducing bias in LLMs. Our work is the first to introduce and evaluate two distinct approaches within this framework for debiasing LLMs: a centralized method, where the conversation is facilitated by a single central LLM, and a decentralized method, where all models communicate directly. Our findings reveal that our multi-LLM framework significantly reduces bias in LLMs, outperforming the baseline method across several social groups.</abstract>
      <url hash="150c332d">2025.ranlp-1.96</url>
      <bibkey>owens-etal-2025-multi</bibkey>
    </paper>
    <paper id="97">
      <title>Toward Quantum-Enhanced Natural Language Understanding: Sarcasm and Claim Detection with <fixed-case>QLSTM</fixed-case></title>
      <author><first>Pritam</first><last>Pal</last></author>
      <author><first>Dipankar</first><last>Das</last></author>
      <pages>854–859</pages>
      <abstract>Traditional machine learning (ML) and deep learning (DL) models have shown effectiveness in natural language processing (NLP) tasks, such as sentiment analysis. However, they often struggle with complex linguistic structures, such as sarcasm and implicit claims. This paper introduces a Quantum Long Short-Term Memory (QLSTM) framework for detecting sarcasm and identifying claims in text, aiming to enhance the analysis of complex sentences. We evaluate four approaches: (1) classical LSTM, (2) quantum framework using QLSTM, (3) voting ensemble combining classical and quantum LSTMs, and (4) hybrid framework integrating both types. The experimental results indicate that the QLSTM approach excels in sarcasm detection, while the voting framework performs best in claim identification.</abstract>
      <url hash="adc286a6">2025.ranlp-1.97</url>
      <bibkey>pal-das-2025-toward</bibkey>
    </paper>
    <paper id="98">
      <title>Legal Terminology Extraction in <fixed-case>S</fixed-case>panish: Gold-standard Generation and <fixed-case>LLM</fixed-case> Evaluation</title>
      <author><first>Lucia</first><last>Palacios Palacios</last></author>
      <author><first>Beatriz</first><last>Guerrero García</last></author>
      <author><first>Patricia</first><last>Martín Chozas</last></author>
      <author><first>Elena</first><last>Montiel Ponsoda</last></author>
      <pages>860–869</pages>
      <abstract>This study aims to develop a gold-standard for terminological extraction in Castilian Spanish within the domain of labour law. To achieve this, a methodology was developed based on established linguistic theories and reviewed by a team of expert terminologists. Departing from previous extraction studies and reference theoretical frameworks, candidate terms were identified by their morphosyntactic patterns, enriched by assessing their degree of specialisation in reference resources. The candidate terms were then subjected to manual validation. To evaluate its applicability, we assessed the performance of the LLaMA3-8B and Mistral-7B language models in extracting labour law terms from the latest version of the Real Decreto Legislativo 2/2015 Ley del Estatuto de los Trabajadores. YAKE was also included as a statistical baseline for comparison between traditional methods and generative approaches. All models were evaluated against the validated gold-standard.</abstract>
      <url hash="3443bb0c">2025.ranlp-1.98</url>
      <bibkey>palacios-palacios-etal-2025-legal</bibkey>
    </paper>
    <paper id="99">
      <title>Benchmarking Item Difficulty Classification in <fixed-case>G</fixed-case>erman Vocational Education and Training</title>
      <author><first>Alonso</first><last>Palomino</last></author>
      <author><first>Benjamin</first><last>Paassen</last></author>
      <pages>870–875</pages>
      <abstract>Predicting the difficulty of exam questions or items is essential to effectively assembling and calibrating exams. While item response theory (IRT) models can estimate item difficulty, they require student responses that are costly and rarely available at scale. Natural language processing methods offer a text-only alternative; however, due to the scarcity of real-world labeled data, prior work often relies on synthetic or domain-specific corpora, limiting generalizability and overlooking the nuanced challenges of real-world text-based item difficulty estimation. Addressing this gap, we benchmark 122 classifiers on 935 German Vocational Education and Training (VET) items labeled via previous IRT analysis to assess feasibility under real-world conditions. In our setup, a stacked ensemble that combines linguistic features, pre-trained embeddings, and external semantic resources outperforms both transformer-based models and few-shot large language models, achieving moderate performance. We report findings and discuss limitations in the context of German VET.</abstract>
      <url hash="35a5a3fd">2025.ranlp-1.99</url>
      <bibkey>palomino-paassen-2025-benchmarking</bibkey>
    </paper>
    <paper id="100">
      <title>Isolating <fixed-case>LLM</fixed-case> Performance Gains in Pre-training versus Instruction-tuning for Mid-resource Languages: The <fixed-case>U</fixed-case>krainian Benchmark Study</title>
      <author><first>Yurii</first><last>Paniv</last></author>
      <pages>876–883</pages>
      <abstract>This paper evaluates language model performance on Ukrainian language tasks across multiple downstream benchmarks, including summarization, closed and open question answering, and translation at both sentence and paragraph levels. We also introduce LongFlores, an extension of the FLORES benchmark designed specifically to assess paragraph-level translation capabilities. In our experiments, we compare the performance of base models against their instruction-tuned counterparts to isolate and quantify the source of performance improvements for Ukrainian language tasks. Our findings reveal that for popular open source models, base models are stronger in the few-shot setting for the task than their instruction-tuned counterparts in the zero-shot setting. This suggests lower attention paid to Ukrainian during the instruction-tuning phase, providing valuable insights for future model development and optimization for Ukrainian and potentially other lower-resourced languages.</abstract>
      <url hash="6c0e0663">2025.ranlp-1.100</url>
      <bibkey>paniv-2025-isolating</bibkey>
    </paper>
    <paper id="101">
      <title>Evaluating <fixed-case>LLM</fixed-case>s on Deceptive Text across Cultures</title>
      <author><first>Katerina</first><last>Papantoniou</last></author>
      <author><first>Panagiotis</first><last>Papadakos</last></author>
      <author><first>Dimitris</first><last>Plexousakis</last></author>
      <pages>884–893</pages>
      <abstract>Deception is a pervasive feature of human communication, yet identifying linguistic cues of deception remains a challenging task due to strong context dependency across domains, cultures, and types of deception. While prior work has relied on human analysis across disciplines like social psychology, philosophy, and political science, large language models (LLMs) offer a new avenue for exploring deception due to their strong performance in Natural Language Processing (NLP) tasks. In this study, we investigate whether open-weight LLMs possess and can apply knowledge about linguistic markers of deception across multiple languages, domains, and cultural contexts, with language and country of origin used as a proxy for culture. We focus on two domains, opinionated reviews and personal descriptions about sensitive topics, spanning five languages and six cultural settings. Using various configurations (zero-shot, one-shot, and fine-tuning), we evaluate the performance of LLMs in detecting and generating deceptive text. In detection tasks, our results reveal cross-model and cross-context performance differences. In generation tasks, linguistic analyses show partial alignment with known deception cues in human text, though this knowledge appears largely uniform and context-agnostic.</abstract>
      <url hash="19bb1cb8">2025.ranlp-1.101</url>
      <bibkey>papantoniou-etal-2025-evaluating</bibkey>
    </paper>
    <paper id="102">
      <title>Annotating Hate Speech towards Identity Groups</title>
      <author><first>Donnie</first><last>Parent</last></author>
      <author><first>Nina</first><last>Georgiades</last></author>
      <author><first>Charvi</first><last>Mishra</last></author>
      <author><first>Khaled</first><last>Mohammed</last></author>
      <author id="sandra-kubler"><first>Sandra</first><last>Kübler</last></author>
      <pages>894–899</pages>
      <abstract>Detecting hate speech, especially implicit hate speech, is a difficult task. We focus on annotating implicit hate targeting identity groups. We describe our dataset, which is a subset of AbuseEval (Caselli et al., 2020) and our annotation process for implicit identity hate. We annotate the type of abuse, the type of identity abuse, and the target identity group. We then discuss cases that annotators disagreed on and provide dataset statistics. Finally, we calculate our inter-annotator agreement.</abstract>
      <url hash="0f724a9d">2025.ranlp-1.102</url>
      <bibkey>parent-etal-2025-annotating</bibkey>
    </paper>
    <paper id="103">
      <title>On the Interaction of Identity Hate Classification and Data Bias</title>
      <author><first>Donnie</first><last>Parent</last></author>
      <author><first>Nina</first><last>Georgiades</last></author>
      <author><first>Charvi</first><last>Mishra</last></author>
      <author><first>Khaled</first><last>Mohammed</last></author>
      <author id="sandra-kubler"><first>Sandra</first><last>Kübler</last></author>
      <pages>900–906</pages>
      <abstract>Hate speech detection is a task where machine learning models tend to be limited by the biases introduced by the dataset. We use two existing datasets of hate speech towards identity groups, the one by Wiegand et al. (2022) and a reannotated subset of the data in AbuseEval (Caselli et al. 2020). Since the data by Wiegand et al. (2022) were collected using one syntactic pattern, there exists a possible syntactic bias in this dataset. We test whether there exists such a bias by using a more syntactically general dataset for testing. Our findings show that classifiers trained on the dataset with the syntactic bias and tested on a less constrained dataset suffer from a loss in performance in the order of 20 points. Further experiments show that this drop can only be partly attributed to a shift in identity groups between datasets.</abstract>
      <url hash="f26fabd0">2025.ranlp-1.103</url>
      <bibkey>parent-etal-2025-interaction</bibkey>
    </paper>
    <paper id="104">
      <title>Financial News as a Proxy of <fixed-case>E</fixed-case>uropean Central Bank Interest Rate Adjustments</title>
      <author><first>Davide</first><last>Paris</last></author>
      <author><first>Martina</first><last>Menzio</last></author>
      <author><first>Elisabetta</first><last>Fersini</last></author>
      <pages>907–914</pages>
      <abstract>This paper examines the relationship between news coverage and the European Central Bank’s (ECB) interest rate decisions. In particular, the hypothesis of a linear relationship between financial news and ECB indications regarding interest rate variations is investigated by leveraging state-of-the-art large language models combined with domain experts and automatically selected keywords. The analysis revealed two key findings related to how news contents can signal the ECB’s decisions to raise or lower interest rates: (1) Sentence Transformer models, when combined with domain-specific keywords, exhibit a higher correlation with ECB decisions than state-of-the-art financial BERT architectures; (2) employing a grid search strategy to select subsets of informative keywords strengthened the relationships between news contents and ECB’s decisions, highlighting how media narratives can anticipate or reflect central bank policy actions.</abstract>
      <url hash="e42a26ed">2025.ranlp-1.104</url>
      <bibkey>paris-etal-2025-financial</bibkey>
    </paper>
    <paper id="105">
      <title>Generating and Analyzing Disfluency in a Code-Mixed Setting</title>
      <author><first>Aryan</first><last>Paul</last></author>
      <author><first>Tapabrata</first><last>Mondal</last></author>
      <author><first>Dipankar</first><last>Das</last></author>
      <author id="sivaji-bandyopadhyay"><first>Sivaji</first><last>Bandyopadhyay</last></author>
      <pages>915–924</pages>
      <abstract>This work explores the intersection of code-mixing and disfluency in bilingual speech and text, with a focus on understanding how large language models (LLMs) handle code-mixed disfluent utterances. One of the primary objectives is to explore LLMs’ ability to generate code-mixed disfluent sentences and to address the lack of high-quality code-mixed disfluent corpora, particularly for Indic languages. We aim to compare the performance of LLM-based approaches with traditional disfluency detection methods and to develop novel metrics for quantitatively assessing disfluency phenomena. Additionally, we investigate the relationship between code-mixing and disfluency, exploring how factors such as switching frequency and direction influence the occurrence of disfluencies. By analyzing these intriguing dynamics, we seek to gain a deeper understanding of the mutual influence between code-mixing and disfluency in multilingual speech.</abstract>
      <url hash="cb163703">2025.ranlp-1.105</url>
      <bibkey>paul-etal-2025-generating</bibkey>
    </paper>
    <paper id="106">
      <title>A Low-Resource Speech-Driven <fixed-case>NLP</fixed-case> Pipeline for <fixed-case>S</fixed-case>inhala Dyslexia Assistance</title>
      <author><first>Peshala Sandali</first><last>Perera</last></author>
      <author><first>Deshan Koshala</first><last>Sumanathilaka</last></author>
      <pages>925–933</pages>
      <abstract>Dyslexia in adults remains an under-researched and under-served area, particularly in non-English-speaking contexts, despite its significant impact on personal and professional lives. This work addresses that gap by focusing on Sinhala, a low-resource language with limited tools for linguistic accessibility. We present an assistive system designed specifically for Sinhala-speaking adults with dyslexia. The system integrates Whisper for speech-to-text conversion, SinBERT a open sourced fine-tuned BERT model trained for Sinhala to identify common dyslexic errors, and a combined mT5 and Mistral-based model to generate corrected text. Finally, the output is converted back to speech using gTTS, creating a complete multi modal feedback loop. Despite the challenges posed by limited Sinhala-language datasets, the system achieves 66% transcription accuracy and 70% correction accuracy with 65% overall system accuracy. These results demonstrate both the feasibility and effectiveness of the approach. Ultimately, this work highlights the importance of inclusive NLP technologies in underrepresented languages and showcases a practical step toward improving accessibility for adult dyslexic users.</abstract>
      <url hash="23713247">2025.ranlp-1.106</url>
      <bibkey>perera-sumanathilaka-2025-low</bibkey>
    </paper>
    <paper id="107">
      <title>Evaluating Transliteration Ambiguity in Adhoc <fixed-case>R</fixed-case>omanized <fixed-case>S</fixed-case>inhala: A Dataset for Transliteration Disambiguation</title>
      <author><first>Sandun Sameera</first><last>Perera</last></author>
      <author><first>Deshan Koshala</first><last>Sumanathilaka</last></author>
      <pages>934–942</pages>
      <abstract>This paper introduces the first Transliteration disambiguation (TD) dataset for Romanized Sinhala, informally known as Singlish, developed to address the challenge of transliteration ambiguity in backwards transliteration tasks. The dataset covers 22 ambiguous Romanized Sinhala words, each mapping to two distinct Sinhala meanings, and provides 30 Romanized sentences per word: ten for each meaning individually and ten containing both meanings in context. Sentences were initially collected through web scraping and later post-processed using the Claude language model, which offers strong support for Sinhala, alongside a rule-based Romanization process to ensure linguistic quality and consistency. To demonstrate its applicability, the dataset was used to evaluate four existing back-transliteration systems, highlighting their performance in resolving context-sensitive ambiguities. Baseline evaluations confirm the dataset’s effectiveness in assessing transliteration systems’ ability to handle transliteration ambiguity, offering a valuable resource for advancing TD and transliteration research for Sinhala.</abstract>
      <url hash="5b21cede">2025.ranlp-1.107</url>
      <bibkey>perera-sumanathilaka-2025-evaluating</bibkey>
    </paper>
    <paper id="108">
      <title>Detecting Deception in Disinformation across Languages: The Role of Linguistic Markers</title>
      <author><first>Alba</first><last>Perez-Montero</last></author>
      <author><first>Silvia</first><last>Gargova</last></author>
      <author><first>Elena</first><last>Lloret</last></author>
      <author id="paloma-moreda-pozo"><first>Paloma</first><last>Moreda Pozo</last></author>
      <pages>943–952</pages>
      <abstract>The unstoppable proliferation of news driven by the rise of digital media has intensified the challenge of news verification. Natural Language Processing (NLP) offers solutions, primarily through content and context analysis. Recognizing the vital role of linguistic analysis, this paper presents a multilingual study of linguistic markers for automated deceptive fake news detection across English, Spanish, and Bulgarian. We compiled datasets in these languages to extract and analyze both general and specific linguistic markers. We then performed feature selection using the <i>SelectKBest</i> algorithm, applying it to various classification models with different combinations of general and specific linguistic markers. The results show that Logistic Regression and Support Vector Machine classification models achieved F1-scores above 0.8 for English and Spanish. For Bulgarian, Random Forest yielded the best results with an F1-score of 0.73. While these markers demonstrate potential for transferability to other languages, results may vary due to inherent linguistic characteristics. This necessitates further experimentation, especially in low-resource languages like Bulgarian. These findings highlight the significant potential of our dataset and linguistic markers for multilingual deceptive news detection.</abstract>
      <url hash="72ea303e">2025.ranlp-1.108</url>
      <bibkey>perez-montero-etal-2025-detecting</bibkey>
    </paper>
    <paper id="109">
      <title>Enhancing Transformer-Based Rerankers with Synthetic Data and <fixed-case>LLM</fixed-case>-Based Supervision</title>
      <author><first>Dimitar</first><last>Peshevski</last></author>
      <author><first>Kiril</first><last>Blazhevski</last></author>
      <author><first>Martin</first><last>Popovski</last></author>
      <author><first>Gjorgji</first><last>Madjarov</last></author>
      <pages>953–961</pages>
      <abstract>Effective document reranking is essential for improving search relevance across diverse applications. While Large Language Models (LLMs) excel at reranking due to their deep semantic understanding and reasoning, their high computational cost makes them impractical for many real-world deployments. Fine-tuning smaller, task-specific models is a more efficient alternative but typically depends on scarce, manually labeled data. To overcome this, we propose a novel pipeline that eliminates the need for human-labeled query-document pairs. Our method uses LLMs to generate synthetic queries from domain-specific corpora and employs an LLM-based classifier to label positive and hard-negative pairs. This synthetic dataset is then used to fine-tune a smaller transformer model with contrastive learning using Localized Contrastive Estimation (LCE) loss. Experiments on the MedQuAD dataset show that our approach significantly boosts in-domain performance and generalizes well to out-of-domain tasks. By using LLMs for data generation and supervision rather than inference, we reduce computational costs while maintaining strong reranking capabilities.</abstract>
      <url hash="6a2d086e">2025.ranlp-1.109</url>
      <bibkey>peshevski-etal-2025-enhancing</bibkey>
    </paper>
    <paper id="110">
      <title><fixed-case>Q</fixed-case>&amp;<fixed-case>A</fixed-case>-<fixed-case>LF</fixed-case> : A <fixed-case>F</fixed-case>rench Question-Answering Benchmark for Measuring Fine-Grained Lexical Knowledge</title>
      <author><first>Alexander</first><last>Petrov</last></author>
      <author><first>Alessandra Thais</first><last>Mancas</last></author>
      <author><first>Viviane</first><last>Binet</last></author>
      <author><first>Antoine</first><last>Venant</last></author>
      <author><first>Francois</first><last>Lareau</last></author>
      <author><first>Yves</first><last>Lepage</last></author>
      <author id="philippe-langlais"><first>Phillippe</first><last>Langlais</last></author>
      <pages>962–969</pages>
      <abstract>We introduce Q&amp;A-LF, a French, question-answering benchmark designed to assess the extent to which large language models capture fine-grained lexical knowledge. We investigate the ability of ChatGPT-4o mini, Qwen2.5-14B, Llama3.0-8B, and Llama3.1-8B to answer questions based on lexical functions from Meaning-Text Theory. Using various prompting setups with different levels of examples and context, we find that Qwen and ChatGPT generally outperform Llama models, achieving up to 70% accuracy, while Llama models reach just above 60%. We identify LFs that are particularly easy or especially challenging for the models. We further investigate whether providing sentence-level context and one-shot prompting improve performance, especially on semantically complex functions.</abstract>
      <url hash="25f73a03">2025.ranlp-1.110</url>
      <bibkey>petrov-etal-2025-q</bibkey>
    </paper>
    <paper id="111">
      <title>Analysis of Vocabulary and Subword Tokenization Settings for Optimal Fine-tuning of <fixed-case>MT</fixed-case>: A Case Study of In-domain Translation</title>
      <author><first>Javad</first><last>Pourmostafa Roshan Sharami</last></author>
      <author><first>Dimitar</first><last>Shterionov</last></author>
      <author><first>Pieter</first><last>Spronck</last></author>
      <pages>970–979</pages>
      <abstract>The choice of vocabulary and subword (SW) tokenization has a significant impact on both training and fine-tuning of language and translation models. Fine-tuning is a common practice in optimizing a model with respect to new data. However, new data potentially introduces new words (or tokens), which, if not considered, may lead to suboptimal performance. In addition, the distribution of tokens in the new data can differ from the distribution of the original data. As such, the original SW tokenization model could be less suitable for the new data. With this work, we aim to gain better insights on the impact of SW tokenization and vocabulary generation on the performance of neural machine translation (NMT) models fine-tuned to a specific domain. To do so, we compare several strategies for SW tokenization and vocabulary generation and investigate the performance of the resulting models. Our findings show that the best way to fine-tune for domain adaptation is to consistently use both BPE and vocabulary from the in-domain data, which helps the model pick up on important domain-specific terms. At the same time, it is crucial not to lose sight of the vocabulary of the base (pre-trained) model—maintaining coverage of this vocabulary ensures the model keeps its general language abilities. The most successful configurations are those that introduce plenty of frequent domain terms while still retaining a substantial portion of the base model vocabulary, leading to noticeably better translation quality and adaptation, as seen in higher BLEU scores. These benefits, however, often come with greater computational costs, such as longer training times, since the model must learn more new tokens. Conversely, approaches that skip important domain terms or combine mismatched tokenization and vocabulary do not perform as well, making it clear that both domain-specific adaptation and broad vocabulary coverage matter—and that these gains are realized when the vocabulary preserves a good portion of the base (pre-trained) model. While using in-domain BPE and vocabulary yields the best domain adaptation, it substantially reduces out-of-domain translation quality. Hybrid configurations that combine base and domain vocabularies help balance this trade-off, maintaining broader translation capabilities alongside improved domain performance.</abstract>
      <url hash="aa59e1e1">2025.ranlp-1.111</url>
      <bibkey>pourmostafa-roshan-sharami-etal-2025-analysis</bibkey>
    </paper>
    <paper id="112">
      <title><fixed-case>LLM</fixed-case>-based Embedders for Prior Case Retrieval</title>
      <author><first>Damith</first><last>Premasiri</last></author>
      <author><first>Tharindu</first><last>Ranasinghe</last></author>
      <author id="ruslan-mitkov"><first>Ruslan</first><last>Mitkov</last></author>
      <pages>980–988</pages>
      <abstract>In common law systems, legal professionals such as lawyers and judges rely on precedents to build their arguments. As the volume of cases has grown massively over time, effectively retrieving prior cases has become essential. Prior case retrieval (PCR) is an information retrieval (IR) task that aims to automatically identify the most relevant court cases for a specific query from a large pool of potential candidates. While IR methods have seen several paradigm shifts over the last few years, the vast majority of PCR methods continue to rely on traditional IR methods, such as BM25. The state-of-the-art deep learning IR methods have not been successful in PCR due to two key challenges: i. Lengthy legal text limitation; when using the powerful BERT-based transformer models, there is a limit of input text lengths, which inevitably requires to shorten the input via truncation or division with a loss of legal context information. ii. Lack of legal training data; due to data privacy concerns, available PCR datasets are often limited in size, making it difficult to train deep learning-based models effectively. In this research, we address these challenges by leveraging LLM-based text embedders in PCR. LLM-based embedders support longer input lengths, and since we use them in an unsupervised manner, they do not require training data, addressing both challenges simultaneously. In this paper, we evaluate state-of-the-art LLM-based text embedders in four PCR benchmark datasets and show that they outperform BM25 and supervised transformer-based models.</abstract>
      <url hash="a7c10fc8">2025.ranlp-1.112</url>
      <bibkey>premasiri-etal-2025-llm</bibkey>
    </paper>
    <paper id="113">
      <title>Exploiting Primacy Effect to Improve Large Language Models</title>
      <author><first>Bianca</first><last>Raimondi</last></author>
      <author><first>Maurizio</first><last>Gabbrielli</last></author>
      <pages>989–997</pages>
      <abstract>Large Language Models (LLMs) have become essential in many Natural Language Processing (NLP) tasks, leveraging extensive pre-training and fine-tuning to achieve high accuracy. However, like humans, LLMs exhibit biases, particularly positional biases such as primacy and recency effects, which can influence the accuracy of the answers. The primacy effect—where items presented first are more likely to be remembered or selected—plays a key role in Multiple Choice Question Answering (MCQA), where the order of answer options can affect prediction outcomes. This study focuses on primacy bias in fine-tuned LLMs: We first show that fine-tuning amplifies this bias, probably due to exposure to human-like patterns. Hence, we strategically leverage this effect, by reordering response options on the basis of semantic similarity to the query - without requiring knowledge of the correct answer. Our experimental results show that this approach significantly improves performance in MCQA. More generally, our findings underscore the dual nature of biases as both challenges and opportunities, offering insights for bias-aware model design and NLP applications.</abstract>
      <url hash="36dae2b0">2025.ranlp-1.113</url>
      <bibkey>raimondi-gabbrielli-2025-exploiting</bibkey>
    </paper>
    <paper id="114">
      <title>Alankaar: A Dataset for Figurativeness Understanding in <fixed-case>B</fixed-case>angla</title>
      <author><first>Geetanjali</first><last>Rakshit</last></author>
      <author><first>Jeffrey</first><last>Flanigan</last></author>
      <pages>998–1002</pages>
      <abstract>Bangla has a rich written literature, automatically making it replete with examples of creative usage of language. There have been limited efforts to computationally analyze creative text in the Bangla language due to a lack of resources. We present Alankaar, a dataset of 2500 manually annotated examples of text fragments in Bangla containing metaphors. We also provide automatic and manual English translations of these examples. Additionally, we provide 2500 examples of non-metaphorical text in Bangla. We use this dataset to build a metaphor identification system in Bangla. We also use it as a test bed for cross-lingual metaphor translation, finding that not all metaphors translate literally across languages and there are several cultural factors at play in the translation of metaphors. We hope this will advance the field in metaphor translation research and in grounding cultural nuances at work in the process of machine translation.</abstract>
      <url hash="443f414c">2025.ranlp-1.114</url>
      <bibkey>rakshit-flanigan-2025-alankaar</bibkey>
    </paper>
    <paper id="115">
      <title><fixed-case>ASQ</fixed-case>: Automatically Generating Question-Answer Pairs Using <fixed-case>AMR</fixed-case>s</title>
      <author><first>Geetanjali</first><last>Rakshit</last></author>
      <author><first>Jeffrey</first><last>Flanigan</last></author>
      <pages>1003–1011</pages>
      <abstract>We introduce ASQ, a tool to automatically mine questions and answers from a sentence using the Abstract Meaning Representation (AMR). Previous work has used question-answer pairs to specify the predicate-argument structure of a sentence using natural language, which does not require linguistic expertise or training, and created datasets such as QA-SRL and QAMR, for which the question-answer pair annotations were crowdsourced. Our goal is to build a tool (ASQ) that maps from the traditional meaning representation AMR to a question-answer meaning representation (QMR). This enables construction of QMR datasets automatically in various domains using existing high-quality AMR parsers, and provides an automatic mapping AMR to QMR for ease of understanding by non-experts. A qualitative evaluation of the output generated by ASQ from the AMR 2.0 data shows that the question-answer pairs are natural and valid, and demonstrate good coverage of the content. We run ASQ on the sentences from the QAMR dataset, to observe that the semantic roles in QAMR are also captured by ASQ. We intend to make this tool and the results publicly available for others to use and build upon.</abstract>
      <url hash="a1c46295">2025.ranlp-1.115</url>
      <bibkey>rakshit-flanigan-2025-asq</bibkey>
    </paper>
    <paper id="116">
      <title>Multi-<fixed-case>LLM</fixed-case> Verification for Question Answering under Conflicting Contexts</title>
      <author><first>Geetanjali</first><last>Rakshit</last></author>
      <author><first>Jeffrey</first><last>Flanigan</last></author>
      <pages>1012–1021</pages>
      <abstract>Open-domain question answering (ODQA) often requires models to resolve conflicting evidence retrieved from diverse sources—a task that remains challenging even for state-of-the-art large language models (LLMs). While single-agent techniques such as self-verification and self-consistency have shown promise across natural language understanding and generation tasks, and multi-agent approaches involving collaborative or competitive strategies have recently emerged, their effectiveness for ODQA in the presence of conflicting contexts remains underexplored. In this work, we investigate these techniques using the QACC dataset as a case study. We find that incorporating a multi-agent verification step—where the best answer is selected from among outputs generated by different LLMs—leads to improved performance. Interestingly, we also observe that requiring explanations during the verification step does not always improve answer quality. Our experiments evaluate three strong LLMs (GPT-4o, Claude 4, and DeepSeek-R1) across a range of prompting and verification baselines.</abstract>
      <url hash="852d215b">2025.ranlp-1.116</url>
      <bibkey>rakshit-flanigan-2025-multi</bibkey>
    </paper>
    <paper id="117">
      <title>Comparative Analysis of Human and Large Language Model Performance in Pharmacology Multiple-Choice Questions</title>
      <author><first>Ricardo</first><last>Rodriguez</last></author>
      <author><first>Stéphane</first><last>Huet</last></author>
      <author id="benoit-favre"><first>Benoît</first><last>Favre</last></author>
      <author><first>Mickael</first><last>Rouvier</last></author>
      <pages>1022–1029</pages>
      <abstract>In this article, we study the answers generated by a selection of Large Language Models to a set of Multiple Choice Questions in Pharmacology, and compare them to the answers provided by students, to understand which questions in this clinical domain are difficult for the models when compared to humans and why. We extract the internal logits to infer probability distributions and analyse the main features that determine the difficulty of questions using statistical methods. We also provide an extension to the FrenchMedMCQA dataset, with pairs of question-answers in pharmacology, enriched with student response rate, answer scoring, clinical topics, and annotations on question structure and semantics.</abstract>
      <url hash="979f5aaa">2025.ranlp-1.117</url>
      <bibkey>rodriguez-etal-2025-comparative</bibkey>
    </paper>
    <paper id="118">
      <title>Enhancing Textual Understanding: Automated Claim Span Identification in <fixed-case>E</fixed-case>nglish, <fixed-case>H</fixed-case>indi, <fixed-case>B</fixed-case>engali, and <fixed-case>C</fixed-case>ode<fixed-case>M</fixed-case>ix</title>
      <author><first>Rudra</first><last>Roy</last></author>
      <author><first>Pritam</first><last>Pal</last></author>
      <author><first>Dipankar</first><last>Das</last></author>
      <author><first>Saptarshi</first><last>Ghosh</last></author>
      <author><first>Biswajit</first><last>Paul</last></author>
      <pages>1030–1035</pages>
      <abstract>Claim span identification, a crucial task in Natural Language Processing (NLP), aims to extract specific claims from texts. Such claim spans can be further utilized in various critical NLP applications, such as claim verification, fact-checking, and opinion mining, among others. The present work proposes a multilingual claim span identification framework for handling social media data in English, Hindi, Bengali, and CodeMixed texts, leveraging the strengths and knowledge of transformer-based pre-trained models. Our proposed framework efficiently identifies the contextual relationships between words and precisely detects claim spans across all languages, achieving a high F1 score and Jaccard score. The source code and datasets are available at: https://github.com/pritampal98/claim-span-multilingual</abstract>
      <url hash="e97bfb3e">2025.ranlp-1.118</url>
      <bibkey>roy-etal-2025-enhancing</bibkey>
    </paper>
    <paper id="119">
      <title>Detecting Fake News in the Era of Language Models</title>
      <author><first>Muhammad Irfan Fikri</first><last>Sabri</last></author>
      <author><first>Hansi</first><last>Hettiarachchi</last></author>
      <author><first>Tharindu</first><last>Ranasinghe</last></author>
      <pages>1036–1043</pages>
      <abstract>The proliferation of fake news has been amplified by the advent of large language models (LLMs), which can generate highly realistic and scalable misinformation. While prior studies have focused primarily on detecting human-generated fake news, the efficacy of current models against LLM-generated content remains underexplored. We address this gap by compiling a novel dataset combining public and LLM-generated fake news, redefining detection as a ternary classification task (real, human-generated fake, LLM-generated fake), and evaluating eight diverse classification models, including traditional machine learning, fine-tuned transformers, and few-shot prompted LLMs. Our findings highlight the strengths and limitations of these models in detecting evolving LLM-generated fake news, offering insights for future detection strategies.</abstract>
      <url hash="09ff5c53">2025.ranlp-1.119</url>
      <bibkey>sabri-etal-2025-detecting</bibkey>
    </paper>
    <paper id="120">
      <title>Cyberbullying Detection via Aggression-Enhanced Prompting</title>
      <author><first>Aisha</first><last>Saeid</last></author>
      <author><first>Anu</first><last>Sabu</last></author>
      <author><first>Girish</first><last>Koushik</last></author>
      <author><first>Ferrante</first><last>Neri</last></author>
      <author><first>Diptesh</first><last>Kanojia</last></author>
      <pages>1044–1052</pages>
      <abstract>Detecting cyberbullying on social media remains a critical challenge due to its subtle and varied expressions. This study investigates whether integrating aggression detection as an auxiliary task within a unified training framework can enhance the generalisation and performance of large language models (LLMs) in cyberbullying detection. Experiments are conducted on five aggression datasets and one cyberbullying dataset using instruction-tuned LLMs. We evaluated multiple strategies: zero-shot, few-shot, independent LoRA fine-tuning, and multi-task learning (MTL). Given the inconsistent results of MTL, we propose an enriched prompt pipeline approach in which aggression predictions are embedded into cyberbullying detection prompts to provide contextual augmentation. Preliminary results show that the enriched prompt pipeline consistently outperforms standard LoRA fine-tuning, indicating that aggression-informed context significantly boosts cyberbullying detection. This study highlights the potential of auxiliary tasks, such as aggression detection, to improve the generalisation of LLMs for safety-critical applications on social networks.</abstract>
      <url hash="8d34c500">2025.ranlp-1.120</url>
      <bibkey>saeid-etal-2025-cyberbullying</bibkey>
    </paper>
    <paper id="121">
      <title>Lingdex.org:Leveraging <fixed-case>LLM</fixed-case>s to Structure and Explore Linguistic Olympiad Puzzles for Learning and Teaching Linguistics</title>
      <author><first>Jonathan</first><last>Sakunkoo</last></author>
      <author><first>Annabella</first><last>Sakunkoo</last></author>
      <pages>1053–1057</pages>
      <abstract>Linguistics Olympiad puzzles provide a valuable but underutilized resource for teaching linguistic reasoning, typology, and cross-cultural understanding. Many of these puzzles feature endangered and low-resource languages and thus offer a rare opportunity to integrate linguistic diversity into education at a time when over 40% of the world’s languages face extinction. This paper presents Lingdex, a novel web-based platform that leverages large language models (LLMs) to classify, organize, and enliven Linguistics Olympiad problems across various linguistic categories such as syntax, morphology, semantics, phonology, and language families. By applying NLP techniques to the multilingual and multicultural corpora of linguistics puzzles drawn from international and national Olympiads, Lingdex supports language and linguistics education, problem-based learning, and curriculum development. The visual, interactive platform also includes problems based on endangered and rare languages to raise awareness and interest in linguistic diversity. We present results from a user study that shows increased learner interest and appreciation for global linguistic richness.</abstract>
      <url hash="bd2f0d25">2025.ranlp-1.121</url>
      <bibkey>sakunkoo-sakunkoo-2025-lingdex</bibkey>
    </paper>
    <paper id="122">
      <title>When Does Language Transfer Help? Sequential Fine-Tuning for Cross-Lingual Euphemism Detection</title>
      <author><first>Julia</first><last>Sammartino</last></author>
      <author><first>Libby</first><last>Barak</last></author>
      <author><first>Jing</first><last>Peng</last></author>
      <author><first>Anna</first><last>Feldman</last></author>
      <pages>1058–1065</pages>
      <abstract>Euphemisms are culturally variable and often ambiguous, posing challenges for language models, especially in low-resource settings. This paper investigates how cross-lingual transfer via sequential fine-tuning affects euphemism detection across five languages: English, Spanish, Chinese, Turkish, and Yorùbá. We compare sequential fine-tuning with monolingual and simultaneous fine-tuning using XLM-R and mBERT, analyzing how performance is shaped by language pairings, typological features, and pretraining coverage. Results show that sequential fine-tuning with a high-resource L1 improves L2 performance, especially for low-resource languages like Yorùbá and Turkish. XLM-R achieves larger gains but is more sensitive to pretraining gaps and catastrophic forgetting, while mBERT yields more stable, though lower, results. These findings highlight sequential fine-tuning as a simple yet effective strategy for improving euphemism detection in multilingual models, particularly when low-resource languages are involved.</abstract>
      <url hash="bccfc31c">2025.ranlp-1.122</url>
      <bibkey>sammartino-etal-2025-language</bibkey>
    </paper>
    <paper id="123">
      <title>Modelling the Relative Contributions of Stylistic Features in Forensic Authorship Attribution</title>
      <author><first>G. Çağatay</first><last>Sat</last></author>
      <author><first>John</first><last>Blake</last></author>
      <author><first>Evgeny</first><last>Pyshkin</last></author>
      <pages>1066–1073</pages>
      <abstract>This paper explores the extent to which stylistic features contribute to the task of authorship attribution in forensic contexts. Drawing on a filtered subset of the Enron email corpus, the study operationalizes stylistic indicators across four groups: lexical, syntactic, orthographic, and discoursal. Using R Programming Language for feature engineering and logistic regression modelling, we systematically assessed both the individual and interactive effects of these features on attribution accuracy. Results show that n-gram similarity consistently outperformed all other features, with the combined model of n-gram similarity and its interaction with other features achieving accuracy, precision and F1 scores of 91.6%, 93.3% and 91.7% respectively. The model was subsequently evaluated on a subset of the TEL corpus to assess its applicability in a forensic setting. The findings highlight the dominant role of lexical similarity and suggest that integrating interaction effects can yield further performance gains in forensic authorship analysis.</abstract>
      <url hash="9794474a">2025.ranlp-1.123</url>
      <bibkey>sat-etal-2025-modelling</bibkey>
    </paper>
    <paper id="124">
      <title>The Hidden Cost of Structure: How Constrained Decoding Affects Language Model Performance</title>
      <author><first>Maximilian</first><last>Schall</last></author>
      <author><first>Gerard</first><last>de Melo</last></author>
      <pages>1074–1084</pages>
      <abstract>Large Language Models excel at generating fluent text, but real-world applications increasingly demand structured outputs like JSON that can be programmatically processed. While prior work examines either task performance or format compliance in isolation, we investigate their interaction through comprehensive experiments across 11 models and multiple benchmarks. We uncover a fundamental divergence between base and instruction-tuned models under structural constraints. Base models often benefit from constrained decoding, producing more precise outputs, while instruction-tuned models frequently suffer performance degradation on generation tasks despite maintaining stability on classification tasks. Our log probability analysis reveals the underlying mechanism: constrained decoding forces models away from their preferred natural language patterns into lower-confidence structured alternatives. We demonstrate that successful constrained generation requires both adapted prompts and sufficient few-shot examples, with constrained models showing steeper performance gains from additional demonstrations compared to unconstrained generation. Notably, we find that base model performance under constraints can serve as an early indicator of post-training structured output capabilities, offering a practical evaluation tool for model development. These findings suggest that current instruction-tuning practices may inadvertently reduce models’ structured output capabilities and highlight the need for training-time integration of structural constraints in future model development.</abstract>
      <url hash="57a6305b">2025.ranlp-1.124</url>
      <bibkey>schall-de-melo-2025-hidden</bibkey>
    </paper>
    <paper id="125">
      <title>A Question-Answering Based Framework/Metric for Evaluation of Newspaper Article Summarization</title>
      <author><first>Vasanth</first><last>Seemakurthy</last></author>
      <author><first>Shashank</first><last>Sundar</last></author>
      <author><first>Siddharth</first><last>Arvind</last></author>
      <author><first>Siddhant</first><last>Jagdish</last></author>
      <author><first>Ashwini M.</first><last>Joshi</last></author>
      <pages>1085–1089</pages>
      <abstract>Condensed summaries of newspaper articles cater to the modern need for easily digestible content amid shrinking attention spans. However, current summarization systems often produce extracts failing to capture the essence of original articles. Traditional evaluation metrics like ROUGE also provide limited insights into whether key information is preserved in the summaries. To address this, we propose a pipeline to generate high-quality summaries tailored for newspaper articles and evaluate them using a question-answering based metric. Our system segments input newspaper images, extracts text, and generates summaries. We also generate relevant questions from the original articles and use a question-answering model to assess how well the summaries can answer these queries to evaluate summary quality beyond just lexical overlap. Experiments on real-world data show the potential effectiveness of our approach in contrast to conventional metrics. Our framework holds promise for enabling reliable news summary generation and evaluation systems.</abstract>
      <url hash="c6cf30ae">2025.ranlp-1.125</url>
      <bibkey>seemakurthy-etal-2025-question</bibkey>
    </paper>
    <paper id="126">
      <title>Efficient Financial Fraud Detection on Mobile Devices Using Lightweight Large Language Models</title>
      <author><first>Lakpriya</first><last>Senevirathna</last></author>
      <author><first>Deshan Koshala</first><last>Sumanathilaka</last></author>
      <pages>1090–1098</pages>
      <abstract>The growth of mobile financial transactions presents new challenges for fraud detection, where traditional and ML methods often miss emerging patterns. While Large Language Models (LLMs) offer advanced language understanding, they are typically too resource-intensive for mobile deployment and raise privacy concerns due to cloud reliance. This paper proposes a lightweight, privacy-preserving approach by fine-tuning and quantizing compact LLMs for on-device fraud detection from textual data. Models were optimized using Open Neural Network Exchange (ONNX) conversion and quantization to ensure efficiency. The fine-tuned quantized Llama-160M-Chat-v1 (bnb4) achieved 99.47% accuracy with a 168MB footprint, while fine-tuned quantized Qwen1.5-0.5B-Chat (bnb4) reached 99.50% accuracy at 797MB. These results demonstrate that optimized LLMs can deliver accurate, real-time fraud detection on mobile devices without compromising user privacy.</abstract>
      <url hash="85c8d99f">2025.ranlp-1.126</url>
      <bibkey>senevirathna-sumanathilaka-2025-efficient</bibkey>
    </paper>
    <paper id="127">
      <title>Contextual Cues in Machine Translation: Investigating the Potential of Multi-Source Input Strategies in <fixed-case>LLM</fixed-case>s and <fixed-case>NMT</fixed-case> Systems</title>
      <author><first>Lia</first><last>Shahnazaryan</last></author>
      <author><first>Patrick</first><last>Simianer</last></author>
      <author><first>Joern</first><last>Wuebker</last></author>
      <pages>1099–1108</pages>
      <abstract>We explore the impact of multi-source input strategies on machine translation (MT) quality, comparing GPT-4o, a large language model (LLM), with a traditional multilingual neural machine translation (NMT) system. Using intermediate language translations as contextual cues, we evaluate their effectiveness in enhancing English and Chinese translations into Portuguese. Results suggest that contextual information significantly improves translation quality for domain-specific datasets and potentially for linguistically distant language pairs, with diminishing returns observed in benchmarks with high linguistic variability. Additionally, we demonstrate that shallow fusion, a multi-source approach we apply within the NMT system, shows improved results when using high-resource languages as context for other translation pairs, highlighting the importance of strategic context language selection.</abstract>
      <url hash="b8043b0f">2025.ranlp-1.127</url>
      <bibkey>shahnazaryan-etal-2025-contextual</bibkey>
    </paper>
    <paper id="128">
      <title>Exposing Pink Slime Journalism: Linguistic Signatures and Robust Detection against <fixed-case>LLM</fixed-case>-Generated Threats</title>
      <author><first>Sadat</first><last>Shahriar</last></author>
      <author><first>Navid</first><last>Ayoobi</last></author>
      <author><first>Arjun</first><last>Mukherjee</last></author>
      <author><first>Mostafa</first><last>Musharrat</last></author>
      <author><first>Sai Vishnu Vamsi</first><last>Senagasetty</last></author>
      <pages>1109–1117</pages>
      <abstract>The local news landscape, a vital source of reliable information for 28 million Americans, faces a growing threat from Pink Slime Journalism, a low-quality, auto-generated articles that mimic legitimate local reporting. Detecting these deceptive articles requires a fine-grained analysis of their linguistic, stylistic, and lexical characteristics. In this work, we conduct a comprehensive study to uncover the distinguishing patterns of Pink Slime content and propose detection strategies based on these insights. Beyond traditional generation methods, we highlight a new adversarial vector: modifications through large language models (LLMs). Our findings reveal that even consumer-accessible LLMs can significantly undermine existing detection systems, reducing their performance by up to 40% in F1-score. To counter this threat, we introduce a robust learning framework specifically designed to resist LLM-based adversarial attacks and adapt to the evolving landscape of automated pink slime journalism, and showed and improvement by up to 27%.</abstract>
      <url hash="bd92f493">2025.ranlp-1.128</url>
      <bibkey>shahriar-etal-2025-exposing</bibkey>
    </paper>
    <paper id="129">
      <title>The Erosion of <fixed-case>LLM</fixed-case> Signatures: Can We Still Distinguish Human and <fixed-case>LLM</fixed-case>-Generated Scientific Ideas after Iterative Paraphrasing?</title>
      <author><first>Sadat</first><last>Shahriar</last></author>
      <author><first>Navid</first><last>Ayoobi</last></author>
      <author><first>Arjun</first><last>Mukherjee</last></author>
      <pages>1118–1126</pages>
      <abstract>With the increasing reliance on LLMs as research agents, distinguishing between LLM and human-generated ideas has become crucial for understanding the cognitive nuances of LLMs’ research capabilities. While detecting LLM-generated text has been extensively studied, distinguishing human vs LLM-generated *scientific ideas* remains an unexplored area. In this work, we systematically evaluate the ability of state-of-the-art (SOTA) machine learning models to differentiate between human and LLM-generated ideas, particularly after successive paraphrasing stages. Our findings highlight the challenges SOTA models face in source attribution, with detection performance declining by an average of 25.4% after five consecutive paraphrasing stages. Additionally, we demonstrate that incorporating the research problem as contextual information improves detection performance by up to 2.97%. Notably, our analysis reveals that detection algorithms struggle significantly when ideas are paraphrased into a simplified, non-expert style, contributing the most to the erosion of distinguishable LLM signatures.</abstract>
      <url hash="b9dc4630">2025.ranlp-1.129</url>
      <bibkey>shahriar-etal-2025-erosion</bibkey>
    </paper>
    <paper id="130">
      <title>Deep Language Geometry: Constructing a Metric Space from <fixed-case>LLM</fixed-case> Weights</title>
      <author><first>Maksym</first><last>Shamrai</last></author>
      <author><first>Vladyslav</first><last>Hamolia</last></author>
      <pages>1127–1136</pages>
      <abstract>We introduce a novel framework that utilizes the internal weight activations of modern Large Language Models (LLMs) to construct a metric space of languages. Unlike traditional approaches based on hand-crafted linguistic features, our method automatically derives high-dimensional vector representations by computing weight importance scores via an adapted pruning algorithm. Our approach captures intrinsic language characteristics that reflect linguistic phenomena. We validate our approach across diverse datasets and multilingual LLMs, covering 106 languages. The results align well with established linguistic families while also revealing unexpected inter-language connections that may indicate historical contact or language evolution. The source code, computed language latent vectors, and visualization tool are made publicly available at https://github.com/mshamrai/deep-language-geometry.</abstract>
      <url hash="459a6dfd">2025.ranlp-1.130</url>
      <bibkey>shamrai-hamolia-2025-deep</bibkey>
    </paper>
    <paper id="131">
      <title>Cross-Lingual Fact Verification: Analyzing <fixed-case>LLM</fixed-case> Performance Patterns across Languages</title>
      <author><first>Hanna</first><last>Shcharbakova</last></author>
      <author><first>Tatiana</first><last>Anikina</last></author>
      <author><first>Natalia</first><last>Skachkova</last></author>
      <author id="josef-van-genabith"><first>Josef</first><last>van Genabith</last></author>
      <pages>1137–1147</pages>
      <abstract>Fact verification has emerged as a critical task in combating misinformation, yet most research remains focused on English-language applications. This paper presents a comprehensive analysis of multilingual fact verification capabilities across three state-of-the-art large language models: Llama 3.1, Qwen 2.5, and Mistral Nemo. We evaluate these models on the X-Fact dataset that includes 25 typologically diverse languages, examining both seen and unseen languages through various evaluation scenarios. Our analysis employs few-shot prompting and LoRA fine-tuning approaches, revealing significant performance disparities based on script systems, with Latin script languages consistently outperforming others. We identify systematic cross-lingual instruction following failures, particularly affecting languages with non-Latin scripts. Surprisingly, some officially supported languages, such as Indonesian and Polish, which are not high-resourced languages, achieve better performance than high-resource languages like German and Spanish, challenging conventional assumptions about resource availability and model performance. The results highlight critical limitations in current multilingual LLMs for the fact verification task and provide insights for developing more inclusive multilingual systems.</abstract>
      <url hash="9bbf06dc">2025.ranlp-1.131</url>
      <bibkey>shcharbakova-etal-2025-cross</bibkey>
    </paper>
    <paper id="132">
      <title><fixed-case>ESAQ</fixed-case>uery<fixed-case>R</fixed-case>ank: Ranking Query Interpretations for Document Retrieval Using Explicit Semantic Analysis</title>
      <author><first>Avijeet</first><last>Shil</last></author>
      <author><first>Wei</first><last>Jin</last></author>
      <pages>1148–1152</pages>
      <abstract>Representing query translation into relevant entities is a critical component of an infor- mation retrieval system. This paper proposes an unsupervised framework, ESAQueryRank, designed to process natural language queries by mapping n-gram phrases to Wikipedia ti- tles and ranking potential entity and phrase combinations using Explicit Semantic Analy- sis. Unlike previous approaches, this frame- work does not rely on query expansion, syn- tactic parsing, or manual annotation. Instead, it leverages Wikipedia metadata—such as ti- tles, redirects, disambiguation pages to dis- ambiguate entities and identify the most rel- evant ones based on cosine similarity in the ESA space. ESAQueryRank is evaluated using a random set of TREC questions and compared against a keyword-based approach and a context-based question translation model (CBQT). In all comparisons of full category types, ESAQueryRank consistently shows bet- ter results against both methods. Notably, the framework excels with more complex queries, achieving improvements in Mean Reciprocal Rank (MRR) of up to 480% for intricate queries like those beginning with “Why,” even without explicitly incorporating the question type. These results demonstrate that ESA- QueryRank is an effective, transparent, and domain-independent framework for building natural language interfaces.</abstract>
      <url hash="67ff412a">2025.ranlp-1.132</url>
      <bibkey>shil-jin-2025-esaqueryrank</bibkey>
    </paper>
    <paper id="133">
      <title>Personalized Author Obfuscation with Large Language Models</title>
      <author><first>Mohammad</first><last>Shokri</last></author>
      <author><first>Sarah Ita</first><last>Levitan</last></author>
      <author><first>Rivka</first><last>Levitan</last></author>
      <pages>1153–1162</pages>
      <abstract>In this paper, we investigate the efficacy of large language models (LLMs) in obfuscating authorship by paraphrasing and altering writing styles. Rather than adopting a holistic approach that evaluates performance across the entire dataset, we focus on user-wise performance to analyze how obfuscation effectiveness varies across individual authors. While LLMs are generally effective, we observe a bimodal distribution of efficacy, with performance varying significantly across users. To address this, we propose a personalized prompting method that outperforms standard prompting techniques and partially mitigates the bimodality issue.</abstract>
      <url hash="31a6d795">2025.ranlp-1.133</url>
      <bibkey>shokri-etal-2025-personalized</bibkey>
    </paper>
    <paper id="134">
      <title><fixed-case>B</fixed-case>ulgarian Event Extraction with <fixed-case>LLM</fixed-case>s</title>
      <author id="kiril-simov"><first>Kiril</first><last>Simov</last></author>
      <author><first>Nikolay</first><last>Paev</last></author>
      <author><first>Petya</first><last>Osenova</last></author>
      <author><first>Stefan</first><last>Marinov</last></author>
      <pages>1163–1171</pages>
      <abstract>The paper presents the results from the experiments with two large language models (LLMs) - T5 and Llama – for extracting events from a Bulgarian event corpus. The two models were pretrained by us on 35 Billion Token Bulgarian Corpus. The extraction was performed within the context of one sentence. Our approach aims at balancing the ACE-oriented approach that uses triggers in event detection, and the MUC-oriented one that uses more general event types. The evaluation relies on the IoU (Intersection over Union) of token spans and is twofold. The first one refers to the predicted event token span. Here if the span is correct, the semantic roles within the event are further checked. The second one refers to the triple of an event type, its semantic roles and participants. The results are promising. A qualitative evaluation is provided as well.</abstract>
      <url hash="bd91ac53">2025.ranlp-1.134</url>
      <bibkey>simov-etal-2025-bulgarian</bibkey>
    </paper>
    <paper id="135">
      <title><fixed-case>F</fixed-case>ig<fixed-case>C</fixed-case>aps-<fixed-case>HF</fixed-case>: A Figure-to-Caption Generative Framework and Benchmark with Human Feedback</title>
      <author><first>Ashish</first><last>Singh</last></author>
      <author><first>Ashutosh</first><last>Singh</last></author>
      <author><first>Prateek</first><last>Agarwal</last></author>
      <author><first>Zixuan</first><last>Huang</last></author>
      <author><first>Arpita</first><last>Singh</last></author>
      <author><first>Tong</first><last>Yu</last></author>
      <author><first>Sungchul</first><last>Kim</last></author>
      <author><first>Victor Soares</first><last>Bursztyn</last></author>
      <author><first>Nesreen K.</first><last>Ahmed</last></author>
      <author><first>Puneet</first><last>Mathur</last></author>
      <author><first>Erik</first><last>Learned-Miller</last></author>
      <author><first>Franck</first><last>Dernoncourt</last></author>
      <author><first>Ryan</first><last>Rossi</last></author>
      <pages>1172–1182</pages>
      <abstract>Captions are crucial for understanding scientific visualizations and documents. Existing captioning methods for scientific figures rely on figure-caption pairs extracted from documents for training, many of which fall short with respect to metrics like helpfulness, explainability, and visual-descriptiveness, leading to generated captions being misaligned with reader preferences. To address this issue, we introduce FigCaps-HF, a new framework for figure-caption generation that can incorporate domain expert feedback in generating captions optimized for reader preferences. Our framework comprises of 1) an automatic method for evaluating the quality of figure-caption pairs, and 2) a novel reinforcement learning with human feedback (RLHF) method to optimize a generative figure-to-caption model for reader preferences. We demonstrate the effectiveness of our simple learning framework by improving performance over standard fine-tuning across different types of models. In particular, when using BLIP as the base model, our RLHF framework achieves a mean gain of 35.7%, 16.9%, 9%, and 11.4% in ROUGE, BLEU, Meteor, and CIDEr scores, respectively. Finally, we release a large-scale benchmark dataset with human feedback on figure-caption pairs to enable further evaluation and development of RLHF techniques for this problem.</abstract>
      <url hash="99792eb0">2025.ranlp-1.135</url>
      <bibkey>singh-etal-2025-figcaps</bibkey>
    </paper>
    <paper id="136">
      <title><fixed-case>LLM</fixed-case> Compression: How Far Can We Go in Balancing Size and Performance?</title>
      <author><first>Sahil</first><last>Sk</last></author>
      <author><first>Debashish</first><last>Dhal</last></author>
      <author><first>Sonal</first><last>Khosla</last></author>
      <author><first>Akash</first><last>Dhaka</last></author>
      <author><first>Shantipriya</first><last>Parida</last></author>
      <author><first>Sk</first><last>Shahid</last></author>
      <author><first>Sambit</first><last>Shekhar</last></author>
      <author><first>Dilip</first><last>Prasad</last></author>
      <author id="ondrej-bojar"><first>Ondrej</first><last>Bojar</last></author>
      <pages>1183–1187</pages>
      <abstract>Quantization is an essential and popular technique for improving the accessibility of large language models (LLMs) by reducing memory usage and computational costs while maintaining performance. In this study, we apply 4-bit Group Scaling Quantization (GSQ) and Generative Pretrained Transformer Quantization (GPTQ) to LLaMA 1B, Qwen 0.5B, and PHI 1.5B, evaluating their impact across multiple NLP tasks. We benchmark these models on MS MARCO (Information Retrieval), BoolQ (Boolean Question Answering), and GSM8K (Mathematical Reasoning) datasets, assessing both accuracy and efficiency accross various tasks. The study measures the trade-offs between model compression and task performance, analyzing key evaluation metrics namely: accuracy, inference latency, and throughput, providing insights into the suitability of low-bit quantization for real-world deployment and highlight the tradeoffs between memory, computing and latency in such settings, helping a user make suitable decisions</abstract>
      <url hash="2d566917">2025.ranlp-1.136</url>
      <bibkey>sk-etal-2025-llm</bibkey>
    </paper>
    <paper id="137">
      <title>Pushing the (Generative) Envelope: Measuring the Effect of Prompt Technique and Temperature on the Generation of Model-based Systems Engineering Artifacts</title>
      <author><first>Erin</first><last>Smith Crabb</last></author>
      <author><first>Cedric</first><last>Bernard</last></author>
      <author><first>Matthew</first><last>Jones</last></author>
      <author><first>Daniel</first><last>Dakota</last></author>
      <pages>1188–1194</pages>
      <abstract>System engineers use Model-based systems engineering (MBSE) approaches to help design and model system requirements. This manually intensive process requires expertise in both the domain of artifact creation (e.g., the requirements for a vacuum), and how to encode that information in a machine readable form (e.g., SysML). We investigated leveraging local LLMs to generate initial draft artifacts using a variety of prompt techniques and temperatures. Our experiments showed promise for generating certain types of artifacts, suggesting that even smaller, local models possesses enough MBSE knowledge to support system engineers. We observed however that while scores for artifacts remain stable across different temperature settings, this is potentially misleading as significantly different, though semantically equivalent, generations can be produced.</abstract>
      <url hash="d304fccf">2025.ranlp-1.137</url>
      <bibkey>smith-crabb-etal-2025-pushing</bibkey>
    </paper>
    <paper id="138">
      <title><fixed-case>D</fixed-case>utch <fixed-case>C</fixed-case>row<fixed-case>S</fixed-case>-Pairs: Adapting a Challenge Dataset for Measuring Social Biases in Language Models for <fixed-case>D</fixed-case>utch</title>
      <author><first>Elza</first><last>Strazda</last></author>
      <author><first>Gerasimos</first><last>Spanakis</last></author>
      <pages>1195–1204</pages>
      <abstract>Language models are prone to exhibiting biases, further amplifying unfair and harmful stereotypes. Given the fast-growing popularity and wide application of these models, it is necessary to ensure safe and fair language models. As of recent considerable attention has been paid to measuring bias in language models, yet the majority of studies have focused only on English language. A Dutch version of the US-specific CrowS-Pairs dataset for measuring bias in Dutch language models is introduced. The resulting dataset consists of 1463 sentence pairs that cover bias in 9 categories, such as Sexual orientation, Gender and Disability. The sentence pairs are composed of contrasting sentences, where one of the sentences concerns disadvantaged groups and the other advantaged groups. Using the Dutch CrowS-Pairs dataset, we show that various language models, BERTje, RobBERT, multilingual BERT, GEITje and Mistral-7B exhibit substantial bias across the various bias categories. Using the English and French versions of the CrowS-Pairs dataset, bias was evaluated in English (BERT and RoBERTa) and French (FlauBERT and CamemBERT) language models, and it was shown that English models exhibit the most bias, whereas Dutch models the least amount of bias. Additionally, results also indicate that assigning a persona to a language model changes the level of bias it exhibits. These findings highlight the variability of bias across languages and contexts, suggesting that cultural and linguistic factors play a significant role in shaping model biases.</abstract>
      <url hash="aceb3fc1">2025.ranlp-1.138</url>
      <bibkey>strazda-spanakis-2025-dutch</bibkey>
    </paper>
    <paper id="139">
      <title>The Challenge of Performing Ontology-driven Entity Extraction in Real-world Unstructured Textual Data from the Domain of Dementia</title>
      <author><first>Sumaiya</first><last>Suravee</last></author>
      <author><first>Carsten Oliver</first><last>Schmidt</last></author>
      <author><first>Kristina</first><last>Yordanova</last></author>
      <pages>1205–1214</pages>
      <abstract>Named entity recognition allows the automated extraction of structured domain-related information from unstructured textual data. Our study explores the task of ontology-driven entity recognition, a sequence labelling process for custom named entity recognition for the domain of dementia, specifically from unstructured forum texts where unprofessional caregivers of people with dementia discuss the challenges they face related to agitation. The targeted corpus is loosely structured, contains ambiguous sentences and vocabulary that does not match the agitation-related medical vocabulary. To address the above challenges, we propose a pipeline that involves the following steps: 1) development of an annotation codebook; 2) annotation of a textual corpus collected from dementia forums, consisting of 45,216 sentences (775 questions and 5571 answers); 3) data augmentation to reduce the imbalance in the corpus; 4) training of a bidirectional LSTM model and a transformer model; 5) comparison of the results with those from few shot- and zero-shot based prompt engineering techniques using a pretrained large language model (LLaMa 3). The results showed that LLaMa 3 was more robust than traditional neural networks and transformer models in detecting underrepresented entities. Furthermore, the study demonstrates that data augmentation improves the entity recognition task when fine-tuning deep learning models. The paper illustrates the challenges of ontology-driven entity recognition in real-world datasets and proposes a roadmap to addressing them that is potentially transferable to other real-world domains.</abstract>
      <url hash="a6c218d2">2025.ranlp-1.139</url>
      <bibkey>suravee-etal-2025-challenge</bibkey>
    </paper>
    <paper id="140">
      <title>Recognizing the Structure and Content of <fixed-case>H</fixed-case>ungarian Civil Registers</title>
      <author><first>Kata Ágnes</first><last>Szűcs</last></author>
      <author><first>Noémi</first><last>Vadász</last></author>
      <author><first>Zsolt Béla</first><last>Záros</last></author>
      <pages>1215–1223</pages>
      <abstract>The study evaluates key steps in a system for processing data from digitized Hungarian state register records (1895-1980) into an SQL database. It examines how template selection and post-processing impact data accessibility and integration. The research details the compiled datasets, annotation processes, and evaluation functions used to measure processing quality, emphasizing template selection and post-processing to improve the overall workflow and the accuracy of the published data. An evaluation method for publishing structured data provides a model for similar projects.</abstract>
      <url hash="0c4fd4ad">2025.ranlp-1.140</url>
      <bibkey>szucs-etal-2025-recognizing</bibkey>
    </paper>
    <paper id="141">
      <title>Optimism, Pessimism, and the Language between: Model Interpretability and Psycholinguistic Profiling</title>
      <author><first>Stefana Arina</first><last>Tabusca</last></author>
      <author id="liviu-p-dinu"><first>Liviu P.</first><last>Dinu</last></author>
      <pages>1224–1231</pages>
      <abstract>This study explores how optimism and pessimism are expressed in social media by combining psycholinguistic profiling with model interpretability. Using the OPT dataset, we fine-tune a RoBERTa-based classifier and apply LIME to examine both the most confident and the most ambiguous predictions. We analyze the influential tokens driving these decisions and identify lexical patterns linked to affective intensity, certainty, and social orientation. A complementary LIWC-based analysis of ground truth labels reveals systematic differences in emotional tone and cognitive style. PCA projections further show that optimism and pessimism occupy overlapping yet distinguishable regions in psycholinguistic space. Our findings demonstrate the value of linguistic interpretability in understanding dispositional sentiment.</abstract>
      <url hash="6d5ac2ca">2025.ranlp-1.141</url>
      <bibkey>tabusca-dinu-2025-optimism</bibkey>
    </paper>
    <paper id="142">
      <title>Demographic Features for Annotation-Aware Classification</title>
      <author><first>Narjes</first><last>Tahaei</last></author>
      <author><first>Sabine</first><last>Bergler</last></author>
      <pages>1232–1236</pages>
      <abstract>This paper revisits the use of annotator demographics as interpretable meta-information for modeling such variation. We adapt a lightweight attention mechanism, Annotation-Wise Attention Network (AWAN), to condition predictions on demographic features, enabling per-annotator modeling. Experiments on the EXIST sexism dataset show that AWAN improves classification performance over standard baselines, especially in cases of high annotator disagreement.</abstract>
      <url hash="dd02e4ed">2025.ranlp-1.142</url>
      <bibkey>tahaei-bergler-2025-demographic</bibkey>
    </paper>
    <paper id="143">
      <title>Exploring the Performance of Large Language Models for Event Detection and Extraction in the Health Domain</title>
      <author id="hristo-tanev"><first>Hristo</first><last>Tanev</last></author>
      <author><first>Nicolas</first><last>Stefanovitch</last></author>
      <author><first>Tomáš</first><last>Harmatha</last></author>
      <author><first>Diana</first><last>F. Sousa</last></author>
      <pages>1237–1247</pages>
      <abstract>Large Language Models (LLM) have entered the world of NLP with a fast pace. LLM has been used for summarization, translation, named entity recognition, and sentiment analysis Recently, different research groups have experimented with event detection and extraction, using LLM at various levels of the processing stage: The LLM have proven to be a very relevant technology from data preparation to event argument extraction. In particular Open Source LLM like Mistral are very important since they can be shared and modified by the research community. Still, little effort was made to study the performance of these models in NLP tasks like event extraction. In this paper we describe an experiment in evaluating several state-of-the-art open large language models (LLM) for the task of event extraction and event detection in the domain of health. The models were prompted to perform detection of health-related events - mostly disease outbreaks, but also natural and man-made disasters, which directly or indirectly have impact on the health of the people. The models were also asked to extract the place, time, number of human and animal cases, and the number of the human fatalities. The performance of the LLM turned out to be better than the one of a state-of-the-art knowledge based system, using as test data a set of 800 news abstracts, containing the title and the lead sentences of health-related news articles. We compared the performance of the event detection and event argument extraction from the open Large Language Models and two knowledge based event extraction systems, NEXUS and Medical NEXUS. Our evaluation shows that all the open LLM show a superior performance w.r.t. the knowledge-based systems with the best improvement of the F1 score of number of human fatalities detection of 0.2 (0.84 vs. 0.64), where the best performing LLM was LLama 3.3 70B instruct.</abstract>
      <url hash="afdc6a78">2025.ranlp-1.143</url>
      <bibkey>tanev-etal-2025-exploring</bibkey>
    </paper>
    <paper id="144">
      <title>Leveraging <fixed-case>LL</fixed-case>a<fixed-case>M</fixed-case>a for Abstractive Text Summarisation in <fixed-case>M</fixed-case>alayalam: An Experimental Study</title>
      <author id="hristo-tanev"><first>Hristo</first><last>Tanev</last></author>
      <author><first>Anitha S.</first><last>Pillai</last></author>
      <author><first>Revathy V.</first><last>R</last></author>
      <pages>1248–1255</pages>
      <abstract>Recent years witnessed tremendous advancements in natural language processing (NLP) because of the development of complex language models that have automated several NLP applications, including text summarisation. Despite this progress, Malayalam text summarisation still faces challenges because of the peculiarities of the language. This research paper explores the potential of using a large language model, specifically the LLaMA (Large Language Model Meta AI) framework, for text summarisation of Malayalam language. In order to assess the performance of LLaMA for text summarization, for the low-resource language Malayalam, a dataset was curated with reference text and summaries. The evaluation showed that the LLaMA model could effectively summarize lengthy articles while maintaining important information and coherence. The generated summaries were compared with the reference summaries generated by human writers to observe how well aligned the model was with a human level of summarisation. The results proved that LLM can deal with the Malayalam text summarisation task, but more research is needed to understand the most relevant training strategy.</abstract>
      <url hash="ac8a40ea">2025.ranlp-1.144</url>
      <bibkey>tanev-etal-2025-leveraging</bibkey>
    </paper>
    <paper id="145">
      <title>Building a Clean Bartangi Language Corpus and Training Word Embeddings for Low-Resource Language Modeling</title>
      <author><first>Warda</first><last>Tariq</last></author>
      <author><first>Victor</first><last>Popov</last></author>
      <author><first>Vasilii</first><last>Gromov</last></author>
      <pages>1256–1262</pages>
      <abstract>In this paper, we showcase a comprehensive end-to-end pipeline for creating a superior Bartangi language corpus and using it for training word embeddings. The critically low-resource Pamiri lan- guage of Bartangi, which is spoken in Tajikistan, has difficulties such as morphological complexity, orthographic variety, and a lack of data. In order to overcome these obstacles, we gathered a raw corpus of roughly 6,550 phrases, used the Uniparser-Morph-Bartangi morphological analyzer for linguistically accurate lemmatization, and implemented a thorough cleaning procedure to eliminate noise and ensure proper tokenization. The lemmatized corpus that results greatly lowers word spar- sity and raises the standard of linguistic analysis.The processed corpus was then used to train two different Word2Vec models, Skip-gram and CBOW, with a vector size of 100, a context window of 5, and a minimum frequency threshold of 1. The resultant word embeddings were displayed using dimensionality reduction techniques like PCA and t-SNE, and assessed using intrinsic methods like nearest-neighbor similarity tests. Our tests show that even from tiny datasets, meaningful semantic representations can be obtained by combining informed morphological analysis with clean prepro- cessing. One of the earliest computational datasets for Bartangi, this resource serves as a vital basis for upcoming NLP tasks, such as language modeling, semantic analysis, and low-resource machine translation. To promote more research in Pamiri and other under-represented languages, we make the corpus, lemmatizer pipeline, and trained embeddings publicly available.</abstract>
      <url hash="1e6296cf">2025.ranlp-1.145</url>
      <bibkey>tariq-etal-2025-building</bibkey>
    </paper>
    <paper id="146">
      <title>A Deep Dive into Multi-Head Attention and Multi-Aspect Embedding</title>
      <author><first>Maryam</first><last>Teimouri</last></author>
      <author><first>Jenna</first><last>Kanerva</last></author>
      <author><first>Filip</first><last>Ginter</last></author>
      <pages>1263–1270</pages>
      <abstract>Multi-vector embedding models play an increasingly important role in retrieval-augmented generation, yet their internal behaviour lacks comprehensive analysis. We conduct a systematic, head-level study of the 32-head Semantic Feature Representation (SFR) encoder with the FineWeb corpus containing 10 billion tokens. For a set of 4,000 web documents, we pair head-specific embeddings with GPT-4o topic annotations and analyse the results using t-SNE visualisations, heat maps, and a 32-way logistic probe. The analysis shows that (i) clear semantic separation between heads emerges only at an intermediate layer, (ii) some heads align with specific topics while others capture broader corpus features, and (iii) naive pooling of head outputs can blur these distinctions, leading to frequent topic mismatches. The study offers practical guidance on where to extract embeddings, which heads may be pruned, and how to aggregate them to support more transparent and controllable retrieval pipelines.</abstract>
      <url hash="32249f84">2025.ranlp-1.146</url>
      <bibkey>teimouri-etal-2025-deep</bibkey>
    </paper>
    <paper id="147">
      <title>A Linguistically-informed Comparison between Multilingual <fixed-case>BERT</fixed-case> and Language-specific <fixed-case>BERT</fixed-case> Models: The Case of Differential Object Marking in <fixed-case>R</fixed-case>omanian</title>
      <author><first>Maria</first><last>Tepei</last></author>
      <author><first>Jelke</first><last>Bloem</last></author>
      <pages>1271–1281</pages>
      <abstract>Current linguistic challenge datasets for language models focus on phenomena that exist in English. This may lead to a lack of attention for typological features beyond English. This is particularly an issue for multilingual models, which may be biased towards English by their training data and this bias may be amplified if benchmarks are also English-centered. We present the syntactically and semantically complex language phenomenon of Differential Object Marking (DOM) in Romanian as a challenging Masked Language Modelling task and compare the performance of monolingual and multilingual models. Results indicate that Romanian-specific BERT models perform better than equivalent multilingual one in representing this phenomenon.</abstract>
      <url hash="772185ea">2025.ranlp-1.147</url>
      <bibkey>tepei-bloem-2025-linguistically</bibkey>
    </paper>
    <paper id="148">
      <title><fixed-case>P</fixed-case>oli<fixed-case>S</fixed-case>tance-<fixed-case>TR</fixed-case>: A Dataset for <fixed-case>T</fixed-case>urkish Stance Detection in Political Domain</title>
      <author><first>Muhammed Cihat</first><last>Unal</last></author>
      <author><first>Yasemin</first><last>Sarkın</last></author>
      <author><first>Alper</first><last>Karamanlioglu</last></author>
      <author><first>Berkan</first><last>Demirel</last></author>
      <pages>1282–1288</pages>
      <abstract>Stance detection in NLP involves determining whether an author is supportive, against, or neutral towards a particular target. This task is particularly challenging for Turkish due to the limited availability of data, which hinders progress in the field. To address this issue, we introduce a novel dataset focused on stance detection in Turkish, specifically within the political domain. This dataset was collected from X (formerly Twitter) and annotated by three human annotators who followed predefined guidelines to ensure consistent labeling and generalizability. After compiling the dataset, we trained various transformer-based models with different architectures, showing that the dataset is effective for stance classification. These models achieved an impressive Macro F1 score of up to 82%, highlighting their effectiveness in stance detection.</abstract>
      <url hash="03fdf220">2025.ranlp-1.148</url>
      <bibkey>unal-etal-2025-polistance</bibkey>
    </paper>
    <paper id="149">
      <title>Towards Safer <fixed-case>H</fixed-case>ebrew Communication: A Dataset for Offensive Language Detoxification</title>
      <author><first>Natalia</first><last>Vanetik</last></author>
      <author><first>Lior</first><last>Liberov</last></author>
      <author><first>Marina</first><last>Litvak</last></author>
      <author><first>Chaya</first><last>Liebeskind</last></author>
      <pages>1289–1298</pages>
      <abstract>Text detoxification is the task of transforming offensive or toxic content into a non-offensive form while preserving the original meaning. Despite increasing research interest in detoxification across various languages, no resources or benchmarks exist for Hebrew, a Semitic language with unique morphological, syntactic, and cultural characteristics. This paper introduces HeDetox, the first annotated dataset for text detoxification in Hebrew. HeDetox contains 600 sentence pairs, each consisting of an offensive source text and a non-offensive text rewritten with LLM and human intervention. We present a detailed dataset analysis and evaluation showing that the dataset benefits offensive language detection. HeDetox offers a foundational resource for Hebrew natural language processing, advancing research in offensive language mitigation and controllable text generation.</abstract>
      <url hash="c0477348">2025.ranlp-1.149</url>
      <bibkey>vanetik-etal-2025-towards</bibkey>
    </paper>
    <paper id="150">
      <title><fixed-case>AIDEN</fixed-case>: Automatic Speaker Notes Creation and Navigation for Enhancing Online Learning Experience</title>
      <author><first>Stalin</first><last>Varanasi</last></author>
      <author><first>Umer</first><last>Butt</last></author>
      <author id="gunter-neumann"><first>Guenter</first><last>Neumann</last></author>
      <author id="josef-van-genabith"><first>Josef</first><last>van Genabith</last></author>
      <pages>1299–1303</pages>
      <abstract>Effective learning in digital environments depends on quick access to educational resources and timely support. We present AIDEN, an advanced, AI-driven virtual teaching assistant integrated into lectures, to provide meaningful support for students. AIDEN’s capabilities include reading lecture materials aloud, locating specific slides, automatic speaker notes generation, search through a video stream. Powered by state-of-the-art retrieval and text generation, AIDEN can be adapted to new lecture content with minimal manual adjustments, requiring only minor customization of data handling processes and model configurations. Through automated testing, we evaluated AIDEN’s performance across key metrics slide retrieval recall for questions, and alignment of generated speaker notes with ground-truth data. The evaluation underscores AIDEN’s potential to significantly enhance learning experiences by offering real-world application and rapid configurability to diverse learning materials.</abstract>
      <url hash="0b1cf564">2025.ranlp-1.150</url>
      <bibkey>varanasi-etal-2025-aiden</bibkey>
    </paper>
    <paper id="151">
      <title>Using <fixed-case>LLM</fixed-case>s for Multilingual Clinical Entity Linking to <fixed-case>ICD</fixed-case>-10</title>
      <author><first>Sylvia</first><last>Vassileva</last></author>
      <author><first>Ivan K.</first><last>Koychev</last></author>
      <author><first>Svetla</first><last>Boytcheva</last></author>
      <pages>1304–1308</pages>
      <abstract>The linking of clinical entities is a crucial part of extracting structured information from clinical texts. It is the process of assigning a code from a medical ontology or classification to a phrase in the text. The International Classification of Diseases - 10th revision (ICD-10) is an international standard for classifying diseases for statistical and insurance purposes. Automatically assigning the correct ICD-10 code to terms in discharge summaries will simplify the work of healthcare professionals and ensure consistent coding in hospitals. Our paper proposes an approach for linking clinical terms to ICD-10 codes in different languages using Large Language Models (LLMs). The approach consists of a multistage pipeline that uses clinical dictionaries to match unambiguous terms in the text and then applies in-context learning with GPT-4.1 to predict the ICD-10 code for the terms that do not match the dictionary. Our system shows promising results in predicting ICD-10 codes on different benchmark datasets in Spanish - 0.89 F1 for categories and 0.78 F1 on subcategories on CodiEsp, and Greek - 0.85 F1 on ElCardioCC.</abstract>
      <url hash="6f6b2f68">2025.ranlp-1.151</url>
      <bibkey>vassileva-etal-2025-using</bibkey>
    </paper>
    <paper id="152">
      <title>Aspect–Sentiment Quad Prediction with Distilled Large Language Models</title>
      <author><first>Filippos Karolos</first><last>Ventirozos</last></author>
      <author><first>Peter</first><last>Appleby</last></author>
      <author><first>Matthew</first><last>Shardlow</last></author>
      <pages>1309–1319</pages>
      <abstract>Aspect-based sentiment analysis offers detailed insights by pinpointing specific product aspects in a text that are associated with sentiments. This study explores it through the prediction of quadruples, comprising aspect, category, opinion, and polarity. We evaluated in-context learning strategies using recently released distilled large language models, ranging from zero to full-dataset demonstrations. Our findings reveal that the performance of these models now positions them between the current state-of-the-art and significantly higher than their earlier generations. Additionally, we experimented with various chain-of-thought prompts, examining sequences such as aspect to category to sentiment in different orders. Our results indicate that the optimal sequence differs from previous assumptions. Additionally, we found that for quadruple prediction, few-shot demonstrations alone yield better performance than chain-of-thought prompting.</abstract>
      <url hash="31e6bc26">2025.ranlp-1.152</url>
      <bibkey>ventirozos-etal-2025-aspect</bibkey>
    </paper>
    <paper id="153">
      <title><fixed-case>SENT</fixed-case>imental - a Simple Multilingual Sentiment Annotation Tool</title>
      <author><first>John</first><last>Vidler</last></author>
      <author><first>Paul</first><last>Rayson</last></author>
      <author><first>Dawn</first><last>Knight</last></author>
      <pages>1320–1326</pages>
      <abstract>Here we present SENTimental, a simple and fast web-based, mobile-friendly tool for capturing sentiment annotations from participants and citizen scientist volunteers to create training and testing data for low-resource languages. In contrast to existing tools, we focus on assigning broad values to segments of text over specific tags for tokens or spans to build datasets for training and testing LLMs. The SENTimental interface minimises barriers to entry with a goal of maximising the time a user spends in a flow state whereby they are able to quickly and accurately rate each text fragment without being distracted by the complexity of the interface. Designed from the outset to handle multilingual representations, SENTimental allows for parallel corpus data to be presented to the user and switched between instantly for immediate comparison. As such this allows for users in any loaded languages to contribute to the data gathered, building up comparable rankings in a simple structured dataset for later processing.</abstract>
      <url hash="149f5e69">2025.ranlp-1.153</url>
      <bibkey>vidler-etal-2025-sentimental</bibkey>
    </paper>
    <paper id="154">
      <title>Anonymise: A Tool for Multilingual Document Pseudonymisation</title>
      <author><first>Rinalds</first><last>Vīksna</last></author>
      <author id="inguna-skadina"><first>Inguna</first><last>Skadina</last></author>
      <pages>1327–1332</pages>
      <abstract>According to the EU legislation, documents containing personal information need to be anonymized before public sharing. However, manual anonymisation is a time-consuming and costly process. Thus, there is a need for a robust text de-identification technique that accurately identifies and replaces personally identifiable information. This paper introduces the Anonymise tool, a system for document de-identification. The tool accepts text documents of various types (e.g., MS Word, plain-text), de-identifies personal information, and saves the de-identified document in its original format. The tool employs a modular architecture, integrating list-based matching, regular expressions and deep-learning-based named entity recognition to detect spans for redaction. Our evaluation results demonstrate high recall rates, making Anonymise a reliable solution for ensuring no sensitive information is left exposed. The tool can be accessed through a userfriendly web-based interface or API, offering flexibility for both individual and large-scale document processing needs. By automating document de-identification with high accuracy and efficiency, Anonymise presents a reliable solution for ensuring compliance with EU privacy regulations while reducing the time and cost associated with manual anonymisation.</abstract>
      <url hash="1578d333">2025.ranlp-1.154</url>
      <bibkey>viksna-skadina-2025-anonymise</bibkey>
    </paper>
    <paper id="155">
      <title>Revealing Gender Bias in Language Models through Fashion Image Captioning</title>
      <author><first>Maria</first><last>Villalba-Oses</last></author>
      <author><first>Victoria</first><last>Muñoz-Garcia</last></author>
      <author><first>Juan Pablo</first><last>Consuegra-Ayala</last></author>
      <pages>1333–1340</pages>
      <abstract>Image captioning bridges computer vision and natural language processing but remains vulnerable to social biases. This study evaluates gender bias in ChatGPT, Copilot, and Grok by analyzing their descriptions of fashion-related images prompted without gender cues. We introduce a methodology combining gender annotation, stereotype classification, and a manually curated dataset. Results show that GPT-4o and Grok frequently assign gender and reinforce stereotypes, while Copilot more often generates neutral captions. Grok shows the lowest error rate but consistently assigns gender, even when cues are ambiguous. These findings highlight the need for bias-aware captioning approaches in multimodal systems.</abstract>
      <url hash="3f27ce3e">2025.ranlp-1.155</url>
      <bibkey>villalba-oses-etal-2025-revealing</bibkey>
    </paper>
    <paper id="156">
      <title>Benchmarking <fixed-case>K</fixed-case>orean Idiom Understanding: A Comparative Analysis of Local and Global Models</title>
      <author><first>Xiaonan</first><last>Wang</last></author>
      <author><first>Seoyoon</first><last>Park</last></author>
      <author><first>Hansaem</first><last>Kim</last></author>
      <pages>1341–1351</pages>
      <abstract>Although an increasing number of multilingual LLMs (large language models) have begun to support Korean, there remains a notable lack of benchmark datasets specifically designed to evaluate their proficiency in Korean cultural and linguistic understanding. A major reason for this gap is that many available benchmarks in Korean are adapted from English originals via translation, which often fails to reflect the unique cultural context embedded in the Korean language. Even the few benchmark datasets based on native Korean data that involve cultural content typically focus on tasks such as bias or hate speech detection, where cultural knowledge serves merely as topical background rather than being integrated as a core component of semantic understanding. To address this gap, we introduce the Korean Idiom Matching Benchmark (KIM Bench), which consists of 1,175 instances. Idioms are culture-specific and often untranslatable, making them ideal for testing models’ cross-cultural semantic understanding. Using KIM Bench, We evaluate global and Korean native models. Our analysis show that larger and locally trained models better capture idiom semantics and cultural nuances, while chain-of-thought prompting may reduce accuracy. Models still struggle with deep semantic and contextual understanding. KIM Bench offers a compact tool for cross-cultural evaluation and insights into improving performance on culturally grounded tasks.</abstract>
      <url hash="224c9aa2">2025.ranlp-1.156</url>
      <bibkey>wang-etal-2025-benchmarking-korean</bibkey>
    </paper>
    <paper id="157">
      <title><fixed-case>T</fixed-case>iny<fixed-case>M</fixed-case>ental<fixed-case>LLM</fixed-case>s Enable Depression Detection in <fixed-case>C</fixed-case>hinese Social Media Texts</title>
      <author><first>Jinyuan</first><last>Xu</last></author>
      <author><first>Tian</first><last>Lan</last></author>
      <author><first>Mathieu</first><last>Valette</last></author>
      <author><first>Pierre</first><last>Magistry</last></author>
      <author><first>Lei</first><last>Li</last></author>
      <pages>1352–1363</pages>
      <abstract>Depression remains a major global mental health concern, bringing a higher risk of suicide and growing social costs tied to mental disorders. Leveraging social media as a valuable source of emotional signals, we identify two limitations in current NLP-based depression detection frameworks: (1) prediction systems often lack clear, user-friendly explanations for predictions in Depression Detection, and (2) the computational and confidentiality demands of LLMs are misaligned with the need for dependable, privacy-focused small-scale deployments. To address these challenges, we introduce TinyMentalLLMs (TMLs), a compact framework that offers two key contributions: (a) the construction of a small yet representative dataset through psychology-based textometry, and (b) an efficient fine-tuning strategy centered on multiple aspects of depression. This design improves both accuracy and F1 scores in generative models with 0.5B and 1.5B parameters, consistently yielding over 20% performance gains across datasets. TMLs achieve results on par with, and deliver better text quality than, much larger state-of-the-art models.</abstract>
      <url hash="cead1091">2025.ranlp-1.157</url>
      <bibkey>xu-etal-2025-tinymentalllms</bibkey>
    </paper>
    <paper id="158">
      <title>Prompt Engineering for <fixed-case>N</fixed-case>epali <fixed-case>NER</fixed-case>: Leveraging <fixed-case>H</fixed-case>indi-Capable <fixed-case>LLM</fixed-case>s for Low-Resource Languages</title>
      <author><first>Dipendra</first><last>Yadav</last></author>
      <author><first>Sumaiya</first><last>Suravee</last></author>
      <author><first>Stefan</first><last>Kemnitz</last></author>
      <author><first>Tobias</first><last>Strauss</last></author>
      <author><first>Kristina</first><last>Yordanova</last></author>
      <pages>1364–1373</pages>
      <abstract>This study provides a systematic evaluation of prompt engineering strategies for Named Entity Recognition in Nepali, a low-resource language with high similarity to Hindi, by leveraging Hindi-capable Meta’s LLaMA 3.3:70B model. Four prompting techniques—Baseline, Chain-of-Thought, Self-Refine, and Least-toMost—are assessed in both zero-shot and fewshot settings. As a novel contribution, we propose an entity-aware sentence selection strategy that prioritizes example diversity and entity coverage for few-shot prompting. Experimental results show that, without Nepali examples, zero-shot and one-shot prompts frequently yield unstructured or hallucinated outputs, underscoring the limitations of cross-lingual capabilities without in-context supervision. However, including even a small number of carefully selected Nepali examples—sometimes as few as ten—substantially enhances model performance, with the Least-to-Most approach achieving the highest F1 scores. These findings highlight the potential of prompt-based adaptation and principled example curation for extending LLM capabilities to related, low-resource languages, offering a practical alternative to full model fine-tuning.</abstract>
      <url hash="721e1d9a">2025.ranlp-1.158</url>
      <bibkey>yadav-etal-2025-prompt</bibkey>
    </paper>
    <paper id="159">
      <title>Seeing, Signing, and Saying: A Vision-Language Model-Assisted Pipeline for Sign Language Data Acquisition and Curation from Social Media</title>
      <author><first>Shakib</first><last>Yazdani</last></author>
      <author><first>Yasser</first><last>Hamidullah</last></author>
      <author><first>Cristina</first><last>España-Bonet</last></author>
      <author id="josef-van-genabith"><first>Josef</first><last>van Genabith</last></author>
      <pages>1374–1384</pages>
      <abstract>Most existing sign language translation (SLT) datasets are limited in scale, lack multilingual coverage, and are costly to curate due to their reliance on expert annotation and controlled recording setup. Recently, Vision Language Models (VLMs) have demonstrated strong capabilities as evaluators and real-time assistants. Despite these advancements, their potential remains untapped in the context of sign language dataset acquisition. To bridge this gap, we introduce the first automated annotation and filtering framework that utilizes VLMs to reduce reliance on manual effort while preserving data quality. Our method is applied to TikTok videos across eight sign languages and to the already curated YouTube-SL-25 dataset in German Sign Language for the purpose of additional evaluation. Our VLM-based pipeline includes a face visibility detection, a sign activity recognition, a text extraction from video content, and a judgment step to validate alignment between video and text, implementing generic filtering, annotation and validation steps. Using the resulting corpus, TikTok-SL-8, we assess the performance of two off-the-shelf SLT models on our filtered dataset for German and American Sign Languages, with the goal of establishing baselines and evaluating the robustness of recent models on automatically extracted, slightly noisy data. Our work enables scalable, weakly supervised pretraining for SLT and facilitates data acquisition from social media.</abstract>
      <url hash="59918211">2025.ranlp-1.159</url>
      <bibkey>yazdani-etal-2025-seeing</bibkey>
    </paper>
    <paper id="160">
      <title>Visual Priming Effect on Large-scale Vision Language Models</title>
      <author><first>Daiki</first><last>Yoshida</last></author>
      <author><first>Haruki</first><last>Sakajo</last></author>
      <author><first>Kazuki</first><last>Hayashi</last></author>
      <author><first>Yusuke</first><last>Sakai</last></author>
      <author><first>Hidetaka</first><last>Kamigaito</last></author>
      <author><first>Katsuhiko</first><last>Hayashi</last></author>
      <author><first>Taro</first><last>Watanabe</last></author>
      <pages>1385–1395</pages>
      <abstract>Large-scale Vision-Language Models (LVLMs) integrate linguistic and visual information, demonstrating advanced task-solving capabilities. These models are originally derived from Large Language Models, leading to strong capabilities for language tasks. However, the impact of additional visual information on model responses remains insufficiently understood. In this study, we focus on the priming effect, a psychological phenomenon, to investigate how visual information influences language task processing. We present additional intentionally designed images alongside two types of language tasks with different characteristics and analyze changes in the model’s responses. Our experimental results show that model responses shift in the direction intended by the image, suggesting that LVLMs do not simply ignore visual information but actively incorporate it into language processing. Furthermore, the similarity between this behavior and priming effects observed in human cognition suggests that LVLMs may share certain aspects of human cognitive mechanisms.</abstract>
      <url hash="ddf3f64f">2025.ranlp-1.160</url>
      <bibkey>yoshida-etal-2025-visual</bibkey>
    </paper>
    <paper id="161">
      <title>From Courtroom to Corpora: Building a Name Entity Corpus for <fixed-case>U</fixed-case>rdu Legal Texts</title>
      <author><first>Adeel</first><last>Zafar</last></author>
      <author><first>Sohail</first><last>Ashraf</last></author>
      <author><first>Slawomir</first><last>Nowaczyk</last></author>
      <pages>1396–1405</pages>
      <abstract>This study explores the effectiveness of transformer-based models for Named Entity Recognition (NER) in Urdu legal documents, a critical task in low-resource language processing. Given the legal texts’ specialized terminology and complex syntax, accurate entity recognition in Urdu remains challenging. We developed a legal Urdu dataset that contains 117,500 documents, generated synthetically from 47 different types of legal documents, and evaluated three BERT-based models. XLMRoBERTa, mBERT, and DistilBERT by analyzing their performance on an annotated Urdu legal dataset. mBERT demonstrated superior accuracy (0.999), and its F1 score (0.975) outperforms XLMRoBERTa and DistilBERT, highlighting its robustness in recognizing entities within low-resource languages. To ensure the privacy of the personal identifiers, all documents are anonymized. The dataset for this study is publicly hosted on Hugging Face and will be made public after the publication.</abstract>
      <url hash="570ce8c6">2025.ranlp-1.161</url>
      <bibkey>zafar-etal-2025-courtroom</bibkey>
    </paper>
    <paper id="162">
      <title><fixed-case>E</fixed-case>mo<fixed-case>H</fixed-case>ope<fixed-case>S</fixed-case>peech: An Annotated Dataset of Emotions and Hope Speech in <fixed-case>E</fixed-case>nglish and <fixed-case>A</fixed-case>rabic</title>
      <author><first>Wajdi</first><last>Zaghouani</last></author>
      <author><first>Md. Rafiul</first><last>Biswas</last></author>
      <pages>1406–1412</pages>
      <abstract>This research introduces a bilingual dataset comprising 27,456 entries for Arabic and 10,036 entries for English, annotated for emotions and hope speech, addressing the scarcity of multi-emotion (Emotion and hope) datasets. The dataset provides comprehensive annotations capturing emotion intensity, complexity, and causes, alongside detailed classifications and subcategories for hope speech. To ensure annotation reliability, Fleiss’ Kappa was employed, revealing 0.75-0.85 agreement among annotators both for Arabic and English language. The evaluation metrics (micro-F1-Score=0.67) obtained from the baseline model (i.e., transformer-based AraBERT model) validate that the data annotations are worthy.</abstract>
      <url hash="5ac888d3">2025.ranlp-1.162</url>
      <bibkey>zaghouani-biswas-2025-emohopespeech</bibkey>
    </paper>
    <paper id="163">
      <title>An Annotated Corpus of <fixed-case>A</fixed-case>rabic Tweets for Hate Speech Analysis</title>
      <author><first>Wajdi</first><last>Zaghouani</last></author>
      <author><first>Md. Rafiul</first><last>Biswas</last></author>
      <pages>1413–1419</pages>
      <abstract>Identifying hate speech content in the Arabic language is challenging due to the rich quality of dialectal variations. This study introduces a multilabel hate speech dataset in the Arabic language. We have collected 10,000 Arabic tweets and annotated each tweet, whether it contains offensive content or not. If a text contains offensive content, we further classify it into different hate speech targets such as religion, gender, politics, ethnicity, origin, and others. A text can contain either single or multiple targets. Multiple annotators are involved in the data annotation task. We calculated the inter-annotator agreement, which was reported to be 0.86 for offensive content and 0.71 for multiple hate speech targets. Finally, we evaluated the data annotation task by employing a different transformers-based model in which AraBERTv2 outperformed with a micro-F1 score of 0.7865 and an accuracy of 0.786.</abstract>
      <url hash="0fc3a03a">2025.ranlp-1.163</url>
      <bibkey>zaghouani-biswas-2025-annotated</bibkey>
    </paper>
    <paper id="164">
      <title>Strategies for Efficient Retrieval-augmented Generation in Clinical Domains with <fixed-case>RAPTOR</fixed-case>: A Benchmarking Study</title>
      <author><first>Xumou</first><last>Zhang</last></author>
      <author><first>Qixuan</first><last>Hu</last></author>
      <author><first>Jinman</first><last>Kim</last></author>
      <author><first>Adam G.</first><last>Dunn</last></author>
      <pages>1420–1429</pages>
      <abstract>The Recursive Abstractive Processing for Tree-Organized Retrieval (RAPTOR) framework deploys a hierarchical tree-structured datastore to integrate local and global context, enabling efficient handling of long documents for language models. This design is especially useful when cloud-based language models are unavailable or undesirable. For instance, with offline confidential patient records or stringent data-privacy requirements. We benchmarked RAPTOR on the QuALITY dataset and a novel Clinical Trial question-answering dataset (CTQA) drawn from over 500 000 registry entries. Experiments varied question complexity (simple vs. complex), four language models, four embedding models, and three chunking strategies. Also incorporated GPT-4o as a cloud-based baseline. Results show that, with optimal settings, RAPTOR combined with smaller local models outperforms GPT-4o on complex CTQA questions, although this gain does not extend to QuALITY. These outcomes highlight RAPTOR’s promise as a practical, locally implementable solution for long-context understanding.</abstract>
      <url hash="32d37260">2025.ranlp-1.164</url>
      <bibkey>zhang-etal-2025-strategies</bibkey>
    </paper>
    <paper id="165">
      <title><fixed-case>LLM</fixed-case>-Based Product Recommendation with Prospect Theoretic Self Alignment Strategy</title>
      <author><first>Manying</first><last>Zhang</last></author>
      <author><first>Zehua</first><last>Cheng</last></author>
      <author><first>Damien</first><last>Nouvel</last></author>
      <pages>1430–1436</pages>
      <abstract>Accurate and personalized product recommendation is central to user satisfaction in e-commerce. However, a persistent language gap often exists between user queries and product titles or descriptions. While traditional user behavior-based recommenders and LLM-based Retrieval-Augmented Generation systems typically optimize for maximum likelihood objectives, they may struggle to bridge this gap or capture users’ true intent. In this paper, we propose a strategy based on Prospect Theoretic Self-Alignment, that reframes LLM-based recommendations as a utility-driven process. Given a user query and a set of candidate products, our model acts as a seller who anticipates latent user needs and generates product descriptions tailored to the user’s perspective. Simultaneously, it simulates user decision-making utility to assess whether the generated content would lead to a purchase. This self-alignment is achieved through a training strategy grounded in Kahneman &amp; Tversky’s prospect theory, ensuring that recommendations are optimized for perceived user value rather than likelihood alone. Experiments on real-world product data demonstrate substantial improvements in intent alignment and recommendation quality, validating the effectiveness of our approach in producing personalized and decision-aware recommendations.</abstract>
      <url hash="36e2d205">2025.ranlp-1.165</url>
      <bibkey>zhang-etal-2025-llm-based-product</bibkey>
    </paper>
    <paper id="166">
      <title>Branching Out: Exploration of <fixed-case>C</fixed-case>hinese Dependency Parsing with Fine-tuned Large Language Models</title>
      <author><first>He</first><last>Zhou</last></author>
      <author><first>Emmanuele</first><last>Chersoni</last></author>
      <author><first>Yu-Yin</first><last>Hsu</last></author>
      <pages>1437–1445</pages>
      <abstract>In this paper, we investigate the effectiveness of large language models (LLMs) for Chinese dependency parsing through fine-tuning. We explore how different dependency representations impact parsing performance when fine-tuning the Chinese Llama-3 model. Our results demonstrate that while the Stanford typed dependency tuple representation yields the highest number of valid dependency trees, converting dependency structure into a lexical centered tree produces parses of significantly higher quality despite generating fewer valid structures. The results further show that fine-tuning enhances LLMs’ capability to handle longer dependencies to some extent, though challenges remain. Additionally, we evaluate the effectiveness of DeepSeek in correcting LLM-generated dependency structures, finding that it is effective for fixing index errors and cyclicity issues but still suffers from tokenization mismatches. Our analysis across dependency distances and relations reveals that fine-tuned LLMs outperform traditional parsers in specific syntactic structures while struggling with others. These findings contribute to the research on leveraging LLMs for syntactic analysis tasks.</abstract>
      <url hash="1b82c2b6">2025.ranlp-1.166</url>
      <bibkey>zhou-etal-2025-branching</bibkey>
    </paper>
  </volume>
  <volume id="stud" ingest-date="2026-01-07" type="proceedings">
    <meta>
      <booktitle>Proceedings of the 9th Student Research Workshop associated with the International Conference Recent Advances in Natural Language Processing</booktitle>
      <editor><first>Boris</first><last>Velichkov</last></editor>
      <editor><first>Ivelina</first><last>Nikolova-Koleva</last></editor>
      <editor><first>Milena</first><last>Slavcheva</last></editor>
      <publisher>INCOMA Ltd., Shoumen, Bulgaria</publisher>
      <address>Varna, Bulgaria</address>
      <month>September</month>
      <year>2025</year>
      <url hash="7d873717">2025.ranlp-stud</url>
      <venue>ranlp</venue>
      <venue>ws</venue>
    </meta>
    <frontmatter>
      <url hash="85073d63">2025.ranlp-stud.0</url>
      <bibkey>ranlp-2025-stud</bibkey>
    </frontmatter>
    <paper id="1">
      <title>A Multi-Baseline Framework for Ranking Global Event Significance Using <fixed-case>G</fixed-case>oogle Trends and Large Language Models</title>
      <author><first>Zenan</first><last>Chen</last></author>
      <pages>1–9</pages>
      <abstract>Determining global event significance lacks standardized metrics for quantifying worldwide impact. While Google Trends has demonstrated utility in domain-specific studies, its application to global event ranking remains limited. This paper presents a framework combining Google Trends data with large language models for automated global event ranking. This study leverages Command R+ and Llama 3.3-70B-Instruct to generate contextually relevant event keywords and establishes significance through comparative search volume analysis against baseline reference terms, incorporating temporal weighting mechanisms to address chronological biases. The proposed methodology identified globally significant events across technology, health, sports, and natural disasters from a dataset of 1,094 events (2020-2024) extracted from Wikipedia.</abstract>
      <url hash="33bf93e0">2025.ranlp-stud.1</url>
      <bibkey>chen-2025-multi</bibkey>
    </paper>
    <paper id="2">
      <title>Investigating Hierarchical Structure in Multi-Label Document Classification</title>
      <author><first>Artemis</first><last>Dampa</last></author>
      <pages>10–19</pages>
      <abstract>Effectively organizing the vast and ever-growing body of research in scientific literature is crucial to advancing the field and supporting scholarly discovery. In this paper, we study the task of fine-grained hierarchical multi-label classification of scholarly articles, using a structured taxonomy. Specifically, we investigate whether incorporating hierarchical information in a classification method can improve performance compared to conventional flat classification approaches. To this end, we suggest and evaluate different strategies for the classification, on three different axes: selection of positive and negative samples; soft-to-hard label mapping; hierarchical post-processing policies that utilize taxonomy-related requirements to update the final labeling. Experiments demonstrate that flat baselines constitute powerful baselines, but the infusion of hierarchical knowledge leads to better recall-focused performance based on use-case requirements.</abstract>
      <url hash="cfd05739">2025.ranlp-stud.2</url>
      <bibkey>dampa-2025-investigating</bibkey>
    </paper>
    <paper id="3">
      <title>Large Language Models for Lexical Resource Enhancement: Multiple Hypernymy Resolution in <fixed-case>W</fixed-case>ord<fixed-case>N</fixed-case>et</title>
      <author><first>Dimitar</first><last>Hristov</last></author>
      <pages>20–26</pages>
      <abstract>Large language models (LLMs) have materially changed natural language processing (NLP). While LLMs have shifted focus from traditional semantic-based resources, structured linguistic databases such as WordNet remain essential for precise knowledge retrieval, decision making and aiding LLM development. WordNet organizes concepts through synonym sets (synsets) and semantic links but suffers from inconsistencies, including redundant or erroneous relations. This paper investigates an approach using LLMs to aid the refinement of structured language resources, specifically WordNet, by an automation for multiple hypernymy resolution, leveraging the LLMs semantic knowledge to produce tools for aiding and evaluating manual resource improvement.</abstract>
      <url hash="1b3af777">2025.ranlp-stud.3</url>
      <bibkey>hristov-2025-large</bibkey>
    </paper>
    <paper id="4">
      <title>Automated classification of causal relations. Evaluating different <fixed-case>LLM</fixed-case> performances.</title>
      <author><first>Giacomo</first><last>Magnifico</last></author>
      <pages>27–36</pages>
      <abstract>The search for formal causal relations in natural language faces inherent limitations due to the lack of mathematically and logically informed datasets. Thus, the exploration of causal relations in natural language leads to the analysis of formal-logic-adjacent language patterns. Thanks to the recent advancements of generative LLMs, this research niche is expanding within the field of natural language processing and evaluation. In this work, we conduct an evaluation of 9 models produced by different AI developing companies in order to answer the question “Are LLMs capable of discerning between different types of causal relations?”. The SciExpl dataset is chosen as a natural language corpus, and we develop three different prompt types aligned with zero-shot, few-shot, and chain-of-thought standards to evaluate the performance of the LLMs. Claude 3.7 Sonnet and Gemini 2.5 Flash Preview emerge as the best models for the task, with the respective highest F1 scores of 0.842 (few-shot prompting) and 0.846 (chain-of-thought prompting).</abstract>
      <url hash="f4e57628">2025.ranlp-stud.4</url>
      <bibkey>magnifico-2025-automated</bibkey>
    </paper>
    <paper id="5">
      <title>Study on Automatic Punctuation Restoration in Bilingual Broadcast Stream</title>
      <author><first>Martin</first><last>Polacek</last></author>
      <pages>37–43</pages>
      <abstract>In this study, we employ various ELECTRA-Small models that are pre-trained and fine-tuned on specific sets of languages for automatic punctuation restoration (APR) in automatically transcribed TV and radio shows, which contain conversations in two closely related languages. Our evaluation data specifically concerns bilingual interviews in Czech and Slovak and data containing speeches in Swedish and Norwegian. We train and evaluate three types of models: the multilingual (mELECTRA) model, which is pre-trained for 13 European languages; two bilingual models, each pre-trained for one language pair; and four monolingual models, each pre-trained for a single language. Our experimental results show that a) fine-tuning, which must be performed using data belonging to both target languages, is the key step in developing a bilingual APR system and b) the mELECTRA model yields competitive results, making it a viable option for bilingual APR and other multilingual applications. Thus, we publicly release our pre-trained bilingual and, in particular, multilingual ELECTRA-small models on HuggingFace, fostering further research in various multilingual tasks.</abstract>
      <url hash="564af393">2025.ranlp-stud.5</url>
      <bibkey>polacek-2025-study</bibkey>
    </paper>
    <paper id="6">
      <title><fixed-case>N</fixed-case>o<fixed-case>C</fixed-case>s: A Non-Compound-Stable Splitter for <fixed-case>G</fixed-case>erman Compounds</title>
      <author><first>Carmen</first><last>Schacht</last></author>
      <pages>44–53</pages>
      <abstract>Compounding—the creation of highly complex lexical items through the combination of existing lexemes—can be considered one of the most efficient communication phenomenons, though the automatic processing of compound structures—especially of multi-constituent compounds—poses significant challenges for natural language processing. Existing tools like compound-split (Tuggener, 2016) perform well on compound head detection but are limited in handling long compounds and distinguishing compounds from non-compounds. This paper introduces NoCs (non-compound-stable splitter), a novel Python-based tool that extends the functionality of compound-split by incorporating recursive splitting, non-compound detection, and integration with state-of-the-art linguistic resources. NoCs employs a custom stack-and-buffer mechanism to traverse and decompose compounds robustly, even in cases involving multiple constituents. A large-scale evaluation using adapted GermaNet data shows that NoCs substantially outperforms compound-split in both non-compound identification and the recursive splitting of three- to five-constituent compounds, demonstrating its utility as a reliable resource for compound analysis in German.</abstract>
      <url hash="09b7a971">2025.ranlp-stud.6</url>
      <bibkey>schacht-2025-nocs</bibkey>
    </paper>
    <paper id="7">
      <title>A Proposal for Evaluating the Linguistic Quality of Synthetic <fixed-case>S</fixed-case>panish Corpora</title>
      <author><first>Lucia</first><last>Sevilla-Requena</last></author>
      <pages>54–61</pages>
      <abstract>Large language models (LLMs) rely heavily on high-quality training data, yet human-generated corpora face increasing scarcity due to legal and practical constraints. Synthetic data generated by LLMs is emerging as a scalable alternative; however, concerns remain about its linguistic quality and diversity. While previous research has identified potential degradation in English synthetic corpora, the effects in Spanish, a language with distinct grammatical characteristics, remain underexplored. This research proposal aims to conduct a systematic linguistic evaluation of synthetic Spanish corpora generated by state-of-the-art LLMs, comparing them with human-written texts. The study will analyse three key dimensions: lexical, syntactic, and semantic diversity, using established corpus linguistics metrics. Through this comparative framework, the proposal intends to identify potential linguistic simplifications and degradation patterns in synthetic Spanish data. Ultimately, the proposed outcome is expected to contribute valuable insights to support the creation of robust and reliable Natural Language Processing (NLP) models for Spanish.</abstract>
      <url hash="b8ccfa1c">2025.ranlp-stud.7</url>
      <bibkey>sevilla-requena-2025-proposal</bibkey>
    </paper>
    <paper id="8">
      <title>Personalizing chatbot communication with associative memory</title>
      <author><first>Kirill</first><last>Soloshenko</last></author>
      <author><first>Alexandra</first><last>Shatalina</last></author>
      <author><first>Marina</first><last>Sevostyanova</last></author>
      <author><first>Elizaveta</first><last>Kornilova</last></author>
      <author><first>Konstantin</first><last>Zaitsev</last></author>
      <pages>62–69</pages>
      <abstract>In our research paper we present the approach that is aimed at effectively expanding the context through integrating a database of associative memory into the pipeline. In order to improve long-term memory and personalization we have utilized methods close to Retrieval-Augmented Generation (RAG). Our method uses a multi-agent pipeline with a cold-start agent for initial interactions, a fact extraction agent to process user inputs, an associative memory agent for storing and retrieving context, and a generation agent for replying to user’s queries.Evaluation results show promising results: a 41% accuracy improvement over the base Gemma3 model (from 16% to 57%). Hence, with our approach, we demonstrate that personalized chatbots can bypass LLM memory limitations while increasing information reliability under the conditions of limited context and memory.</abstract>
      <url hash="b3d1ce79">2025.ranlp-stud.8</url>
      <bibkey>soloshenko-etal-2025-personalizing</bibkey>
    </paper>
    <paper id="9">
      <title>Visualization of <fixed-case>LLM</fixed-case> Annotated Documents</title>
      <author><first>Teodor Todorov</first><last>Valtchev</last></author>
      <author><first>Nikolay</first><last>Paev</last></author>
      <pages>70–77</pages>
      <abstract>The paper presents an automatic annotation and visualization system for documents in the field of Social Sciences and Humanities. The annotation is on two levels, named Entities and Events. The system combines automatically generated annotations from language models with a powerful text editor that is extended to accommodate manual annotation. The goal is to support the extraction of information from historical documents by scientists in the SS&amp;H field. At the time of writing of the paper, the system is still in development.</abstract>
      <url hash="7885ae61">2025.ranlp-stud.9</url>
      <bibkey>valtchev-paev-2025-visualization</bibkey>
    </paper>
  </volume>
  <volume id="ahasis" ingest-date="2026-01-07" type="proceedings">
    <meta>
      <booktitle>Proceedings of the Shared Task on Sentiment Analysis for Arabic Dialects</booktitle>
      <editor><first>Maram</first><last>Alharbi</last></editor>
      <editor><first>Salmane</first><last>Chafik</last></editor>
      <editor><first>Saad</first><last>Ezzini</last></editor>
      <editor id="ruslan-mitkov"><first>Ruslan</first><last>Mitkov</last></editor>
      <editor><first>Tharindu</first><last>Ranasinghe</last></editor>
      <editor><first>Hansi</first><last>Hettiarachchi</last></editor>
      <publisher>INCOMA Ltd., Shoumen, Bulgaria</publisher>
      <address>Varna, Bulgaria</address>
      <month>September</month>
      <year>2025</year>
      <url hash="b8f8789d">2025.ranlp-ahasis</url>
      <venue>ranlp</venue>
      <venue>ws</venue>
    </meta>
    <frontmatter>
      <url hash="5880a0b5">2025.ranlp-ahasis.0</url>
      <bibkey>ranlp-ws-2025-ahasis</bibkey>
    </frontmatter>
    <paper id="1">
      <title><fixed-case>AH</fixed-case>a<fixed-case>SIS</fixed-case>: Shared Task on Sentiment Analysis for <fixed-case>A</fixed-case>rabic Dialects</title>
      <author><first>Maram I.</first><last>Alharbi</last></author>
      <author><first>Salmane</first><last>Chafik</last></author>
      <author><first>Saad</first><last>Ezzini</last></author>
      <author id="ruslan-mitkov"><first>Ruslan</first><last>Mitkov</last></author>
      <author><first>Tharindu</first><last>Ranasinghe</last></author>
      <author><first>Hansi</first><last>Hettiarachchi</last></author>
      <pages>1–6</pages>
      <abstract>The hospitality industry in the Arab world increasingly relies on customer feedback to shape services, driving the need for advanced Arabic sentiment analysis tools. To address this challenge, the Sentiment Analysis on Arabic Dialects in the Hospitality Domain shared task focuses on Sentiment Detection in Arabic Dialects. This task leverages a multi-dialect, manually curated dataset derived from hotel reviews originally written in Modern Standard Arabic (MSA) and translated into Saudi and Moroccan (Darija) dialects. The dataset consists of 538 sentiment-balanced reviews spanning positive, neutral, and negative categories. Translations were validated by native speakers to ensure dialectal accuracy and sentiment preservation. This resource supports the development of dialect-aware NLP systems for real-world applications in customer experience analysis. More than 40 teams have registered for the shared task, with 12 submitting systems during the evaluation phase. The top-performing system achieved an F1 score of 0.81, demonstrating the feasibility and ongoing challenges of sentiment analysis across Arabic dialects.</abstract>
      <url hash="39f5421d">2025.ranlp-ahasis.1</url>
      <bibkey>alharbi-etal-2025-ahasis</bibkey>
    </paper>
    <paper id="2">
      <title>i<fixed-case>WAN</fixed-case>-<fixed-case>NLP</fixed-case> at <fixed-case>AH</fixed-case>a<fixed-case>SIS</fixed-case> 2025: A Stacked Ensemble of <fixed-case>A</fixed-case>rabic Transformers for Sentiment Analysis on <fixed-case>A</fixed-case>rabic Dialects in the Hospitality Domain</title>
      <author><first>Hend</first><last>Al-Khalifa</last></author>
      <pages>7–13</pages>
      <abstract>This paper details the iWAN-NLP system developed for participation in the AHaSIS 2025 shared task, “Sentiment Analysis on Arabic Dialects in the Hospitality Domain: A Multi-Dialect Benchmark.” Our approach leverages a multi-model ensemble strategy, combining the strengths of MARBERTv2, Saudibert, and DarijaBERT. These pre-trained Arabic language models were fine-tuned for sentiment classification using a 5-fold stratified cross-validation methodology. The final predictions on the test set were derived by averaging the logits produced by each model across all folds and then averaging these combined logits across the three models. This system achieved a macro F1-score of 81.0% on the official evaluation dataset and a cross-validated macro F1-score of 0.8513 (accuracy 0.8628) on the training set. Our findings highlight the effectiveness of ensembling regionally adapted models and robust cross-validation for Arabic sentiment analysis in the hospitality domain, ultimately securing first place in the AHaSIS 2025 shared task.</abstract>
      <url hash="8839fedf">2025.ranlp-ahasis.2</url>
      <bibkey>al-khalifa-2025-iwan</bibkey>
    </paper>
    <paper id="3">
      <title>Fine-tuning <fixed-case>A</fixed-case>ra<fixed-case>B</fixed-case>ert model for arabic sentiment detection</title>
      <author><first>Mustapha</first><last>Jaballah</last></author>
      <author><first>Dhaou</first><last>Ghoul</last></author>
      <author><first>Ammar</first><last>Mars</last></author>
      <pages>14–23</pages>
      <abstract>Arabic exhibits a rich and intricate linguistic landscape, with Modern Standard Arabic (MSA) serving as the formal written and spoken medium, alongside a wide variety of regional dialects used in everyday communication. These dialects vary considerably in syntax, vocabulary, phonology, and meaning, presenting significant challenges for natural language processing (NLP). The complexity is particularly pronounced in sentiment analysis, where emotional expressions and idiomatic phrases differ markedly across regions, hindering consistent and accurate sentiment detection. This paper describes our submission to the Ahasis Shared Task: A Benchmark for Arabic Sentiment Analysis in the hospitality domain. This shared task focuses on advancing sentiment analysis techniques for Arabic dialects in the hotel domain. Our proposed approach achieved an F1 score of 0.88 % on the internal test set (split from the original training data), and 79.16% on the official hidden test set of the shared task. This performance secured our team second place in the Ahasis Shared Task.</abstract>
      <url hash="b8294855">2025.ranlp-ahasis.3</url>
      <bibkey>jaballah-etal-2025-fine</bibkey>
    </paper>
    <paper id="4">
      <title>Enhancing <fixed-case>A</fixed-case>rabic Dialectal Sentiment Analysis through Advanced Data Augmentation Techniques</title>
      <author><first>Md. Rafiul</first><last>Biswas</last></author>
      <author><first>Wajdi</first><last>Zaghouani</last></author>
      <pages>24–28</pages>
      <abstract>This work addresses the challenge of Arabic sentiment analysis in the hospitality domain in all dialects by using data augmentation techniques. We created a pipeline with three simple techniques: context-based paraphrasing, pattern-based sentence generation, and domain-specific word replacement. Our method preserves the original dialect features, meanings, and key classification details while adding diversity to the training data. It also includes automatic fallback between methods to handle challenges effectively. We used the Fanar API for dialectal data augmentation in the hospitality domain. The AraBERT-Large-v02 model was fine-tuned on original and augmented data, showing improved performance. This study helps solve the problem of limited dialect data in Arabic NLP and offers an effective framework that is useful for other Arabic text analysis tasks.</abstract>
      <url hash="ac86ba9a">2025.ranlp-ahasis.4</url>
      <bibkey>biswas-zaghouani-2025-enhancing</bibkey>
    </paper>
    <paper id="5">
      <title>Ahasis Shared Task: Hybrid Lexicon-Augmented <fixed-case>A</fixed-case>ra<fixed-case>BERT</fixed-case> Model for Sentiment Detection in <fixed-case>A</fixed-case>rabic Dialects</title>
      <author><first>Shimaa Amer</first><last>Ibrahim</last></author>
      <author><first>Mabrouka</first><last>Bessghaier</last></author>
      <author><first>Wajdi</first><last>Zaghouani</last></author>
      <pages>29–34</pages>
      <abstract>This work was conducted as part of the Ahasis@RANLP–2025 shared task, which focuses on sentiment detection in Arabic dialects within the hotel review domain. The primary objective is to advance sentiment analysis methodologies tailored to dialectal Arabic. Our work combines data augmentation with a hybrid model that integrates AraBERT and our created sentiment lexicon. Notably, our hybrid model significantly improved performance, reaching an F1-score of 0.74, compared to 0.56 when using only AraBERT. These results highlight the effectiveness of lexicon integration and augmentation strategies in enhancing both the accuracy and robustness of sentiment classification in dialectal Arabic.</abstract>
      <url hash="82ed5865">2025.ranlp-ahasis.5</url>
      <bibkey>ibrahim-etal-2025-ahasis</bibkey>
    </paper>
    <paper id="6">
      <title>Lab17 @ Ahasis Shared Task 2025: Fine-Tuning and Prompting techniques for Sentiment Analysis of Saudi and <fixed-case>D</fixed-case>arija Dialects</title>
      <author><first>Al Mukhtar</first><last>Al Hadhrami</last></author>
      <author><first>Firas</first><last>Al Mahrouqi</last></author>
      <author><first>Mohammed</first><last>Al Shaaili</last></author>
      <author><first>Hala</first><last>Mulki</last></author>
      <pages>35–39</pages>
      <abstract>In this paper, we describe our contribution in Ahasis shared task: Sentiment analysis on Arabic Dialects in the Hospitality Domain. Through the presented framework, we explored using two learning strategies tailored to a Large Language Model (LLM) and Transformer-based model variants. While few-shot prompting was used with GPT-4o, fine-tuning was adopted once to refine the essential MARBERT model on the Ahasis dataset and then to utilize a MARBERT variant model, SODA-BERT, that was pretrained on an Omani sentiment dataset and later evaluated with the shared task data.</abstract>
      <url hash="ff26b011">2025.ranlp-ahasis.6</url>
      <bibkey>al-hadhrami-etal-2025-lab17</bibkey>
    </paper>
    <paper id="7">
      <title>Dialect-Aware Sentiment Analysis for Ahasis Challenge</title>
      <author><first>Hasna</first><last>Chouikhi</last></author>
      <author><first>Manel</first><last>Aloui</last></author>
      <pages>40–45</pages>
      <abstract>This paper presents our approach to Arabic sentiment analysis with a specific focus on dialect-awareness for Saudi and Moroccan (Darija) dialectal variants. We develop a system that achieves a macro F1 score of 77% on the test set, demonstrating effective generalization across these dialect variations. Our approach leverages a pre-trained Arabic language model (Qarib) with custom dialect-specific embeddings and preprocessing techniques tailored to each dialect. The results show a significant improvement over baseline models that do not incorporate dialect information, with an absolute gain of 5% in F1 score over the equivalent non-dialect-aware model. Our analysis further reveals distinct sentiment expression patterns between Saudi and Darija dialects, highlighting the importance of dialect-aware approaches for Arabic sentiment analysis.</abstract>
      <url hash="122daf71">2025.ranlp-ahasis.7</url>
      <bibkey>chouikhi-aloui-2025-dialect</bibkey>
    </paper>
    <paper id="8">
      <title><fixed-case>MAPROC</fixed-case> at <fixed-case>AH</fixed-case>a<fixed-case>SIS</fixed-case> Shared Task: Few-Shot and Sentence Transformer for Sentiment Analysis of <fixed-case>A</fixed-case>rabic Hotel Reviews</title>
      <author><first>Randa</first><last>Zarnoufi</last></author>
      <pages>46–53</pages>
      <abstract>Sentiment analysis of Arabic dialects presents significant challenges due to linguistic diversity and the scarcity of annotated data. This paper describes our approach to the AHaSIS shared task, which focuses on sentiment analysis on Arabic dialects in the hospitality domain. The dataset comprises hotel reviews written in Moroccan and Saudi dialects, and the objective is to classify the reviewers’ sentiment as positive, negative, or neutral. We employed the SetFit (Sentence Transformer Fine-tuning) framework, a data-efficient few-shot learning technique. On the official evaluation set, our system achieved an F1 of 73%, ranking 12th among 26 participants. This work highlights the potential of few-shot learning to address data scarcity in processing nuanced dialectal Arabic text within specialized domains like hotel reviews.</abstract>
      <url hash="5d6ce176">2025.ranlp-ahasis.8</url>
      <bibkey>zarnoufi-2025-maproc</bibkey>
    </paper>
    <paper id="9">
      <title>muc<fixed-case>AI</fixed-case> at Ahasis Shared Task: Sentiment Analysis with Adaptive Few Shot Prompting</title>
      <author><first>Ahmed Mohamed Abdelaal</first><last>Abdou</last></author>
      <pages>54–61</pages>
      <abstract>Sentiment Analysis is a crucial task in Natural Language Processing (NLP) focused on identifying and categorizing emotional tones or opinions within text. For Arabic customer reviews, sentiment analysis is particularly challenging. The language’s rich diversity, with numerous regional dialects differing significantly from Modern Standard Arabic (MSA) and each other in lexicon, syntax, and sentiment expression, complicates consistent performance across dialects. In this paper, we present our approach, submitted to the AHASIS Shared Task 2025, focusing on sentiment analysis for Arabic dialects in the hotel domain. Our method leverages the capabilities of GPT-4o through adaptive few-shot prompting technique, where similar contextual examples are dynamically selected for each review using a k-Nearest Neighbors (kNN) search over train embeddings from a fine-tuned encoder model. This approach tailors the prompt to each specific instance, enhancing classification performance over minority class. Our submission achieved an F1-score of 76.0% on the official test set, showing stronger performance for the Saudi dialect compared to Darija.</abstract>
      <url hash="af5d4211">2025.ranlp-ahasis.9</url>
      <bibkey>abdou-2025-mucai-ahasis</bibkey>
    </paper>
    <paper id="10">
      <title>A Hybrid Transformer-Based Model for Sentiment Analysis of <fixed-case>A</fixed-case>rabic Dialect Hotel Reviews</title>
      <author><first>Rawand</first><last>Alfugaha</last></author>
      <author><first>Mohammad</first><last>AL-Smadi</last></author>
      <pages>62–68</pages>
      <abstract>This paper describes the AraNLP system developed for the “Ahasis” shared task on sentiment detection in Arabic dialects for hotel reviews. The task involved classifying the overall sentiment of hotel reviews (Positive, Negative, or Neutral) written in Arabic dialects, specifically Saudi and Darija. Our proposed model, AraNLP, is a hybrid deep learning classifier that leverages the strengths of a transformer-based Arabic model (AraELECTRA)augmented with classical bag-of-words style features (TF-IDF). Our system achieved an F1-score of 76%, securing the 5th rank in the shared task, significantly outperforming the baseline system’s F1-score of 56%.</abstract>
      <url hash="81d707a5">2025.ranlp-ahasis.10</url>
      <bibkey>alfugaha-al-smadi-2025-hybrid</bibkey>
    </paper>
    <paper id="11">
      <title><fixed-case>A</fixed-case>rabic-Centric Large Language Models for Dialectal <fixed-case>A</fixed-case>rabic Sentiment Analysis Task</title>
      <author><first>Salwa Saad</first><last>Alahmari</last></author>
      <author id="eric-atwell"><first>Eric</first><last>Atwell</last></author>
      <author><first>Hadeel</first><last>Saadany</last></author>
      <author><first>Mohammad</first><last>Alsalka</last></author>
      <pages>69–75</pages>
      <abstract>This paper presents a study on sentiment anal- ysis of Dialectal Arabic (DA), with a particu- lar focus on Saudi and Moroccan (Darija) di- alects within the hospitality domain. We in- troduce a novel dataset comprising 698 Saudi Arabian proverbs annotated with sentiment polarity labels—Positive, Negative, and Neu- tral—collected from five major Saudi dialect regions: Najdi, Hijazi, Shamali, Janoubi, and Sharqawi. In addition to this, we used customer reviews for fine-tuning the CAMeLBERT-DA- SA model, which achieved a 75% F1 score in sentiment classification. To further evaluate the robustness of Arabic-centric models, we assessed the performance of three open-source large language models—Allam, ACeGPT, and Jais—in a zero-shot setting using the Ahasis shared task test set. Our results highlight the effectiveness of domain-specific fine-tuning in improving sentiment analysis performance and demonstrate the potential of Arabic-centric LLMs in zero-shot scenarios. This work con- tributes new linguistic resources and empirical insights to support ongoing research in senti- ment analysis for Arabic dialect</abstract>
      <url hash="e329d007">2025.ranlp-ahasis.11</url>
      <bibkey>alahmari-etal-2025-arabic</bibkey>
    </paper>
    <paper id="12">
      <title>A Gemini-Based Model for <fixed-case>A</fixed-case>rabic Sentiment Analysis of Multi-Dialect Hotel Reviews: Ahasis Shared Task Submission</title>
      <author><first>Mohammed A. H.</first><last>Lubbad</last></author>
      <pages>76–85</pages>
      <abstract>This paper presents a sentiment analysis model tailored for Arabic dialects in the hospitality domain, developed for the Ahasis Shared Task. Leveraging the Gemini Pro 1.5 language model, we address the challenges posed by the diversity of Arabic dialects, specifically Saudi and Moroccan Darija. Our method used the official Ahasis dataset of 3,000 hotel reviews. Through iterative benchmarking, dialect labeling, sarcasm detection, and fine-tuning, we adapted Gemini Pro 1.5 for the task. The final model achieved an F1-score of 0.7361 and ranked 10th on the competition leaderboard. This work shows that prompt engineering and domain adaptation of LLMs can mitigate challenges of dialectal variation, sarcasm, and resource scarcity in Arabic sentiment classification. Our contribution lies in the integration of dialect-specific prompt tuning with real-time batch inference, avoiding retraining. This approach, validated across 3,000 competition samples and 700 internal benchmarks, establishes a novel template for Arabic-domain sentiment pipelines.</abstract>
      <url hash="73be82c6">2025.ranlp-ahasis.12</url>
      <bibkey>lubbad-2025-gemini</bibkey>
    </paper>
    <paper id="13">
      <title>Sentiment Analysis on <fixed-case>A</fixed-case>rabic Dialects: A Multi-Dialect Benchmark</title>
      <author><first>Abdusalam F. Ahmad</first><last>Nwesri</last></author>
      <author><first>Nabila Almabrouk S.</first><last>Shinbir</last></author>
      <author><first>Amani Bahlul</first><last>Sharif</last></author>
      <pages>86–91</pages>
      <abstract>This paper presents our contribution to the AHASIS Shared Task at RANLP 2025, which focuses on sentiment analysis for Arabic dialects. While sentiment analysis has seen considerable progress in Modern Standard Arabic (MSA), the diversity and complexity of Arabic dialects pose unique challenges that remain underexplored. We address this by fine-tuning six pre-trained language models, including AraBERT, MARBERTv2, QARiB, and DarijaBERT, on a sentiment-labeled dataset comprising hotel reviews written in Saudi and Moroccan (Darija) dialects. Our experiments evaluate the models’ performance on both combined and individual dialect datasets. MARBERTv2 achieved the highest performance with an F1-score of 79% on the test set, securing third place among 14 participants. We further analyze the effectiveness of each model across dialects, demonstrating the importance of dialect-aware pretraining for Arabic sentiment analysis. Our findings highlight the value of leveraging large pre-trained models tailored to dialectal Arabic for improved sentiment classification.</abstract>
      <url hash="fd46a664">2025.ranlp-ahasis.13</url>
      <bibkey>nwesri-etal-2025-sentiment</bibkey>
    </paper>
  </volume>
  <volume id="mdaigt" ingest-date="2026-01-07" type="proceedings">
    <meta>
      <booktitle>Proceedings of the Shared Task on Multi-Domain Detection of AI-Generated Text</booktitle>
      <editor><first>Salima</first><last>Lamsiyah</last></editor>
      <editor><first>Saad</first><last>Ezzini</last></editor>
      <editor><first>Abdelkader</first><last>El Mahdaoui</last></editor>
      <editor><first>Hamza</first><last>Alami</last></editor>
      <editor><first>Abdessamad</first><last>Benlahbib</last></editor>
      <editor><first>Samir</first><last>El Amrani</last></editor>
      <editor><first>Salmane</first><last>Chafik</last></editor>
      <editor><first>Hicham</first><last>Hammouchi</last></editor>
      <publisher>INCOMA Ltd., Shoumen, Bulgaria</publisher>
      <address>Varna, Bulgaria</address>
      <month>September</month>
      <year>2025</year>
      <url hash="8ca24b8f">2025.ranlp-mdaigt</url>
      <venue>ranlp</venue>
      <venue>ws</venue>
    </meta>
    <frontmatter>
      <url hash="61f81fc9">2025.ranlp-mdaigt.0</url>
      <bibkey>ranlp-ws-2025-mdaigt</bibkey>
    </frontmatter>
    <paper id="1">
      <title><fixed-case>M</fixed-case>-<fixed-case>DAIGT</fixed-case>: A Shared Task on Multi-Domain Detection of <fixed-case>AI</fixed-case>-Generated Text</title>
      <author><first>Salima</first><last>Lamsiyah</last></author>
      <author><first>Saad</first><last>Ezzini</last></author>
      <author><first>Abdelkader</first><last>El Mahdaouy</last></author>
      <author><first>Hamza</first><last>Alami</last></author>
      <author><first>Abdessamad</first><last>Benlahbib</last></author>
      <author><first>Samir</first><last>El amrany</last></author>
      <author><first>Salmane</first><last>Chafik</last></author>
      <author><first>Hicham</first><last>Hammouchi</last></author>
      <pages>1–9</pages>
      <abstract>The generation of highly fluent text by Large Language Models (LLMs) poses a significant challenge to information integrity and academic research. In this paper, we introduce the Multi-Domain Detection of AI-Generated Text (M-DAIGT) shared task, which focuses on detecting AI-generated text across multiple domains, particularly in news articles and academic writing. M-DAIGT comprises two binary classification subtasks: News Article Detection (NAD) (Subtask 1) and Academic Writing Detection (AWD) (Subtask 2). To support this task, we developed and released a new large-scale benchmark dataset of 30,000 samples, balanced between human-written and AI-generated texts. The AI-generated content was produced using a variety of modern LLMs (e.g., GPT-4, Claude) and diverse prompting strategies. A total of 46 unique teams registered for the shared task, of which four teams submitted final results. All four teams participated in both Subtask 1 and Subtask 2. We describe the methods employed by these participating teams and briefly discuss future directions for M-DAIGT.</abstract>
      <url hash="bd47ebd8">2025.ranlp-mdaigt.1</url>
      <bibkey>lamsiyah-etal-2025-daigt</bibkey>
    </paper>
    <paper id="2">
      <title><fixed-case>AI</fixed-case>-Generated Text Detection Using <fixed-case>D</fixed-case>e<fixed-case>BERT</fixed-case>a with Auxiliary Stylometric Features</title>
      <author><first>Annepaka</first><last>Yadagiri</last></author>
      <author><first>L. D. M. S</first><last>Sai Teja</last></author>
      <author><first>Partha</first><last>Pakray</last></author>
      <author><first>Chukhu</first><last>Chunka</last></author>
      <pages>10–14</pages>
      <abstract>The global proliferation of Generative Artificial Intelligence (GenAI) has led to the increasing presence of AI-generated text across a wide spectrum of topics, ranging from everyday content to critical and specialized domains. Often, individuals are unaware that the text they interact with was produced by AI systems rather than human authors, leading to instances where AI-generated content is unintentionally combined with human-written material. In response to this growing concern, we propose a novel approach as part of the Multi-Domain AI-Generated Text Detection (M-DAIGT) shared task, which aims to accurately identify AI-generated content across multiple domains, particularly in news reporting and academic writing. Given the rapid evolution of large language models (LLMs), distinguishing between human-authored and AI-generated text has become increasingly challenging. To address this, our method employs fine-tuning strategies using transformer-based language models for binary text classification. We focus on two specific domains, news and scholarly writing, and demonstrate that our approach, based on the DeBERTa transformer model, achieves superior performance in identifying AI-generated text. Our team, CNLP-NITS-PP, achieved 5th position in Subtask 1 and 3rd position in Subtask 2.</abstract>
      <url hash="0c62fd9c">2025.ranlp-mdaigt.2</url>
      <bibkey>yadagiri-etal-2025-ai</bibkey>
    </paper>
    <paper id="3">
      <title>Shared Task on Multi-Domain Detection of <fixed-case>AI</fixed-case>-Generated Text (<fixed-case>M</fixed-case>-<fixed-case>DAIGT</fixed-case>)</title>
      <author><first>Sareem</first><last>Farooqui</last></author>
      <author><first>Ali</first><last>Zain</last></author>
      <author><first>Dr Muhammad</first><last>Rafi</last></author>
      <pages>15–19</pages>
      <abstract>We participated in two subtasks: Subtask 1, focusing on news articles, and Subtask 2, focusing on academic abstracts. Our submission is based on three distinct architectural approaches: (1) Fine-tuning a RoBERTa-base model, (2) A TF-IDF based system with a Linear Support Vector Machine (SVM) classifier, and (3) An experimental system named Candace, which leverages probabilistic features extracted from multiple Llama-3.2 models (1B and 3B variants) fed into a Transformer Encoder-based classifier. Our RoBERTa-based system demonstrated strong performance on the development and test sets for both subtasks and was chosen as our primary submission to both the shared subtasks.</abstract>
      <url hash="0654895f">2025.ranlp-mdaigt.3</url>
      <bibkey>farooqui-etal-2025-shared</bibkey>
    </paper>
    <paper id="4">
      <title>A Multimodal Transformer-based Approach for Cross-Domain Detection of Machine-Generated Text</title>
      <author><first>Mohammad</first><last>AL-Smadi</last></author>
      <pages>20–25</pages>
      <abstract>The rapid advancement of large language models (LLMs) has made it increasingly challenging to distinguish between human-written and machine-generated content. This paper presents IntegrityAI, a multimodal ELECTRA-based model for the detection of AI-generated text across multiple domains. Our approach combines textual features processed through a pre-trained ELECTRA model with handcrafted stylometric features to create a robust classifier. We evaluate our system on the Multi-Domain Detection of AI-Generated Text (M-DAIGT) shared task, which focuses on identifying AI-generated content in news articles and academic writing. IntegrityAI achieves exceptional performance and ranked 1st in both subtasks, with F1-scores of 99.6% and 99.9% on the news article detection and academic writing detection subtasks, respectively. Our results demonstrate the effectiveness of combining transformer-based models with stylometric analysis for detecting AI-generated content across diverse domains and writing styles.</abstract>
      <url hash="1d30eaa3">2025.ranlp-mdaigt.4</url>
      <bibkey>al-smadi-2025-multimodal</bibkey>
    </paper>
    <paper id="5">
      <title>Inside the Box: A Streamlined Model for <fixed-case>AI</fixed-case>-Generated News Article Detection</title>
      <author><first>Nsrin</first><last>Ashraf</last></author>
      <author><first>Mariam</first><last>Labib</last></author>
      <author><first>Hamada</first><last>Nayel</last></author>
      <pages>26–30</pages>
      <abstract>The rapid proliferation of AI-generated text has raised concerns. With the increasing prevalence of AI-generated content, concerns have grown regarding authenticity, authorship, and the spread of misinformation. Detecting such content accurately and efficiently has become a pressing challenge. In this study, we propose a simple yet effective system for classifying AI-generated versus human-written text. Rather than relying on complex or resource-intensive deep learning architectures, our approach leverages classical machine learning algorithms combined with the TF-IDF text representation technique. Evaluated on the M-DAIGT shared task dataset, our Support Vector Machine (SVM) based system achieved strong results, ranking second on the official leaderboard and demonstrating competitive performance across all evaluation metrics. These findings highlight the potential of traditional lightweight models to address modern challenges in text authenticity detection, particularly in low-resource or real-time applications where interpretability and efficiency are essential.</abstract>
      <url hash="fffab036">2025.ranlp-mdaigt.5</url>
      <bibkey>ashraf-etal-2025-inside</bibkey>
    </paper>
  </volume>
  <event id="ranlp-2025">
    <meta>
      <title>The 15th International Conference on Recent Advances in Natural Language Processing</title>
      <location>Varna, Bulgaria</location>
      <dates>September 8-10, 2025</dates>
    </meta>
    <colocated>
      <volume-id>2025.case-1</volume-id>
      <volume-id>2025.ethicalllms-1</volume-id>
      <volume-id>2025.gaze4nlp-1</volume-id>
      <volume-id>2025.globalnlp-1</volume-id>
      <volume-id>2025.lm4dh-1</volume-id>
      <volume-id>2025.lowresnlp-1</volume-id>
      <volume-id>2025.ommm-1</volume-id>
      <volume-id>2025.r2lm-1</volume-id>
    </colocated>
  </event>
</collection>
