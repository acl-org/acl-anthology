<?xml version='1.0' encoding='UTF-8'?>
<collection id="2022.osact">
  <volume id="1" ingest-date="2022-09-23">
    <meta>
      <booktitle>Proceedinsg of the 5th Workshop on Open-Source Arabic Corpora and Processing Tools with Shared Tasks on Qur'an QA and Fine-Grained Hate Speech Detection</booktitle>
      <editor><first>Hend</first><last>Al-Khalifa</last></editor>
      <editor><first>Tamer</first><last>Elsayed</last></editor>
      <editor><first>Hamdy</first><last>Mubarak</last></editor>
      <editor><first>Abdulmohsen</first><last>Al-Thubaity</last></editor>
      <editor><first>Walid</first><last>Magdy</last></editor>
      <editor><first>Kareem</first><last>Darwish</last></editor>
      <publisher>European Language Resources Association</publisher>
      <address>Marseille, France</address>
      <month>June</month>
      <year>2022</year>
      <url hash="f399629f">2022.osact-1</url>
      <venue>osact</venue>
    </meta>
    <frontmatter>
      <url hash="4086ebe2">2022.osact-1.0</url>
      <bibkey>osact-2022-proceedinsg</bibkey>
    </frontmatter>
    <paper id="1">
      <title><fixed-case>TURJUMAN</fixed-case>: A Public Toolkit for Neural <fixed-case>A</fixed-case>rabic Machine Translation</title>
      <author><first>El Moatez Billah</first><last>Nagoudi</last></author>
      <author><first>AbdelRahim</first><last>Elmadany</last></author>
      <author><first>Muhammad</first><last>Abdul-Mageed</last></author>
      <pages>1–11</pages>
      <abstract>We present TURJUMAN, a neural toolkit for translating from 20 languages into Modern Standard Arabic (MSA). TURJUMAN exploits the recently-introduced text-to-text Transformer AraT5 model, endowing it with a powerful ability to decode into Arabic. The toolkit offers the possibility of employing a number of diverse decoding methods, making it suited for acquiring paraphrases for the MSA translations as an added value. To train TURJUMAN, we sample from publicly available parallel data employing a simple semantic similarity method to ensure data quality. This allows us to prepare and release AraOPUS-20, a new machine translation benchmark. We publicly release our translation toolkit (TURJUMAN) as well as our benchmark dataset (AraOPUS-20).</abstract>
      <url hash="4a706d98">2022.osact-1.1</url>
      <bibkey>nagoudi-etal-2022-turjuman</bibkey>
      <pwccode url="https://github.com/ubc-nlp/turjuman" additional="false">ubc-nlp/turjuman</pwccode>
    </paper>
    <paper id="2">
      <title>Detecting Users Prone to Spread Fake News on <fixed-case>A</fixed-case>rabic <fixed-case>T</fixed-case>witter</title>
      <author><first>Zien</first><last>Sheikh Ali</last></author>
      <author><first>Abdulaziz</first><last>Al-Ali</last></author>
      <author><first>Tamer</first><last>Elsayed</last></author>
      <pages>12–22</pages>
      <abstract>The spread of misinformation has become a major concern to our society, and social media is one of its main culprits. Evidently, health misinformation related to vaccinations has slowed down global efforts to fight the COVID-19 pandemic. Studies have shown that fake news spreads substantially faster than real news on social media networks. One way to limit this fast dissemination is by assessing information sources in a semi-automatic way. To this end, we aim to identify users who are prone to spread fake news in Arabic Twitter. Such users play an important role in spreading misinformation and identifying them has the potential to control the spread. We construct an Arabic dataset on Twitter users, which consists of 1,546 users, of which 541 are prone to spread fake news (based on our definition). We use features extracted from users’ recent tweets, e.g., linguistic, statistical, and profile features, to predict whether they are prone to spread fake news or not. To tackle the classification task, multiple learning models are employed and evaluated. Empirical results reveal promising detection performance, where an F1 score of 0.73 was achieved by the logistic regression model. Moreover, when tested on a benchmark English dataset, our approach has outperformed the current state-of-the-art for this task.</abstract>
      <url hash="4721c1cb">2022.osact-1.2</url>
      <bibkey>sheikh-ali-etal-2022-detecting</bibkey>
      <pwccode url="https://gitlab.com/bigirqu/arpfn" additional="false">bigirqu/arpfn</pwccode>
    </paper>
    <paper id="3">
      <title><fixed-case>A</fixed-case>ra<fixed-case>SAS</fixed-case>: The Open Source <fixed-case>A</fixed-case>rabic Semantic Tagger</title>
      <author><first>Mahmoud</first><last>El-Haj</last></author>
      <author><first>Elvis</first><last>de Souza</last></author>
      <author><first>Nouran</first><last>Khallaf</last></author>
      <author><first>Paul</first><last>Rayson</last></author>
      <author><first>Nizar</first><last>Habash</last></author>
      <pages>23–31</pages>
      <abstract>This paper presents (AraSAS) the first open-source Arabic semantic analysis tagging system. AraSAS is a software framework that provides full semantic tagging of text written in Arabic. AraSAS is based on the UCREL Semantic Analysis System (USAS) which was first developed to semantically tag English text. Similarly to USAS, AraSAS uses a hierarchical semantic tag set that contains 21 major discourse fields and 232 fine-grained semantic field tags. The paper describes the creation, validation and evaluation of AraSAS. In addition, we demonstrate a first case study to illustrate the affordances of applying USAS and AraSAS semantic taggers on the Zayed University Arabic-English Bilingual Undergraduate Corpus (ZAEBUC) (Palfreyman and Habash, 2022), where we show and compare the coverage of the two semantic taggers through running them on Arabic and English essays on different topics. The analysis expands to compare the taggers when run on texts in Arabic and English written by the same writer and texts written by male and by female students. Variables for comparison include frequency of use of particular semantic sub-domains, as well as the diversity of semantic elements within a text.</abstract>
      <url hash="efc025c7">2022.osact-1.3</url>
      <bibkey>el-haj-etal-2022-arasas</bibkey>
    </paper>
    <paper id="4">
      <title><fixed-case>A</fixed-case>ra<fixed-case>NPCC</fixed-case>: The <fixed-case>A</fixed-case>rabic Newspaper <fixed-case>COVID</fixed-case>-19 Corpus</title>
      <author><first>Abdulmohsen</first><last>Al-Thubaity</last></author>
      <author><first>Sakhar</first><last>Alkhereyf</last></author>
      <author><first>Alia O.</first><last>Bahanshal</last></author>
      <pages>32–40</pages>
      <abstract>This paper introduces a corpus for Arabic newspapers during COVID-19: AraNPCC. The AraNPCC corpus covers 2019 until 2021 via automatically-collected data from 12 Arab countries. It comprises more than 2 billion words and 7.2 million texts alongside their metadata. AraNPCC can be used for several natural language processing tasks, such as updating available Arabic language models or corpus linguistics tasks, including language change over time. We utilized the corpus in two case studies. In the first case study, we investigate the correlation between the number of officially reported infected cases and the collective word frequency of “COVID” and “Corona.” The data shows a positive correlation that varies among Arab countries. For the second case study, we extract and compare the top 50 keywords in 2020 and 2021 to study the impact of the COVID-19 pandemic on two Arab countries, namely Algeria and Saudi Arabia. For 2020, the data shows that the two countries’ newspapers strongly interacted with the pandemic, emphasizing its spread and dangerousness, and in 2021 the data suggests that the two countries coped with the pandemic.</abstract>
      <url hash="35ab7854">2022.osact-1.4</url>
      <bibkey>al-thubaity-etal-2022-aranpcc</bibkey>
    </paper>
    <paper id="5">
      <title>Pre-trained Models or Feature Engineering: The Case of Dialectal <fixed-case>A</fixed-case>rabic</title>
      <author><first>Kathrein</first><last>Abu Kwaik</last></author>
      <author><first>Stergios</first><last>Chatzikyriakidis</last></author>
      <author><first>Simon</first><last>Dobnik</last></author>
      <pages>41–50</pages>
      <abstract>The usage of social media platforms has resulted in the proliferation of work on Arabic Natural Language Processing (ANLP), including the development of resources. There is also an increased interest in processing Arabic dialects and a number of models and algorithms have been utilised for the purpose of Dialectal Arabic Natural Language Processing (DANLP). In this paper, we conduct a comparison study between some of the most well-known and most commonly used methods in NLP in order to test their performance on different corpora and two NLP tasks: Dialect Identification and Sentiment Analysis. In particular, we compare three general classes of models: a) traditional Machine Learning models with features, b) classic Deep Learning architectures (LSTMs) with pre-trained word embeddings and lastly c) different Bidirectional Encoder Representations from Transformers (BERT) models such as (Multilingual-BERT, Ara-BERT, and Twitter-Arabic-BERT). The results of the comparison show that using feature-based classification can still compete with BERT models in these dialectal Arabic contexts. The use of transformer models have the ability to outperform traditional Machine Learning approaches, depending on the type of text they have been trained on, in contrast to classic Deep Learning models like LSTMs which do not perform well on the tasks</abstract>
      <url hash="7ad6dc7e">2022.osact-1.5</url>
      <bibkey>abu-kwaik-etal-2022-pre</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/astd">ASTD</pwcdataset>
    </paper>
    <paper id="6">
      <title>A Context-free <fixed-case>A</fixed-case>rabic Emoji Sentiment Lexicon (<fixed-case>CF</fixed-case>-<fixed-case>A</fixed-case>rab-<fixed-case>ESL</fixed-case>)</title>
      <author><first>Shatha Ali A.</first><last>Hakami</last></author>
      <author><first>Robert</first><last>Hendley</last></author>
      <author><first>Phillip</first><last>Smith</last></author>
      <pages>51–59</pages>
      <abstract>Emoji can be valuable features in textual sentiment analysis. One of the key elements of the use of emoji in sentiment analysis is the emoji sentiment lexicon. However, constructing such a lexicon is a challenging task. This is because interpreting the sentiment conveyed by these pictographic symbols is highly subjective, and differs depending upon how each person perceives them. Cultural background is considered to be one of the main factors that affects emoji sentiment interpretation. Thus, we focus in this work on targeting people from Arab cultures. This is done by constructing a context-free Arabic emoji sentiment lexicon annotated by native Arabic speakers from seven different regions (Gulf, Egypt, Levant, Sudan, North Africa, Iraq, and Yemen) to see how these Arabic users label the sentiment of these symbols without a textual context. We recruited 53 annotators (males and females) to annotate 1,069 unique emoji. Then we evaluated the reliability of the annotation for each participant by applying sensitivity (Recall) and consistency (Krippendorff’s Alpha) tests. For the analysis, we investigated the resulting emoji sentiment annotations to explore the impact of the Arabic cultural context. We analyzed this cultural reflection from different perspectives, including national affiliation, use of colour indications, animal indications, weather indications and religious impact.</abstract>
      <url hash="9e8436b0">2022.osact-1.6</url>
      <bibkey>hakami-etal-2022-context</bibkey>
      <pwccode url="https://github.com/shathahakami/context-free-arabic-emoji-sentiment-lexicon" additional="true">shathahakami/context-free-arabic-emoji-sentiment-lexicon</pwccode>
    </paper>
    <paper id="7">
      <title><fixed-case>S</fixed-case>a‘7r: A Saudi Dialect Irony Dataset</title>
      <author><first>Halah</first><last>AlMazrua</last></author>
      <author><first>Najla</first><last>AlHazzani</last></author>
      <author><first>Amaal</first><last>AlDawod</last></author>
      <author><first>Lama</first><last>AlAwlaqi</last></author>
      <author><first>Noura</first><last>AlReshoudi</last></author>
      <author><first>Hend</first><last>Al-Khalifa</last></author>
      <author><first>Luluh</first><last>AlDhubayi</last></author>
      <pages>60–70</pages>
      <abstract>In sentiment analysis, detecting irony is considered a major challenge. The key problem with detecting irony is the difficulty to recognize the implicit and indirect phrases which signifies the opposite meaning. In this paper, we present Sa‘7r ساخرthe Saudi irony dataset, and describe our efforts in constructing it. The dataset was collected using Twitter API and it consists of 19,810 tweets, 8,089 of them are labeled as ironic tweets. We trained several models for irony detection task using machine learning models and deep learning models. The machine learning models include: K-Nearest Neighbor (KNN), Logistic Regression (LR), Support Vector Machine (SVM), and Naïve Bayes (NB). While the deep learning models include BiLSTM and AraBERT. The detection results show that among the tested machine learning models, the SVM outperformed other classifiers with an accuracy of 0.68. On the other hand, the deep learning models achieved an accuracy of 0.66 in the BiLSTM model and 0.71 in the AraBERT model. Thus, the AraBERT model achieved the most accurate result in detecting irony phrases in Saudi Dialect.</abstract>
      <url hash="2708829c">2022.osact-1.7</url>
      <bibkey>almazrua-etal-2022-sa7r</bibkey>
    </paper>
    <paper id="8">
      <title>Classifying <fixed-case>A</fixed-case>rabic Crisis Tweets using Data Selection and Pre-trained Language Models</title>
      <author><first>Alaa</first><last>Alharbi</last></author>
      <author><first>Mark</first><last>Lee</last></author>
      <pages>71–78</pages>
      <abstract>User-generated Social Media (SM) content has been explored as a valuable and accessible source of data about crises to enhance situational awareness and support humanitarian response efforts. However, the timely extraction of crisis-related SM messages is challenging as it involves processing large quantities of noisy data in real-time. Supervised machine learning methods have been successfully applied to this task but such approaches require human-labelled data, which are unlikely to be available from novel and emerging crises. Supervised machine learning algorithms trained on labelled data from past events did not usually perform well when classifying a new disaster due to data variations across events. Using the BERT embeddings, we propose and investigate an instance distance-based data selection approach for adaptation to improve classifiers’ performance under a domain shift. The K-nearest neighbours algorithm selects a subset of multi-event training data that is most similar to the target event. Results show that fine-tuning a BERT model on a selected subset of data to classify crisis tweets outperforms a model that has been fine-tuned on all available source data. We demonstrated that our approach generally works better than the self-training adaptation method. Combing the self-training with our proposed classifier does not enhance the performance.</abstract>
      <url hash="600bd715">2022.osact-1.8</url>
      <bibkey>alharbi-lee-2022-classifying</bibkey>
    </paper>
    <paper id="9">
      <title>Qur’an <fixed-case>QA</fixed-case> 2022: Overview of The First Shared Task on Question Answering over the Holy Qur’an</title>
      <author><first>Rana</first><last>Malhas</last></author>
      <author><first>Watheq</first><last>Mansour</last></author>
      <author><first>Tamer</first><last>Elsayed</last></author>
      <pages>79–87</pages>
      <abstract>Motivated by the resurgence of the machine reading comprehension (MRC) research, we have organized the first Qur’an Question Answering shared task, “Qur’an QA 2022”. The task in its first year aims to promote state-of-the-art research on Arabic QA in general and MRC in particular on the Holy Qur’an, which constitutes a rich and fertile source of knowledge for Muslim and non-Muslim inquisitors and knowledge-seekers. In this paper, we provide an overview of the shared task that succeeded in attracting 13 teams to participate in the final phase, with a total of 30 submitted runs. Moreover, we outline the main approaches adopted by the participating teams in the context of highlighting some of our perceptions and general trends that characterize the participating systems and their submitted runs.</abstract>
      <url hash="16dac126">2022.osact-1.9</url>
      <bibkey>malhas-etal-2022-quran</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/arcd">ARCD</pwcdataset>
    </paper>
    <paper id="10">
      <title><fixed-case>DTW</fixed-case> at Qur’an <fixed-case>QA</fixed-case> 2022: Utilising Transfer Learning with Transformers for Question Answering in a Low-resource Domain</title>
      <author><first>Damith</first><last>Premasiri</last></author>
      <author><first>Tharindu</first><last>Ranasinghe</last></author>
      <author><first>Wajdi</first><last>Zaghouani</last></author>
      <author><first>Ruslan</first><last>Mitkov</last></author>
      <pages>88–95</pages>
      <abstract>The task of machine reading comprehension (MRC) is a useful benchmark to evaluate the natural language understanding of machines. It has gained popularity in the natural language processing (NLP) field mainly due to the large number of datasets released for many languages. However, the research in MRC has been understudied in several domains, including religious texts. The goal of the Qur’an QA 2022 shared task is to fill this gap by producing state-of-the-art question answering and reading comprehension research on Qur’an. This paper describes the DTW entry to the Quran QA 2022 shared task. Our methodology uses transfer learning to take advantage of available Arabic MRC data. We further improve the results using various ensemble learning strategies. Our approach provided a partial Reciprocal Rank (pRR) score of 0.49 on the test set, proving its strong performance on the task.</abstract>
      <url hash="0cf1458e">2022.osact-1.10</url>
      <bibkey>premasiri-etal-2022-dtw</bibkey>
      <pwccode url="https://github.com/damithdr/questionanswering" additional="false">damithdr/questionanswering</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/squad">SQuAD</pwcdataset>
    </paper>
    <paper id="11">
      <title>e<fixed-case>R</fixed-case>ock at Qur’an <fixed-case>QA</fixed-case> 2022: Contemporary Deep Neural Networks for Qur’an based Reading Comprehension Question Answers</title>
      <author><first>Esha</first><last>Aftab</last></author>
      <author><first>Muhammad Kamran</first><last>Malik</last></author>
      <pages>96–103</pages>
      <abstract>Question Answering (QA) has enticed the interest of NLP community in recent years. NLP enthusiasts are engineering new Models and fine-tuning the existing ones that can give out answers for the posed questions. The deep neural network models are found to perform exceptionally on QA tasks, but these models are also data intensive. For instance, BERT has outperformed many of its contemporary contenders on SQuAD dataset. In this work, we attempt at solving the closed domain reading comprehension Question Answering task on QRCD (Qur’anic Reading Comprehension Dataset) to extract an answer span from the provided passage, using BERT as a baseline model. We improved the model’s output by applying regularization techniques like weight-decay and data augmentation. Using different strategies we had 0.59% and 0.31% partial Reciprocal Ranking (pRR) on development and testing data splits respectively.</abstract>
      <url hash="5a7a8978">2022.osact-1.11</url>
      <bibkey>aftab-malik-2022-erock</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/arcd">ARCD</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/squad">SQuAD</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/tydi-qa">TyDi QA</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/tydiqa-goldp">TyDiQA-GoldP</pwcdataset>
    </paper>
    <paper id="12">
      <title><fixed-case>GOF</fixed-case> at Qur’an <fixed-case>QA</fixed-case> 2022: Towards an Efficient Question Answering For The Holy Qu’ran In The <fixed-case>A</fixed-case>rabic Language Using Deep Learning-Based Approach</title>
      <author><first>Ali</first><last>Mostafa</last></author>
      <author><first>Omar</first><last>Mohamed</last></author>
      <pages>104–111</pages>
      <abstract>Recently, significant advancements were achieved in Question Answering (QA) systems in several languages. However, QA systems in the Arabic language require further research and improvement because of several challenges and limitations, such as a lack of resources. Especially for QA systems in the Holy Qur’an since it is in classical Arabic and most recent publications are in Modern Standard Arabic. In this research, we report our submission to the Qur’an QA 2022 Shared task-organized with the 5th Workshop on Open-Source Arabic Corpora and Processing Tools Arabic (OSACT5). We propose a method for dealing with QA issues in the Holy Qur’an using Deep Learning models. Furthermore, we address the issue of the proposed dataset’s limited sample size by fine-tuning the model several times on several large datasets before fine-tuning it on the proposed dataset achieving 66.9% pRR 54.59% pRR on the development and test sets, respectively.</abstract>
      <url hash="c313e4b2">2022.osact-1.12</url>
      <bibkey>mostafa-mohamed-2022-gof</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/arcd">ARCD</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/squad">SQuAD</pwcdataset>
    </paper>
    <paper id="13">
      <title><fixed-case>LARSA</fixed-case>22 at Qur’an <fixed-case>QA</fixed-case> 2022: Text-to-Text Transformer for Finding Answers to Questions from Qur’an</title>
      <author><first>Youssef</first><last>Mellah</last></author>
      <author><first>Ibtissam</first><last>Touahri</last></author>
      <author><first>Zakaria</first><last>Kaddari</last></author>
      <author><first>Zakaria</first><last>Haja</last></author>
      <author><first>Jamal</first><last>Berrich</last></author>
      <author><first>Toumi</first><last>Bouchentouf</last></author>
      <pages>112–119</pages>
      <abstract>Question Answering (QA) is one of the main foсuses of Natural Language Proсessing (NLP) researсh. However, Arabiс Question Answering is still not within reaсh. The сhallenges of the Arabiс language and the laсk of resourсes have made it diffiсult to provide powerful Arabiс QA systems with high aссuraсy. While low aссuraсy may be aссepted for general purpose systems, it is сritiсal in some fields suсh as religious affairs. Therefore, there is a need for speсialized aссurate systems that target these сritiсal fields. In this paper, we propose a Transformer-based QA system using the mT5 Language Model (LM). We finetuned the model on the Qur’aniс Reading Сomprehension Dataset (QRСD) whiсh was provided in the сontext of the Qur’an QA 2022 shared task. The QRСD dataset сonsists of question-passage pairs as input, and the сorresponding adequate answers provided by expert annotators as output. Evaluation results on the same DataSet show that our best model сan aсhieve 0.98 (F1 Sсore) on the Dev Set and 0.40 on the Test Set. We disсuss those results and сhallenges, then propose potential solutions for possible improvements. The sourсe сode is available on our repository.</abstract>
      <url hash="dc6004cd">2022.osact-1.13</url>
      <bibkey>mellah-etal-2022-larsa22</bibkey>
    </paper>
    <paper id="14">
      <title><fixed-case>LK</fixed-case>2022 at Qur’an <fixed-case>QA</fixed-case> 2022: Simple Transformers Model for Finding Answers to Questions from Qur’an</title>
      <author><first>Abdullah</first><last>Alsaleh</last></author>
      <author><first>Saud</first><last>Althabiti</last></author>
      <author><first>Ibtisam</first><last>Alshammari</last></author>
      <author><first>Sarah</first><last>Alnefaie</last></author>
      <author><first>Sanaa</first><last>Alowaidi</last></author>
      <author><first>Alaa</first><last>Alsaqer</last></author>
      <author><first>Eric</first><last>Atwell</last></author>
      <author><first>Abdulrahman</first><last>Altahhan</last></author>
      <author><first>Mohammad</first><last>Alsalka</last></author>
      <pages>120–125</pages>
      <abstract>Question answering is a specialized area in the field of NLP that aims to extract the answer to a user question from a given text. Most studies in this area focus on the English language, while other languages, such as Arabic, are still in their early stage. Recently, research tend to develop question answering systems for Arabic Islamic texts, which may impose challenges due to Classical Arabic. In this paper, we use Simple Transformers Question Answering model with three Arabic pre-trained language models (AraBERT, CAMeL-BERT, ArabicBERT) for Qur’an Question Answering task using Qur’anic Reading Comprehension Dataset. The model is set to return five answers ranking from the best to worst based on their probability scores according to the task details. Our experiments with development set shows that AraBERT V0.2 model outperformed the other Arabic pre-trained models. Therefore, AraBERT V0.2 was chosen for the the test set and it performed fair results with 0.45 pRR score, 0.16 EM score and 0.42 F1 score.</abstract>
      <url hash="2fa07e37">2022.osact-1.14</url>
      <bibkey>alsaleh-etal-2022-lk2022</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/arcd">ARCD</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/squad">SQuAD</pwcdataset>
    </paper>
    <paper id="15">
      <title>niksss at Qur’an <fixed-case>QA</fixed-case> 2022: A Heavily Optimized <fixed-case>BERT</fixed-case> Based Model for Answering Questions from the Holy Qu’ran</title>
      <author><first>Nikhil</first><last>Singh</last></author>
      <pages>126–129</pages>
      <abstract>This paper presents the system description by team niksss for the Qur’an QA 2022 Shared Task. The goal of this shared task was to evaluate systems for Arabic Reading Comprehension over the Holy Quran. The task was set up as a question-answering task, such that, given a passage from the Holy Quran (consisting of consecutive verses in a specific surah(Chapter)) and a question (posed in Modern Standard Arabic (MSA)) over that passage, the system is required to extract a span of text from that passage as an answer to the question. The span was required to be an exact sub-string of the passage. We attempted to solve this task using three techniques namely conditional text-to-text generation, embedding clustering, and transformers-based question answering.</abstract>
      <url hash="02665f6b">2022.osact-1.15</url>
      <bibkey>singh-2022-niksss-quran</bibkey>
    </paper>
    <paper id="16">
      <title><fixed-case>QQAT</fixed-case>eam at Qur’an <fixed-case>QA</fixed-case> 2022: Fine-Tunning <fixed-case>A</fixed-case>rabic <fixed-case>QA</fixed-case> Models for Qur’an <fixed-case>QA</fixed-case> Task</title>
      <author><first>Basem</first><last>Ahmed</last></author>
      <author><first>Motaz</first><last>Saad</last></author>
      <author><first>Eshrag A.</first><last>Refaee</last></author>
      <pages>130–135</pages>
      <abstract>The problem of auto-extraction of reliable answers from a reference text like a constitution or holy book is a real challenge for the natural languages research community. Qurán is the holy book of Islam and the primary source of legislation for millions of Muslims around the world, which can trigger the curiosity of non-Muslims to find answers about various topics from the Qurán. Previous work on Question Answering (Q&amp;A) from Qurán is scarce and lacks the benchmark of previously developed systems on a testbed to allow meaningful comparison and identify developments and challenges. This work presents an empirical investigation of our participation in the Qurán QA shared task (2022) that utilizes a benchmark dataset of 1,093 tuples of question-Qurán passage pairs. The dataset comprises Qurán verses, questions and several ranked possible answers. This paper describes the approach we follow with our participation in the shared task and summarises our main findings. Our system attained the best score at 0.63 pRR and 0.59 F1 on the development set and 0.56 pRR and 0.51 F1 on the test set. The best results of the Exact Match (EM) score at 0.34 indicate the difficulty of the task and the need for more future work to tackle this challenging task.</abstract>
      <url hash="41be478c">2022.osact-1.16</url>
      <bibkey>ahmed-etal-2022-qqateam</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/squad">SQuAD</pwcdataset>
    </paper>
    <paper id="17">
      <title><fixed-case>SMASH</fixed-case> at Qur’an <fixed-case>QA</fixed-case> 2022: Creating Better Faithful Data Splits for Low-resourced Question Answering Scenarios</title>
      <author><first>Amr</first><last>Keleg</last></author>
      <author><first>Walid</first><last>Magdy</last></author>
      <pages>136–145</pages>
      <abstract>The Qur’an QA 2022 shared task aims at assessing the possibility of building systems that can extract answers to religious questions given relevant passages from the Holy Qur’an. This paper describes SMASH’s system that was used to participate in this shared task. Our experiments reveal a data leakage issue among the different splits of the dataset. This leakage problem hinders the reliability of using the models’ performance on the development dataset as a proxy for the ability of the models to generalize to new unseen samples. After creating better faithful splits from the original dataset, the basic strategy of fine-tuning a language model pretrained on classical Arabic text yielded the best performance on the new evaluation split. The results achieved by the model suggests that the small scale dataset is not enough to fine-tune large transformer-based language models in a way that generalizes well. Conversely, we believe that further attention could be paid to the type of questions that are being used to train the models given the sensitivity of the data.</abstract>
      <url hash="d8bee53e">2022.osact-1.17</url>
      <bibkey>keleg-magdy-2022-smash</bibkey>
      <pwccode url="https://github.com/amr-keleg/smash-quranqa" additional="false">amr-keleg/smash-quranqa</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/squad">SQuAD</pwcdataset>
    </paper>
    <paper id="18">
      <title>Stars at Qur’an <fixed-case>QA</fixed-case> 2022: Building Automatic Extractive Question Answering Systems for the Holy Qur’an with Transformer Models and Releasing a New Dataset</title>
      <author><first>Ahmed</first><last>Sleem</last></author>
      <author><first>Eman Mohammed lotfy</first><last>Elrefai</last></author>
      <author><first>Marwa Mohammed</first><last>Matar</last></author>
      <author><first>Haq</first><last>Nawaz</last></author>
      <pages>146–153</pages>
      <abstract>The Holy Qur’an is the most sacred book for more than 1.9 billion Muslims worldwide, and it provides a guide for their behaviours and daily interactions. Its miraculous eloquence and the divine essence of its verses (Khorami, 2014)(Elhindi,2017) make it far more difficult for non-scholars to answer their questions from the Qur’an. Here comes the significant role of technology in assisting all Muslims in answering their Qur’anic questions with state-of-the-art advancements in natural language processing (NLP) and information retrieval (IR). The task of constructing the finest automatic extractive Question Answering system from the Holy Qur’an with the use of the recently available Qur’anic Reading Comprehension Dataset(QRCD) was announced for LREC 2022 (Malhas et al., 2022) which opened up this new area for researchers around the world. In this paper, we propose a novel Qur’an Question Answering dataset with over 700 samples to aid future Qur’an research projects and three different approaches where we utilised self-attention based deep learning models (transformers) for building reliable intelligent question-answering systems for the Holy Qur’an that achieved a partial Reciprocal Rank (pRR) best score of 52% on the released QRCD test se</abstract>
      <url hash="29fba83c">2022.osact-1.18</url>
      <bibkey>sleem-etal-2022-stars</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/arcd">ARCD</pwcdataset>
    </paper>
    <paper id="19">
      <title><fixed-case>TCE</fixed-case> at Qur’an <fixed-case>QA</fixed-case> 2022: <fixed-case>A</fixed-case>rabic Language Question Answering Over Holy Qur’an Using a Post-Processed Ensemble of <fixed-case>BERT</fixed-case>-based Models</title>
      <author><first>Mohamemd</first><last>Elkomy</last></author>
      <author><first>Amany M.</first><last>Sarhan</last></author>
      <pages>154–161</pages>
      <abstract>In recent years, we witnessed great progress in different tasks of natural language understanding using machine learning. Question answering is one of these tasks which is used by search engines and social media platforms for improved user experience. Arabic is the language of the Holy Qur’an; the sacred text for 1.8 billion people across the world. Arabic is a challenging language for Natural Language Processing (NLP) due to its complex structures. In this article, we describe our attempts at OSACT5 Qur’an QA 2022 Shared Task, which is a question answering challenge on the Holy Qur’an in Arabic. We propose an ensemble learning model based on Arabic variants of BERT models. In addition, we perform post-processing to enhance the model predictions. Our system achieves a Partial Reciprocal Rank (pRR) score of 56.6% on the official test set.</abstract>
      <url hash="7b7b66d7">2022.osact-1.19</url>
      <bibkey>elkomy-sarhan-2022-tce</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/squad">SQuAD</pwcdataset>
    </paper>
    <paper id="20">
      <title>Overview of <fixed-case>OSACT</fixed-case>5 Shared Task on <fixed-case>A</fixed-case>rabic Offensive Language and Hate Speech Detection</title>
      <author><first>Hamdy</first><last>Mubarak</last></author>
      <author><first>Hend</first><last>Al-Khalifa</last></author>
      <author><first>Abdulmohsen</first><last>Al-Thubaity</last></author>
      <pages>162–166</pages>
      <abstract>This paper provides an overview of the shard task on detecting offensive language, hate speech, and fine-grained hate speech at the fifth workshop on Open-Source Arabic Corpora and Processing Tools (OSACT5). The shared task comprised of three subtasks; Subtask A, involving the detection of offensive language, which contains socially unacceptable or impolite content including any kind of explicit or implicit insults or attacks against individuals or groups; Subtask B, involving the detection of hate speech, which contains offensive language targeting individuals or groups based on common characteristics such as race, religion, gender, etc.; and Subtask C, involving the detection of the fine-grained type of hate speech which takes one value from the following types: (i) race/ethnicity/nationality, (ii) religion/belief, (iii) ideology, (iv) disability/disease, (v) social class, and (vi) gender. In total, 40 teams signed up to participate in Subtask A, and 17 of them submitted test runs. For Subtask B, 26 teams signed up to participate and 12 of them submitted runs. And for Subtask C, 23 teams signed up to participate and 10 of them submitted runs. 10 teams submitted papers describing their participation in one subtask or more, and 8 papers were accepted. We present and analyze all submissions in this paper.</abstract>
      <url hash="624c1860">2022.osact-1.20</url>
      <bibkey>mubarak-etal-2022-overview</bibkey>
    </paper>
    <paper id="21">
      <title><fixed-case>GOF</fixed-case> at <fixed-case>A</fixed-case>rabic Hate Speech 2022: Breaking The Loss Function Convention For Data-Imbalanced <fixed-case>A</fixed-case>rabic Offensive Text Detection</title>
      <author><first>Ali</first><last>Mostafa</last></author>
      <author><first>Omar</first><last>Mohamed</last></author>
      <author><first>Ali</first><last>Ashraf</last></author>
      <pages>167–175</pages>
      <abstract>With the rise of social media platforms, we need to ensure that all users have a secure online experience by eliminating and identifying offensive language and hate speech. Furthermore, detecting such content is challenging, particularly in the Arabic language, due to a number of challenges and limitations. In general, one of the most challenging issues in real-world datasets is long-tailed data distribution. We report our submission to the Offensive Language and hate-speech Detection shared task organized with the 5th Workshop on Open-Source Arabic Corpora and Processing Tools Arabic (OSACT5); in our approach, we focused on how to overcome such a problem by experimenting with alternative loss functions rather than using the traditional weighted cross-entropy loss. Finally, we evaluated various pre-trained deep learning models using the suggested loss functions to determine the optimal model. On the development and test sets, our final model achieved 86.97% and 85.17%, respectively.</abstract>
      <url hash="0e50951e">2022.osact-1.21</url>
      <bibkey>mostafa-etal-2022-gof</bibkey>
    </paper>
    <paper id="22">
      <title>i<fixed-case>C</fixed-case>ompass at <fixed-case>A</fixed-case>rabic Hate Speech 2022: Detect Hate Speech Using <fixed-case>QRNN</fixed-case> and Transformers</title>
      <author><first>Mohamed Aziz</first><last>Bennessir</last></author>
      <author><first>Malek</first><last>Rhouma</last></author>
      <author><first>Hatem</first><last>Haddad</last></author>
      <author><first>Chayma</first><last>Fourati</last></author>
      <pages>176–180</pages>
      <abstract>This paper provides a detailed overview of the system we submitted as part of the OSACT2022 Shared Tasks on Fine-Grained Hate Speech Detection on Arabic Twitter, its outcome, and limitations. Our submission is accomplished with a hard parameter sharing Multi-Task Model that consisted of a shared layer containing state-of-the-art contextualized text representation models such as MarBERT, AraBERT, ArBERT and task specific layers that were fine-tuned with Quasi-recurrent neural networks (QRNN) for each down-stream subtask. The results show that MARBERT fine-tuned with QRNN outperforms all of the previously mentioned models.</abstract>
      <url hash="d54493cb">2022.osact-1.22</url>
      <bibkey>bennessir-etal-2022-icompass</bibkey>
    </paper>
    <paper id="23">
      <title><fixed-case>UPV</fixed-case> at the <fixed-case>A</fixed-case>rabic Hate Speech 2022 Shared Task: Offensive Language and Hate Speech Detection using Transformers and Ensemble Models</title>
      <author><first>Angel Felipe</first><last>Magnossão de Paula</last></author>
      <author><first>Paolo</first><last>Rosso</last></author>
      <author><first>Imene</first><last>Bensalem</last></author>
      <author><first>Wajdi</first><last>Zaghouani</last></author>
      <pages>181–185</pages>
      <abstract>This paper describes our participation in the shared task Fine-Grained Hate Speech Detection on Arabic Twitter at the 5th Workshop on Open-Source Arabic Corpora and Processing Tools (OSACT). The shared task is divided into three detection subtasks: (i) Detect whether a tweet is offensive or not; (ii) Detect whether a tweet contains hate speech or not; and (iii) Detect the fine-grained type of hate speech (race, religion, ideology, disability, social class, and gender). It is an effort toward the goal of mitigating the spread of offensive language and hate speech in Arabic-written content on social media platforms. To solve the three subtasks, we employed six different transformer versions: AraBert, AraElectra, Albert-Arabic, AraGPT2, mBert, and XLM-Roberta. We experimented with models based on encoder and decoder blocks and models exclusively trained on Arabic and also on several languages. Likewise, we applied two ensemble methods: Majority vote and Highest sum. Our approach outperformed the official baseline in all the subtasks, not only considering F1-macro results but also accuracy, recall, and precision. The results suggest that the Highest sum is an excellent approach to encompassing transformer output to create an ensemble since this method offered at least top-two F1-macro values across all the experiments performed on development and test data.</abstract>
      <url hash="6b1ad524">2022.osact-1.23</url>
      <bibkey>magnossao-de-paula-etal-2022-upv</bibkey>
      <pwccode url="https://github.com/angelfelipemp/Transformers-for-Arabic-hate-speech-and-offensive-language" additional="false">angelfelipemp/Transformers-for-Arabic-hate-speech-and-offensive-language</pwccode>
    </paper>
    <paper id="24">
      <title>Meta <fixed-case>AI</fixed-case> at <fixed-case>A</fixed-case>rabic Hate Speech 2022: <fixed-case>M</fixed-case>ulti<fixed-case>T</fixed-case>ask Learning with Self-Correction for Hate Speech Classification</title>
      <author><first>Badr</first><last>AlKhamissi</last></author>
      <author><first>Mona</first><last>Diab</last></author>
      <pages>186–193</pages>
      <abstract>In this paper, we tackle the Arabic Fine-Grained Hate Speech Detection shared task and demonstrate significant improvements over reported baselines for its three subtasks. The tasks are to predict if a tweet contains (1) Offensive language; and whether it is considered (2) Hate Speech or not and if so, then predict the (3) Fine-Grained Hate Speech label from one of six categories. Our final solution is an ensemble of models that employs multitask learning and a self-consistency correction method yielding 82.7% on the hate speech subtask—reflecting a 3.4% relative improvement compared to previous work.</abstract>
      <url hash="6abdb939">2022.osact-1.24</url>
      <bibkey>alkhamissi-diab-2022-meta</bibkey>
    </paper>
    <paper id="25">
      <title><fixed-case>CHILLAX</fixed-case> - at <fixed-case>A</fixed-case>rabic Hate Speech 2022: A Hybrid Machine Learning and Transformers based Model to Detect <fixed-case>A</fixed-case>rabic Offensive and Hate Speech</title>
      <author><first>Kirollos</first><last>Makram</last></author>
      <author><first>Kirollos George</first><last>Nessim</last></author>
      <author><first>Malak Emad</first><last>Abd-Almalak</last></author>
      <author><first>Shady Zekry</first><last>Roshdy</last></author>
      <author><first>Seif Hesham</first><last>Salem</last></author>
      <author><first>Fady Fayek</first><last>Thabet</last></author>
      <author><first>Ensaf Hussien</first><last>Mohamed</last></author>
      <pages>194–199</pages>
      <abstract>Hate speech and offensive language have become a crucial problem nowadays due to the extensive usage of social media by people of different gender, nationality, religion and other types of characteristics allowing anyone to share their thoughts and opinions. In this research paper, We proposed a hybrid model for the first and second tasks of OSACT2022. This model used the Arabic pre-trained Bert language model MARBERT for feature extraction of the Arabic tweets in the dataset provided by the OSACT2022 shared task, then fed the features to two classic machine learning classifiers (Logistic Regression, Random Forest). The best results achieved for the offensive tweet detection task were by the Logistic Regression model with accuracy, precision, recall, and f1-score of 80%, 78%, 78%, and 78%, respectively. The results for the hate speech tweet detection task were 89%, 72%, 80%, and 76%.</abstract>
      <url hash="36bbd000">2022.osact-1.25</url>
      <bibkey>makram-etal-2022-chillax</bibkey>
    </paper>
    <paper id="26">
      <title><fixed-case>A</fixed-case>lex<fixed-case>U</fixed-case>-<fixed-case>AIC</fixed-case> at <fixed-case>A</fixed-case>rabic Hate Speech 2022: Contrast to Classify</title>
      <author><first>Ahmad</first><last>Shapiro</last></author>
      <author><first>Ayman</first><last>Khalafallah</last></author>
      <author><first>Marwan</first><last>Torki</last></author>
      <pages>200–208</pages>
      <abstract>Online presence on social media platforms such as Facebook and Twitter has become a daily habit for internet users. Despite the vast amount of services the platforms offer for their users, users suffer from cyber-bullying, which further leads to mental abuse and may escalate to cause physical harm to individuals or targeted groups. In this paper, we present our submission to the Arabic Hate Speech 2022 Shared Task Workshop (OSACT5 2022) using the associated Arabic Twitter dataset. The Shared Task consists of 3 Sub-tasks, Sub-task A focuses on detecting whether the tweet is Offensive or not. Then, For offensive Tweets, Sub-task B focuses on detecting whether the tweet is Hate Speech or not. Finally, For Hate Speech Tweets, Sub-task C focuses on detecting the fine-grained type of hate speech among six different classes. Transformer models proved their efficiency in classification tasks, but with the problem of over-fitting when fine-tuned on a small or an imbalanced dataset. We overcome this limitation by investigating multiple training paradigms such as Contrastive learning and Multi-task learning along with classification fine-tuning and an ensemble of our top 5 performers. Our proposed solution achieved 0.841, 0.817, and 0.476 macro F1-average in sub-tasks A, B, and C respectively.</abstract>
      <url hash="40775429">2022.osact-1.26</url>
      <bibkey>shapiro-etal-2022-alexu</bibkey>
    </paper>
    <paper id="27">
      <title><fixed-case>GUCT</fixed-case> at <fixed-case>A</fixed-case>rabic Hate Speech 2022: Towards a Better Isotropy for Hatespeech Detection</title>
      <author><first>Nehal</first><last>Elkaref</last></author>
      <author><first>Mervat</first><last>Abu-Elkheir</last></author>
      <pages>209–213</pages>
      <abstract>Hate Speech is an increasingly common occurrence in verbal and textual exchanges on online platforms, where many users, especially those from vulnerable minorities, are in danger of being attacked or harassed via text messages, posts, comments, or articles. Therefore, it is crucial to detect and filter out hate speech in the various forms of text encountered on online and social platforms. In this paper, we present our work on the shared task of detecting hate speech in dialectical Arabic tweets as part of the OSACT shared task on Fine-grained Hate Speech Detection. Normally, tweets have a short length, and hence do not have sufficient context for language models, which in turn makes a classification task challenging. To contribute to sub-task A, we leverage MARBERT’s pre-trained contextual word representations and aim to improve their semantic quality using a cluster-based approach. Our work explores MARBERT’s embedding space and assess its geometric properties in-order to achieve better representations and subsequently better classification performance. We propose to improve the isotropic word representations of MARBERT via clustering. we compare the word representations generated by our approach to MARBERT’s default word representations via feeding each to a bidirectional LSTM to detect offensive and non-offensive tweets. Our results show that enhancing the isotropy of an embedding space can boost performance. Our system scores 81.2% on accuracy and a macro-averaged F1 score of 79.1% on sub-task A’s development set and achieves 76.5% for accuracy and an F1 score of 74.2% on the test set.</abstract>
      <url hash="a9a8b933">2022.osact-1.27</url>
      <bibkey>elkaref-abu-elkheir-2022-guct</bibkey>
    </paper>
    <paper id="28">
      <title>ai<fixed-case>X</fixed-case>plain at <fixed-case>A</fixed-case>rabic Hate Speech 2022: An Ensemble Based Approach to Detecting Offensive Tweets</title>
      <author><first>Salaheddin</first><last>Alzubi</last></author>
      <author><first>Thiago Castro</first><last>Ferreira</last></author>
      <author><first>Lucas</first><last>Pavanelli</last></author>
      <author><first>Mohamed</first><last>Al-Badrashiny</last></author>
      <pages>214–217</pages>
      <abstract>Abusive speech on online platforms has a detrimental effect on users’ mental health. This warrants the need for innovative solutions that automatically moderate content, especially on online platforms such as Twitter where a user’s anonymity is loosely controlled. This paper outlines aiXplain Inc.’s ensemble based approach to detecting offensive speech in the Arabic language based on OSACT5’s shared sub-task A. Additionally, this paper highlights multiple challenges that may hinder progress on detecting abusive speech and provides potential avenues and techniques that may lead to significant progress.</abstract>
      <url hash="bda88a34">2022.osact-1.28</url>
      <bibkey>alzubi-etal-2022-aixplain</bibkey>
    </paper>
  </volume>
</collection>
