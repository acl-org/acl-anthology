<?xml version='1.0' encoding='UTF-8'?>
<collection id="2023.splurobonlp">
  <volume id="1" ingest-date="2023-11-30" type="proceedings">
    <meta>
      <booktitle>Proceedings of the 3rd Combined Workshop on Spatial Language Understanding and Grounded Communication for Robotics (SpLU-RoboNLP 2023)</booktitle>
      <editor><first>Aishwarya</first><last>Padmakumar</last></editor>
      <editor><first>Mert</first><last>Inan</last></editor>
      <editor><first>Yue</first><last>Fan</last></editor>
      <editor><first>Xin</first><last>Wang</last></editor>
      <editor><first>Malihe</first><last>Alikhani</last></editor>
      <publisher>Association for Computational Linguistics</publisher>
      <address>Singapore</address>
      <month>December</month>
      <year>2023</year>
      <url hash="8d922e2f">2023.splurobonlp-1</url>
      <venue>splurobonlp</venue>
      <venue>ws</venue>
    </meta>
    <frontmatter>
      <url hash="9ef7bec4">2023.splurobonlp-1.0</url>
      <bibkey>splurobonlp-ws-2023-combined</bibkey>
    </frontmatter>
    <paper id="1">
      <title>Dialogue-based generation of self-driving simulation scenarios using Large Language Models</title>
      <author><first>Antonio Valerio</first><last>Miceli Barone</last><affiliation>The University of Edinburgh</affiliation></author>
      <author><first>Craig</first><last>Innes</last><affiliation>University of Edinburgh</affiliation></author>
      <author><first>Alex</first><last>Lascarides</last><affiliation>University of Edinburgh</affiliation></author>
      <pages>1-12</pages>
      <abstract>Simulation is an invaluable tool for developing and evaluating controllers for self-driving cars. Current simulation frameworks are driven by highly-specialist domain specific languages, and so a natural language interface would greatly enhance usability. But there is often a gap, consisting of tacit assumptions the user is making, between a concise English utterance and the executable code that captures the user’s intent. In this paper we describe a system that addresses this issue by supporting an extended multimodal interaction: the user can follow up prior instructions with refinements or revisions, in reaction to the simulations that have been generated from their utterances so far. We use Large Language Models (LLMs) to map the user’s English utterances in this interaction into domain-specific code, and so we explore the extent to which LLMs capture the context sensitivity that’s necessary for computing the speaker’s intended message in discourse.</abstract>
      <url hash="4d8dd4db">2023.splurobonlp-1.1</url>
      <attachment type="SupplementaryMaterial" hash="e23adad3">2023.splurobonlp-1.1.SupplementaryMaterial.zip</attachment>
      <bibkey>miceli-barone-etal-2023-dialogue</bibkey>
      <doi>10.18653/v1/2023.splurobonlp-1.1</doi>
    </paper>
  </volume>
</collection>
