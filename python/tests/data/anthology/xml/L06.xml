<?xml version='1.0' encoding='UTF-8'?>
<collection id="L06">
  <volume id="1" type="proceedings">
    <meta>
      <booktitle>Proceedings of the Fifth International Conference on Language Resources and Evaluation (<fixed-case>LREC</fixed-case>’06)</booktitle>
      <editor><first>Nicoletta</first><last>Calzolari</last></editor>
      <editor><first>Khalid</first><last>Choukri</last></editor>
      <editor><first>Aldo</first><last>Gangemi</last></editor>
      <editor><first>Bente</first><last>Maegaard</last></editor>
      <editor><first>Joseph</first><last>Mariani</last></editor>
      <editor><first>Jan</first><last>Odijk</last></editor>
      <editor><first>Daniel</first><last>Tapias</last></editor>
      <publisher>European Language Resources Association (ELRA)</publisher>
      <address>Genoa, Italy</address>
      <month>May</month>
      <year>2006</year>
      <venue>lrec</venue>
    </meta>
    <frontmatter>
      <bibkey>lrec-2006-international</bibkey>
    </frontmatter>
    <paper id="1">
      <author><first>Nina</first><last>Grønnum</last></author>
      <title><fixed-case>D</fixed-case>an<fixed-case>PASS</fixed-case> - A <fixed-case>D</fixed-case>anish Phonetically Annotated Spontaneous Speech Corpus</title>
      <url>http://www.lrec-conf.org/proceedings/lrec2006/pdf/4_pdf.pdf</url>
      <abstract>A corpus is described consisting of non-scripted monologues and dialogues, recorded by 22 speakers, comprising a total of about 70.000 words, corresponding to well over 10 hours of speech. The monologues were recorded as one-way communication with blind partner where the speaker performed three different tasks: (S)he described a network consisting of various geometrical shapes in various colours. (S)he guided the listener through four different routes in a virtual city map.(S)he instructed the listener how to build a house from its individual parts. The dialogues are replicas of the HCRC map tasks (http://www.hcrc.ed.ac.uk/maptask/). Annotation is performed in Praat. The sound files are segmented into prosodic phrases, words, and syllables, always to the nearest zero-crossing in the waveform. It is supplied, in seven separate interval tiers, with an orthographical transcription, detailed part-of-speech tags, simplified part-of-speech tags, a phonological transcription, a broad phonetic transcription, the pitch relation between each stressed and post-tonic syllable, the phrasal intonation, and an empty tier for comments.</abstract>
      <bibkey>gronnum-2006-danpass</bibkey>
    </paper>
    <paper id="60">
      <author><first>Brian</first><last>Roark</last></author>
      <author><first>Mary</first><last>Harper</last></author>
      <author><first>Eugene</first><last>Charniak</last></author>
      <author><first>Bonnie</first><last>Dorr</last></author>
      <author><first>Mark</first><last>Johnson</last></author>
      <author><first>Jeremy</first><last>Kahn</last></author>
      <author id="yang-liu-icsi"><first>Yang</first><last>Liu</last></author>
      <author><first>Mari</first><last>Ostendorf</last></author>
      <author><first>John</first><last>Hale</last></author>
      <author><first>Anna</first><last>Krasnyanskaya</last></author>
      <author><first>Matthew</first><last>Lease</last></author>
      <author><first>Izhak</first><last>Shafran</last></author>
      <author><first>Matthew</first><last>Snover</last></author>
      <author><first>Robin</first><last>Stewart</last></author>
      <author><first>Lisa</first><last>Yung</last></author>
      <title><fixed-case>SP</fixed-case>arseval: Evaluation Metrics for Parsing Speech</title>
      <url>http://www.lrec-conf.org/proceedings/lrec2006/pdf/116_pdf.pdf</url>
      <abstract>While both spoken and written language processing stand to benefit from parsing, the standard Parseval metrics (Black et al., 1991) and their canonical implementation (Sekine and Collins, 1997) are only useful for text. The Parseval metrics are undefined when the words input to the parser do not match the words in the gold standard parse tree exactly, and word errors are unavoidable with automatic speech recognition (ASR) systems. To fill this gap, we have developed a publicly available tool for scoring parses that implements a variety of metrics which can handle mismatches in words and segmentations, including: alignment-based bracket evaluation, alignment-based dependency evaluation, and a dependency evaluation that does not require alignment. We describe the different metrics, how to use the tool, and the outcome of an extensive set of experiments on the sensitivity.</abstract>
      <bibkey>roark-etal-2006-sparseval</bibkey>
    </paper>
    <paper id="67">
      <author><first>M.</first><last>Yaseen</last></author>
      <author><first>M.</first><last>Attia</last></author>
      <author><first>B.</first><last>Maegaard</last></author>
      <author><first>K.</first><last>Choukri</last></author>
      <author><first>N.</first><last>Paulsson</last></author>
      <author><first>S.</first><last>Haamid</last></author>
      <author id="steven-krauwer"><first>S.</first><last>Krauwer</last></author>
      <author><first>C.</first><last>Bendahman</last></author>
      <author><first>H.</first><last>Fersøe</last></author>
      <author><first>M.</first><last>Rashwan</last></author>
      <author><first>B.</first><last>Haddad</last></author>
      <author><first>C.</first><last>Mukbel</last></author>
      <author><first>A.</first><last>Mouradi</last></author>
      <author><first>A.</first><last>Al-Kufaishi</last></author>
      <author><first>M.</first><last>Shahin</last></author>
      <author><first>N.</first><last>Chenfour</last></author>
      <author><first>A.</first><last>Ragheb</last></author>
      <title>Building Annotated Written and Spoken <fixed-case>A</fixed-case>rabic <fixed-case>LR</fixed-case>s in <fixed-case>NEMLAR</fixed-case> Project</title>
      <url>http://www.lrec-conf.org/proceedings/lrec2006/pdf/131_pdf.pdf</url>
      <abstract>The NEMLAR project: Network for Euro-Mediterranean LAnguage Resource and human language technology development and support (www.nemlar.org) was a project supported by the EC with partners from Europe and Arabic countries, whose objective is to build a network of specialized partners to promote and support the development of Arabic Language Resources (LRs) in the Mediterranean region. The project focused on identifying the state of the art of LRs in the region, assessing priority requirements through consultations with language industry and communication players, and establishing a protocol for developing and identifying a Basic Language Resource Kit (BLARK) for Arabic, and to assess first priority requirements. The BLARK is defined as the minimal set of language resources that is necessary to do any pre-competitive research and education, in addition to the development of crucial components for any future NLP industry. Following the identification of high priority resources the NEMLAR partners agreed to focus on, and produce three main resources, which are 1) Annotated Arabic written corpus of about 500 K words, 2) Arabic speech corpus for TTS applications of 2x5 hours, and 3) Arabic broadcast news speech corpus of 40 hours Modern Standard Arabic. For each of the resources underlying linguistic models and assumptions of the corpus, technical specifications, methodologies for the collection and building of the resources, validation and verification mechanisms were put and applied for the three LRs.</abstract>
      <bibkey>yaseen-etal-2006-building</bibkey>
    </paper>
    <paper id="471">
      <author><first>Ann</first><last>Bies</last></author>
      <author><first>Stephanie</first><last>Strassel</last></author>
      <author><first>Haejoong</first><last>Lee</last></author>
      <author><first>Kazuaki</first><last>Maeda</last></author>
      <author><first>Seth</first><last>Kulick</last></author>
      <author id="yang-liu-icsi"><first>Yang</first><last>Liu</last></author>
      <author><first>Mary</first><last>Harper</last></author>
      <author><first>Matthew</first><last>Lease</last></author>
      <title>Linguistic Resources for Speech Parsing</title>
      <url>http://www.lrec-conf.org/proceedings/lrec2006/pdf/755_pdf.pdf</url>
      <abstract>We report on the success of a two-pass approach to annotating metadata, speech effects and syntactic structure in English conversational speech: separately annotating transcribed speech for structural metadata, or structural events, (fillers, speech repairs ( or edit dysfluencies) and SUs, or syntactic/semantic units) and for syntactic structure (treebanking constituent structure and shallow argument structure). The two annotations were then combined into a single representation. Certain alignment issues between the two types of annotation led to the discovery and correction of annotation errors in each, resulting in a more accurate and useful resource. The development of this corpus was motivated by the need to have both metadata and syntactic structure annotated in order to support synergistic work on speech parsing and structural event detection. Automatic detection of these speech phenomena would simultaneously improve parsing accuracy and provide a mechanism for cleaning up transcriptions for downstream text processing. Similarly, constraints imposed by text processing systems such as parsers can be used to help improve identification of disfluencies and sentence boundaries. This paper reports on our efforts to develop a linguistic resource providing both spoken metadata and syntactic structure information, and describes the resulting corpus of English conversational speech.</abstract>
      <bibkey>bies-etal-2006-linguistic</bibkey>
    </paper>
  </volume>
</collection>
